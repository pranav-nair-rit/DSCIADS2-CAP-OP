Comment
b'TODO continuous feature names no longer required only number; move to infer number of continuous features from model_builder and batch_yielder'
b'TODO: check whether model_builder is necessary here'
b'TODO model.default_collection only in BaseModel class'
b'TODO Lida Xu please re-write the CNN model'
"b'\\""\\""\\"" || TODO: This test fails due to the random state not being properly fixed ||  || def test_hyperband(): ||     model; param_dist; X; y; rng = setup() ||     search = HyperbandSearchCV(model; param_dist; random_state=rng) ||     search.fit(X; y) ||  ||     # results = pd.DataFrame(search.cv_results_) ||     expected_params = { ||         \'bootstrap\': False; ||         \'criterion\': \'entropy\'; ||         \'max_depth\': None; ||         \'max_features\': 7; ||         \'min_samples_leaf\': 2; ||         \'min_samples_split\': 2; ||         \'n_estimators\': 81 ||     } ||  ||     # assert(results.shape[0] == 186) TODO: sort out what the expected n_i and r_i values are ||     assert(search.best_params_ == expected_params) || \\""\\""\\""'"
b'TODO: feature translate should out of this main program for better compatible with keras and estimator model'
b'TODO: convert model to Functional or Sequential so that can be saved as h5 model'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || # TODO(sguada) docstring paragraph by (a) motivating the need for the file and || # (b) defining clones. ||  || # TODO(sguada) describe the high-level components of model deployment. || # E.g. \\""each model deployment is composed of several parts: a DeploymentConfig; || # which captures A; B and C; an input_fn which loads data.. etc ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||   g = tf.Graph() ||  ||   # Set up DeploymentConfig ||   config = slim.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||   # Create the global step on the device storing the variables. ||   with tf.device(config.variables_device()): ||     global_step = slim.create_global_step() ||  ||   # Define the inputs ||   with tf.device(config.inputs_device()): ||     images; labels = LoadData(...) ||     inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||   # Define the optimizer. ||   with tf.device(config.optimizer_device()): ||     optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||   # Define the model including the loss. ||   def model_fn(inputs_queue): ||     images; labels = inputs_queue.dequeue() ||     predictions = CreateNetwork(images) ||     slim.losses.log_loss(predictions; labels) ||  ||   model_dp = slim.deploy(config; model_fn; [inputs_queue]; optimizer=optimizer) ||  ||   # Run training. ||   slim.learning.train(model_dp.train_op; my_log_dir; ||                       summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||   * outputs: The return values of the calls to `model_fn()`. ||   * scope: The scope used to create the clone. ||   * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||   * train_op: An operation that run the optimizer training op and include ||     all the update ops created by `model_fn`. Present only if an optimizer ||     was specified. ||   * summary_op: An operation that run the summaries created by `model_fn` ||     and process_gradients. ||   * total_loss: A `Tensor` that contains the sum of all losses created by ||     `model_fn` plus the regularization losses. ||   * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||   * num_clones: Number of model clones to deploy in each replica. ||   * clone_on_cpu: True if clones should be placed on CPU. ||   * replica_id: Integer.  Index of the replica for which the model is ||       deployed.  Usually 0 for the chief replica. ||   * num_replicas: Number of replicas to use. ||   * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||   * worker_job_name: A name for the worker job. ||   * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||   - describe side effect to the graph. ||   - what happens to summaries and update_ops. ||   - which graph collections are altered. ||   - write a tutorial on how to use this. ||   - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
"b""TODO: This should be done in model's postprocess function ideally."""
b'TODO replace with database model'
b'TODO Move to test_role_model.py'
b'TODO explore impact of scaling on model performance'
b'TODO: check that model is loading from .h5 correctly'
b'TODO: add auxiliary classifiers to model'
b'TODO: evaluate the model'
b'TODO: save the best model'
b'TODO: Change the model name to train different models'
b'TODO: We could estimate covariance of Y using a hierarchy of corex models!'
b'FIXME: pre-train the model'
"b'\\""\\""\\""An implementation of the overfitting test for the Transformer model. ||  || A simple test; which often signifies bugs in the implementation of a model; is the overfitting test. To that end; the || considered model is trained and evaluated on the same tiny dataset; which it should be able to overfit easily. || Therefore; the final model should yield very high probabilities for the desired target values. If this is not the case; || however; then there is probably something wrong with the tested model and\\/or its implementation. ||  || TODO: explain a bit more || \\""\\""\\""'"
b'TODO Keras models to detect whether an image is present'
b'FIXME: exclude accented characters for model 6?'
b'FIXME: do unknown word model stuff here.'
b'FIXME: re-estimate unknown word model?'
b'TODO FIXME: change it to ADE20K dataset and pretrained model'
"b'\\""\\""\\"" || CommandLine: ||     python ~\\/code\\/netharn\\/netharn\\/fit_harn.py __doc__ ||  || Notes: ||     when profiling ensure CUDA_LAUNCH_BLOCKING=1 ||  || Notes: ||     to use; your training session must have the concept of: ||         * epochs ||         * batch_size ||         * xpu ||         * train \\/ validation datasets ||  ||     or better yet: ||         * a model ||         * a criterion ||         * an optimizer ||  || TODO: ||     [ ] - output \\""glance\\"" curves to disk ||     [x] - move logs to a logs folder. Keep a single master log in the root ||     [ ] - Why didnt the best_snapshot.pt get saved in the most recent yolo run? ||  || Example: ||     >>> import netharn as nh ||     >>> size = 3 ||     >>> max_epoch = 10 ||     >>> datasets = { ||     >>>     \'train\': nh.data.ToyData2d(size=size; border=1; n=256; rng=0); ||     >>>     \'vali\': nh.data.ToyData2d(size=size; border=1; n=128; rng=1); ||     >>> } ||     >>> hyper = { ||     >>>     # --- Data First ||     >>>     \'datasets\'    : datasets; ||     >>>     \'nice\'        : \'demo\'; ||     >>>     \'workdir\'     : ub.ensure_app_cache_dir(\'netharn\\/demo\'); ||     >>>     \'loaders\'     : {\'batch_size\': 64}; ||     >>>     \'xpu\'         : nh.XPU.cast(\'auto\'); ||     >>>     # --- Algorithm Second ||     >>>     \'model\'       : (nh.models.ToyNet2d; {}); ||     >>>     \'optimizer\'   : (nh.optimizers.SGD; { ||     >>>         \'lr\': 0.0001 ||     >>>     }); ||     >>>     \'criterion\'   : (nh.criterions.CrossEntropyLoss; {}); ||     >>>     #\'criterion\'   : (nh.criterions.FocalLoss; {}); ||     >>>     \'initializer\' : (nh.initializers.KaimingNormal; { ||     >>>         \'param\': 0; ||     >>>     }); ||     >>>     \'scheduler\'   : (nh.schedulers.ListedLR; { ||     >>>         \'points\': {0: .0001; 2: .01; 5: .015; 6: .005; 9: .001}; ||     >>>         \'interpolate\': True; ||     >>>     }); ||     >>>     \'dynamics\'   : {\'batch_step\': 4}; ||     >>>     \'monitor\'     : (nh.Monitor; { ||     >>>         \'max_epoch\': max_epoch; ||     >>>     }); ||     >>> } ||     >>> harn = FitHarn(hyper) ||     >>> harn.config[\'use_tqdm\'] = 1 ||     >>> harn.initialize(reset=\'delete\') ||     >>> harn.run() || \\""\\""\\""'"
"b'\\""\\""\\"" || Notes: ||     when profiling ensure CUDA_LAUNCH_BLOCKING=1 ||  || Notes: ||     to use; your training session must have the concept of: ||         * epochs ||         * batch_size ||         * xpu ||         * train \\/ validation datasets ||  ||     or better yet: ||         * a model ||         * a criterion ||         * an optimizer ||  || TODO: ||     [ ] - output \\""glance\\"" curves to disk ||     [x] - move logs to a logs folder. Keep a single master log in the root ||     [ ] - Why didnt the best_snapshot.pt get saved in the most recent yolo run? ||  || Notes: ||     In the following example we demonstrate how to use netharn to train a model ||     to solve a toy problem. ||  ||     In this toy problem; we do not extend the nh.FitHarn object; so we are ||     using the default behavior of ``run_batch``. The default ``on_batch``; and ||     ``on_epoch`` do nothing; so only loss will be the only measurement of ||     performance. ||  ||     For further examples please see the examples directory. These example show ||     how to extend nh.FitHarn to measure performance wrt a particular problem. ||     The MNIST and CIFAR examples are the most simple. The YOLO example is more ||     complex.  The IBEIS example depends on non-public data \\/ software; but can ||     still be useful to look at.  Its complexity is more than CIFAR but less ||     than YOLO. ||  || CommandLine: ||     xdoctest netharn.fit_harn __doc__:0 ||     xdoctest netharn.fit_harn __doc__:0 --progiter ||  || Example: ||     >>> import netharn as nh ||     >>> hyper = nh.HyperParams(**{ ||     >>>     # ================ ||     >>>     # Environment Components ||     >>>     \'workdir\'     : ub.ensure_app_cache_dir(\'netharn\\/tests\\/demo\'); ||     >>>     \'nice\'        : \'demo\'; ||     >>>     \'xpu\'         : nh.XPU.cast(\'auto\'); ||     >>>     # workdir is a directory where intermediate results can be saved ||     >>>     # nice symlinks <workdir>\\/fit\\/nice\\/<nice> -> ..\\/runs\\/<hashid> ||     >>>     # XPU auto select a gpu if idle and VRAM>6GB else a cpu ||     >>>     # ================ ||     >>>     # Data Components ||     >>>     \'datasets\'    : {  # dict of plain ol torch.data.Dataset instances ||     >>>         \'train\': nh.data.ToyData2d(size=3; border=1; n=256; rng=0); ||     >>>         \'vali\': nh.data.ToyData2d(size=3; border=1; n=128; rng=1); ||     >>>         \'test\': nh.data.ToyData2d(size=3; border=1; n=128; rng=1); ||     >>>     }; ||     >>>     \'loaders\'     : {\'batch_size\': 64}; # DataLoader instances or kw ||     >>>     # ================ ||     >>>     # Algorithm Components ||     >>>     # Note the (cls; kw) tuple formatting ||     >>>     \'model\'       : (nh.models.ToyNet2d; {}); ||     >>>     \'optimizer\'   : (nh.optimizers.SGD; { ||     >>>         \'lr\': 0.0001 ||     >>>     }); ||     >>>     # focal loss is usually better than nh.criterions.CrossEntropyLoss ||     >>>     \'criterion\'   : (nh.criterions.FocalLoss; {}); ||     >>>     \'initializer\' : (nh.initializers.KaimingNormal; { ||     >>>         \'param\': 0; ||     >>>     }); ||     >>>     # these may receive an overhaul soon ||     >>>     \'scheduler\'   : (nh.schedulers.ListedLR; { ||     >>>         \'points\': {0: .0001; 2: .01; 5: .015; 6: .005; 9: .001}; ||     >>>         \'interpolate\': True; ||     >>>     }); ||     >>>     \'monitor\'     : (nh.Monitor; { ||     >>>         \'max_epoch\': 10; ||     >>>     }); ||     >>>     # dynamics are a config option that modify the behavior of the main ||     >>>     # training loop. These parameters effect the learned model. ||     >>>     \'dynamics\'   : {\'batch_step\': 4}; ||     >>> }) ||     >>> harn = nh.FitHarn(hyper) ||     >>> # non-algorithmic behavior configs (do not change learned models) ||     >>> harn.config[\'prog_backend\'] = \'tqdm\' ||     >>> if ub.argflag(\'--progiter\'):  # I prefer progiter (I may be biased) ||     ...     harn.config[\'prog_backend\'] = \'progiter\' ||     >>> # start training. ||     >>> harn.initialize(reset=\'delete\') ||     >>> harn.run()  # note: run calls initialize it hasn\'t already been called. ||     >>> # xdoc: +IGNORE_WANT ||     RESET HARNESS BY DELETING EVERYTHING IN TRAINING DIR ||     Symlink: ...tests\\/demo\\/fit\\/runs\\/demo\\/keyeewlr -> ...tests\\/demo\\/fit\\/nice\\/demo ||     .... already exists ||     .... and points to the right place ||     Initializing tensorboard (dont forget to start the tensorboard server) ||     Model has 824 parameters ||     Mounting ToyNet2d model on CPU ||     Initializing model weights ||      * harn.train_dpath = \'...tests\\/demo\\/fit\\/runs\\/demo\\/keyeewlr\' ||      * harn.nice_dpath  = \'...tests\\/demo\\/fit\\/nice\\/demo\' ||     Snapshots will save to harn.snapshot_dpath = \'...tests\\/demo\\/fit\\/runs\\/demo\\/keyeewlr\\/torch_snapshots\' ||     dont forget to start: ||         tensorboard --logdir ...tests\\/demo\\/fit\\/nice ||     === begin training === ||     epoch lr:0.001 \\u2502 vloss: 0.1409 (n_bad_epochs=00; best=0.1409): 100%|\\u2588| 10\\/10 [00:01<00:00;  9.95it\\/s]  0:00<?; ?it\\/s] ||     train x64 \\u2502 loss:0.147 \\u2502: 100%|\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588| 8\\/8 [00:00<00:00; 130.56it\\/s] ||     vali x64 \\u2502 loss:0.140 \\u2502: 100%|\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588| 4\\/4 [00:00<00:00; 342.04it\\/s] ||     test x64 \\u2502 loss:0.140 \\u2502: 100%|\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588| 4\\/4 [00:00<00:00; 342.92it\\/s] ||     <BLANKLINE> ||     Maximum harn.epoch reached; terminating ... ||     <BLANKLINE> ||     training completed ||     current lrs: [0.001] ||     harn.train_dpath = \'...tests\\/demo\\/fit\\/runs\\/demo\\/keyeewlr\' ||     harn.nice_dpath  = \'...tests\\/demo\\/fit\\/nice\\/demo\' ||     view tensorboard results for this run via: ||         tensorboard --logdir ...tests\\/demo\\/fit\\/nice ||     exiting fit harness. || \\""\\""\\""'"
"b'\\""\\""\\"" || The examples\\/cifar.py is probably the most clear example of what netharn is and || what it\'s trying to do \\/ not do. ||  || The basic idea is make an object that inherits from nh.FitHarn. This is our || harness object. It will contain the hyperparameters as well as the learning || state. All the training loop boilerplate has already been written in the parent || class; so all our child class needs to do is: define `prepare_batch` (not || usually needed) and `run_batch`. Code to measure and record performance should || be placed in `on_batch` and `on_epoch`. ||  || The `train` function is our main entry point. It reads parameters from the || command line to override defaults. It then consructs the `HyperParams` object || and constructs an instance of `CIFAR_FitHarn` and calls `harn.run()`. ||  || This begins the training process. At a high level the harness will load the || data using torch DataLoaders; and call `run_batch` when it needs to compute the || model outputs and loss based on the input data. The returned loss is used to || update the model weights if `harn.tag === \'train\'`; for validation; test; and || calibration (todo) datasets the loss is simply recorded. ||  || After `run_batch` finishes the `on_batch` function is called; where you can || optionally return a dict of scalars to log as measurements for this batch (note || loss is always recorded; so we need not return it here; but loss components may || be useful). A similar thing happens in `on_epoch`; where you should return || metrics about the entire dataset. ||  || The training harness manages the fit directory structure based on a hash of the || hyperparameters; the creation of algorithm component instance (e.g. model; || optimizer); initializing model weights; restarting from the most recent epoch; || updating the learning rates; various training loop boilerplate details; || checking divergence; reporting progress; handling differences between train; || validation; and test sets. In short; netharn handles the necessary parts and || let the developer focus on the important parts. || \\""\\""\\""'"
b'TODO: might be good to check for multiple model exports at this time'
b'TODO: if pretrained is another netharn model; then we should read that'
"b'\\""\\""\\"" || WIP ||  || This file should contain classes (that behave like torch models); but they || implement the learning of classical learning algorithms like SVM and || RandomForest. ||  || Deep networks are amazing at learning features. However; I don\'t think it\'s || very useful to use linear logicstic regression as a classifier. In many cases I || think an SVM or a RandomForest might produce a superior classification model; || but this has yet to be shown. ||  || TODO: ||     - [ ] Classical Abstract API ||     - [ ] Integration with the FitHarn ||         - [ ] How do we swap netharn\'s backprop+SGD with sklearn\'s SVM and RandomForest fit methods? ||         - [ ] Netharn needs a \\""classical\\"" implementation of \\""run\\"". ||             - [ ] Simply use the data loader to load the data ||             - [ ] Defaults should encourage use with deep features. ||     - [ ] RandomForest ||     - [ ] SVM || \\""\\""\\""'"
b'TODO: missing model_equivalent_rules; rule importances'
b'TODO: Functionality to automatically download CoNLL models'
"b""'' || Test action recognition on || (1) a video; (2) a folder of images; (3) or web camera. ||  || Input: ||     classes: data_proc\\/classes.csv # TODO: change this to a config file ||     model: model\\/trained_classifier.pickle ||  || Output: ||     result video:    output\\/${video_name}\\/video.avi ||     result skeleton: output\\/${video_name}\\/skeleton_res\\/XXXXX.txt ||     visualization by cv2.imshow() in img_displayer || '''"""
b'TODO finish codes of loading models from local file here.'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || # TODO(sguada) docstring paragraph by (a) motivating the need for the file and || # (b) defining clones. ||  || # TODO(sguada) describe the high-level components of model deployment. || # E.g. \\""each model deployment is composed of several parts: a DeploymentConfig; || # which captures A; B and C; an input_fn which loads data.. etc ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||   g = tf.Graph() ||  ||   # Set up DeploymentConfig ||   config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||   # Create the global step on the device storing the variables. ||   with tf.device(config.variables_device()): ||     global_step = slim.create_global_step() ||  ||   # Define the inputs ||   with tf.device(config.inputs_device()): ||     images; labels = LoadData(...) ||     inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||   # Define the optimizer. ||   with tf.device(config.optimizer_device()): ||     optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||   # Define the model including the loss. ||   def model_fn(inputs_queue): ||     images; labels = inputs_queue.dequeue() ||     predictions = CreateNetwork(images) ||     slim.losses.log_loss(predictions; labels) ||  ||   model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                  optimizer=optimizer) ||  ||   # Run training. ||   slim.learning.train(model_dp.train_op; my_log_dir; ||                       summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||   * outputs: The return values of the calls to `model_fn()`. ||   * scope: The scope used to create the clone. ||   * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||   * train_op: An operation that run the optimizer training op and include ||     all the update ops created by `model_fn`. Present only if an optimizer ||     was specified. ||   * summary_op: An operation that run the summaries created by `model_fn` ||     and process_gradients. ||   * total_loss: A `Tensor` that contains the sum of all losses created by ||     `model_fn` plus the regularization losses. ||   * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||   * num_clones: Number of model clones to deploy in each replica. ||   * clone_on_cpu: True if clones should be placed on CPU. ||   * replica_id: Integer.  Index of the replica for which the model is ||       deployed.  Usually 0 for the chief replica. ||   * num_replicas: Number of replicas to use. ||   * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||   * worker_job_name: A name for the worker job. ||   * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||   - describe side effect to the graph. ||   - what happens to summaries and update_ops. ||   - which graph collections are altered. ||   - write a tutorial on how to use this. ||   - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
b'TODO(Przemek): implement loading a model'
"b'\\""\\""\\"" || detector.py is an out-of-the-box windowed detector || callable from the command line. ||  || By default it configures and runs the Caffe reference ImageNet model. || Note that this model was trained for image classification and not detection; || and finetuning for detection can be expected to improve results. ||  || The selective_search_ijcv_with_python code required for the selective search || proposal mode is available at ||     https:\\/\\/github.com\\/sergeyk\\/selective_search_ijcv_with_python ||  || TODO: || - batch up image filenames as well: don\'t want to load all of them into memory || - come up with a batching scheme that preserved order \\/ keeps a unique ID || \\""\\""\\""'"
b'TODO: mistake: the model name should be selected_tfidf'
b'TODO: move to tensorflow model?'
b'TODO AND WARNING: this is a hotfix so that copying works for trained models.'
b'TODO I could make NetWrapper more flexible allowing to preprocess the batch before giving it to the model!'
b'TODO: aside from the name; DTNNModel is unmodified. May need modification like GraphConvModel did.'
b'TODO: aside from the name; DAGModel is unmodified. May need modification like GraphConvModel did.'
b'TODO: aside from the name; MPNNModel is unmodified. May need modification like GraphConvModel did.'
b'TODO: If you want to use this function; please update it according to model_regression()'
b'TODO: build model or load pre-trained model'
"b'\\""\\""\\""Module dedicated to extraction of Model Based Metafeatures. ||  || Todo: ||     * Implement metafeatures. ||     * Improve documentation. || \\""\\""\\""'"
b'TODO 11\\/11\\/2018 continue and compare with statsmodels result'
b'TODO: Integrate this with the logic of the MultiPlanarUNet.models'
b'TODO: model type.'
b'TODO add evaluation; model checkpointing; tensorboard'
b'@TODO Just play them for now; RNN model prediction later'
b'@todo integrate Frontend and Model to that workflow'
b'_model_ext = @Todo: dense(numpy\\/pk.gz) or sparse => gt...?'
b'TODO: add ensemble models as last-step models (voting; ensembles; etc)'
b'TODO: Implement score function for all models; including clustering'
b'TODO: this needs to be replaced by the one in Model_Builder'
b'TODO: Find a meaningful way (metric) to notify the user of model score.'
b'TODO: This is exactly the same as in single_model so you might'
b'TODO: EVERYTHING below here is the same as in single_model.'
b'TODO: LSTMModel needs to be reimplemented'
b'TODO Replace this part with SavedModel'
b'FIXME: However the fix requires a refactoring of ALL the models to deal with their session internaly.'
b'TODO: Fix multiple-learn on commented-out models (Issue #619).'
b'FIXME this is essentially the ModelBuilder.build_model'
b'TODO need model file'
b'TODO use model number as input and return only one model at a time; e.g. default: model=1'
b'TODO consider multiple models'
b'# TODO: Add default model weights to models\\/weights\\/ and import them here  #'
"b""TODO Every model must return a layer named 'logits'"""
b'TODO: Improve. If only tf.keras.clone_model(model) worked.'
b'TODO Finish implementing loading in and initializing a Model object from a stored description'
b'TODO REMOVE when implemnting live model prediction'
b'TODO refactor second part of if statement when implementing live model prediction'
b'TODO move model stuff from lpi to analysis.base'
b'FIXME: get the answer from the PyTorch model here'
b'model.load_state_dict(torch.load(jt_config.model_load)) # TODO'
b'Test model (TODO: this is an ugly and brittle line)'
b'TODO Create Pipeline; init model; predict on fake dataset; save predictions; save model'
b'TODO load saved model; predict on same dataset; compare predictions to saved ones'
b'TODO: throw error if given model does not exist (instead of returning empty vectors)'
b'TODO: What is the standard file path of the models?'
b'TODO: Do not crash when the asked model is not one of the trained models'
"b""TODO: Cache the model in the process memory; it's quite hard as the RQ"""
"b""TODO: Switch to the pure Defect model; as it's better in this case."""
b'TODO: Support modeling fix time at filing time or at assignment time'
b'TODO: Support modeling fix time for a subset of bugs (e.g. regressions only)'
b'TODO: Support modeling fix time with different number of quantiles'
"b""''' || TODO:   ||     This needs to become something that can measure performance of the  ||     randomized ModelAverage method since thresholding the output there is  ||     appropriate. || '''"""
b'TODO make type of model dependent on input param'
b'TODO Assert the convergence of the model at the end by reading the'
"b""TODO Currently assumes we're on slug. Need to package up the model and"""
"b""TODO: Complete the mixture of expert model: verify from if self.options['name'] == 'MixExp': (predict)"""
b'TODO : choice of the surrogate model experts to be used'
b'TODO : add factory to get proper surrogate model object'
"b""TODO : MOE should be a true 'surrogate model' object"""
b'TODO: should we add leaf surrogate models options?'
b'TODO(take-cheeze) Investigate why onnx.checker.check_model succeed'
b'TODO how to pass seasonal frequency for ARIMA model'
b'TODO add more constructor\\/fit options from statsmodels'
b'TODO: This seems sepcific to agents. Refactor this out of base_model.py'
b'TODO: change this to search for the model_init.py based on the'
b'TODO but this must be done with my own Model Classifier at the loss selection'
b'TODO : #TODO : Regress should be in the model'
"b'save_path = FLAGS.ckpt_dir + \\""model.ckpt\\"" #TODO temp remove==>only save checkpoint for each epoch once.'"
b'assign_pretrained_word_embedding(sess; vocabulary_index2word; vocab_size; model;FLAGS.word2vec_model_path2;model.Embedding2) #TODO'
b'TODO: BELOW IS NOT THE CASE IF MODEL IS NN - SETTING THE GLOBAL RANDOM SEED DOES SOMETHING'
"b""TODO: Check :attr:`module_name`'s library_helper for :attr:`model_initializer` for a default `hyperparameter` list"""
b'TODO: Create `Keras` key based on compiled model architecture; which is far more accurate'
"b""TODO: Grab all '__hh' attrs from `model.layers` - `load_model` fucks with '<kernel\\/bias>_initializer'"""
"b""TODO: After setting `self.model` to result of `load_model`; revert the '__hh' attrs to saved values"""
"b""TODO: Model's `get_config()` returns the final learning rate; rather than the initial one; so experiment description"""
b'TODO: Add `model` here; with a `TranslateTrace` decorator; and document it below'
b'model=None;  # TODO: May need to pass `model` from `set_experiment_guidelines`'
"b'@TranslateTrace(\\""model\\""; (\\""model_initializer\\""; \\""model_init_params\\""))  # TODO: Add when tested with `Mirror`'"
b'TODO: When `TranslateTrace` added document `model` below with expectation that if `model`'
b'TODO: ... given; (`model_initializer`; `model_init_params`) should not be; and vice versa'
b'TODO: `model` (Class instance; default=None);'
"b'TODO: `model_initializer`\\/`model_init_params` docstring types += \\""default=None\\""'"
b'self._model_original = model  # TODO: Add for `TranslateTrace`'
b'TODO: Check here if callable; and using a `Trace`d model\\/model_initializer'
b'TODO: determine num input channels from model or input data'
"b""TODO: This won't work with layers shared between models\\/messy layers"""
b'TODO add a pretrained model?'
b'@TODO replace tensorflow to pytorch model'
"b'\\""\\""\\"" || Layers for voxelmorph model ||  || TODO: clean up and join with neuron.layers || \\""\\""\\""'"
"b""TODO: This is wrong. We'd want to use the PCA model fit on training data"""
b'TODO: edge model'
"b'\\""\\""\\"" || detector.py is an out-of-the-box windowed detector || callable from the command line. ||  || By default it configures and runs the Caffe reference ImageNet model. || Note that this model was trained for image classification and not detection; || and finetuning for detection can be expected to improve results. ||  || The selective_search_ijcv_with_python code required for the selective search || proposal mode is available at ||     https:\\/\\/github.com\\/sergeyk\\/selective_search_ijcv_with_python ||  || TODO: || - batch up image filenames as well: don\'t want to load all of them into memory || - come up with a batching scheme that preserved order \\/ keeps a unique ID || \\""\\""\\""'"
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || # TODO(sguada) docstring paragraph by (a) motivating the need for the file and || # (b) defining clones. ||  || # TODO(sguada) describe the high-level components of model deployment. || # E.g. \\""each model deployment is composed of several parts: a DeploymentConfig; || # which captures A; B and C; an input_fn which loads data.. etc ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||   g = tf.Graph() ||  ||   # Set up DeploymentConfig ||   config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||   # Create the global step on the device storing the variables. ||   with tf.device(config.variables_device()): ||     global_step = slim.create_global_step() ||  ||   # Define the inputs ||   with tf.device(config.inputs_device()): ||     images; labels = LoadData(...) ||     inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||   # Define the optimizer. ||   with tf.device(config.optimizer_device()): ||     optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||   # Define the model including the loss. ||   def model_fn(inputs_queue): ||     images; labels = inputs_queue.dequeue() ||     predictions = CreateNetwork(images) ||     slim.losses.log_loss(predictions; labels) ||  ||   model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                  optimizer=optimizer) ||  ||   # Run training. ||   slim.learning.train(model_dp.train_op; my_log_dir; ||                       summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||   * outputs: The return values of the calls to `model_fn()`. ||   * scope: The scope used to create the clone. ||   * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||   * train_op: An operation that run the optimizer training op and include ||     all the update ops created by `model_fn`. Present only if an optimizer ||     was specified. ||   * summary_op: An operation that run the summaries created by `model_fn` ||     and process_gradients. ||   * total_loss: A `Tensor` that contains the sum of all losses created by ||     `model_fn` plus the regularization losses. ||   * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||   * num_clones: Number of model clones to deploy in each replica. ||   * clone_on_cpu: True if clones should be placed on CPU. ||   * replica_id: Integer.  Index of the replica for which the model is ||       deployed.  Usually 0 for the chief replica. ||   * num_replicas: Number of replicas to use. ||   * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||   * worker_job_name: A name for the worker job. ||   * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||   - describe side effect to the graph. ||   - what happens to summaries and update_ops. ||   - which graph collections are altered. ||   - write a tutorial on how to use this. ||   - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
b'TODO model.Embedding. assign this value to our embedding variables of our model.'
b'from model.bert_model import BertModel # TODO TODO TODO test whether pretrain can boost perofrmance with other model'
b'TODO test basic ml model\\uFFFF'
b'TODO test basic spark model\\uFFFF'
b'TODO: if we set regularization for the model to be sufficiently high; the'
b'TODO: add model_io check'
"b""TODO: This should be done in model's postprocess"""
b'todo: refactor the model such that it is less state sensitive'
b'TODO move the model load and the converter creation in a method called on init; but after the arg parsing'
b'TODO Remove this hacky fix when we move them to the same models'
b'TODO Currently any models which have a list input will not contain the main model'
b'train the model:  TODO - fix the ugly if statements and put this in the arguments of the script'
b'TODO - check prev argument for the model'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || # TODO(sguada) docstring paragraph by (a) motivating the need for the file and || # (b) defining clones. ||  || # TODO(sguada) describe the high-level components of model deployment. || # E.g. \\""each model deployment is composed of several parts: a DeploymentConfig; || # which captures A; B and C; an input_fn which loads data.. etc ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||     g = tf.Graph() ||  ||     # Set up DeploymentConfig ||     config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||     # Create the global step on the device storing the variables. ||     with tf.device(config.variables_device()): ||         global_step = slim.create_global_step() ||  ||     # Define the inputs ||     with tf.device(config.inputs_device()): ||         images; labels = LoadData(...) ||         inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||     # Define the optimizer. ||     with tf.device(config.optimizer_device()): ||         optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||     # Define the model including the loss. ||     def model_fn(inputs_queue): ||         images; labels = inputs_queue.dequeue() ||         predictions = CreateNetwork(images) ||         slim.losses.log_loss(predictions; labels) ||  ||     model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                    optimizer=optimizer) ||  ||     # Run training. ||     slim.learning.train(model_dp.train_op; my_log_dir; ||                                             summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||     * outputs: The return values of the calls to `model_fn()`. ||     * scope: The scope used to create the clone. ||     * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||     * train_op: An operation that run the optimizer training op and include ||         all the update ops created by `model_fn`. Present only if an optimizer ||         was specified. ||     * summary_op: An operation that run the summaries created by `model_fn` ||         and process_gradients. ||     * total_loss: A `Tensor` that contains the sum of all losses created by ||         `model_fn` plus the regularization losses. ||     * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||     * num_clones: Number of model clones to deploy in each replica. ||     * clone_on_cpu: True if clones should be placed on CPU. ||     * replica_id: Integer.  Index of the replica for which the model is ||             deployed.  Usually 0 for the chief replica. ||     * num_replicas: Number of replicas to use. ||     * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||     * worker_job_name: A name for the worker job. ||     * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||     - describe side effect to the graph. ||     - what happens to summaries and update_ops. ||     - which graph collections are altered. ||     - write a tutorial on how to use this. ||     - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
"b'fwd_params = [v for v in tf.all_variables() if v.name.startswith(self.model_scope + \\""\\/\\"" + var_scope)]  # TODO'"
"b'params = [v for v in tf.all_variables() if v.name.startswith(self.model_scope + \\""\\/\\"" + var_scope)]  # TODO'"
b'TODO Move to model.py'
b'TODO: check whether the model is QuartzNet'
"b""TODO: Make sure this doesn't load a previous trained model!"""
b'TODO: Replace with ps.ls.model?'
b'TODO: dont use _model as model'
b'TODO: do not use _model as model'
b'TODO : revise ModelData docstring :: Attributes'
b'TODO : revise ModelData docstring :: Examples'
b'TODO: integrate into VoxelModelCache'
b'TODO Check model dtype'
b'TODO: fix model path later!'
b'TODO: Chunk and NER model + NER config'
b'TODO: Train new model!'
"b""TODO: replace this with segmentation_models' FPN"""
b'TODO: enable users to run model with older incompatible Pfam DB versions?'
b'TODO: use the splits and average the results?? instead of picking best model...'
b'TODO: Load saved model.'
b'TODO: Model Precision'
b'TODO FIX AND ADD MODEL NAME TO SUPERVISED!'
"b""# TODO elif 'Priors' in model_folder: #                print 'Processi           print 'Processing Robotics priors model: '; path_to_neighbors"""
"b""ONLY FOR FAST TESTING !!:   model_name = MOBILE_ROBOT#STATIC_BUTTON_SIMPLEST#'pushingButton3DAugmented' #TODO REMOVE-testing  model_name = MOBILE_ROBOT"""
b'TODO create folder for experiment and models'
b'A future enhancement TODO for running on multiple GPU: CUDA_VISIBLE_DEVICES=2;3 python main.py   and then also model = torch.nn.DataParallel(model; device_ids=[0;1]).cuda()'
b'TODO: load best model before predicting states'
"b'TODO: use load_metadata in utils.modelIO + don\'t just use \\""specs.json\\""'"
"b'model_name=\\""all_comb_model_%d\\"" % config.impact_k; # TODO update name'"
b'TODO have a Model.logger to prefix all logs with model name'
b'FIXME: it should be more general (MAIN model compt.)'
b'TODO: Model here'
"b'\\""\\""\\""   || #TODO: || class HopfieldModel(LatentModel): ||      ||     def __init__(self; nvis; nhid): ||         self.layers = {} ||         self.layers[\'visible\'] = layers.IsingLayer(nvis) ||         self.layers[\'hidden\'] = layers.GaussianLayer(nhid) ||          ||         self.params = {} ||         self.params[\'weights\'] = numpy.random.normal(loc=0.0; scale=1.0; size=(self.layers[\'visible\'].len; self.layers[\'hidden\'].len)).astype(dtype=numpy.float32) ||         self.params[\'bias\'] = numpy.ones_like(self.layers[\'visible\'].loc)   ||  ||  || class HookeMachine(LatentModel): ||      ||     def __init__(self; nvis; nhid; vis_type=\'gauss\'; hid_type=\'expo\'):    ||         assert vis_type.lower() in [\'gauss\'; \'ising\'] ||         assert hid_type.lower() in [\'expo\'; \'bern\'] ||          ||         self.layers = {} ||         self.layers[\'visible\'] = layers.get(vis_type)(nvis) ||         self.layers[\'hidden\'] = layers.get(hid_type)(nhid) ||          ||         self.params = {} ||         self.params[\'weights\'] = numpy.random.normal(loc=0.0; scale=1.0; size=(self.layers[\'visible\'].len; self.layers[\'hidden\'].len)).astype(dtype=numpy.float32) ||         self.params[\'bias\'] = numpy.ones_like(self.layers[\'hidden\'].loc)   ||         self.params[\'T\'] = numpy.ones(1; dtype=numpy.float32) ||                  ||         self.deriv = {} ||         self.deriv[\'weights\'] = numpy.zeros_like(self.params[\'weights\']) ||         self.deriv[\'bias\'] = numpy.zeros_like(self.params[\'bias\']) ||         self.params[\'T\'] = numpy.zeros_like(self.params[\'T\']) ||          ||         self.set_vis(numpy.zeros_like(self.layers[\'visible\'].loc)) ||          ||     def set_vis(self; vis): ||         self.vis = vis ||         self.diff = (self.params[\'weights\'].T - vis).T ||         self.squared_dist = numpy.sum(self.diff ** 2; axis=0) ||         self.layers[\'hidden\'].update_params(self.params[\'bias\'] + self.squared_dist \\/ (2 * self.params[\'T\'])) ||         self.energy = -numpy.sum(numpy.log(self.layers[\'hidden\'].partition_function()))         ||          ||     def visible_conditional_params(self; hid): ||         total = numpy.sum(hid) ||         loc = numpy.dot(self.params[\'weights\']; hid) \\/ total ||         scale = self.params[\'T\'] \\/ total * numpy.ones_like(self.layers[\'visible\'].loc) ||         return (loc; scale) ||          ||     def update_visible_params(self; hid): ||         self.layers[\'visible\'].update_params(*self.visible_conditional_params(hid)) ||          ||     def derivatives(self; vis; key): ||         self.update_hidden_params(vis) ||         hidden_mean = self.layers[\'hidden\'].mean() ||         if key == \'bias\': ||             # del H(v; k) \\/ del b ||             return hidden_mean ||         elif key == \'weights\': ||             # del H(v; k) \\/ del W ||             return (self.difference(vis) * hidden_mean.T) \\/ self.params[\'T\'] ||         elif key == \'T\': ||             # del H(v;k) \\/ del T ||             return numpy.dot(hidden_mean.T; self.squared_distance(vis)) ||         else: ||             raise ValueError(\'unknown key: {}\'.format(key)) ||     \\""\\""\\""'"
b'TODO: move resampling into the model class so that it can be alternated with gibbs'
b'TODO: should import the State class from model.py'
b'TODO; start with 10 random models; evaluate them'
b'TODO print p values for binomial model'
b'TODO: Write a bit about the models used in this text field'
b'TODO optimize LR https:\\/\\/github.com\\/flairNLP\\/flair\\/blob\\/master\\/resources\\/docs\\/TUTORIAL_8_MODEL_OPTIMIZATION.md'
b'TODO Figure out how nested model config options will work'
b'TODO load model graph into model class called by click'
b'TODO: for all models types; train a single model on the whole dataset'
"b""TODO: it's worth to switch back to the correct preprocess_input when InceptionResNetV2 model is re-trained"""
b'TODO: model.add? or x= ...'
"b'\\""\\""\\"" || Adapt acoustic models using maximum-likelihood linear regression. ||  || This module implements single-class mean and variance adaptation using || MLLR as described in M.J.F. Gales & P.C. Woodland; \\\\\\""Mean and Variance || Adaptation within the MLLR Framework\\\\\\""; Computer Speech and Language; || vol. 10; pp 249-264. ||  || TODO: Multiple regression classes. || \\""\\""\\""'"
"b'\\""\\""\\""Probability models for species substitution. ||  || Implements base class :class:`SubstitutionModel`; || which can be extended to allow for development of new || lambda tables. An example of such an extension; || :class:`RadiusModel`; is also implemented. ||  || Todo: ||     * Allow for parallelism in lambda table calculations ||       by implementing a `sub_probs` abstractmethod ||       that :meth:`SubstitutionModel.gen_lambda` uses; ||       if available. ||  || \\""\\""\\""'"
b'# TODO Change to call remote model'
b'TODO: auto-modeling by custom config (get_model(**config)); defaults to {}'
b'TODO: model tunning; pass layers and other config to get custom models'
b'TODO: introduce exception in case of model failure to predict'
b'TODO: This report should be constructed based on sales order line model; not supplier mode.'
b'TODO clarify difference between local path and url to download model'
b'todo: should save tpot model here'
b'todo: the top models (including one model type with mutliple'
b'todo: combinations of model params).'
b'todo: combinations of model params).'
b'TODO extract MLE and std of model here.'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||   g = tf.Graph() ||  ||   # Set up DeploymentConfig ||   config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||   # Create the global step on the device storing the variables. ||   with tf.device(config.variables_device()): ||     global_step = slim.create_global_step() ||  ||   # Define the inputs ||   with tf.device(config.inputs_device()): ||     images; labels = LoadData(...) ||     inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||   # Define the optimizer. ||   with tf.device(config.optimizer_device()): ||     optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||   # Define the model including the loss. ||   def model_fn(inputs_queue): ||     images; labels = inputs_queue.dequeue() ||     predictions = CreateNetwork(images) ||     slim.losses.log_loss(predictions; labels) ||  ||   model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                  optimizer=optimizer) ||  ||   # Run training. ||   slim.learning.train(model_dp.train_op; my_log_dir; ||                       summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||   * outputs: The return values of the calls to `model_fn()`. ||   * scope: The scope used to create the clone. ||   * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||   * train_op: An operation that run the optimizer training op and include ||     all the update ops created by `model_fn`. Present only if an optimizer ||     was specified. ||   * summary_op: An operation that run the summaries created by `model_fn` ||     and process_gradients. ||   * total_loss: A `Tensor` that contains the sum of all losses created by ||     `model_fn` plus the regularization losses. ||   * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||   * num_clones: Number of model clones to deploy in each replica. ||   * clone_on_cpu: True if clones should be placed on CPU. ||   * replica_id: Integer.  Index of the replica for which the model is ||       deployed.  Usually 0 for the chief replica. ||   * num_replicas: Number of replicas to use. ||   * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||   * worker_job_name: A name for the worker job. ||   * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||   - describe side effect to the graph. ||   - what happens to summaries and update_ops. ||   - which graph collections are altered. ||   - write a tutorial on how to use this. ||   - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
b'TODO: model_ids'
b'TODO: error if object not in invariant_inputs or model.probes'
b'TODO: document important attributes (e.g. keras_model)'
b'TODO Add argument to skip modelling.'
b'TODO Move auxiliary model functions to `models\\/auxiliary.py`'
b'Todo: support for sklearn linear models'
b'TODO: Here; we should be able to add these 2 new lists to DataDict so that they can be used in model.plot().'
"b'\\""\\""\\"" || trainer.py: Contains the code implementation of the main worker of mi-prometheus. || This worker in particular is called the `episodic trainer` and will take care of training || a specified model on a specified problem for a given number of episodes (among other adjustable || parameters). ||  || #TODO: Enhance this description and documentation. ||  || \\""\\""\\""'"
b'nir_model = copy.deepcopy(model) # TODO: change to load only the part that we want'
b'TODO: add following info: associated featuresets; models'
b'Initialize model (TODO: do i really need this?)'
b'Initialize model (TODO: really necessary?)'
b'TODO Marcin: Load model from path'
b'TODO (johngiorgi): make model checkpointing a config param'
b'TODO (johngiorgi): consider introduction a new function; create_model()'
b'TODO (johngiorgi): need to clear the models after each fold'
b'TODO (johngiorgi): I need to name the models based on their dataset folder'
b'TODO (johngiorgi): https:\\/\\/machinelearningmastery.com\\/dropout-regularization-deep-learning-models-keras\\/'
b'TODO (johngiorgi) add verbosity parameter for printing model summary'
b'TODO (johngiorgi): fix some of the test_model_attributes_after_creation_of_model tests'
b'TODO (johngiorgi): Read about spacys models; choose the most'
b'TODO: change to the following statement with new models'
b'TODO (johngiorgi): add a dummy model fixture'
b'TODO: compute betas for linear SKLL models?'
b'TODO: fix actor model'
b'TODO(ahundt) consider making image_model_weights shared vs separate configurable'
b'Quite good kfold; best hyperparams from 2018-04 2000 model hyperopt run TODO(ahundt) add details from kfold run'
b'TODO(ahundt) it seems set_trainable_layers in grasp_model.py has a bug?'
b'lead to NaNs in some models (resnet50).  TODO(tucker): fix it.'
b'TODO(rishabhagarwal): Hack for loading a model trained on cloud machine.'
b'TODO(yovadia): Figure out why save_model() wants to serialize ModelOptions.'
"b'r\\""\\""\\""Reader for the format provided by SIGTYP 2020 Shared Task. ||  || More information on the format is available here: ||   https:\\/\\/sigtyp.github.io\\/st2020.html ||  || Example: || -------- ||  Clone the GitHub data to ST2020_DIR. Then run: ||  ||  > ST2020_DIR=... ||  > python3 sigtyp_reader_main.py --sigtyp_dir ${ST2020_DIR}\\/data \\\\ ||     --output_dir ${OUTPUT_DIR} ||  ||  The above will create \\""train.csv\\""; \\""dev.csv\\"" and \\""test_blinded.csv\\"" files ||  converted from the format provided by SIGTYP. Our models should be able to ||  injest these csv files. Along each of the above files; an accompanying ||  \\""data_train_*.json.gz\\"" file is generated that contains metainformation on ||  various features and their values. ||  || TODO: || ----- || Following needs to be done: ||   - Latitude and longitude need to be on a point on a unit sphere? Keep as is ||     and add three further columns for (x;y;z)? ||   - Country codes are *several*. ||   - Other types of SOMs. ||   - Use BaseMap for visualizations? || \\""\\""\\""'"
b'TODO(ddjohnson) Move common layers out of `edge_supervision_models`.'
b'FIXME: anything to check or copy from other model_opt?'
"b'\\""\\""\\""Export \\/ Import of generic python models. ||  || This module defines generic filesystem format for python models and provides utilities || for saving and loading to and from this format. The format is self contained in a sense || that it includes all necessary information for anyone to load it and use it. Dependencies || are either stored directly with the model or referenced via a conda environment. ||  || The convention for pyfunc models is to have a predict method or function with the following || signature ||  || predict(data: pandas.DataFrame) -> pandas.DataFrame ||  || This convention is relied upon by other mlflow components. ||  || Pyfunc model format is defined as a directory structure containing all required data; code and || configuration: ||  || .\\/dst-path\\/ ||     .\\/MLmodel - config ||     <code> - any code packaged with the model (specified in the conf file; see below) ||     <data> - any data packaged with the model (specified in the conf file; see below) ||     <env>  - conda environment definition (specified in the conf file; see below) ||  || It must contain MLmodel file in its root with \\""python_function\\"" format with the following || parameters: ||  ||    - loader_module [required]: ||          Python module that can load the model. Expected as module identifier ||           e.g. ``mlflow.sklearn``; it will be imported via importlib.import_module. ||          The imported module must contain function with the following signature: ||  ||               load_pyfunc(path: string) -> <pyfunc model> ||  ||          The path argument is specified by the data parameter and may refer to a file or directory. ||  ||    - code [optional]: ||         relative path to a directory containing the code packaged with this model. ||         All files and directories inside this directory are added to the python path ||         prior to importing the model loader. ||  ||    - data [optional]: ||          relative path to a file or directory containing model data. ||          the path is passed to the model loader. ||  ||    - env [optional]: ||          relative path to an exported conda environment. If present this environment ||          should be activated prior to running the model. ||  || Example: ||  || ``` || >tree example\\/sklearn_iris\\/mlruns\\/run1\\/outputs\\/linear-lr || \\u251C\\u2500\\u2500 MLmodel || \\u251C\\u2500\\u2500 code || \\u2502\\u00A0\\u00A0 \\u251C\\u2500\\u2500 sklearn_iris.py || \\u2502\\u00A0\\u00A0 || \\u251C\\u2500\\u2500 data || \\u2502\\u00A0\\u00A0 \\u2514\\u2500\\u2500 model.pkl || \\u2514\\u2500\\u2500 mlflow_env.yml ||  || >cat example\\/sklearn_iris\\/mlruns\\/run1\\/outputs\\/linear-lr\\/MLmodel || python_function: ||   code: code ||   data: data\\/model.pkl ||   env: mlflow_env.yml ||   main: sklearn_iris ||  || ``` || Todo: || * Get default conda_env of the project. || \\""\\""\\""'"
"b'\\""\\""\\"" || This module imports contents from CloudPickle in a way that is compatible with the || ``pickle_module`` parameter of PyTorch\'s model persistence function: ``torch.save`` || (see https:\\/\\/github.com\\/pytorch\\/pytorch\\/blob\\/692898fe379c9092f5e380797c32305145cd06e1\\/torch\\/ || serialization.py#L192). It is included as a distinct module from :mod:`mlflow.pytorch` to avoid || polluting the namespace with wildcard imports. ||  || Calling ``torch.save(...; pickle_module=mlflow.pytorch.pickle_module)`` will persist PyTorch model || definitions using CloudPickle; leveraging improved pickling functionality such as the ability || to capture class definitions in the \\""__main__\\"" scope. ||  || TODO: Remove this module or make it an alias of CloudPickle when CloudPickle and PyTorch have || compatible pickling APIs. || \\""\\""\\""'"
b'TODO: Tech debt. Refactor search code into common utils; tracking server; and model'
b'TODO: move this to a specific mlflow.statsmodels.tsa flavor? Time series models'
b'todo: tf2 change ludwig.Model not be subclass of tensorflow.keras Model class?'
b'model.close_session()  # todo tf2 code clean -up'
b'TODO tf2: currently no clear way to set model graph'
b'todo refactoring: maybe replace the self.model_definition paramter'
b'TODO: support loading other model types based on definition'
b'TODO: Input shape should be determined by combination of model + scan.'
b'TODO: build child models'
b'TODO: Construct this from built child models'
b'TODO: build the model'
b'TODO: fit the model'
"b'\\""\\""\\""Abstract model classes. ||  || TODO: more info... ||  || \\""\\""\\""'"
"b'\\""\\""\\""Common already-made models. ||  || TODO: more info... ||  || \\""\\""\\""'"
"b""TODO: recursively build this model's args"""
b'TODO: DiscreteModel (for poisson etc)\\uFFFF'
b'TODO: but will have to SAMPLE from model and compute prob multiple times?'
b'TODO: and should use mean model; not sampling'
b'TODO: should return built_model; mean_model'
b'TODO: i feel like BaseLayer should have everything BaseModel has;'
b'TODO: so the values are the sampled values? so self.built_model.sample()?'
b'TODO: need to account for the jacobian if input is a BaseModel'
b'TODO: should inherit layer? model?'
b'TODO: should inherit layer? model?  Layer; I think.'
b'TODO: recurse down the model; setting param._session = sess for each parameter'
"b""TODO: ensure x data shape matches model._ph['x'] shape (only if fit)"""
b'TODO: restore_best_weights? using save_model and load_model?'
"b'\\""\\""\\""Models. ||  || Models are objects which take Tensor(s) as input; perform some computation on  || those Tensor(s); and output probability distributions. ||  || TODO: more... ||  || * :func:`.Model` || * :func:`.ContinuousModel` || * :func:`.DiscreteModel` || * :func:`.CategoricalModel` || * :func:`.save_model` || * :func:`.load_model` ||  || ---------- ||  || \\""\\""\\""'"
"b'\\""\\""\\"" || Models are objects which take Tensor(s) as input; perform some computation || on those Tensor(s); and output probability distributions. ||  || TODO: more... ||  || * :class:`.Model` || * :class:`.ContinuousModel` || * :class:`.DiscreteModel` || * :class:`.CategoricalModel` ||  || ---------- ||  || \\""\\""\\""'"
b'TODO: update with better model for testing (currently ~85% on testing; ~99% on training)'
b'@todo the loading of the model and prediction functions should be within a class that is initialized by starting a'
b'TODO: init function for saved model'
"b""'' ||     ----- TODO ----- ||  || [ ] Match the perspective via camera height estimation (with camera || calibration) || [ ] WHY IS IT SO UGLY???! || [ ] Thread it! || [x] Random positioning of the gate || [x] Boundaries definition for the gate (relative to the mesh's size) || [x] Compute the center of the gate || [ ] Compute the presence of the gate in the image frame || [?] Compute the distance to the gate || [ ] Camera calibration (use the correct parameters) || [x] Project on transparent background || [x] Overlay with background image || [ ] Model the camera distortion || [ ] Apply the distortion to the OpenGL projection || [ ] Histogram equalization of both images (hue; saturation; luminence ?...) || [ ] Motion blur (shader ?) || [ ] Anti alisasing (shader ?) || [ ] Ship it! ||  || '''"""
b'by default; use_cache is false (for older pre-trained models TODO: remove in version 0.4)'
b'make compatible with serialized models (TODO: remove)'
b'TODO check if this is necessary is this method is called before prepare_for_model'
b'TODO: think about moving this to model_eval mtry function'
b'TODO save models and stats'
b'# TODO loop over all the models?'
b'TODO is it possible to get to this return if you are in develop_model_mode?'
b'TODO This might change as deploy no longer trains a model'
b'TODO should this timestamp a model name automatically? (for example 2017-04-26_01.33.55_random_forest.pkl)'
b'TODO keeping these column names as part of the saved model avoids all the hassle of dropping grain and other'
b'TODO factor model here?'
b'TODO refactor this to take an arbitrary number of models rather than just a linear and random forest'
b'TODO This will not work without a linear and random forest model for now until the base function is refactored'
b'TODO this is broken - it might look like tools.plot_roc(models=[random_forest; linear; knn])'
b'TODO put TrainedSupervisedModel into advanced class and compare how it feels with the linear_regression()'
b'TODO because these now all return TSMs it will be additionally slow by all the factor models.'
b'TODO Could these be trained separately then after the best is found; train the factor model and add to TSM?'
b'TODO should the factor model be either 1) optional or 2) separate?'
b'TODO add approx to model'
b'TODO: add notebooks for each models : PoissonReg; CoxPartial; Hawkes; that illustrates simulation and inference of the models; and compares solvers for each models'
b'TODO: write callback for model save'
b'TODO: set check_hash to True on final model'
b'TODO: check it is implemented. The model cannot be loaded when they are present.'
b'TODO change for model to deployment version'
b'TODO This exists so that models can set up default values'
b'TODO: seems like we should store args.model to restore it after this loading'
"b""TODO: what's model_name?"""
b'TODO: The logger is define a bit later (needs the model name) - change this to a log message ?'
b'TODO: test this for tacotron models'
b'TODO: fix optimizer init; model.cuda() needs to be called before'
b'FIXME: can trim the model'
b'TODO(rbharath): config and model_params overlap significantly. Maybe just'
b'TODO(rbharath): This is a hack based on fact that multi-tasktype models'
"b'FIXME: Signature of \\""fit\\"" incompatible with supertype \\""Model\\""'"
"b'FIXME: Return type \\""None\\"" of \\""fit\\"" incompatible with return type \\""float\\"" in supertype \\""Model\\""'"
b'TODO: This test is a little awkward. The Smiles2Vec model awkwardly depends on a dataset_file being available on disk. This needs to be cleaned up to match the standard model handling API.'
b'TODO: change this to your bert model and tokenizer used in pytorch-transformer'
b'TODO: Do a better job of guessing defaults from the model'
b'TODO: ensure that the number of models is only 2'
b'TODO: once we make ScoreVisualizer and ModelVisualizer pass through'
b'TODO: parametrize with models when unittest dependency removed'
b'TODO: parametrize with models when unittest dependency removed (new test case)'
b'TODO: is this how sklearn stores all centers in the model?'
b'TODO: honestly this was done because it was only in the statsmodels'
b'TODO. learn feature normalization and store it as a layer in the model'
b'TODO. check that model specs are coherent'
b'TODO. get rid of from_model_pt'
b'TODO: add support for torch.hub models directly in docopt'
b'TODO: in pyannote.audio.train.model'
b'FIXME add support for pretrained model with different specs'
"b'\\""\\""\\"" || Simulate Artificial Data || ======================== ||  || From package Scanpy (https:\\/\\/github.com\\/theislab\\/scanpy). || Written in Python 3 (compatible with 2). || Copyright 2016-2017 F. Alexander Wolf (http:\\/\\/falexwolf.de). ||      || Simulate stochastic dynamic systems to model gene expression dynamics and || cause-effect data. ||  || TODO || ---- || Beta Version. The code will be reorganized soon. || \\""\\""\\""'"
b'TODO: add conv models'
b'@TODO: add model grads support and visualization'
b'TODO - Add storage bucket name field in django models'
"b'TODO should we use \\""generator\\"" or \\""metamodel\\"" in the name of'"
b'TODO: For now; the model are trained for a specific dataset (because of the maxLength which define the'
b'TODO: Put a limit size (ex: 3GB for the modelDir)'
b'We need to restore the model length because of the textData associated and the vocabulary size (TODO: Compatibility mode between different maxLength)'
b'TODO(Mark) Make the language configurable and based on a model attribute.'
b'TODO: Use modelforge to save the model'
b'TODO: assert that only on first recursion lvl `parent_model` can be None'
b'TODO: if possible; give a warning if model is already fitted (acceptable in case of custom experimentation;'
b'TODO add test about initializing a model from a run given a parameter distribution - also'
b'fixme str(model) might contain (...)'
b'TODO: if possible; give a warning if model is already fitted (acceptable'
b'TODO: Make this robust against an adversarial model namer'
b'TODO some sanity checks on config_dict (e.g. whether the model is actually a model; etc)'
b'todo: load & return model blob'
b'TODO Implement project_out on PCAModel'
"b""TODO the model needs to be able to generate it's jacobian."""
b'TODO Implement project_out on SimilarityModel'
b'TODO: better document what a linear model does.'
b'TODO: give a description of what it means to be a PCA model'
b'TODO: give a description of what it means to be a Similarity Model'
b'TODO: this bit of logic should to be transferred down to PCAModel'
b'Register useful parameters and objects useful for model instantiation #TODO: do proper testing on this part'
b'TODO Find a way to verify if the model natively supports sample_weight'
b'TODO: replace rnnsearch with model_cls.name'
b'TODO: switch back to nkjp when model config is updated'
b'# TODO: add multi_model stuff!'
b'TODO: make sure newer models are trained with mul=1'
b'TODO: make sure newer models are trained with diff_ratio=0.5'
b'TODO: old models do not have the init attribute; thus create it'
"b""FIXME: these old models don't have the online attribute set; so we"""
b'TODO: old models have underscores at some variable names; thus rename'
"b""TODO: old models have a 'hid_init' instead of an 'init' attribute"""
"b'TODO: this is another place can be simplified by \\""model-before-preprocess\\"" reorganization'"
b'Todo: add static version of model.predict_subset_classes; use here'
b'TODO break out EncoderConfig to allow use without populating options for full translation model'
b'TODO: At the moment LHUC is RNN specific. We should support other models as well.'
b'TODO: make this configurable in the model; separately per target factor.'
b'TODO(ohta): Remove this workaround when `number` field is added to `TrialModel`.'
b'TODO: support using pretrained model.'
b'TODO: How do we strip the arg checking from Model?'
b'TODO: We should return also h_n e.g. for seq2seq models'
b'TODO: Which settings should we expose via Model.visualize?'
b'TODO: input \\/ output types for model?'
b'TODO: Generalize this to be able to use other model classes like Transformer'
b'TODO: pass to dual model too'
b'TODO (T36875783): instantiate a langauge model'
b'TODO (T40938917): Allow loading of multiple rescoring models'
b'TODO: (T41818693) Map translation model vs LM model differences'
b'TODO: model ensemble'
"b'\\""\\""\\"" || The hyphenation\\/syllabification algorithm is based on the typical syllable structure model of onset\\/nucleus\\/coda. || TODO: Add hypothesized IPA transcription || \\""\\""\\""'"
"b""TODO and add:  ['latin_text_perseus'; 'latin_treebank_perseus'; 'latin_text_latin_library'; 'phi5'; 'phi7'; 'latin_proper_names_cltk'; 'latin_models_cltk'; 'latin_pos_lemmata_cltk'; 'latin_treebank_index_thomisticus'; 'latin_lexica_perseus'; 'latin_training_set_sentence_cltk'; 'latin_word2vec_cltk'; 'latin_text_antique_digiliblt'; 'latin_text_corpus_grammaticorum_latinorum'; 'latin_text_poeti_ditalia']"""
b'TODO: This is a weak check for the models actually being downloaded and valid'
b'TODO: Use ``models_dir`` var from below and make self. or global to module'
b'TODO: Check all 4 types of model reading on cpu w\\/ enough memory'
b'TODO: Check; this probably loads model a second time'
b'TODO: Decide whether to drop repos w\\/o models'
b'FIXME res.model.InterceptFlag'
b'- spec.model_base: [optional] base string for C lookup function; FIXME: should not be necessary'
b'TODO \\u5F53\\u524D\\u7684\\u5B9E\\u73B0\\u4F1A\\u5BFC\\u81F4\\u4E4B\\u540E\\u7684processor\\u9700\\u8981\\u77E5\\u9053model\\u8F93\\u51FA\\u7684output\\u7684key\\u662F\\u4EC0\\u4E48'
b'TODO \\u8FD9\\u91CC\\u53EF\\u80FD\\u4F1A\\u9047\\u5230\\u95EE\\u9898\\uFF0C\\u4E07\\u4E00\\u7528\\u6237\\u5728model\\u5185\\u90E8\\u4FEE\\u6539\\u4E86prediction\\u7684device\\u5C31\\u4F1A\\u6709\\u95EE\\u9898'
b'todo \\u53C2\\u8003fairseq\\u7684FairseqModel\\u7684\\u5199\\u6CD5'
b'TODO make way that the model and the criterion are also passed as parameter with introspection thingy as the optimizer'
b'TODO Load model expected size from the actual model'
b'TODO best model is not saved if epoch = 1'
b'TODO: make different functions for different models'
b'TODO: make different functions for different VGG models'
"b'\\""\\""\\""Script to train highres3dnet model. ||  || The input CSV must have two columns: ||     1. filepaths of features ||     2. filepaths of corresponding labels ||  || TODO || ---- || - Make this script more general. Ideally; one could drop in their model and ||     loss function. || - Move some common methods (eg; i\\/o) to dedicated modules. || - Dice coefficient for class 1 (brainmask) is sometimes NaN. || - Input of 1 * 128**3 is too large for 1080ti. This seems to be related to the ||     `input_fn` used. || - Remove pandas as a dependency. Make pure python reader that accepts CSV or ||     TSV as input. || \\""\\""\\""'"
"b'\\""\\""\\""Example script to train model. ||  || The input CSV must have two columns: ||     1. filepaths of features ||     2. filepaths of corresponding labels ||  || TODO || ---- || - Dice coefficient for class 1 (brainmask) is sometimes NaN. This occurs when ||     Dice should be zero. || - Input of 1 * 128**3 is too large for 1080ti to train HighRes3DNet. It is OK ||     for MeshNet. This issue seems to be related to the `input_fn` used. || \\""\\""\\""'"
b'TODO: add priors from existing Keras model.'
b'TODO: can we test if the model is compiled? We lose the optimizer'
b'TODO: if we can load weights after compiling model; load the most recent'
b'TODO add permissions for all comicmodels and registrationRequest'
b'TODO: This class should derive from ComicModelAdmin and not from GuardedModelAdmin'
b'TODO: Add some model tests'
b'TODO: This class is mostly duplicate from evaluation\\/models.py.'
b'TODO patient only images? Propose model change'
b'TODO: Find a better way to support SavedModel. Exposing private attributes is'
b'TODO include default_model & example.txt under resources\\/'
b'todo save model to iteration_0 folder as bin_model'
b'todo major sophisticated automatic execution (check what is missing e.g. bin_model)'
b'TODO download non-packaged [example_entity_model](https:\\/\\/github.com\\/Rostlab\\/nalaf\\/blob\\/develop\\/nalaf\\/data\\/example_entity_model)'
"b'raise ValueError(\\""Model is not persisted; so training must be performed\\"") # TODO is this true?'"
b'TODO This is the desired implementation; but the graphs are altered by the model to have duplicated reversed'
"b'TODO (wardlt): Consider making \\""num_*_features\\"" funcs to simplify making a MEGNet model'"
b'TODO: check if the xml adheres to slicer execution model'
b'TODO: check if the xml adheres to slicer execution model xml schema'
b'TODO: check if xml adheres to slicer execution model xml schema'
b'FIXME: Code to save and restore the model if Training is skipped'
"b'\\""\\""\\"" visualise.py ||  || Visualises the output from training a classifier. ||  || Supports both binary and multi class classifiers. ||  || Use cases: ||  - Visualising the output from training a model ||  - Viewing the output from running batch predictions on a dataset ||  || TODO: Order confusion matrix by most popular class to least popular class || TODO: Output file format in HTML. Always print to the screen. || TODO: Visualisation function should be different from function the output metrics || TODO: Wrap in a Visualiser interface for use in Surround || TODO: Support multiple ground truth and prediction columns || TODO: Add flag to output file with incorrect records. True by default. || TODO: Rename module to visualise_classifier.py ||  || TODO: Add a flag to set probability thresholds || TODO: Add a flag that describes each aspect of the generated report in human readable terminology ||  || \\""\\""\\""'"
b'TODO: this should be the same for every model; given that you pass a config??'
b'TODO: Fix bc it writes in the same folder several models'
b'TODO: Fix to load the correct models'
b'TODO: to train parts of the model in different device'
b'# TODO: to train parts of the model in different device'
"b'\\""\\""\\"" || Classes for representing and processing probabilistic information. ||  || The L{FreqDist} class is used to encode X{frequency distributions}; || which count the number of times that each outcome of an experiment || occurs. ||  || The L{ProbDistI} class defines a standard interface for X{probability || distributions}; which encode the probability of each outcome for an || experiment.  There are two types of probability distribution: ||  ||   - X{derived probability distributions} are created from frequency ||     distributions.  They attempt to model the probability distribution ||     that generated the frequency distribution. ||   - X{analytic probability distributions} are created directly from ||     parameters (such as variance). ||  || The L{ConditionalFreqDist} class and L{ConditionalProbDistI} interface || are used to encode conditional distributions.  Conditional probability || distributions can be derived or analytic; but currently the only || implementation of the C{ConditionalProbDistI} interface is || L{ConditionalProbDist}; a derived distribution. ||  || The L{ProbabilisticMixIn} class is a mix-in class that can be used to || associate probabilities with data classes (such as C{Token} or || C{Tree}). ||  || @group Frequency Distributions: FreqDist || @group Derived Probability Distributions: ProbDistI; MLEProbDist; ||     LidstoneProbDist; LaplaceProbDist; ELEProbDist; HeldoutProbDist; ||     CrossValidationProbDist || @group Analyitic Probability Distributions: UniformProbDist || @group Conditional Distributions: ConditionalFreqDist; ||     ConditionalProbDistI; ConditionalProbDist || @group Probabilistic Mix-In: ProbabilisticMixIn || @sort: FreqDist; ProbDistI; MLEProbDist; LidstoneProbDist; LaplaceProbDist;  ||     ELEProbDist; HeldoutProbDist; CrossValidationProbDist; UniformProbDist; ||     ConditionalFreqDist; ConditionalProbDistI; ConditionalProbDist ||  || @todo: Better handling of log probabilities. || \\""\\""\\""'"
b'TODO use Model 4 scoring instead of Model 5'
b'TODO - last_model :='
b'TODO: adjust regexp for different models'
"b'\\""\\""\\""Temporary hack for decoding mtf_transformer models. ||  || This is a transformer implementation in regular TensorFlow which is || checkpoint-compatible with MtfTransformer for eval\\/inference. ||  || The purpose of this model is to run inference on MtfTransformer models. || We are working on native decoding in MtfTransformer which will be faster and || cleaner. ||  || TODO(noam): Remove once we can decode in mtf. || \\""\\""\\""'"
"b""TODO serialize the entire tfidf model. We'll need it later  to create a sparseMatrixSimilarity object"""
"b'\\""\\""\\"" || Latent Dirichlet Allocation (LDA) in Python; using all cores to parallelize and || speed up model training. ||  || The parallelization uses multiprocessing; in case this doesn\'t work for you for || some reason; try `LdaModel` which is an equivalent; but more straightforward and || single-core implementation. ||  || FIXME wiki timings ||  || This module allows both LDA model estimation from a training corpus and inference of topic || distribution on new; unseen documents. The model can also be updated with new documents || for online training. ||  || The core estimation code is based on the `onlineldavb.py` script by M. Hoffman [1]_; see || **Hoffman; Blei; Bach: Online Learning for Latent Dirichlet Allocation; NIPS 2010.** ||  || The algorithm: ||  || * is **streamed**: training documents may come in sequentially; no random access required; || * runs in **constant memory** w.r.t. the number of documents: size of the ||   training corpus does not affect memory footprint; can process corpora larger than RAM; and || * is **distributed**: makes use of a cluster of machines; if available; to ||   speed up model estimation. ||  || .. [1] http:\\/\\/www.cs.princeton.edu\\/~mdhoffma || \\""\\""\\""'"
b'FIXME : Meant to work for LDAModel; LdaVowpalWabbit right now. Make it work for others.'
b'TODO: replace fit_lda_post with appropriate ldamodel functions; if possible.'
b'TODO create show_topic in HdpModel and then test'
b'TODO: this is duplication of code in LdaModel. Refactor.'
b'TODO: this method is somewhat similar to the one in LdaModel. Refactor if possible.'
b'TODO: This method is very similar to the one in LdaModel. Refactor.'
b'TODO: Allow passing in full model path and only require one argument'
"b""TODO: Unset this once we don't want to support models previous models."""
"b""TODO: Remove this once we're not supporting models trained with thinc <6.9.0"""
b'TODO: fix load model'
b'TODO: Multiply by the number of dimensions so it scales the number of models'
b'TODO: fix broken model here'
b'TODO: finish the tests once the main model is ready'
b'TODO: should support parallelization at the model level'
b'TODO: discuss how to standardize data for different model types'
b'class Attachment(models.Model):  TODO'
b'TODO for API use; pred_model and dim_reducer must be validated here again'
b'TODO: Where to set this? Or; is this the same as Estimator.model_dir?'
b'todo: recompute model'
b'TODO: we can do this automatically when setting up the models by having'
b'TODO: remove self.testing condition because model.summarize() is wiping out the weights'
b'TODO - refector this function to accept model_name; instance; parent so it makes more sense'
b'todo: without passing model it fails for missing best weights'
b'TODO currently no support for vertical model parallel'
b'Todo: required argument `model` is not used'
b'todo: enabled since internally we wrap the model for optimizer step; this should be fixed'
b'todo: think about better way without need to dump model to drive'
b'todo: seems it does not work with quantized models - it returns 0.0'
b'TODO: is there a better way than accessing trainer through model -> trainer?'
b'TODO: disallow None pipeline (modify model selection case handling)'
b'TODO save model'
b'TODO see openai baselines; model.py;  _mlp is so clean'
b'TODO turn on save\\/load model mode'
b'TODO hack and set the eval model location inside info_space'
b'TODO eval call using eval_model_prepath'
b'TODO: incorporate into heuristic models'
"b""TODO: I don't like the redundancy here; i.e.; the model class is a key in"""
b'TODO: FrameModel needs to have a metaclass that knows how to map extractors'
b'TODO: Move this into Model'
b'TODO: This is used in analyze.extractor and model.frame. Can it be'
"b""TODO: I'm not sure the model module package is the appropriate place for this;"""
b'TODO: Remove import when statsmodels updates #18264'
"b'\\""\\""\\"" || Model Zoos. || TODO add shape size for each layer || \\""\\""\\""'"
b'TODO ? link_vectors_to_models(self.vocab)'
b'TODO ? link_vectors_to_models(self.vocab) depr?'
b'TODO: handle base model'
"b'\\""\\""\\"" || Todo: cross-check the F-value with stats model || \\""\\""\\""'"
b'## TODO: intercept for all models'
"b'\\""\\""\\"" || Simple Gaussian Mixture model plotting example ||  || TODO: use the faithful dataset || \\""\\""\\""'"
"b""TODO store the best model in a variable named 'clf'"""
"b""FIXME in 1.2: parameter 'normalize' should be removed from linear models"""
b'TODO - DSG - transform data into model ready data. Must return list; where each element is an example.'
b'TODO - DSG - load model from disk to memory'
b'Todo score accumulation to check if this model is better than the saved one'
b'combine column headers into one list #TODO: this is probably not neccessary as lists are combined at modelling'
b'TODO: Estimate likelihood of jghj datasetjgj; given the model'
b'TODO: maybe due to the initial embedding that has to be done; all inputs are given when defining the model;'
b'TODO: maybe do not execute this line in the training model to save computation ? Maybe it wouldnt be executed anyway ?'
b'TODO sample_posterior_predictive_w is currently only work for model with'
b'TODO: cache bn for the same `meta_model` and `variational`.'
b'TODO: Model based FS (random forest variable importance; ...); RFE'
b'FIXME: irrespective of PyListModel check; this might\\/should always'
b'TODO: Implement filtering on the model'
"b""This is a simple implementation of Kipf & Welling's Semi-Supervised Classificaton with Graph Convolutional Networks in ICLR 2017; which propose a simple yet efficient model that extends convolutional neual network from the grid structured data we all familiar and like to graphs; like social network and knowledge graph. It starts from the framework of spectral graph convolutions and makes reasonable simplifications to achieve both faster training and higher prediction accuracy. It also achieves start-of-the-art classification results on a number of graph datasets like CORA; etc. \\/TODO: elaborate."""
b'TODO: loading model emb only work for genernal Embedding; not for ExternalEmbedding'
"b'\\""\\""\\""01. Predict depth from a single image with pre-trained Monodepth2 models || =========================================================================== ||  || TODO || \\""\\""\\""'"
b'TODO: should use model instead of self.model'
b'TODO replace this speedup implementation with nni.compression.torch.ModelSpeedup'
b'TODO: how to get the actual model?'
b'TODO: replace with actual models'
b'TODO(ekl): move to rllib\\/models dir'
b'TODO: Have a separate model catalogue for bandits'
b'TODO(sven): Add once ModelV1 is deprecated and we no longer cause circular'
b'TODO(sven): Move `add_layer_norm` into ModelCatalog as'
b'TODO: (sven) allow for having a default model config over many'
b'TODO: (sven) move to models\\/utils.py'
b'TODO: (sven) hack; but works for `target_[q_]?model`.'
b'TODO: modelpar currently broken on synthetic-sanity_check.yaml'
"b""TODO: arguments won't be saved in keras export model"""
b'todo: add test that use the same random seed with two models: a static chain'
b'TODO: This feature seems to be a normalized version of the'
b'TODO: If the categorical attributes are considered; this feature is'
"b""''' || Todo: || - Add categorical features || - Add method to FoldYielder to import other data into correct format; e.g. csv; root || - Make HEPAugFoldYielder able to augment targets as well || '''"""
b'TODO Decide how to handle missing features when deprocessing matrix data'
b'FIXME we do this because context.feature is set dynamically in EE testing'
b'TODO: check if stride of 2 causes alignment issues if the featuremap'
"b""TODO: add assert to varify feature map sizes match what's in config"""
b'TODO: If this is not true; the feature slicing should be differnet in the network building.'
b'TODO: How to trim the auxiliary features? Align left or center?'
b'TODO : add more feature with downsample?'
b'FIXME: proper representation for arbitrary features'
b'TODO: decompose postag into individual morphological features'
b'FIXME: split features in multiple attributes'
"b'\\""\\""\\"" || WIP ||  || This file should contain classes (that behave like torch models); but they || implement the learning of classical learning algorithms like SVM and || RandomForest. ||  || Deep networks are amazing at learning features. However; I don\'t think it\'s || very useful to use linear logicstic regression as a classifier. In many cases I || think an SVM or a RandomForest might produce a superior classification model; || but this has yet to be shown. ||  || TODO: ||     - [ ] Classical Abstract API ||     - [ ] Integration with the FitHarn ||         - [ ] How do we swap netharn\'s backprop+SGD with sklearn\'s SVM and RandomForest fit methods? ||         - [ ] Netharn needs a \\""classical\\"" implementation of \\""run\\"". ||             - [ ] Simply use the data loader to load the data ||             - [ ] Defaults should encourage use with deep features. ||     - [ ] RandomForest ||     - [ ] SVM || \\""\\""\\""'"
"b'\\""\\""\\"" || Proof-of-concept for porting mmcv DataContainer concept to netharn. Depending || on how well this works these features might be useful as a standalone module or || to contribute to torch proper. ||  || References: ||     https:\\/\\/github.com\\/open-mmlab\\/mmcv\\/blob\\/master\\/mmcv\\/parallel\\/data_container.py ||     https:\\/\\/github.com\\/open-mmlab\\/mmcv\\/blob\\/master\\/mmcv\\/parallel\\/collate.py ||     https:\\/\\/github.com\\/open-mmlab\\/mmcv\\/blob\\/master\\/mmcv\\/parallel\\/scatter_gather.py ||  || FIXME 0 dimension tensors || \\""\\""\\""'"
b'TODO: Add information about the number of prototype cells and the feature size'
b'FIXME: switch to layer.out_features?'
b'FIXME: switch to layer.in_features?'
b'FIXME  dict_key\\u662Ffeature value;dict_value\\u662Fsubspace-tree-root\\u8282\\u70B9'
b'TODO: check if stride of 2 causes alignment issues if the feature map'
b'TODO This is scaling samples. Perhaphs amend to give option to scale features as well.'
b'todo: this is not completed. feature dimension must be the same as training data'
b'todo: save features'
b'TODO HANDLE DIFFERENT DATASETS FEATURES AND FIX OTHER THINGS (RUN TO SEE)'
"b""TODO(rbharath): Untransform doesn't work properly for binary feature"""
"b'\\""\\""\\""Meta-feature extractor wrapper for MFE R package. ||  || This module is a wrapper to MFE package. MFE is a meta-feature extractor || package building in R. ||  || Example: ||     TODO ||         $ python example_google.py ||  || Todo: ||     * Create an simple example ||     * Create a method to extract meta-features from csv files ||     * You have to also use ``sphinx.ext.todo`` extension ||  || \\""\\""\\""'"
"b'\\""\\""\\""EXtracts metafeatures from structured datasets. ||  || Todo: ||     More information here. || \\""\\""\\""'"
"b'\\""\\""\\""Module dedicated to extraction of General Metafeatures. ||  || Todo: ||     - Implement all metafeatures. ||     - Improve documentation. ||  || References: ||     1. \\""Towards Reproducible Empirical Research in Meta-Learning\\""; ||         Rivolli et al. URL: https:\\/\\/arxiv.org\\/abs\\/1808.10406 || \\""\\""\\""'"
"b'\\""\\""\\""Main module for extracting metafeatures from datasets. ||  || Todo: ||     - Improve documentation. ||     - Implement MFE class. || \\""\\""\\""'"
"b'\\""\\""\\""Main module for extracting metafeatures from datasets. ||  || Todo: ||     * Improve documentation. ||     * Implement MFE class. || \\""\\""\\""'"
"b'\\""\\""\\""Module dedicated to extraction of Information Theory Metafeatures. ||  || Todo: ||     * Implement metafeatures. ||     * Improve documentation. || \\""\\""\\""'"
"b'\\""\\""\\""Module dedicated to extraction of Landmarking Metafeatures. ||  || Todo: ||     * Implement metafeatures. ||     * Improve documentation. || \\""\\""\\""'"
"b'\\""\\""\\""Module dedicated to extraction of Statistical Metafeatures. ||  || Todo: ||     * Implement metafeatures. ||     * Improve documentation. || \\""\\""\\""'"
b'TODO Add a stop at convergence feature'
b'TODO: Maybe skip the FeatureUnion if `len(parents)==1` ?'
"b'\\""\\""\\"" || Surfit || ====== ||  ||  || Create a surface image from CT volume ||  || This script consists of three main steps: ||  ||     1. Denoise ||     2. Feature Enhancement ||     3. Surface Generation ||  ||  || 1. Denoise || ********** || TODO ||  || 2. Feature Enahncement || ********************** || TODO ||  ||  || 3. Surface Generation || ********************* || TODO ||  ||  ||  ||  ||  || \\""\\""\\""'"
b'TODO: Should be using feature columns?'
"b'\\""\\""\\"" || Batch sizes: 32 = 5GB memory; 128 = 17GB ||  || The \\""read -1 expected ...\\"" errors are harmless and come from Docker. See https:\\/\\/github.com\\/horovod\\/horovod\\/issues\\/503 || Running Docker in privileged mode (docker run --privileged) solves the issue. ||  || Dataset handling: Lots of empty lines; use dataset.filter() to eliminate those. || For now; just grab one sentence. || TODO: Combine two segments into a single example. https:\\/\\/github.com\\/google-research\\/electra\\/blob\\/master\\/build_pretraining_dataset.py || TODO: Add zero-padding for shorter sequences ||  || nlp feature request: Select from dataset with arbitrary slices || `nlp` package tutorial: https:\\/\\/colab.research.google.com\\/github\\/huggingface\\/nlp\\/blob\\/master\\/notebooks\\/Overview.ipynb || \\""\\""\\""'"
b'TODO write tests for feature extractor once class is written'
b'TODO this should have options for window_wize; features to exclude; and anything else.'
"b""TODO: we can't handle modification features in"""
b'TODO because we use the API Gateway; this feature is not longer needed.'
b'TODO: handle BindingFeatures and FragmentFeatures here'
b'TODO: make it so that question counts are removed in generating features'
b'(TODO): Perhaps create versions with different subsets of the features?'
"b""TODO: don't use most frequent bigrams; look by class via feature selection"""
b'TODO: add more external features like:'
b'TODO: Alternative features; to integreate in bug_features.py'
b'TODO: Try simply using all possible fields instead of extracting features manually.'
b'TODO: Actually implement feature importance visualization for multiclass problems.'
b'precision_nnz = 1. * np.count_nonzero(precision) \\/ n_features # TODO: does this scaling make sense?'
b'TODO Remove assumption of fbank features'
"b""TODO Confirm that the feature files exist. Create them if they don't."""
b'TODO Make this None and infer feature_type from dimension of NN input layer.'
b'TODO input checks on target and feature args'
b'TODO implement compatibility checks between metadata and task: e.g. for tsc; if features are present'
b'TODO include series-as-features transformers'
b'TODO refactor Tabularizer as series-as-features composition meta-estimator;'
b'TODO support sparse features'
b'1 TODO Preprocess data? norm? if RR interval; last 4 features are pre; post; local and global RR'
b'TODO export features;labels .csv?'
b'0) TODO if feature_Selection:'
b'feature usage # !TODO: Dangerous if max_depth is set to None; what happens then?'
b'TODO: Record the column features in train df'
b'TODO: Drop `suppress` - Was for `feature_engineer={}`'
b'TODO: Add `FeatureEngineer` method called after `inverse_transform` to format as DataFrame'
"b'\\""\\""\\""This module defines mechanisms for managing an experiment\'s various datasets; and each datasets\'s || inputs; targets; and predictions. ||  || **Important Contents** ||  || In order to maintain the states of different datasets across all divisions of an experiment and || amid transformations that may be applied to the data via || :mod:`~hyperparameter_hunter.feature_engineering`; two main classes are defined herein: ||  || 1. :class:`BaseDataChunk`: ||  ||     * Logical separations between \\""columns\\"" of data for a given :class:`BaseDataset` ||     * Held and maintained by :class:`BaseDataset` and its descendants ||     * Three primary descendants of :class:`BaseDataChunk`: ||  ||         1. :class:`InputChunk`: Maintains a dataset\'s input data (and transformations) ||         2. :class:`TargetChunk`: Maintains a dataset\'s target data (and transformations) ||         3. :class:`PredictionChunk`: Maintains a dataset\'s predictions (and transformations) ||  ||     * Descendants of :class:`BaseDataChunk` should implement the eight \\""on_<division>_<point>\\"" ||       callback methods defined by :class:`~hyperparameter_hunter.callbacks.bases.BaseCallback` ||  ||         * Because :class:`BaseDataChunk` subclasses are isolated from the experiment; these methods ||           need not invoke their `super` methods; although they are allowed to if necessary ||  ||     * :class:`NullDataChunk` does nothing but mimic the normal :class:`BaseDataChunk` child structure ||  ||         * Used for :class:`BaseDataset` subclasses lacking a particular data chunk; such as: ||  ||             1) `TestDataset`\'s `TargetChunk`; because the targets for a test dataset are unknown; or ||             2) `TrainDataset`\'s `PredictionChunk`; because predictions are not made on training data ||  || 2. :class:`BaseDataset`: ||  ||     # TODO: ... ||  || **Dataset Attribute Syntax** ||  || The intricate subclass network bolstering the module\'s predominant :class:`BaseDataset` subclasses || may be intimidating at first; but don\'t worry; there\'s a shortcut. Follow these steps to ensure || proper syntax and a valid result when accessing data from a || :class:`~hyperparameter_hunter.experiments.CVExperiment`: ||  || 1. {`data_train`; `data_oof`; `data_holdout`; `data_test`} - Dataset attribute || 2. {`input`; `target`; `prediction`} - Data chunk || 3. [`T`] - Optional transformation || 4. {`d`; `run`; `fold`; `rep`; `final`} - Division; initial (`d`) or `final` data ||  || By stacking three values (four if following optional step \\""3\\"") from the above formula; you can || access all of the interesting stuff stored in the datasets from the comfort of your experiment or || :func:`~hyperparameter_hunter.callbacks.bases.lambda_callback`. ||  || Related || ------- || :mod:`hyperparameter_hunter.callbacks.bases` ||     This module defines the core callback method structure mirrored by :class:`BaseDataCore`. ||     Despite the strong logical connection to this module; it is important to remember that the only ||     actual connection between the two modules is in :mod:`hyperparameter_hunter.callbacks.wranglers` || :mod:`hyperparameter_hunter.callbacks.wranglers` ||     # TODO: ... Handlers for the `Dataset`s to invoke callback methods with required parameters ||     This module defines the callback classes that act as handlers for the descendants of ||     :class:`BaseDataset` || :mod:`hyperparameter_hunter.experiments` ||     # TODO: ... || \\""\\""\\""'"
"b'TODO: Should target wranglers addition be contingent on `kwargs[\\""feature_engineer\\""].steps'"
b'TODO Add numbers in the final image to the feature channels.'
b'TODO: min_num_of_features -> init argument'
b'TODO: if wanna use time as a categorical feature'
"b""hps_dict.update({'dqn_input_feature_len':(FLAGS.dec_hidden_dim+FLAGS.max_dec_steps)}) # TODO: more test on this; if wanna use time as a categorical feature"""
b'TODO: a more flexible way to decide which feature maps to use'
"b""TODO:  self.init_std\\/ math.sqrt(float(dim))  #self.params['feature_dim']"""
b'TODO: maybe replace numDownSlope instead with a different feature:'
b'mfcc_delta = librosa.feature.delta(mfcc; width=5; order=1)    TODO'
b'TODO Feature transform function.'
b'TODO gazetteer features'
b'Path to TODO file and feature cache:'
b'Check for features TODO: THIS NEEDS TO BE CHANGED!'
b'TODO: Avg feature importance foo all classifiers'
"b""[BETA] - TODO: select features 'manually'"""
b'TODO: Look in to missing data ratios of disease-specific features'
b'Todo: try to discriminate the feature map'
b'TODO: Remove X% of the x_features'
b'TODO: Return the features that were removed'
b'TODO: FeatureUnion?'
b'TODO check the feature_map_shape_list is consistent with'
b'TODO: add more features'
b'TODO: This logic needs to be checked. See if it works with multiple features.'
b'TODO: extract prosodic features'
b'TODO: test the feature'
b'FIXME: change according to feature preprocessing. tip: for standardization; use'
b'TODO add more Baidu-style features here'
b'feature_np[index; length:] = 0  # TODO replace 0 by dict'
b'feature_copy[index; length:] = 0  # TODO replace 0 by dict'
b'TODO clean up all this to leverage built-in features of tokenizers'
b'TODO: add tests for the following once they return features not matrixes:'
b'TODO: Why are correlated features only pruned if the target is present?'
b'Todo: At the moment; scaling and feature reduction converts ints to floats'
b'todo: tests should include using custom (user speficied) features as well'
b'todo: change the feature_na_method!'
b'TODO: Optimize: When running multiple detectors feature extraction has to be done only once'
b'TODO: Implement feature extraction parts of Magpie in python.'
b'from rasterio.features import is_valid_geom #FIXME: wait for https:\\/\\/github.com\\/mapbox\\/rasterio\\/issues\\/1815 to be solved'
b'TODO: test this with invalid features.'
b'TODO: add following info: associated featuresets; models'
b'TODO: Custom features script handling'
b'TODO: Extract list of custom features from code'
b'TODO: terminology? feature or observation?'
b'FIXME: features? need to use extract from preprocess.py'
b'TODO: prepare for a future where tgt features are possible'
b'TODO: prepare for a future where tgt features are possible.'
b'TODO: support these blacklisted features.'
b'TODO: support these blacklisted features'
b'TODO maybe add scrollbar feature for one supply\\/demand list'
b'TODO: Remove when FeatureHasher is implemented in PYPY'
b'todo: refactor to reuse SeuuqnceOutputFeature.postprocess_results'
b'todo tf2: hardcoding for a single output feature - need to generalize'
b'output_last_hidden[output_feature_name] = decoder_last_hidden  #todo tf2 do we need this long-term give the above'
b'set_feature(vocab_size=3);  # TODO fix'
b'bag_feature(vocab_size=3);  # TODO fix'
b'assert len(inputs.shape) == 2  # TODO: check correct inputs.shape as per sequence feature'
b'todo revisit to see if can use output feature.postprocess_results()'
b'todo tf2: encoder_obj should be passed to the sequenceinputfeature'
b'todo maybe move code from add_feature_data here'
b'TODO remove feature?'
b'TODO: provenence feature based on Rule.STATETRANS? but seems that it is the only option for the AMR!'
b':TODO Add 6 low-level feature extraction'
b'TODO: save feature as np'
b'TODO: Subtract feature stats; run prediction'
b'TODO: Get RandomizedLogistic (auto feature selection) working in place of linear'
b'TODO Modify mu and sigma once feature scaling is built into the logistic regression'
"b""TODO: features simulation isn't launch each time we call simulate"""
b'TODO: check and correct also n_samples; n_features and cov_corr and features_scaling'
"b""TODO: features simulation isn't launch each time we call simulate"""
b'TODO rename image-features'
b'TODO: add scrolling feature (currently disabled)'
b'Todo: generalize and move to features.core'
"b'\'\' || def load_pdbbind_molecules(paths; dir_name=\\""fingerprints\\""): ||   \\""\\""\\""Load dataset fingerprints and return fingerprints. ||   \\""\\""\\"" ||   # TODO(rbharath): This is a total kludge. Clean up later. ||   dir_name = \\""targets\\"" ||   molecules = {} ||   for dataset_path in paths: ||     pickle_dir = os.path.join(dataset_path; dir_name) ||     pickle_files = os.listdir(pickle_dir) ||     if len(pickle_files) == 0: ||       raise ValueError(\\""No Pickle Files found to load molecules\\"") ||     for pickle_file in pickle_files: ||       with gzip.open(os.path.join(pickle_dir; pickle_file); \\""rb\\"") as f: ||         contents = pickle.load(f) ||         smiles; fingerprints; scaffolds; mol_ids = ( ||             contents[\\""smiles\\""]; contents[\\""features\\""]; ||             None; None) ||         for mol in range(len(contents[\\""smiles\\""])): ||           molecules[smiles[mol]] = {\\""fingerprint\\"": fingerprints[mol]; ||                                     \\""scaffold\\"": None; ||                                     \\""mol_id\\"": None} ||   return molecules  || \'\'\''"
"b""TODO: add pi_stack and cation_pi to feature_types (it's not trivial"""
"b""TODO: add pi_stack and cation_pi to feature_types (it's not trivial"""
b'TODO: Allow the user to specify this feature'
b'TODO: Refactor MissingDataVisualizer to make use of new features.'
b'TODO: allow the user specified features to filter the dataset'
"b""FIXME use feature.crop(mode='center'; fixed=duration) instead"""
b'TODO: use new pytorch feature that handle sorting automatically'
b'@TODO: return the feature'
b'TODO: programmatically check wether these are indeed features (predict; correct)'
b'TODO let the user choose the feature indices of interest'
b'TODO: this should use check_feature_type'
b'TODO: Is this correct or should I return np.hstack((features; 1)) as'
b'TODO: feature?'
b'TODO (nakago): test feature extraction behavior...'
"b""TODO check if most_common feature really isn't that useful"""
b'TODO: this code is very similar to features.onsets.peak_picking();'
b'TODO: inherit from features.Activations'
b'TODO: refactor this to use new feature.tempo functionality'
b'TODO: split the classes similar to madmom.features.onsets?'
b'TODO: split the classes similar to madmom.features.beats?'
b'TODO: Add some sort of check for duplicate feature names'
b'TODO: evaluate cases when len(unique(feature))==2'
b'TODO: check on the feature space approximation (V2)'
b'TODO: extend support to other forms of Vectorization schemes - Feature Hashing'
b'TODO: weight tying? lexicon and all other features the RNN supports?!'
b'TODO: enable caching to reuse features and resume computation'
b'TODO: Not sure how this feature should work still...'
b'TODO: Is this made obsolete by the FeatureExtractor?'
b'TODO: Ensure only v2 Feature Columns are used.'
b'TODO: Deserialized embedding feature column behavior is the'
"b'\\""\\""\\""Example script to train model. ||  || The input CSV must have two columns: ||     1. filepaths of features ||     2. filepaths of corresponding labels ||  || TODO || ---- || - Dice coefficient for class 1 (brainmask) is sometimes NaN. This occurs when ||     Dice should be zero. || - Input of 1 * 128**3 is too large for 1080ti to train HighRes3DNet. It is OK ||     for MeshNet. This issue seems to be related to the `input_fn` used. || \\""\\""\\""'"
b'TODO: in the future; multi-channel features should be supported.'
b'TODO implement separate test functions for each feature that is already implemented in test_generate'
b'TODO decorator that checks features'
b'TODO move to edge features'
b'TODO investigate features'
b'TODO this would be better written in the (entities) FeatureGenerator'
b'TODO the following is better written here; instead of the FeatureDictionary as originally written'
b'TODO Drop support for ignoring features'
b'TODO: For dense; cast to Conv1D size e.g. (1; out_features).'
b'TODO: Parse feature values to their real type here; e.g. parse ints or floats'
"b'\\""\\""\\"" || Basic data classes for representing feature structures.  A X{feature || structure} is a mapping from feature names to feature values; where: ||  ||   - Each X{feature name} is a case sensitive string. ||   - Each X{feature value} can be a base value (such as a string); a ||     variable; or a nested feature structure. ||  || Feature structures are typically used to represent partial information || about objects.  A feature name that is not mapped to a value stands || for a feature whose value is unknown (I{not} a feature without a || value).  Two feature structures that represent (potentially || overlapping) information about the same object can be combined by || X{unification}.  When two inconsistent feature structures are unified; || the unification fails and returns C{None}. ||  || Features can be specified using X{feature paths}; or tuples of feature || names that specify path through the nested feature structures to a || value.  Feature structures may contain reentrant feature values.  A || X{reentrant feature value} is a single feature value that can be || accessed via multiple feature paths.  Unification preserves the || reentrance relations imposed by both of the unified feature || structures.  In the feature structure resulting from unification; any || modifications to a reentrant feature value will be visible using any || of its feature paths.  Feature structures may also contain X{cyclic || feature values}; i.e.; values that recursively contain themself. ||  || Feature structure variables are encoded using the L{nltk.sem.Variable} || class.  The variables\' values are tracked using a X{bindings} || dictionary; which maps variables to their values.  When two feature || structures are unified; a fresh bindings dictionary is created to || track their values; and before unification completes; all bound || variables are replaced by their values.  Thus; the bindings || dictionaries are usually strictly internal to the unification process. || However; it is possible to track the bindings of variables if you || choose to; by supplying your own initial bindings dictionary to the || L{unify() <FeatStruct.unify>} method. ||  || When unbound variables are unified with one another; they become || X{aliased}.  This is encoded by binding one variable to the other. ||  || @todo: add a fail parameter to unify?  This would be a function that ||    would be called if unificaiton fails; it could either raise a ||    UnificationFailure error; or return a value.  How would this be ||    useful?  Well; one example is that it could be used to find a ||    \\""diff\\"" between two feature structures -- i.e.; a list of all ||    feature paths with different values.  Anyway; the old version had ||    it.  Ask steven why it was introduced? ||  || @todo: Figure out yaml support.  Do we need any? ||  || @todo: support for mutable feature structures? ||  || @todo: define __div__ for feature structures? ||  || relative to category; we don\'t define... ||   - .symbol (we\'re not a Nonterminal) ||   - .head() ||   - .feature_names(); .has_features() -- eh ||   - .to_yaml() and .from_yaml() ||   - parsing of cfgs.. ||  || \\""\\""\\""'"
b'TODO: Add FeatureProduction; with a better def. of __str__:'
b'Todo : can come up with more complicated features set for better performance.'
b'Todo : can come up with more complicated features set for better'
b'TODO: Support extract features from multiple layers'
b'TODO add a check for min_features; e.g. d<=3 & max_features as well'
b'TODO: failed due to sklearn uses 2 feature examples.'
b'TODO: formulate this on the basis of _FEATURE_MASK'
b'TODO document this feature or remove it'
b'TODO perhaps I can have two arguments: one to specify feature type (which determines the reader); and another'
b'TODO generate visualizations for each feature set as well as a comparative summary!'
b'TODO need to devise a way to avoid re-reading all the features from scratch every time.'
b'TODO if feature names are implemented; save them too'
b'TODO to achieve feature- or method-level parallization;'
b'TODO new feature: add additional metrics such as PPV'
b'TODO optimize the num features to select as part of grid search'
b'TODO: DynamicFeaturesAdder'
b'TODO: ShapeFeaturesAdder'
b'todo (tchaton) awaiting this feature to move upstream to DeepSpeed'
b'#TODO: add user features and concat here; use usergraph.extend'
b'TODO: MultiFeature class (like for minhash features)'
b'TODO: Grabs features; builds an Extractor chain; can check db for'
b'TODO: MultiFeature class (like for minhash features)'
b'TODO: Lazily compute unstored features when requested'
b'TODO: ExtractorChain.prune() that can take multiple features and tests'
b'TODO: return every frame of this feature shuffled'
b'TODO: tf\\/idf on features'
b'TODO: nbits could be inferred from the feature'
b'TODO: Should I just expect input from the AutoCorrelation feature?'
b'TODO: Should I do a sub-database per feature; or organize the keys as'
b'TODO(rohanj): This is a hack to get around not depending on feature_column and'
b'FIXME: NOT WORKING. PLEASE FIX ME. There seem to be something wrong with the n-gram features.'
b'FIXME: the iris dataset has only 4 features!'
b'TODO: test also n_samples > n_features'
b'TODO: feature request OpenML.'
b'TODO: pass in a list of expected nominal features'
b'TODO: this should be `feature_names_in_` when we start having it'
b'TODO: Remove parametrization in 0.24 when None is removed for FeatureUnion'
b'TODO: also call _check_n_features(reset=False) in 0.24'
b'TODO: complexity is O(n_categorical_features * 255). Maybe this is'
b'TODO: add PolynomialFeatures if it moves to _polynomial.py'
"b'\\""\\""\\"" || _import(\\""data.sample\\"") || _import(\\""data.outliers\\"") || _import(\\""data.preprocess\\"") || _import(\\""data.preprocess.scaling\\"") || _import(\\""data.utils\\"") || _import(\\""data.discretization\\"") || _import(\\""data.continuization\\"") || _import(\\""data.filter\\"") || _import(\\""data.imputation\\"") ||  || _import(\\""feature\\"") || _import(\\""feature.construction\\"") || _import(\\""feature.construction.functionDecomposition\\"") || _import(\\""feature.construction.univariate\\"") || _import(\\""feature.discretization\\"") || _import(\\""feature.imputation\\"") || _import(\\""feature.scoring\\"") || _import(\\""feature.selection\\"") ||  || _import(\\""network\\"") ||  || _import(\\""stat\\"") ||  || _import(\\""statistics\\"") || _import(\\""statistics.estimate\\"") || _import(\\""statistics.contingency\\"") || _import(\\""statistics.distribution\\"") || _import(\\""statistics.basic\\"") || _import(\\""statistics.evd\\"") ||  || _import(\\""classification\\"") || _import(\\""classification.tree\\"") ||  || _import(\\""classification.rules\\"") ||  || _import(\\""classification.lookup\\"") || _import(\\""classification.bayes\\"") || _import(\\""classification.svm\\"") || _import(\\""classification.logreg\\"") || _import(\\""classification.knn\\"") || _import(\\""classification.majority\\"") ||  || _import(\\""tuning\\"") ||  || _import(\\""projection\\"") || _import(\\""projection.linear\\"") || _import(\\""projection.mds\\"") || _import(\\""projection.som\\"") ||  || _import(\\""ensemble\\"") || _import(\\""ensemble.bagging\\"") || _import(\\""ensemble.boosting\\"") || _import(\\""ensemble.forest\\"") || _import(\\""ensemble.stacking\\"") ||  || _import(\\""regression\\"") || _import(\\""regression.base\\"") || _import(\\""regression.earth\\"") || _import(\\""regression.lasso\\"") || _import(\\""regression.linear\\"") || _import(\\""regression.mean\\"") || _import(\\""regression.pls\\"") || _import(\\""regression.tree\\"") ||  || _import(\\""multitarget\\"") || _import(\\""multitarget.tree\\"") ||  || _import(\\""multilabel\\"") || _import(\\""multilabel.multibase\\"") || _import(\\""multilabel.br\\"") || _import(\\""multilabel.lp\\"") || _import(\\""multilabel.mlknn\\"") || _import(\\""multilabel.brknn\\"") || _import(\\""multilabel.mulan\\"") ||  || _import(\\""associate\\"") ||  || _import(\\""distance\\"") ||  || _import(\\""wrappers\\"") ||  || _import(\\""featureConstruction\\"") || _import(\\""featureConstruction.univariate\\"") || _import(\\""featureConstruction.functionDecomposition\\"") ||  || _import(\\""evaluation\\"") || _import(\\""evaluation.scoring\\"") || _import(\\""evaluation.testing\\"") ||  || _import(\\""clustering\\"") || _import(\\""clustering.kmeans\\"") || _import(\\""clustering.hierarchical\\"") || _import(\\""clustering.consensus\\"") ||  || _import(\\""misc\\"") ||  || _import(\\""utils\\"") #TODO hide utils from the user || _import(\\""utils.environ\\"") || _import(\\""utils.counters\\"") || _import(\\""utils.addons\\"") || _import(\\""utils.render\\"") || _import(\\""utils.serverfiles\\"") ||  || _import_addons() || \\""\\""\\""'"
"b'\\""\\""\\"" || Use DGLGraph || ============ ||  || In this tutorial; we introduce how to use our graph class -- ``DGLGraph``. || The ``DGLGraph`` is the very core data structure in our library. It provides the basic || interfaces to manipulate graph structure; set\\/get node\\/edge features and convert || from\\/to many other graph formats. You can also perform computation on the graph || using our message passing APIs. (TODO: give a link here to the message passing doc) || \\""\\""\\""'"
b'TODO I duplicate some node features.'
"b""TODO: all all the SGD features from PyTorch's SGD"""
b'TODO implement this feature using MultiPointerTensor'
b'TODO: Avoid using undocumented feature'
b'todo: Optimizers do not yet support static graph feature.'
b'TODO: load pretrained embeddings to check sizes'
b'TODO: support training mode?'
b'TODO: Fix training parameter'
b'TODO Restore our CNN from trained data'
"b'\\""\\""\\""TODO Implement controller ||  || Example request with tasks to the API: || { ||     \'userId\': 20; ||     \'commandTemplate\': \'CUDA_VISIBLE_DEVICES={CVD} train.py --task-id {TID}\'; ||     \'values\': [ ||         {\'hostname\': \'galileo\'; \'CVD\': 0; \'TID\': \'ps\'}; ||         {\'hostname\': \'galileo\'; \'CVD\': 1; \'TID\': \'worker\'}; ||         {\'hostname\': \'galileo\'; \'CVD\': 1; \'TID\': \'worker\'}; ||         {\'hostname\': \'galileo\'; \'CVD\': 1; \'TID\': \'worker\'}; ||     ] || } || \\""\\""\\""'"
b'TODO: Run beam search whenever self.training is False so that we can get'
b'TODO(xhebraj) implement return of train\\/test\\/validation'
b'@todo only pick training images!!!'
b'TODO: cross-validations or at least train\\/test split'
"b"".conv(3; 3; 64; 1; 1; name='conv1_2'; trainable=True)     # TODO"""
b'Needs to restore the other hyper-parameters\\/states for training; (TODO xinlei) I have'
"b'\\""\\""\\""An implementation of the overfitting test for the Transformer model. ||  || A simple test; which often signifies bugs in the implementation of a model; is the overfitting test. To that end; the || considered model is trained and evaluated on the same tiny dataset; which it should be able to overfit easily. || Therefore; the final model should yield very high probabilities for the desired target values. If this is not the case; || however; then there is probably something wrong with the tested model and\\/or its implementation. ||  || TODO: explain a bit more || \\""\\""\\""'"
"b""FIXME: for 'rest' to be able to contain parens; would need constraint"""
b'TODO: need to put all trainable layer types here'
b'TODO: check for train_info.json in a few different places'
b'TODO: Use sliding windows so detection can be run and trained on'
b'TODO: find a better\\/general way of handling training dynamics'
b'TODO: Remove the constraint that forces columns to be sorted'
"b""''' || Test action recognition on || (1) a video; (2) a folder of images; (3) or web camera. ||  || Input: ||     classes: data_proc\\/classes.csv # TODO: change this to a config file ||     model: model\\/trained_classifier.pickle ||  || Output: ||     result video:    output\\/${video_name}\\/video.avi ||     result skeleton: output\\/${video_name}\\/skeleton_res\\/XXXXX.txt ||     visualization by cv2.imshow() in img_displayer || '''"""
b'X_train = X_train \\/ 127.5 - 1.  #TODO'
b'FIXME stop and start training!!'
"b""''' || * todo || * bcolz.set_nthreads(nthreads) || * bucket sampling ||  ||  || --- ||  || same bucket algorithm; with indexing: ||  || figure out the sizes required from each generation based on buckets (easy; any rounding issues; || drop from oldest generation) ||  || create a range(n) where n is the size of a generation.  shuffle.  remove head or tail until size. || [old version removed tail; but it doesn't matter] ||  || combine all (need to offset start index of each generation data] ||  || shuffle. ||  || --- ||  || old algo for validation set: || * no shuffling done on generation.  ie always the same last n of the generation data. || * any buckets < 1.0; threw away tail || * was shuffled before training ||  || --- ||  ||  || # XXX call samples -> observations (from self play). ||  ||  || # steps: ||  || init || ---- || * read summary file (gendata_summary.json); and validate against cache || * if no cache \\/ summary file.  delete any spurious files.  Create. || * Validate existing files (md5sum). ||  ||  || sync || ---- || * check directory for any recent files. || * read new data; and preprocessed into numpy arrays (as generator) || * append numpy data to cache || * update the summary ||  ||  || create an indexer || ----------------- || * specify from buckets || * init: how to do this?  Should be a bunch of ranges; I guess. || * resample_data\\/validation_data() both create a chunk indexer || * what about weightings?  Future step. ||  ||  || generator || --------- || * bcolz generator.  yields batches. ||  || * inputs: ||   * cache & chunk indexer ||  || * evaluation speed tests ||  ||  || callbacks || --------- || * before each epoch.  Idea is to keep epochs small (1 million) ||  ||  ||  ||  ||  || missing from train.py: ||  ||  ||     def verify_samples(self; sm): ||         # create a basestate ||         basestate = sm.new_base_state() ||  ||         counters = [Counter(); Counter()] ||         max_values = [{}; {}] ||         min_values = [{}; {}] ||         for s in self.samples: ||             basestate.from_list(decode_state(s.state)) ||             sm.update_bases(basestate) ||  ||             # get legals... ||             for ri in range(2): ||                 ls = sm.get_legal_state(ri) ||                 policy = s.policies[ri] ||                 for legal in ls.to_list(): ||                     found = False ||                     for ll; pp in policy: ||                         if ll == legal: ||                             max_values[ri][legal] = max(max_values[ri].get(legal; -1); pp) ||                             min_values[ri][legal] = min(max_values[ri].get(legal; 2); pp) ||                             found = True ||                             break ||                     assert found ||                     counters[ri][legal] += 1 ||  ||  ||  ||  ||  ||     def debug(self): ||         # good to see some outputs ||         for x in (10; 420; 42): ||             log.info('train input; shape: %s.  Example: %s' % (self.inputs.shape; self.inputs[x])) ||             for o in self.outputs: ||                 log.info('train output; shape: %s.  Example: %s' % (o.shape; o[x])) ||  ||  || # XXX add tests || class Buckets(object): ||     def __init__(self; bucket_def): ||         self.bucket_def = bucket_def ||  ||     def get(self; depth; max_depth): ||         if not self.bucket_def: ||             return 1.0 ||  ||         for idx; (cut_off; pct) in enumerate(self.bucket_def): ||             if cut_off <= 0: ||                 return self.get2(depth; max_depth; self.bucket_def[idx:]) ||  ||             if depth < cut_off: ||                 return pct ||  ||     def get2(self; depth; max_depth; stripped_def): ||         assert len(stripped_def) == 1 ||         return stripped_def[0][1] ||  ||  || '''"""
"b'\\""\\""\\""Problem definitions for Allen Brain Atlas problems. ||  || Notes: ||  ||   * TODO(cwbeitel): Want to be able to increase up-sampling ratio and\\/or ||     in-paint fraction over the course of training. This could be done by ||     defining a range of problems or perhaps more aptly with an hparam ||     that is dialed up depending on training performance. ||  || \\""\\""\\""'"
"b'TODO: Do stuff with \\""remainder\\"" training data'"
b'TODO: uncomment to train on all data'
b'TODO: kg_vector for training'
b'TODO: remove to add kg_vector for training'
b'TODO: apply constrain on training set size'
b'TODO: support integer; category; and basic scipy.optimize constraints'
b'todo training on the first graph only!'
b'TODO: handle each of ModeKeys.{EVAL;TRAIN;PREDICT}'
b'TODO: Deprecated; Update with tf.train.MonitoredTrainingSession'
b'TODO: Darknet region training includes extra coordinate loss for early'
b'TODO: train step makes cross_entropy NAN'
b'TODO: train step makes cross_entropy NAN'
b'TODO implement resuming a training'
b'TODO does the imported retrain function take this path?'
b'TODO: maybe we should use arc_pred sometimes in training??'
b'TODO Check constraint algorithms + optimise'
b'TODO Maybe switch to using predicted arcs towards end of training'
b'TODO: I think this checking should be removed (already checked in trainer init)'
b'Needs to restore the other hyperparameters\\/states for training; (TODO xinlei) I have'
b'TODO: codeup a while loop - dry iterations (non training). or may be have a separate'
b'TODO: for compatibility reason; remove once we retrain'
"b'TODO fix Delta.arg_constraints[\\""v\\""] to be a'"
"b'TODO fix Dirichlet.arg_constraints[\\""concentration\\""] to be a'"
"b'TODO fix DirichletMultinomial.arg_constraints[\\""concentration\\""] to be a'"
b'TODO fix LowRankMultivariateNormal.arg_constraints upstream'
b'TODO add temperature to RelaxedBernoulli.arg_constraints upstream'
b'TODO: Change this to per_gpu_train_batch_size'
"b'\\""\\""\\"" || What\'s the best way to develop a new pretraining script? ||  || Dynamic masking straight from text. || Abtract out the gradient accumulation functionality. Tracking loss; acc variables within the accumulator rather than outside. || Incorporate the new transformers version. Be willing to lose my current work. ||  || # TODO: Should we include special tokens? <BOS>; <EOS>. || # TODO: Weight sharing between generator and discriminator; only token embeddings. ||  || \\""\\""\\""'"
"b'\\""\\""\\"" || Batch sizes: 32 = 5GB memory; 128 = 17GB ||  || The \\""read -1 expected ...\\"" errors are harmless and come from Docker. See https:\\/\\/github.com\\/horovod\\/horovod\\/issues\\/503 || Running Docker in privileged mode (docker run --privileged) solves the issue. ||  || Dataset handling: Lots of empty lines; use dataset.filter() to eliminate those. || For now; just grab one sentence. || TODO: Combine two segments into a single example. https:\\/\\/github.com\\/google-research\\/electra\\/blob\\/master\\/build_pretraining_dataset.py || TODO: Add zero-padding for shorter sequences ||  || nlp feature request: Select from dataset with arbitrary slices || `nlp` package tutorial: https:\\/\\/colab.research.google.com\\/github\\/huggingface\\/nlp\\/blob\\/master\\/notebooks\\/Overview.ipynb || \\""\\""\\""'"
b'TODO: Limit code duplication between train_step and val_step.'
b'todo: make this script capable of training and annotating corpora'
b'(TODO): Perhaps compress the training files after pasting them together?'
"b'\\""\\""\\"" || class GQCNNTrainingProgress(object): ||     def __init__(self; total_epochs): ||         self._training_status = GQCNNTrainingStatus.NOT_STARTED ||         self._epoch = np.nan ||         self._total_epochs = total_epochs || #        self._train_error = np.nan || #        self._val_error = np.nan || #        self._train_loss = np.nan || #        self._val_loss = np.nan ||  ||     @property ||     def training_status(self): ||         return self._training_status ||  ||     @property ||     def epoch(self): ||         return self._epoch ||  ||     @property ||     def total_epochs(self): ||         return self._total_epochs ||  ||     @training_status.setter ||     def training_status(self; status): ||         assert status in GQCNNTrainingStatus.__dict__.keys(); \'Invalid training status \\""{}\\""\'.format(status) #TODO: @Vishal this is kind of jank but still works ||         self._training_status = training_status ||  ||     @epoch.setter ||     def epoch(self; epoch): ||         self._epoch = epoch || \\""\\""\\""'"
b'TODO (Neil): Enable both train and validation'
b'TODO: support training mode?'
b'TODO: need more arguments for full training'
b'TODO Reconsider the place of these splits. Perhaps train\\/dev\\/test'
b'TODO Probably should be hardcoding the list of train\\/dev\\/test utterances'
b'TODO Perhaps the ReadyCorpus train_prefixes variable should be a'
b'TODO This logic should be changed. The number of training instances'
b'# FIXME: need standard format for train\\/test\\/inputs\\/targets'
b'# FIXME: combine results from train and test'
"b""TODO: Extend to multifidelity problems by adding training_pts = {'approx': {}}"""
"b'\\""\\""\\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||  || Some functions are copied from gaussian_process submodule (Scikit-learn 0.14) ||  || TODO: || - Add additional points GEKPLS1; GEKPLS2 and so on ||  || - define outputs[\'sol\'] = self.sol ||  || - debug _train: self_pkl = pickle.dumps(obj) ||                            cPickle.PicklingError: Can\'t pickle <type \'function\'>: attribute lookup __builtin__.function failed ||  || \\""\\""\\""'"
"b'\\""\\""\\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||  || Some functions are copied from gaussian_process submodule (Scikit-learn 0.14) ||  || TODO: || - define outputs[\'sol\'] = self.sol ||  || - debug _train: self_pkl = pickle.dumps(obj) ||                            cPickle.PicklingError: Can\'t pickle <type \'function\'>: attribute lookup __builtin__.function failed ||  || \\""\\""\\""'"
"b'\\""\\""\\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||  || Some functions are copied from gaussian_process submodule (Scikit-learn 0.14) ||  || TODO: || - fail_iteration and nb_iter_max to remove from options || - define outputs[\'sol\'] = self.sol ||  || - debug _train: self_pkl = pickle.dumps(obj) ||                            cPickle.PicklingError: Can\'t pickle <type \'function\'>: attribute lookup __builtin__.function failed ||  || \\""\\""\\""'"
"b""TODO: Extend to multifidelity problems by adding training_points = {'approx': {}}"""
b'TODO -- could use BFGS for this (unconstrained) optimization as well -- everytime for min of mean'
b'TODO: save trained strategy on disk'
b'TODO: Add training commands'
b'TODO: Add support for training'
"b""TODO: Constraints: 3-128 alphanumeric characters; parentheses (()); square brackets ([]); spaces ( ); periods (.); slashes (\\/); dashes (-); single quotes ('); at-signs (@); or underscores(_)"""
b'TODO: add mlm back to pretrain'
b'TODO weights = tf.mul(train_labels; class_weight)'
b'TODO Build trainer class'
b'TODO implement multi-gpu training and compare performance'
b'TODO: Add student training test code.'
b'3. transform to train\\/valid data to standardized format #TODO change to multi-processing version for train'
b'TODO(jerry): Implement training resume'
b'TODO: Allow providing separate train_input; train_target dataframes; or the full df'
b'TODO add a pretrained model?'
b'TODO: Create a random minibatch of training data and labels; storing  #'
b'TODO: note this is the opposite of train_miccai and it might be confusing.'
b'TODO: support evaluation on training split'
b'TODO: refactor forward_train in two stage to reduce code redundancy'
"b'TODO: I think this should be a \\""sampler\\"" class and moved to training.py. To keep this file generic-sampling.'"
b'TODO: Move config in train\\/test cfg.'
b'TODO: Merge with same in trainSessionParams'
b'todo need load vocabulary of tokens from pretrain; but labels from real task.'
b'from model.bert_model import BertModel # TODO TODO TODO test whether pretrain can boost perofrmance with other model'
"b'\\""\\""\\""Data augmentation functionality. Passed as callable transformations to || Dataset classes. ||  || The data augmentation procedures were interpreted from @weiliu89\'s SSD paper || http:\\/\\/arxiv.org\\/abs\\/1512.02325 ||  || TODO: explore https:\\/\\/github.com\\/ncullen93\\/torchsample\\/blob\\/master\\/torchsample\\/transforms ||     for any useful tranformations || TODO: implement data_augment for training ||  || Ellis Brown || \\""\\""\\""'"
b'TODO: For full training; put preprocessing inside training loop.'
b'TODO: implement passing of SVMlight parameters from train() to learn()'
b'TODO: Make orthographic heuristic less susceptible to overtraining'
"b'TODO check \\""Tips for mask refinement (optional after >15k iters)\\"" => https:\\/\\/render.githubusercontent.com\\/view\\/ipynb?commit=87d6e7a28ce754acd38d885367b6ceb0be92ec54&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7368616f616e6c752f66616365737761702d47414e2f383764366537613238636537353461636433386438383533363762366365623062653932656335342f46616365537761705f47414e5f76325f737a3132385f747261696e2e6970796e62&nwo=shaoanlu%2Ffaceswap-GAN&path=FaceSwap_GAN_v2_sz128_train.ipynb&repository_id=115182783&repository_type=Repository#Tips-for-mask-refinement-(optional-after-%3E15k-iters)'"
b'TODO: Parallel this part to make it train faster'
b'TODO: Try different dropout schemes. On the small training set; every kind of dropout'
b'TODO: If plotting; self.plot_train will be empty'
b'FIXME this does not train for some reason'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || # TODO(sguada) docstring paragraph by (a) motivating the need for the file and || # (b) defining clones. ||  || # TODO(sguada) describe the high-level components of model deployment. || # E.g. \\""each model deployment is composed of several parts: a DeploymentConfig; || # which captures A; B and C; an input_fn which loads data.. etc ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||     g = tf.Graph() ||  ||     # Set up DeploymentConfig ||     config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||     # Create the global step on the device storing the variables. ||     with tf.device(config.variables_device()): ||         global_step = slim.create_global_step() ||  ||     # Define the inputs ||     with tf.device(config.inputs_device()): ||         images; labels = LoadData(...) ||         inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||     # Define the optimizer. ||     with tf.device(config.optimizer_device()): ||         optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||     # Define the model including the loss. ||     def model_fn(inputs_queue): ||         images; labels = inputs_queue.dequeue() ||         predictions = CreateNetwork(images) ||         slim.losses.log_loss(predictions; labels) ||  ||     model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                    optimizer=optimizer) ||  ||     # Run training. ||     slim.learning.train(model_dp.train_op; my_log_dir; ||                                             summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||     * outputs: The return values of the calls to `model_fn()`. ||     * scope: The scope used to create the clone. ||     * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||     * train_op: An operation that run the optimizer training op and include ||         all the update ops created by `model_fn`. Present only if an optimizer ||         was specified. ||     * summary_op: An operation that run the summaries created by `model_fn` ||         and process_gradients. ||     * total_loss: A `Tensor` that contains the sum of all losses created by ||         `model_fn` plus the regularization losses. ||     * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||     * num_clones: Number of model clones to deploy in each replica. ||     * clone_on_cpu: True if clones should be placed on CPU. ||     * replica_id: Integer.  Index of the replica for which the model is ||             deployed.  Usually 0 for the chief replica. ||     * num_replicas: Number of replicas to use. ||     * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||     * worker_job_name: A name for the worker job. ||     * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||     - describe side effect to the graph. ||     - what happens to summaries and update_ops. ||     - which graph collections are altered. ||     - write a tutorial on how to use this. ||     - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
b'TODO add a field _train; _test ; _dev in the unified dataset'
b'TODO: Rewrite this function to match inputs_train().'
b'TODO train.txt'
b'TODO Wrapper for all used dataset wrappers; that creates the train.txt; test.txt; dev.txt'
b'TODO Acquire train data.'
b'tf.train.NanTensorHook(loss); TODO fix'
b'TODO: Removed for now. Complete training first.'
b'tf.train.NanTensorHook(loss); TODO fix'
b'TODO: Known issue: Item coverage here is not considering as recommendable items those who were not in the train set'
b'FIXME for fast training. when it comes to service; comment out'
b'TODO: Save results for this classifier\\/trainingset in database'
"b""FIXME: Enforce this for META only. The problem is the TrainingSet class; which doesn't know about which classifier is running it"""
b'ToDo: Stop if details indicate that training failed.'
b'TODO: Implement grid search training'
b'Todo: combine training'
b'TODO: this is bad solution to resume the training'
b'TODO: Verify that we need to split into training and validation or into inputs and expected_outputs.'
b'@todo: not sure whether it is absoluately necessary in training.'
b'TODO: change n_entity to n_train_entity and n_unseen_entity;'
b'TODO: Change to tf.contrib.training.bucket_by_sequence_length'
b'TODO: Specify also the weights if pre-trained'
b'TODO: Make a line that adds a point at each trained batch (Or percentage being updated)'
b'TODO: better to use trainable=False?'
b'g.load(sess; self.save_dir; ckpt_name)  # TODO: use previously trained gan'
b'TODO: add self-trained cartoongan: MODE'
b'TODO: adversarial training code'
b'TODO: implement parameter constraints'
"b""tmp.set_state(abatch.get('train')) # TODO: fix"""
b'TODO: remove special constraint for Bernoulli case'
b'TODO: re-implement support for constraint satisfaction method'
b'TODO: re-implement support for constraint satisfaction method as needed'
b'TODO: Darknet region training includes extra coordinate loss for early'
b'todo: For these operations it is impossible to guess the size and all constrains on the matrix'
b'todo: For these expectations it is impossible to guess the size and all constrains on the matrix'
b'TODO implement train_set_mask! Currently BROKEN.'
b'TODO implement train_set_mask!'
b'TODO implement train_test split'
b'TODO use self.X_train_norm_squared_'
b'TODO: Fix the train generator code'
b'TODO dynamic decode defined scope here! train has to do this too'
b'compute a metric for training set (TODO: change to validation)'
b'TODO: retrain for -1 fold'
b'todo include training data into measures'
b'TODO: replace get_trainign data by get using the training data name'
"b'\\""\\""\\""Deploy Slim models across multiple clones and replicas. ||  || To easily train a model on multiple GPUs or across multiple machines this || module provides a set of helper functions: `create_clones`; || `optimize_clones` and `deploy`. ||  || Usage: ||  ||   g = tf.Graph() ||  ||   # Set up DeploymentConfig ||   config = model_deploy.DeploymentConfig(num_clones=2; clone_on_cpu=True) ||  ||   # Create the global step on the device storing the variables. ||   with tf.device(config.variables_device()): ||     global_step = slim.create_global_step() ||  ||   # Define the inputs ||   with tf.device(config.inputs_device()): ||     images; labels = LoadData(...) ||     inputs_queue = slim.data.prefetch_queue((images; labels)) ||  ||   # Define the optimizer. ||   with tf.device(config.optimizer_device()): ||     optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate; FLAGS.momentum) ||  ||   # Define the model including the loss. ||   def model_fn(inputs_queue): ||     images; labels = inputs_queue.dequeue() ||     predictions = CreateNetwork(images) ||     slim.losses.log_loss(predictions; labels) ||  ||   model_dp = model_deploy.deploy(config; model_fn; [inputs_queue]; ||                                  optimizer=optimizer) ||  ||   # Run training. ||   slim.learning.train(model_dp.train_op; my_log_dir; ||                       summary_op=model_dp.summary_op) ||  || The Clone namedtuple holds together the values associated with each call to || model_fn: ||   * outputs: The return values of the calls to `model_fn()`. ||   * scope: The scope used to create the clone. ||   * device: The device used to create the clone. ||  || DeployedModel namedtuple; holds together the values needed to train multiple || clones: ||   * train_op: An operation that run the optimizer training op and include ||     all the update ops created by `model_fn`. Present only if an optimizer ||     was specified. ||   * summary_op: An operation that run the summaries created by `model_fn` ||     and process_gradients. ||   * total_loss: A `Tensor` that contains the sum of all losses created by ||     `model_fn` plus the regularization losses. ||   * clones: List of `Clone` tuples returned by `create_clones()`. ||  || DeploymentConfig parameters: ||   * num_clones: Number of model clones to deploy in each replica. ||   * clone_on_cpu: True if clones should be placed on CPU. ||   * replica_id: Integer.  Index of the replica for which the model is ||       deployed.  Usually 0 for the chief replica. ||   * num_replicas: Number of replicas to use. ||   * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas. ||   * worker_job_name: A name for the worker job. ||   * ps_job_name: A name for the parameter server job. ||  || TODO(sguada): ||   - describe side effect to the graph. ||   - what happens to summaries and update_ops. ||   - which graph collections are altered. ||   - write a tutorial on how to use this. ||   - analyze the possibility of calling deploy more than once. ||  ||  || \\""\\""\\""'"
b'TODO: compare trained and enrolled values?'
b'# TODO: do we want gains\\/biases to be trainable?'
b'TODO: should we disable training on connections to learning'
b'TODO: why does training fail if we probe out instead of out.neurons?'
b'TODO: remove this hack after we re-train w2v without OOV rows'
b'TODO: is it useful? How to delimitate train & test dataset?'
b'Keep only the folders that contain validation.csv and training.csv TODO: Why?'
b'FIXME: color mapping scheme is hardcoded for now because of memory constraint; To be fixed.'
b'TODO: return the result of train_and_evaluate.'
b'TODO: Decoder training stream mask!'
b'TODO: make sparse layer respond to train'
b'TODO (johngiorgi): read up on train_test_split; do I want to shuffle?'
b'TODO (johngiorgi): the way I get train\\/test partitions is likely copying'
b'TODO (johngiorgi): begin writing tests; start with _split_train_valid'
b'assert train_size == (64*64*3) + self.num_pose_vars + 1 + self.num_options; #KDK TODO'
b'TODO(ahundt) it seems set_trainable_layers in grasp_model.py has a bug?'
b'TODO(rishabhagarwal): Hack for loading a model trained on cloud machine.'
b'TODO(tfish): Improve handling of known linear constraints between'
b'TODO: this creates a problem for pretrained vecs; as Guillaume noted'
"b'\\""\\""\\"" || Implementation of \\""Training RNNs as Fast as CNNs\\"". || TODO: turn to pytorch\'s implementation when it is available. ||  || This implementation is adpoted from the author of the paper: || https:\\/\\/github.com\\/taolei87\\/sru\\/blob\\/master\\/cuda_functional.py. || \\""\\""\\""'"
b'TODO: Edge case? Currently this is handled by flooring the number of training\\/testing samples'
b'train_writer.add_summary(summary; step)  # todo tf2: delete following to clean up after TF2'
b'todo: tf2 to be removed #train_helper;'
b'tf.train.AdagradDAOptimizer  todo appears tf.keras.optimizers does not support'
b'tf.train.MomentumOptimizer  todo appears tf.keras.optimizers does not support'
b'tf.train.ProximalGradientDescentOptimizer todo appears tf.keras.optimizers does not support'
b'tf.train.ProximalAdagradOptimizer todo appears tf.keras.optimizers does not support'
b'train_sampler;  # todo: tf2 to be removed #train_helper;'
b'TODO: use `constraint_to` inside `pyro.param(...)` when available'
b'TODO consider returing constrained'
b'TODO implement constraints.sphere or similar'
b'TODO: change corr_cholesky_constraint to corr_cholesky when the latter is availabler'
b'TODO: just a hack for now; but eventually opcode will be different in i_mvm and i_train'
b'TODO output training time'
"b""TODO: do we have to re-compute batch size here so it'll work w\\/ both validation and training?"""
"b""TODO: this'll throw an error when using training data tho..."""
b'if not isinstance(optimizer; tf.train.Optimizer): #TODO uh this fails'
b'TODO: ygao20130130 relax constraint by comment out following; see if it is ok'
b'# TODO: train and benchmark against Parsey'
b'TODO: Split training data into validation'
b'TODO: Train on harmony and style'
b'FIXME: Training hyperparameters'
b'TODO: MaxPool constraints'
b'TODO: the y_train should be given us externally; so far we create it as random values'
"b'\\""\\""\\""TODO: Docstring for setup_training.'"
b'token_ids = [torch.LongTensor(self.spm.SampleEncodeAsIds(sentence.to_original_text(); self.length; self.alpha[self.training])) for sentence in sentences]  # TODO: expose these params; we want this to be random in training; but fixed in inference'
b'TODO how do we validate this happens before train\\/test split? Or do we need to? Can we implement it in the'
b'TODO      simple trainer in the correct order and leave this to advanced users?'
b'TODO how do we validate this happens before train\\/test split? Or do we need to? Can we implement it in the'
b'TODO      simple trainer in the correct order and leave this to advanced users?'
b'Pete Todo: separate train\\/val?'
b'TODO: code for training; experience replay; storing data to a database'
b'TODO merge it with train_wd.py'
b'TODO: maybe we should log the indices of episodes used to train ?'
"b""FIXME: don't retrain if there was only one fold"""
b'TODO(rbharath): This training is currently broken w.r.t minibatches! Fix.'
"b'FIXME: Signature of \\""train_valid_test_split\\"" incompatible with supertype \\""Splitter\\""'"
b'TODO: training not yet supported'
b'TODO Is there a better way to differentiate between train and test points?'
b'TODO: determine how to use quick methods that require train and test data.'
b'TODO: move this into Trainer class'
b'TODO: in pyannote.audio.train.model'
b'@TODO: better solution with train\\/inference handling ?'
b'@TODO: add registry for algorithms; trainers; samplers'
b'@TODO: better solution with train\\/inference handling ?'
b'todo: should implement different training steps'
b'dep_constraints = bdb.sql TODO'
b'TODO: Save params\\/results ? or already inside training args ?'
b'TODO JRK: test GAT with non-exhaustive CV (eg. train on 80%; test on 10%)'
b'TODO (pradeep): Make the distinction between the two kinds of trainers in the way they'
b'TODO: distributed training and 16-bits training (FP16)'
"b""logging.info('Pre-training on 1 sample.')   # TODO Confirm if needed"""
b'FIXME This makes bind_trainer in register_callback reduntant;'
b'TODO implement function to load a pretrained unet'
b'TODO: revise kwarg trilist in method constrain_mask_to_landmarks;'
b'TODO: repeated code from Builder. Should builder and Trainer have a'
b'TODO: include this into the NMT training part'
"b""sample_probability = (20 + self.epoch_index) \\/ self.config_args['num_epochs']  # TODO: include this into the NMT training part"""
"b""logging.info('Pre-training on 1 sample.')   # TODO Confirm if needed"""
b'TODO(Yada): Move logic for checkpointing finetuned vs frozen pretrained tasks'
"b""TODO: We don't want diagnostic tasks in train_task_names"""
b'TODO there is probably some elegant way to combine ConstrainedRidge and ConstrainedSVR'
b'@TODO: remove seed from param. See @TODO in constraints\\/chunks'
b'TODO: Check should trainable=True really be set here'
b'TODO: make training compatible with full net'
b'TODO: Refactor the run_train_translate function!'
b'TODO: Figure out a better way to set train_op_fn and optimizer'
b'TODO: supports for distributed training and evaluation.'
b'TODO (T36875783): load pretrained lm to score'
"b'\\""\\""\\"" Params: Latin ||  || TODO: Some of these are only used for training. PRAENOMINA for training punkt tokenizer (als ABBREVIATIONS; CALENDAR; MISC) || TODO: The enclitic exceptions (que_exceptions and below) can all be deleted ||  || \\""\\""\\""'"
b'TODO pretrain\\u7684embedding\\u662F\\u600E\\u4E48\\u89E3\\u51B3\\u7684\\uFF1F'
b'TODO add pretrain urls'
b'TODO why in the training we have this and here is flat without the if ?'
"b'\\""\\""\\""Script to train highres3dnet model. ||  || The input CSV must have two columns: ||     1. filepaths of features ||     2. filepaths of corresponding labels ||  || TODO || ---- || - Make this script more general. Ideally; one could drop in their model and ||     loss function. || - Move some common methods (eg; i\\/o) to dedicated modules. || - Dice coefficient for class 1 (brainmask) is sometimes NaN. || - Input of 1 * 128**3 is too large for 1080ti. This seems to be related to the ||     `input_fn` used. || - Remove pandas as a dependency. Make pure python reader that accepts CSV or ||     TSV as input. || \\""\\""\\""'"
b'TODO: add `K.in_train_phase`.'
b'TODO: Presets for training; prediction and evaluation'
b'todo: make auto split 80% train; 20% test (make this configurable; also random vs sequential) and save it to disk'
"b'raise ValueError(\\""Model is not persisted; so training must be performed\\"") # TODO is this true?'"
"b'\\""\\""\\""A script to randomly move files in a directory to a test; train and || validate folder. ||  || This script is intended to be used on projects where the data is made || up of multiple files e.g. images or email files. ||  || Usage: python3 split_data.py <directory> <file extension> ||  || TODO: Add a flag to sort data into sub-folders based on a prefix for file names || TODO: Make sure reset works for all flags || TODO: Modify script to work on a CSV file. In this case split the CSV file into multiple files under each folder. ||  || \\""\\""\\""'"
"b'\\""\\""\\"" visualise.py ||  || Visualises the output from training a classifier. ||  || Supports both binary and multi class classifiers. ||  || Use cases: ||  - Visualising the output from training a model ||  - Viewing the output from running batch predictions on a dataset ||  || TODO: Order confusion matrix by most popular class to least popular class || TODO: Output file format in HTML. Always print to the screen. || TODO: Visualisation function should be different from function the output metrics || TODO: Wrap in a Visualiser interface for use in Surround || TODO: Support multiple ground truth and prediction columns || TODO: Add flag to output file with incorrect records. True by default. || TODO: Rename module to visualise_classifier.py ||  || TODO: Add a flag to set probability thresholds || TODO: Add a flag that describes each aspect of the generated report in human readable terminology ||  || \\""\\""\\""'"
b'TODO:  Needs to be updated to use train loader'
b'TODO: add additional constraints in the future'
b'TODO: need to revisit this to be able to plot after training; interactive plotting is messing up'
b'TODO: give option to mirror train\\/target'
b'TODO maybe it was trained on the whole w2v?'
b'!! FIXME: tests in trainer.fast and trainer.brillorig are exact duplicates'
b'TODO(trax): Move to trainer.py. Only here because of t2t_trainer usage.'
b'TODO: maybe add testStepTrain (and possibly some other tests) from dopamine'
b'TODO: batching; send a set of sentences to the train_sentence_sg Cython method. Sum of sentence lengths should not exceed MAX_SENTENCE_LENGTH (probably just import this constant directly from word2vec_inner.pyx).'
"b""TODO: Get spaCy using Thinc's trainer and optimizer"""
b'TODO: verify if n_train is needed'
b'TODO perhaps k-fold is a better inner CV; which guarantees full use of training set with fewer repeats?'
b'self.update_temperature(adv_epoch; cfg.ADV_train_epoch)   # TODO: update parents temperature'
b'self.clas_data.reset(train_s)  # TODO: bug: have to reset'
b'TODO: optimize this; skip untrainable architecture at the beginning'
b'TODO: Check why the CUDA version does 3.7291 (train_nrmse32); 0.16 (test_mse32) and 3.42 (test_nrmse32)'
b'todo: if valid set if None; create it as random segment of the shuffled train set'
b'todo: if valid set is None; create it as random segment of the shuffled train set'
b'TODO: fix training part...'
b'todo: check duplicated tests against trainer_checks'
b'TODO: convert train_percent_check to limit_train_batches'
b'todo: IDE is complaining; these shall be initialized in the Trainer init at leas as placeholders'
b'TODO: Move this check to Trainer __init__ or device parser'
b'TODO: remove bool from Trainer.profiler param in v1.3.0; update profiler_connector.py'
b'TODO: How to start training in middle of epoch'
b'todo: add also `train_dataloader__multiple_sequence`'
b'todo: consider rename as `is_training`'
"b'TODO: the old setup is now called \\""pre_training\\""; where should this hook be called now?'"
b'TODO: connectors refactor: move callbacks list to connector and do not write Trainer state'
b'TODO: the rpc plugin should wrap trainer.save_checkpoint'
b'TODO: is there a better way than accessing trainer through model -> trainer?'
b'TODO: check for trainer reference'
b'TODO: unrolling function in theano; for training'
b'TODO: per step recurrence function in theano; for training'
b'TODO: Should id_train be used here?'
b'TODO also missing: index in AEB space; train_mode'
b'TODO Fix for training iters; docstring'
"b""TODO Fix for multi-episode training. Won't know where to delete after the first episode."""
b'TODO set to_train here'
b'TODO: relax this constraint'
b'#TODO stop training'
b'@@TODO: this should come from the trainer class as the current epoch number'
b'@@TODO: split the sample_folds and label_folds into sizes K-1 and 1 for test and training sets'
b'TODO: validate_json(train_data; schema)'
b'Load in pretrained weights - TODO test'
b'TODO: validate that [pretraining] block exists'
b'TODO: begin_training is not guaranteed to see all data \\/ labels ?'
b'FIXME: replace  with GaussianHMMMAPTrainer code?'
b'TODO: parallel training using joblib.'
b'FIXME: sample_weight must be split into training\\/validation data'
"b""TODO: define variables 'filenames_train' and 'filenames_test'"""
"b""TODO: define variables 'y_train' and 'y_test'"""
"b""TODO: define a variable named 'X_train'"""
b'TODO: define variables X_train; X_test; y_train; y_test by splitting the data'
b'TODO request that classifiers return classification of training sets when fitting'
"b""todo this won't work correctly when test_size > train_size"""
b'todo: run eval in parallel (i.e. at the same time as training?)'
b'todo: add flag to toggle loss comp in validation? (add to trainer config maybe?)'
b'TODO: add pretrained param to toggle loading weights from imagenet before applying task?'
b'TODO: 1. use better training parameters. 2. use consistant activation functions; 3. consider how to do this for hierarchical case'
b'TODO: change activation default to relu and implement weight constraint'
b'test #TODO: implement complementary testing to training set selection'
b'TODO: make sure we arent falling for any https:\\/\\/medium.com\\/@utk.is.here\\/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9'
"b'\\""\\""\\"" || ======================== || Variables (``variable``) || ======================== ||  || Data instances in Orange can contain several types of variables: || :ref:`discrete <discrete>`; :ref:`continuous <continuous>`; || :ref:`strings <string>`; and :ref:`Python <Python>` and types derived from it. || The latter represent arbitrary Python objects. || The names; types; values (where applicable); functions for computing the || variable value from values of other variables; and other properties of the || variables are stored in descriptor classes defined in this module. ||  || Variable descriptors || -------------------- ||  || Variable descriptors can be constructed either directly; using  || constructors and passing attributes as parameters; or by a  || factory function :func:`Orange.data.variable.make`; which either  || retrieves an existing descriptor or constructs a new one. ||  || .. class:: Variable ||  ||     An abstract base class for variable descriptors. ||  ||     .. attribute:: name ||  ||         The name of the variable. Variable names do not need to be unique since two ||         variables are considered the same only if they have the same descriptor ||         (e.g. even multiple variables in the same table can have the same name). ||         This should; however; be avoided since it may result in unpredictable ||         behavior. ||      ||     .. attribute:: var_type ||         ||         Variable type; it can be Orange.data.Type.Discrete; ||         Orange.data.Type.Continuous; Orange.data.Type.String or ||         Orange.data.Type.Other.   ||  ||     .. attribute:: get_value_from ||  ||         A function (an instance of :obj:`Orange.classification.Classifier`) which computes ||         a value of the variable from values of one or more other variables. This ||         is used; for instance; in discretization where the variables describing ||         the discretized variable are computed from the original variable.  ||  ||     .. attribute:: ordered ||      ||         A flag telling whether the values of a discrete variable are ordered. At ||         the moment; no built-in method treats ordinal variables differently than ||         nominal ones. ||      ||     .. attribute:: distributed ||      ||         A flag telling whether the values of the variables are distributions. ||         As for the flag ordered; no methods treat such variables in any special ||         manner. ||      ||     .. attribute:: random_generator ||      ||         A local random number generator used by method ||         :obj:`Variable.random_value`. ||      ||     .. attribute:: default_meta_id ||      ||         A proposed (but not guaranteed) meta id to be used for that variable. ||         This is used; for instance; by the data loader for tab-delimited file ||         format instead of assigning an arbitrary new value; or by ||         :obj:`Orange.data.new_meta_id` if the variable is passed as an argument.  ||          ||     .. attribute:: attributes ||          ||         A dictionary which allows the user to store additional information ||         about the variable. All values should be strings. See the section  ||         about :ref:`storing additional information <attributes>`. ||  ||     .. method:: __call__(obj) ||      ||            Convert a string; number; or other suitable object into a variable ||            value. ||             ||            :param obj: An object to be converted into a variable value ||            :type o: any suitable ||            :rtype: :class:`Orange.data.Value` ||         ||     .. method:: randomvalue() ||  ||            Return a random value for the variable. ||         ||            :rtype: :class:`Orange.data.Value` ||         ||     .. method:: compute_value(inst) ||  ||            Compute the value of the variable given the instance by calling ||            obj:`~Variable.get_value_from` through a mechanism that prevents deadlocks by ||            circular calls. ||  ||            :rtype: :class:`Orange.data.Value` ||  || .. _discrete: || .. class:: Discrete ||  ||     Bases: :class:`Variable` ||     ||     Descriptor for discrete variables. ||      ||     .. attribute:: values ||      ||         A list with symbolic names for variables\' values. Values are stored as ||         indices referring to this list. Therefore; modifying this list  ||         instantly changes the (symbolic) names of values as they are printed out or ||         referred to by user. ||      ||         .. note:: ||          ||             The size of the list is also used to indicate the number of ||             possible values for this variable. Changing the size - especially ||             shrinking the list - can have disastrous effects and is therefore not ||             really recommended. Also; do not add values to the list by ||             calling its append or extend method: call the :obj:`add_value` ||             method instead. ||  ||             It is also assumed that this attribute is always defined (but can ||             be empty); so never set it to None. ||      ||     .. attribute:: base_value ||  ||             Stores the base value for the variable as an index in `values`. ||             This can be; for instance; a \\""normal\\"" value; such as \\""no ||             complications\\"" as opposed to abnormal \\""low blood pressure\\"". The ||             base value is used by certain statistics; continuization etc. ||             potentially; learning algorithms. The default is -1 which means that ||             there is no base value. ||      ||     .. method:: add_value ||      ||             Add a value to values. Always call this function instead of ||             appending to values. ||  || .. _continuous: || .. class:: Continuous ||  ||     Bases: :class:`Variable` ||  ||     Descriptor for continuous variables. ||      ||     .. attribute:: number_of_decimals ||      ||         The number of decimals used when the value is printed out; converted to ||         a string or saved to a file. ||      ||     .. attribute:: scientific_format ||      ||         If ``True``; the value is printed in scientific format whenever it ||         would have more than 5 digits. In this case; :obj:`number_of_decimals` is ||         ignored. ||  ||     .. attribute:: adjust_decimals ||      ||         Tells Orange to monitor the number of decimals when the value is ||         converted from a string (when the values are read from a file or ||         converted by; e.g. ``inst[0]=\\""3.14\\""``):  ||         0: the number of decimals is not adjusted automatically; ||         1: the number of decimals is (and has already) been adjusted; ||         2: automatic adjustment is enabled; but no values have been converted yet. ||  ||         By default; adjustment of the number of decimals goes as follows: ||      ||         If the variable was constructed when data was read from a file; it will  ||         be printed with the same number of decimals as the largest number of  ||         decimals encountered in the file. If scientific notation occurs in the  ||         file; :obj:`scientific_format` will be set to ``True`` and scientific format  ||         will be used for values too large or too small.  ||      ||         If the variable is created in a script; it will have; by default; three ||         decimal places. This can be changed either by setting the value ||         from a string (e.g. ``inst[0]=\\""3.14\\""``; but not ``inst[0]=3.14``) or by ||         manually setting the :obj:`number_of_decimals`. ||  ||     .. attribute:: start_value; end_value; step_value ||      ||         The range used for :obj:`randomvalue`. ||  || .. _String: || .. class:: String ||  ||     Bases: :class:`Variable` ||  ||     Descriptor for variables that contain strings. No method can use them for  ||     learning; some will complain and others will silently ignore them when they  ||     encounter them. They can be; however; useful for meta-attributes; if  ||     instances in a dataset have unique IDs; the most efficient way to store them  ||     is to read them as meta-attributes. In general; never use discrete  ||     attributes with many (say; more than 50) values. Such attributes are  ||     probably not of any use for learning and should be stored as string ||     attributes. ||  ||     When converting strings into values and back; empty strings are treated  ||     differently than usual. For other types; an empty string can be used to ||     denote undefined values; while :obj:`String` will take empty strings ||     as empty strings -- except when loading or saving into file. ||     Empty strings in files are interpreted as undefined; to specify an empty ||     string; enclose the string in double quotes; these are removed when the ||     string is loaded. ||  || .. _Python: || .. class:: Python ||  ||     Bases: :class:`Variable` ||  ||     Base class for descriptors defined in Python. It is fully functional ||     and can be used as a descriptor for attributes that contain arbitrary Python ||     values. Since this is an advanced topic; PythonVariables are described on a  ||     separate page. !!TODO!! ||      ||      || Variables computed from other variables || --------------------------------------- ||  || Values of variables are often computed from other variables; such as in || discretization. The mechanism described below usually functions behind the scenes; || so understanding it is required only for implementing specific transformations. ||  || Monk 1 is a well-known dataset with target concept ``y := a==b or e==1``. || It can help the learning algorithm if the four-valued attribute ``e`` is || replaced with a binary attribute having values `\\""1\\""` and `\\""not 1\\""`. The || new variable will be computed from the old one on the fly.  ||  || .. literalinclude:: code\\/variable-get_value_from.py ||     :lines: 7-17 ||      || The new variable is named ``e2``; we define it with a descriptor of type  || :obj:`Discrete`; with appropriate name and values ``\\""not 1\\""`` and ``1`` (we  || chose this order so that the ``not 1``\'s index is ``0``; which can be; if  || needed; interpreted as ``False``). Finally; we tell e2 to use  || ``checkE`` to compute its value when needed; by assigning ``checkE`` to  || ``e2.get_value_from``.  ||  || ``checkE`` is a function that is passed an instance and another argument we  || do not care about here. If the instance\'s ``e`` equals ``1``; the function  || returns value ``1``; otherwise it returns ``not 1``. Both are returned as  || values; not plain strings. ||  || In most circumstances the value of ``e2`` can be computed on the fly - we can  || pretend that the variable exists in the data; although it does not (but  || can be computed from it). For instance; we can compute the information gain of || variable ``e2`` or its distribution without actually constructing data containing || the new variable. ||  || .. literalinclude:: code\\/variable-get_value_from.py ||     :lines: 19-22 ||  || There are methods which cannot compute values on the fly because it would be || too complex or time consuming. In such cases; the data need to be converted || to a new :obj:`Orange.data.Table`:: ||  ||     new_domain = Orange.data.Domain([data.domain[\\""a\\""]; data.domain[\\""b\\""]; e2; data.domain.class_var]) ||     new_data = Orange.data.Table(new_domain; data)  ||  || Automatic computation is useful when the data is split into training and  || testing examples. Training instances can be modified by adding; removing  || and transforming variables (in a typical setup; continuous variables  || are discretized prior to learning; therefore the original variables are  || replaced by new ones). Test instances; on the other hand; are left as they  || are. When they are classified; the classifier automatically converts the  || testing instances into the new domain; which includes recomputation of  || transformed variables.  ||  || .. literalinclude:: code\\/variable-get_value_from.py ||     :lines: 24- ||  || .. _attributes: ||  || Storing additional variables || ----------------------------- ||  || All variables have a field :obj:`~Variable.attributes`; a dictionary || which can contain strings. Although the current implementation allows all || types of value we strongly advise to use only strings. An example: ||  || .. literalinclude:: code\\/attributes.py ||  || These attributes can only be saved to a .tab file. They are listed in the || third line in <name>=<value> format; after other attribute specifications || (such as \\""meta\\"" or \\""class\\""); and are separated by spaces.  ||  || .. _variable_descriptor_reuse: ||  || Reuse of descriptors || -------------------- ||  || There are situations when variable descriptors need to be reused. Typically; the  || user loads some training examples; trains a classifier; and then loads a separate || test set. For the classifier to recognize the variables in the second data set; || the descriptors; not just the names; need to be the same.  ||  || When constructing new descriptors for data read from a file or during unpickling; || Orange checks whether an appropriate descriptor (with the same name and; in case || of discrete variables; also values) already exists and reuses it. When new || descriptors are constructed by explicitly calling the above constructors; this || always creates new descriptors and thus new variables; although a variable with || the same name may already exist. ||  || The search for an existing variable is based on four attributes: the variable\'s name; || type; ordered values; and unordered values. As for the latter two; the values can  || be explicitly ordered by the user; e.g. in the second line of the tab-delimited  || file. For instance; sizes can be ordered as small; medium; or big. ||  || The search for existing variables can end with one of the following statuses. ||  || .. data:: Orange.data.variable.MakeStatus.NotFound (4) ||  ||     The variable with that name and type does not exist.  ||  || .. data:: Orange.data.variable.MakeStatus.Incompatible (3) ||  ||     There are variables with matching name and type; but their ||     values are incompatible with the prescribed ordered values. For example; ||     if the existing variable already has values [\\""a\\""; \\""b\\""] and the new one ||     wants [\\""b\\""; \\""a\\""]; the old variable cannot be reused. The existing list can; ||     however be appended with the new values; so searching for [\\""a\\""; \\""b\\""; \\""c\\""] would ||     succeed. Likewise a search for [\\""a\\""] would be successful; since the extra existing value ||     does not matter. The formal rule is thus that the values are compatible iff ``existing_values[:len(ordered_values)] == ordered_values[:len(existing_values)]``. ||  || .. data:: Orange.data.variable.MakeStatus.NoRecognizedValues (2) ||  ||     There is a matching variable; yet it has none of the values that the new ||     variable will have (this is obviously possible only if the new variable has ||     no prescribed ordered values). For instance; we search for a variable ||     \\""sex\\"" with values \\""male\\"" and \\""female\\""; while there is a variable of the same  ||     name with values \\""M\\"" and \\""F\\"" (or; well; \\""no\\"" and \\""yes\\"" :). Reuse of this  ||     variable is possible; though this should probably be a new variable since it  ||     obviously comes from a different data set. If we do decide to reuse the variable; the  ||     old variable will get some unneeded new values and the new one will inherit  ||     some from the old. ||  || .. data:: Orange.data.variable.MakeStatus.MissingValues (1) ||  ||     There is a matching variable with some of the values that the new one  ||     requires; but some values are missing. This situation is neither uncommon  ||     nor suspicious: in case of separate training and testing data sets there may ||     be values which occur in one set but not in the other. ||  || .. data:: Orange.data.variable.MakeStatus.OK (0) ||  ||     There is a perfect match which contains all the prescribed values in the ||     correct order. The existing variable may have some extra values; though. ||  || Continuous variables can obviously have only two statuses;  || :obj:`~Orange.data.variable.MakeStatus.NotFound` or :obj:`~Orange.data.variable.MakeStatus.OK`. ||  || When loading the data using :obj:`Orange.data.Table`; Orange takes the safest  || approach and; by default; reuses everything that is compatible up to  || and including :obj:`~Orange.data.variable.MakeStatus.NoRecognizedValues`. Unintended reuse would be obvious from the || variable having too many values; which the user can notice and fix. More on that  || in the page on `loading data`. !!TODO!! ||  || There are two functions for reusing the variables instead of creating new ones. ||  || .. function:: Orange.data.variable.make(name; type; ordered_values; unordered_values[; create_new_on]) ||  ||     Find and return an existing variable or create a new one if none of the existing ||     variables matches the given name; type and values. ||      ||     The optional `create_new_on` specifies the status at which a new variable is ||     created. The status must be at most :obj:`~Orange.data.variable.MakeStatus.Incompatible` since incompatible (or ||     non-existing) variables cannot be reused. If it is set lower; for instance  ||     to :obj:`~Orange.data.variable.MakeStatus.MissingValues`; a new variable is created even if there exists ||     a variable which is only missing the same values. If set to :obj:`~Orange.data.variable.MakeStatus.OK`; the function ||     always creates a new variable. ||      ||     The function returns a tuple containing a variable descriptor and the ||     status of the best matching variable. So; if ``create_new_on`` is set to ||     :obj:`~Orange.data.variable.MakeStatus.MissingValues`; and there exists a variable whose status is; say; ||     :obj:`~Orange.data.variable.MakeStatus.NoRecognizedValues`; a variable would be created; while the second  ||     element of the tuple would contain :obj:`~Orange.data.variable.MakeStatus.NoRecognizedValues`. If; on the other ||     hand; there exists a variable which is perfectly OK; its descriptor is  ||     returned and the returned status is :obj:`~Orange.data.variable.MakeStatus.OK`. The function returns no  ||     indicator whether the returned variable is reused or not. This can be; ||     however; read from the status code: if it is smaller than the specified ||     ``create_new_on``; the variable is reused; otherwise a new descriptor has been constructed. ||  ||     The exception to the rule is when ``create_new_on`` is OK. In this case; the  ||     function does not search through the existing variables and cannot know the  ||     status; so the returned status in this case is always :obj:`~Orange.data.variable.MakeStatus.OK`. ||  ||     :param name: Variable name ||     :param type: Variable type ||     :type type: Orange.data.variable.Type ||     :param ordered_values: a list of ordered values ||     :param unordered_values: a list of values; for which the order does not ||         matter ||     :param create_new_on: gives the condition for constructing a new variable instead ||         of using the new one ||      ||     :return_type: a tuple (:class:`Orange.data.variable.Variable`; int) ||      || .. function:: Orange.data.variable.retrieve(name; type; ordered_values; onordered_values[; create_new_on]) ||  ||     Find and return an existing variable; or :obj:`None` if no match is found. ||      ||     :param name: variable name. ||     :param type: variable type. ||     :type type: Orange.data.variable.Type ||     :param ordered_values: a list of ordered values ||     :param unordered_values: a list of values; for which the order does not ||         matter ||     :param create_new_on: gives the condition for constructing a new variable instead ||         of using the new one ||  ||     :return_type: :class:`Orange.data.variable.Variable` ||      || These following examples (from :download:`variable-reuse.py <code\\/variable-reuse.py>`) give the shown results if || executed only once (in a Python session) and in this order. ||  || :func:`Orange.data.variable.make` can be used for the construction of new variables. :: ||      ||     >>> v1; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; [\\""a\\""; \\""b\\""]) ||     >>> print s; v1.values ||     4 <a; b> ||  || No surprises here: a new variable is created and the status is :obj:`~Orange.data.variable.MakeStatus.NotFound`. :: ||  ||     >>> v2; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; [\\""a\\""]; [\\""c\\""]) ||     >>> print s; v2 is v1; v1.values ||     1 True <a; b; c> ||  || The status is 1 (:obj:`~Orange.data.variable.MakeStatus.MissingValues`); yet the variable is reused (``v2 is v1``). || ``v1`` gets a new value; ``\\""c\\""``; which was given as an unordered value. It does || not matter that the new variable does not need the value ``b``. :: ||  ||     >>> v3; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; [\\""a\\""; \\""b\\""; \\""c\\""; \\""d\\""]) ||     >>> print s; v3 is v1; v1.values ||     1 True <a; b; c; d> ||  || This is like before; except that the new value; ``d`` is not among the || ordered values. :: ||  ||     >>> v4; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; [\\""b\\""]) ||     >>> print s; v4 is v1; v1.values; v4.values ||     3; False; <b>; <a; b; c; d> ||  || The new variable needs to have ``b`` as the first value; so it is incompatible  || with the existing variables. The status is thus 3 (:obj:`~Orange.data.variable.MakeStatus.Incompatible`); the two  || variables are not equal and have different lists of values. :: ||  ||     >>> v5; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; None; [\\""c\\""; \\""a\\""]) ||     >>> print s; v5 is v1; v1.values; v5.values ||     0 True <a; b; c; d> <a; b; c; d> ||  || The new variable has values ``c`` and ``a``; but the order is not important;  || so the existing attribute is :obj:`~Orange.data.variable.MakeStatus.OK`. :: ||  ||     >>> v6; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; None; [\\""e\\""]) \\""a\\""]) ||     >>> print s; v6 is v1; v1.values; v6.values ||     2 True <a; b; c; d; e> <a; b; c; d; e> ||  || The new variable has different values than the existing variable (status is 2; || :obj:`~Orange.data.variable.MakeStatus.NoRecognizedValues`); but the existing one is nonetheless reused. Note that we || gave ``e`` in the list of unordered values. If it was among the ordered; the || reuse would fail. :: ||  ||     >>> v7; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; None; ||             [\\""f\\""]; Orange.data.variable.MakeStatus.NoRecognizedValues))) ||     >>> print s; v7 is v1; v1.values; v7.values ||     2 False <a; b; c; d; e> <f> ||  || This is the same as before; except that we prohibited reuse when there are no || recognized values. Hence a new variable is created; though the returned status is  || the same as before:: ||  ||     >>> v8; s = Orange.data.variable.make(\\""a\\""; Orange.data.Type.Discrete; ||             [\\""a\\""; \\""b\\""; \\""c\\""; \\""d\\""; \\""e\\""]; None; Orange.data.variable.MakeStatus.OK) ||     >>> print s; v8 is v1; v1.values; v8.values ||     0 False <a; b; c; d; e> <a; b; c; d; e> ||  || Finally; this is a perfect match; but any reuse is prohibited; so a new  || variable is created. ||  || \\""\\""\\""'"
b'TODO: keyboard modifiers and constraints.'
b'TODO add test to assure history is written to from trainer'
b'FIXME: but we need validation data during training (LR annealing)'
b'FIXME: currently we have iterators for training and validation. Both of those'
b'TODO creation of training data changed'
b'TODO we reload params again in train do we need it here?'
b'TODO local: except specific training exception that can occur'
b'TODO: loss functions and training'
"b'\\""\\""\\""02. Monodepth2 training on KITTI dataset || ================================================== ||  || TODO\\""\\""\\""'"
b'TODO this may be a problem when training config is large'
b'TODO: This is somewhat brittle. Make these constants in trainer.py.'
b'TODO: Move Trainable autopopulation to a util function'
b'TODO: Implement autoscaling. If num_workers=-1; the trainer will use as'
b'TODO(ekl) fix iterator metrics bugs w\\/multiple trainers.'
"b""TODO: (sven) if sub_exploration is None; use Trainer's default"""
b'TODO: implement loopy training case'
"b'\\""emit_constraint_type\\"": \\""center\\""; TODO: enable when adds support for no gt boxes'"
b'TODO: training and bn_training'
b'TODO: find a way to reset the state of Adam so we only need to compile the training function ones'
b'fixme: check if `configuration.config.train` flag has changed. If so; run define-by-run code.'
b'FIXME: detect corpus reading errors here (e.g. wrong encoding)'
b'TODO: token encoding scheme where subdirectories'
b'FIXME: support sparse encoding'
"b'\\""\\""\\"" || This module handles map plotting. Currently only 3 types of map types are \\\\ || supported (aggregated choropleth; geo-scatterplot; and lines on map). ||  || Global Variables: ||     - Sidebar: To be used for creating side-menus. ||  || Functions: ||     - Map_Options: Generate the layout of the dashboard. ||     - country2code: It takes a string and tries to convert it to a country \\\\ ||                     code by trying out various encodings. ||  || Dash callbacks: ||     - render_variable_choices_maps: Create a menu of dcc components for \\\\ ||                                     the user to choose plotting options. ||     - show_hide_aggregator_dropdown: Disable some dropdowns. Some maps do \\\\ ||                                      not handle all the fields. ||     - plot_map: Plot the map according to user choices. ||  || TODO: ||     Implement https:\\/\\/plot.ly\\/python\\/choropleth-maps\\/#choropleth-inset-map || TODO: ||     Add text\\/annotations to the various maps. || \\""\\""\\""'"
b'TODO use np.unique for run-length encoding?'
b'TODO: add character level encoding'
b'TODO: add character-level encoding'
b'TODO First spike encoding.'
"b""f = open(JobService.Project.path(project) + '.upload';'w') #TODO: check for problems with character encoding?"""
b'TODO: catch encoding errors'
b'TODO: check for problems with character encoding?'
"b'o += \\"" format=\\\\\\""\\""+inputformat.__class__.__name__+\\""\\\\\\"" formatlabel=\\\\\\""\\""+inputformat.name+\\""\\\\\\"" encoding=\\\\\\""\\""+inputformat.encoding+\\""\\\\\\""\\""; #TODO: output nice format labels?'"
"b""TODO: only re-download the ones with encoding issues. Don't touch the rest."""
b'TODO: Arguments for sparse vector encoding'
b'TODO: use `image_encoding_channels` when calling class ImageEncoding'
b'todo: re-add positional encodings'
b'TODO: Should write this to file and avoid doing encoding if already exists'
"b'\\""\\""\\""Converts legacy encodings into Unicode || TODO for replacer.py: ||  - add perseus-style iota subscript and diaeresis || \\""\\""\\""'"
"b'\\""\\""\\""Converts legacy encodings into Unicode. ||  || TODO: Rm regex dependency || TODO: Add tests || \\""\\""\\""'"
b'get_sinusoid_encoding_table  # todo: \\u5E94\\u8BE5\\u5C06position embedding\\u79FB\\u5230core'
b'TODO: Check if the encoding method is included in the manifest'
"b""TODO: If auto-sklearn & TPOT also require imputation & dummy encoding; let's move this to common_code"""
b'TODO One-hot encoding of either type labels or of a tensor of type ids (some class renaming required in the'
b'TODO (wardlt): One-hot encoding for the elements'
b'TODO: Encoding and decoding back and forth not terribly efficient'
b'todo encoding; unicode fields; errors?'
b'TODO: assert encoding and filename exist'
b'TODO: encoding of molecular graph into vector'
b'TODO: Handle encodings other than int16'
"b""TODO: I've got the encoding (int16) hardcoded in a few places."""
b'TODO: Write test for encoding bug'
b'TODO: remove label encoding when class bug is fixed'
b'TODO: Check if weight is tied to encoding embedding'
b'TODO: use `tokenize.detect_encoding`'
"b""TODO don't like that: encoding after each event"""
b'TODO might not work with label_featurizer encoding;'
