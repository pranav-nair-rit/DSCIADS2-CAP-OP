{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33125d2b-416b-419d-816d-6a49ab055873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57e039f5-a118-43ca-b71d-9a3486d2ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"capstone_main_dataset (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8d4b95e-9150-4a53-8907-7c9b7ef14ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Comment'].str.contains(\"todo|fixme|xxx|add|fix|hack|set|need|check\", case=False, na=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d390b3a-3389-49c1-b9d2-e2f80ebd3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7b64ffe-b414-4497-b006-7b860cb481b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe for 'test':\n",
      "                         repo  \\\n",
      "185           omegaml/omegaml   \n",
      "237           omegaml/omegaml   \n",
      "260           omegaml/omegaml   \n",
      "271    ssydasheng/GPflow-Slim   \n",
      "322       tritemio/FRETBursts   \n",
      "...                       ...   \n",
      "68678         chainer/chainer   \n",
      "68741         chainer/chainer   \n",
      "68742         chainer/chainer   \n",
      "68745         chainer/chainer   \n",
      "68746         chainer/chainer   \n",
      "\n",
      "                                                filename  \\\n",
      "185                          omegaml/mixins/mdf/apply.py   \n",
      "237                omegaml/tests/features/environment.py   \n",
      "260                omegaml/backends/restapi/asyncrest.py   \n",
      "271                                      examples/gpr.py   \n",
      "322                    fretbursts/tests/test_burstlib.py   \n",
      "...                                                  ...   \n",
      "68678               chainerx/python/chainerx/__init__.py   \n",
      "68741  tests/chainer_tests/links_tests/loss_tests/tes...   \n",
      "68742  tests/chainer_tests/links_tests/loss_tests/tes...   \n",
      "68745  tests/chainer_tests/links_tests/loss_tests/tes...   \n",
      "68746  tests/chainer_tests/links_tests/loss_tests/tes...   \n",
      "\n",
      "                                         Commit  \\\n",
      "185    fa4a8267a2ec050bc8a15d6a15289ac81e43e92a   \n",
      "237    bacd5dff3831d0feaa3f49b15328a416e7888adf   \n",
      "260    65669112df0861b07c796bc5c0aaaa8f12b5e699   \n",
      "271    5d83d31893746a9e768ce94a1e90874eff0ce09a   \n",
      "322    9a0d27d0641794ed9a22a63460051b80ce2a3617   \n",
      "...                                         ...   \n",
      "68678  37aae99064f0fbaf5794a51bd2413ec3ff07b5eb   \n",
      "68741  8eacd20e35f31f124da36759953a21b29871e72f   \n",
      "68742  d16abee4b4272ccfdbaa7b846cd39d365f8c42be   \n",
      "68745  401040aa701eaf2466a3d5f2bd4ed8236710759f   \n",
      "68746  302686e849f68c2106398fabb54c7217b93fb7e1   \n",
      "\n",
      "                                                 Comment  \\\n",
      "185            TODO write a unit test for this condition   \n",
      "237    FIXME we do this because context.feature is se...   \n",
      "260                          hack to allow local testing   \n",
      "271                            TODO: test when ARD=FALSE   \n",
      "322    TODO add all the ph_sel combinations like in t...   \n",
      "...                                                  ...   \n",
      "68678  `testing` needs to be imported before `_core`;...   \n",
      "68741  Fix this test. The code seems to fix the sampl...   \n",
      "68742  Fix this test. The code seems to fix the sampl...   \n",
      "68745  Fix this test. The code seems to fix the sampl...   \n",
      "68746  Fix this test. The code seems to fix the sampl...   \n",
      "\n",
      "                                                    link  \n",
      "185    https://github.com/omegaml/omegaml/commit/fa4a...  \n",
      "237    https://github.com/omegaml/omegaml/commit/bacd...  \n",
      "260    https://github.com/omegaml/omegaml/commit/6566...  \n",
      "271    https://github.com/ssydasheng/GPflow-Slim/comm...  \n",
      "322    https://github.com/tritemio/FRETBursts/commit/...  \n",
      "...                                                  ...  \n",
      "68678  https://github.com/chainer/chainer/commit/37aa...  \n",
      "68741  https://github.com/chainer/chainer/commit/8eac...  \n",
      "68742  https://github.com/chainer/chainer/commit/d16a...  \n",
      "68745  https://github.com/chainer/chainer/commit/4010...  \n",
      "68746  https://github.com/chainer/chainer/commit/3026...  \n",
      "\n",
      "[2558 rows x 5 columns]\n",
      "Dataframe for 'train':\n",
      "                     repo                                           filename  \\\n",
      "24           evhart/crees                                        text_cnn.py   \n",
      "51      GilesStrong/lumin                         lumin/nn/models/helpers.py   \n",
      "417    noxouille/rt-mrcnn                                           model.py   \n",
      "437    noxouille/rt-mrcnn                                      run_webcam.py   \n",
      "454      rstemmer/musicdb                                  lib/db/musicdb.py   \n",
      "...                   ...                                                ...   \n",
      "68482     chainer/chainer       chainer/graph_optimimzations/static_graph.py   \n",
      "68491     chainer/chainer                      examples/cifar/train_cifar.py   \n",
      "68559     chainer/chainer  examples/static_graph_optimizations/cifar/trai...   \n",
      "68560     chainer/chainer  examples/static_graph_optimizations/mnist/trai...   \n",
      "68676     chainer/chainer  chainermn/functions/point_to_point_communicati...   \n",
      "\n",
      "                                         Commit  \\\n",
      "24     a7794272b20c9e2c3362d9809a85bfa9dd416159   \n",
      "51     af0cbd5bb81072384b592230616fd97f8f8f1734   \n",
      "417    2368d206f079adf1bfe7ccb23824d5d18c22e031   \n",
      "437    7952d563eeaed6db35a2d94ca2dbcba177a3316c   \n",
      "454    b88a22c4d2ecbe4c09517384815a8831fbbfca9a   \n",
      "...                                         ...   \n",
      "68482  ed93a50e8f37bba1cc3fccf0f37d33654e85b0c0   \n",
      "68491  dbb4663dfcf2fb076b05a1ec8919d79a3f575837   \n",
      "68559  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68560  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68676  5bb57bba985516b35455252fc5d8909c8ded1694   \n",
      "\n",
      "                                                 Comment  \\\n",
      "24     Define session context (not needed when trainn...   \n",
      "51       TODO: load pretrained embeddings to check sizes   \n",
      "417                         TODO: support training mode?   \n",
      "437    Download COCO trained weights from Releases if...   \n",
      "454    \\\"\\\"\\\" || This class manages the *MusicDB Data...   \n",
      "...                                                  ...   \n",
      "68482  fixme: check if `configuration.config.train` f...   \n",
      "68491                   training_length is needed to set   \n",
      "68559  \\\"\\\"\\\"Convnet example using CIFAR10 or CIFAR10...   \n",
      "68560  \\\"\\\"\\\"Fully-connected neural network example u...   \n",
      "68676  dummy_var is needed to maintain Chainer's cons...   \n",
      "\n",
      "                                                    link  \n",
      "24     https://github.com/evhart/crees/commit/a779427...  \n",
      "51     https://github.com/GilesStrong/lumin/commit/af...  \n",
      "417    https://github.com/noxouille/rt-mrcnn/commit/2...  \n",
      "437    https://github.com/noxouille/rt-mrcnn/commit/7...  \n",
      "454    https://github.com/rstemmer/musicdb/commit/b88...  \n",
      "...                                                  ...  \n",
      "68482  https://github.com/chainer/chainer/commit/ed93...  \n",
      "68491  https://github.com/chainer/chainer/commit/dbb4...  \n",
      "68559  https://github.com/chainer/chainer/commit/191e...  \n",
      "68560  https://github.com/chainer/chainer/commit/191e...  \n",
      "68676  https://github.com/chainer/chainer/commit/5bb5...  \n",
      "\n",
      "[1005 rows x 5 columns]\n",
      "Dataframe for 'validate':\n",
      "                      repo                            filename  \\\n",
      "1348   jmbr/diffusion-maps    diffusion_maps/diffusion_maps.py   \n",
      "1842          erp12/pyshgp             pyshgp/.gp_bak2/base.py   \n",
      "2883    jungtaekkim/bayeso                bayeso/covariance.py   \n",
      "2916    jungtaekkim/bayeso                bayeso/covariance.py   \n",
      "2994          bmcfee/pumpp                  pumpp/task/base.py   \n",
      "...                    ...                                 ...   \n",
      "63460     RasaHQ/rasa_core                 rasa_core/server.py   \n",
      "63466     RasaHQ/rasa_core                 rasa_core/server.py   \n",
      "63469     RasaHQ/rasa_core                 rasa_core/server.py   \n",
      "64667     OpenMined/PySyft  syft/core/frameworks/torch/hook.py   \n",
      "66868      ray-project/ray   python/ray/autoscaler/commands.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "1348   07d47acc9f6ce178ead89a7168592c88bb456c74   \n",
      "1842   dfcec1a78a8b5f1786a98b63eb186f5e60630418   \n",
      "2883   f753ab73aaeb117f9a3b39270dcaed144209a32d   \n",
      "2916   efecb73ae17fffc041ec8ec230d3b7a5636e8183   \n",
      "2994   d75b207f4f5eba37975d518093e3402053837f48   \n",
      "...                                         ...   \n",
      "63460  5c969d88a45f2ff872a3c5a37a50819dadbafd31   \n",
      "63466  5124609e65844f3733fb0c04815833b75cc9520a   \n",
      "63469  bca29e139ba895206050ad6eb146d645c363f9c8   \n",
      "64667  12c53e0e75baa516af5fe15f1e3913b05d6dbd6e   \n",
      "66868  908c0c630a6c7c6e35b7bb0e172d41372bfb309d   \n",
      "\n",
      "                                                 Comment  \\\n",
      "1348                                  XXX Validate this.   \n",
      "1842   \\\"\\\"\\\" || The :mod:`base` module defines the b...   \n",
      "2883   TODO: ValueError is appropriate? We can just r...   \n",
      "2916   TODO: ValueError is appropriate? We can just r...   \n",
      "2994                 TODO: validate shape and dtype here   \n",
      "...                                                  ...   \n",
      "63460     TODO LOCAL: validate namespace json in request   \n",
      "63466     TODO LOCAL: validate namespace json in request   \n",
      "63469     TODO LOCAL: validate namespace json in request   \n",
      "64667  TODO: check and validate how the registration ...   \n",
      "66868         todo: validate file_mounts; ssh keys; etc.   \n",
      "\n",
      "                                                    link  \n",
      "1348   https://github.com/jmbr/diffusion-maps/commit/...  \n",
      "1842   https://github.com/erp12/pyshgp/commit/dfcec1a...  \n",
      "2883   https://github.com/jungtaekkim/bayeso/commit/f...  \n",
      "2916   https://github.com/jungtaekkim/bayeso/commit/e...  \n",
      "2994   https://github.com/bmcfee/pumpp/commit/d75b207...  \n",
      "...                                                  ...  \n",
      "63460  https://github.com/RasaHQ/rasa_core/commit/5c9...  \n",
      "63466  https://github.com/RasaHQ/rasa_core/commit/512...  \n",
      "63469  https://github.com/RasaHQ/rasa_core/commit/bca...  \n",
      "64667  https://github.com/OpenMined/PySyft/commit/12c...  \n",
      "66868  https://github.com/ray-project/ray/commit/908c...  \n",
      "\n",
      "[135 rows x 5 columns]\n",
      "Dataframe for 'model':\n",
      "                                   repo  \\\n",
      "24                         evhart/crees   \n",
      "44                    GilesStrong/lumin   \n",
      "45                    GilesStrong/lumin   \n",
      "604               yonkshi/text2imageNet   \n",
      "691    Seanforfun/GMAN_Net_Haze_Removal   \n",
      "...                                 ...   \n",
      "68396                   chainer/chainer   \n",
      "68397                   chainer/chainer   \n",
      "68445                   chainer/chainer   \n",
      "68559                   chainer/chainer   \n",
      "68560                   chainer/chainer   \n",
      "\n",
      "                                                filename  \\\n",
      "24                                           text_cnn.py   \n",
      "44                  lumin/nn/callbacks/data_callbacks.py   \n",
      "45                         lumin/nn/ensemble/ensemble.py   \n",
      "604                       lenet/tensorcv/train/config.py   \n",
      "691               DehazeNet/dehazenet_multi_gpu_train.py   \n",
      "...                                                  ...   \n",
      "68396          examples/cifar/train_cifar_custom_loop.py   \n",
      "68397          examples/mnist/train_mnist_custom_loop.py   \n",
      "68445       chainer/graph_optimimzations/static_graph.py   \n",
      "68559  examples/static_graph_optimizations/cifar/trai...   \n",
      "68560  examples/static_graph_optimizations/mnist/trai...   \n",
      "\n",
      "                                         Commit  \\\n",
      "24     a7794272b20c9e2c3362d9809a85bfa9dd416159   \n",
      "44     4ebe08737e4e3076fdb2ca6c5688466eace91168   \n",
      "45     d16d25768f0b677b548c7b0b3c9d36329991af25   \n",
      "604    28cf797566877a80db00e33e4311f70ab7b241b2   \n",
      "691    f3eb9864e9de8255464a1ffb1e95fab5091c389f   \n",
      "...                                         ...   \n",
      "68396  8ededc85430f7341d99ddd8127871f4f795c420b   \n",
      "68397  8ededc85430f7341d99ddd8127871f4f795c420b   \n",
      "68445  4b9cbf779b6918b8f5710aeb7965ede6e9eb1864   \n",
      "68559  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68560  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "\n",
      "                                                 Comment  \\\n",
      "24     Define session context (not needed when trainn...   \n",
      "44     TODO cont feat names no longer required only n...   \n",
      "45     TODO: check whether model_builder is necessary...   \n",
      "604    TODO model.default_collection only in BaseMode...   \n",
      "691           TODO Lida Xu please re-write the CNN model   \n",
      "...                                                  ...   \n",
      "68396  \\\"\\\"\\\"Convnet example using CIFAR10 or CIFAR10...   \n",
      "68397  \\\"\\\"\\\"Fully-connected neural network example u...   \n",
      "68445  todo: add test that use the same random seed w...   \n",
      "68559  \\\"\\\"\\\"Convnet example using CIFAR10 or CIFAR10...   \n",
      "68560  \\\"\\\"\\\"Fully-connected neural network example u...   \n",
      "\n",
      "                                                    link  \n",
      "24     https://github.com/evhart/crees/commit/a779427...  \n",
      "44     https://github.com/GilesStrong/lumin/commit/4e...  \n",
      "45     https://github.com/GilesStrong/lumin/commit/d1...  \n",
      "604    https://github.com/yonkshi/text2imageNet/commi...  \n",
      "691    https://github.com/Seanforfun/GMAN_Net_Haze_Re...  \n",
      "...                                                  ...  \n",
      "68396  https://github.com/chainer/chainer/commit/8ede...  \n",
      "68397  https://github.com/chainer/chainer/commit/8ede...  \n",
      "68445  https://github.com/chainer/chainer/commit/4b9c...  \n",
      "68559  https://github.com/chainer/chainer/commit/191e...  \n",
      "68560  https://github.com/chainer/chainer/commit/191e...  \n",
      "\n",
      "[1347 rows x 5 columns]\n",
      "Dataframe for 'hyperparameter':\n",
      "                                    repo  \\\n",
      "2545                    Erotemic/netharn   \n",
      "4735                      simonfqy/PADME   \n",
      "4768                      simonfqy/PADME   \n",
      "4771                      simonfqy/PADME   \n",
      "6115   bareblackfoot/lddp-tf-faster-rcnn   \n",
      "...                                  ...   \n",
      "62103              arthurpaulino/miraiml   \n",
      "64456                      microsoft/nni   \n",
      "66838                    ray-project/ray   \n",
      "66897                    ray-project/ray   \n",
      "66937                    ray-project/ray   \n",
      "\n",
      "                                                filename  \\\n",
      "2545                           netharn/examples/cifar.py   \n",
      "4735                     dcCustom/models/tensor_graph.py   \n",
      "4768         dcCustom/models/tensorgraph/tensor_graph.py   \n",
      "4771         dcCustom/models/tensorgraph/tensor_graph.py   \n",
      "6115                              lib/model/train_val.py   \n",
      "...                                                  ...   \n",
      "62103                                miraiml/__init__.py   \n",
      "64456           src/sdk/pynni/nni/pbt_tuner/pbt_tuner.py   \n",
      "66838         doc/source/tune/_tutorials/tune-sklearn.py   \n",
      "66897  doc/source/tune/_tutorials/tune-serve-integrat...   \n",
      "66937               python/ray/tune/tests/ext_pytorch.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "2545   5f79282c043a0d58be110ce7719c72f3402fbd58   \n",
      "4735   4f3610b7ee05d2bd755fa73ffdd2afdb154f1421   \n",
      "4768   2cb677a6ee205673b6e17454b979c3a2cce991a5   \n",
      "4771   90a881f4afc0e536b8fc242c9f6646c6cce09b0a   \n",
      "6115   ee512c4533be6d7c26a1f8ebbc1c373114b5bc9f   \n",
      "...                                         ...   \n",
      "62103  0e1d3a1100e8feb22053ef2f8450ba74efd15b02   \n",
      "64456  a82b4a3bf7c64e18172cc3a93de567ae6e607a76   \n",
      "66838  139d21e068585fc2eb4b79808c3477347eb3dafe   \n",
      "66897  dee3322ab0a9b8ebbd8a5747120781f64325346d   \n",
      "66937  efa1d51aeadeb23491d0159c588c31fd85e85eae   \n",
      "\n",
      "                                                 Comment  \\\n",
      "2545   \\\"\\\"\\\" || The examples\\/cifar.py is probably t...   \n",
      "4735   TODO: the following two variables are temporar...   \n",
      "4768   TODO: the following two variables are temporar...   \n",
      "4771   TODO: the following two variables are temporar...   \n",
      "6115   Needs to restore the other hyperparameters\\/st...   \n",
      "...                                                  ...   \n",
      "62103  \\\"\\\"\\\" || MiraiML is an asynchronous engine fo...   \n",
      "64456  TODO think about different type of hyperparame...   \n",
      "66838  \\\"\\\"\\\" || Tune's Scikit Learn Adapters || ====...   \n",
      "66897  \\\"\\\"\\\" || Model selection and serving with Ray...   \n",
      "66937  \\\"\\\"\\\" || Hyperparameter tuning with Ray Tune ...   \n",
      "\n",
      "                                                    link  \n",
      "2545   https://github.com/Erotemic/netharn/commit/5f7...  \n",
      "4735   https://github.com/simonfqy/PADME/commit/4f361...  \n",
      "4768   https://github.com/simonfqy/PADME/commit/2cb67...  \n",
      "4771   https://github.com/simonfqy/PADME/commit/90a88...  \n",
      "6115   https://github.com/bareblackfoot/lddp-tf-faste...  \n",
      "...                                                  ...  \n",
      "62103  https://github.com/arthurpaulino/miraiml/commi...  \n",
      "64456  https://github.com/microsoft/nni/commit/a82b4a...  \n",
      "66838  https://github.com/ray-project/ray/commit/139d...  \n",
      "66897  https://github.com/ray-project/ray/commit/dee3...  \n",
      "66937  https://github.com/ray-project/ray/commit/efa1...  \n",
      "\n",
      "[72 rows x 5 columns]\n",
      "Dataframe for 'AB testing':\n",
      "Empty DataFrame\n",
      "Columns: [repo, filename, Commit, Comment, link]\n",
      "Index: []\n",
      "Dataframe for 'Epoch':\n",
      "                           repo  \\\n",
      "392          noxouille/rt-mrcnn   \n",
      "2388   Angzz/panoptic-fpn-gluon   \n",
      "2523           Erotemic/netharn   \n",
      "2524           Erotemic/netharn   \n",
      "2545           Erotemic/netharn   \n",
      "...                         ...   \n",
      "65837          allenai/allennlp   \n",
      "66440           ray-project/ray   \n",
      "67394       NervanaSystems/neon   \n",
      "67503       NervanaSystems/neon   \n",
      "67541       NervanaSystems/neon   \n",
      "\n",
      "                                                filename  \\\n",
      "392                                              coco.py   \n",
      "2388   docs/tutorials/classification/dive_deep_imagen...   \n",
      "2523                                 netharn/fit_harn.py   \n",
      "2524                                 netharn/fit_harn.py   \n",
      "2545                           netharn/examples/cifar.py   \n",
      "...                                                  ...   \n",
      "65837  allennlp/models/semantic_parsing/nlvr/nlvr_cov...   \n",
      "66440  python/ray/tune/examples/pbt_tune_cifar10_with...   \n",
      "67394                      neon/transforms/batch_norm.py   \n",
      "67503                           examples/cifar10_msra.py   \n",
      "67541                      examples/faster-rcnn/train.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "392    2368d206f079adf1bfe7ccb23824d5d18c22e031   \n",
      "2388   7caee8e1cb994730efa849cd10603c1294e2b759   \n",
      "2523   54bb6c1f371c12649df97ed5b2c5f4710e97bd0a   \n",
      "2524   54bb6c1f371c12649df97ed5b2c5f4710e97bd0a   \n",
      "2545   5f79282c043a0d58be110ce7719c72f3402fbd58   \n",
      "...                                         ...   \n",
      "65837  7dfc34247cedfe16c9d35a557855977fbd3df15c   \n",
      "66440  6b1e592d5c34acb9716cd625a2adfaac9a0cb63c   \n",
      "67394  3f90773a6694aaf472b1ad84e02dece87cf1df48   \n",
      "67503  c11415229feec19ed8df20e718f66ac80fdfee8e   \n",
      "67541  ce992a7a916564cd00e88ea87286b039a5a9c180   \n",
      "\n",
      "                                                 Comment  \\\n",
      "392                   Adjust epochs and layers as needed   \n",
      "2388   \\\"\\\"\\\"5. Train Your Own Model on ImageNet || =...   \n",
      "2523   \\\"\\\"\\\" || CommandLine: ||     python ~\\/code\\/...   \n",
      "2524   \\\"\\\"\\\" || Notes: ||     when profiling ensure ...   \n",
      "2545   \\\"\\\"\\\" || The examples\\/cifar.py is probably t...   \n",
      "...                                                  ...   \n",
      "65837  We look at the epoch number and adjust the che...   \n",
      "66440  \\\"\\\"\\\"Train keras CNN on the CIFAR10 small ima...   \n",
      "67394  increment the global estimates (TODO: stop aft...   \n",
      "67503  \\\"\\\"\\\" || Deep Residual Network on CIFAR10 dat...   \n",
      "67541  \\\"\\\"\\\" || Train a Faster-RCNN model to do obje...   \n",
      "\n",
      "                                                    link  \n",
      "392    https://github.com/noxouille/rt-mrcnn/commit/2...  \n",
      "2388   https://github.com/Angzz/panoptic-fpn-gluon/co...  \n",
      "2523   https://github.com/Erotemic/netharn/commit/54b...  \n",
      "2524   https://github.com/Erotemic/netharn/commit/54b...  \n",
      "2545   https://github.com/Erotemic/netharn/commit/5f7...  \n",
      "...                                                  ...  \n",
      "65837  https://github.com/allenai/allennlp/commit/7df...  \n",
      "66440  https://github.com/ray-project/ray/commit/6b1e...  \n",
      "67394  https://github.com/NervanaSystems/neon/commit/...  \n",
      "67503  https://github.com/NervanaSystems/neon/commit/...  \n",
      "67541  https://github.com/NervanaSystems/neon/commit/...  \n",
      "\n",
      "[133 rows x 5 columns]\n",
      "Dataframe for 'batch':\n",
      "                    repo                                           filename  \\\n",
      "44     GilesStrong/lumin               lumin/nn/callbacks/data_callbacks.py   \n",
      "84     GilesStrong/lumin                           lumin/nn/models/model.py   \n",
      "96     GilesStrong/lumin                           lumin/nn/models/model.py   \n",
      "100    GilesStrong/lumin                           lumin/nn/models/model.py   \n",
      "376      munagekar/nnpso                     benchmarking/benchmark_test.py   \n",
      "...                  ...                                                ...   \n",
      "68396    chainer/chainer          examples/cifar/train_cifar_custom_loop.py   \n",
      "68397    chainer/chainer          examples/mnist/train_mnist_custom_loop.py   \n",
      "68497    chainer/chainer        chainer/graph_optimizations/static_graph.py   \n",
      "68559    chainer/chainer  examples/static_graph_optimizations/cifar/trai...   \n",
      "68560    chainer/chainer  examples/static_graph_optimizations/mnist/trai...   \n",
      "\n",
      "                                         Commit  \\\n",
      "44     4ebe08737e4e3076fdb2ca6c5688466eace91168   \n",
      "84     b645b61c579666d5bee11ac16af49b5c6fea7df3   \n",
      "96     0f54ff380fe8d13450a6f0755334ff614dee8450   \n",
      "100    43fca6fcdded3e6265ed030f59e3c715665d4e30   \n",
      "376    64d7e48469c111ca7d9541c2edfccdfabf7199d1   \n",
      "...                                         ...   \n",
      "68396  8ededc85430f7341d99ddd8127871f4f795c420b   \n",
      "68397  8ededc85430f7341d99ddd8127871f4f795c420b   \n",
      "68497  def5bc916a17f50b45a622818ad7455d1e3126bb   \n",
      "68559  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68560  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "\n",
      "                                                 Comment  \\\n",
      "44     TODO cont feat names no longer required only n...   \n",
      "84           TODO: Fix this to work for incomplete batch   \n",
      "96           TODO: Fix this to work for incomplete batch   \n",
      "100          TODO: Fix this to work for incomplete batch   \n",
      "376            TODO: Add batch size and other properties   \n",
      "...                                                  ...   \n",
      "68396  \\\"\\\"\\\"Convnet example using CIFAR10 or CIFAR10...   \n",
      "68397  \\\"\\\"\\\"Fully-connected neural network example u...   \n",
      "68497  todo (vogel): Also check if minibatch size has...   \n",
      "68559  \\\"\\\"\\\"Convnet example using CIFAR10 or CIFAR10...   \n",
      "68560  \\\"\\\"\\\"Fully-connected neural network example u...   \n",
      "\n",
      "                                                    link  \n",
      "44     https://github.com/GilesStrong/lumin/commit/4e...  \n",
      "84     https://github.com/GilesStrong/lumin/commit/b6...  \n",
      "96     https://github.com/GilesStrong/lumin/commit/0f...  \n",
      "100    https://github.com/GilesStrong/lumin/commit/43...  \n",
      "376    https://github.com/munagekar/nnpso/commit/64d7...  \n",
      "...                                                  ...  \n",
      "68396  https://github.com/chainer/chainer/commit/8ede...  \n",
      "68397  https://github.com/chainer/chainer/commit/8ede...  \n",
      "68497  https://github.com/chainer/chainer/commit/def5...  \n",
      "68559  https://github.com/chainer/chainer/commit/191e...  \n",
      "68560  https://github.com/chainer/chainer/commit/191e...  \n",
      "\n",
      "[689 rows x 5 columns]\n",
      "Dataframe for 'graph':\n",
      "                                   repo  \\\n",
      "27        gbnk0/simple-image-classifier   \n",
      "379                     munagekar/nnpso   \n",
      "687    Seanforfun/GMAN_Net_Haze_Removal   \n",
      "688    Seanforfun/GMAN_Net_Haze_Removal   \n",
      "862    sshleifer/object_detection_kitti   \n",
      "...                                 ...   \n",
      "68557                   chainer/chainer   \n",
      "68563                   chainer/chainer   \n",
      "68595                   chainer/chainer   \n",
      "68648                   chainer/chainer   \n",
      "68797                PaddlePaddle/ERNIE   \n",
      "\n",
      "                                                filename  \\\n",
      "27                                            retrain.py   \n",
      "379                                             newnn.py   \n",
      "687                         DehazeNet/dehazenet_input.py   \n",
      "688                         DehazeNet/dehazenet_input.py   \n",
      "862                          slim/models/model_deploy.py   \n",
      "...                                                  ...   \n",
      "68557             chainer/functions/connection/linear.py   \n",
      "68563  examples/static_graph_optimizations/ptb/train_...   \n",
      "68595             chainer/functions/connection/linear.py   \n",
      "68648        chainer/graph_optimizations/static_graph.py   \n",
      "68797                            ernie/modeling_ernie.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "27     2071f2ad4cd1708c801e51849e8f32667f0f4e70   \n",
      "379    d716b6b09004f67c631f6008ebecc94729aac1ab   \n",
      "687    070c04a0abc4f94786a8de26c6ecd41634ac284a   \n",
      "688    23c6bcf63a401a449afa0aa0b6a88961e52545bd   \n",
      "862    a5c4fd06d21e85a231ec05cc5305478a6c2d6a73   \n",
      "...                                         ...   \n",
      "68557  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68563  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68595  b18210db47de997cc1057d63439d5bda83558ba1   \n",
      "68648  22c5d798e356e820acc9687225e306031a213679   \n",
      "68797  defa38e7c4e7da8c05626569f17f80eac518a088   \n",
      "\n",
      "                                                 Comment  \\\n",
      "27     TODO: Make this use an eval graph; to avoid qu...   \n",
      "379    NOTE:Graph Isn't initialized Properly Needsd t...   \n",
      "687                       TODO Put all graphs into queue   \n",
      "688                       TODO Put all graphs into queue   \n",
      "862    \\\"\\\"\\\"Deploy Slim models across multiple clone...   \n",
      "...                                                  ...   \n",
      "68557  fixme: either re-implement static graph here o...   \n",
      "68563  assert isinstance(words_labels; list) #fixme: ...   \n",
      "68595  fixme: either re-implement static graph here o...   \n",
      "68648  todo: this is O(N^2) and maybe too slow for la...   \n",
      "68797  F.io.load_program_state(param_path) #buggy in ...   \n",
      "\n",
      "                                                    link  \n",
      "27     https://github.com/gbnk0/simple-image-classifi...  \n",
      "379    https://github.com/munagekar/nnpso/commit/d716...  \n",
      "687    https://github.com/Seanforfun/GMAN_Net_Haze_Re...  \n",
      "688    https://github.com/Seanforfun/GMAN_Net_Haze_Re...  \n",
      "862    https://github.com/sshleifer/object_detection_...  \n",
      "...                                                  ...  \n",
      "68557  https://github.com/chainer/chainer/commit/191e...  \n",
      "68563  https://github.com/chainer/chainer/commit/191e...  \n",
      "68595  https://github.com/chainer/chainer/commit/b182...  \n",
      "68648  https://github.com/chainer/chainer/commit/22c5...  \n",
      "68797  https://github.com/PaddlePaddle/ERNIE/commit/d...  \n",
      "\n",
      "[375 rows x 5 columns]\n",
      "Dataframe for 'tuning':\n",
      "                                                    repo  \\\n",
      "383                                      munagekar/nnpso   \n",
      "389                                      munagekar/nnpso   \n",
      "946                     sshleifer/object_detection_kitti   \n",
      "2394                            Angzz/panoptic-fpn-gluon   \n",
      "2688                                    Erotemic/netharn   \n",
      "2690                                    Erotemic/netharn   \n",
      "2785                   isikdogan/deep_learning_tutorials   \n",
      "3138                  roberthangu/snn_object_recognition   \n",
      "3421                 fpaupier/tensorflow-serving_sidecar   \n",
      "4263                      jason718/game-feature-learning   \n",
      "4735                                      simonfqy/PADME   \n",
      "4768                                      simonfqy/PADME   \n",
      "4771                                      simonfqy/PADME   \n",
      "4951          davidhaohanli/Abnormal-Behaviour-Detection   \n",
      "4955          davidhaohanli/Abnormal-Behaviour-Detection   \n",
      "5728                             annomator/annomator_1.0   \n",
      "10452                                dirty-cat/dirty_cat   \n",
      "12815                              Octavian-ai/mac-graph   \n",
      "12994                     HewlettPackard/dlcookbook-dlbs   \n",
      "15950                           ShuangLI59/person_search   \n",
      "16318             brightmart/bert_language_understanding   \n",
      "16321             brightmart/bert_language_understanding   \n",
      "16324             brightmart/bert_language_understanding   \n",
      "16927                     AKSHAYUBHAT/DeepVideoAnalytics   \n",
      "16957                     AKSHAYUBHAT/DeepVideoAnalytics   \n",
      "21015  kscompsci/TAKING-IDENTITY-INFORMATION-WITH-CAM...   \n",
      "22204  ShreyAmbesh/Traffic-Rule-Violation-Detection-S...   \n",
      "22242             ambakick/Person-Detection-and-Tracking   \n",
      "25757                                yoshida-lab/XenonPy   \n",
      "25865                           csc-training/intro-to-dl   \n",
      "27973                            IBM/MAX-Object-Detector   \n",
      "29561                    google-research/google-research   \n",
      "33030                           apacha/Mensural-Detector   \n",
      "36135                    scikit-optimize/scikit-optimize   \n",
      "42378                                feedly/transfer-nlp   \n",
      "42649                                    online-ml/river   \n",
      "44833                                    explosion/thinc   \n",
      "56132                                cong/ros_tensorflow   \n",
      "58587                                    chrislit/abydos   \n",
      "58619                                    chrislit/abydos   \n",
      "60980                          scikit-learn/scikit-learn   \n",
      "62266                                     biolab/orange3   \n",
      "63083                                 Tencent/PocketFlow   \n",
      "63090                                 Tencent/PocketFlow   \n",
      "63868                                      dmlc/gluon-cv   \n",
      "63870                                      dmlc/gluon-cv   \n",
      "63871                                      dmlc/gluon-cv   \n",
      "63916                                      dmlc/gluon-cv   \n",
      "63942                                      dmlc/gluon-cv   \n",
      "63954                                      dmlc/gluon-cv   \n",
      "65496                                    chainer/chainer   \n",
      "66838                                    ray-project/ray   \n",
      "66937                                    ray-project/ray   \n",
      "67423                                NervanaSystems/neon   \n",
      "\n",
      "                                                filename  \\\n",
      "383                                             clinn.py   \n",
      "389                                             lbest.py   \n",
      "946    object_detection/meta_architectures/ssd_meta_a...   \n",
      "2394      docs/tutorials/detection/finetune_detection.py   \n",
      "2688                                      netharn/api.py   \n",
      "2690                                 netharn/fit_harn.py   \n",
      "2785                                       S7/trainer.py   \n",
      "3138                         classify-images-one-shot.py   \n",
      "3421   object_detection/meta_architectures/ssd_meta_a...   \n",
      "4263   eval-3rd-party/voc_cls/phikr_caffe/python/dete...   \n",
      "4735                     dcCustom/models/tensor_graph.py   \n",
      "4768         dcCustom/models/tensorgraph/tensor_graph.py   \n",
      "4771         dcCustom/models/tensorgraph/tensor_graph.py   \n",
      "4951                                       code/split.py   \n",
      "4955                                       code/split.py   \n",
      "5728   tf_slim_obj_det/object_detection/meta_architec...   \n",
      "10452           examples/05_scaling_non_linear_models.py   \n",
      "12815                                   macgraph/lars.py   \n",
      "12994            python/pytorch_benchmarks/benchmarks.py   \n",
      "15950                   caffe-fast-rcnn/python/detect.py   \n",
      "16318                                model/bert_model.py   \n",
      "16321                          model/transfomer_model.py   \n",
      "16324                            model/bert_cnn_model.py   \n",
      "16927  repos/object_detection/meta_architectures/ssd_...   \n",
      "16957  repos/tfdetection/object_detection/meta_archit...   \n",
      "21015                meta_architectures/ssd_meta_arch.py   \n",
      "22204                meta_architectures/ssd_meta_arch.py   \n",
      "22242                meta_architectures/ssd_meta_arch.py   \n",
      "25757              samples/transfer_learning_tutorial.py   \n",
      "25865                          day2/pytorch-20ng-bert.py   \n",
      "27973  training/training_code/object_detection/meta_a...   \n",
      "29561              aptamers_mlpd/learning/feedforward.py   \n",
      "33030  tensorflow_object_detection/meta_architectures...   \n",
      "36135            examples/hyperparameter-optimization.py   \n",
      "42378                 transfer_nlp/runners/runnersABC.py   \n",
      "42649                           creme/expert/__init__.py   \n",
      "44833             thinc/neural/_classes/window_encode.py   \n",
      "56132  scripts/object_detection/meta_architectures/ss...   \n",
      "58587                                   abydos/phones.py   \n",
      "58619                           abydos/phones/_phones.py   \n",
      "60980                    sklearn/tree/tests/test_tree.py   \n",
      "62266                                 Orange/__init__.py   \n",
      "63083        learners/nonuniform_quantization/learner.py   \n",
      "63090           learners/uniform_quantization/learner.py   \n",
      "63868               scripts/classification/cifar/demo.py   \n",
      "63870            scripts/classification/imagenet/demo.py   \n",
      "63871                      scripts/segmentation/train.py   \n",
      "63916     docs/tutorials/detection/finetune_detection.py   \n",
      "63942  docs/tutorials/action_recognition/finetune_cus...   \n",
      "63954  docs/tutorials_torch/action_recognition/finetu...   \n",
      "65496  chainer/links/normalization/batch_normalizatio...   \n",
      "66838         doc/source/tune/_tutorials/tune-sklearn.py   \n",
      "66937               python/ray/tune/tests/ext_pytorch.py   \n",
      "67423                        neon/backends/nervanagpu.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "383    701f236a9a6ec7be94f7343a75432a8236de732d   \n",
      "389    c9b3fc7943ec398526ea5a449a1b7062794ecaaa   \n",
      "946    a4944a57ad2811e1f6a7a87589a9fc8a776e8d3c   \n",
      "2394   7caee8e1cb994730efa849cd10603c1294e2b759   \n",
      "2688   ef932c663f51f5cb804a56ea4c63ff70c7d6bc31   \n",
      "2690   ef932c663f51f5cb804a56ea4c63ff70c7d6bc31   \n",
      "2785   3fb01832735e65e65eb6594b9f0738ac2809272e   \n",
      "3138   f77a229eda9deca2562e9098098a1794c5f204c0   \n",
      "3421   e78e2946749dd804dc3868eee8973161222c3d68   \n",
      "4263   c1844d400fe3d191c3e012f8c6eb83dfc46ff7e9   \n",
      "4735   4f3610b7ee05d2bd755fa73ffdd2afdb154f1421   \n",
      "4768   2cb677a6ee205673b6e17454b979c3a2cce991a5   \n",
      "4771   90a881f4afc0e536b8fc242c9f6646c6cce09b0a   \n",
      "4951   2bcfb1b25d15a402761f41ef866388ded80c50cd   \n",
      "4955   6a9fd7464ec95dbb8812a557e3f17cb384f5bd01   \n",
      "5728   042cc36cba515855a4cbc963df4328123d624c9f   \n",
      "10452  b63be92e130592bf30f74a763ac743b554366cf0   \n",
      "12815  af3e5b5bb5c85cea82e9a665821ab4d61aa55877   \n",
      "12994  8f953918efc41de684507734351b7b226066cbb6   \n",
      "15950  52350f294541ceee9cb5b3c04ab728a7babf0bed   \n",
      "16318  b3bb4a3acc10a28a2718a72442feaf804b37327d   \n",
      "16321  b3bb4a3acc10a28a2718a72442feaf804b37327d   \n",
      "16324  29dcb8611592f1ed65fa31fbec2bb6fff3b5c863   \n",
      "16927  e1068503267ee475d33e77523b049165a6548614   \n",
      "16957  54370fcfcd1b6fe237fe004045103fd12da756f1   \n",
      "21015  cc1411d16f434cf1acae3bc2f47bc4cd0562b492   \n",
      "22204  c92e89118945f181e91391c12c51117e58def69e   \n",
      "22242  b4d9405956e9df117d214bbf5eb67f83304e251a   \n",
      "25757  a599614fb2c9983bfd20d396bba736dd736d09b7   \n",
      "25865  8d756c50bcc82f6a8570a9048ff07edea5c42b8b   \n",
      "27973  e7aef82865713ee7bd109156a2eb2fadd57f2387   \n",
      "29561  328de318e5ad9baf62bf541cb0f24e6b31f2f264   \n",
      "33030  22404eb2931793c36fd2ecf361b81166eed6726b   \n",
      "36135  335391d15ac93562215a0352102b4252485abbbe   \n",
      "42378  f5c28a8d1d295f0674897b05d24fb0f63ac32c57   \n",
      "42649  4d2a671bb5a73400b7be8ef2713e85401b585c6c   \n",
      "44833  0e2df2a6d000ed5c7a81f19a710338fb3adaab59   \n",
      "56132  efa22a59737173567b1cbb999a914cbd10ea0bf6   \n",
      "58587  6da092970e952341c60ab024a4e35c36a820f239   \n",
      "58619  0186998d684753e070edf1fdc124aaa56133db27   \n",
      "60980  de59efe7cbe9e33245e7573cb9d0d98478b05f98   \n",
      "62266  5cf6b70c5115524f48b8f3eb9a2ce2632ebe4933   \n",
      "63083  82244d9db61f0cf6f28c3d2e31f94b057ce6e623   \n",
      "63090  82244d9db61f0cf6f28c3d2e31f94b057ce6e623   \n",
      "63868  e7389b15ea6509268a5c54d239992df43603d50b   \n",
      "63870  e7389b15ea6509268a5c54d239992df43603d50b   \n",
      "63871  f1fd98531a1706cf1b6afa0872f5990b937087de   \n",
      "63916  1868c55b73bccc22602d87e3f2dc65699d9efa14   \n",
      "63942  c030232c22906f839926ae8fc4687b30d5da53b2   \n",
      "63954  dce2f28661f8d1e1cb5f68c6e699f0a0177c5b27   \n",
      "65496  d518feb1ee563c9ec5dc22d6fb5a1481fe3561b1   \n",
      "66838  139d21e068585fc2eb4b79808c3477347eb3dafe   \n",
      "66937  efa1d51aeadeb23491d0159c588c31fd85e85eae   \n",
      "67423  3497dcc8bb6200f2ce073b61bd6e5ad599f23141   \n",
      "\n",
      "                                                 Comment  \\\n",
      "383    Useful if the network needs very fine tuning t...   \n",
      "389    Useful if the network needs very fine tuning t...   \n",
      "946    Needed for fine-tuning from classification che...   \n",
      "2394   \\\"\\\"\\\"08. Finetune a pretrained detection mode...   \n",
      "2688      TODO: allow for \\\"discriminative fine-tuning\\\"   \n",
      "2690      TODO: allow for \\\"discriminative fine-tuning\\\"   \n",
      "2785   \\\"\\\"\\\" Coding Session 7: fine tuning a model i...   \n",
      "3138   # TODO: uncomment these lines after the comple...   \n",
      "3421   Needed for fine-tuning from classification che...   \n",
      "4263   \\\"\\\"\\\" || detector.py is an out-of-the-box win...   \n",
      "4735   TODO: the following two variables are temporar...   \n",
      "4768   TODO: the following two variables are temporar...   \n",
      "4771   TODO: the following two variables are temporar...   \n",
      "4951                                 TODO Default tuning   \n",
      "4955                                 TODO Default tuning   \n",
      "5728   Needed for fine-tuning from classification che...   \n",
      "10452  r\\\"\\\"\\\" || Fitting scalable; non-linear models...   \n",
      "12815  \\\"\\\"\\\" || From https:\\/\\/github.com\\/bparr\\/la...   \n",
      "12994  TODO: Is it good to enable cuDNN autotuning (b...   \n",
      "15950  \\\"\\\"\\\" || detector.py is an out-of-the-box win...   \n",
      "16318  \\\"\\\"\\\" ||  BERT: Pre-training of Deep Bidirect...   \n",
      "16321  \\\"\\\"\\\" ||  BERT: Pre-training of Deep Bidirect...   \n",
      "16324  \\\"\\\"\\\" ||  BERT: Pre-training of Deep Bidirect...   \n",
      "16927  Needed for fine-tuning from classification che...   \n",
      "16957  Needed for fine-tuning from classification che...   \n",
      "21015  Needed for fine-tuning from classification che...   \n",
      "22204  Needed for fine-tuning from classification che...   \n",
      "22242  Needed for fine-tuning from classification che...   \n",
      "25757  \\\"\\\"\\\" || Transfer Learning tutorial || ======...   \n",
      "25865  We set the remaining hyperparameters needed fo...   \n",
      "27973  Needed for fine-tuning from classification che...   \n",
      "29561  \\\"\\\"\\\"Provides a simple feed forward neural ne...   \n",
      "33030  Needed for fine-tuning from classification che...   \n",
      "36135  \\\"\\\"\\\" || ====================================...   \n",
      "42378  #  unfreezing the fc2 layer for extra tuning i...   \n",
      "42649  \\\"\\\"\\\"Expert learning. ||  || This module regr...   \n",
      "44833                        TODO: Implement fine-tuning   \n",
      "56132  Needed for fine-tuning from classification che...   \n",
      "58587       TODO: finish implementation\\/testing\\/tuning   \n",
      "58619       TODO: finish implementation\\/testing\\/tuning   \n",
      "60980  Note: Some fine tuning was needed to have metr...   \n",
      "62266  \\\"\\\"\\\" || _import(\\\"data.sample\\\") || _import(...   \n",
      "63083  TODO: add layerwise finetuning. working not ve...   \n",
      "63090  add layerwise finetuning. TODO: working not ve...   \n",
      "63868  \\\"\\\"\\\"Training Your First Classification Model...   \n",
      "63870  \\\"\\\"\\\"Training Your First Classification Model...   \n",
      "63871  \\\"\\\"\\\"Train FCN on Pascal VOC Dataset || =====...   \n",
      "63916  \\\"\\\"\\\"8. Finetune a pretrained detection model...   \n",
      "63942  Try fine-tuning other SOTA video models on you...   \n",
      "63954  Try fine-tuning these SOTA video models on you...   \n",
      "65496  (TODO: mkusumoto) Test finetuning in recomputa...   \n",
      "66838  \\\"\\\"\\\" || Tune's Scikit Learn Adapters || ====...   \n",
      "66937  \\\"\\\"\\\" || Hyperparameter tuning with Ray Tune ...   \n",
      "67423         TODO: Perhaps I'll add an autotuning mode.   \n",
      "\n",
      "                                                    link  \n",
      "383    https://github.com/munagekar/nnpso/commit/701f...  \n",
      "389    https://github.com/munagekar/nnpso/commit/c9b3...  \n",
      "946    https://github.com/sshleifer/object_detection_...  \n",
      "2394   https://github.com/Angzz/panoptic-fpn-gluon/co...  \n",
      "2688   https://github.com/Erotemic/netharn/commit/ef9...  \n",
      "2690   https://github.com/Erotemic/netharn/commit/ef9...  \n",
      "2785   https://github.com/isikdogan/deep_learning_tut...  \n",
      "3138   https://github.com/roberthangu/snn_object_reco...  \n",
      "3421   https://github.com/fpaupier/tensorflow-serving...  \n",
      "4263   https://github.com/jason718/game-feature-learn...  \n",
      "4735   https://github.com/simonfqy/PADME/commit/4f361...  \n",
      "4768   https://github.com/simonfqy/PADME/commit/2cb67...  \n",
      "4771   https://github.com/simonfqy/PADME/commit/90a88...  \n",
      "4951   https://github.com/davidhaohanli/Abnormal-Beha...  \n",
      "4955   https://github.com/davidhaohanli/Abnormal-Beha...  \n",
      "5728   https://github.com/annomator/annomator_1.0/com...  \n",
      "10452  https://github.com/dirty-cat/dirty_cat/commit/...  \n",
      "12815  https://github.com/Octavian-ai/mac-graph/commi...  \n",
      "12994  https://github.com/HewlettPackard/dlcookbook-d...  \n",
      "15950  https://github.com/ShuangLI59/person_search/co...  \n",
      "16318  https://github.com/brightmart/bert_language_un...  \n",
      "16321  https://github.com/brightmart/bert_language_un...  \n",
      "16324  https://github.com/brightmart/bert_language_un...  \n",
      "16927  https://github.com/AKSHAYUBHAT/DeepVideoAnalyt...  \n",
      "16957  https://github.com/AKSHAYUBHAT/DeepVideoAnalyt...  \n",
      "21015  https://github.com/kscompsci/TAKING-IDENTITY-I...  \n",
      "22204  https://github.com/ShreyAmbesh/Traffic-Rule-Vi...  \n",
      "22242  https://github.com/ambakick/Person-Detection-a...  \n",
      "25757  https://github.com/yoshida-lab/XenonPy/commit/...  \n",
      "25865  https://github.com/csc-training/intro-to-dl/co...  \n",
      "27973  https://github.com/IBM/MAX-Object-Detector/com...  \n",
      "29561  https://github.com/google-research/google-rese...  \n",
      "33030  https://github.com/apacha/Mensural-Detector/co...  \n",
      "36135  https://github.com/scikit-optimize/scikit-opti...  \n",
      "42378  https://github.com/feedly/transfer-nlp/commit/...  \n",
      "42649  https://github.com/online-ml/river/commit/4d2a...  \n",
      "44833  https://github.com/explosion/thinc/commit/0e2d...  \n",
      "56132  https://github.com/cong/ros_tensorflow/commit/...  \n",
      "58587  https://github.com/chrislit/abydos/commit/6da0...  \n",
      "58619  https://github.com/chrislit/abydos/commit/0186...  \n",
      "60980  https://github.com/scikit-learn/scikit-learn/c...  \n",
      "62266  https://github.com/biolab/orange3/commit/5cf6b...  \n",
      "63083  https://github.com/Tencent/PocketFlow/commit/8...  \n",
      "63090  https://github.com/Tencent/PocketFlow/commit/8...  \n",
      "63868  https://github.com/dmlc/gluon-cv/commit/e7389b...  \n",
      "63870  https://github.com/dmlc/gluon-cv/commit/e7389b...  \n",
      "63871  https://github.com/dmlc/gluon-cv/commit/f1fd98...  \n",
      "63916  https://github.com/dmlc/gluon-cv/commit/1868c5...  \n",
      "63942  https://github.com/dmlc/gluon-cv/commit/c03023...  \n",
      "63954  https://github.com/dmlc/gluon-cv/commit/dce2f2...  \n",
      "65496  https://github.com/chainer/chainer/commit/d518...  \n",
      "66838  https://github.com/ray-project/ray/commit/139d...  \n",
      "66937  https://github.com/ray-project/ray/commit/efa1...  \n",
      "67423  https://github.com/NervanaSystems/neon/commit/...  \n",
      "Dataframe for 'feature':\n",
      "                  repo                                           filename  \\\n",
      "6      ealcobaca/pymfe                                pymfe/complexity.py   \n",
      "8      ealcobaca/pymfe                                pymfe/complexity.py   \n",
      "9      ealcobaca/pymfe                                pymfe/complexity.py   \n",
      "12     ealcobaca/pymfe                                pymfe/complexity.py   \n",
      "14     ealcobaca/pymfe                                pymfe/complexity.py   \n",
      "...                ...                                                ...   \n",
      "65700  chainer/chainer                 chainer/datasets/pickle_dataset.py   \n",
      "66264    clips/pattern    pattern/server/cherrypy/_cpcompat_subprocess.py   \n",
      "66271    clips/pattern                pattern/server/cherrypy/_cptools.py   \n",
      "66838  ray-project/ray         doc/source/tune/_tutorials/tune-sklearn.py   \n",
      "68454  chainer/chainer  examples/static_graph_optimizations/test_stati...   \n",
      "\n",
      "                                         Commit  \\\n",
      "6      70e58ce4494a521fabb30b96657629b9542b63f1   \n",
      "8      70e58ce4494a521fabb30b96657629b9542b63f1   \n",
      "9      2d382ec699f34b2b76c1b4be235f4fab426ba594   \n",
      "12     8354becab0e8b59bb7f39fe792b9fe5a08399b7b   \n",
      "14     8354becab0e8b59bb7f39fe792b9fe5a08399b7b   \n",
      "...                                         ...   \n",
      "65700  cd8291bd7fe6bcac16167a4fe0d128932d46175d   \n",
      "66264  5e62f02ecc9dea0add2f81d041df889c67e49ec8   \n",
      "66271  5e62f02ecc9dea0add2f81d041df889c67e49ec8   \n",
      "66838  139d21e068585fc2eb4b79808c3477347eb3dafe   \n",
      "68454  4b9cbf779b6918b8f5710aeb7965ede6e9eb1864   \n",
      "\n",
      "                                                 Comment  \\\n",
      "6      TODO: This feature seems to be a normalized ve...   \n",
      "8      TODO: If the categorical attributes are consid...   \n",
      "9      TODO: If the categorical attributes are consid...   \n",
      "12     TODO: This feature seems to be a normalized ve...   \n",
      "14     TODO: If the categorical attributes are consid...   \n",
      "...                                                  ...   \n",
      "65700             TODO: Avoid using undocumented feature   \n",
      "66264  r\\\"\\\"\\\"subprocess - Subprocesses with accessib...   \n",
      "66271  \\\"\\\"\\\"CherryPy tools. A \\\"tool\\\" is any helper...   \n",
      "66838  \\\"\\\"\\\" || Tune's Scikit Learn Adapters || ====...   \n",
      "68454  todo: Optimizers do not yet support static gra...   \n",
      "\n",
      "                                                    link  \n",
      "6      https://github.com/ealcobaca/pymfe/commit/70e5...  \n",
      "8      https://github.com/ealcobaca/pymfe/commit/70e5...  \n",
      "9      https://github.com/ealcobaca/pymfe/commit/2d38...  \n",
      "12     https://github.com/ealcobaca/pymfe/commit/8354...  \n",
      "14     https://github.com/ealcobaca/pymfe/commit/8354...  \n",
      "...                                                  ...  \n",
      "65700  https://github.com/chainer/chainer/commit/cd82...  \n",
      "66264  https://github.com/clips/pattern/commit/5e62f0...  \n",
      "66271  https://github.com/clips/pattern/commit/5e62f0...  \n",
      "66838  https://github.com/ray-project/ray/commit/139d...  \n",
      "68454  https://github.com/chainer/chainer/commit/4b9c...  \n",
      "\n",
      "[582 rows x 5 columns]\n",
      "Dataframe for 'para':\n",
      "                                                  repo  \\\n",
      "155                 NickleDave/hybrid-vocal-classifier   \n",
      "295    tommytracey/DeepRL-P3-Collaboration-Competition   \n",
      "468                                   rstemmer/musicdb   \n",
      "471                                   rstemmer/musicdb   \n",
      "562                             shahrukhqasim/TIES-2.0   \n",
      "...                                                ...   \n",
      "68408                                  chainer/chainer   \n",
      "68489                                  chainer/chainer   \n",
      "68583                                  chainer/chainer   \n",
      "68589                                  chainer/chainer   \n",
      "68797                               PaddlePaddle/ERNIE   \n",
      "\n",
      "                                                filename  \\\n",
      "155                                hvc/featureextract.py   \n",
      "295                    python/unityagents/environment.py   \n",
      "468                                     mdbapi/extern.py   \n",
      "471                                     mdbapi/extern.py   \n",
      "562                         python/models/basic_model.py   \n",
      "...                                                  ...   \n",
      "68408                                    chainer/link.py   \n",
      "68489  chainer/graph_optimizations/static_graph_utili...   \n",
      "68583        chainer/graph_optimizations/static_graph.py   \n",
      "68589        chainer/graph_optimizations/static_graph.py   \n",
      "68797                            ernie/modeling_ernie.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "155    c03b461dc2c606e394ecdb1109c78e38ef8b9801   \n",
      "295    0fca20fdd859be224d0c2ca9ba5f3baeb206c445   \n",
      "468    b88a22c4d2ecbe4c09517384815a8831fbbfca9a   \n",
      "471    b88a22c4d2ecbe4c09517384815a8831fbbfca9a   \n",
      "562    8daa8c380f58759ebd59daf1304bf40eb40371dd   \n",
      "...                                         ...   \n",
      "68408  2b3d5ca54312c5da640e1ff6844c72b57e3166b9   \n",
      "68489  e5f605d06db1b31bcb82991f5656c173c35522a1   \n",
      "68583  aef64159d655c7196f8227f20afb1d1a8b4598b7   \n",
      "68589  aef64159d655c7196f8227f20afb1d1a8b4598b7   \n",
      "68797  defa38e7c4e7da8c05626569f17f80eac518a088   \n",
      "\n",
      "                                                 Comment  \\\n",
      "155    if seg params not defined in todo; revert to d...   \n",
      "295    TODO : think of a better way to expose the aca...   \n",
      "468    \\\"\\\"\\\" || This class handles the upload of mus...   \n",
      "471    2.: Start the copy-process TODO: Make it in pa...   \n",
      "562                         TODO: Fix training parameter   \n",
      "...                                                  ...   \n",
      "68408  tuple() here is needed to avoid conflicts with...   \n",
      "68489  todo: consider only marking a variable if it i...   \n",
      "68583  todo: Add a debug mode (perhaps enabled by def...   \n",
      "68589  in params_list. This is needed so that we can ...   \n",
      "68797  F.io.load_program_state(param_path) #buggy in ...   \n",
      "\n",
      "                                                    link  \n",
      "155    https://github.com/NickleDave/hybrid-vocal-cla...  \n",
      "295    https://github.com/tommytracey/DeepRL-P3-Colla...  \n",
      "468    https://github.com/rstemmer/musicdb/commit/b88...  \n",
      "471    https://github.com/rstemmer/musicdb/commit/b88...  \n",
      "562    https://github.com/shahrukhqasim/TIES-2.0/comm...  \n",
      "...                                                  ...  \n",
      "68408  https://github.com/chainer/chainer/commit/2b3d...  \n",
      "68489  https://github.com/chainer/chainer/commit/e5f6...  \n",
      "68583  https://github.com/chainer/chainer/commit/aef6...  \n",
      "68589  https://github.com/chainer/chainer/commit/aef6...  \n",
      "68797  https://github.com/PaddlePaddle/ERNIE/commit/d...  \n",
      "\n",
      "[1781 rows x 5 columns]\n",
      "Dataframe for 'word count':\n",
      "                           repo                                  filename  \\\n",
      "10459       dirty-cat/dirty_cat  dirty_cat/gamma_poisson_factorization.py   \n",
      "21843  undertheseanlp/sentiment               labs/document_clustering.py   \n",
      "52372  RaRe-Technologies/gensim          src/gensim/corpora/textcorpus.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "10459  b61398b0ccbbe8abe92dd05cc21b0a25d503773a   \n",
      "21843  0b678859b4044297714d6c8f11c41ed74475d403   \n",
      "52372  956fc79db9fcfef18a3eb1dfa96df824bb220a47   \n",
      "\n",
      "                                                 Comment  \\\n",
      "10459            Init a word counts vectorizer if needed   \n",
      "21843  \\\"\\\"\\\" || ====================================...   \n",
      "52372  \\\"\\\"\\\" ||  || The original idea of Gensim was ...   \n",
      "\n",
      "                                                    link  \n",
      "10459  https://github.com/dirty-cat/dirty_cat/commit/...  \n",
      "21843  https://github.com/undertheseanlp/sentiment/co...  \n",
      "52372  https://github.com/RaRe-Technologies/gensim/co...  \n",
      "Dataframe for 'lemmatize':\n",
      "                  repo                filename  \\\n",
      "16049  alvations/pywsd                 lesk.py   \n",
      "16059  alvations/pywsd          pywsd/utils.py   \n",
      "49412    Rostlab/nalaf  nalaf/download_data.py   \n",
      "58913  explosion/spaCy       spacy/language.py   \n",
      "58916  explosion/spaCy       spacy/language.py   \n",
      "58918  explosion/spaCy       spacy/language.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "16049  970ed2b288d3d82f880ab8d4ae63c233211d8b3d   \n",
      "16059  802c094aa3b0b97f9fa8d32d8f9379d5cb0329e3   \n",
      "49412  13bf86d5973aa24fc75f93b73571308700bc94c3   \n",
      "58913  e5d9eaf79c5c935b4553c5ede31de383571fe0dc   \n",
      "58916  0cddb0dbe9b9af85bb017393ec017a16f2acdaec   \n",
      "58918  e257e66ab908e289b64976558f843956376923d5   \n",
      "\n",
      "                                                 Comment  \\\n",
      "16049  ''' || #TODO: various stem \\/ lemmatizers. || ...   \n",
      "16059  ''' || #TODO: various stem \\/ lemmatizers. || ...   \n",
      "49412  TODO download non-packaged [biolemmatizer-core...   \n",
      "58913  TODO: Will be replaced when the lemmatizer bec...   \n",
      "58916  TODO: Will be replaced when the lemmatizer bec...   \n",
      "58918  TODO: Will be replaced when the lemmatizer bec...   \n",
      "\n",
      "                                                    link  \n",
      "16049  https://github.com/alvations/pywsd/commit/970e...  \n",
      "16059  https://github.com/alvations/pywsd/commit/802c...  \n",
      "49412  https://github.com/Rostlab/nalaf/commit/13bf86...  \n",
      "58913  https://github.com/explosion/spaCy/commit/e5d9...  \n",
      "58916  https://github.com/explosion/spaCy/commit/0cdd...  \n",
      "58918  https://github.com/explosion/spaCy/commit/e257...  \n",
      "Dataframe for 'word':\n",
      "                                        repo  \\\n",
      "486                         rstemmer/musicdb   \n",
      "841         sshleifer/object_detection_kitti   \n",
      "886         sshleifer/object_detection_kitti   \n",
      "1361                          Koziev/chatbot   \n",
      "1392                          Koziev/chatbot   \n",
      "...                                      ...   \n",
      "67087                        ray-project/ray   \n",
      "67298  scikit-learn-contrib/imbalanced-learn   \n",
      "68435                        chainer/chainer   \n",
      "68563                        chainer/chainer   \n",
      "68645                        chainer/chainer   \n",
      "\n",
      "                                                filename  \\\n",
      "486                                       lib/icecast.py   \n",
      "841                                    swivel/wordsim.py   \n",
      "886                                         wiki_data.py   \n",
      "1361                    PyModels/bot/nn_person_change.py   \n",
      "1392            PyModels/bot/simple_answering_machine.py   \n",
      "...                                                  ...   \n",
      "67087                    python/ray/operator/operator.py   \n",
      "67298           unbalanced_dataset/unbalanced_dataset.py   \n",
      "68435              examples/image_captioning/datasets.py   \n",
      "68563  examples/static_graph_optimizations/ptb/train_...   \n",
      "68645        chainer/graph_optimizations/static_graph.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "486    cad7ec358175ee63ecb9c474c59a5fc39e2283e0   \n",
      "841    f3a2f63b734e73dfb72e5d82719b03a0e93baba8   \n",
      "886    124a501db1fe2880c92381c747467dc87f546a15   \n",
      "1361   fe5467f509758bf233df626e758117b25a84af94   \n",
      "1392   b43f8304e98f62c85dd4d3eb1a8eaba40a4804e4   \n",
      "...                                         ...   \n",
      "67087  11ce1dc743b24f5472d6773f997ded20ba001d50   \n",
      "67298  50484c24505c5c31dd7aba1d38155eab0c1adad7   \n",
      "68435  9058c34d29a86967c96928b6a8e2f4225f6a228c   \n",
      "68563  191e2741244360e1083b559164ab5afa92f33ee1   \n",
      "68645  22c5d798e356e820acc9687225e306031a213679   \n",
      "\n",
      "                                                 Comment  \\\n",
      "486    \\\"\\\"\\\" || This module implements the interface...   \n",
      "841    \\\"\\\"\\\"Computes Spearman's rho with respect to ...   \n",
      "886    \\\"\\\"\\\"Loads the WikiQuestions dataset. ||  || ...   \n",
      "1361   todo \\u0441\\u043E\\u0437\\u0434\\u0430\\u043D\\u043...   \n",
      "1392   TODO: \\u0432\\u043E\\u0437\\u043C\\u043E\\u0436\\u04...   \n",
      "...                                                  ...   \n",
      "67087  TODO: Add support for user-specified redis por...   \n",
      "67298  \\\"\\\"\\\" || UnbalancedDataset || ===============...   \n",
      "68435  This vocabulary is needed in order to convert ...   \n",
      "68563  assert isinstance(words_labels; list) #fixme: ...   \n",
      "68645           todo: set in initializer as keyword arg?   \n",
      "\n",
      "                                                    link  \n",
      "486    https://github.com/rstemmer/musicdb/commit/cad...  \n",
      "841    https://github.com/sshleifer/object_detection_...  \n",
      "886    https://github.com/sshleifer/object_detection_...  \n",
      "1361   https://github.com/Koziev/chatbot/commit/fe546...  \n",
      "1392   https://github.com/Koziev/chatbot/commit/b43f8...  \n",
      "...                                                  ...  \n",
      "67087  https://github.com/ray-project/ray/commit/11ce...  \n",
      "67298  https://github.com/scikit-learn-contrib/imbala...  \n",
      "68435  https://github.com/chainer/chainer/commit/9058...  \n",
      "68563  https://github.com/chainer/chainer/commit/191e...  \n",
      "68645  https://github.com/chainer/chainer/commit/22c5...  \n",
      "\n",
      "[439 rows x 5 columns]\n",
      "Dataframe for 'lemma':\n",
      "                         repo                           filename  \\\n",
      "10899          mozilla/bugbug                             run.py   \n",
      "15598            lovit/soynlp    soynlp/lemmatizer/_predicate.py   \n",
      "15601            lovit/soynlp         soynlp/predicator/_eomi.py   \n",
      "16049         alvations/pywsd                            lesk.py   \n",
      "16059         alvations/pywsd                     pywsd/utils.py   \n",
      "21299        dlt-rilmta/emtsv                          config.py   \n",
      "21300        dlt-rilmta/emtsv                          config.py   \n",
      "24181      swabhs/open-sesame                 sesame/targetid.py   \n",
      "25661       nert-nlp/streusle                   sst2conllulex.py   \n",
      "25673       nert-nlp/streusle                          syncud.py   \n",
      "25687       nert-nlp/streusle              releaseutil/syncud.py   \n",
      "27885       quadflor/Quadflor     Code/tests/test_integration.py   \n",
      "28001         ncbi-nlp/NegBio  tests/negbio/ngrex/test_parser.py   \n",
      "28002         ncbi-nlp/NegBio  tests/negbio/ngrex/test_parser.py   \n",
      "28003         ncbi-nlp/NegBio  tests/negbio/ngrex/test_parser.py   \n",
      "31972     bjascob/LemmInflect     lemminflect/core/Lemmatizer.py   \n",
      "37904       summanlp/textrank          textrank/textrank_word.py   \n",
      "46126               cltk/cltk             cltk/corpus/readers.py   \n",
      "46294               cltk/cltk    src/cltkv1/wordnet/processes.py   \n",
      "49412           Rostlab/nalaf             nalaf/download_data.py   \n",
      "51149  mideind/GreynirPackage           src/reynir/simpletree.py   \n",
      "54744          proycon/pynlpl                clients/cornetto.py   \n",
      "58913         explosion/spaCy                  spacy/language.py   \n",
      "58916         explosion/spaCy                  spacy/language.py   \n",
      "58918         explosion/spaCy                  spacy/language.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "10899  a2533876feb2dc5065959b6917af93465d5eb3cf   \n",
      "15598  f50ea51407e9996e54d935b79eb0ae9ba6dcba91   \n",
      "15601  24ff114ddb663daf5fad2d110c2ef6e7a243b586   \n",
      "16049  970ed2b288d3d82f880ab8d4ae63c233211d8b3d   \n",
      "16059  802c094aa3b0b97f9fa8d32d8f9379d5cb0329e3   \n",
      "21299  a84b577eabf8f3febeb7c7cd7c6dd8a201a8eac6   \n",
      "21300  a84b577eabf8f3febeb7c7cd7c6dd8a201a8eac6   \n",
      "24181  35732f46e5246f2badaf1eb8e44a21e35acb64aa   \n",
      "25661  b94ef47c8e33046a54de9e3a4981df9da8c7c7ac   \n",
      "25673  8ddc2cd14090cc5b01bb22230c8e6e98c72ad171   \n",
      "25687  4fb1067335124a8706cef2f4a89798f37403902e   \n",
      "27885  ac8b358a9a99f5eb91ce61b6085a90897d9dec8b   \n",
      "28001  78f08f839a129cc2d1a8acc89f08b384a10948eb   \n",
      "28002  78f08f839a129cc2d1a8acc89f08b384a10948eb   \n",
      "28003  78f08f839a129cc2d1a8acc89f08b384a10948eb   \n",
      "31972  a31162b650411f25fb883f4084a620c23339839c   \n",
      "37904  154d7a7f63025c573fef9cd875e05b7f260f8233   \n",
      "46126  320e810184204d9171e683241adea4c5c1c73a04   \n",
      "46294  ac4a80caa7b438460381a22975cf9c96059b42f4   \n",
      "49412  13bf86d5973aa24fc75f93b73571308700bc94c3   \n",
      "51149  81d77879fb15789bd5e67947c96430a98f8602eb   \n",
      "54744  c16dd550369505d18e2a1531fb5fd564d29c5c38   \n",
      "58913  e5d9eaf79c5c935b4553c5ede31de383571fe0dc   \n",
      "58916  0cddb0dbe9b9af85bb017393ec017a16f2acdaec   \n",
      "58918  e257e66ab908e289b64976558f843956376923d5   \n",
      "\n",
      "                                                 Comment  \\\n",
      "10899  TODO: Perform lemmatization and tokenization v...   \n",
      "15598             TODO: evaluation lemma of (stem; eomi)   \n",
      "15601                                    TODO with lemma   \n",
      "16049  ''' || #TODO: various stem \\/ lemmatizers. || ...   \n",
      "16059  ''' || #TODO: various stem \\/ lemmatizers. || ...   \n",
      "21299  \\\"\\\"\\\" || Disable OBSOLETE emDep instance || #...   \n",
      "21300  \\\"\\\"\\\" || Disable OBSOLETE emDep instance || #...   \n",
      "24181  Hack: replace with anything the lemma is seen ...   \n",
      "25661  TODO: if data[\\\"lemmas\\\"]: assert data[\\\"lemma...   \n",
      "25673  NOTE: lemmas updated in column 3 need to be ma...   \n",
      "25687  NOTE: lemmas updated in column 3 need to be ma...   \n",
      "27885  TODO: consider: this is removed by lemmatization.   \n",
      "28001  _test_yacc(\\\"{lemma:\\/xxx\\/} <{dependency:\\/nm...   \n",
      "28002  _test_yacc(\\\"{lemma:\\/xxx\\/} >{dependency:\\/nm...   \n",
      "28003  _test_yacc(\\\"{lemma:\\/xxx\\/} >{dependency:\\/nm...   \n",
      "31972  Get the lemma(s) for the upos.  Use OOV rules ...   \n",
      "37904  TODO: Aca se puede cambiar; para que la ventan...   \n",
      "46126  TODO and add:  ['latin_text_perseus'; 'latin_t...   \n",
      "46294                 TODO: map CLTK lemmas to WN lemmas   \n",
      "49412  TODO download non-packaged [biolemmatizer-core...   \n",
      "51149           Hack: Set the lemma of the last terminal   \n",
      "54744  \\\"\\\"\\\" || ------------------------------------...   \n",
      "58913  TODO: Will be replaced when the lemmatizer bec...   \n",
      "58916  TODO: Will be replaced when the lemmatizer bec...   \n",
      "58918  TODO: Will be replaced when the lemmatizer bec...   \n",
      "\n",
      "                                                    link  \n",
      "10899  https://github.com/mozilla/bugbug/commit/a2533...  \n",
      "15598  https://github.com/lovit/soynlp/commit/f50ea51...  \n",
      "15601  https://github.com/lovit/soynlp/commit/24ff114...  \n",
      "16049  https://github.com/alvations/pywsd/commit/970e...  \n",
      "16059  https://github.com/alvations/pywsd/commit/802c...  \n",
      "21299  https://github.com/dlt-rilmta/emtsv/commit/a84...  \n",
      "21300  https://github.com/dlt-rilmta/emtsv/commit/a84...  \n",
      "24181  https://github.com/swabhs/open-sesame/commit/3...  \n",
      "25661  https://github.com/nert-nlp/streusle/commit/b9...  \n",
      "25673  https://github.com/nert-nlp/streusle/commit/8d...  \n",
      "25687  https://github.com/nert-nlp/streusle/commit/4f...  \n",
      "27885  https://github.com/quadflor/Quadflor/commit/ac...  \n",
      "28001  https://github.com/ncbi-nlp/NegBio/commit/78f0...  \n",
      "28002  https://github.com/ncbi-nlp/NegBio/commit/78f0...  \n",
      "28003  https://github.com/ncbi-nlp/NegBio/commit/78f0...  \n",
      "31972  https://github.com/bjascob/LemmInflect/commit/...  \n",
      "37904  https://github.com/summanlp/textrank/commit/15...  \n",
      "46126  https://github.com/cltk/cltk/commit/320e810184...  \n",
      "46294  https://github.com/cltk/cltk/commit/ac4a80caa7...  \n",
      "49412  https://github.com/Rostlab/nalaf/commit/13bf86...  \n",
      "51149  https://github.com/mideind/GreynirPackage/comm...  \n",
      "54744  https://github.com/proycon/pynlpl/commit/c16dd...  \n",
      "58913  https://github.com/explosion/spaCy/commit/e5d9...  \n",
      "58916  https://github.com/explosion/spaCy/commit/0cdd...  \n",
      "58918  https://github.com/explosion/spaCy/commit/e257...  \n",
      "Dataframe for 'tokens':\n",
      "                          repo  \\\n",
      "117      lazybootsafe/AI2Match   \n",
      "124      lazybootsafe/AI2Match   \n",
      "1144        roscisz/TensorHive   \n",
      "1943   arne-cl/discoursegraphs   \n",
      "3814      yuantiku/fairseq-gec   \n",
      "...                        ...   \n",
      "63978        snipsco/snips-nlu   \n",
      "66052         allenai/allennlp   \n",
      "66053         allenai/allennlp   \n",
      "66055         allenai/allennlp   \n",
      "66067         allenai/allennlp   \n",
      "\n",
      "                                                filename  \\\n",
      "117    match/chnlp/TextBrewer/examples/cmrc2018_examp...   \n",
      "124    match/chnlp/TextBrewer/examples/mnli_example/p...   \n",
      "1144   tensorhive/controllers/user/DeleteUserControll...   \n",
      "1943          src/discoursegraphs/readwrite/exportxml.py   \n",
      "3814            fairseq/data/round_robin_zip_datasets.py   \n",
      "...                                                  ...   \n",
      "63978            snips_nlu/slot_filler/features_utils.py   \n",
      "66052  allennlp/data/dataset_readers/masked_language_...   \n",
      "66053  allennlp/data/dataset_readers/masked_language_...   \n",
      "66055     allennlp/data/dataset_readers/next_token_lm.py   \n",
      "66067      allennlp/modules/token_embedders/embedding.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "117    20e1096901f091737be28b5281496c824b2b2559   \n",
      "124    20e1096901f091737be28b5281496c824b2b2559   \n",
      "1144   495426b14289273e545f11d4623c6e300a9743f4   \n",
      "1943   5ea8774e2476a4967fae47e6b641eb9e71e9d5d0   \n",
      "3814   86d46970c4e0715ebda7138d1853474c5e023fff   \n",
      "...                                         ...   \n",
      "63978  09fb53048b54924127585ddf88131d8ba251ec71   \n",
      "66052  bb1b1c6e27b273a66135d02a04232835d5bfc3ca   \n",
      "66053  bb1b1c6e27b273a66135d02a04232835d5bfc3ca   \n",
      "66055  bb1b1c6e27b273a66135d02a04232835d5bfc3ca   \n",
      "66067  1e923fd19c8eda2719c150e9716eeb1374a049bb   \n",
      "\n",
      "                                                 Comment  \\\n",
      "117    Add additional embeddings for special tokens i...   \n",
      "124    Add additional embeddings for special tokens i...   \n",
      "1144   FIXME Since we use JWT; there's no easy way to...   \n",
      "1943   ''' || WARNING: academic ad-hoc code to export...   \n",
      "3814   TODO should max_tokens be used independently f...   \n",
      "...                                                  ...   \n",
      "63978  TODO: if possible avoid looping on the tokens ...   \n",
      "66052        temporary hack to not to add special tokens   \n",
      "66053  to be indexed with PretrainedTokenIndexer. It ...   \n",
      "66055  to be indexed with PretrainedTokenIndexer. It ...   \n",
      "66067  TODO: having to pass tokens here is SUPER gros...   \n",
      "\n",
      "                                                    link  \n",
      "117    https://github.com/lazybootsafe/AI2Match/commi...  \n",
      "124    https://github.com/lazybootsafe/AI2Match/commi...  \n",
      "1144   https://github.com/roscisz/TensorHive/commit/4...  \n",
      "1943   https://github.com/arne-cl/discoursegraphs/com...  \n",
      "3814   https://github.com/yuantiku/fairseq-gec/commit...  \n",
      "...                                                  ...  \n",
      "63978  https://github.com/snipsco/snips-nlu/commit/09...  \n",
      "66052  https://github.com/allenai/allennlp/commit/bb1...  \n",
      "66053  https://github.com/allenai/allennlp/commit/bb1...  \n",
      "66055  https://github.com/allenai/allennlp/commit/bb1...  \n",
      "66067  https://github.com/allenai/allennlp/commit/1e9...  \n",
      "\n",
      "[119 rows x 5 columns]\n",
      "Dataframe for 'encoding':\n",
      "                      repo                                           filename  \\\n",
      "1699        iamvon/viBlind  AI_Team/API/Blind_Vision_Backend/env-Backend/l...   \n",
      "1723        iamvon/viBlind  AI_Team/API/Blind_Vision_Backend/env-Backend/l...   \n",
      "2230   andreasvc/disco-dop                                  fragmentseeker.py   \n",
      "2765      Erotemic/netharn                 netharn/initializers/functional.py   \n",
      "2769      Erotemic/netharn             netharn/initializers/_nx_extensions.py   \n",
      "...                    ...                                                ...   \n",
      "61591         delzac/cntkx                          layers/models/language.py   \n",
      "62716       biolab/orange3              Orange/widgets/data/owpythonscript.py   \n",
      "63198     RasaHQ/rasa_core                    rasa_core/training/generator.py   \n",
      "63199     RasaHQ/rasa_core                    rasa_core/training/generator.py   \n",
      "66154        clips/pattern                  pattern/web/soup/BeautifulSoup.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "1699   bc7d672875dcce2cc6f2729ffea044e3d2b80567   \n",
      "1723   bc7d672875dcce2cc6f2729ffea044e3d2b80567   \n",
      "2230   14137f4a90b12b0b86a21c2fc92db3f007b658c9   \n",
      "2765   8f77a3a1b79c76ffae839b671acdcfc2479c1a8d   \n",
      "2769   62c5dd9e126e65d81ea4c5c624aecd3c2276e1ed   \n",
      "...                                         ...   \n",
      "61591  dbd6190a96b8de78eaa7d973fa497b65889abe22   \n",
      "62716  b535452389d79b579dd499374bab66b4ecc87f1f   \n",
      "63198  1689c64e6c8a6b0eb7f48329517dcf4321a41459   \n",
      "63199  1689c64e6c8a6b0eb7f48329517dcf4321a41459   \n",
      "66154  6a6bc557626b1a0fe8115f44b364139379b28905   \n",
      "\n",
      "                                                 Comment  \\\n",
      "1699   language name is needed to interpret the given...   \n",
      "1723   encoding after initialization.  The test for p...   \n",
      "2230   FIXME: detect corpus reading errors here (e.g....   \n",
      "2765    TODO: token encoding scheme where subdirectories   \n",
      "2769    TODO: token encoding scheme where subdirectories   \n",
      "...                                                  ...   \n",
      "61591  TODO: Check if weight is tied to encoding embe...   \n",
      "62716               TODO: use `tokenize.detect_encoding`   \n",
      "63198    TODO don't like that: encoding after each event   \n",
      "63199  TODO might not work with label_featurizer enco...   \n",
      "66154  \\\"\\\"\\\"Beautiful Soup || Elixir and Tonic || \\\"...   \n",
      "\n",
      "                                                    link  \n",
      "1699   https://github.com/iamvon/viBlind/commit/bc7d6...  \n",
      "1723   https://github.com/iamvon/viBlind/commit/bc7d6...  \n",
      "2230   https://github.com/andreasvc/disco-dop/commit/...  \n",
      "2765   https://github.com/Erotemic/netharn/commit/8f7...  \n",
      "2769   https://github.com/Erotemic/netharn/commit/62c...  \n",
      "...                                                  ...  \n",
      "61591  https://github.com/delzac/cntkx/commit/dbd6190...  \n",
      "62716  https://github.com/biolab/orange3/commit/b5354...  \n",
      "63198  https://github.com/RasaHQ/rasa_core/commit/168...  \n",
      "63199  https://github.com/RasaHQ/rasa_core/commit/168...  \n",
      "66154  https://github.com/clips/pattern/commit/6a6bc5...  \n",
      "\n",
      "[97 rows x 5 columns]\n",
      "Dataframe for 'embading':\n",
      "Empty DataFrame\n",
      "Columns: [repo, filename, Commit, Comment, link]\n",
      "Index: []\n",
      "Dataframe for 'span':\n",
      "                                                    repo  \\\n",
      "113                                lazybootsafe/AI2Match   \n",
      "1943                             arne-cl/discoursegraphs   \n",
      "5033                                  jkkummerfeld/slate   \n",
      "5043                                  jkkummerfeld/slate   \n",
      "6529   mesnico/learning-relationship-aware-visual-fea...   \n",
      "8116                                     NLPatVCU/medaCy   \n",
      "8119                                     NLPatVCU/medaCy   \n",
      "8180                                     NLPatVCU/medaCy   \n",
      "10967                                     mozilla/bugbug   \n",
      "12217                        persephone-tools/persephone   \n",
      "22688                                davidsbatista/BREDS   \n",
      "22696                                davidsbatista/BREDS   \n",
      "24169                                 swabhs/open-sesame   \n",
      "26972                                     vecto-ai/vecto   \n",
      "28210                                 delph-in/pydelphin   \n",
      "29695                  pandas-profiling/pandas-profiling   \n",
      "31636                                      d2l-ai/d2l-zh   \n",
      "32776                                 proycon/foliatools   \n",
      "33257                               HazyResearch/fonduer   \n",
      "40871                             plasticityai/magnitude   \n",
      "40872                             plasticityai/magnitude   \n",
      "45132                             chartbeat-labs/textacy   \n",
      "48148                         ecohealthalliance/EpiTator   \n",
      "48159                         ecohealthalliance/EpiTator   \n",
      "48164                         ecohealthalliance/EpiTator   \n",
      "49323                                      Rostlab/nalaf   \n",
      "49695                      DependableSystemsLab/TensorFI   \n",
      "49900                                    delph-in/pydmrs   \n",
      "50545                          ResponsiblyAI/responsibly   \n",
      "50564                          ResponsiblyAI/responsibly   \n",
      "50566                          ResponsiblyAI/responsibly   \n",
      "50567                          ResponsiblyAI/responsibly   \n",
      "50995                             mideind/GreynirCorrect   \n",
      "51009                             mideind/GreynirCorrect   \n",
      "51015                             mideind/GreynirCorrect   \n",
      "51021                             mideind/GreynirCorrect   \n",
      "51022                             mideind/GreynirCorrect   \n",
      "51027                             mideind/GreynirCorrect   \n",
      "54816                                     proycon/pynlpl   \n",
      "54827                                     proycon/pynlpl   \n",
      "54831                                     proycon/pynlpl   \n",
      "62074                                    proycon/foliapy   \n",
      "62084                                    proycon/foliapy   \n",
      "62088                                    proycon/foliapy   \n",
      "65798                                   allenai/allennlp   \n",
      "65799                                   allenai/allennlp   \n",
      "66207                                      clips/pattern   \n",
      "\n",
      "                                                filename  \\\n",
      "113    match/chnlp/TextBrewer/examples/cmrc2018_examp...   \n",
      "1943          src/discoursegraphs/readwrite/exportxml.py   \n",
      "5033                                         src/data.py   \n",
      "5043                                         src/data.py   \n",
      "6529    networkx/networkx/algorithms/tree/recognition.py   \n",
      "8116   medacy/pipeline_components/annotation/gold_ann...   \n",
      "8119   medacy/pipeline_components/metamap/metamap_com...   \n",
      "8180   medacy/pipeline_components/feature_overlayers/...   \n",
      "10967       scripts/test_scheduling_history_retriever.py   \n",
      "12217                          persephone/datasets/na.py   \n",
      "22688                   automatic-evaluation/evaluate.py   \n",
      "22696                   automatic-evaluation/evaluate.py   \n",
      "24169                                     src/conll09.py   \n",
      "26972                          vecto/corpus/iterators.py   \n",
      "28210                                     delphin/lnk.py   \n",
      "29695  pandas_profiling/report/structure/variables/re...   \n",
      "31636                                       d2l/mxnet.py   \n",
      "32776                            foliatools/foliaspec.py   \n",
      "33257       tests/utils/data_model_utils/test_tabular.py   \n",
      "40871  pymagnitude/third_party/allennlp/modules/span_...   \n",
      "40872  pymagnitude/third_party/allennlp/modules/span_...   \n",
      "45132                                   textacy/texts.py   \n",
      "48148                     annotator/geoname_annotator.py   \n",
      "48159                      epitator/count_annotator_2.py   \n",
      "48164                         epitator/infection_span.py   \n",
      "49323                            nala/structures/data.py   \n",
      "49695                                  TensorFI/fiLog.py   \n",
      "49900                pydmrs/matching/aligned_matching.py   \n",
      "50545                      ethically/dataset/__init__.py   \n",
      "50564                    responsibly/dataset/__init__.py   \n",
      "50566                      ethically/dataset/__init__.py   \n",
      "50567                    responsibly/dataset/__init__.py   \n",
      "50995                                       eval/eval.py   \n",
      "51009                                       eval/eval.py   \n",
      "51015                                       eval/eval.py   \n",
      "51021                                       eval/eval.py   \n",
      "51022                                       eval/eval.py   \n",
      "51027                                       eval/eval.py   \n",
      "54816                                     formats/fql.py   \n",
      "54827                                   formats/folia.py   \n",
      "54831                            pynlpl/formats/folia.py   \n",
      "62074                                     formats/fql.py   \n",
      "62084                                   formats/folia.py   \n",
      "62088                            pynlpl/formats/folia.py   \n",
      "65798  allennlp/modules/span_extractors/bidirectional...   \n",
      "65799  allennlp/modules/span_extractors/bidirectional...   \n",
      "66207                                   test/test_web.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "113    20e1096901f091737be28b5281496c824b2b2559   \n",
      "1943   5ea8774e2476a4967fae47e6b641eb9e71e9d5d0   \n",
      "5033   1ba863e477bd5b883434365e6babe991d35ca20d   \n",
      "5043   15436b8cbd5545199c0e82e1a3cf9a71a35ace97   \n",
      "6529   f7d9014a2009b22ab6a75ca44ac7822c0099ce09   \n",
      "8116   c69888184b3d0ce3c639414d186b71e1bd7001fd   \n",
      "8119   c69888184b3d0ce3c639414d186b71e1bd7001fd   \n",
      "8180   5be19816b063ad9663f01fd1ecb240f1387a6082   \n",
      "10967  2492ed58b4d6b14e03f0efbb46b71016ec716111   \n",
      "12217  db136b75d01eae6fbae7e07330ea9343e7720baf   \n",
      "22688  76643b3d06a6283f2dfe6ebe54a5ce41356b3232   \n",
      "22696  9a6146c55036dc1cb9e5611d2541034a084231c4   \n",
      "24169  c88c6f624c436bbffa490f790fb904a3d4bb9488   \n",
      "26972  ae40d966a1a84f65915b8f3c8f53198d66c26f53   \n",
      "28210  6fd718b688048165ab2c52392db28c47e491efd5   \n",
      "29695  906be41cecbc0464469fbfec4521f5a320170a76   \n",
      "31636  35364a693e8025d65b218be9e0fb8143a6689b92   \n",
      "32776  91892fa52ef3c2e314f25c213843822452fda37a   \n",
      "33257  697b32e8c94d394f99881a7bba4f92ad4b8abb47   \n",
      "40871  96f0fc6a8839cf1c824febcb170ab75ce8a6f854   \n",
      "40872  96f0fc6a8839cf1c824febcb170ab75ce8a6f854   \n",
      "45132  aa92bc2801ad74cf7a0beea3b40634af6a1e9ff1   \n",
      "48148  5757857216415a34c94a744112b1a449a2860871   \n",
      "48159  091c287051fd801cd112246b990ed58e92d88aa8   \n",
      "48164  54bf30d4bb2ba5d2d2c3e1f3b2a810fa9e4da4ae   \n",
      "49323  eceebaf2e8dfc1cc61b4c8c6ef650fcb5f66db4c   \n",
      "49695  ed9ea0db1adb3ba5e8751139b42d3f11e68f32fa   \n",
      "49900  b8ff28d34c1a941297273cb2df9298615e3575d8   \n",
      "50545  876e0ae510817c142668773e6eac910762d5bca0   \n",
      "50564  705391d447899607192e591a63cce39843d3de28   \n",
      "50566  77e3584be52139e6edbdc5ffa722301acfcec1b0   \n",
      "50567  8f911803d9481f35233f5ce4304c4aab46167444   \n",
      "50995  40fd14cfd8d42682cbc296afdeb2a291a58cdcb4   \n",
      "51009  bb1c5dc07cee9ede94042ed4ff8f215a80d4f215   \n",
      "51015  4857bbf1ce4b401a6440ae16c24a897e7611b766   \n",
      "51021  f7991b5bf40b45c708345663d863b039f81c02e3   \n",
      "51022  f19614ac89cc290be461269e127d4e63b77063c4   \n",
      "51027  e5365f6fa2a4d4a2e0f3f5f042f9b91f6072803a   \n",
      "54816  cff725015e8dd0671048298afdea866902bed2af   \n",
      "54827  24b446e118635485ecf85fd6123d0a684ec84243   \n",
      "54831  273ebc61bbd1d3c0eb4cc59f08166598b946bfbc   \n",
      "62074  5eb4d32bfddfc9b343540d90c65c35631a75080f   \n",
      "62084  13471e19e9a0da8a4a9414b65c84e5214ad96658   \n",
      "62088  ee54da08688ff0e52dbeb2173cfd31f920d13b73   \n",
      "65798  2d9bf0507696fe553eafeeafd164dbb9359ad135   \n",
      "65799  2d9bf0507696fe553eafeeafd164dbb9359ad135   \n",
      "66207  7bba151c8739ca2ccaabdb3b4e012d1314d68288   \n",
      "\n",
      "                                                 Comment  \\\n",
      "113         continue #TODO if doc_span_index>0: continue   \n",
      "1943   ''' || WARNING: academic ad-hoc code to export...   \n",
      "5033   TODO: Handle color given use of spans now inst...   \n",
      "5043                           TODO: Record the span too   \n",
      "6529   \\\"\\\"\\\" || Recognition Tests || ===============...   \n",
      "8116   TODO REALLY clean this up asap - this method w...   \n",
      "8119   TODO spans are none when indices and token bou...   \n",
      "8180   TODO spans are none when indices and token bou...   \n",
      "10967  TODO: Increase timespan when https:\\/\\/github....   \n",
      "12217  TODO Address extrametrical span symbol \\u25CA ...   \n",
      "22688  \\\"\\\"\\\" || def query_a(queue; list_a; e1_type; ...   \n",
      "22696  \\\"\\\"\\\" || def query_a(queue; list_a; e1_type; ...   \n",
      "24169  if felabel is None: # TODO: how is it inside a...   \n",
      "26972  TODO: sentence may span over multiple lines; w...   \n",
      "28210  \\\"\\\"\\\" || Surface alignment for semantic entit...   \n",
      "29695                                    TODO: colspan=2   \n",
      "31636  Recomputing `fake_Y` is needed since `net_D` i...   \n",
      "32776                              TODO: find span roles   \n",
      "33257  TODO: it'd be better to use the mention that s...   \n",
      "40871  we add 1 to the span ends as the AllenNLP ``Sp...   \n",
      "40872  As we added 1 to the span_ends to make them ex...   \n",
      "45132  TODO: cache key terms; and return them as spac...   \n",
      "48148  TODO: Add combined_span to geoname_spans being...   \n",
      "48159  TODO: This should really be an init() method f...   \n",
      "48164  TODO: This should check that span is actually ...   \n",
      "49323          todo check again with *span and unpacking   \n",
      "49695  FIXME: This won't work if the injection spans ...   \n",
      "49900  Convert DMRSs to SortDictDmrs with span_pred_k...   \n",
      "50545  \\\"\\\"\\\" || Collection of common benchmark datas...   \n",
      "50564  \\\"\\\"\\\" || Collection of common benchmark datas...   \n",
      "50566  \\\"\\\"\\\" || Collection of common benchmark datas...   \n",
      "50567  \\\"\\\"\\\" || Collection of common benchmark datas...   \n",
      "50995  TODO Finna f\\u00E1ga\\u00F0ri lausn; sem tekur ...   \n",
      "51009  TODO Finna f\\u00E1ga\\u00F0ri lausn; sem tekur ...   \n",
      "51015  TODO Finna f\\u00E1ga\\u00F0ri lausn; sem tekur ...   \n",
      "51021  TODO taka saman corr_rec og span_rec; sko\\u00F...   \n",
      "51022  TODO taka saman corr_rec og span_rec; sko\\u00F...   \n",
      "51027  TODO taka saman corr_rec og span_rec; sko\\u00F...   \n",
      "54816                             TODO: span annotation?   \n",
      "54827  TODO: span roles don't take classes; derived o...   \n",
      "54831  AbstractSpanAnnotation is needed when requesti...   \n",
      "62074                             TODO: span annotation?   \n",
      "62084  TODO: span roles don't take classes; derived o...   \n",
      "62088  AbstractSpanAnnotation is needed when requesti...   \n",
      "65798  we add 1 to the span ends as the AllenNLP ``Sp...   \n",
      "65799  As we added 1 to the span_ends to make them ex...   \n",
      "66207  XXX should test <td colspan=\\\"x\\\"> more thorou...   \n",
      "\n",
      "                                                    link  \n",
      "113    https://github.com/lazybootsafe/AI2Match/commi...  \n",
      "1943   https://github.com/arne-cl/discoursegraphs/com...  \n",
      "5033   https://github.com/jkkummerfeld/slate/commit/1...  \n",
      "5043   https://github.com/jkkummerfeld/slate/commit/1...  \n",
      "6529   https://github.com/mesnico/learning-relationsh...  \n",
      "8116   https://github.com/NLPatVCU/medaCy/commit/c698...  \n",
      "8119   https://github.com/NLPatVCU/medaCy/commit/c698...  \n",
      "8180   https://github.com/NLPatVCU/medaCy/commit/5be1...  \n",
      "10967  https://github.com/mozilla/bugbug/commit/2492e...  \n",
      "12217  https://github.com/persephone-tools/persephone...  \n",
      "22688  https://github.com/davidsbatista/BREDS/commit/...  \n",
      "22696  https://github.com/davidsbatista/BREDS/commit/...  \n",
      "24169  https://github.com/swabhs/open-sesame/commit/c...  \n",
      "26972  https://github.com/vecto-ai/vecto/commit/ae40d...  \n",
      "28210  https://github.com/delph-in/pydelphin/commit/6...  \n",
      "29695  https://github.com/pandas-profiling/pandas-pro...  \n",
      "31636  https://github.com/d2l-ai/d2l-zh/commit/35364a...  \n",
      "32776  https://github.com/proycon/foliatools/commit/9...  \n",
      "33257  https://github.com/HazyResearch/fonduer/commit...  \n",
      "40871  https://github.com/plasticityai/magnitude/comm...  \n",
      "40872  https://github.com/plasticityai/magnitude/comm...  \n",
      "45132  https://github.com/chartbeat-labs/textacy/comm...  \n",
      "48148  https://github.com/ecohealthalliance/EpiTator/...  \n",
      "48159  https://github.com/ecohealthalliance/EpiTator/...  \n",
      "48164  https://github.com/ecohealthalliance/EpiTator/...  \n",
      "49323  https://github.com/Rostlab/nalaf/commit/eceeba...  \n",
      "49695  https://github.com/DependableSystemsLab/Tensor...  \n",
      "49900  https://github.com/delph-in/pydmrs/commit/b8ff...  \n",
      "50545  https://github.com/ResponsiblyAI/responsibly/c...  \n",
      "50564  https://github.com/ResponsiblyAI/responsibly/c...  \n",
      "50566  https://github.com/ResponsiblyAI/responsibly/c...  \n",
      "50567  https://github.com/ResponsiblyAI/responsibly/c...  \n",
      "50995  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "51009  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "51015  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "51021  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "51022  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "51027  https://github.com/mideind/GreynirCorrect/comm...  \n",
      "54816  https://github.com/proycon/pynlpl/commit/cff72...  \n",
      "54827  https://github.com/proycon/pynlpl/commit/24b44...  \n",
      "54831  https://github.com/proycon/pynlpl/commit/273eb...  \n",
      "62074  https://github.com/proycon/foliapy/commit/5eb4...  \n",
      "62084  https://github.com/proycon/foliapy/commit/1347...  \n",
      "62088  https://github.com/proycon/foliapy/commit/ee54...  \n",
      "65798  https://github.com/allenai/allennlp/commit/2d9...  \n",
      "65799  https://github.com/allenai/allennlp/commit/2d9...  \n",
      "66207  https://github.com/clips/pattern/commit/7bba15...  \n",
      "Dataframe for 'droupout':\n",
      "Empty DataFrame\n",
      "Columns: [repo, filename, Commit, Comment, link]\n",
      "Index: []\n",
      "Dataframe for 'normalization':\n",
      "                                                    repo  \\\n",
      "748                                         breeko/spypy   \n",
      "1982   ildoonet/kaggle-human-protein-atlas-image-clas...   \n",
      "2388                            Angzz/panoptic-fpn-gluon   \n",
      "2443   SheikhRabiul/A-Deep-Learning-Based-Illegal-Ins...   \n",
      "3055                        fsx950223/mobilenetv2-yolov3   \n",
      "...                                                  ...   \n",
      "63867                                      dmlc/gluon-cv   \n",
      "63869                                      dmlc/gluon-cv   \n",
      "63888                                      dmlc/gluon-cv   \n",
      "66022                                   allenai/allennlp   \n",
      "68093                                    chainer/chainer   \n",
      "\n",
      "                                                filename  \\\n",
      "748                                         yad2k_out.py   \n",
      "1982                                             data.py   \n",
      "2388   docs/tutorials/classification/dive_deep_imagen...   \n",
      "2443   litigation-classifier-and-visualizations/prepr...   \n",
      "3055                                          convert.py   \n",
      "...                                                  ...   \n",
      "63867                     scripts/detection/train_ssd.py   \n",
      "63869              scripts/classification/cifar/train.py   \n",
      "63888  docs/tutorials/classification/dive_deep_imagen...   \n",
      "66022  allennlp/interpret/saliency_interpreters/smoot...   \n",
      "68093                     examples/imagenet/inception.py   \n",
      "\n",
      "                                         Commit  \\\n",
      "748    fc888c86638d3f82715535634dd6d6fdee37d96b   \n",
      "1982   74785993b8cc10ed72893535c5e696fafdd0669b   \n",
      "2388   7caee8e1cb994730efa849cd10603c1294e2b759   \n",
      "2443   760566efa552794535f121af889208808aaa6c42   \n",
      "3055   bd72721d4db2988e64ac2fc8042e5365f332b380   \n",
      "...                                         ...   \n",
      "63867  5767d1d1dee332faef3057a8416aa48179006edb   \n",
      "63869  e7389b15ea6509268a5c54d239992df43603d50b   \n",
      "63888  037379107e3b7960a07987e8519d955d1f1fa494   \n",
      "66022  9166c18439eb30cea4f668d113066e2ed6cb86eb   \n",
      "68093  78f760dbdec92f75251391957fc58a4d0c641dad   \n",
      "\n",
      "                                                 Comment  \\\n",
      "748    TODO: Keras BatchNormalization mistakenly refe...   \n",
      "1982                     TODO : different normalization?   \n",
      "2388   \\\"\\\"\\\"5. Train Your Own Model on ImageNet || =...   \n",
      "2443                  @todo normalization; if that helps   \n",
      "3055   TODO: Keras BatchNormalization mistakenly refe...   \n",
      "...                                                  ...   \n",
      "63867  \\\"\\\"\\\" || Train SSD on Pascal VOC dataset || =...   \n",
      "63869  \\\"\\\"\\\"Dive Deep Into CIFAR10 || ==============...   \n",
      "63888  \\\"\\\"\\\"Train Your Own Model on ImageNet || ====...   \n",
      "66022  TODO (@Eric-Wallace); SmoothGrad is not using ...   \n",
      "68093  (TODO) Implement Local Response Normalization ...   \n",
      "\n",
      "                                                    link  \n",
      "748    https://github.com/breeko/spypy/commit/fc888c8...  \n",
      "1982   https://github.com/ildoonet/kaggle-human-prote...  \n",
      "2388   https://github.com/Angzz/panoptic-fpn-gluon/co...  \n",
      "2443   https://github.com/SheikhRabiul/A-Deep-Learnin...  \n",
      "3055   https://github.com/fsx950223/mobilenetv2-yolov...  \n",
      "...                                                  ...  \n",
      "63867  https://github.com/dmlc/gluon-cv/commit/5767d1...  \n",
      "63869  https://github.com/dmlc/gluon-cv/commit/e7389b...  \n",
      "63888  https://github.com/dmlc/gluon-cv/commit/037379...  \n",
      "66022  https://github.com/allenai/allennlp/commit/916...  \n",
      "68093  https://github.com/chainer/chainer/commit/78f7...  \n",
      "\n",
      "[96 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"test\",\"train\",\"validate\",\"model\",\"hyperparameter\",\"AB testing\",\"Epoch\",\"batch\",\"graph\",\"tuning\",\"feature\",\"para\",\"word count\"\n",
    "            ,\"lemmatize\",\"word\",\"lemma\",\"tokens\",\"encoding\",\"embading\",\"span\",\"batch\",\"droupout\",\"normalization\"]\n",
    "# Create a list of dataframes, each containing comments with a specific word\n",
    "dataframes = {}\n",
    "for word in word_list:\n",
    "    mask = df['Comment'].str.contains(word, case=False)  # Case-insensitive search\n",
    "    dataframes[word] = df[mask].copy()\n",
    "\n",
    "# Access the dataframes for each specific word\n",
    "for word, word_df in dataframes.items():\n",
    "    print(f\"Dataframe for '{word}':\")\n",
    "    print(word_df)\n",
    "\n",
    "# If you want to save these dataframes to separate files\n",
    "for word, word_df in dataframes.items():\n",
    "    word_df.to_csv(f\"{word}_comments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "042486ec-245d-432f-b7ab-8198da25f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./All_Data/test.xlsx\n",
      "./All_Data/train.xlsx\n",
      "./All_Data/validate.xlsx\n",
      "./All_Data/model.xlsx\n",
      "./All_Data/hyperparameter.xlsx\n",
      "./All_Data/AB testing.xlsx\n",
      "./All_Data/Epoch.xlsx\n",
      "./All_Data/batch.xlsx\n",
      "./All_Data/graph.xlsx\n",
      "./All_Data/tuning.xlsx\n",
      "./All_Data/feature.xlsx\n",
      "./All_Data/para.xlsx\n",
      "./All_Data/word count.xlsx\n",
      "./All_Data/lemmatize.xlsx\n",
      "./All_Data/word.xlsx\n",
      "./All_Data/lemma.xlsx\n",
      "./All_Data/tokens.xlsx\n",
      "./All_Data/encoding.xlsx\n",
      "./All_Data/embading.xlsx\n",
      "./All_Data/span.xlsx\n",
      "./All_Data/droupout.xlsx\n",
      "./All_Data/normalization.xlsx\n"
     ]
    }
   ],
   "source": [
    "for key in dataframes.keys():\n",
    "    df_tmp = dataframes.get(key)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    name = \"./All_Data/\" + key + \".xlsx\"\n",
    "    print(name)\n",
    "    df_tmp.to_excel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "453350c5-7398-48d2-bf6c-26030a2068fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test   2558\n",
      "train   1005\n",
      "validate   135\n",
      "model   1347\n",
      "hyperparameter   72\n",
      "AB testing   0\n",
      "Epoch   133\n",
      "batch   689\n",
      "graph   375\n",
      "tuning   54\n",
      "feature   582\n",
      "para   1781\n",
      "word count   3\n",
      "lemmatize   6\n",
      "word   439\n",
      "lemma   25\n",
      "tokens   119\n",
      "encoding   97\n",
      "embading   0\n",
      "span   47\n",
      "droupout   0\n",
      "normalization   96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9563"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_len = 0\n",
    "for key in dataframes.keys():\n",
    "    tmp_len = len(dataframes.get(key)) + tmp_len\n",
    "    print(key, \" \" ,len(dataframes.get(key)))\n",
    "tmp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "004996a9-e952-4e6f-96df-45eaf62e5bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9563"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i.shape[0] for i in dataframes.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98a35018-c962-4e79-a10b-8c0ef4d62eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tp code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3b9526f-31c4-4e5d-a8dc-9167943709b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/omkarkhanvilkar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: 33192\n",
      "needed: 6305\n",
      "columns: 4140\n",
      "xxx: 3398\n",
      "use: 3088\n",
      "fixme: 3072\n",
      "add: 3046\n",
      "fix: 2799\n",
      "data: 2749\n",
      "better: 2482\n",
      "implement: 2203\n",
      "1: 2139\n",
      "model: 2102\n",
      "check: 2091\n",
      "remove: 2073\n",
      "10: 2066\n",
      "make: 1981\n",
      "move: 1920\n",
      "hack: 1902\n",
      "test: 1757\n",
      "need: 1629\n",
      "0: 1520\n",
      "set: 1492\n",
      "way: 1483\n",
      "using: 1456\n",
      "code: 1377\n",
      "maybe: 1361\n",
      "used: 1323\n",
      "2: 1301\n",
      "file: 1299\n",
      "function: 1266\n",
      "class: 1264\n",
      "one: 1262\n",
      "number: 1243\n",
      "support: 1192\n",
      "work: 1144\n",
      "python: 1128\n",
      "3: 1114\n",
      "output: 1083\n",
      "unused: 1034\n",
      "values: 1034\n",
      "list: 1031\n",
      "also: 1030\n",
      "get: 1017\n",
      "return: 997\n",
      "handle: 989\n",
      "array: 983\n",
      "method: 977\n",
      "example: 975\n",
      "efficient: 939\n",
      "module: 934\n",
      "training: 910\n",
      "instead: 909\n",
      "may: 902\n",
      "could: 888\n",
      "name: 887\n",
      "input: 877\n",
      "change: 876\n",
      "new: 876\n",
      "workaround: 874\n",
      "ends: 850\n",
      "different: 836\n",
      "dataset: 835\n",
      "would: 834\n",
      "probably: 834\n",
      "author: 832\n",
      "type: 799\n",
      "models: 795\n",
      "two: 787\n",
      "x: 787\n",
      "create: 777\n",
      "true: 764\n",
      "time: 754\n",
      "case: 736\n",
      "see: 715\n",
      "convention: 703\n",
      "produce: 702\n",
      "like: 701\n",
      "import: 698\n",
      "image: 690\n",
      "value: 681\n",
      "first: 680\n",
      "error: 679\n",
      "feature: 666\n",
      "tests: 660\n",
      "default: 656\n",
      "multiple: 653\n",
      "dont: 653\n",
      "index: 640\n",
      "files: 639\n",
      "functions: 626\n",
      "parameters: 625\n",
      "find: 624\n",
      "note: 621\n",
      "object: 619\n",
      "00: 616\n",
      "following: 615\n",
      "size: 606\n",
      "want: 602\n",
      "run: 597\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the NLTK stopwords (you may need to install the nltk library)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Sample DataFrame with a 'comment' column\n",
    "# data = {'Comment': [\"This is a sample comment. It's just an example.\", \"Don't use stop words in your analysis.\"]}\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the text data and tokenize into words\n",
    "df['Comment'] = df['Comment'].str.lower()  # Convert to lowercase\n",
    "df['Comment'] = df['Comment'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))  # Remove special characters\n",
    "df['Comment'] = df['Comment'].str.split()  # Tokenize into words\n",
    "\n",
    "# Filter out stop words and count word frequencies\n",
    "word_counts = Counter(word for words in df['Comment'] for word in words if word not in stop_words)\n",
    "\n",
    "# Get the top 100 most common words\n",
    "top_words = word_counts.most_common(100)\n",
    "\n",
    "# Display the top 100 words and their frequencies\n",
    "for word, count in top_words:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "008e4dea-f1d6-48e0-a9e1-2de3341e1360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||: 57688\n",
      ":: 44060\n",
      ";: 43698\n",
      "TODO: 32021\n",
      "the: 28138\n",
      ".: 25669\n",
      "'': 23158\n",
      "to: 21981\n",
      "): 19646\n",
      "(: 19590\n",
      "\\: 18928\n",
      "--: 15759\n",
      "a: 13706\n",
      "of: 13401\n",
      "is: 13277\n",
      "for: 10891\n",
      "and: 10198\n",
      "in: 10078\n",
      "this: 10053\n",
      "#: 8477\n",
      "': 7749\n",
      "`: 7710\n",
      ">: 7206\n",
      "be: 7121\n",
      "?: 6549\n",
      "*: 6247\n",
      "[: 6067\n",
      "]: 6044\n",
      "needed: 6011\n",
      "if: 5631\n",
      "with: 5530\n",
      "that: 4546\n",
      "it: 4530\n",
      "=: 4522\n",
      "not: 4323\n",
      "we: 4181\n",
      "-: 4119\n",
      "``: 4087\n",
      "as: 4078\n",
      "columns: 4040\n",
      "are: 3869\n",
      "on: 3619\n",
      "This: 3541\n",
      "XXX: 3351\n",
      "should: 3342\n",
      "{: 2998\n",
      "}: 2994\n",
      "by: 2977\n",
      "FIXME: 2931\n",
      "The: 2869\n",
      "from: 2841\n",
      "!: 2834\n",
      "can: 2808\n",
      "use: 2731\n",
      "1: 2719\n",
      "or: 2619\n",
      "data: 2589\n",
      "better: 2368\n",
      "add: 2257\n",
      "here: 2216\n",
      "do: 2158\n",
      "n't: 2158\n",
      "an: 2154\n",
      "<: 2149\n",
      "0: 2110\n",
      "todo: 2047\n",
      "all: 2020\n",
      "model: 2011\n",
      "more: 1899\n",
      "fix: 1891\n",
      "@: 1820\n",
      "when: 1813\n",
      "only: 1762\n",
      "'s: 1756\n",
      "have: 1749\n",
      "but: 1672\n",
      "check: 1655\n",
      "2: 1621\n",
      "make: 1606\n",
      "will: 1603\n",
      "|: 1603\n",
      "which: 1545\n",
      "test: 1523\n",
      "class: 1500\n",
      "need: 1486\n",
      "...: 1486\n",
      "way: 1467\n",
      "implement: 1457\n",
      "remove: 1443\n",
      "3: 1406\n",
      "move: 1404\n",
      "so: 1397\n",
      "using: 1388\n",
      "hack: 1349\n",
      "does: 1348\n",
      "code: 1343\n",
      "into: 1330\n",
      "used: 1307\n",
      "set: 1301\n",
      "at: 1284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have a DataFrame with a \"comment\" column called 'df'\n",
    "# If you don't have the nltk library, you can install it using pip install nltk\n",
    "\n",
    "# Tokenize the comments\n",
    "df['comment_tokens'] = df['Comment'].apply(word_tokenize)\n",
    "\n",
    "# Create a list of all tokens\n",
    "all_tokens = [token for tokens in df['comment_tokens'] for token in tokens]\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_freq = Counter(all_tokens)\n",
    "\n",
    "# Get the top 100 words\n",
    "top_100_words = word_freq.most_common(100)\n",
    "\n",
    "# Print the top 100 words\n",
    "for word, freq in top_100_words:\n",
    "    print(f'{word}: {freq}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c58b5c5c-7967-44a0-ab91-ee662385a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/omkarkhanvilkar/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98cac4-6361-4079-895e-479db7024f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
