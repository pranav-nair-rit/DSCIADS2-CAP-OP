index,Comment,GPT_4_Predicted_MLTD_label,spaCy_Predicted_MLTD_label,actual_MLTD_label
1306,TODO: Move the below code into torch tensor. ( To make use of GPU ),Yes,No,Yes
1496,Move to GPU; if available,No,Yes,Yes
1962,FIXME: dplpstr2dplptree output is no longer a tree,Yes,Yes,Yes
2633,TODO:,Yes,No,No
2845,XXX: We keep only the first half of the rule list and classifications; since sum_rows returns the counts,No,Yes,No
3086,Fix generator :)),No,No,Yes
3529,TODO: adapt the embedded batch size,Yes,No,Yes
3915,i_dert and unused d_dert,No,No,No
4072,"add \""_rev\"" as a hack to avoid image standardization",Yes,Yes,Yes
4304,TODO: How should these be initialized?,Yes,No,Yes
4711,TODO: check flow_back_wrap,Yes,No,Yes
4915,"\""\""\"" ||    Download and etract file if needed ||    dirpath: filename ||    url_name:  network location to download ||    is_xxx : type of file (could check by extenstion of file) || \""\""\""",No,Yes,Yes
5005,Needed for colours,No,No,Yes
5006,TODO:,Yes,No,No
5007,TODO: Change to be nano-style across the full bottom,Yes,Yes,Yes
5009,TODO: Only calculate color if it is going to be displayed,Yes,No,Yes
5010,TODO: Set to linking line rather than cursor where,Yes,Yes,Yes
5011,TODO: Work out how to handle the AnnType.text case,Yes,No,Yes
5012,TODO: Hacky; these numbers were worked out by hand.,Yes,Yes,Yes
5013,TODO: Only implemented correctly for the line matching case at the,Yes,Yes,Yes
5017,Normally; have a single position; left =; right; etc move it.,Yes,Yes,Yes
5021,TODO: long-jump as well as jump; have jump do a smaller scale,Yes,Yes,Yes
5022,TODO: Think about maintaining whitespace variations,Yes,Yes,Yes
5024,TODO: allow for <filename>:data,Yes,No,Yes
5027,TODO: next search term or disagreement,Yes,Yes,Yes
5029,TODO: support non-token cases,Yes,No,Yes
5030,Needed for blank line skipping,No,Yes,Yes
5031,Move in bounds,No,Yes,Yes
5032,TODO: read other annotations,Yes,No,Yes
5035,TODO: Need to make sure the entire line fits,Yes,Yes,Yes
5036,TODO: Make combination cursor and link,Yes,Yes,Yes
5038,TODO: Switch cursor to just be an underline,Yes,Yes,Yes
5040,TODO: Save both cursor and linking pos,Yes,No,Yes
5041,TODO: switch link to be like the old style,Yes,Yes,Yes
5042,TODO - simplified value here,Yes,No,Yes
5044,TODO: In this case move the linking pos along one step,Yes,No,Yes
5045,TODO: if self links are prevented; but forward links are allowed;,Yes,Yes,Yes
5048,TODO: Have an 'are you sure?' step,Yes,No,Yes
5049,TODO - simplified value here,Yes,No,Yes
5051,TODO: Genralize for missing any attribute,Yes,Yes,Yes
5052,# TODO: data loader,Yes,No,Yes
5053,TODO:,Yes,No,No
5057,''' || TODO: keep original || net.stage4[0].xception_block[5].dwconv.stride = (1; 1) || net.stage4[1].xception_block[4].dwconv.padding = (2; 2) || net.stage4[1].xception_block[4].dwconv.dilation = (2; 2) || ''',Yes,Yes,Yes
5058,TODO: support more backbone,Yes,No,Yes
5061,Select values from columns for IForest:,No,Yes,No
5064,first  perceptron implement,No,No,No
5066,TODO: Check transpose flag when implementing fully connected layers.,Yes,Yes,Yes
5067,TODO: This assumes channel last dim_ordering.,Yes,Yes,Yes
5069,TODO: Add check for Theano dim ordering.,Yes,Yes,Yes
5070,TODO run NONETYPE,Yes,Yes,Yes
5072,Needed to make sure the logging output is visible.,No,Yes,Yes
5073,save the better model based on the f1 score,No,Yes,Yes
5074,TODO: uncomment packages (but travis will fail),Yes,No,Yes
5077,columns of data file to convert from time format to float,No,Yes,No
5078,columns with malformed floats values,Yes,Yes,No
5079,get columns names and raw data,No,Yes,No
5082,get columns names and raw data,No,Yes,No
5084,"todo may not be needed self._wait_for(By.CLASS_NAME; \""activity-tracking-disclaimer\"")",Yes,Yes,Yes
5085,TODO: Allow Keras Lambda to use func arguments for output_shape?,Yes,No,Yes
5086,TODO: Remove or add option for static implementation.,Yes,Yes,Yes
5087,TODO: Repeat_elements and tf.split doesn't support dynamic splits.,Yes,Yes,Yes
5089,TODO: Remove extra computation shared with yolo_head.,Yes,Yes,Yes
5090,TODO: Adjust predictions by image width\/height for non-square images?,Yes,Yes,Yes
5097,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,Yes,Yes,Yes
5098,TODO: validate generated target,Yes,No,Yes
5100,"'''ShuffleNet in PyTorch. ||  || See the paper \""ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\"" for more details. || '''",No,Yes,Yes
5102,TODO: make efficient,Yes,Yes,Yes
5108,Compute Fisher matrix if needed,No,No,Yes
5110,TODO minimal import,Yes,Yes,Yes
5112,TODO do this better,Yes,No,Yes
5114,TODO random seed as an option,Yes,Yes,Yes
5116,if self.args.lr_decay != 1:   #TODO add lr decay support,Yes,No,Yes
5117,TODO random seed as an option,Yes,Yes,Yes
5118,dirty fix for extra data,Yes,Yes,Yes
5120,TODO update docstring,Yes,No,Yes
5121,if self.args.lr_decay != 1:   #TODO add lr decay support,Yes,No,Yes
5122,dirty fix for extra data,Yes,Yes,Yes
5125,TODO make it cleaner,Yes,Yes,Yes
5126,TODO,Yes,Yes,No
5127,TODO there is apparently a bug when scheduler is used; to be fixed,Yes,Yes,Yes
5128,TODO when corrected bug in izitorch (conf mat does not include unobserved labels),Yes,Yes,Yes
5130,TODO optimise redundant blocks,Yes,No,Yes
5131,TODO correct elapsed time display,Yes,No,Yes
5133,TODO Find a less expensive way to do this,Yes,No,Yes
5140,TODO Remove per class metrics,Yes,Yes,Yes
5144,TODO can be simplified,Yes,No,Yes
5145,get columns,No,Yes,No
5146,in a better way,No,No,No
5147,"\""\""\"" || A script to grid search all parameters provided in parameters.py || including both classifiers and regressors. || Note that the execution of this script may take hours to search the  || best possible model parameters for various algorithms; feel free || to edit parameters.py on your need ( e.g remove some parameters for  || faster search ) || \""\""\""",No,Yes,Yes
5148,model already created; why call twice,Yes,Yes,Yes
5151,fix random seed for reproducibility,No,No,Yes
5153,TODO: Convert the following to TensorFlow:,Yes,No,Yes
5154,Needed to make sure the logging output is visible.,No,Yes,Yes
5157,Attention: for subclass to implement,No,Yes,Yes
5159,Needed to make sure the logging output is visible.,No,Yes,Yes
5160,THIS CODE COULD BE ADDED BEFORE SAVING FOR SLIGHT IMPROVEMENT IN PERFORMANCE,Yes,Yes,Yes
5162,determine number of images we want to move from train to validation,No,Yes,Yes
5163,perform the move,No,Yes,Yes
5164,THIS CODE COULD BE ADDED BEFORE SAVING FOR SLIGHT IMPROVEMENT IN PERFORMANCE,Yes,Yes,Yes
5169,longer test: train model on two classes; accuracy has to be >60%; significantly better than random,No,Yes,Yes
5170,"TODO: Can be generalized: take an argument \""number of top layers\""; include",Yes,Yes,Yes
5172,TODO: how many images does this generate,Yes,No,Yes
5173,check if significantly better than random,No,No,Yes
5175,new_background = TODO,Yes,No,Yes
5176,TODO fix this!,Yes,Yes,Yes
5177,For reference in case it is needed,No,Yes,Yes
5178,TODO:,Yes,No,Yes
5182,Needed to make sure the logging output is visible.,No,Yes,Yes
5187,"\""\""\"" || only one of attribute_distribution_params or attribute_distribution can be set of each run || leave the unused element as an empty list; as below ||  || attribute_distribution_params: list(list[string; string; float]) || attribute_distribution: list(list(string; dict(string; float; float))) || \""\""\""",No,Yes,Yes
5188,# TODO add more sophisticated checking once format of object files concrete,Yes,Yes,Yes
5190,"\""\""\"" || only one of attribute_distribution_params or attribute_distribution can be set of each run || leave the unused element as an empty list; as below ||  || attribute_distribution_params: list(list[string; string; float]) || attribute_distribution: list(list(string; dict(string; float; float))) || \""\""\""",No,Yes,Yes
5191,move unwanted side directly behind camera such that origin of mesh bounding sphere,No,No,Yes
5192,move unwanted side directly behind camera such that origin of mesh bounding sphere,No,No,Yes
5193,this is really ugly; but it does the job - rendering it for the first,Yes,Yes,Yes
5194,lamp energy is a TRUNCATED NORMAL DISTRIBUTION; param descriptions same as above,No,Yes,Yes
5196,Hacky way to import render_pipeline,Yes,Yes,Yes
5200,lamp energy is a TRUNCATED NORMAL DISTRIBUTION; param descriptions same as above,No,Yes,Yes
5203,FIXME: should handle P+transparency as well,Yes,Yes,Yes
5205,FIXME: decode and apply image,Yes,Yes,Yes
5207,really is necessary (platform-dependent; though...),No,Yes,Yes
5208,FIXME: huh?,Yes,No,Yes
5212,FIXME: the fill decoder is not implemented,Yes,No,Yes
5213,FIXME: jpeg tables are tile dependent; the prefix,Yes,No,Yes
5214,"FIXME: \""P\""",Yes,No,Yes
5215,FIXME: hack,Yes,No,Yes
5219,FIXME: this may read whole file if not a text file,Yes,Yes,Yes
5220,FIXME: hack,Yes,No,Yes
5221,NOTE: this functionality will be moved to the extended,Yes,Yes,Yes
5223,FIXME: _imaging returns a confusing error message for this case,Yes,Yes,Yes
5225,implement the <b>seek<\/b>; <b>tell<\/b>; and <b>write<\/b>,No,Yes,Yes
5229,FIXME: future versions should optimize crop\/paste,Yes,Yes,Yes
5230,bug; and will probably be fixed in a future release.  The current,Yes,Yes,Yes
5231,must implement <b>read<\/b>; <b>seek<\/b>; and <b>tell<\/b> methods;,Yes,Yes,Yes
5232,@param alpha The interpolation alpha factor.  If alpha is 0.0; a,No,Yes,Yes
5234,FIXME: add RGBA support,Yes,Yes,Yes
5239,FIXME: add support for bitmap fonts,Yes,Yes,Yes
5240,@param factor Enhancement factor.,No,Yes,Yes
5241,until we know better,No,No,Yes
5242,FIXME: on Unix; use PROT_READ etc,Yes,Yes,Yes
5243,FIXME: This is a hack to handle TIFF's JpegTables tag.,Yes,No,Yes
5244,FIXME: This is a hack to handle rotated PCD's,Yes,Yes,Yes
5245,FIXME: this is slow!,Yes,No,Yes
5250,Todo:,Yes,No,Yes
5254,Load a (probably rather ugly) default font.,No,Yes,Yes
5255,FIXME: apply to lookup table; not image data,Yes,Yes,Yes
5256,cut off pixels from both ends of the histogram,No,No,Yes
5257,liveArea is wider than what's needed; crop the sides,Yes,No,Yes
5261,FIXME - is this really the best way to do this?,Yes,Yes,Yes
5266,1996-05-05 fl   Workaround Photoshop 2.5 CMYK polarity bug,Yes,Yes,Yes
5267,FIXME: The quantization tables can be used to estimate the,Yes,No,Yes
5269,padded marker or junk; move on,Yes,Yes,Yes
5271,FIXME: issue a warning if the wrong form is used (post-1.1.5),Yes,No,Yes
5272,FIXME: should store the navigation and calibration blocks,Yes,No,Yes
5273,somewhere (or perhaps extract some basic information from,No,No,Yes
5275,FIXME: is this the right field?,Yes,Yes,Yes
5276,1997-01-22 fl   Fixed 64-bit portability quirk,No,Yes,Yes
5278,"FIXME: change filename to use \""a\/b\/c\"" instead of [\""a\""; \""b\""; \""c\""]",Yes,Yes,Yes
5279,FIXME: provide a glob mechanism function (using fnmatchcase),Yes,No,Yes
5281,the actual functionality of the Software represents the correct,No,No,Yes
5283,FIXME: should store the list of sects obtained by following,Yes,No,Yes
5284,FIXME: should add a counter in here to avoid looping forever,Yes,Yes,Yes
5285,couldn't move right; move up instead,No,Yes,Yes
5286,FIXME: could check version and byte order fields,Yes,Yes,Yes
5287,described by DIF blocks (FIXME: not yet implemented),Yes,Yes,Yes
5288,FIXME: some day; Python will provide an official way to handle,Yes,Yes,Yes
5290,FIXME,Yes,Yes,Yes
5291,"FIXME: this is a 64-bit int: \""number of 100ns periods",Yes,No,Yes
5292,FIXME: add support for VT_VECTOR,Yes,No,Yes
5295,FIXME: not correct for rotated images!,Yes,Yes,Yes
5300,"assuming a 4-byte magic label (FIXME: add \""_accept\"" hook)",Yes,No,Yes
5303,FIXME,Yes,Yes,Yes
5304,FIXME: to be supported some day,Yes,Yes,Yes
5305,FIXME: multilayer,Yes,No,Yes
5306,FIXME,Yes,Yes,Yes
5312,work around broken (?) matrox library,Yes,No,Yes
5313,Hack to handle abbreviated JPEG headers,Yes,Yes,Yes
5314,FIXME: this doesn't work if the image size,Yes,Yes,Yes
5316,FIXME: make save work (this requires quantization support),,,Yes
5318,needed to get current value of this option,No,Yes,Yes
5321,main hack,Yes,Yes,Yes
5322,"FIXME: won't work with \""P\"" images",Yes,Yes,Yes
5324,used the traceback module to do a much better job of reporting,No,No,Yes
5325,Hard to think of a better example of why this is useful <wink>.,,,Yes
5330,FIXME: use distutils logging (?),,,Yes
5331,3. Try modifying the architecture and the hyper-parameters to get a better performance.,No,Yes,Yes
5332,Improve the pre-processing and the model to recognize human activity in a better way,No,Yes,Yes
5333,3. Even the kernel size from 2. could be considered too big. Modify the model from 2. to use kernels size of 3. Due to,,,Yes
5335,"Gets the results into a DataFrame; drops some \""irrelevant\"" columns; sorts by best score and saves to spreadsheet",,,Yes
5337,(n_examples; n_labels) --> Need to operate on columns; so axis=1,No,Yes,Yes
5340,would be by 0s if we used a one-hot-encoded input vector instead of a token id. Mathematically; however;,No,Yes,Yes
5341,TODO: change cost function to reconstruction error,Yes,No,Yes
5342,improve patience if loss improvement is good enough,Yes,Yes,Yes
5343,in order to implement CD-k\/PCD-k we need to scan over the,No,Yes,Yes
5344,``shared_y`` we will have to cast it to int. This little hack,,,Yes
5345,improve patience if loss improvement is good enough,No,Yes,Yes
5346,improve patience if loss improvement is good enough,No,Yes,Yes
5347,in order to implement CD-k\/PCD-k we need to scan over the,,,Yes
5348,Fix the bias unit.,Yes,Yes,Yes
5349,TODO: Remove the code duplication between this method and `run_visible`?,,,Yes
5350,Gets the best result so far; so that we only save the model if the result is better (test loss in this case),No,Yes,Yes
5351,Only saves the model if it's better than the models from all of the other experiments,No,Yes,Yes
5352,3. Try modifying the architecture and the hyper-parameters to get a better performance.,No,Yes,Yes
5353,nn.Conv1d operates on the columns; each embedding dimension is considered as one channel,No,Yes,Yes
5355,to process each sentence one by one instead of in batches; which would be pretty slow; but maybe worth it!,Yes,Yes,Yes
5356,Another way (and probably better) of processing variable length sequences is by,,,Yes
5357,ds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # Idem; although not really needed,,,Yes
5360,3. Try modifying the architecture and the hyper-parameters to get a better performance.,,,Yes
5364,Estimators use a system called feature columns to describe,,,Yes
5365,columns describe how the model should convert each feature.,,,Yes
5367,mask needed because sentences aren't all the same length,No,Yes,Yes
5369,TODO Permute results,Yes,No,Yes
5371,TODO - only if gpu mode,Yes,Yes,Yes
5373,mask needed because sentences aren't all the same length,No,Yes,Yes
5374,TODO: might need to be chainer function instead of np,Yes,Yes,Yes
5378,TODO Add dropout to head and label MLPs,Yes,Yes,Yes
5382,TODO: check multiple roots issue,Yes,No,Yes
5385,TODO: remove me,Yes,No,Yes
5386,TODO: Write pad method - add END to word sequences.,Yes,Yes,Yes
5387,they aren't always needed but it simplifies our work,No,Yes,Yes
5389,needed to import train to visualise_train,,,Yes
5390,TODO: ask chainer devs about this?,No,Yes,Yes
5391,there seems to be no easy way to reset the seed!,No,No,Yes
5396,# Indices for Token Columns,,,Yes
5397,Columns 1--7: words and morphosyntactic information,No,Yes,Yes
5399,dependency relation labels corresponding to the dependencies  described in 9,No,No,Yes
5400,Columns 12--13,No,Yes,Yes
5402,APREDs: N columns; one for each predicate in 15; containing the semantic roles\/dependencies of each particular predicate,No,Yes,Yes
5405,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
5406,Fix blocks,,,Yes
5407,move to GPU,,,Yes
5409,"\""\""\"" || Average parameters from multiple model checkpoints. Checkpoints can be either || specified manually or automatically chosen according to one of several || strategies. The default strategy of simply selecting the top-scoring N points || works well in practice. || \""\""\""",No,Yes,Yes
5410,Points dominated by a previous better point have lifespan 0,No,Yes,Yes
5412,Once MXNet allows item assignments given a list of indices (probably MXNet 1.0): e.g a[[0;1;5;2]] = x;,,,Yes
5417,TODO: possible alternative: feed back the context vector instead of the hidden (see lamtram),,,Yes
5419,TODO: add context gating?,,,Yes
5420,TODO: potentially project the encoder hidden size to the decoder hidden size.,,,Yes
5425,Map from restricted to full vocab ids if needed,No,Yes,Yes
5427,TODO: Contribute these to MXNet?  For now it appears that registered activation types must be implemented in C++.,Yes,No,Yes
5428,TODO dropout?,,,Yes
5430,"\""\""\"" || Input to attention callables. ||  || :param seq_idx: Decoder time step \/ sequence index. || :param query: Query input to attention mechanism; e.g. decoder hidden state (plus previous word). || \""\""\""",No,No,Yes
5431,TODO: Push update to MXNet to expose the optimizer (Module should have a get_optimizer method),Yes,Yes,Yes
5433,Reference not needed since there will be no reads or writes,No,Yes,Yes
5434,TODO: Currently disabled due to periodic outages of nlp.stanford.edu,Yes,Yes,Yes
5435,TODO: check MD5sum,Yes,No,Yes
5436,v2cs = [t for t in filtered if t[1] == ':instance-of'],No,Yes,Yes
5438,Alignment bug; ignore node and move to the next one,Yes,Yes,Yes
5441,todo redirect to help page,Yes,Yes,Yes
5443,todo sentence types,No,No,Yes
5444,todo modality,Yes,No,Yes
5446,todo async,Yes,No,Yes
5448,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
5452,nbh_radius = 2.0      # TODO change,Yes,Yes,Yes
5457,# TODO implement random data initialization for super-SOM,Yes,Yes,Yes
5458,TODO remove after PCA init implementation:,Yes,No,Yes
5462,TODO accept_sparse,Yes,Yes,Yes
5463,nbh_radius = 2.0      # TODO change,,,Yes
5466,The convention in BERT is:,No,No,Yes
5468,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
5470,"What we really want to return is \""Steve Smith\"".",No,No,Yes
5471,Should be more efficient to first transpose.,,,Yes
5472,Maybe crop if needed.,No,No,Yes
5473,Maybe pad if needed.,Yes,No,Yes
5474,Maybe crop if needed.,,,Yes
5475,Maybe pad if needed.,Yes,No,Yes
5477,TODO: Reduce the number of times iterating over things,Yes,Yes,Yes
5478,TODO: Make the assignments agnostic to the number of trees and ccs,,,Yes
5480,TODO: add check for localpath existence,,,Yes
5481,TODO: add exception handling for invalid type,Yes,Yes,Yes
5482,TODO: add exception handling for invalid caching flag,Yes,Yes,Yes
5485,todo: may add auto-generated vertex ID to refere to a more rich representation of vertex,Yes,Yes,Yes
5488,remove punctuation can improve the model a little bit,No,Yes,Yes
5491,"Calculates the \""realized\"" basis for a particular symbol; given a trade history. This refers to the actual amounts paid in and out; including dividend payments; as well as money gained or lost on derivatives related to that symbol (e.g.; short puts; covered calls).",No,Yes,Yes
5492,TODO: FOP,Yes,No,Yes
5510,TODO: Determine valid CUSIP for bonds,,,Yes
5511,TODO: Use order depth if available?,,,Yes
5512,TODO: Support non-standard multipliers,Yes,No,Yes
5513,TODO: This should be supported for Futures too,,,Yes
5514,FIXME: Define a get_historical_prices function,,,Yes
5515,TODO: make the exchange rate flexible. This should generally be the dollar value of 1 point of instrument i.,,,Yes
5516,TODO: Check uniqueness of instruments,,,Yes
5518,TODO: make the exchange rate flexible. This should generally be the dollar value of 1 point of instrument i.,Yes,Yes,Yes
5519,TODO: Do we want a new TradeFlag?,,,Yes
5520,Annoying hack because some transactions depend on others around them.,Yes,Yes,Yes
5522,TODO: Refactor\/simplify Configuration class so it can be used in cases,Yes,Yes,Yes
5524,TODO: Memoize the result of deduplication?,Yes,No,Yes
5526,FIXME: This is roughly what it _should_ be; but due to exchange rate,Yes,Yes,Yes
5529,FIXME: This is roughly what it _should_ be; but due to exchange rate,,,Yes
5530,FIXME: This is specific to IBDataProvider right now,Yes,Yes,Yes
5532,TODO we can probably use nn.fused_batch_norm here too for speedup,,,Yes
5533,TODO: why normal and not uniform?,Yes,No,Yes
5534,'coronary (?:atherosclerosis)';  # remove is better,,,Yes
5536,TODO. should guarantee that order the same as during reading operation.,,,Yes
5537,TODO list:,Yes,No,Yes
5538,2. Implement expanded word2vec; which includes relation phrases and related,No,Yes,Yes
5540,TODO. move this method into the kernel (at entity.py file).,,,Yes
5541,TODO. O(N) now; search,,,Yes
5544,TODO. Move ignored entities into core.,Yes,Yes,Yes
5545,TODO. window size should be unchanged,Yes,Yes,Yes
5546,TODO. Shuffle,Yes,Yes,Yes
5547,TODO list:,,,Yes
5548,2. Implement expanded word2vec; which includes relation phrases and related,,,Yes
5550,TODO. Duplicated from vectors.py,Yes,Yes,Yes
5552,TODO. move this method into the kernel (at entity.py file).,Yes,Yes,Yes
5553,TODO. O(N) now; search,Yes,Yes,Yes
5554,TODO. Refactor method_name with method_root,,,Yes
5555,TODO. Method name (is not root actually). Better to refactor it.,Yes,Yes,Yes
5556,TODO. window size should be unchanged,,,Yes
5557,TODO. Choose base class for optimiser,Yes,Yes,Yes
5560,TODO: guarantee that entities ordered by e_begin.,,,Yes
5561,TODO: Move this logger into a root of a networks folder in future.,Yes,Yes,Yes
5562,TODO. Implement distributed placement with average for same sentence relation occurance,Yes,No,Yes
5565,TODO: fix tight bound on variable matching,,,Yes
5567,Import all needed modules (folder is valid at this point),,,Yes
5568,Move grid to real space,,,Yes
5572,Update batch size on generators (needed after OOM error --> reduced,Yes,Yes,Yes
5574,Move back,No,No,Yes
5575,Apply rotation if needed,No,Yes,Yes
5576,Get int labels if needed; otherwise returns identity,No,Yes,Yes
5580,TODO: Make all sequences store a reference to the queue,,,Yes
5582,Flatten labels in spatial dimensions; needed for sample weighting,,,Yes
5583,TEMP TODO,,,Yes
5584,Temporary memory leak fix,Yes,Yes,Yes
5587,Workaround for dng: first save dng; then convert to array; then to png,,,Yes
5588,TODO,,,Yes
5592,TODO: add limited pickling support for sharing an iterator,Yes,Yes,Yes
5595,''' || Reference implementation of node2vec. || Author: Aditya Grover || For more details; refer to the paper: || node2vec: Scalable Feature Learning for Networks || Aditya Grover and Jure Leskovec || Knowledge Discovery and Data Mining (KDD); 2016 ||  || Src: https:\/\/github.com\/aditya-grover\/node2vec || ''',,,Yes
5598,maybe mutate the action of the learner,,,Yes
5599,remove unused learners,,,Yes
5600,maybe do something about teamqueue here; don't know how I'm,,,Yes
5602,maybe insert instruction,No,No,Yes
5604,maybe swap two instructions,,,Yes
5605,bid is better,No,Yes,Yes
5607,"\""\""\"" || Contains all information needed to pick up from wherever last left off. An || instance can be obtained by the client and saved with something like Pickle. || \""\""\""",No,Yes,Yes
5612,delete now unused learners,Yes,Yes,Yes
5614,delete now unused learners,Yes,Yes,Yes
5617,column to maybe write corresponding value into,No,No,Yes
5618,mutations repeatedly; random probably small amount,,,Yes
5619,maybe delete instruction,Yes,Yes,Yes
5620,maybe mutate an instruction (flip a bit),No,No,Yes
5621,maybe swap two instructions,No,No,Yes
5622,maybe add instruction,No,Yes,Yes
5623,TODO move to config,Yes,Yes,Yes
5624,TODO: mode to configurator,Yes,No,Yes
5626,mutations repeatedly; random probably small amount,No,No,Yes
5627,maybe delete instruction,No,Yes,Yes
5630,maybe add instruction,,,Yes
5635,fix range of rampancy if invalid,,,Yes
5637,needed for mutation,,,Yes
5638,"\""\""\"" || Make the appropriate changes needed to be able to use real actions. || \""\""\""",,,Yes
5639,TODO: add learner configurable,Yes,Yes,Yes
5641,mutations repeatedly; random probably small amount,No,No,Yes
5643,maybe mutate an instruction (flip a bit),,,Yes
5645,maybe add instruction,,,Yes
5646,TODO What happens when actionIndex is None?,,,Yes
5647,TODO What's self.states?,,,Yes
5648,maybe delete instruction,Yes,Yes,Yes
5650,maybe swap two instructions,No,No,Yes
5651,maybe add instruction,,,Yes
5653,"\""\""\"" || This is implementation of fasttext with bigram features. || see [Bag of Tricks for Efficient Text Classification](https:\/\/arxiv.org\/abs\/1607.01759) || \""\""\""",No,Yes,Yes
5654,Todo: bug fix,,,Yes
5655,create the tables needed by TOBOT to store what it learns,No,Yes,Yes
5656,TOBOT doesn't know how to answer; so send a generic message,No,No,Yes
5663,TODO: Copy resources once they're specified,Yes,Yes,Yes
5664,TODO: Add in ESP Boards,,,Yes
5665,TODO,,,Yes
5668,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,,Yes
5669,it is only needed for transfer mode 3,No,Yes,Yes
5670,"We \""pool\"" the model by simply taking the hidden state corresponding",No,Yes,Yes
5673,TODO do actual A* and deal with moving targets,,,Yes
5675,TODO get confidence in visibilty,,,Yes
5676,TODO get confidence in wm,Yes,Yes,Yes
5677,TODO,,,Yes
5678,You can just specify the packages manually here if your project is,,,Yes
5679,TODO: Enforce same data specs for all datasets,Yes,No,Yes
5680,Require a joint to move at least 200mm since the previous pose,No,No,Yes
5683,Move centre to (0; 0),No,Yes,Yes
5684,Move centre to centre of image,No,Yes,Yes
5685,FIXME: This is actually a bug! The skeleton should be made root-relative; scaled;,Yes,Yes,Yes
5686,FIXME: The conversion to int generates a warning during tracing; and is not necessary,Yes,Yes,Yes
5689,Lots of options that should work and appear similar accross platforms,No,No,Yes
5690,Naming convention for binary file encoding\/decoding,No,Yes,Yes
5691,import json # NOT NEEDED,No,No,Yes
5692,from pycocotools import mask # NOT NEEDED,Yes,Yes,Yes
5696,Needed for training and re-runs to match mask,No,Yes,Yes
5698,The problem at the moment is it is not very user friendly.  You cannot run any of the code directly on Mac or Windows without fixing many errors.  Many of the bigger models also require a lot of computing power and will fail because it assumes you have a good linux computer.  The other option of buying cloud time; or uploading gigs of photos are simply not practical for the other 99% percent of us.,,,Yes
5700,"A case in point is \""pip install tensorflow\"" on Mac will give you 1.8.0 at the moment.  It will not work with object detection scripts.  Neither will 1.5.1.  The models were all trained in tf 1.5.0 so all good.  I had errors with 1.4.0 even though the demo notebook proudly adds 2 more lines of code to check; it is wrong in most cases.  You may be able to run it on linux with 2.7 but I assume most end-users can't.",Yes,Yes,Yes
5701,video: can now do smart green-screen (no green background needed),,,Yes
5702,The best thing is you can avoid painful hours of making masks manually.  You can then use the pre-made masks to train.  Booya!,,,Yes
5703,#NAME?,,,Yes
5704,- add pdf; txt\/csv and jpg\/png output - TODO,Yes,Yes,Yes
5705,Not all are needed but easy to replicate when tf slim or object changes,Yes,Yes,Yes
5706,Want better; faster?,,,Yes
5707,Compatible with single shot; faster rcnn; nasnet - from fastest to best,No,Yes,Yes
5711,TODO python 3 format to 27,Yes,Yes,Yes
5712,simple hack to overcome this issue; we only exclude bbox labels,,,Yes
5715,This is needed because the pre-activation variant does not have batch,No,Yes,Yes
5716,once we refactor Faster RCNN models to set is_training through an outer,Yes,Yes,Yes
5720,TODO(b\/65130867): Use image_id tensor once we fix the input data,Yes,Yes,Yes
5722,A dictionary of metric names to classes that implement the metric. The classes,,,Yes
5724,Unused by updated loading code.,,,Yes
5729,Needed for fine-tuning from classification checkpoints whose,,,Yes
5734,"\""\""\"" || SUpervised Dimensionality Reduction with ivis || ============================================= ||  || ivis is able to make use of any provided class labels to perform supervised || dimensionality reduction. Supervised embeddings combine the distance-based || characteristics of the unsupervised ivis algorithm with clear class boundaries || between the class categories. The resulting embeddings encode relevant || class-specific information into lower dimensional space; making them useful || for enhancing the performance of a classifier. ||  || To train ivis in supervised mode; simply provide the labels to the fit || method\u2019s Y parameter. These labels should be a list of 0-indexed integers with || each integer corresponding to a class. || \""\""\""",,,Yes
5736,TODO validate the dimensions of the neighbour matrix,,,Yes
5738,Probably the best way to do this is by moving the sample pushing,No,Yes,Yes
5740,FIXME Do it in batches,Yes,Yes,Yes
5742,A kludge for now until I spend more than two mins writing this func,,,Yes
5745,The wildcard search terms are needed to ge all the correct file,,,Yes
5746,TODO This is not good enough long term - a temp fix,Yes,Yes,Yes
5748,needed due to apparent bug in glob2 - removes duplicate entries,Yes,Yes,Yes
5750,TODO IMPORTANT add xgb boost functionality,,,Yes
5751,TODO this has become rather messy and inefficient - need to make it more,Yes,No,Yes
5752,TODO 1- find an efficient way of classifying only non-zero values,Yes,Yes,Yes
5754,TODO - a list of classes would be better eliminating the need for the one,,,Yes
5762,"\""\""\"" || Created on Thu Sep  8 22:35:39 2016 || @author: Ciaran Robb || Research Associate in Earth Observation || Centre for Landscape and Climate Research (CLCR) || Department of Geography; University of Leicester; University Road; Leicester;  || LE1 7RH; UK  ||  || If you use code to publish work cite\/acknowledge me and authors of libs etc as  || appropriate  || \""\""\""",No,Yes,Yes
5763,XXX both work,No,Yes,Yes
5766,TODO - Add atmosphere info for Atcor in orfeo,,,Yes
5767,The wildcard search terms are needed to ge all the correct file,,,Yes
5768,TODO This is not good enough long term - a temp fix,Yes,Yes,Yes
5770,needed due to apparent bug in glob2 - removes duplicate entries,,,Yes
5771,TODO - sort the code below as it is very fast - just something wrong with,Yes,Yes,Yes
5772,TODO IMPORTANT add xgb boost functionality,Yes,No,Yes
5773,TODO this has become rather messy and inefficient - need to make it more,,,Yes
5774,TODO 1- find an efficient way of classifying only non-zero values,Yes,Yes,Yes
5777,TODO - order is not quite right -sort this,,,Yes
5779,TODO Axis measurements are not quite right -,Yes,Yes,Yes
5780,TODO - this may not write to shape as a tuple,Yes,No,Yes
5781,TODO This is horrible there must be a better way....,Yes,No,Yes
5782,Make columns uppercase if wanted,,,Yes
5783,"\""\""\"" || Created on Thu Sep  8 22:35:39 2016 || @author: Ciaran Robb || Research Associate in Earth Observation || Centre for Landscape and Climate Research (CLCR) || Department of Geography; University of Leicester; University Road; Leicester;  || LE1 7RH; UK  ||  || If you use code to publish work cite\/acknowledge me and authors of libs etc as  || appropriate  || \""\""\""",No,Yes,Yes
5784,XXX both work,,,Yes
5786,TODO - it wouold be better to use xml2dict to make the code more,Yes,Yes,Yes
5788,The wildcard search terms are needed to ge all the correct file,No,Yes,Yes
5789,TODO This is not good enough long term - a temp fix,Yes,Yes,Yes
5791,needed due to apparent bug in glob2 - removes duplicate entries,,,Yes
5793,TODO IMPORTANT add xgb boost functionality,,,Yes
5794,TODO this has become rather messy and inefficient - need to make it more,Yes,No,Yes
5798,TODO - order is not quite right -sort this,,,Yes
5799,TODO - come up with a field based solution to this,Yes,No,Yes
5800,TODO Axis measurements are not quite right -,,,Yes
5803,Make columns uppercase if wanted,,,Yes
5804,"\""\""\"" || Created on Thu Sep  8 22:35:39 2016 || @author: Ciaran Robb || Research Associate in Earth Observation || Centre for Landscape and Climate Research (CLCR) || Department of Geography; University of Leicester; University Road; Leicester;  || LE1 7RH; UK  ||  || If you use code to publish work cite\/acknowledge me and authors of libs etc as  || appropriate  || \""\""\""",No,Yes,Yes
5805,XXX both work,No,Yes,Yes
5807,TODO Maybe improve check of library so it doesn't use a global,,,Yes
5808,TODO: Check if SentinelAPI will use TokenAuth instead of hard-coded cred strings,,,Yes
5809,TODO: investigate flaky sentinelAPI,Yes,No,Yes
5811,TODO: put metadata urls in a config file,,,Yes
5817,TODO: Check if SentinelAPI will use TokenAuth instead of hard-coded cred strings,Yes,Yes,Yes
5819,TODO: maybe clean up these nested functions. Or it might be alright.,Yes,No,Yes
5820,TODO: put metadata urls in a config file,Yes,Yes,Yes
5822,TODO maybe improve this so it doesn't use a global,Yes,Yes,Yes
5825,TODO: investigate flaky sentinelAPI,Yes,No,Yes
5826,TODO: maybe clean up these nested functions. Or it might be alright.,,,Yes
5830,TODO: put metadata urls in a config file,,,Yes
5831,TODO optimise with either cython or numba,,,Yes
5836,TODO: Check if SentinelAPI will use TokenAuth instead of hard-coded cred strings,Yes,Yes,Yes
5839,TODO: put metadata urls in a config file,Yes,Yes,Yes
5840,TODO investigate ways of speeding this up,,,Yes
5841,TODO maybe improve this so it doesn't use a global,,,Yes
5843,TODO: Check if SentinelAPI will use TokenAuth instead of hard-coded cred strings,Yes,Yes,Yes
5844,TODO: investigate flaky sentinelAPI,,,Yes
5845,TODO: maybe clean up these nested functions. Or it might be alright.,Yes,No,Yes
5848,TODO optimise with either cython or numba,,,Yes
5849,TODO - cythinis or numba this one,,,Yes
5850,YUCK!!!!!! This is a repulsive solution,Yes,No,Yes
5852,TODO,Yes,Yes,Yes
5853,TODO can an ogr solution be worked in; still allowing for interactive stuff??,,,Yes
5854,Context hack for now,Yes,No,Yes
5855,Might this be better run in parallel from bash?,,,Yes
5857,TODO Maybe improve check of library so it doesn't use a global,Yes,Yes,Yes
5860,TODO: maybe clean up these nested functions. Or it might be alright.,Yes,No,Yes
5861,TODO: put metadata urls in a config file,Yes,Yes,Yes
5862,TODO investigate ways of speeding this up,Yes,Yes,Yes
5863,TODO: improve this assert statement to make it more that just a check,Yes,No,Yes
5865,TODO: Progress bar here,Yes,No,Yes
5866,TODO: Implement mass downloading with a cool-off in case of 429 response,Yes,Yes,Yes
5867,TODO: Implement mass downloading with a cool-off in case of 429 response,Yes,Yes,Yes
5870,ugly yes; but sometimes geotrans not quite right,Yes,Yes,Yes
5871,TODO drop the subprocess call,,,Yes
5872,TODO,Yes,Yes,Yes
5873,Context hack for now,,,Yes
5874,Might this be better run in parallel from bash?,Yes,Yes,Yes
5876,TODO: Implement more robust error handling here (not just 429),,,Yes
5878,TODO - this is VERY ugly fix mess of if statements,Yes,Yes,Yes
5879,TODO drop the subprocess call,Yes,Yes,Yes
5880,TODO: Make less hacky,,,Yes
5882,TODO Cut out the serial subprocess usage eugh!!!,Yes,No,Yes
5884,ugly yes; but sometimes geotrans not quite right,,,Yes
5885,TODO - this is VERY ugly fix mess of if statements,Yes,Yes,Yes
5886,TODO - this is VERY ugly fix mess of if statements,Yes,Yes,Yes
5888,There must be a less ugly way surely......,,,Yes
5890,TODO ad other stat types - consider mask array for safety......,Yes,No,Yes
5892,ugly and efficient for now,,,Yes
5893,TODO maybe open update if we want to write stats,Yes,No,Yes
5894,"\""\""\"" || Created on Thu Sep  8 22:35:39 2016 || @author: Ciaran Robb || Aberytswyth Uni || Wales ||  || If you use code to publish work cite\/acknowledge me and authors of libs etc as  || appropriate  || \""\""\""",No,Yes,Yes
5895,TODO maybe open update if we want to write stats,Yes,No,Yes
5897,Specify offset and rows and columns to read,No,No,Yes
5900,TODO this is FAR too long,,,Yes
5901,TODO,Yes,Yes,Yes
5902,get columns,No,Yes,Yes
5906,TODO - make alternating intervals make it rotational,Yes,Yes,Yes
5907,TODO Axis measurements are not quite right -,,,Yes
5909,TODO - this may not write to shape as a tuple,Yes,No,Yes
5910,otsu threshold works perfectly on green band - would be better stat representation,No,No,Yes
5914,TODO this is FAR too long,Yes,No,Yes
5916,get columns,No,Yes,Yes
5918,"\""\""\"" || ==================== || Morphological Snakes || ==================== ||  || *Morphological Snakes* [1]_ are a family of methods for image segmentation. || Their behavior is similar to that of active contours (for example; *Geodesic || Active Contours* [2]_ or *Active Contours without Edges* [3]_). However; || *Morphological Snakes* use morphological operators (such as dilation or || erosion) over a binary array instead of solving PDEs over a floating point || array; which is the standard approach for active contours. This makes || *Morphological Snakes* faster and numerically more stable than their || traditional counterpart. ||  || There are two *Morphological Snakes* methods available in this implementation: || *Morphological Geodesic Active Contours* (**MorphGAC**; implemented in the || function ``morphological_geodesic_active_contour``) and *Morphological Active || Contours without Edges* (**MorphACWE**; implemented in the function || ``morphological_chan_vese``). ||  || **MorphGAC** is suitable for images with visible contours; even when these || contours might be noisy; cluttered; or partially unclear. It requires; however; || that the image is preprocessed to highlight the contours. This can be done || using the function ``inverse_gaussian_gradient``; although the user might want || to define their own version. The quality of the **MorphGAC** segmentation || depends greatly on this preprocessing step. ||  || On the contrary; **MorphACWE** works well when the pixel values of the inside || and the outside regions of the object to segment have different averages. || Unlike **MorphGAC**; **MorphACWE** does not require that the contours of the || object are well defined; and it works over the original image without any || preceding processing. This makes **MorphACWE** easier to use and tune than || **MorphGAC**. ||  || References || ---------- ||  || .. [1] A Morphological Approach to Curvature-based Evolution of Curves and ||        Surfaces; Pablo M\u00E1rquez-Neila; Luis Baumela and Luis \u00C1lvarez. In IEEE ||        Transactions on Pattern Analysis and Machine Intelligence (PAMI); ||        2014; DOI 10.1109\/TPAMI.2013.106 || .. [2] Geodesic Active Contours; Vicent Caselles; Ron Kimmel and Guillermo ||        Sapiro. In International Journal of Computer Vision (IJCV); 1997; ||        DOI:10.1023\/A:1007979827043 || .. [3] Active Contours without Edges; Tony Chan and Luminita Vese. In IEEE ||        Transactions on Image Processing; 2001; DOI:10.1109\/83.902291 ||  || \""\""\""",,,Yes
5919,intersecting multiline with its bounding box somehow triggers a first,,,Yes
5920,move coordinates of the vertex to destination,,,Yes
5922,TODO rectify pixel gap issue,,,Yes
5926,TODO - get fuse burner algo in this,,,Yes
5929,TODO Clean up lack of loops funcs to do stuff,Yes,No,Yes
5930,TODO Jeez tidy this too,,,Yes
5931,TODO this has become rather messy (understatement),Yes,No,Yes
5932,Specify offset and rows and columns to read,No,No,Yes
5939,todo tense,Yes,No,Yes
5941,this flush method is needed for python 3 compatibility.,No,Yes,Yes
5943,Convert shape from [num examples; rows; columns; depth],,,Yes
5949,group a set of images row per columns,No,No,Yes
5953,''' || Motion Cube || Contains functions for generating spatial representations of biological motion ||  || todo: implement GPU convolutions on minibatches || todo: implement pre-computed gaussian kernel || ''',Yes,Yes,Yes
5954,used during evaluation; it is more efficient to just update in one,No,Yes,Yes
5955,''' || certain samples mirror || def random_flip_images(image_batch;label_batch;landmark_batch): ||     num_images = image_batch.shape[0] ||     random_number = npr.choice([0;1];num_images;replace=True) ||     #the index of image needed to flip ||     indexes = np.where(random_number>0)[0] ||     fliplandmarkindexes = np.where(label_batch[indexes]==-2)[0] ||  ||     #random flip ||     for i in indexes: ||         cv2.flip(image_batch[i];1;image_batch[i]) ||     #pay attention: flip landmark ||     for i in fliplandmarkindexes: ||         landmark_ = landmark_batch[i].reshape((-1;2)) ||         landmark_ = np.asarray([(1-x; y) for (x; y) in landmark_]) ||         landmark_[[0; 1]] = landmark_[[1; 0]]#left eye<->right eye ||         landmark_[[3; 4]] = landmark_[[4; 3]]#left mouth<->right mouth ||         landmark_batch[i] = landmark_.ravel() ||     return image_batch;landmark_batch || ''',,,Yes
5957,ToDo1 ref,,,Yes
5958,TODO: add backend thread to load data,,,Yes
5959,''' Furthest point sampling || Original author: Haoqiang Fan || Modified by Charles R. Qi || All Rights Reserved. 2017.  || ''',,,Yes
5960,remove nodes not needed during inference (e.g. Dropout; and those in the ignoreList),,,Yes
5965,TODO: do no always filter,,,Yes
5966,TODO: tru != 'UNK'!!!,,,Yes
5967,TODO,Yes,Yes,Yes
5969,TODO: make this fold self-contained; only depends on utils package,Yes,Yes,Yes
5972,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
5977,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
5980,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
5981,TODO: make fast_rcnn irrelevant,,,Yes
5982,TODO: make fast_rcnn irrelevant,,,Yes
5984,RLE is a simple yet efficient format for storing binary masks. RLE,,,Yes
5986,TODO: make fast_rcnn irrelevant,,,Yes
5987,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
5989,max overlap with gt over classes (columns),No,Yes,Yes
5991,Compute values needed for means and stds,No,No,Yes
5992,These values will be needed for making predictions,,,Yes
5995,Infer number of classes from the number of columns in gt_overlaps,No,Yes,Yes
5996,Compute values needed for means and stds,No,No,Yes
5998,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
5999,TODO: make fast_rcnn irrelevant,,,Yes
6000,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
6001,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
6002,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
6003,config to remove unused area,No,Yes,Yes
6004,Boyutlar\u0131n s\u0131rayla y\u00FCkseklik (rows); geni\u015Flik (columns) ve kanal say\u0131s\u0131n\u0131,No,Yes,Yes
6005,you can make the training more efficient,No,Yes,Yes
6006,whenever gym would not work properly; set using additional parameter,No,Yes,Yes
6007,'''This module contains the following: ||  || BaseOptimizer ||   A class containing useful methods that are inherited by any optimizer. ||   Generally it is an attempt; to make the code more readable. ||    || Todo: ||     * Add automatic verbose report.''',,,Yes
6010,Pong has either +1 or -1 reward exactly when game ends.,,,Yes
6012,TODO implement halving step,,,Yes
6013,of variances; so the corresponding columns have small weight and,No,Yes,Yes
6014,or in more detailed; properly subscripted; and vectorized form,No,Yes,Yes
6016,multiply columns of the diff by weights; square; and sum,,,Yes
6020,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
6021,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
6022,"projected data. There is no backfitting so each \""stage\"" is fit exactly once.",,,Yes
6023,Encoder does the argmax over columns itself to find the index of the,No,Yes,Yes
6025,add needed packet,Yes,Yes,Yes
6026,move on to next packet,No,Yes,Yes
6027,num_images; unused,No,Yes,Yes
6029,num_images; unused,No,Yes,Yes
6031,TODO: fix to use stdin like docker-cli,,,Yes
6034,TODO: give more information,Yes,Yes,Yes
6035,TODO: raise original Error (No such job\/task\/task_index),Yes,No,Yes
6036,TensorFlow Better Bicubic Downsample,No,Yes,Yes
6040,swap current and previous columns,No,Yes,Yes
6041,needed),No,No,Yes
6043,add differing tokens as separate markables; if needed,,,Yes
6045,re-arrange columns and rows,,,Yes
6047,TODO: \u043F\u043E\u0441\u043B\u0435 \u0438\u0441\u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u043D\u0438\u044F \u043F\u043E\u0441\u043C\u043E\u0442\u0440\u0435\u0442\u044C \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043A\u0443 \u0431\u0430\u0437\u044B,,,Yes
6048,TODO: \u043C\u043E\u0436\u0435\u0442 \u0432\u0441\u0435\u0433\u0434\u0430 \u043B\u0438\u0441\u0442 \u0434\u043E\u043B\u0436\u0435\u043D \u0432\u043E\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044C\u0441\u044F,Yes,Yes,Yes
6049,TODO: \u041D\u0430\u0441\u0442\u043E\u044F\u0449\u0438\u0439 dilated_convs,Yes,Yes,Yes
6051,TODO: \u0441\u043A\u043E\u043B\u044C\u043A\u043E \u043F\u0440\u0438\u0437\u043D\u0430\u043A\u043E\u0432,Yes,No,Yes
6052,workaround for browser that do not like <br><br\/>,Yes,Yes,Yes
6054,Print summary report we can directly include into release notes.,No,No,Yes
6055,\/* TEMPORARY AND NASTY HACK UNTIL mxSPARSE_CLASS IS COMPLETELY ELIMINATED *\/,Yes,Yes,Yes
6056,TODO: CHECK,Yes,No,Yes
6058,TODO ALL BELOW,,,Yes
6059,Append a path separator to this directory if needed.,,,Yes
6060,TODO: add reshape input data function,,,Yes
6061,Append a path separator to this directory if needed.,No,Yes,Yes
6064,smaller; better,,,Yes
6065,bigger; better,No,Yes,Yes
6066,Needed only for compatibility with Python 2.6,Yes,Yes,Yes
6067,TODO: Change placeholder below to generate authentication credentials. See,,,Yes
6068,value_input_option = 'RAW'  # TODO: Update placeholder value.,,,Yes
6069,in order to implement CD-k\/PCD-k we need to scan over the,,,Yes
6070,smaller; better,No,Yes,Yes
6072,TODO check the start,Yes,Yes,Yes
6073,TODO: with padding,,,Yes
6074,\treturn a tf session which takes proper GPU usage instead of all memory,No,Yes,Yes
6076,Needed only for compatibility with Python 2.6,,,Yes
6078,value_input_option = 'RAW'  # TODO: Update placeholder value.,,,Yes
6079,TODO,Yes,Yes,Yes
6080,TODO check the start,,,Yes
6083,TODO,,,Yes
6084,TODO check the start,Yes,Yes,Yes
6086,Script taken from doing the needed operation,,No,Yes
6087,TODO: Build and use this function to reduce code duplication,,,Yes
6088,todo:,Yes,No,Yes
6089,5. Drop a checkpoint if needed.,,,Yes
6090,Set up a separated copy attention layer; if needed.,No,Yes,Yes
6095,Hack. Can't pickle defaultdict :(,Yes,Yes,Yes
6097,Pass in needed options only when modify function definition.,,,Yes
6100,Set up a separated copy attention layer; if needed.,No,Yes,Yes
6101,Temporary kludge solution to handle changed dim expectation,Yes,Yes,Yes
6102,@TODO add health check here,Yes,Yes,Yes
6104,@TODO Implement this,,,Yes
6105,@TODO read arguments for network setup,Yes,Yes,Yes
6108,@TODO start websocket server,,,Yes
6110,# This alternative is more efficient because it avoid the discouraged TF placeholder usage,,,Yes
6113,TODO consider using Iterator,Yes,Yes,Yes
6114,Fix TF random seed,No,Yes,Yes
6115,TODO atomic: score attacks on adjacent king squares,,,Yes
6117,max overlap with gt over classes (columns),,,Yes
6119,Testing mode; default to be 'nms'; 'top' is slower but better,No,Yes,Yes
6121,every network should fix the rgb issue at least,No,Yes,Yes
6122,fix RGB to BGR,No,Yes,Yes
6125,maybe it had more room to go lower,No,Yes,Yes
6126,TODO: shuffle qas,Yes,No,Yes
6127,The size of the image patch in rows or columns,No,No,Yes
6129,Enable mouse move events,No,Yes,Yes
6130,TODO,,,Yes
6133,somehow; for the numpad key in some machines; a check on Insert is needed aswell,Yes,No,Yes
6134,Increase maybe,No,Yes,Yes
6135,Move the layer up (negative offset) or down (postive offset),No,No,Yes
6136,The index we want to move to,No,Yes,Yes
6137,self.clearChanges() #TODO perhaps?,Yes,No,Yes
6138,Enable mouse move events,No,Yes,Yes
6139,hack?,,,Yes
6140,In progress:: TODO: Add properly the functionalities,Yes,Yes,Yes
6144,we'll publish a TF related to this object only once,No,No,Yes
6145,@todo: catch attributeError on config; and print possibilities if possible,,,Yes
6146,UNUSED,Yes,No,Yes
6152,todo ?,,,Yes
6153,K is would be fix or +1 for nonparametric case,No,Yes,Yes
6155,todo ?,Yes,Yes,Yes
6156,K is would be fix or +1 for nonparametric case,,,Yes
6157,@todo: compute the variance for random simulation,,,Yes
6158,Nasty hack to make serialisation possible,Yes,Yes,Yes
6162,find the unused and used tables,No,Yes,Yes
6169,"\""\""\"" || @author: Ke Zhai (zhaike@cs.umd.edu) ||  || This code was modified from the code originally written by Frank Wood (fwood@stat.columbia.edu). || Implements collapsed Gibbs sampling for the infinite Gaussian mixture model (IGMM). || \""\""\""",,,Yes
6172,"@todo: Estimation of x_min instead of the \""max\"" heuristic.",,,Yes
6176,Re-order the confusion matrix in order to map the cluster (columns) to the best (classes) according to purity,No,Yes,Yes
6177,TODO,Yes,Yes,Yes
6178,UNUSED,,,Yes
6180,todo if needed,,,Yes
6181,Unused -- see RawDescriptionHelpFormatter,,,Yes
6183,@ugly debug,Yes,Yes,Yes
6185,python3 hook; nothing better ?,,,Yes
6186,@ugly debug,,,Yes
6187,move this in draw data,,,Yes
6191,TODO,,,Yes
6192,@todo: Merge this with plot do abstract,,,Yes
6193,\u00A0upgrade to '{corpus}_{model}} or much better hash of the settings.,,,Yes
6194,if self._it % hack_up != 0:,Yes,No,Yes
6196,if self._it % hack_up != 0:,,,Yes
6197,@todo; lhs for clustering expe applications.,Yes,Yes,Yes
6199,\u00A0IX integration needed..,Yes,Yes,Yes
6200,todo if needed,,,Yes
6201,\u00A0Don't work well; why ?,Yes,Yes,Yes
6202,frame.fig.tight_layout() # works better in parameter,No,Yes,Yes
6203,\u00A0Don't work well; why ?,Yes,Yes,Yes
6205,@todo; lhs for clustering expe applications.,,,Yes
6207,fun =  self.__hack_me_fit,Yes,Yes,Yes
6208,fun =  self.__hack_me_transform,Yes,Yes,Yes
6209,fun =  self.__hack_me_predict,,,Yes
6210,@TODO: should be in Manager,Yes,Yes,Yes
6213,+ implement dict value for model (or in list of model; in order to,No,No,Yes
6214,1. ba able to describe params in a better way,Yes,Yes,Yes
6218,lstrip('_') is a usefull hack for identical measure with diferent parameter...,,,Yes
6219,any connectivity. It's only used for data association. By convention; a layer with a,,,Yes
6220,Case 2: output_name violates the convention layer.name == output_name.,No,Yes,Yes
6221,TODO: Find a better solution for this.,Yes,No,Yes
6222,TODO: This is the default Caffe batch norm eps,Yes,Yes,Yes
6223,TODO: Axis,Yes,No,Yes
6224,TODO: Unbiased,,,Yes
6226,fill ends of dimension that is too short with random noise,No,No,Yes
6227,Prepare Object Grid of size pattern_size where pattern_size[0] is columns and pattern_size[1] is rows,No,No,Yes
6229,TODO,,,Yes
6230,Unused indices for training and validation,Yes,Yes,Yes
6232,Check if batch only has one item and expand dims if needed,No,Yes,Yes
6234,this should not be needed with the above; but meh,No,Yes,Yes
6235,"\""\""\"" || setup ||  || Module installs the synthnn package || Can be run via command: python setup.py install (or develop) ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Nov 2; 2018 || \""\""\""",,,Yes
6237,"\""\""\"" || synthit.exec.nn_train ||  || command line interface to train a deep convolutional neural network for || synthesis of MR (brain) images ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Aug 28; 2018 || \""\""\""",,,Yes
6239,hack to get linear output,Yes,No,Yes
6240,"\""\""\"" || synthnn.util.io ||  || handle io operations for the synthnn package ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Nov 2; 2018 || \""\""\""",No,No,Yes
6242,"\""\""\"" || tests.test_plot ||  || test plotting functions for common runtime errors ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Sep 07; 2018 || \""\""\""",No,Yes,Yes
6243,"\""\""\"" || synthit.exec.nn_train ||  || command line interface to train a deep convolutional neural network for || synthesis of MR (brain) images ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Aug 28; 2018 || \""\""\""",,,Yes
6244,"\""\""\"" || synthit.exec.fa_train ||  || command line interface to synthesize an MR (brain) image || with a trained NN where the DNN was trained in fastai ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Nov 2; 2018 || \""\""\""",No,No,Yes
6247,TODO: document this section better,Yes,No,Yes
6248,not needed,,,Yes
6249,fix decoder,Yes,No,Yes
6252,"\""\""\"" || synthnn.learn.layers ||  || define auxillary layers for defining neural networks in pytorch ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Feb 21; 2018 || \""\""\""",,,Yes
6253,lr_scheduler cannot affect final_lr; this is a workaround to apply lr decay,Yes,No,Yes
6254,"\""\""\"" || synthnn.util.config ||  || create class for experiment configuration in the synthnn package ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Feb 26; 2018 || \""\""\""",,,Yes
6258,"\""\""\"" || tests.test_exec ||  || test the synthtorch command line interfaces for runtime errors ||  || Author: Jacob Reinhold (jacob.reinhold@jhu.edu) ||  || Created on: Sep 07; 2018 || \""\""\""",No,Yes,Yes
6264,Keeping track of the number of columns,No,No,Yes
6265,Raising exception if all lines do not have the same number of columns or,No,Yes,Yes
6268,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
6271,"logging.debug(\""Feature columns: {}\"".format(data_object.feature_columns))",No,No,Yes
6272,todo: check if there is something to print,,,Yes
6275,TODO: Make this interface cleaner,,,Yes
6277,TODO: THIS PROBABLY NEEDS A BETTER IMPLEMENTATION,,,Yes
6278,# TODO: Port internal functionality to apps.analyze_tabs,Yes,Yes,Yes
6279,TODO: This needs revisiting for allowing user to add,,,Yes
6282,TODO: This might need to be removed (or updated),Yes,No,Yes
6284,These are all elements that are needed as callback inputs,No,No,Yes
6285,TODO: This might need change; depending on whether we specify,,,Yes
6286,TODO: This might need change when the login is implemented,Yes,No,Yes
6287,TODO: This probably is not needed anymore; the check is performed above,,,Yes
6290,TODO: This probably is not needed anymore; the check is performed above,,,Yes
6292,first six columns of row,,,Yes
6293,second six columns of row,No,Yes,Yes
6295,# Functions below here implement the various graphs,,,Yes
6297,# Functions below here implement the various graphs,,,Yes
6298,Placeholder for low-level submenus; if needed,No,Yes,Yes
6300,TODO: Implement user_id correctly:,Yes,No,Yes
6301,TODO: Persist data from logged in users,Yes,Yes,Yes
6305,first eight columns of row,,,Yes
6307,first eight columns of row; (1st subrow),,,Yes
6309,This needs a better implementation,,,Yes
6310,# yvars is needed,No,No,Yes
6312,Fix bugs occurring due to Dash not ordering callbacks,No,Yes,Yes
6313,# TODO: Consider using slots,,,Yes
6315,TODO: This needs a better implementation to allow,,,Yes
6323,TODO: This needs a better implementation to allow,,,Yes
6325,TODO: find a better way to estimate positions,,,Yes
6326,TODO: Consider making this an executable,Yes,Yes,Yes
6327,TODO: These two callbacks can probably be condensed in a loop or combined,Yes,Yes,Yes
6336,TODO: This check for data existence might be slow.,,,Yes
6337,It would be good to test\/review and improve it.,,,Yes
6338,TODO: This check for data existence might be slow.,,,Yes
6339,It would be good to test\/review and improve it.,Yes,Yes,Yes
6340,"\""\""\"" || This module collects functions and utilities for 3D visualization. ||  || Functions: ||     - scatterplot3d: Create a 3D scatterplot. ||  || Notes to others: ||     Feel free to write code here either to improve current or to add ||     new functionality. What is particularly needed is new graph types. || \""\""\""",No,Yes,Yes
6341,"\""\""\"" || This module collects functions and utilities for text visualizations. ||  || Functions: ||     - create_wordcloud: Generate a wordcloud and save it to a file. ||  || Notes to others: ||     Feel free to write code here either to improve current or to add ||     new functionality. Avoid word vectors visualizations at this stage ||     of development as it will simply increase (re)load times for the app. || \""\""\""",No,No,Yes
6343,"\""\""\"" || <h2> Welcome to EDA Miner! <\/h2> ||  || <h3>Usage walk-through<\/h3> || We strive to create a simple and intuitive interface. The app is meant to be || run in a central server and accessed via web; but can of course be run locally; || too. ||  || Upon visiting the page you will be directed to the \""<b>Data View<\/b>\"" tab where || you upload your own datasets; connect to APIs; or view the data you have || uploaded. When viewing your data; each API displays data in different ways; || although actually using those data is not yet implemented (May 2019). ||  || As soon as you have uploaded a dataset; the other two tabs become functional. || The first stop would be the \""<b>Explore & Visualize<\/b>\"" tab. Here you will || find options to plot your data; each sub-tab contains a different class of || visualizations. || <ol> ||     <li><b>Exploratory analysis<\/b> contains all the 2D graphs; including ||     matplotlib-generated pairplots.<\/li> ||     <li><b>Key performance indicators<\/b> currently implements only ||     a baseline graph; but we plan to implement functionality so you ||     can create your own KPIs; and we want to add additional analysis ||     tools.<\/li> ||     <li><b>3D graphs<\/b> currently only plots 3D scatterplots.<\/li> ||     <li><b>Network graphs<\/b> use Cytoscape.js to create graph\/network ||     visualizations; allowing various layout choices.<\/li> ||     <li><b>Text visualizations<\/b> currently only allow for creating ||     simple word clouds (from given text); but plans for further integration ||     and more visualizations include word vector visualization.<\/li> ||     <li><b>PDF report<\/b> allows you to create reports using the figures ||     you plot in the other tabs (using the \""export graph config\"" buttons) ||     and add custom text; headers; titles.<\/li> || <\/ol> ||  || Finally; in the \""<b>Analyze & Predict<\/b>\"" tab you are able to use your || data to train Machine Learning models. The <b>Model builder<\/b> can be || used to create more advanced pipelines (including defining your own || features). The default steps are to first define the model <b>fully<\/b> || (or some features may not work); then go over every node you want to || customize and change its node options; and when you're done export the || model (\""convert to model\"" button). Finally; head over to the \""Pipelines || trainer\"" tab; select and train your model. If you want to run simpler || models; there are additional tabs with the most common types of problems. ||  ||  || <h3>Project structure<\/h3> || Contributors wanting to familiarize themselves with the project structure || can take a look at the <a src='https:\/\/github.com\/KMouratidis\/EDA_miner_public\/wiki\/Style-guide-and-contributor-guidelines'> || contributor guidelines<\/a>. You can also go through all the files and read || the module docstrings that have rough guidelines about contributions. In the || Python spirit; <b>feel free to completely ignore them<\/b> || \""\""\""",No,Yes,Yes
6344,TODO: This probably needs a better\/cleaner implementation and\/or,,,Yes
6345,TODO: Visualize the (in)correctly grouped points.,,,Yes
6348,TODO: This needs improvement; e.g. with adding,,,Yes
6349,Only existing for debugging the next callback; no yvars needed,,,Yes
6350,TODO: Add visualizations for the results.,,,Yes
6351,TODO: These probably need their own positioning!,,,Yes
6352,TODO: Remove parents that don't have children,Yes,Yes,Yes
6354,"\""\""\"" || This module collects every model class; including input and transformers. ||  || Notes to others: ||     Feel free to tamper with anything or add your own models and classes. \\ ||     Everything should implement an sklearn-like API providing a fit and \\ ||     (more importantly) a transform method. It should also have a \\ ||     `modifiable_params` dictionary with the names of attributes that can \\ ||     be modified and a list of possible values (keep them limited; for now). \\ ||     Input classes should subclass `GenericInput`. If you add new classes \\ ||     remember to modify `ml_options` in `graph_structures.py`. || \""\""\""",,,Yes
6356,TODO: Sort based on date,Yes,No,Yes
6358,TODO: do an actual implementation,Yes,No,Yes
6360,TODO: THIS MIGHT NOT WORK CORRECTLY IF MORE THAN ONE PIPELINES ARE,,,Yes
6361,TODO: This needs a better \/ cleaner implementation,Yes,Yes,Yes
6363,TODO: Consider saving for future use \/ as a dataset.,Yes,Yes,Yes
6364,"\""\""\"" || <h2>Developer notes<\/h2> ||  || The modules here are for implementing utilities needed by higher-level || modules. Some suggestions on what could be done: || <ul> ||     <li>Add new API connections (note: you need to implement both ||     the connector and define a layout\/form).<\/li> ||     <li>Fix the bug that made me pollute the whole file with those ||     ugly debugger layouts.<\/li> || <\/ul> || \""\""\""",Yes,Yes,Yes
6365,"\""\""\"" || <h2>Developer notes<\/h2> ||  || Some suggestions on what could be done here: || <ul> ||     <li><b>Define more PDF report layouts<\/b> ||     (see also <code>layouts.py<\/code>).<\/li> ||     <li>Add more graph types in any of the categories (but avoid word ||     vector visualizations).<\/li> ||     <li>Add additional functionality in KPIs.<\/li> ||     <li>Improve baseline graph and\/or function.<\/li> ||     <li>Improve network visualizations.<\/li> || <\/ul> || \""\""\""",,,Yes
6366,TODO: could add check for windows hidden files,Yes,Yes,Yes
6367,"\""\""\"" || Welcome to EDA Miner! ||  || Usage walk-through: || We strive to create a simple and intuitive interface. The app is meant to \\ || be run in a central server and accessed via web; but can of course be run \\ || locally; too. ||  || Upon visiting the page you will be directed to the \""Data View\"" tab where \\ || you upload your own datasets; connect to APIs; or view the data you have \\ || uploaded. When viewing your data; each API displays data in different \\ || ways; although actually using those data is not yet implemented (May 2019). ||  || As soon as you have uploaded a dataset; the other two tabs become \\ || functional. The first stop would be the \""Explore & Visualize\"" tab. \\ || Here you will find options to plot your data; each sub-tab contains \\ || a different class of visualizations. ||     - Exploratory analysis: contains all the 2D graphs; including \\ ||                             matplotlib-generated pairplots. ||     - Key performance indicators: currently implements only a baseline \\ ||                                   graph; but we plan to implement \\ ||                                   functionality so you can create your \\ ||                                   own KPIs; and we want to add additional \\ ||                                   analysis tools. ||     - 3D graphs: currently only plots 3D scatterplots. ||     - Network graphs: use Cytoscape.js to create graph\/network \\ ||                       visualizations; allowing various layout choices. ||     - Text visualizations: currently only allow for creating simple word \\ ||                            clouds (from given text); but plans for further \\ ||                            integration and more visualizations include \\ ||                            word vector visualization. ||     - PDF report: allows you to create reports using the figures you \\ ||                   plot in the other tabs (using the \""export graph \\ ||                   config\"" buttons) and add custom text; headers; titles. ||  ||  || Finally; in the \""Analyze & Predict\"" tab you are able to use your \\ || data to train Machine Learning models. The Model builder can be \\ || used to create more advanced pipelines (including defining your own \\ || features). The default steps are to first define the model fully \\ || (or some features may not work); then go over every node you want to \\ || customize and change its node options; and when you're done export the \\ || model (\""convert to model\"" button). Finally; head over to the \""Pipelines \\ || trainer\"" tab; select and train your model. If you want to run simpler \\ || models; there are additional tabs with the most common types of problems. ||  ||  || Project structure: ||     Contributors wanting to familiarize themselves with the project \\ ||     structure can take a look at the contributor guidelines \\ ||     (https:\/\/github.com\/KMouratidis\/EDA_miner_public\/wiki\/Style-guide-and-contributor-guidelines). \\ ||     You can also go through all the files and read the module docstrings \\ ||     that have rough guidelines about contributions. In the Python \\ ||     spirit; feel free to completely ignore them. || \""\""\""",,,Yes
6369,TODO: use a more unified interface,Yes,No,Yes
6370,TODO: This needs a better implementation; or at least a function,,,Yes
6371,TODO: properly do set up \/ tear down & split function & rename,,,Yes
6376,TODO: Does this indeed kill the server?,Yes,No,Yes
6378,TODO: Actually implement this; e.g.:,Yes,No,Yes
6379,TODO: Handle initial schema here,Yes,Yes,Yes
6384,Float columns can be anything; so ignore for now,No,Yes,Yes
6386,TODO: Why have this requester here if below you do your own request?!,,,Yes
6388,LGTM [py\/unused-import],No,Yes,Yes
6389,"\""\""\"" || Developer notes: ||     Some suggestions on what could be done: ||         - Implementing the editing and filtering of datasets. ||         - A \""download\"" button for datasets that were modified. ||         - More API connections. ||         - Prettier interfaces. || \""\""\""",,,Yes
6390,TODO: Any sidemenus; if any; should be added here. If none; delete.,Yes,Yes,Yes
6392,TODO: This might need change; depending on whether we specify,Yes,Yes,Yes
6393,TODO: This might need change when the login is implemented,,,Yes
6394,"\""\""\"" || This module collects the layouts for connecting to the various APIs. ||  || Functions: ||     - twitter_connect: Connect to the Twitter API. ||     - google_sheets_connect: Connect to the Google Sheets API. ||     - reddit_connect: Connect to the Reddit API. ||     - spotify_connect: Connect to the Spotify API. ||  || Notes to others: ||     You should probably not write code here; unless adding \\ ||     a new API connection (or improving existing ones). || \""\""\""",No,No,Yes
6400,"\""\""\"" || This module takes care of the menu and choices provided when the \\ || \""Analyze & Predict\"" high-level tab is selected. ||  || Dash callbacks: ||     - tab_subpages: Given the low-level tab choice; render the \\ ||                     appropriate view. ||     - render_sidemenu: Render the menu in the side-navbar. ||  || Notes to others: ||     You should probably not write code here; unless you are defining \\ ||     a new level-2 tab. Here you can find functionality to define or \\ ||     train ML \/ NN models. Implementations go to their own modules \\ ||     down the package hierarchy; in `apps.analyze`. || \""\""\""",Yes,Yes,Yes
6405,"\""\""\"" || Developer notes: ||     Some suggestions on what could be done: ||         - Improve handling of pipeline traversal and creation. ||         - Add new classes for the pipelines (inputs; transformers; \\ ||         data cleaners; models). ||         - Improve handling of data \/ use better data structures. || \""\""\""",Yes,Yes,Yes
6409,TODO: This probably needs a better implementation,Yes,No,Yes
6410,TODO: find a better way to estimate positions,,,Yes
6416,Prepend the input_node.id to the keys in case of columns,No,Yes,Yes
6417,FIXME: We're selecting the first because of one input during,Yes,No,Yes
6420,TODO: Visualize the (in)correctly grouped points.,,,Yes
6421,TODO: This probably needs a better\/cleaner implementation and\/or,,,Yes
6422,TODO: Visualize the (in)correctly grouped points.,,,Yes
6424,"TODO: Night-mode. It should be 1) a script that adds a \""night-mode\""",Yes,No,Yes
6430,"\""\""\"" || Developer notes: ||     Some suggestions on what could be done here: ||         - Define more PDF report layouts (see also `layouts.py`). ||         - Add more graph types in any of the categories (but avoid word \\ ||           vector visualizations). ||         - Add additional functionality in KPIs. ||         - Improve baseline graph and\/or function. ||         - Improve network visualizations. || \""\""\""",Yes,Yes,Yes
6432,Functions below here implement the various graphs,No,No,Yes
6434,"\""\""\"" || This module is about building and viewing KPIs. The user should be \\ || able to view more advanced graphs and also create their own indicators. ||  || Global Variables: ||     - Sidebar: To be used for creating side-menus. ||  || Functions: ||     - KPI_Options: Generate the layout of the dashboard. ||  || Dash callbacks: ||     - render_variable_choices_kpi: Create a menu of dcc components for \\ ||                                    the user to choose  plotting options. ||     - plot_graph_kpi: Plot the graph according to user choices. ||  || Notes to others: ||     Contributions are greatly needed and encouraged here. Main \\ ||     functionality is still lacking in this part. You can use this \\ ||     module to add new buttons; input; or other interface-related; \\ ||     element; or maybe a new type of graph (in which case implement \\ ||     it in `graphs.kpis.py`). Working on exporting KPI graphs is \\ ||     also encouraged. || \""\""\""",Yes,Yes,Yes
6437,TODO: Add a dash app for monitoring flask_prometheus,Yes,Yes,Yes
6439,"\""\""\"" || A dummy script to generate the database; a dummy user; and do any other \\ || initialization action needed to fire up the project. || \""\""\""",,,Yes
6440,TODO: Split this in 2 chained dropdowns. Use the first to,Yes,Yes,Yes
6444,after correlation analysis; column 38 and 122 were deleted for their low correlations with rest of other columns,No,Yes,Yes
6445,We have to memorise which columns we used so that we can produce the correct,Yes,No,Yes
6446,If we used column sampling then we have to make sure the columns of X are arranged,No,Yes,Yes
6447,TODO,Yes,Yes,Yes
6451,TODO construct unique key for statistics -- only need to generate imid and year,Yes,Yes,Yes
6453,crop (TODO verify that it's the correct ordering!),Yes,No,Yes
6454,TODO construct unique key for statistics -- only need to generate imid and year,Yes,Yes,Yes
6456,TODO: does this retain previous activations?,Yes,Yes,Yes
6457,Variable (b; hdim)  # HACK because we assume action is just a scalar,,,Yes
6458,end is the index right after where the term right after opidx ends,No,No,Yes
6461,"\""\""\"" || ==================== || Parallel Betweenness || ==================== ||  || Example of parallel implementation of betweenness centrality using the || multiprocessing module from Python Standard Library. ||  || The function betweenness centrality accepts a bunch of nodes and computes || the contribution of those nodes to the betweenness centrality of the whole || network. Here we divide the network in chunks of nodes and we compute their || contribution to the betweenness centrality of the whole network. ||  || This doesn't work in python2.7.13. It does work in 3.6; 3.5; 3.4; and 3.3. ||  || It may be related to this: || https:\/\/stackoverflow.com\/questions\/1816958\/cant-pickle-type-instancemethod-when-using-multiprocessing-pool-map || \""\""\""",No,Yes,Yes
6466,"r\""\""\"" This module provides functions and operations for bipartite || graphs.  Bipartite graphs `B = (U; V; E)` have two node sets `U;V` and edges in || `E` that only connect nodes from opposite sets. It is common in the literature || to use an spatial analogy referring to the two node sets as top and bottom nodes. ||  || The bipartite algorithms are not imported into the networkx namespace || at the top level so the easiest way to use them is with: ||  || >>> import networkx as nx || >>> from networkx.algorithms import bipartite ||  || NetworkX does not have a custom bipartite graph class but the Graph() || or DiGraph() classes can be used to represent bipartite graphs. However; || you have to keep track of which set each node belongs to; and make || sure that there is no edge between nodes of the same set. The convention used || in NetworkX is to use a node attribute named `bipartite` with values 0 or 1 to || identify the sets each node belongs to. This convention is not enforced in || the source code of bipartite functions; it's only a recommendation. ||   || For example: ||  || >>> B = nx.Graph() || >>> # Add nodes with the node attribute \""bipartite\"" || >>> B.add_nodes_from([1; 2; 3; 4]; bipartite=0) || >>> B.add_nodes_from(['a'; 'b'; 'c']; bipartite=1) || >>> # Add edges only between nodes of opposite node sets || >>> B.add_edges_from([(1; 'a'); (1; 'b'); (2; 'b'); (2; 'c'); (3; 'c'); (4; 'a')]) ||  || Many algorithms of the bipartite module of NetworkX require; as an argument; a || container with all the nodes that belong to one set; in addition to the bipartite || graph `B`. The functions in the bipartite package do not check that the node set || is actually correct nor that the input graph is actually bipartite. || If `B` is connected; you can find the two node sets using a two-coloring  || algorithm:  ||  || >>> nx.is_connected(B) || True || >>> bottom_nodes; top_nodes = bipartite.sets(B) ||  || However; if the input graph is not connected; there are more than one possible || colorations. This is the reason why we require the user to pass a container || with all nodes of one bipartite node set as an argument to most bipartite || functions. In the face of ambiguity; we refuse the temptation to guess and || raise an :exc:`AmbiguousSolution <networkx.AmbiguousSolution>` || Exception if the input graph for || :func:`bipartite.sets <networkx.algorithms.bipartite.basic.sets>` || is disconnected. ||  || Using the `bipartite` node attribute; you can easily get the two node sets: ||  || >>> top_nodes = {n for n; d in B.nodes(data=True) if d['bipartite']==0} || >>> bottom_nodes = set(B) - top_nodes ||  || So you can easily use the bipartite algorithms that require; as an argument; a || container with all nodes that belong to one node set: ||  || >>> print(round(bipartite.density(B; bottom_nodes); 2)) || 0.5 || >>> G = bipartite.projected_graph(B; top_nodes) ||  || All bipartite graph generators in NetworkX build bipartite graphs with the  || `bipartite` node attribute. Thus; you can use the same approach: ||  || >>> RB = bipartite.random_graph(5; 7; 0.2) || >>> RB_top = {n for n; d in RB.nodes(data=True) if d['bipartite']==0} || >>> RB_bottom = set(RB) - RB_top || >>> list(RB_top) || [0; 1; 2; 3; 4] || >>> list(RB_bottom) || [5; 6; 7; 8; 9; 10; 11] ||  || For other bipartite graph generators see || :mod:`Generators <networkx.algorithms.bipartite.generators>`. ||  || \""\""\""",No,Yes,Yes
6467,Maybe we should raise an exception here,Yes,Yes,Yes
6470,TODO Why is extra inner loop necessary?,,,Yes
6478,Find the first unused color.,No,Yes,Yes
6479,Find the smallest possible; unused color,No,Yes,Yes
6484,Compute k-edge-ccs using the most efficient algorithms available.,,,Yes
6487,workaround for classmethod decorator,,,Yes
6489,Full connectivity should be no better than our partial,,,Yes
6490,needed because K5s share only one node.,,,Yes
6491,TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!,Yes,Yes,Yes
6496,number of blocks needed to cover all edges,,,Yes
6500,##     and instead provide a method to do this manually. Eventually;,,,Yes
6502,HACK Since the `matching_dict_to_set` function returns a set of,Yes,Yes,Yes
6503,order for the set difference function to work. Ideally; we would,,,Yes
6504,"The algorithm is taken from \""Efficient Algorithms for Finding Maximum",No,No,Yes
6505,This is used for efficient computation of delta3.,,,Yes
6507,A stage finds an augmenting path and uses that to improve,No,Yes,Yes
6508,the stage ends. If there is no augmenting path; the,No,Yes,Yes
6509,This is not a particularly efficient implementation of this relation:,Yes,No,Yes
6512,TODO In Python 3; instances of the `object` class are,,,Yes
6515,TODO In Python 3; instances of the `object` class are,Yes,Yes,Yes
6516,expand outer blossom such that inner blossom ends up on an,,,Yes
6517,maybe *_d_threshold_sequence routines should,Yes,Yes,Yes
6520,TODO In Python 3.3+; this should be `yield from ...`,Yes,Yes,Yes
6522,TODO: Implement method from Gabow; Galil; Spence and Tarjan:,,,Yes
6523,Needed to make .copy() work,No,Yes,Yes
6524,Needed for 2.x\/3.x compatibilitity,Yes,No,Yes
6525,Move to method,Yes,Yes,Yes
6526,TODO: make this preserve the key. In fact; make this use the,,,Yes
6532,generator here to implement list;set;string...,No,Yes,Yes
6533,If all additional columns requested; build up a list of tuples,,,Yes
6537,FIXME: Why does this function accept a variadic dictionary of keyword arguments,Yes,Yes,Yes
6541,With each new edge; nodes at the ends of the edge are added to the list.,No,Yes,Yes
6544,to find the most general numeric format needed.,No,Yes,Yes
6545,"\""\""\"" || Read graphs in LEDA format. ||  || LEDA is a C++ class library for efficient data types and algorithms. ||  || Format || ------ || See http:\/\/www.algorithmic-solutions.info\/leda_guide\/graphs\/leda_native_graph_fileformat.html ||  || \""\""\""",,,Yes
6546,Apparently many Pajek format readers can't process this line,,,Yes
6552,TODO In Python 3.3+; this should be `yield from ...`.,,,Yes
6553,TODO: check for 'combinations' instead of permutations,,,Yes
6554,TODO: get transform matrix components from scene json,,,Yes
6556,TODO: not exact length,,,Yes
6562,imX = im.astype('float32')\/255. - .5 # TODO: have a mean image,Yes,Yes,Yes
6563,What is being done here is a bit of a hack. The thing is,Yes,No,Yes
6564,This `2048` better be un-hardcoded. Donno a way to have this number in the constructor,Yes,Yes,Yes
6566,TODO: the window (below) need to be reset as per Z.,,,Yes
6567,TODO: Regularization,,,Yes
6570,TODO : Generalized GPU version. Does not work for now.,,,Yes
6571,TODO : Possibly a function to do this,,,Yes
6572,TODO: To be replaced with NetVLAD-layer,,,Yes
6574,What is being done here is a bit of a hack. The thing is,,,Yes
6576,TODO: zNormalize im_batch,,,Yes
6580,TODO: Write a function to parse arguments,,,Yes
6582,"\""\""\"" Given a real camera image (captured from high flying drone; facing down). Does ||     an ANN query on the KD-tree to find the most similar image. It uses the VLAD-like ||     image representation ||  ||     Created : 25th Jan; 2017 ||     Author  : Manohar Kuse <mpkuse@connect.ust.hk> || \""\""\""",No,Yes,Yes
6583,TODO: Figure out why t_ann.load() does not work,Yes,No,Yes
6585,TODO: Figure out why t_ann.load() does not work,,,Yes
6589,xxx = np.multiply( nl_sm[:;kk:kk+1] * np.ones((1;256)); nl_Xd - nl_c[kk;:] ),,,Yes
6590,xxx_s = xxx[0:4800;:].sum( axis=0 ),No,Yes,Yes
6594,"\""\""\"" Likelihood Ratio Test of the NetVLAD descriptors ||         Computes the Likelihood ratio test of the trained descriptors' ability. ||         LR = frac{ Probab( dot(X;Y) > 0.8 \/ same place )} { Probab( dot(X;Y) > 0.8 \/ diff place) } ||  ||         This can be realized by drawing random samples from PandaRenderer\/NetVLADrenderer ||  ||         Created : 22nd Feb; 2017 ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||  || \""\""\""",No,Yes,Yes
6595,"\""\""\"" Neural Appearence based Place model (NAP) ||         Using the learned netvlad to find nearest neighbours from ||         past frames in current sequence in the high dimensioanl space (8192-dim). ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 17th Feb; 2017 || \""\""\""",No,Yes,Yes
6596,TODO: look at techniqures to build KD-tree index on the fly for ANN search,,,Yes
6597,"\""\""\"" Learn Siamese Mapping ||         Defines class DimRed to compute the mapping. This class will also ||         have a siamese style loss function ||  ||         Roughly based on ||         Hadsell; Raia; Sumit Chopra; and Yann LeCun. \""Dimensionality ||         reduction by learning an invariant mapping.\"" Computer vision and pattern ||         recognition; 2006 IEEE computer society conference on. Vol. 2. IEEE; 2006. ||  ||         Created : 24th Feb; 2017 ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> || \""\""\""",,,Yes
6599,TODO: write a color-mapped file,Yes,Yes,Yes
6600,choose a better vantage point selection process,No,No,Yes
6602,TODO: Try reduce_mean here. (As suggested in 'All About VLAD' paper),Yes,Yes,Yes
6604,TODO: Consider not writing pickle; instead just write them as .npz,Yes,Yes,Yes
6605,TODO Read as cmd-line arg,Yes,Yes,Yes
6607,TODO blur before resizing,Yes,Yes,Yes
6609,TODO: Validate these values. Currently working on trust that all these are OK values.,Yes,Yes,Yes
6610,"\""\""\"" Make ROC Plots ||  ||     Uses a trained model. Uses data from Pitssburg dataset to compute the ||     NetVLAD descriptors. Having known the ground truth will compute confusion matrix. ||     And then eventually the ROC plot for various thresholds. ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 24th Jan; 2018 || \""\""\""",No,Yes,Yes
6611,"\""\""\"" Loads a specified (learned) model. Loads the specified image. ||     Computes the netvlad descriptor and the association map. ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 30th Jan; 2018 || \""\""\""",No,Yes,Yes
6612,"\""\""\"" Demo usage script for my various renderers. ||  ||     These renderer classes are supposed to be used for feeding data into ||     tensorflow for training. This gives a nice way to separate data-handling ||     from the core learning part. This script demos the usage of the rendering ||     classes. This is mainly done because in my NetVLAD training I need to ||     draw complicated sample (query; positive set; negative set). This is very ||     different from the standard image-net style training where you just need ||     to feed images independently. ||  ||     Currently has the following renderers. ||     a) PandaRender - Images from 3d model. (needs to have python package Panda3d) ||     b) PittsburgRenderer - Draws samples from Pittsburg dataset ||     c) WalksRenderer - Keezi_walks is a youtube channel of walking around various cities with a camera. I have collected a few of those videos. ||     d) TimeMachineRender - From tokyoTM dataset ||  ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 11th July; 2017 ||         Updated : 7th Feb; 2018 || \""\""\""",,,Yes
6613,This `2048` better be un-hardcoded. Donno a way to have this number in the constructor,Yes,Yes,Yes
6614,TODO: Expect x to be individually normalized; ie. for each image in the batch; it has mean=0 and var=1,,,Yes
6615,TODO: Instead of using dot product use `acos( <q;P_i> )` as measure of,Yes,Yes,Yes
6618,"\""\""\"" Loads a specified (learned) model. Loads the specified image. ||     Computes the netvlad descriptor and the association map. ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 30th Jan; 2018 || \""\""\""",No,Yes,Yes
6619,"\""\""\"" ||     A class interfce to netvlad based whole image descriptor. To use the ||     pre-trained network in your application use this code and unit-test ||  ||     Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||     Created : 20th Aug; 2018 || \""\""\""",,,Yes
6621,"\""\""\"" NetVLAD training; slightly better model representation for ||     cost computation. ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 7th Oct; 2018 || \""\""\""",No,Yes,Yes
6622,TODO: callbacks : Tensorboard; lr; multigpu,Yes,Yes,Yes
6627,move pixels locally around (with random strengths),No,No,Yes
6628,sometimes move parts of the image around,No,Yes,Yes
6630,TODO : Either a) set keras's data augmentation b) or use imgaug. Get rid of custom data augmentation.,Yes,Yes,Yes
6631,TODO : add kernel regularizers and activity_regularizer to conv layers,,No,Yes
6633,TODO: Verify the computations of this function,,,Yes
6634,TODO: Also implement triplet loss and compare performance.,Yes,Yes,Yes
6635,"\""\""\"" NetVLAD training. Using features from deeper VGG layers. ||  ||     - Input -- BN -- MobileNet -- NetVLAD ||     - Deeper features (instead of currently using very shallow ones) ||     - Verify my pairwise_loss also implement triplet loss ||     - Keras sequence use ||  ||         Author  : Manohar Kuse <mpkuse@connect.ust.hk> ||         Created : 15th Oct; 2018 || \""\""\""",Yes,Yes,Yes
6636,TODO - Triplet loss,,,Yes
6642,[[[[[Option-B]]]]] (from h5 files). Apparently h5 stores the model config and the weights.,,,Yes
6643,TODO: Removal. No need to apply distortion as this is taken care of by img_aug package.,Yes,Yes,Yes
6644,TODO : removal,Yes,No,Yes
6645,TODO : removal,,,Yes
6647,TODO : removal,,,Yes
6648,TODO This is a simpler implementation of WSequence. Eventually delete WSequence,Yes,No,Yes
6650,TimeDistributed - This is a hack to get Weakly-supervised learning working,Yes,Yes,Yes
6651,TODO,,,Yes
6652,TODO : removal,Yes,No,Yes
6654,sometimes move parts of the image around,No,Yes,Yes
6657,TODO,Yes,Yes,Yes
6659,change_model_inputshape uses model_from_json internally; I feel a bit uncomfortable about this.,Yes,Yes,Yes
6661,a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1\/4hler for this suggestion,No,Yes,Yes
6662,In order to implement ALEXNET; we are resizing them to,No,Yes,Yes
6663,In order to implement ALEXNET; we are resizing them to,No,Yes,Yes
6664,Resize and crop if needed.,No,No,Yes
6670,todo: Curvelet based isophotes?,,,Yes
6671,TODO: Drop using these. Write stuff in C,,,Yes
6673,todo fix strides,,,Yes
6675,Todo optimize -> cython,Yes,Yes,Yes
6676,Check rank todo,Yes,Yes,Yes
6677,todo set own noise variance,,,Yes
6678,todo flip arguments to match random_dictionary,,,Yes
6679,todo pickle support for faster to\/from python,Yes,Yes,Yes
6680,Implement __getitem__ to fix,,,Yes
6685,TODO!,,,Yes
6686,TODO This is a mess; there must better way,,,Yes
6687,TODO better name,Yes,Yes,Yes
6690,check more iterations better,No,No,Yes
6691,would be a nice idea if the upsampling could be learned too;,No,Yes,Yes
6693,False = Allocate all GPU memory at the beginning. True = Allocate only as much GPU memory as needed.,,,Yes
6696,maybe the requested attribute is missing?,No,Yes,Yes
6697,we are out of luck; but we have no idea why,No,Yes,Yes
6698,i.e.; How many bits of additional information are needed to where we are on axis 1 if we know where we are on axis 0?,No,No,Yes
6699,'linear' = human-readable; 'recursive' = efficient; None = select automatically.,No,Yes,Yes
6700,'linear' = human-readable; 'recursive' = efficient; None = select automatically,,,Yes
6701,The gradients of these are not necessary efficient or even meaningful.,Yes,Yes,Yes
6703,Leaky ReLU activation. More efficient than tf.nn.leaky_relu() and supports FP16.,No,No,Yes
6707,"print \""Blind Performance Best\""",No,Yes,Yes
6709,Sort candidates by loss; lesser loss is better,No,Yes,Yes
6710,TODO: properly handle <UNK>,Yes,Yes,Yes
6711,finally project down if needed,,,Yes
6712,finally project down to projection dim if needed,No,Yes,Yes
6713,load the checkpoint data if needed,No,No,Yes
6714,#NAME?,,,Yes
6715,You can just specify the packages manually here if your project is,,,Yes
6718,This import is needed so that pickle knows about the class Ex2Job.,,,Yes
6719,create parameter instance that is needed for any batch computation engine,No,Yes,Yes
6720,each computing node loads by itself (no data passing).,,,Yes
6722,create parameter instance that is needed for any batch computation engine,No,Yes,Yes
6724,This import is needed so that pickle knows about the class Ex5Job.,No,Yes,Yes
6725,create parameter instance that is needed for any batch computation engine,No,Yes,Yes
6727,It's a kind of workaround,Yes,No,Yes
6729,It's a kind of workaround,,,Yes
6730,w = os.get_terminal_size().columns,No,Yes,Yes
6731,It's a kind of workaround,,,Yes
6732,w = os.get_terminal_size().columns,,,Yes
6734,w = os.get_terminal_size().columns,,,Yes
6735,It's a kind of workaround,Yes,No,Yes
6737,It's a kind of workaround,Yes,No,Yes
6738,w = os.get_terminal_size().columns,No,Yes,Yes
6739,It's a kind of workaround,Yes,No,Yes
6740,w = os.get_terminal_size().columns,,,Yes
6741,It's a kind of workaround,,,Yes
6742,this flush method is needed for python 3 compatibility.,,,Yes
6744,this flush method is needed for python 3 compatibility.,,,Yes
6745,this flush method is needed for python 3 compatibility.,,,Yes
6747,Otherwise if it's punctuation; we're either somehow before or directly after a word.,,,Yes
6749,TODO: review and fix this behavior.,Yes,Yes,Yes
6750,TODO: limit the number of words returned to half or a maximum:,Yes,Yes,Yes
6751,TODO: find good balance here. Lower?,Yes,No,Yes
6752,TODO: safer and cleaner to do this here; otherwise doing this only once at transform time would be faster.,Yes,No,Yes
6753,TODO: behavior is unchanged. Could be improved.,Yes,Yes,Yes
6754,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
6755,TODO:,Yes,No,Yes
6757,"sentences = [\""I feel a little bit tired today; but I am really happy!\"";",No,Yes,Yes
6759,TODO: should handle any sentence with no token or more than maxlen tokens,,,Yes
6761,TODO: the following 3 lines should be replaced by the above return statement,Yes,Yes,Yes
6762,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
6763,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
6765,move onto the next state,No,Yes,Yes
6768,move onto the next state,,,Yes
6770,TODO,,,Yes
6772,TODO: to be filled,Yes,Yes,Yes
6774,the CoNLL 2000 task on chunking has three columns: text; pos and np (chunk),No,No,Yes
6780,TODO: use bucket to improve performance,Yes,No,Yes
6782,the CoNLL 2000 task on chunking has three columns: text; pos and np (chunk),No,No,Yes
6783,the GERMEVAL task only has two columns: text and ner,No,No,Yes
6784,(!!) needed for code inside fcn_arch; utils..,Yes,Yes,Yes
6787,(one hypothesis - maybe our steps below include two gobal steps somehow...,,,Yes
6789,Most probably the inception models were trainined using this color augmentation:,,,Yes
6790,AF WTF how did it work...,No,Yes,Yes
6791,TODO: try bilinear resampling for image only,,,Yes
6794,TODO: hide 'low-contrast' image warning during saving.,,,Yes
6795,TODO: check if it works for other datasets,,,Yes
6798,TODO: add non-adaptive visualization function; where the colorbar,Yes,Yes,Yes
6799,''' ||     Credits: ||     Vast majority of this package should be credited to Daniil of http:\/\/warmspringwinds.github.io\/; ||      (or to one of his own spiritual fathers). A healthy round of applaud is in place; really. ||       ||     We at Hailo added some adaptaions: ||         - updated tf_records.py to work with TF Datasets (the modern way of feeding data in tensorflow) ||         - somewhat improved visualization ||         - records creation as script vs. notebook; with some doc || ''',,,Yes
6801,...below line is redundant but mean_iou won't work without it somehow..,,,Yes
6805,TODO mean_iou is doing flattening! is it OK?,,,Yes
6806,"TODO add back an option to run without preprocessing... (\""native\"")",Yes,Yes,Yes
6808,won't really work w. pixels==None,Yes,Yes,Yes
6810,"better in case of downsampling (avoids aliasing a.k.a \""moire\"")",,,Yes
6812,"TODO add back an option to run \""native\"" (without pre-scaling to pixels x pixels at all)",,,Yes
6813,camvid_label2name = {lb:str(lb) for lb in range(CAMVID_NUM_CLASSES+1)}  # TODO names...,,,Yes
6815,TODO FCN8,,,Yes
6816,if self.is_training == 'placeholder': # SDK workaround,,,Yes
6817,is_training = 'placeholder' # TEMP!!! SDK hack,,,Yes
6820,recompute temporary state if needed,,,Yes
6821,XXX,No,Yes,Yes
6823,XXX,,,Yes
6825,TO-DO: need to check all the attribute of the ops as well,Yes,No,Yes
6828,assume sampled loss is averaged. TO-DO:figure out better,,,Yes
6829,TO-DO: figure out why this op has delays (possibly moving,,,Yes
6830,Input and output variables needed for computing loss,,,Yes
6832,HACK,Yes,No,Yes
6833,Frames per env; so total (nenv * frames) Frames needed,No,Yes,Yes
6834,save the policy if it's better than the previous ones,,,Yes
6839,FIXME: Incorrect call argument...,Yes,Yes,Yes
6840,TODO: Add session everywhere for GAIL,Yes,Yes,Yes
6842,Feel free to fix it if you know what is meant here.,Yes,Yes,Yes
6843,HACK,,,Yes
6845,TODO: Add session everywhere for GAIL,,,Yes
6846,TODO: fix missing\/inacurate comments,,,Yes
6847,HACK,,,Yes
6850,TODO: add support for continuous actions,Yes,No,Yes
6853,TODO: replace with stable_baselines.__version__,Yes,Yes,Yes
6856,Fix for DDPG:,,,Yes
6857,TODO: simplify this to this:,Yes,No,Yes
6859,TODO: replay_buffer refactoring,,,Yes
6860,TODO: replay_buffer refactoring,Yes,No,Yes
6866,TODO: replay_buffer refactoring,Yes,No,Yes
6868,Use two Q-functions to improve performance by reducing overestimation bias.,No,Yes,Yes
6870,from a uniform distribution for better exploration.,,,Yes
6871,Transform to callable if needed,,,Yes
6872,TODO: why not init_scale = 0.001 here like in the feedforward,,,Yes
6875,check if a gpu version is needed,No,Yes,Yes
6876,TODO: replay_buffer refactoring,Yes,No,Yes
6877,TODO: replay_buffer refactoring,,,Yes
6878,so no additional changes is needed in the dataloader,No,Yes,Yes
6879,maybe with Gumbel-max trick ? (http:\/\/amid.fish\/humble-gumbel),No,No,Yes
6882,TODO: replace with normal tb logging,Yes,No,Yes
6883,Reshape actions if needed when using discrete actions,No,Yes,Yes
6884,maybe we can try calling `compute_reward()` ?,,,Yes
6887,Use two Q-functions to improve performance by reducing overestimation bias,,,Yes
6888,Transform to callable if needed,No,Yes,Yes
6891,Create the monitor folder if needed,,,Yes
6892,Warn the user if needed.,No,No,Yes
6894,Create folder if needed,,,Yes
6895,Create folders if needed,,,Yes
6898,Automatic wrapping; old way of doing callbacks,,,Yes
6899,Exit processes if needed,,,Yes
6900,Stop training if the performance is good enough,No,Yes,Yes
6902,case a corresponding rule is needed (at least for the time being),Yes,No,Yes
6903,--> the representation of M is columns major; i.e. M[i] is the i-th,,,Yes
6904,I am not sure what the best approach is except to hard code them?,,,Yes
6905,-- Options for todo extension ----------------------------------------------,,,Yes
6906,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
6907,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
6908,ends with non regex,,,Yes
6909,likewise if hour >= 12 no 'pm' action is needed,,,Yes
6910,ToDo: earlyfirst; earlylateafternoon,No,No,Yes
6911,TODO: the second element of the rule is not being used,,,Yes
6912,ends with non regex,No,No,Yes
6917,TODO: why do we have a different method for scoring,Yes,Yes,Yes
6919,TODO: we should make sure ctparse_gen never returns None. If there is no result,,,Yes
6920,likewise if hour >= 12 no 'pm' action is needed,,,Yes
6921,more than 1000. A better way would be to return an ordering tuple instead;,No,Yes,Yes
6922,"\""\""\""Those rules are applied as postprocessing steps after scoring has been already || done. Needed for backwards compatibility.\""\""\""",,,Yes
6923,TODO: NEEDS BETTER EXPLANATION\/ORGANISATION,Yes,Yes,Yes
6924,Enable mouse move events,,,Yes
6925,TODO,Yes,Yes,Yes
6927,last_annotation = self.in_progress_annotation  #TODO: self?,Yes,No,Yes
6928,somehow; for the numpad key in some machines; a check on Insert is needed aswell,,,Yes
6930,Move the layer up (negative offset) or down (postive offset),No,No,Yes
6931,The index we want to move to,No,Yes,Yes
6932,self.clearChanges() #TODO perhaps?,Yes,No,Yes
6933,and set the required environment variables as needed; such that,,,Yes
6934,use a convolution with appropriate kernel; manually deal with the boundaries first,No,Yes,Yes
6935,and set the required environment variables as needed; such that,No,Yes,Yes
6936,Check if C-Support is available for better performance,No,No,Yes
6938,IDs are needed.,,,Yes
6940,if the label is not known; but ends with a 'group' (e.g. cargroup),No,No,Yes
6943,TODO: rename.,Yes,Yes,Yes
6945,''' || ######################################################### || This file trains a deep learning model to predict || disruptions on time series data from plasma discharges. ||  || Dependencies: || conf.py: configuration of model;training;paths; and data || builder.py: logic to construct the ML architecture || data_processing.py: classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',,,Yes
6946,''' || ######################################################### || This file trains a deep learning model to predict || disruptions on time series data from plasma discharges. ||  || Dependencies: || conf.py: configuration of model;training;paths; and data || model_builder.py: logic to construct the ML architecture || data_processing.py: classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',,,Yes
6948,The shortest works best so far: less overfitting. log TTd prediction also works well. 0.5 better than 0.2,,,Yes
6949,size 100 slight overfitting; size 20 no overfitting. 200 is not better than 100. Prediction much better with size 100; size 20 cannot capture the data.,No,Yes,Yes
6950,'loss' : target.loss; #binary crossentropy performs slightly better?,No,No,Yes
6951,1e-4 is too high; 5e-7 is too low. 5e-5 seems best at 256 batch size; full dataset and ~10 epochs; and lr decay of 0.90. 1e-4 also works well if we decay a lot (i.e ~0.7 or more),No,Yes,Yes
6954,''' || ######################################################### || This file trains a deep learning model to predict || disruptions on time series data from plasma discharges. ||  || Dependencies: || conf.py: configuration of model;training;paths; and data || model_builder.py: logic to construct the ML architecture || data_processing.py: classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',No,No,Yes
6955,##TODO add optimizers other than SGD,,,Yes
6956,''' || ######################################################### || This file containts classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',,,Yes
6958,''' || ######################################################### || This file containts classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',No,No,Yes
6965,binary crossentropy performs slightly better?,No,No,Yes
6966,FIXME deprecated,,,Yes
6967,FIXME perhaps it is better to pass from driver or derive a class from History or Callbacks,,,Yes
6971,FIXME prepare callbacks to pass here,,,Yes
6972,potentially move to conf.yaml,,,Yes
6973,potentially move to conf.yaml,Yes,Yes,Yes
6974,FIXME deprecated,Yes,No,Yes
6975,FIXME perhaps it is better to pass from driver or derive a class from History or Callbacks,Yes,Yes,Yes
6983,''' || ######################################################### || This file trains a deep learning model to predict || disruptions on time series data from plasma discharges. ||  || Dependencies: || conf.py: configuration of model;training;paths; and data || builder.py: logic to construct the ML architecture || data_processing.py: classes to handle data processing ||  || Author: Julian Kates-Harbeck; jkatesharbeck@g.harvard.edu ||  || This work was supported by the DOE CSGF program. || ######################################################### || ''',,,Yes
6984,"'''TODO || - incorporate stats; pass machine (perhaps save machine in stats object!) || - incorporate stats; have a dictionary of aggregate stats for every machine. || - check \""is_previously_saved\"" by making sure there is a normalizer for every machine || '''",,,Yes
6987,cut shot ends if we are supposed to,No,No,Yes
6988,cut_shot_ends = conf['data']['cut_shot_ends'],No,Yes,Yes
6990,cut_shot_ends = conf['data']['cut_shot_ends'],No,Yes,Yes
6991,if cut_shot_ends:,,,Yes
6995,performs !much better than minmaxnormalizer,,,Yes
6996,performs !much better than minmaxnormalizer,No,No,Yes
6998,TODO(KGF): this funciton is unused,Yes,Yes,Yes
6999,TODO(KGF): confirm that this second PRNG seed setting is not needed,,,Yes
7000,TODO(KGF): maybe only allow end='';'\\r';'\ || ' to prevent bugs?,Yes,Yes,Yes
7001,TODO(KGF): above; builder.py (bug workaround); mpi_launch_tensorflow.py;,Yes,Yes,Yes
7002,"Cannot fix these Keras internals via \""import tensorflow.compat.v1 as tf\""",,,Yes
7003,TODO(KGF): replace this hacky workaround,,,Yes
7004,TODO(KGF): perhaps relax the requirement of thse dependencies with try\/except,Yes,Yes,Yes
7006,TODO(KGF): replace this hacky workaround,Yes,Yes,Yes
7008,TODO(KGF): currently unused shot list files in project directory,Yes,Yes,Yes
7009,TODO(KGF): replace this hacky workaround,,,Yes
7010,TODO(KGF): perhaps relax the requirement of thse dependencies with try\/except,Yes,Yes,Yes
7011,"LSTM in ONNX: \""The maximum opset needed by this model is only 9.\""",,,Yes
7012,TODO should be WeightNorm here; but using batchNorm instead,,,Yes
7013,TODO remove later.,,,Yes
7016,TODO(KGF): next 3x fns are currently unused; near dupes of Preprocessor class,Yes,No,Yes
7017,TODO(KGF): remove unused threshold_range() methods (#54),Yes,No,Yes
7018,TODO(KGF): unused,,,Yes
7020,KGF: why random position?,Yes,Yes,Yes
7021,TODO: should ignore any files that dont match our naming convention,,,Yes
7022,TODO(KGF): why would d3d_all preprocessed shots result in this behavior,,,Yes
7024,TODO: info \u2192 debug in release,Yes,No,Yes
7025,TODO,,,Yes
7027,TODO move to some util\/misc module?,,,Yes
7029,`config.rics` is a better idea,No,Yes,Yes
7030,TODO move to some util\/misc module?,Yes,Yes,Yes
7031,It is better to share one procedure with the search;,No,Yes,Yes
7032,Let's keep that in mind and add it back if needed.,,,Yes
7033,SQLite doesn't implement DROP COLUMN so we just nullify them instead,Yes,Yes,Yes
7034,Note: `sommaire` is in reverse order; because python lists are better,No,Yes,Yes
7035,Backtrack if the word ends with an intra-word char,,,Yes
7041,print(data) # fix,Yes,No,Yes
7042,print(data) # fix,,,Yes
7043,print(data) # fix,Yes,No,Yes
7045,In case of super batching; additional functionality must be,No,Yes,Yes
7046,TODO: add several named commonly used values for bwa_mem_args,Yes,Yes,Yes
7047,This try...except only needed in the case where training stops after,No,No,Yes
7048,"\""\""\""  Convention: inMat row major (C ordering) as (time; batch; state) || \""\""\""",No,No,Yes
7049,TODO: initialise forget gate bias to positive value,Yes,Yes,Yes
7050,Equivalent to np.dot(np.diag(D); H) but faster; apparently,,,Yes
7051,We will use chunk_starts and chunk_ends to stitch the basecalls together,,,Yes
7053,We will use chunk_starts and chunk_ends to stitch the basecalls together,No,No,Yes
7055,TODO include logic to merge data sets with different alphabets,,,Yes
7058,Add move score,,,Yes
7061,TODO could add additional checks for layer size or names; but,,,Yes
7062,TODO apply additional attributes (e.g. has_bias; convolutional padding),Yes,Yes,Yes
7063,json files are due to the unused GRU bias parameters.,Yes,Yes,Yes
7064,TODO implement extraction of reference sequence and alignment parsing,,,Yes
7065,group read ids by batch for more efficient access,No,Yes,Yes
7067,XXX make a is_a_imgs function ?,,,Yes
7068,XXX make a is_a_imgs function ?,No,Yes,Yes
7070,ToDo,Yes,Yes,Yes
7074,Fix for AUC = 1 if no overlap;,,,Yes
7075,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
7077,Might consider moving anatomical field out of object and just request when needed.  Probably only when plotting,Yes,Yes,Yes
7078,Regress method is pretty convoluted and slow; this should be optimized better.,Yes,Yes,Yes
7081,This can be done by passing in a vector of unique subject IDs that,,,Yes
7084,"\""\""\"" || Univariate Regression || ============================================================ ||  || This example simulates data according to a very simple sketch of brain || imaging data and applies a standard two-level univariate GLM to identify || significant voxels. ||  || \""\""\""",No,Yes,Yes
7085,We can also easily perform convolution and the class is smart enough to ignore all constant and polynomial columns,No,Yes,Yes
7087,A really nice feature of this class is simplified; but intelligent matrix concatentation. Here it's trivially to horizontally concatenate our convolved onsets and covariates; while keeping our column names and order.,No,Yes,Yes
7088,But we can also intelligently vertically concatenate design matrices to handle say; different experimental runs; or subjects. The method enables the user to indicate which columns to keep separated during concatenation or which to treat as extensions along the first dimension. By default the class will keep constant terms separated.,,,Yes
7090,We can also easily perform convolution and the class is smart enough to ignore all constant and polynomial columns,,,Yes
7091,Here we fill NaN values with 0 and zscore all columns except the last. Because the class has all of pandas functionality; method-chaining is built-in.,,,Yes
7092,A really nice feature of this class is simplified; but intelligent matrix concatentation. Here it's trivially to horizontally concatenate our convolved onsets and covariates; while keeping our column names and order.,No,Yes,Yes
7093,But we can also intelligently vertically concatenate design matrices to handle say; different experimental runs; or subjects. The method enables the user to indicate which columns to keep separated during concatenation or which to treat as extensions along the first dimension. By default the class will keep constant terms separated.,,,Yes
7097,Figure out what columns we need to relabel,No,No,Yes
7098,Rename the columns and update the dm,Yes,Yes,Yes
7099,for colA;colB in zip(out.columns; outdf.columns):,No,Yes,Yes
7103,Prevent copy of all data in self multiple times; instead start with an empty instance and copy only needed attributes from self; and use this as a template for other outputs,,,Yes
7105,- This `environment` configurable,No,Yes,Yes
7106,The `enviornment` configurable should be set by JupyterHub administrators to,Yes,Yes,Yes
7108,# An optional hook function that you can implement to do some bootstrapping work,No,Yes,Yes
7109,"''' || MmtfSequenceFileReader.py: Reads and decodes an MMTF Hadoop Sequence file. || (e.g. PDB ID) as the key and the MMTF StructureDataInterface as the value. ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" || TODO:  || '''",,,Yes
7113,Get chain types from Chain ID: #TODO#,Yes,No,Yes
7115,Get chain types from Chain ID: #TODO#,Yes,No,Yes
7116,Get group types for chain: #TODO#,Yes,No,Yes
7119,TODO Can't Find getGroupNames : Double check with Peter if it is in group_list,,,Yes
7121,TODO Clarify on group_counter,,,Yes
7122,TODO clarify on group_counter,,,Yes
7124,TODO Peter uses switch case; might have to do with getQ3Code,Yes,Yes,Yes
7125,TODO Not sure how to DsspSecondaryStructure.getQ3Code,Yes,No,Yes
7129,TODO,Yes,Yes,Yes
7132,"TODO Traceback \""ResourceWarning: unclosed file\""",,,Yes
7133,TODO Docstring,,,Yes
7136,TODO Check logic flow,Yes,Yes,Yes
7139,TODO Can't Find getGroupNames : Double check with Peter if it is in group_list,Yes,No,Yes
7140,TODO can't find getGroupName,Yes,Yes,Yes
7142,TODO Peter uses switch case; might have to do with getQ3Code,,,Yes
7144,TODO double check break is for switchcase,,,Yes
7147,"TODO Traceback \""ResourceWarning: unclosed file\""",,,Yes
7148,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by resolution;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7149,"TODO Traceback \""ResourceWarning: unclosed filecodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 25: ordinal not in range(128)\""",,,Yes
7152,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7153,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7154,TODO: Mapper structure to polymer chains,Yes,Yes,Yes
7155,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Pass\"" || '''",No,Yes,Yes
7156,TODO: Mapper structure to polymer chains,Yes,Yes,Yes
7157,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7158,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",,,Yes
7160,"TODO Traceback \""ResourceWarning: unclosed filecodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 25: ordinal not in range(128)\""",Yes,Yes,Yes
7162,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7164,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",,,Yes
7168,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rWork;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7169,TODO: Mapper structure to polymer chains,,,Yes
7172,"''' || dsspSecondaryStructure.py: ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" || '''",No,Yes,Yes
7177,"TODO Traceback \""ResourceWarning: unclosed filecodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 25: ordinal not in range(128)\""",,,Yes
7183,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rFree;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7184,"TODO Traceback \""ResourceWarning: unclosed filecodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 25: ordinal not in range(128)\""",,,Yes
7186,"''' || Simple example of reading an MMTF Hadoop Sequence file; filtering the entries \\ || by rFree;and counting the number of entries. ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Mars Huang\"" || __email__ = \""marshuang80@gmai.com: || __status__ = \""Warning\"" || '''",No,Yes,Yes
7187,"TODO Traceback \""ResourceWarning: unclosed filecodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 25: ordinal not in range(128)\""",Yes,Yes,Yes
7189,"''' || structureToPolymerChain.py: ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" ||  || '''",No,Yes,Yes
7190,TODO skipping adding inter group bond info for now,Yes,No,Yes
7193,"''' || structureToInteractingResidues.py: ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" ||  || '''",,,Yes
7194,TODO add unique group (and atom?) for each group?,Yes,Yes,Yes
7197,TODO double check,Yes,No,Yes
7199,TODO double check while loop logic,Yes,No,Yes
7201,TODO double check indexing,Yes,Yes,Yes
7202,TODO double check while loop logic,Yes,No,Yes
7203,TODO using local mmtf-python,Yes,Yes,Yes
7204,TODO import piscesDownloader,Yes,Yes,Yes
7206,"''' || dsspSecondaryStructure.py: ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" || '''",,,Yes
7208,TODO Docstring,Yes,No,Yes
7209,TODO,Yes,Yes,Yes
7211,"''' || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmai.com: ||     __status__ = \""debug\"" || '''",No,Yes,Yes
7213,TODO colNames to be string or list,Yes,Yes,Yes
7215,"''' || dataAnalysisWithDataFramesExample.py: ||  || Example script to demonstrate how to do data analysis with dataframes || using mmtf-pyspark ||  || Authorship information: ||     __author__ = \""Peter Rose\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: || '''",No,Yes,Yes
7219,TODO Set xtal info,,,Yes
7221,TODO Set bioassembly info,,,Yes
7226,# TODO: precalculate DSSP secondary structure,,,Yes
7228,# TODO: how to get formal charge?,,,Yes
7229,biop_encoder.set_group_bond()  ## TODO,,,Yes
7231,TODO dictionary in bytes,,,Yes
7233,TODO dictionary in bytes,Yes,Yes,Yes
7234,TODO dictionary in bytes,Yes,Yes,Yes
7236,TODO dictionary in bytes,,,Yes
7237,TODO: set inputdata first,Yes,Yes,Yes
7238,TODO check,,,Yes
7241,"''' || secondaryStructureElementDemo.py: ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",No,Yes,Yes
7242,"''' || secondaryStructureElementExtractor.py: ||  || # TODO comment ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Debug\"" || '''",,,Yes
7245,TODO: unable to use filter when dataset is set to global,Yes,No,Yes
7246,TODO: Using self.dataset causes spark unable to use filter,,,Yes
7247,"''' || advancedQueryService.py ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",,,Yes
7248,"''' || customReportDemo.py: ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",No,Yes,Yes
7252,Get requested data columns,,,Yes
7253,"''' || JpredDemo.py: ||  ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",,,Yes
7256,TODO named tuple or enum,Yes,Yes,Yes
7257,"''' || SecondaryStructureOneHotEncoderDemo.py: ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",No,Yes,Yes
7259,TODO data count is more than Java,Yes,No,Yes
7263,TODO data count is more than Java,Yes,No,Yes
7265,TODO set input column,,,Yes
7268,TODO data count is more than Java,Yes,No,Yes
7270,TODO,Yes,Yes,Yes
7272,TODO predictor.getClass().getSimpleName(),Yes,No,Yes
7273,TODO predictor.getClass();getSimpleName,Yes,Yes,Yes
7276,"''' || UniProtDemo.py: ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",,,Yes
7277,"''' || UniProt.py ||  || Thisclass<ahref=\""http:\/\/www.uniprot.org\/downloads\"">downloads<\/a>andreads || UniProtsequencefilesintheFASTAformatandconvertsthemtodatasets.This || classreadsthefollowingfiles:SWISS_PROT;TREMBL;UNIREF50;UNIREF90;UNIREF100. ||  || Thedatasetshavethefollowing || <ahref=\""http:\/\/www.uniprot.org\/help\/fasta-headers\"">columns<\/a>. ||  || <p> || Example:download;read;andsavetheSWISS_PROTdataset ||  || <pre> ||     {@code ||     Dataset<Row>ds=UniProt.getDataset(UniProtDataset.SWISS_PROT); ||     ds.printSchema(); ||     ds.show(5); || ds.write().mode(\""overwrite\"").format(\""parquet\"").save(fileName); || } || <\/pre> ||  ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",No,Yes,Yes
7287,from src.main.datasets import UniProtDataset # TODO find ways to skip import,,,Yes
7288,"''' || structureToPolymerSequences.py: ||  || Authorship information: ||     __author__ = \""Mars Huang\"" ||     __maintainer__ = \""Mars Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" ||  || '''",,,Yes
7292,TODO: Numpy bool type is different than python bools; might need to fix,Yes,Yes,Yes
7296,convert structure to an array-based format for efficient processing,No,Yes,Yes
7299,TODO: points or neighbor points,Yes,Yes,Yes
7300,TODO Make get_interactions function (need atomInteractions),Yes,Yes,Yes
7303,TODO use list instead of numpy,,,Yes
7304,"''' || MmtfBenchmark.py: Benchmarking of MMTF-Hadoop Sequence file reading ||  || Authorship information: ||     __author__ = \""Peter Rose\"" || '''",,,Yes
7305,TODO: check if all sequence files are gzipped,Yes,Yes,Yes
7306,"'''advancedQueryService.py ||  || Authorship information: ||     __author__ = \""Mars (Shih-Cheng) Huang\"" ||     __maintainer__ = \""Mars (Shih-Cheng) Huang\"" ||     __email__ = \""marshuang80@gmail.com: ||     __status__ = \""Done\"" || '''",,,Yes
7312,TODO: double check logic flow,Yes,No,Yes
7314,"'''traverseStructureHierachy.py ||  || A class that prints of hierachy information about a structure ||  || Example || ------- ||  ||     pdb = mmtfReader.download_mmtf_files(['1STP']; sc) ||     pdb.foreach(lambda t: traverseStructureHierarchy.printMmtfInfo(t[1]) ) ||  ||     structure = mmtfReader.download_mmtf_files(['1STP']; sc).collect()[0] ||     traverseStructureHierarchy.print_mmtf_info(structure[1]) ||  || Authorship information: ||     __author__ = \""Yue Yu\"" ||     __maintainer__ = \""Mars (Shih-Cheng) Huang\"" ||     __email__ = \""marshuang80@gmail.com\"" ||     __version__ = \""0.2.0\"" ||     __status__ = \""Done\"" || '''",No,Yes,Yes
7317,This exmaple queries the \\_citation category. Each category represents a table; and fields represent database columns. [Avalible tables and columns](https:\/\/pdbj.org\/mine-rdb-docs),,,Yes
7319,"This demo creates a dataset by extracting secondary structure elements \""H\""; then encode an overlapping Ngram feature vector",,,Yes
7320,Each category represents a table and fields represent database columns; see:,,,Yes
7321,[Available tables and columns](https:\/\/pdbj.org\/mine-rdb-docs),No,Yes,Yes
7324,"\""\""\"" || Downloads PDB to UniProt chain and residue-level mappings from the SIFTS project. || Data are retrieved from a data cache and only data that are not cached || are downloaded when required. || This class also provides a method to create a new mapping file. ||  || For more information about SIFTS see: || The \""Structure Integration with Function; Taxonomy and Sequence\"" || https:\/\/www.ebi.ac.uk\/pdbe\/docs\/sifts\/overview.html is || the authoritative source of up-to-date chain and residue-level || mappings to UniProt. ||  || Example of chain-level mappings ||  || >>> df = get_chain_mappings() || >>> df.show() ||  || +----------------+-----------+-------+---------+ || |structureChainId|structureId|chainId|uniprotId| || +----------------+-----------+-------+---------+ || |          1A02.F|       1A02|      F|   P01100| || |          1A02.J|       1A02|      J|   P05412| || |          1A02.N|       1A02|      N|   Q13469| ||  || Example of residue-level mappings ||  || >>> df = get_cached_residue_mappings() || >>> df.show() ||  || Columns: || structureChainId - pdbId.chainId || pdbResNum - PDB residue number in ATOM records || pdbSeqNum - PDB residue number in the sequence record (index start at 1) || uniprotId - UniProt id (accession number) || uniprotNum - UniProt residue number (index starts at 1) ||  || +----------------+---------+---------+---------+----------+ || |structureChainId|pdbResNum|pdbSeqNum|uniprotId|uniprotNum| || +----------------+---------+---------+---------+----------+ || |          1STP.A|     null|        1|   P22629|        25| || |          1STP.A|     null|        2|   P22629|        26| || |          1STP.A|     null|        3|   P22629|        27| || |          1STP.A|     null|       12|   P22629|        36| ||  ... || |          1STP.A|       13|       13|   P22629|        37| || |          1STP.A|       14|       14|   P22629|        38| || |          1STP.A|       15|       15|   P22629|        39| ||  ... || \""\""\""",,,Yes
7325,cleanup and rename columns to be consistent with MMTF conventions.,Yes,Yes,Yes
7326,split residue columns into an array,No,No,Yes
7331,Convert RDD to a Dataset with the following columns and types,No,No,Yes
7332,TODO add this to ColumnarStructure,Yes,No,Yes
7337,new more efficient method,No,Yes,Yes
7338,'''columnarStructure.py ||  || Provides efficient access to structure information in the form of atom-based arrays. || Data are lazily initialized as needs. ||  || ''',No,Yes,Yes
7340,n = ends[-1],,,Yes
7343,TODO should this be int,Yes,Yes,Yes
7346,TODO check if these methods are still required,,,Yes
7349,TODO,Yes,Yes,Yes
7350,TODO temporary,Yes,No,Yes
7351,TODO should compare chain_id since ligands may have the same chain id as proteins,Yes,No,Yes
7353,TODO call method by string?,,,Yes
7354,TODO should compare chain_id since ligands may have the same chain id as proteins,,,Yes
7355,define query columns,No,Yes,Yes
7356,define target columns,No,Yes,Yes
7362,TODO,Yes,Yes,Yes
7363,TODO check if any value exceeds min\/max -> skip this step?,Yes,Yes,Yes
7364,TODO optimize speed; e.g. use mod to find #repeats,Yes,Yes,Yes
7365,TODO initialize as str or np.object_ or default?,Yes,Yes,Yes
7366,TODO optimize this method,Yes,Yes,Yes
7367,# TODO call method by string?,Yes,Yes,Yes
7369,TODO optimize speed; e.g. use mod to find #repeats,Yes,Yes,Yes
7372,TODO,,,Yes
7374,TODO bio assemblies; bonds; entity lists,Yes,No,Yes
7375,TODO,Yes,Yes,Yes
7376,TODO option to add columns; see: https:\/\/stackoverflow.com\/questions\/47094437\/adding-np-arrays-to-existing-pandas-dataframe,Yes,Yes,Yes
7377,"''' ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Peter Rose\"" || __status__ = \""Warning\"" || '''",No,Yes,Yes
7378,"''' ||  || Authorship information: || __author__ = \""Peter Rose\"" || __maintainer__ = \""Peter Rose\"" || __status__ = \""Warning\"" || '''",No,Yes,Yes
7380,TODO need to update entity_list when self.truncate,Yes,Yes,Yes
7381,TODO fix this,Yes,Yes,Yes
7385,TODO this should be a range; e.g. tuple ('1';10);(20;30),,,Yes
7387,Sort the atomic numbers. This is not needed but makes things maybe a,No,No,Yes
7390,Sort the atomic numbers. This is not needed but makes things maybe a,No,No,Yes
7391,vector direction. We take as many copies as needed for the,No,Yes,Yes
7392,sparse matrix; CSR is good for efficient math.,No,Yes,Yes
7394,"print(\""Time needed to get sine matrix:\""; dt_get_sinemat)",No,No,Yes
7395,"print(\""Time needed to get charge over distance matrix:\"")",No,No,Yes
7396,"print(\""Time needed to get nrep random permutations of coulomb matrix:\"")",,,Yes
7397,TODO: check that the user input makes sense...,Yes,Yes,Yes
7398,-- Options for todo extension ----------------------------------------------,,,Yes
7399,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
7400,Fully periodic with minimum image convention,,,Yes
7401,If a specific atom is marked to be in the center; move it to be,,,Yes
7404,values mean better accuracy.,No,Yes,Yes
7405,Fix ordering,No,Yes,Yes
7406,# No cell needed for finite systems,,,Yes
7407,Fix ordering,Yes,Yes,Yes
7408,k>=i. The enumeration begins from [0; 0; 0]; and ends at [n_elem;,No,No,Yes
7409,Needed to specify X++ runtime library on OSX. This solution is replicated,Yes,Yes,Yes
7410,# k>=i. The enumeration begins from [0; 0; 0]; and ends at [n_elem;,No,No,Yes
7411,# No cell needed for finite systems,,,Yes
7412,from [0; 0; 0]; and ends at [n_elem; n_elem; n_elem]; looping the,,,Yes
7414,vector direction. We take as many copies as needed for to reach the,No,Yes,Yes
7415,# vector direction. We take as many copies as needed for to reach the,No,Yes,Yes
7416,Precalculate the alpha and beta constants for the GTO basis,,,Yes
7418,If centers are given and\/or cell indices are needed; the process is done,,,Yes
7420,# Fully periodic with minimum image convention,,,Yes
7423,the -fvisibility flag is needed by pybind11,,,Yes
7424,rCutHard = rcut + 5 # ??? This should not be needed,Yes,No,Yes
7428,# needed for constructing the real form,No,Yes,Yes
7432,Position way outside bins,,,Yes
7436,# Calculate the partial power spectrum. This loop is the most efficient,No,Yes,Yes
7439,needed for constructing the real form,No,Yes,Yes
7443,Calculate with central finite difference implemented in C++,No,No,Yes
7444,Calculate with central finite difference implemented in C++,,,Yes
7445,variables. Pytorch will not do this by default as it is typically not needed.,,,Yes
7446,Perhaps most common scenario: multiple systems with same atoms in,,,Yes
7447,Calculate with central finite difference implemented in C++,,,Yes
7451,needed for constructing the real form,No,Yes,Yes
7453,# Perhaps most common scenario: multiple systems with same atoms in,,,Yes
7454,# Calculate with central finite difference implemented in C++,,,Yes
7455,Perhaps most common scenario: multiple systems with same atoms in,No,No,Yes
7456,Calculate with central finite difference implemented in C++.,No,No,Yes
7457,highly efficient for zero-initialized arrays. Similar,,,Yes
7458,FIXME grep-based hack,Yes,Yes,Yes
7460,FIXME '_inherit' is pickle-initializier specific,,,Yes
7462,FIXME we pin this preprocessing action to GPU because of,,,Yes
7463,FIXME we pin this preprocessing action to GPU because of,Yes,Yes,Yes
7464,FIXME variables not used,Yes,No,Yes
7466,TODO add IO interface to module,Yes,Yes,Yes
7467,TODO SplitNode handling,Yes,Yes,Yes
7468,TODO instantiate layer,Yes,Yes,Yes
7469,TODO channel gating to follow after merge into develop,Yes,Yes,Yes
7471,FIXME gating mult is only used in channel gating;,Yes,Yes,Yes
7473,TODO Instead of minimizing L1 regularization loss; we could,,,Yes
7475,FIXME is_contiunue??,,,Yes
7476,FIXME decarese?,Yes,Yes,Yes
7477,FIXME is_contiunue ??,Yes,Yes,Yes
7482,TODO make threshold a variable,,,Yes
7483,a hack,,,Yes
7485,TODO is multiple application allowed?,Yes,Yes,Yes
7486,a temporary hack,Yes,No,Yes
7487,TODO: finish channel pruner,,,Yes
7488,FIXME estimator is tensorflow-only for now,Yes,Yes,Yes
7489,TODO change decrease scale,Yes,Yes,Yes
7491,TODO: check decrease scale,,,Yes
7493,TODO: check decrease scale,Yes,No,Yes
7494,FIXME this cannot do vector-wise,,,Yes
7496,TODO integrate this into Profile.,,,Yes
7497,FIXME this consumes a huge amount of memory; please consider,Yes,Yes,Yes
7498,FIXME,Yes,Yes,Yes
7501,Xitong: FIXME @vaenyr Couldn't this be achieved by:,Yes,Yes,Yes
7504,TODO this works as a way to collect global gammas; but the `gamma`,Yes,Yes,Yes
7505,will fix later if performance proves to be problematic.,,,Yes
7506,FIXME setting trace to frame does not work,,,Yes
7508,TODO: cope with multiple overriders inside mask_quantizer_map,,,Yes
7511,TODO this works as a way to collect global gammas; but the `gamma`,Yes,Yes,Yes
7518,FIXME hacky way to make it instantiate only one tower,Yes,Yes,Yes
7519,FIXME this method is somewhat redundant; as similar,Yes,Yes,Yes
7520,FIXME is tf.map_fn good for performance?,Yes,Yes,Yes
7521,FIXME annoying hack for batching different sized shapes,Yes,No,Yes
7522,FIXME annoying hack for batching different sized shapes;,Yes,Yes,Yes
7523,FIXME annoying hack for batching different sized shapes,Yes,No,Yes
7524,# FIXME: not sure whether this fix affects other behaviors,,,Yes
7525,FIXME annoying hack for batching different sized shapes,Yes,No,Yes
7527,FIXME: this is redundant; could use o.quantize_loss(),,,Yes
7528,TODO resize to input image,Yes,No,Yes
7530,FIXME how can we continue search?,,,Yes
7531,shouldn't be a problem,No,Yes,Yes
7532,TODO continue here...,Yes,Yes,Yes
7535,FIXME use overrider.estimate,Yes,Yes,Yes
7536,TODO _add_overrider here,,,Yes
7537,TODO _add_overrider here,Yes,Yes,Yes
7538,FIXME speghetti,Yes,Yes,Yes
7540,@Aaron @Xitong FIXME possible redundancy:,Yes,Yes,Yes
7541,FIXME @xitong should saturate mantissa when the exponent,,,Yes
7542,TODO fixed point bitwidth after multiplication,,,Yes
7544,TODO: add completion to --update,Yes,Yes,Yes
7545,print the options to be filtered by bash (maybe filter them here?),Yes,No,Yes
7548,TODO: validate against responses,Yes,No,Yes
7550,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
7551,temporary hack (due to piclking issues otherwise; this needs to be fixed),Yes,Yes,Yes
7552,This is really not efficient as it's done a second time in _cluster_func,,,Yes
7553,as apparently there is way to reliably get the target of a PR with circle,,,Yes
7557,TODO unused variables,,,Yes
7558,TODO unused variables,Yes,No,Yes
7560,TODO unused (overwritten on the next line),,,Yes
7561,TODO unused variables,Yes,No,Yes
7565,TODO unused (overwritten on the next line),,,Yes
7566,Make this call in a background process (there should be a better way of doing it),,,Yes
7568,make sure we can use the selected columns as an index,No,Yes,Yes
7569,ignore all additional columns,No,Yes,Yes
7571,TODO unused variable,,,Yes
7572,TODO unused variable,,,Yes
7574,TODO unused variable,Yes,Yes,Yes
7575,This is really not efficient as,,,Yes
7576,TODO: this can be better rewritten with df.to_dict(),Yes,No,Yes
7579,Make this call in a background process (there should be a better way of doing it),Yes,Yes,Yes
7581,This is really not efficient as,Yes,Yes,Yes
7582,get file information; needed for samefile on older Python versions,,,Yes
7583,"XXX extended paths should also disable the collapsing of \"".\""",No,Yes,Yes
7584,XXX if suffix is None; should the current suffix be removed?,No,Yes,Yes
7585,is accessed.  XXX is this necessary?,,,Yes
7589,contactenate all columns together,,,Yes
7590,Fix numpy seed for reproducibility,,,Yes
7591,Fix random seed for reproducibility,No,No,Yes
7592,Fix TensorFlow graph-level seed for reproducibility,,,Yes
7594,f_{i}(x) = activation(W_{i} * x + b); where activation is ReLU according to the paper,No,No,Yes
7595,f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x)),,,Yes
7596,Fix numpy seed for reproducibility,No,Yes,Yes
7597,Fix random seed for reproducibility,No,No,Yes
7598,Fix TensorFlow graph-level seed for reproducibility,,,Yes
7599,TODO warm start,,,Yes
7603,TODO: that's kind of unsafe,,,Yes
7605,TODO: refactor!,Yes,Yes,Yes
7606,TODO: improve (as a sentence is generally much longer than the two entities),,,Yes
7608,Close node from last tick; if needed,No,No,Yes
7611,Configure here for speed if jacobian is not needed,No,Yes,Yes
7614,tend to hang around some times.,No,Yes,Yes
7616,pass #TODO: generate individual notation,Yes,No,Yes
7617,TODO: debug the situation where parents are not related,Yes,Yes,Yes
7619,lets move simplfy to updateT,Yes,Yes,Yes
7621,TO DO: silence this on the console for better output,Yes,No,Yes
7622,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7624,TODO:  this is no longer needed,Yes,No,Yes
7626,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7627,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7628,fix!!,Yes,Yes,Yes
7633,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7636,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7638,Implement a transform in which we identify,,,Yes
7639,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7640,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7641,move loop logic outside of the node 21-Jun-2017 -DZ,Yes,Yes,Yes
7642,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7645,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7646,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7648,these self.assertTrues are not conditional - no self.assertTrueion counting needed,,,Yes
7650,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7654,TODO: color stderr,,,Yes
7655,TODO: simplify javascript using ;ore than 1 class in the class attribute?,,,Yes
7656,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7658,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7659,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7660,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",No,Yes,Yes
7662,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7667,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7669,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7670,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7671,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7673,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",No,Yes,Yes
7674,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7675,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",No,Yes,Yes
7678,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",No,Yes,Yes
7679,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7680,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7681,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7682,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7683,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7684,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7685,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,No,Yes,Yes
7686,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7688,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7689,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7692,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7693,3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.,,,Yes
7696,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",,,Yes
7697,Big thanks for your help; really appreciate it.,No,Yes,Yes
7701,###   Temp code:  manually review all the FK matrix equations(!),,,Yes
7702,"standardize on the order \""alpha N-1; a N-1; d N; theta N' for the DH table columns.",Yes,Yes,Yes
7704,elist[0][3][i] = e  # HACK: put aux eqns into row 4 Meqn[0],Yes,No,Yes
7706,work around pytorch shape bug,,,Yes
7707,work around a pytorch bug,Yes,No,Yes
7708,FIXME this doesn't work at all,,,Yes
7709,TODO implement optimized .contract(),Yes,Yes,Yes
7712,TODO implement optimized .contract(),Yes,Yes,Yes
7713,TODO implement optimized .argcontract(),Yes,Yes,Yes
7718,TODO apply log_abs_det_jacobian of each transform in self.subs,Yes,Yes,Yes
7719,FIXME for densities; add log_abs_det_jacobian,,,Yes
7721,TODO repopulate path,Yes,Yes,Yes
7722,This illustrates why effect handlers are a useful PPL implementation technique:,No,No,Yes
7723,FIXME for densities; add log_abs_det_jacobian,Yes,Yes,Yes
7724,TODO unsqueeze and expand,Yes,No,Yes
7730,TODO,,,Yes
7732,TODO get input args right,Yes,Yes,Yes
7734,TODO don't reduce a dimension too early - keep a collections.Counter,,,Yes
7736,TODO use backend einsum directly,,,Yes
7737,XXX is this true?,,,Yes
7738,TODO need Finitary as well?,,,Yes
7744,TODO Can we simply return x here?,Yes,No,Yes
7748,TODO unsqueeze and expand,,,Yes
7749,TODO move to registry,Yes,Yes,Yes
7750,TODO use defaultdict,Yes,Yes,Yes
7751,TODO disable memoization by default,,,Yes
7753,FIXME,Yes,Yes,Yes
7754,TODO be more efficient here,Yes,Yes,Yes
7755,TODO make more efficient,,,Yes
7756,XXX hack to make OpRegistry work,,,Yes
7758,TODO do this once on class init.,,,Yes
7759,TODO do this once on class init.,,,Yes
7760,XXX is this necessary?,,,Yes
7761,TODO add general Distribution,,,Yes
7764,TODO add general Distribution,Yes,Yes,Yes
7766,FIXME broadcast here,,,Yes
7768,TODO,,,Yes
7769,FIXME,Yes,Yes,Yes
7770,TODO check data,,,Yes
7771,TODO support advanced indexing,,,Yes
7772,"raise NotImplementedError(\""TODO implement naive plated einsum\"")",,,Yes
7773,FIXME implement .align() attribute.,Yes,No,Yes
7775,TODO set a better value for this,,,Yes
7777,FIXME this does not align to new ints.,Yes,Yes,Yes
7779,FIXME add missing terms,Yes,Yes,Yes
7780,TODO Compute a jacobian; update log_prob; and emit another Delta.,Yes,Yes,Yes
7781,TODO Implement ops.add to simulate .to_event().,Yes,No,Yes
7782,work around shape bug https:\/\/github.com\/pytorch\/pytorch\/issues\/16685,Yes,No,Yes
7783,FIXME Is this valid?,Yes,Yes,Yes
7785,This is a globally configurable parameter to draw multiple samples.,,,Yes
7786,FIXME: Quadratic integration is not supported:,,,Yes
7787,naive_contract_einsum;  # XXX not working; probably issue with canonicalization,,,Yes
7788,TODO Use exact KLs where possible.,,,Yes
7789,This illustrates why effect handlers are a useful PPL implementation technique:,No,No,Yes
7791,FIXME do not marginalize; instead sample.,,,Yes
7793,FIXME Is this valid?,Yes,Yes,Yes
7794,This illustrates why effect handlers are a useful PPL implementation technique:,,,Yes
7795,TODO allow mixing of sampling and exact integration,,,Yes
7797,TODO remove this when removing eager_subs methods,Yes,No,Yes
7800,TODO Promote this to a first class funsor; enabling zero-copy slicing.,Yes,Yes,Yes
7801,FIXME triggers tensor op,Yes,No,Yes
7803,TODO support syntax,,,Yes
7806,TODO perform math here once sequential_sum_product has been,Yes,No,Yes
7807,TODO This could be optimized into a single .reshape().cat().reshape() if,Yes,Yes,Yes
7808,TODO perform math here once sequential_sum_product has been,,,Yes
7812,TODO use correct op here with bin_op,Yes,No,Yes
7816,TODO use correct op here with bin_op,,,Yes
7817,TODO Implement ops.add to simulate .to_event().,,,Yes
7819,TODO refactor this logic into Gaussian.eager_subs() and,Yes,No,Yes
7820,FIXME Most code assumes this is an AssociativeCommutativeOp.,Yes,Yes,Yes
7822,"XXX hacks to simulate \""expand\""",Yes,Yes,Yes
7823,TODO support continuous random effects with monte carlo,Yes,No,Yes
7824,seed is used to fix the RNG state when calling a model.,,,Yes
7825,TODO Consider using this for more than binary contractions.,Yes,Yes,Yes
7826,TODO: return self._eager_subs_affine(affine_subs; lazy_subs),,,Yes
7827,TODO: return self._eager_subs_affine(affine_subs; lazy_subs),,,Yes
7828,FIXME: this raises AttributeErorr: 'Unary' object has no attribute 'data',Yes,Yes,Yes
7829,TODO restrict to factors that depend on free_vars,,,Yes
7831,XXX: convert NumPy scalar to ndarray,No,Yes,Yes
7834,TODO: add numpy einsum here,,,Yes
7835,TODO: we should not change global states here,Yes,No,Yes
7837,TODO: remove dtype when using JAX. For now; we cast to np.float64,Yes,Yes,Yes
7838,TODO: remove this logic when using JAX,Yes,Yes,Yes
7840,TODO attempt to infer output,,,Yes
7844,FIXME: contruct TriangularSolveMeta and TriangularSolveOp to cache,Yes,No,Yes
7845,TODO: use unscaled_sample key instead of random key here; this won't work under jit,Yes,Yes,Yes
7847,TODO attempt to infer output,Yes,Yes,Yes
7854,XXX: if the backend does not have the same definition of constraints; we should,,,Yes
7855,XXX: in Pyro backend; we always convert pyro.distributions.Categorical,No,Yes,Yes
7856,XXX: subclasses of Pyro distribution which defines a custom __init__ method,,,Yes
7857,TODO: enable when minipyro is backend-agnostic,Yes,Yes,Yes
7858,TODO: make this file backend agnostic,Yes,No,Yes
7861,This is needed to pacify sphinx.,No,Yes,Yes
7863,TODO Promote this to a Funsor subclass.,Yes,Yes,Yes
7865,TODO remove dependency on numpy in this file,Yes,Yes,Yes
7866,FIXME Most code assumes this is an AssociativeCommutativeOp.,,,Yes
7867,TODO is this right?,,,Yes
7874,@to_data.register(Unary[ops.SigmoidOp; Variable])  # TODO create a SigmoidOp class,,,Yes
7875,TODO: remove this `if` for NumPyro > 0.4.0,Yes,Yes,Yes
7877,TODO: investigate why jax backend gives inconsistent results on Travis,,,Yes
7880,"(\""LogisticNormal\""; ());  # TODO handle as transformed dist",Yes,Yes,Yes
7888,XXX is this ever nonzero?,Yes,No,Yes
7889,TODO move these properties upstream to numpyro.distributions,Yes,Yes,Yes
7894,XXX should this return a Union?,No,Yes,Yes
7895,TODO support domains,,,Yes
7896,TODO make registry a WeakKeyDictionary,,,Yes
7897,TODO make this work with transforms with nontrivial event_dim logic,Yes,No,Yes
7898,XXX should this return a Union?,Yes,Yes,Yes
7899,Work around a bug in to_funsor(TransformedDistribution),Yes,No,Yes
7903,FIXME this can lead to linear nesting of interpretations,Yes,Yes,Yes
7904,TODO: find a solution for an example subfolder; e.g. examples\/mixed_hmm folder,Yes,Yes,Yes
7905,FIXME this should simply be isinstance(cls; Domain),Yes,Yes,Yes
7906,TODO refactor this once Approximate is merged,,,Yes
7907,TODO Add a check for injectivity and dispatch to scatter_add etc.,Yes,Yes,Yes
7909,FIXME make lazy_output linear instead of quadratic in the size of the tape,Yes,No,Yes
7910,TODO fix traversal order in AdjointTape instead of using stack_reinterpret,,,Yes
7913,TODO adapt from moment_matching,,,Yes
7914,TODO implement this,Yes,Yes,Yes
7915,XXX Temporarily use Pyro's MNIST https:\/\/github.com\/pyro-ppl\/pyro\/pull\/2775,,,Yes
7916,TODO do we expect this +x or not?,,,Yes
7917,TODO absorb this into interpret,Yes,Yes,Yes
7918,this isn't really a mathematical op,No,Yes,Yes
7919,TODO generalize to more funsor types; ideally to Funsor itself.,,,Yes
7921,# TODO Finish implementation of generalized hdf5 file generation,,,Yes
7922,TODO########################################################## Figure out how to split up the gradient averaging,Yes,No,Yes
7923,TODO########################################################## Figure out how to split up the gradient averaging,Yes,No,Yes
7924,TODO########################################################## Figure out how to split up the gradient averaging,,,Yes
7925,Why slice? Wasn't range specified to be len(minVidFrames),Yes,No,Yes
7926,Definition of all arguments needed in functions defined within this file,No,Yes,Yes
7930,TODO: Add more preprcessing arguments if desired #,Yes,No,Yes
7932,TODO: Add any video related preprocessing (looping; resampling; etc.... Options found in utils\/preprocessing_utils.py) #,Yes,Yes,Yes
7933,############## TO DO: FIX THIS ASAP ########################,,,Yes
7936,TODO: Add any video related preprocessing (looping; resampling; etc.... Options found in utils\/preprocessing_utils.py) #,Yes,Yes,Yes
7938,TODO: Final Layer must be 'logits'                                             #,Yes,Yes,Yes
7941,TODO: Add more preprcessing arguments if desired #,,,Yes
7942,TODO: ADD CUSTOM LOSS HERE; DEFAULT IS CROSS ENTROPY LOSS                       #,Yes,Yes,Yes
7943,Errors occurring in a model's preprocessing function are not properly traced back when using 'clip_q'.,Yes,Yes,Yes
7947,TODO: On iteration 0; loss=11 and loss_scale()=32768; so scaled_loss=inf.,Yes,Yes,Yes
7948,It would be better to have rank 0 save the model and all the ranks read it; but,Yes,Yes,Yes
7951,unused,,,Yes
7952,"model_dir: str = field(default=None; metadata={\""help\"": \""Unused; but passed by SageMaker\""})",,,Yes
7957,TODO: Tokenizer batch encode,Yes,Yes,Yes
7958,TODO: Corrupt some of these instead of mask,Yes,No,Yes
7961,TODO: Should I use bert-base-uncased?,Yes,No,Yes
7962,TODO: Change to 0.15,Yes,Yes,Yes
7963,TODO: If generator generates correct token; invert the loss,Yes,Yes,Yes
7964,TODO: Abstract out to specify any checkpoint path,,,Yes
7968,TODO: Remove these since they're a little too specific,Yes,No,Yes
7971,TODO: Re-add validation step,Yes,No,Yes
7976,This method is only needed for momentum optimization.,No,Yes,Yes
7979,TO-DO: check what happens with grayscale images,Yes,No,Yes
7980,# TO-DO: No parece que este try - except est\u00E9 haciendo nada,,,Yes
7983,TO-DO: What if it is a zFace?,Yes,No,Yes
7984,'''Core module of the estnltk library. || Defines functionality common to all modules. || ''',,,Yes
7990,TODO complete indexing,,,Yes
7991,Basically wraps around the javabridge library; which needs to be installed,,,Yes
7994,TODO MAP TIMO POS TO KOM POS,,,Yes
7995,TODO satisfy timo via additional relation_synset annotations,Yes,Yes,Yes
7997,''' || Module containing functionality for training and using NER models. || ''',No,Yes,Yes
7998,'''Functionality for using Java-based components. ||  || Attributes || ---------- || JAVARES_PATH: str ||     The root path for Java components of Estnltk library. || ''',No,No,Yes
7999,todo: fix the problem here,Yes,No,Yes
8000,TODO: siin tuleks ilmselt keelata ka 'saama + Verb_tud' konstruktsioonide laiendused;,,,Yes
8002,This is a bit ugly; but it avoids running this again.,Yes,Yes,Yes
8004,text classifier related + some needed in future,No,No,Yes
8005,TODO: because order of the timex.items() is arbitary; inserting,Yes,Yes,Yes
8009,TODO: fix the indexerror,Yes,Yes,Yes
8017,FIXME:imageRegEx; ImagesParser,Yes,Yes,Yes
8023,TODO: FULL LABEL ISSUE,Yes,Yes,Yes
8025,TODO.  pudi-padi; special pages,,,Yes
8026,"\""\""\"" ||     referencesRegEx = re.compile(r'&lt;ref(.+?)(\/&gt|\/ref&gt);'; re.DOTALL|re.IGNORECASE) ||     references = referencesRegEx.finditer(data) ||     refend = referencesEndRegEx.finditer(data) ||     count = 0 ||     ends = [] ||     for i in references: ||        # print(i.end()) ||        print(i.group()) ||        print('--------------------------') ||        count += 1 ||     print('sss'; referencesParser(data)) ||     print(count) || \""\""\""",No,No,Yes
8027,TODO: this method should reveive text w shit cut out.,,,Yes
8029,TODO: \u00FClesande 2.a (aesteetikute ja kihtide mappingu parsimine) v\u00F5iks enne edasi liikumist,,,Yes
8030,TODO: HEADER ja FOOTER lihtsuse m\u00F5ttes t\u00F5sta klassist v\u00E4lja mooduli tasemele v\u00F5i,,,Yes
8031,TODO: return pole vajalik kuna vaikimisi ilma returnita meetodid alati v\u00E4ljastavad None,,,Yes
8032,TODO: t\u00E4helepanek; et siin meetodis tuleb kindlasti abstraheerida konkreetsed kihid,,,Yes
8033,TODO: m\u00E4rgendamine v\u00F5iks t\u00F6\u00F6tada kihtide start\/end positsioonide peal.,Yes,Yes,Yes
8035,TODO: m\u00E4rkus; css renderdamine ei tohiks s\u00F5ltuda tekstist,Yes,No,Yes
8036,TODO: suured eeldefineeritud mallid\/tekstiblokid v\u00F5iks t\u00F5sta mooduli tasemele v\u00F5i eraldi moodulisse (nt templates.py),Yes,Yes,Yes
8037,TODO: kas try\/except on IndexErrori tuvastamiseks?,Yes,Yes,Yes
8039,TODO: m\u00E4rkus. CSS klasside genereerimisel tuleb hiljem arvestada ka seda; et erinevad m\u00E4rgendused v\u00F5ivad kattuda;,Yes,Yes,Yes
8042,"\""\""\""Core module of the Estnltk library; that sets up some common paths and has functions to convert between || binary and unicode data. ||  || Python 2.x and Python 3.x versions are different in the way the handle unicode data. ||  || * Python 2 uses ``str`` for binary data and ``unicode`` for textual data. || * Python 3 uses ``str`` for unicode data and ``bytes`` for binary data. ||  || As it is impossible to write code that is compatible with both Python versions due to using different types; || we use :py:func:`~estnltk.core.as_unicode` and  :py:func:`~estnltk.core.as_binary` to abstact the conversion away. ||  || \""\""\""",,,Yes
8043,TODO: Should there be text = Text(text) ?,Yes,Yes,Yes
8044,TODO: \u00FClesande 2.a (aesteetikute ja kihtide mappingu parsimine) v\u00F5iks enne edasi liikumist valmis teha; kuna see aitab l\u00E4bi m\u00F5elda kuidas koodi paremini struktureerida,Yes,Yes,Yes
8045,TODO: HEADER ja FOOTER lihtsuse m\u00F5ttes t\u00F5sta klassist v\u00E4lja mooduli tasemele v\u00F5i isegi eraldi moodulisse; n\u00E4iteks teha moodul nimega templates.py ja sealt need importida,,,Yes
8046,TODO: return pole vajalik kuna vaikimisi ilma returnita meetodid alati v\u00E4ljastavad None (sama t\u00E4helepanek ka allpool olevate meetodite kohta),Yes,No,Yes
8047,TODO: m\u00E4rkus. CSS klasside genereerimisel tuleb hiljem arvestada ka seda; et erinevad m\u00E4rgendused v\u00F5ivad kattuda; n\u00E4iteks teksti v\u00E4rv ja taustav\u00E4rv. Selliste juhtude lahendamiseks peaks olema \u00FCks CSS klass iga aesteetik-v\u00E4\u00E4rtuse paari jaoks.,Yes,Yes,Yes
8050,TODO: Text('jklafh'),,,Yes
8051,TODO: PrettyPrinter(bacground = 'white'),,,Yes
8054,TODO from . import templates,Yes,Yes,Yes
8055,TODO: m\u00E4rkus. CSS klasside genereerimisel tuleb hiljem arvestada ka seda; et erinevad m\u00E4rgendused v\u00F5ivad kattuda; n\u00E4iteks teksti v\u00E4rv ja taustav\u00E4rv. Selliste juhtude lahendamiseks peaks olema \u00FCks CSS klass iga aesteetik-v\u00E4\u00E4rtuse paari jaoks.,Yes,Yes,Yes
8056,TODO: m\u00E4rkus. CSS klasside genereerimisel tuleb hiljem arvestada ka seda; et erinevad m\u00E4rgendused v\u00F5ivad kattuda; n\u00E4iteks teksti v\u00E4rv ja taustav\u00E4rv. Selliste juhtude lahendamiseks peaks olema \u00FCks CSS klass iga aesteetik-v\u00E4\u00E4rtuse paari jaoks.,,,Yes
8057,' '.join is not really needed here; but we use it for consistency of Tag information.,No,Yes,Yes
8063,TODO: delete me.,,,Yes
8064,TODO: missing actual assertions,,,Yes
8066,TODO: missing actual assertions,,,Yes
8069,TODO: vaikimisi v\u00F5iks olla lisatud nagu praegu,Yes,No,Yes
8071,A hack for defining a string type common in Py 2 and Py 3,Yes,No,Yes
8073,in Python 3.4; although; apparently; all file handles seem to be closed;,No,Yes,Yes
8074,Nothing seems to be wrong in Python 2.7;,,,Yes
8075,TODO: tegelikult on yldse kysitav; kas siin midagi peale 'mitte'\/'ei' peaks lubama ...,Yes,Yes,Yes
8076,TODO: M6nikord me ikkagi tahame; et D ka sees oleks; nt:,,,Yes
8077,Non-hack variant: word tokenization has not been applied yet;,No,Yes,Yes
8078,A hack variant: word tokenization has already been made; so,Yes,Yes,Yes
8082,2) Fix overlapping graphic annotations in the index,,,Yes
8083,Hack: fix for a potential overflow \/ unclosed graphics,,,Yes
8086,TODO: tempfile is currently used to ensure that the input is in 'utf-8';,Yes,Yes,Yes
8088,If required; fix self-references (in punctuation):,Yes,Yes,Yes
8092,Fix self references ( if requested ),No,Yes,Yes
8096,deciding whether one sentence ends and another begins;,No,No,Yes
8097,Fix sentence tags that mistakenly could have analysis (in EDT corpus),,,Yes
8099,Fix links pointing out of the sentence;,No,Yes,Yes
8102,TODO: Here we create a new Text object and add an ANALYSIS layer to it;,Yes,Yes,Yes
8104,ner models take time to load; load only when needed,No,Yes,Yes
8106,A hack variant: word tokenization has already been made; so,,,Yes
8107,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
8108,b. fix the sentence begin\/end tags,,,Yes
8112,TODO tee \u00FCks annotation F ja pane sinna listi k\u00F5ik praegused F v\u00E4\u00E4rtused,Yes,Yes,Yes
8114,TODO use mkdtemp (https:\/\/pymotw.com\/2\/tempfile\/) to cache output,Yes,No,Yes
8118,TODO do not line up with tokenization boundaries.,Yes,Yes,Yes
8119,TODO Should this raise an exception instead? Metamapping should be preprocessing possibly,Yes,No,Yes
8122,TODO I simply transferred my exploratory code - it is a mess and needs to be cleaned.,Yes,Yes,Yes
8125,TODO Look into spacy GoldParse,,,Yes
8128,TODO refactor completely. This should take a Pipeline and output the build ann file using that pipeline,Yes,Yes,Yes
8129,TODO This code really needs a fixing but it is bootstrapped to work from development,,,Yes
8130,TODO I hacked this together and never looked at it again - please don't judge :) -Andriy.,Yes,Yes,Yes
8134,"\""\""\"" || Converts data from made to brat. Enter input and output directories as command line arguments. || The associated txt file is not needed to perform any calculations. ||  || :date: 23 November; 2018 || :author: Steele W. Farnsworth || \""\""\""",No,No,Yes
8137,TODO metamap.map_text is broken currently,,,Yes
8144,"\""\""\"" || A medaCy annotation. This stores all relevent information needed as input to medaCy or as output || \""\""\""",,,Yes
8148,TODO replaced each time the data is updated (if it is).,Yes,Yes,Yes
8151,"\""\""\"" || A Dataset facilities the management of data for both model training and model prediction. || A Dataset object provides a wrapper for a unix file directory containing training\/prediction || data. If a Dataset; at training time; is fed into a pipeline requiring auxilary files || (Metamap for instance) the Dataset will automatically create those files in the most efficient way possible. ||  || = Training || When a directory contains **both** raw text files alongside annotation files; an instantiated Dataset || detects and facilitates access to those files. ||  || = Prediction || When a directory contains **only** raw text files; an instantiated Dataset object interprets this as || a directory of files that need to be predicted. This means that the internal Datafile that aggregates || meta-data for a given prediction file does not have fields for annotation_file_path set. ||  || = External Datasets || An actual dataset can be versioned and distributed by interfacing this class as described in the || Dataset examples. Existing Datasets can be imported by installing the relevant python packages that || wrap them. || \""\""\""",No,Yes,Yes
8152,of the last word is what is needed; not the last char of the last word.,Yes,Yes,Yes
8155,Initialize everything needed for model,No,No,Yes
8157,TODO fix,Yes,Yes,Yes
8159,:param title: What should appear in the header of the outputted HTML file; not very important,,,Yes
8160,"\""\""\"" || DataFile wraps all relevant information needed to manage a text document and it's corresponding annotation. Specifically; || a Datafile keeps track of the filepath of the raw text; annotation file; and metamapped file for each document. || \""\""\""",No,Yes,Yes
8161,"\""\""\"" || An Annotations object stores all relevant information needed to manage Annotations over a document. ||  || The Annotation object is utilized by medaCy to structure input to models and output from models. || This object wraps a dictionary containing two keys at the root level: 'entities' and 'relations'. || This structured dictionary is designed to interface easily with the BRAT ANN format. The key 'entities' contains || as a value a dictionary with keys T_1; T2; ... ;TN corresponding each to a single entity. The key 'relations' || contains a list of tuple relations where the first element of each tuple is the relation type and the last two || elements correspond to keys in the 'entities' dictionary. || \""\""\""",,,Yes
8163,Figure out how many matches come before the instance we're looking at; including itself,No,Yes,Yes
8164,TODO add all the entities we want in the demo,Yes,Yes,Yes
8167,:param title: What should appear in the header of the outputted HTML file; not very important,,,Yes
8168,"sample_2_expected = \""\""\""TODO\""\""\""",,,Yes
8170,# Figure out how many matches come before the instance we're looking at; including itself,,,Yes
8173,Need to fix model so we don't have to return redundant data,Yes,Yes,Yes
8175,TODO: Implement cleaner way to handle this,Yes,Yes,Yes
8176,Move to GPU if possible,Yes,No,Yes
8177,TODO transition to using argparse,Yes,Yes,Yes
8179,"\""\""\""Learner for running predictions and fine tuning BERT models. || \""\""\""",No,Yes,Yes
8183,Specify why MetaMap tests may be skipped,No,Yes,Yes
8184,Manually introduce ambiguity by changing the name of an entity in the copy,Yes,Yes,Yes
8186,TODO include tokenizer,,,Yes
8188,"\""\""\"" || A command-line tool for creating tabular data regarding the lexical variation || of a given dataset. ||  || python -m medacy.tools.calculators.lexical_variation --help ||  || The output of this tool is compatible with the tabulate module || \""\""\""",,,Yes
8189,If starts with a number; add an underscore FIXME,Yes,Yes,Yes
8190,For the rule names: unfortunately; due to what looks like a bug in,,,Yes
8191,FIXME,Yes,Yes,Yes
8192,TODO: query site one the TRIPS output is fixed,,,Yes
8194,TODO: extract more information about text to use as evidence,Yes,Yes,Yes
8197,TODO: extract more information about text to use as evidence,Yes,Yes,Yes
8198,TODO: handle case when,Yes,Yes,Yes
8201,TODO: handle protein families like 14-3-3 with IDs like,Yes,No,Yes
8203,TODO: This assumes phosphorylation; but in principle,,,Yes
8208,TODO: This is specific to phosphorylation but we should be,,,Yes
8209,TODO: This assumes phosphorylation; but in principle,Yes,No,Yes
8217,TODO,Yes,Yes,Yes
8218,TODO As these checks proceed; there should also be some way of,Yes,Yes,Yes
8219,TODO: For now; we only look at exact agent matches; not at family,,,Yes
8220,FIXME: This matching procedure will get confused if the same,,,Yes
8221,TODO: If ext_groups dict doesn't contain either one of these;,Yes,Yes,Yes
8223,TODO: Develop an activity hierarchy? In which kinaseactivity is a,Yes,No,Yes
8224,TODO: get ChEBI ID,Yes,No,Yes
8225,TODO: this should be based on the difference of input\/output PE,Yes,No,Yes
8229,#NAME?,No,Yes,Yes
8231,TODO: extend to all Agent modifications,,,Yes
8232,TODO: represent mutations in INDRA,Yes,No,Yes
8234,TODO: the 'aggregate' tag here  might be deprecated,,,Yes
8235,Following filter not needed once all statement types are implemented.,,,Yes
8239,"TODO: sometimes mutation_str is \""mutant\""; \""Mutant\"";",,,Yes
8240,TODO: take into account relation here,,,Yes
8243,FIXME,,,Yes
8244,FIXME,,,Yes
8245,FIXME For now; both mod and mod_pos are expected to be,,,Yes
8246,FIXME this information already exists in the invalid sites list,Yes,Yes,Yes
8247,FIXME,Yes,Yes,Yes
8249,TODO: handle non-uniprot protein IDs here,Yes,No,Yes
8251,Hack to deal with excessive number of names,Yes,No,Yes
8252,TODO,Yes,Yes,Yes
8253,client directly; because the Clickthrough API key seems unreliable,Yes,Yes,Yes
8256,(this will make duplicate removal more efficient,,,Yes
8258,TODO: PMCID to PMID conversion,Yes,Yes,Yes
8259,TODO: complete this dict,,,Yes
8260,TODO: standardize name here,,,Yes
8261,Fix grounding,,,Yes
8263,TODO: Find a paper that has only abstract,No,Yes,Yes
8265,This second autoclass is needed because of a jnius,,,Yes
8268,Here we fix some grounding standardization issues,No,Yes,Yes
8270,may be needed.,No,No,Yes
8276,So what's needed is an assembly procedure where an active form is applied,No,No,Yes
8277,TODO: Update this to include the path length; and perhaps to,,,Yes
8278,FIXME Currently this will match rules with the corresponding monomer,Yes,Yes,Yes
8279,rule) FIXME,,,Yes
8280,FIXME Could also update this to check for alternative,Yes,Yes,Yes
8282,FIXME etc.,Yes,Yes,Yes
8289,TODO Bound condition,,,Yes
8295,TODO TODO TODO,,,Yes
8296,FIXME: Note that this will eliminate rules where the subject,,,Yes
8297,TODO TODO TODO,Yes,Yes,Yes
8298,FIXME: Issue: Increasing kinase activity doesn't make it capable of executing,,,Yes
8299,FIXME Issue increase activity (generic) doesn't make something capable of,,,Yes
8302,TODO: handle context here in conjunction with active forms,Yes,No,Yes
8304,FIXME: for some reason labels are not accessible,Yes,No,Yes
8305,TODO: here; res[3] is the complex physical entity,Yes,Yes,Yes
8306,structure faithfully. It would be better to use res[3],,,Yes
8307,TODO: handle agent-or-substrate,Yes,Yes,Yes
8308,TODO: handle collections,Yes,Yes,Yes
8309,Rename columns in MIDAS the same way they are renamed in SIF,Yes,Yes,Yes
8310,Rename columns in MIDAS the same way they are renamed in SIF,Yes,Yes,Yes
8311,TODO: possibly handle this as location,,,Yes
8312,control TR columns will be 0 for all but CellLine,No,Yes,Yes
8313,TODO: handle activity hierarchies,Yes,Yes,Yes
8314,statements as needed,No,Yes,Yes
8315,TODO: what can we do about semantic conflicts here like the same,Yes,Yes,Yes
8316,TODO: revise the conditions here,,,Yes
8317,TODO: handle activity types,,,Yes
8318,TODO: generalize to other modification sites,Yes,Yes,Yes
8319,TODO: handle activity types,,,Yes
8321,(or perhaps tuples of stmts along with index into the original array,,,Yes
8323,TODO: Currently we don't look at source text; but we may want to,Yes,Yes,Yes
8324,TODO: log results here!,Yes,No,Yes
8325,Set these if filtering based on magnitude is needed,No,Yes,Yes
8326,TODO: extend to other Statement types if needed,Yes,Yes,Yes
8327,FIXME: for simplicity we start with a single object agent,Yes,No,Yes
8328,FIXME (This should use grounding rather than the name),,,Yes
8330,FIXME act_type = agent.activity.activity_type,,,Yes
8331,FIXME: the sign information for the target should be associated with,Yes,Yes,Yes
8332,TODO,,,Yes
8333,TODO: handle other agent state,Yes,No,Yes
8337,TODO: handle bound conditions,Yes,No,Yes
8338,Score paths here TODO,,,Yes
8340,FIXME Returns on the path found for the first enz_mp\/obs combo,Yes,Yes,Yes
8343,TODO: do we need to look at bpe.getEvidence(),Yes,No,Yes
8344,TODO: It is possible to find which member of the complex is,Yes,Yes,Yes
8345,TODO: It is possible to find which member of the complex,Yes,Yes,Yes
8346,TODO: by finding matching proteins on either side; in principle,,,Yes
8347,TODO: it could be possible to extract certain complexes here; for,Yes,Yes,Yes
8348,TODO: possibly allow Complex too,Yes,No,Yes
8349,TODO: it could be possible to extract certain complexes here; for,Yes,Yes,Yes
8350,TODO: by finding matching proteins on either side; in principle,Yes,Yes,Yes
8353,Create pieces needed for to object,,,Yes
8355,TODO: the issue here is that failures stick around for a long,Yes,Yes,Yes
8357,TODO: standardize name here,,,Yes
8358,TODO: handle other participant types,Yes,No,Yes
8359,TODO: Get evidence information from edge_attributes dict,Yes,Yes,Yes
8361,TODO: factor this out and reuse fix_agents,Yes,Yes,Yes
8364,TODO: Flesh this out more with some examples defining typical return,,,Yes
8365,FIXME: For now; deal only with agents having HGNC grounding,,,Yes
8366,FIXME: For now; don't look at bound\/mod\/mut\/loc\/activity conditions,,,Yes
8368,FIXME Retrieve citation information from pubmed_client,,,Yes
8372,TODO: Refactor to allow activity on a complex drawn from the prime agent,,,Yes
8374,TODO: Activity conditions\/modifiers on complexes drawn from the main,Yes,No,Yes
8375,TODO: Is it possible to have modified proteins inside a complex in BEL\/PyBEL?,Yes,Yes,Yes
8377,FIXME,Yes,Yes,Yes
8380,Fix errors in references to protein sequences,No,No,Yes
8382,We fix the time point to 10 hours,No,No,Yes
8383,TODO: handle multiple mutations on same gene?,Yes,No,Yes
8384,TODO TODO TODO: we need to set the initial conditions of mutated,Yes,No,Yes
8385,We fix the time point to 10 hours,No,No,Yes
8389,TODO: Mappings for SIGNOR families; complexes; etc.,Yes,Yes,Yes
8390,"\""\""\"" || Known issues: || * The generic \""up-regulates\"" effect type should be mapped to a generic up ||   regulation rather than Activation\/Inhibition; as it is currently. || * || \""\""\""",,,Yes
8392,TODO Add ActiveForm statements here,Yes,Yes,Yes
8394,TODO: See above.,,,Yes
8395,TODO: Translocation;,Yes,Yes,Yes
8396,FIXME,Yes,Yes,Yes
8397,FIXME can get rid of this,,,Yes
8398,FIXME uncomment,Yes,Yes,Yes
8399,FIXME this could be eliminated if logging not needed,,,Yes
8400,FIXME this could be eliminated if logging not needed,,,Yes
8402,TODO: Actually write this. Must have access to group data first.,Yes,Yes,Yes
8405,TODO: we should probably support reading from a different,Yes,Yes,Yes
8406,TODO: we really should be more intelligent about this,,,Yes
8408,Maybe include the journal subtitle too; in future.,,,Yes
8412,TODO: Check if the abstract is already there.,,,Yes
8414,FIXME: I don't think the default here is really correct.,Yes,No,Yes
8415,TODO: implement setup-teardown system.,Yes,Yes,Yes
8417,TODO: Work out how to insert multiple things.,Yes,No,Yes
8420,FIXME: Find an actual example. The pmid found was actually erroneous.,,,Yes
8425,This could perhaps be simplified with map_async from mp.pool.,,,Yes
8428,Solution to fix postgres drop tables,No,Yes,Yes
8432,TODO,Yes,Yes,Yes
8433,FIXME: A hack that depends on the _0 convention,,,Yes
8434,TODO: Wrap this in try\/except?,Yes,No,Yes
8438,TODO: Implement this use-case.,Yes,Yes,Yes
8439,Retrieve the kwargs needed in this function.,,,Yes
8441,Perhaps refactor read_content.,,,Yes
8442,TODO: Make sure we don't get repeat refences due to duplicate ids.,,,Yes
8444,Don't use pool if not needed.,,,Yes
8448,TODO: @cthoyt put in some additional epistemics info from pybel,,,Yes
8449,FIXME: If an RNA agent type; create a transcription-specific,,,Yes
8450,FIXME: If object is a degradation; create a stability-specific,,,Yes
8451,FIXME: Create a transcription-specific statement for p->rna,Yes,Yes,Yes
8453,FIXME: Handle translocations on the agent for ActiveForms; turn into,,,Yes
8454,FIXME: Look up go ID in ontology lookup service,,,Yes
8456,FIXME: Update when GO lookup is implemented,,,Yes
8458,TODO: Handle named complexes and map to Bioentities where possible,Yes,Yes,Yes
8460,FIXME: Handle EGID; SFAM; MESHPP; SDIS,Yes,Yes,Yes
8461,FIXME: Look up MESH IDs from name,Yes,No,Yes
8462,FIXME: Handle MIRNA; ABUNDANCE nodes,Yes,Yes,Yes
8463,FIXME: Handle reactions; composite nodes,,,Yes
8464,it won't disappear. (such as s3). Perhaps these could,,,Yes
8469,TODO: Can V_current be replaced simply by the nodes in g at level i?,Yes,Yes,Yes
8472,FIXME: Why isn't the target in dic_PG[len-1]?,,,Yes
8476,This could perhaps be simplified with map_async from mp.pool.,,,Yes
8477,TODO: This is very slow...should find a way to speed it up.,Yes,Yes,Yes
8481,A hack to get rid of the redundant 'Provenance' label.,Yes,Yes,Yes
8482,FIXME: once groundings are propagated well from offline reading,Yes,Yes,Yes
8483,TODO: handle other types of grounding here,Yes,No,Yes
8484,TODO: Fix comment,,,Yes
8486,has_content; total = get_content_nums(log_str)  # unused,Yes,Yes,Yes
8493,TODO: it might be interesting to get the time it took to read,,,Yes
8494,has_content; total = get_content_nums(log_str)  # unused,,,Yes
8496,TODO: Here we could normalize the sentence text to its,Yes,Yes,Yes
8497,TODO: Figure out if there's something better we can do with,,,Yes
8498,TODO: support more types of URNs,Yes,No,Yes
8499,TODO: Make this doe what it says it does or remove it,Yes,No,Yes
8500,TODO: Produce complex statements for each subcomplex,,,Yes
8501,TODO: Expect to get complex statements for SIGNOR-C22; should,Yes,Yes,Yes
8502,TODO: For IncreaseAmount statement; expect the obj to be an agent,Yes,Yes,Yes
8503,TODO: any cleanup needed here?,,,Yes
8506,TODO: support more types of URNs,,,Yes
8507,Overridden later if needed,Yes,No,Yes
8511,TODO: this currently assumes that a list of sentences is to be read,,,Yes
8512,TODO: run DRUM in PMC reading mode here,Yes,No,Yes
8513,TODO: this needs to be recursive,Yes,No,Yes
8516,TODO: remove this too,,,Yes
8517,TODO: This is a temporary measure; remove ASAP.,Yes,Yes,Yes
8518,TODO: complete the list here,Yes,No,Yes
8519,This really shouldn't be an issue.,,,Yes
8520,"TODO: Here we could monitor the stdout and wait for the \""Ready\"" line",,,Yes
8521,Get the base set of tables needed.,No,Yes,Yes
8522,development; and once that is done; TODO: Format pickle to match,,,Yes
8525,Work out how to resolve those issues; either by controlling what gets,No,Yes,Yes
8528,TODO: This file will definitely need some fixing.,Yes,No,Yes
8529,"Statements with \""better\"" alternatives",Yes,Yes,Yes
8530,TODO: Remove. This is a temporary workaround.,Yes,Yes,Yes
8531,TODO: We should look at more than just the agent name.,Yes,No,Yes
8534,really needed for the demo but are conceptually interesting to think,,,Yes
8535,What follows is another terrible hack.,Yes,Yes,Yes
8536,FIXME: Handle cases in which there is a missing cause\/effect,,,Yes
8538,Invert if needed,No,No,Yes
8539,TODO: we will also need to capitalize each part of each,,,Yes
8541,this shouldn't really happen.,,,Yes
8542,Sometimes the exact same score appears multiple times; in this,,,Yes
8543,FIXME what if ev_citation is Falsy?,Yes,No,Yes
8544,TODO check for missing grounding?,,,Yes
8546,TODO: Handle other summary plots.,Yes,No,Yes
8547,TODO: Handle conversions.,Yes,Yes,Yes
8550,Specifically; this should probably be an order-by a parameter such as,Yes,Yes,Yes
8552,TODO: Do better than truncating.,Yes,No,Yes
8554,Process the json to fix refs etc.,,,Yes
8556,This is a bit of a hack; but on average there are 4.5 raw statements,,,Yes
8557,Specifically; this should probably be an order-by a parameter such as,,,Yes
8558,Process the json to fix refs etc.,No,Yes,Yes
8559,TODO: Allow recursive mode (argument should probably be an integer level).,Yes,Yes,Yes
8560,Tools for getting statement jsons (or less) using efficient queries. (Newer),,,Yes
8562,TODO: Look into why this is so SLOW,,,Yes
8567,Fix the pmid,Yes,No,Yes
8568,TODO: optionally implement necessary annotations.,Yes,No,Yes
8571,TODO: We could get phosphorylation states from the prtein data.,Yes,No,Yes
8572,TODO: We could get phosphorylation states from the prtein data.,,,Yes
8573,TODO: We could get phosphorylation states from the protein data.,Yes,No,Yes
8575,FIXME: INDRA's section_type entry is meant to contain,,,Yes
8576,under annotations; just in case it's needed,,,Yes
8581,TODO: we could do some chemical mappings here i.e. CHEBI\/PUBCHEM\/CHEMBL,Yes,Yes,Yes
8583,FIXME: the EnglishAssembler capitalizes the first letter of,,,Yes
8584,TODO: It would be nice to not have to choose.,,,Yes
8588,TODO: We should probably handle defaults better; particularly host\/port.,,,Yes
8591,TODO: generalize to other modification sites,,,Yes
8593,FIXME: Handle cases in which there is a missing cause\/effect,Yes,Yes,Yes
8601,Flatten evidence if needed,No,No,Yes
8605,FIXME: for development purposes only.,,,Yes
8606,FIXME: For dev purposes only,Yes,No,Yes
8610,TODO: should we explicitly remove grounding if we conclude it,Yes,No,Yes
8612,TODO: generalize this to other kinds of scorers,Yes,No,Yes
8614,TODO: Add the entry by finding the right place in the YAML object,Yes,Yes,Yes
8615,TODO: Re-run the assembly here before returning,Yes,No,Yes
8616,TODO: determine if this should be done in the protmapper or if this is the,Yes,No,Yes
8619,Check to see if we can improve the annotation of the existing,No,Yes,Yes
8621,Get a list of monomer patterns matching the subject FIXME Currently,,,Yes
8622,rule) FIXME,,,Yes
8626,TODO: Find a pmcid that actually works.,,,Yes
8627,Todo,,,Yes
8629,Finally; if renaming is needed we standardize the Agent's name,No,Yes,Yes
8631,Initialize annotations if needed so Adeft predicted,No,Yes,Yes
8633,# rule) FIXME,,,Yes
8635,TODO implement sampling,,,Yes
8636,# FIXME: the sign information for the target should be associated with,,,Yes
8637,Get a list of monomer patterns matching the subject FIXME Currently,Yes,Yes,Yes
8639,FIXME: Note that this will eliminate rules where the subject,,,Yes
8640,FIXME: A hack that depends on the _0 convention,Yes,No,Yes
8641,TODO: Wrap this in try\/except?,Yes,No,Yes
8642,TODO: Wrap in try\/except?,Yes,No,Yes
8643,TODO implement sampling,Yes,Yes,Yes
8644,TODO: figure out how to represent db_refs,,,Yes
8649,Explicit 'is not None' needed to accept 0,Yes,Yes,Yes
8650,making pybel an implicit dependency of the model checker,No,Yes,Yes
8651,making pybel an implicit dependency of the model checker,No,Yes,Yes
8652,Note: interaction[1] is a catalyst; but unused due to a lack of ways,Yes,Yes,Yes
8653,f.readlines is needed so that the file content is consumed,,,Yes
8654,FIXME: these are temporary patches that should later be moved,,,Yes
8655,Initialize annotations if needed so Adeft predicted,,,Yes
8656,Ommit file part of key; assume it ends with json if it is present,Yes,No,Yes
8657,Step 1: fix JSON directly to reduce errors when deserializing,No,No,Yes
8660,TODO: handle collections,Yes,Yes,Yes
8661,TODO: factor this out and reuse fix_agents,,,Yes
8662,Fix evidence,No,No,Yes
8663,Step 1: fix JSON directly to reduce errors when deserializing,,,Yes
8664,therefore we implement a wait and retry approach here.,,,Yes
8665,TODO: how can we tell what kind of BioContext this is exactly?,,,Yes
8666,but this is still a good way to work with it,No,Yes,Yes
8667,TODO: in principle we could also do a reverse mapping to MESH IDs from,,,Yes
8669,TODO: handle already existing curation,,,Yes
8670,From here on; a Flask app built around a LiveCurator is implemented,No,Yes,Yes
8671,Ommit file part of key; assume it ends with json if it is present,Yes,No,Yes
8672,TODO: we should return the parent UniProt ID here but only once that,,,Yes
8673,ndex_cred = {'user': 'myusername'; 'password': 'xxx'},No,No,Yes
8674,but in principle; we could consider ones across ontologies,,,Yes
8675,TODO: this could also be used on agent conditions; here,,,Yes
8676,FIXME: this is a very naive initial solution; we should instead,Yes,Yes,Yes
8677,better sorted key,,,Yes
8679,FIXME: this shouldn't be using the INDRA_LOCATIONS name space,,,Yes
8680,FIXME: this shouldn't be using the INDRA_LOCATIONS name space,Yes,Yes,Yes
8681,FIXME: this list could be read from the ontology or another resource file,Yes,No,Yes
8684,FIXME: temporarily returning dummy component,,,Yes
8686,TODO: We should look at more than just the agent name.,Yes,No,Yes
8691,This is needed for e.g.; '1.0',No,No,Yes
8694,Todo add to annotations if interesting,Yes,Yes,Yes
8695,Todo wipe the cache (stored in ~\/.pypath\/cache) clean and,Yes,Yes,Yes
8697,TODO: there's probably more but this is what is visible so far,,,Yes
8698,TODO: we should return the parent UniProt ID here but only once that,Yes,Yes,Yes
8701,FIXME: we probably want to use the custom matches key function here,Yes,Yes,Yes
8702,TODO: we could probably do some optimization here,,,Yes
8703,NOTE: this way of retrieving agents might miss some important,,,Yes
8705,This is a bit hack-y; but the names are so interchanged the alternative is,Yes,Yes,Yes
8707,Fix CHEMBL IDs,No,No,Yes
8709,FIXME: can there be multiple entries here?,Yes,Yes,Yes
8710,FIXME: what do we do if there are multiple entries in,Yes,No,Yes
8711,ToDo:,,,Yes
8712,TODO: any cleanup needed here?,,,Yes
8713,TODO: any cleanup needed here?,Yes,Yes,Yes
8714,FIXME: can there be multiple entries here?,Yes,Yes,Yes
8715,There are some extra columns that we don't need to take and,,,Yes
8716,This is redundant but needed for documentation build,,,Yes
8718,TODO add other types of agent conditions here,Yes,No,Yes
8721,"TODO this is failing because we get GSK3B phos on \""S\""; \""9\"" as a main node;",,,Yes
8723,Check if the path ends with a refinement,No,Yes,Yes
8725,FIXME: the way we interpret stmts_to_compare here should be,Yes,Yes,Yes
8726,the number of columns with the number in the famplex grounding map,,,Yes
8727,Flag will become true if a new grounding map file is needed.,No,Yes,Yes
8728,FIXME: try to not start multiple processes at a time with some locking here,Yes,Yes,Yes
8729,FIXME: Move this to its own file. Too many packages now import this from nbrserverproxy.handlers,,,Yes
8730,FIXME: Make sure this times out properly?,,,Yes
8731,FIXME: Handle graceful exits of spawned processes here,Yes,Yes,Yes
8732,FIXME: Set 'name' properly,,,Yes
8733,FIXME: Should be a StaticFileHandler subclass,Yes,No,Yes
8734,-- Options for todo extension ----------------------------------------------,,,Yes
8735,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
8737,FIXME: support kwargs,Yes,No,Yes
8739,TODO: Doesn't work since Configurable doesn't have a log,Yes,Yes,Yes
8741,Configurable doesn't have a log,,,Yes
8742,https:\/\/github.com\/ipython\/traitlets\/blob\/5.0.5\/traitlets\/config\/configurable.py#L181,,,Yes
8745,implement iterable versions on top: iter_fit; iter_predict; etc,,,Yes
8747,implement iterable versions on top: iter_fit; iter_predict; etc,,,Yes
8748,A hack to support,Yes,No,Yes
8750,TODO: You could probably be cute and make this a decorator,Yes,Yes,Yes
8753,# TODO: migrate this to child class,Yes,Yes,Yes
8754,# TODO: migrate this to child class,Yes,Yes,Yes
8756,Move to the next streamer,,,Yes
8758,If we couldn't iterate over streamers; then it must \/ had better be a,No,Yes,Yes
8759,print 'todo: in threading',Yes,No,Yes
8760,improve patience if loss improvement is good enough,No,Yes,Yes
8763,local memory indices - TODO,Yes,Yes,Yes
8766,thoroughly verify by hand for 4 GEMM cases (after doing global) - TODO,,,Yes
8767,"s += \""  deviceProfile.devices[0].name = \\\""TODO\\\"";\ || \""",Yes,No,Yes
8768,compile kernels if needed,No,Yes,Yes
8769,TODO - kernelArgIdxOfAssignment,Yes,No,Yes
8771,TODO remove this; for debugging just to one unroll,Yes,Yes,Yes
8772,global tile indices being loaded - TODO,,,Yes
8776,but only < 32 does a unique tile improve performance;,No,Yes,Yes
8778,TODO; if unroll=8 is faster than unroll=16 then also check unroll=4,Yes,No,Yes
8779,TODO remove these,,,Yes
8781,if optimization level optimizes away offsets; but problem requires offsets; fix it,Yes,Yes,Yes
8782,if optimization level optimizes away initial strides; but problem uses non-zero initial strides; fix it,Yes,Yes,Yes
8785,TODO - re-implement this for new loads,,,Yes
8786,"\""\""\"" || TODOs ||  - move loads ||  - debug ddp offsets || \""\""\""",,,Yes
8790,TODO handle None here,Yes,Yes,Yes
8792,need problem sizes to assign - TODO ? reasonable default for Tensors?,Yes,Yes,Yes
8793,TODO [maxC; maxA; maxB],,,Yes
8794,need problem sizes to assign - TODO ? reasonable default for Tensors?,,,Yes
8795,TODO - how to insert and override problem sizes?,Yes,No,Yes
8796,TODO - how to insert and override problem sizes?,,,Yes
8799,TODO check if solution matches problem size for exact tile kernels,,,Yes
8800,TODO,Yes,Yes,Yes
8801,"TODO sort summation indices by \""stride\""",Yes,No,Yes
8802,TODO do I always need edges?,Yes,No,Yes
8804,TODO only handling kernelGrid = 1;1;1 and single kernel,Yes,Yes,Yes
8806,TODO needs splitU,Yes,Yes,Yes
8807,TODO num solution permutations won't be same for each hard-code b\/c invalids,Yes,Yes,Yes
8810,TODO can I avoid reaching this code by not allowing join DepthU,Yes,No,Yes
8812,(I-7) any default param with 1 value will be hardcoded; move to beginning,,,Yes
8817,data along different sizes (but perhaps it should,Yes,Yes,Yes
8822,newRule gets better score; accept,No,Yes,Yes
8823,W2 = 1 means we would rather lose 1us per kernel rather than adding another split (actually they're equal),Yes,Yes,Yes
8826,are there pairs of weights that would result in same logic complexity but better score?,,,Yes
8830,TODO global prefetch; how do I swap write addresses,,,Yes
8831,TODO global prefetch; how do I swap read addresses,Yes,Yes,Yes
8833,TODO increment global read pointers,Yes,Yes,Yes
8834,TODO if we have outer summation indices;,Yes,Yes,Yes
8836,TODO: lds read do it,,,Yes
8839,TODO: lds read inc,Yes,No,Yes
8841,implement tensileGetSolutionPointerUncached_ProblemType,No,Yes,Yes
8842,implement tensileGetSolutionPointer_ProblemType,,,Yes
8845,TODO convert to always using hfma2 since we always have even number of fma's; half2*=rC,,,Yes
8849,TODO fix formatting,Yes,Yes,Yes
8850,TODO - how many tmp vgprs available before loop; after loop,Yes,No,Yes
8851,TODO - what occupancy does this numSgpr limit to;,,,Yes
8853,TODO - how many tmp vgprs available before loop; after loop,,,Yes
8854,TODO - mac macro,Yes,Yes,Yes
8855,TODO: read nwg0 from sgpr,,,Yes
8856,sgId not needed until local read addresses,,,Yes
8858,Global Read Addresses: Increments B - TODO,,,Yes
8859,Local Write Addresses: Tile Assignment A - TODO,Yes,Yes,Yes
8862,Local Write Addresses: Unroll Assignment B - TODO,,,Yes
8863,Local Write Addresses: First Offset A - TODO,,,Yes
8864,Local Write Addresses: First Offset B - TODO,,,Yes
8865,Local Write Addresses: Final Offsets A - TODO,Yes,Yes,Yes
8866,Local Write Addresses: Final Offsets B - TODO,Yes,Yes,Yes
8868,Local Write Addresses: Declare Addresses B - TODO,Yes,Yes,Yes
8872,Local Read Addresses: Final Offset B - TODO,,,Yes
8873,Local Read Addresses: Declare Addresses A - TODO,Yes,Yes,Yes
8874,Local Read Addresses: Declare Addresses B - TODO,Yes,Yes,Yes
8875,Declare Loop Num Iterations - TODO,Yes,Yes,Yes
8876,Calculate Loop Num Iter - TODO,Yes,Yes,Yes
8877,Open Loop - TODO,,,Yes
8879,MAC Iteration - TODO,,,Yes
8880,At Least 1 Unroll - TODO,Yes,No,Yes
8881,Tail Loop: Num Iter - TODO,Yes,No,Yes
8882,Global Read: Increment A - TODO,,,Yes
8883,Global Read: Increment B - TODO,,,Yes
8886,Local Write: Swap Offsets A - TODO,Yes,Yes,Yes
8887,Local Write: Swap Offsets B - TODO,Yes,Yes,Yes
8888,Local Write: Reset Offsets A - TODO,Yes,No,Yes
8889,Local Write: Reset Offsets B - TODO,,,Yes
8892,Local Write: Do It A - TODO,,,Yes
8893,Local Write: Do It B - TODO,Yes,Yes,Yes
8894,Local Read: Swap Offsets A - TODO,Yes,No,Yes
8896,Local Read: Reset Offsets A - TODO,Yes,No,Yes
8898,Local Read: Init Pointers A - TODO,Yes,Yes,Yes
8900,Local Read: Increment A - TODO,Yes,No,Yes
8902,Local Read: Do It A - TODO,Yes,No,Yes
8905,Shift Vectors Components d1 - TODO,Yes,No,Yes
8906,Complex Declare Tmp Registers - TODO,Yes,Yes,Yes
8909,LocalSplitU: Reduction - TODO,,,Yes
8910,LocalSplitU: Global Write Indices - TODO,Yes,No,Yes
8911,LocalSplitU: Global Write - TODO,,,Yes
8912,Not LocalSplitU: Global Write Indices - TODO,Yes,No,Yes
8917,TODO: read nwg0 from sgpr,Yes,Yes,Yes
8919,no wait needed here b\/c we already waited for ds_write,No,No,Yes
8921,TODO change to static vector divide and remainder,Yes,No,Yes
8922,TODO clarify support of sgpr and constant operand\/multipliers,Yes,Yes,Yes
8926,3 * pow of 2 TODO FIXME,Yes,Yes,Yes
8928,FIXME,,,Yes
8932,FIXME,Yes,Yes,Yes
8933,FIXME,Yes,Yes,Yes
8934,FIXME this should be index assignments for dim0;1,Yes,Yes,Yes
8936,FIXME,Yes,Yes,Yes
8937,FIXME - how to do 64 bit add sgprs,Yes,No,Yes
8939,move vgprs into sgprs,No,No,Yes
8941,TODO optimize inner workgroups to not consider edge,,,Yes
8943,TODO optimize inner workgroups to not consider edge,,,Yes
8944,nwg0 FIXME use nwg0 from above,Yes,Yes,Yes
8945,how many vgprs are needed for zero elements,No,Yes,Yes
8946,5 = how many vgprs are needed per element,No,Yes,Yes
8947,FIXME can this be moved to below or do flat instructions return out of order,Yes,Yes,Yes
8948,if beta: # FIXME kept above since flat instruction may return out of order,Yes,Yes,Yes
8949,FIXME remove this,,,Yes
8951,FIXME op_sel,,,Yes
8952,FIXME can this be removed?,,,Yes
8953,"kStr += inst(\""flat_load_short_d16_hi\""; vgpr(addr;2); vgpr(sumIdx\/2); \""store C\"" ) # FIXME need d16_hi",Yes,Yes,Yes
8954,"kStr += inst(\""flat_store_short_d16_hi\""; vgpr(addr;2); vgpr(sumIdx\/2); \""store C\"" ) # FIXME need d16_hi",Yes,Yes,Yes
8955,how much info to print. 0=none; 1=standard; 2=verbose,No,Yes,Yes
8956,both options were supported until a refactoring of the short-vector code (necessary to enable assembly) broke it. Since =True always seems to be faster; no time has been spend on fixing =False,,,Yes
8957,in opencl for some compilers; performance improved by putting a memfence after each subiteration; it prevented the loads of one subiteration from being moved,No,Yes,Yes
8959,performance so this has been deprecated and probably doesn't work,Yes,No,Yes
8960,add gls or slc after global memory read\/writes to change cacheing; not cacheing the writes is promising and improved performance a tiny bit,Yes,Yes,Yes
8962,ShiftTile: todo. this is MIOpenGemm's strategy; probably eliminates unshift however smallest supported problem size would be tile size,,,Yes
8963,BoundaryLoad: todo. use isa to set buffer\/image load boundaries and out of bounds data automatically comes in as zero,Yes,Yes,Yes
8965,TODO - replace this with a direct compare against the offset,,,Yes
8966,TODO - remove me; this is temp workaround,Yes,Yes,Yes
8967,"if tP[\""isA\""] and self.localReadDoCnt >=3: # TODO - disable",,,Yes
8968,TODO - there is some additional dead code here that computes the upper 32 bits,,,Yes
8969,TODO - ignore LdsPadB,Yes,Yes,Yes
8970,TODO - handle vector-load,,,Yes
8972,TODO: Can refactor code above to Compute this directly:,Yes,No,Yes
8974,TODO - currently only support Single but could be extended to 2 halfs or part of a double,Yes,Yes,Yes
8975,else seems registers below would collide??,,,Yes
8976,Grow the register pool if needed - we need enough regs for at least one element,,,Yes
8977,else seems registers below would collide??,,,Yes
8978,else seems registers below would collide??,Yes,Yes,Yes
8980,Grow the register pool if needed - we need enough regs for at least one element,,,Yes
8981,TODO - we could support larger loads if we know the array is a multiple,Yes,Yes,Yes
8984,TODO : the vgprSerial is needed for-ever and if we grow here will split the,Yes,No,Yes
8985,range of the tmps.  Maybe want to move vgprSerial to first vgpr?,Yes,Yes,Yes
8986,TODO - this can be fixed by using buffer_atomic_cmpswap,Yes,Yes,Yes
8987,TODO - remove this code? No reason not to use LocalWriteUseSgpr?,Yes,Yes,Yes
8989,TODO - for doubles we need to add something special here?,Yes,Yes,Yes
8990,TODO - Fix for double here; would need bigger load,,,Yes
8991,TODO: use chooseGlobalStore; could use vector loads here too perhaps:,Yes,Yes,Yes
8992,TODO for atomic GWVW:,,,Yes
8993,FIXME-atomic,,,Yes
8996,TODO for atomic GWVW:,,,Yes
8998,Tensile will allocate additional VGPR in Global Store phase if needed to,No,Yes,Yes
8999,fixme-iui  need to use wrapping increment for double or triple buffering:,,,Yes
9000,TODO-64 : This is max 32-bit negative value; the tail loop,,,Yes
9002,move the srd + base vs move the GRO,,,Yes
9003,#NAME?,No,Yes,Yes
9004,TODO - could have this generate dwordx3 loads in addition; step down by 1 instead of div2,Yes,Yes,Yes
9007,don't shift if ASEM guarantees it is not needed:,,,Yes
9008,TODO : the unshift code is complex and currently appears broken.  Long-term want to use,,,Yes
9009,Header written once at start of solution lookup functions,No,Yes,Yes
9010,TODO - why does this use VectorWidth to control store width?  Could be GlobalWriteVectorWidth?,Yes,Yes,Yes
9011,TODO - fix code to use atomics,,,Yes
9012,fixme; do we need this for atomic? BOZO,,,Yes
9015,Perhaps could optimize this into something simpler with fewer bank conflicts,,,Yes
9018,Work TODO,,,Yes
9022,so will use VGPR from consec elements? TODO,Yes,No,Yes
9023,TODO - remove this and next line when VAW works for other types,Yes,No,Yes
9027,TODO - remove this code; this generates the old if-tree and checks against above,Yes,Yes,Yes
9028,Create a special macro that does one K iter if needed:,No,No,Yes
9034,we can detect if that is needed or not,No,No,Yes
9035,TODO - move this after coord*stride; and handle 64-bit,,,Yes
9036,TODO - for PreciseBoundsCheck we could set bounds on C to tile dim,,,Yes
9037,TODO - future opportunities for store vgpr and other optimization,,,Yes
9039,TODO - extend to 64 bit calc s_mul_hi ?,Yes,No,Yes
9040,Can be enabled with PBC (does not use branch logic) or if assertions guarantee no shift needed,No,Yes,Yes
9046,TODO - change to reject?,Yes,Yes,Yes
9048,TODO - move these two moves into computeSrd; and fold into existing addr calc,Yes,Yes,Yes
9051,TODO; support broader range here,Yes,Yes,Yes
9052,Can be enabled with PBC (does not use branch logic) or if assertions guarantee no shift needed,No,Yes,Yes
9054,TODO - use BFE here:,Yes,No,Yes
9057,Gives pointer shift some room to move left; even into the previous macro-tile,,,Yes
9058,TODO - enable this as optimization; need to move add below,,,Yes
9059,would move outside the array bounds.,,,Yes
9061,jgolds HACK,,,Yes
9063,TODO -this is only needed for the shift\/unshift code - with some assertions,Yes,Yes,Yes
9064,we can detect if that is needed or not,,,Yes
9065,jgolds HACK,,,Yes
9066,jgolds HACK,,,Yes
9068,TODO - does this handle N-dim tensors correctly?,Yes,Yes,Yes
9069,TODO - does this handle multiple summation indices?,Yes,Yes,Yes
9070,TODO - move this after coord*stride; and handle 64-bit,,,Yes
9073,TODO - move this after coord*stride; and handle 64-bit,Yes,Yes,Yes
9074,TODO - move this after coord*stride; and handle 64-bit,Yes,Yes,Yes
9075,jgolds HACK,Yes,Yes,Yes
9079,create problem size - TODO could move this up to the caller,,,Yes
9081,implement tensileGetSolutionPointer_ProblemType,,,Yes
9083,- Requires 4 instructions to move scalar limit and a couple SGPR,No,Yes,Yes
9084,Header written once at start of solution lookup functions,,,Yes
9085,implement tensileGetSolutionPointerUncached_ProblemType,No,Yes,Yes
9086,implement tensileGetSolutionPointer_ProblemType,No,Yes,Yes
9087,TODO - remove this code; this generates the old if-tree and checks against above,,,Yes
9091,This can improve utilization; in particular if macro-tile is larger than the lower dimensions.,No,Yes,Yes
9094,+ Less VGPRS (32b offset vs 64-bit) needed for addressing,No,No,Yes
9096,- Requires 4 instructions to move scalar limit and a couple SGPR,No,Yes,Yes
9097,implement tensileGetSolutionPointerUncached_ProblemType,No,Yes,Yes
9098,implement tensileGetSolutionPointer_ProblemType,,,Yes
9099,TODO - remove this code; this generates the old if-tree and checks against above,,,Yes
9100,implement tensileGetSolutionPointerUncached_ProblemType,No,Yes,Yes
9102,implement tensileGetSolutionPointerUncached_ProblemType,,,Yes
9103,implement tensileGetSolutionPointer_ProblemType,,,Yes
9106,TODO - use a different value for OOB data,Yes,Yes,Yes
9107,TODO - could just compute this on the host,Yes,Yes,Yes
9108,TODO: add some adds,,,Yes
9110,TODO - could just compute this on the host,Yes,Yes,Yes
9116,add a wrap increment; if needed:,No,No,Yes
9117,TODO - use a different value for OOB data,Yes,Yes,Yes
9118,note loop counter numIterK\/numIterL hard-coded; manually hack if needed,,,Yes
9119,as a simplificaton; don't move writes past any loads,Yes,Yes,Yes
9120,Prepend a waitcnt if needed,,,Yes
9121,bozo - could perhaps make this more optimal,,,Yes
9122,TODO - can schedule these writes across iters; should figure this out above,Yes,Yes,Yes
9123,TODO - gfx9 supports higher max VMCNT,Yes,Yes,Yes
9125,pointerCode contains local pointer changes (if needed),Yes,Yes,Yes
9126,#NAME?,,,Yes
9127,so this is better match to what it is trying to do,,,Yes
9128,TODO - could tune these for store mode (BufferStore; edge; etc):,Yes,Yes,Yes
9130,TODO - if this is the last tile; don't need to jump to next instruction,Yes,Yes,Yes
9132,"\""Persistent-hack loop count\"")",Yes,No,Yes
9135,TODO - should cache the device properties - expensive to call on each iteration here:,Yes,Yes,Yes
9136,unused parms,Yes,No,Yes
9138,nwg0 FIXME use nwg0 from above,Yes,Yes,Yes
9139,"\""Persistent-hack loop count\"")",,,Yes
9143,move wg0;1 in vgprs into sgprs,,,Yes
9146,move wg0;1 in vgprs into sgprs,No,No,Yes
9148,move wg0;1 in vgprs into sgprs,No,No,Yes
9149,move wg0;1 in vgprs into sgprs,,,Yes
9151,move wg0;1 in vgprs into sgprs,No,No,Yes
9152,move wg0;1 in vgprs into sgprs,No,No,Yes
9156,Create a special macro that does one K iter if needed:,No,No,Yes
9158,TODO-64 : This is max 32-bit negative value; the tail loop,,,Yes
9159,Change offset for subsequent dims (if needed),,,Yes
9160,nwg0 FIXME use NumWorkGroups0,,,Yes
9161,move vgprs into sgprs,No,No,Yes
9162,Blocked rows or columns,No,Yes,Yes
9164,TODO - For GlobalSplitU; perhaps need to do this before the GSU workgroup assignment?  Or NumWorkGroups0,,,Yes
9169,TODO - does this handle N-dim tensors correctly?,Yes,Yes,Yes
9171,add a wrap increment; if needed:,,,Yes
9173,fixme-iui  need to use wrapping increment for double or triple buffering:,,,Yes
9175,Perhaps could optimize this into something simpler with fewer bank conflicts,Yes,Yes,Yes
9177,TODO-packed - modify to ignore packed; perhaps:,Yes,Yes,Yes
9180,TODO - if this is the last tile; don't need to jump to next instruction,,,Yes
9183,fixme; do we need this for atomic? BOZO,,,Yes
9185,TODO for atomic GWVW:,Yes,No,Yes
9190,Original stagger register.  Only needed for Persistent,,,Yes
9191,Create a special macro that does one K iter if needed:,,,Yes
9193,jgolds HACK,,,Yes
9194,TODO-64 : This is max 32-bit negative value; the tail loop,,,Yes
9195,Change offset for subsequent dims (if needed),No,No,Yes
9196,unused parms,,,Yes
9198,move vgprs into sgprs,,,Yes
9203,remainder; unused here,,,Yes
9205,"kStr += inst(\""v_mov_b32\""; vgpr(21); hex(self.initVgprValue); \""hack tmp in pool\"")",Yes,No,Yes
9208,add a wrap increment; if needed:,No,No,Yes
9210,fixme-iui  need to use wrapping increment for double or triple buffering:,Yes,No,Yes
9213,TODO - future opportunities for store vgpr and other optimization,Yes,Yes,Yes
9216,TODO - for hpa the host should pass in an F32 alpha so we don't have to do it here,Yes,Yes,Yes
9217,TODO - could tune these for store mode (BufferStore; edge; etc):,,,Yes
9219,5 = how many vgprs are needed per element (flat),,,Yes
9221,Grow the register pool if needed - we need enough regs for at least one element,No,Yes,Yes
9223,range of the tmps.  Maybe want to move vgprSerial to first vgpr?,Yes,Yes,Yes
9224,TODO - if this is the last tile; don't need to jump to next instruction,,,Yes
9225,approx psuedocode; probably not quite right:,No,Yes,Yes
9227,fixme; do we need this for atomic? BOZO,Yes,No,Yes
9232,TODO - use BFE here:,,,Yes
9234,Gives pointer shift some room to move left; even into the previous macro-tile,No,Yes,Yes
9235,Original stagger register.  Only needed for Persistent,No,Yes,Yes
9240,Change offset for subsequent dims (if needed),,,Yes
9242,nwg0 FIXME use NumWorkGroups0,,,Yes
9243,move vgprs into sgprs,No,No,Yes
9244,Blocked rows or columns,No,Yes,Yes
9245,move wg0;1 in vgprs into sgprs,No,No,Yes
9246,TODO - For GlobalSplitU; perhaps need to do this before the GSU workgroup assignment?  Or NumWorkGroups0,Yes,Yes,Yes
9248,remainder; unused here,Yes,Yes,Yes
9251,TODO - does this handle N-dim tensors correctly?,Yes,Yes,Yes
9252,"kStr += inst(\""s_mov_b32\""; sgpr(\""OffsetB\""); sgpr(\""SrdB+0\""); \""hack to save\"")",,,Yes
9255,fixme-iui  need to use wrapping increment for double or triple buffering:,Yes,No,Yes
9256,TODO - handle vector-load,Yes,Yes,Yes
9259,TODO-packed - modify to ignore packed; perhaps:,Yes,Yes,Yes
9260,TODO - why does this use VectorWidth to control store width?  Could be GlobalWriteVectorWidth?,Yes,Yes,Yes
9261,TODO - for hpa the host should pass in an F32 alpha so we don't have to do it here,Yes,Yes,Yes
9263,how many vgprs are needed for zero elements,No,Yes,Yes
9264,5 = how many vgprs are needed per element (flat),No,Yes,Yes
9266,Grow the register pool if needed - we need enough regs for at least one element,No,Yes,Yes
9267,TODO : the vgprSerial is needed for-ever and if we grow here will split the,Yes,No,Yes
9269,TODO - if this is the last tile; don't need to jump to next instruction,Yes,Yes,Yes
9271,TODO - for PreciseBoundsCheckStore we could set bounds on C to tile dim,Yes,Yes,Yes
9272,fixme; do we need this for atomic? BOZO,,,Yes
9273,TODO - Fix for double here; would need bigger load,Yes,Yes,Yes
9275,TODO - we are always atomic here?,Yes,No,Yes
9279,Gives pointer shift some room to move left; even into the previous macro-tile,,,Yes
9280,Original stagger register.  Only needed for Persistent,No,Yes,Yes
9282,FIXME op_sel,,,Yes
9283,jgolds HACK,,,Yes
9284,TODO-64 : This is max 32-bit negative value; the tail loop,,,Yes
9285,Change offset for subsequent dims (if needed),No,No,Yes
9286,unused parms,,,Yes
9287,nwg0 FIXME use NumWorkGroups0,,,Yes
9292,TODO: Can refactor code above to Compute this directly:,Yes,No,Yes
9294,TODO: add some adds,,,Yes
9296,TODO - does this handle N-dim tensors correctly?,Yes,Yes,Yes
9297,"kStr += inst(\""s_mov_b32\""; sgpr(\""OffsetB\""); sgpr(\""SrdB+0\""); \""hack to save\"")",Yes,Yes,Yes
9298,add a wrap increment; if needed:,,,Yes
9299,TODO - does this handle multiple summation indices?,Yes,Yes,Yes
9301,TODO - handle vector-load,Yes,Yes,Yes
9302,Perhaps could optimize this into something simpler with fewer bank conflicts,,,Yes
9303,TODO - future opportunities for store vgpr and other optimization,Yes,Yes,Yes
9304,TODO-packed - modify to ignore packed; perhaps:,Yes,Yes,Yes
9305,TODO - why does this use VectorWidth to control store width?  Could be GlobalWriteVectorWidth?,Yes,Yes,Yes
9306,TODO - for hpa the host should pass in an F32 alpha so we don't have to do it here,Yes,Yes,Yes
9308,how many vgprs are needed for zero elements,No,Yes,Yes
9309,5 = how many vgprs are needed per element (flat),No,Yes,Yes
9312,TODO : the vgprSerial is needed for-ever and if we grow here will split the,Yes,No,Yes
9314,TODO - if this is the last tile; don't need to jump to next instruction,,,Yes
9316,TODO - for PreciseBoundsCheckStore we could set bounds on C to tile dim,,,Yes
9317,fixme; do we need this for atomic? BOZO,Yes,No,Yes
9318,TODO - Fix for double here; would need bigger load,,,Yes
9319,TODO for atomic GWVW:,Yes,No,Yes
9323,unused,Yes,No,Yes
9325,TODO: Handle both from cmdline and python APIs.,Yes,Yes,Yes
9328,TODO: Move somewhere else to share with `db setup`.,Yes,No,Yes
9329,TODO: Remove this when factory is reworked,Yes,Yes,Yes
9330,TODO: Configure this,,,Yes
9334,TODO: move to utils.backward.,,,Yes
9335,TODO: branch_from cannot be passed from build_from_cmdargs; must add --branch-from argument,Yes,Yes,Yes
9337,XXX: Reminder for future DB implementations:,,,Yes
9338,TODO: Remove since this should not occur anymore without metadata.user in the indices?,,,Yes
9339,TODO: This should only be possible when using cmdline API,Yes,No,Yes
9340,TODO: Remove when _init_done is removed.,,,Yes
9342,TODO: Find a better solution,Yes,No,Yes
9343,TODO: handle all other arguments,Yes,Yes,Yes
9344,TODO: Find a better solution,Yes,No,Yes
9345,TODO: Remove when space is in DB,,,Yes
9348,TODO: Remove and replace Experiment's init with this,Yes,Yes,Yes
9350,TODO: Remove and use OrionState instead,Yes,Yes,Yes
9351,TODO: replace metadata[priors] by space when space in DB,,,Yes
9352,TODO: Replace when space in db,Yes,Yes,Yes
9353,TODO: Find another way around the circular import,Yes,Yes,Yes
9354,TODO: Parse commandline for any options to python and pick the script filepath properly,Yes,No,Yes
9355,Maybe its a float; maybe user made a mistake and report objective='name',,,Yes
9356,TODO:,,,Yes
9358,TODO: This should be built automatically like get_branching_args_group,,,Yes
9360,need to implement interior-points algorithm to solve the convex problem by CVXPY in future#,Yes,Yes,Yes
9361,TODO: How could we support orion.core.config.storage.database as well?,Yes,No,Yes
9363,TODO: TPE should support this case once discrete is added;,Yes,Yes,Yes
9364,"\""\""\"" || Plotting public API. || Authors of third-party plotting backends should implement a module with a || public ``plot(data; kind; **kwargs)``. The parameter `data` will contain || the data structure and can be a `ExperimentClient`. For example; || for ``ec.plot()`` the parameter `data` will contain the ExperimentClient `ec`. ||  || The parameter `kind` will be one of: || - learning || \""\""\""",,,Yes
9366,TODO: Delegate call to correct plotting functions.,Yes,No,Yes
9367,TODO: Call self(kind='learning'),,,Yes
9368,TODO,,,Yes
9371,TODO: user_args won't be defined if reading from DB only (`orion hunt -n <exp> ` alone),Yes,Yes,Yes
9373,TODO: task can be an object instead of package.class,Yes,No,Yes
9374,TODO use sequential id,Yes,Yes,Yes
9375,TODO: task can be an object instead of package.class,,,Yes
9376,TODO: Fix these singletons to remove Legacy; MongoDB; PickledDB and EphemeralDB.,Yes,Yes,Yes
9377,TODO: task can be an object instead of package.class,Yes,No,Yes
9379,TODO: Adapt when removing init_only after deprecation phase,,,Yes
9380,TODO: it is a blocking call,Yes,No,Yes
9382,TODO: We should move branching specific stuff below in a centralized place for EVC stuff.,Yes,Yes,Yes
9388,TODO move this,Yes,Yes,Yes
9394,"if(\""youtube_id\"" not in entry or  TODO: uncomment this",Yes,No,Yes
9399,meta_information = row['meta']  # TODO include in Gulpio,Yes,No,Yes
9400,# TODO improvable,,,Yes
9403,TODO log file; print statement;...,Yes,Yes,Yes
9409,TODO: read item by gulpio api,,,Yes
9411,The minimum number of characters needed for a line to be valid.,No,Yes,Yes
9412,We also apply a little hack to make sure paragraphs are separated.,Yes,Yes,Yes
9414,TODO: Error handling,Yes,No,Yes
9416,TODO: Make sleep decision based on time since last,Yes,Yes,Yes
9418,TODO: I think StringIO buffers don't handle unicode properly. Investigate.,,,Yes
9419,TODO: Instead of just returning once the function has completed;,,,Yes
9420,This should be fairly easy to implement; but this is good enough,,,Yes
9422,TODO: Max messages per tick?,Yes,Yes,Yes
9423,TODO: may not be available yet,Yes,No,Yes
9425,Gross hack - Needs to happen as soon as possible so we put it here,,,Yes
9426,TODO: Message batching,Yes,No,Yes
9427,TODO: Constantize\/config,,,Yes
9429,TODO: Keep alive,,,Yes
9431,TODO: Max messages per tick?,Yes,Yes,Yes
9432,TODO: Message batching,,,Yes
9435,TODO: Move me,,,Yes
9437,TODO: Error handling,,,Yes
9438,TODO: Constantize this,,,Yes
9439,TODO: Error handling,Yes,No,Yes
9445,"TODO: Right now we can't detect when the run is done because there is no \""completion\""",,,Yes
9447,An non-negative index; larger is better.,,,Yes
9448,The KCL has much better convergence of optimization when the BN layers are added.,,,Yes
9452,TODO: Incorporate token position here as well to improve,Yes,Yes,Yes
9453,Workaround for odd unicode issues (Jordan),,,Yes
9455,TODO: This branch happens when there's only one content word,Yes,Yes,Yes
9457,TODO: My implementation of idf isn't matching *exactly* with theirs;,Yes,Yes,Yes
9458,TODO: Much of this processesing is from an abundance of,,,Yes
9462,probably be fixed.,Yes,Yes,Yes
9464,TODO: Make sure the name matches metadata,Yes,Yes,Yes
9466,TODO(jbg): Fix the real source of this issue; wherever it is,,,Yes
9467,"flags.define_list(\""train_columns\""; [\""title_score\""; \""title_edit_dist\""; \""bias\""; \""body_score\""];",No,Yes,Yes
9469,al = ActiveLearner(flags.raw_csv; flags.match_location; flags.train_columns; max_size=flags.max_size),No,Yes,Yes
9471,TODO: Make referring expression data-driven,Yes,No,Yes
9472,TODO: add start\/end tokens (perhaps as option),Yes,Yes,Yes
9475,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
9476,For performance; compile the regular expressions once:,,,Yes
9477,TODO: make this not hard coded,,,Yes
9478,guess_df so it is safe and efficient to compute the text before iterating over guesses,No,Yes,Yes
9479,Save the model if its better,No,Yes,Yes
9480,wasteful in terms of memory. It is better to pay the cost to copy a small portion,Yes,Yes,Yes
9483,Save the model if its better,No,Yes,Yes
9484,wasteful in terms of memory. It is better to pay the cost to copy a small portion,,,Yes
9486,Todo: sort by (redirected) wikipedia page frequency,Yes,No,Yes
9487,TODO: sort by frequency,Yes,No,Yes
9490,FIXME because there can be missing guessers; must iterate position first,,,Yes
9492,TODO: Change folds to use correct ones,Yes,No,Yes
9494,Maybe group paragraphs together until we hit a length limit,No,No,Yes
9496,TODO,,,Yes
9497,FIXME only accept + and -,,,Yes
9500,TODO: If we care about more than one user (entrant); need to change logic here,Yes,Yes,Yes
9501,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
9502,TODO: what if the sentences in a batch are all of different lengths?,Yes,Yes,Yes
9506,needed to ensure reproduction of random word vectors for out of vocab terms,No,Yes,Yes
9510,TODO: we may support size = -1 in the future,Yes,No,Yes
9512,TODO: Prediton to Text,,,Yes
9514,TODO: fix by reading the .dimensions file,Yes,Yes,Yes
9516,model_outfile is actually a directory; using model_outfile to conform to Trainer naming convention,,,Yes
9517,actually a directory; using model_outfile to conform to Trainer naming convention,,,Yes
9518,model_outfile is actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
9519,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
9520,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
9521,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
9524,model_outfile is actually a directory; using model_outfile to conform to Trainer naming convention,,,Yes
9526,TODO: Add Poisson Loss,Yes,No,Yes
9529,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
9530,"\""\""\"" || Demonstrates image-based grasp candidate sampling; which is used in the || GQ-CNN-based grasping policy || Author: Jeff Mahler || \""\""\""",No,No,Yes
9532,TODO: implement reinitialization of pc0,,,Yes
9534,TODO: remove this and figure out why queue thread does not properly exit,,,Yes
9536,"\""\""\"" || Script to plot the errors during training || Author: Jeff Mahler || \""\""\""",,,Yes
9537,TODO: remove this and figure out why queue thread does not properly exit,Yes,Yes,Yes
9538,TODO: remove,,,Yes
9539,"\""\""\"" || Example file for loading a policy test case. || Author: Jeff Mahler || \""\""\""",,,Yes
9540,"TODO: implement \""quality_function\""",,,Yes
9542,as needed so it is possible to run multiple tf sessions on the same GPU,No,No,Yes
9543,TODO: Add Poisson Loss,Yes,No,Yes
9545,TODO: currently we are assuming the layer before a res layer must be conv layer; fix this,Yes,Yes,Yes
9546,TODO: Clean this giant if statement up,Yes,Yes,Yes
9550,TODO: Add Poisson Loss,Yes,No,Yes
9551,"\""\""\"" || Script to run saved policy output from a user run || Author: Jeff Mahler || \""\""\""",,,Yes
9552,as needed so it is possible to run multiple tf sessions on the same GPU,No,No,Yes
9555,as needed so it is possible to run multiple tf sessions on the same GPU,No,No,Yes
9559,TODO,,,Yes
9560,"\""\""\"" || Makes a new split for a TensorDataset ||  || Author || ------ || Jeff Mahler || \""\""\""",No,Yes,Yes
9561,fix legacy,Yes,Yes,Yes
9562,"\""\""\"" || Converts a GQ-CNN model trained using the Dex-Net train_grasp_quality_cnn.py script to a model that the GQ-CNN package can import. || Author: Jeff Mahler || \""\""\""",No,Yes,Yes
9563,"\""\""\"" || GQCNN network implemented in Tensorflow || Author: Vishal Satish || \""\""\""",No,Yes,Yes
9566,"\""\""\"" || Displays robust grasps planned using a GQ-CNN-based policy on a set of saved RGB-D images. || The default configuration is cfg\/examples\/policy.yaml. ||  || Author || ------ || Jeff Mahler || \""\""\""",No,No,Yes
9567,modern naming convention,,,Yes
9568,"\""\""\"" || FC-GQCNN network implemented in Tensorflow || Author: Vishal Satish || \""\""\""",No,Yes,Yes
9569,"\""\""\"" || Displays robust grasps planned using a GQ-CNN-based policy on a set of saved RGB-D images. || The default configuration is cfg\/examples\/policy.yaml. ||  || Author || ------ || Jeff Mahler || \""\""\""",No,No,Yes
9571,"\""\""\"" || Script to convert TensorDataset split indices to legacy indices format ||  || Author: Vishal Satish || \""\""\""",No,Yes,Yes
9572,TODO: don't access raw depth data like this,Yes,No,Yes
9573,TODO: make sure a list\/array is returned,,,Yes
9575,hack to fix reverse angle convention,Yes,Yes,Yes
9579,TODO: This really doesn't need to it's own layer type...it does the same thing as _build_fc_layer(),Yes,Yes,Yes
9580,TODO: @Vishal update this to work with angular outputs,,,Yes
9581,TODO: @Vishal integrate this in a cleaner fashion,Yes,Yes,Yes
9582,TODO: @Vishal rename this because it doesn't really open the dataset; which happens in self._load_and_enqueue(),,,Yes
9583,TODO: @Vishal refactor this function to refer to 'tensor' instead of 'file',Yes,Yes,Yes
9584,TODO: @Vishal this needs to be refactored to reference a 'tensor' instead of a 'file',Yes,Yes,Yes
9585,fix legacy,Yes,Yes,Yes
9586,TODO: @Vishal update this to work with angular outputs,Yes,Yes,Yes
9588,TODO: @Vishal refactor this function to refer to 'tensor' instead of 'file',,,Yes
9591,fix legacy #TODO: @Jeff; what needs to be fixed here? Or did I add this in?,,,Yes
9592,TODO: @Jeff; this isn't needed; right?,,,Yes
9595,TODO: @Vishal update this to work with angular outputs,Yes,Yes,Yes
9596,TODO: @Vishal integrate this in a cleaner fashion,Yes,Yes,Yes
9597,TODO: @Vishal rename this because it doesn't really open the dataset; which happens in self._load_and_enqueue(),,,Yes
9601,fix legacy,Yes,Yes,Yes
9602,support for legacy file naming convention,Yes,Yes,Yes
9603,fix legacy #TODO: @Jeff; what needs to be fixed here? Or did I add this in?,,,Yes
9606,"\""\""\"" || Displays robust grasps planned using a GQ-CNN-based policy on a set of saved RGB-D images. || The default configuration is cfg\/examples\/policy.yaml. ||  || Author || ------ || Jeff Mahler || \""\""\""",,,Yes
9609,TODO: @Vishal update this to work with angular outputs,Yes,Yes,Yes
9610,TODO: @Vishal integrate this in a cleaner fashion,,,Yes
9611,TODO: @Vishal rename this because it doesn't really open the dataset; which happens in self._load_and_enqueue(),Yes,Yes,Yes
9612,TODO: @Vishal refactor this function to refer to 'tensor' instead of 'file',Yes,Yes,Yes
9613,TODO: @Vishal this needs to be refactored to reference a 'tensor' instead of a 'file',Yes,Yes,Yes
9614,TODO: @Vishal find a better way to find policy type,,,Yes
9616,this is a hack because it seems that psutil is returning a lower load than htop; which could be because htop takes into account queued tasks,Yes,Yes,Yes
9618,TODO: @Vishal we should really be doing this in some factory policy,Yes,Yes,Yes
9621,"\""\""\"" || Constraint functions for grasp sampling || Author: Jeff Mahler || \""\""\""",No,Yes,Yes
9622,fix legacy,Yes,Yes,Yes
9623,support for legacy file naming convention,,,Yes
9627,fix legacy,,,Yes
9628,TODO: @Vishal find a better way to find policy type,Yes,No,Yes
9631,hack to fix reverse angle convention,,,Yes
9633,TODO: @Vishal figure out why install.run(self) causes install_requires to be ignored,Yes,Yes,Yes
9634,hack to fix reverse angle convention,,,Yes
9637,"TODO (vsatish): Figure out why this isn\""t printed.",Yes,Yes,Yes
9638,TODO(vsatish): Confirm that this is really not needed.,Yes,Yes,Yes
9639,TODO(vsatish): Confirm that this is really not needed.,,,Yes
9640,TODO(vsatish): Figure out why this isn't printed.,,,Yes
9641,TODO (vsatish): Figure out why this isn't printed.,,,Yes
9643,TODO(vsatish): We should really be doing this in some factory policy.,,,Yes
9644,"\""\""\"" || FC-GQ-CNN network implemented in Tensorflow || Author: Vishal Satish || \""\""\""",No,Yes,Yes
9646,TODO: Eliminate the notebook from disk if it's an Untitled one,Yes,Yes,Yes
9647,TODO: Eliminate the notebook from disk if it's an Untitled one,Yes,Yes,Yes
9648,TODO: Eliminate the notebook from disk if it's an Untitled one,,,Yes
9651,because it's needed by our kernel spec.,,,Yes
9653,FIXME: Don't use a CDN here,,,Yes
9656,TODO,Yes,Yes,Yes
9658,TODO: check it,Yes,No,Yes
9659,TODO: add cmd args,,,Yes
9660,TODO: add cmd args,Yes,No,Yes
9661,TODO: check if user uses vocab_load and not rewrite vocabulary,Yes,Yes,Yes
9662,TODO,Yes,Yes,Yes
9666,TODO: n_samples % batch = 0,Yes,Yes,Yes
9667,TODO,,,Yes
9668,TODO: n_samples % batch = 0,,,Yes
9669,hack for metrics,Yes,Yes,Yes
9670,TODO: profile this. Pool works over-slow.,Yes,Yes,Yes
9671,We'll impute missing values using the median for numeric columns and the most,No,Yes,Yes
9672,common value for string columns.,,,Yes
9673,"\""\""\"" || Speedml is a Python package to speed start machine learning projects. Author @manavsehgal. Docs https:\/\/speedml.com. || \""\""\""",No,No,Yes
9676,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
9678,[TODO] What is the performance cost of message ops?,Yes,Yes,Yes
9679,[TODO] Can we possibly use pandas.isin to check counts?,,,Yes
9680,"\""\""\"" || Speedml Model component with methods that work on sklearn models workflow. Contact author https:\/\/twitter.com\/manavsehgal. Code; docs and demos https:\/\/speedml.com. || \""\""\""",No,Yes,Yes
9681,TODO: Add more file formats supported by pandas.read_,Yes,Yes,Yes
9683,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
9686,**Efficient z update**,,,Yes
9691,This is a bit ugly; but it avoids running this again.,Yes,Yes,Yes
9693,XXX: 'probit',,,Yes
9695,"\""\""\"" || Machine learning module for Python || ================================== || sklearn is a Python module integrating classical machine || learning algorithms in the tightly-knit world of scientific Python || packages (numpy; scipy; matplotlib). || It aims to provide simple and efficient solutions to learning problems || that are accessible to everybody and reusable in various contexts: || machine-learning as a versatile tool for science and engineering. || See http:\/\/scikit-learn.org for complete documentation. || \""\""\""",,,Yes
9696,"\""\""\""Compatibility fixes for older version of python; numpy and scipy || If you add content to this file; please give the version of the package || at which the fixe is no longer needed. || \""\""\""",Yes,Yes,Yes
9697,store reference to original array to check if copy is needed when,,,Yes
9698,to an error. This is needed because specifying a non complex,No,Yes,Yes
9699,matrix had better be shifted so that we aren't allowed to use the spike,,,Yes
9700,matrix had better be shifted so that we aren't allowed to,Yes,Yes,Yes
9701,rescaling needed to adjust for how frequently loss_history is updated,Yes,Yes,Yes
9703,adam; rmsprop; adadelta. this should really be 1e-8,Yes,Yes,Yes
9705,These functions expose a public interface that properly encapsulates their internals,No,No,Yes
9706,this is needed to update loss history,,,Yes
9707,Create curriculum state and tracking variables if needed.,No,Yes,Yes
9708,create alphabet if needed and if it will be shared between layers; otherwise set to None so that _dihedrals takes care of it,No,Yes,Yes
9710,add to list of recurrent layers' outputs (needed for residual connection and some skip connections),,,Yes
9712,strictly speaking this isn't needed; but it allows multiple cuDNN-based models to run on the same GPU when num_layers = 1,,,Yes
9713,stack multiple cells if needed,No,No,Yes
9716,Obtain the classes from the cropped query (To-do implement it directly on model --> Now we do 2 forward),Yes,Yes,Yes
9717,TODO: Not sure if we should put this in a subfolder.,Yes,Yes,Yes
9718,"\""\""\"" || .. todo:: ||  ||     Based on code from pylearn2.datasets.hdf5 ||  || \""\""\""",,,Yes
9719,TODO: This could be made faster with a custom ufunc,Yes,No,Yes
9720,TODO: This loads it from hdf5 files that I have prepared.,Yes,No,Yes
9721,Maybe shuffle an iterator of the indices?,,,Yes
9724,TODO: This is temporary,Yes,No,Yes
9727,This is a bit ugly; but it avoids running this again.,Yes,Yes,Yes
9728,Workaround for standalone backslash,,,Yes
9731,TODO: Make ensemble method a choice,,,Yes
9732,TODO: Read this 10000 from the datasets,,,Yes
9733,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
9734,TODO: Add option to inspect as dict,Yes,Yes,Yes
9736,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
9737,Step 2: Skipping unused operators; e.g. batch normalization; linear activation quantizer,No,Yes,Yes
9738,"\""\""\""TVM Runtime module used to improve CPU performance.\""\""\""",No,Yes,Yes
9739,temporary: formula which derive number of qinput is not complete,Yes,No,Yes
9740,backward run: check the data format and transpose if needed,No,No,Yes
9742,TODO it's better to fix makefile,,,Yes
9743,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
9745,fix for github,No,Yes,Yes
9746,TODO(wakisaka): move to somewhere.,Yes,No,Yes
9747,TODO(tokunaga): the number of processes should be configurable,,,Yes
9748,Original model use truncated_normal as kernel init; but xavier is better than it in Cifar10 experiment.,Yes,Yes,Yes
9750,TODO(wakisaka): move to somewhere.,Yes,No,Yes
9754,TODO: check if the quantizers use same n_bits,Yes,No,Yes
9758,TODO: Neil-san; you don't probably need this,Yes,Yes,Yes
9759,TODO: Neil-san; you keep the things in a list already,,,Yes
9762,Step 2: Skipping unused operators; e.g. batch normalization; linear activation quantizer,,,Yes
9763,TODO: check if the quantizers use same n_bits,Yes,No,Yes
9765,FIXME(tokunaga): dataset should not have thier own data format,,,Yes
9766,TODO(tokunaga): the number of processes should be configurable,Yes,Yes,Yes
9767,is it really needed?,,,Yes
9769,HACK: cross py2-py3 compatible version,Yes,No,Yes
9772,fixme: default output format is NC (workaround for classification tasks),Yes,No,Yes
9774,FIXME: Cannot run library with hard_quantize=False for segmentation task.,,,Yes
9775,TODO(yang): Busy loop is not efficient here. Improve it and change them in other tasks.,,,Yes
9776,HACK: This is for TensorFlow bug workaround.,,,Yes
9777,TODO: These operations should be performed in Makefile instead of here,Yes,No,Yes
9778,TODO(primenumber): fix shape,,,Yes
9779,TODO(wakisaka): move to somewhere.,Yes,No,Yes
9780,Fix unsupported image types using the PIL.,No,Yes,Yes
9781,TODO,Yes,Yes,Yes
9783,TODO,Yes,Yes,Yes
9784,TODO make calls to get switch state;,Yes,Yes,Yes
9787,TODO change response to something reflecting success of traversal,,,Yes
9788,TODO make calls to get switch state;,,,Yes
9789,TODO compare to previous switch state,,,Yes
9791,TODO change response to something reflecting success of traversal,Yes,Yes,Yes
9792,TODO make calls to get switch state;,,,Yes
9793,TODO compare to previous switch state,Yes,Yes,Yes
9794,TODO schedule something to occur for updated flows,,,Yes
9797,TODO flag error?,Yes,No,Yes
9803,"\""\""\"" || Created on 24 August 2016 || @author: bradh; tlanham ||  || Test module for deep learning || package to classify pcap hex || headers. || \""\""\""",,,Yes
9805,"\""\""\"" || Created on 24 August 2016 || @author: bradh41; tlanham ||  || Evaluation module for deep learning || model to classify packets based on || hex headers. ||  || rabbitmq: ||     host:       poseidon-rabbit ||     exchange:   topic-poseidon-internal ||     queue:       || \""\""\""",No,Yes,Yes
9806,fix this,,,Yes
9808,TODO!!,,,Yes
9810,TODO more,,,Yes
9812,1 - (how much good stuff did we miss),No,Yes,Yes
9815,TODO!! remove for production,Yes,Yes,Yes
9818,TODO: fix the mac switchout,Yes,Yes,Yes
9819,TODO: should port\/ip\/mac address be ignored? yes,,,Yes
9820,TODO!! throws away the first packet!,Yes,Yes,Yes
9822,@TODO db call to see if really need to run things,,,Yes
9823,@TODO init the rabbitmq,,,Yes
9824,@TODO read item from queue (NONBLOCKING...),,,Yes
9825,@TODO write findings to main,,,Yes
9826,TODO more,Yes,No,Yes
9827,@TODO read item from queue (NONBLOCKING...),,,Yes
9828,@TODO make this into a function,Yes,Yes,Yes
9831,TODO make a db call,Yes,Yes,Yes
9832,"\""\""\"" || Simple script to add docs to poseidon || mongo database. ||  || @author: lanhamt || Created on September 13; 2016 || \""\""\""",,,Yes
9833,TODO schedule endpoint for analysis,Yes,No,Yes
9837,TODO: fix the mac switchout,Yes,Yes,Yes
9838,TODO: should port\/ip\/mac address be ignored? yes,,,Yes
9839,TODO!! throws away the first packet!,,,Yes
9841,TODO look at this again,Yes,Yes,Yes
9842,TODO figure out what this is:,,,Yes
9843,TODO: fix url for appropriate rest call,Yes,Yes,Yes
9845,TODO verify that this is not needed,Yes,Yes,Yes
9846,TODO more,,,Yes
9847,TODO do something with reccomendation,Yes,Yes,Yes
9849,TODO make this read until nothing in q,Yes,Yes,Yes
9851,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
9853,Fix unsupported image types using the Pillow.,,,Yes
9854,TODO is this the best place for this?,,,Yes
9855,TODO move this lower with the rest of the checks,,,Yes
9856,TODO move this lower with the rest of the checks,Yes,Yes,Yes
9857,TODO set defaults if these are not set,,,Yes
9858,TODO set defaults if these are not set,Yes,Yes,Yes
9859,TODO db call to see if really need to run things,Yes,Yes,Yes
9860,TODO option to receive other files (config can be multiple files),,,Yes
9861,TODO option to send other files (config can be multiple files),,,Yes
9866,TODO check for other files,Yes,Yes,Yes
9870,this will break if more than one port expires at the same time TODO,Yes,Yes,Yes
9871,TODO if no endpoints; update prometheus,,,Yes
9872,TODO this should grab 'state': 'Active',Yes,No,Yes
9873,TODO this should grab interface,,,Yes
9874,TODO this should grab 'state': 'Active',,,Yes
9876,TODO clean up loggers,Yes,Yes,Yes
9878,TODO this doesn't seem right,,,Yes
9880,TODO needs work,Yes,Yes,Yes
9882,TODO this should grab interface,,,Yes
9883,TODO option to receive other files (config can be multiple files),Yes,Yes,Yes
9884,TODO option to send other files (config can be multiple files),Yes,Yes,Yes
9886,TODO this should actually check if faucet is running (package or container),,,Yes
9887,TODO check if this is actually True,Yes,Yes,Yes
9889,TODO check for still running captures on this port,,,Yes
9890,TODO,Yes,Yes,Yes
9891,this will break if more than one port expires at the same time TODO,Yes,Yes,Yes
9892,TODO - still not right,,,Yes
9894,TODO: ***This code below is temporary.***,,,Yes
9895,TODO check the length didn't change before wiping it out,Yes,Yes,Yes
9897,move to mirroring state,No,Yes,Yes
9901,TODO needs data validation,,,Yes
9902,TODO needs data validation,,,Yes
9905,move to mirroring state,,,Yes
9907,TODO make this smarter about more complex configurations (backup original values; etc),Yes,Yes,Yes
9908,TODO improve logged output,Yes,Yes,Yes
9909,TODO handle expectation of '?',Yes,Yes,Yes
9910,TODO parse out args instead of hardcoding inactive,Yes,Yes,Yes
9911,TODO check if it should call show_state or show_devices,Yes,Yes,Yes
9912,TODO,,,Yes
9914,"\""\""\"" || The commands that can be executed in the Poseidon shell. ||  || Created on 18 January 2019 || @author: Charlie Lewis || \""\""\""",,,Yes
9915,TODO parse out args instead of all endpoints,,,Yes
9916,TODO add options to modify the columns,Yes,Yes,Yes
9918,make all the columns types be text,No,No,Yes
9919,TODO add options to modify the columns,,,Yes
9920,make all the columns types be text,Yes,No,Yes
9921,TODO add options to modify the columns,Yes,Yes,Yes
9922,make all the columns types be text,No,No,Yes
9923,TODO,Yes,Yes,Yes
9925,TODO,Yes,Yes,Yes
9926,TODO #971 check if unqiue flag and limit columns (fields),Yes,No,Yes
9927,TODO #963 check if nonzero flag and limit rows\/columns,Yes,No,Yes
9929,TODO this should grab 'state': 'Active',Yes,No,Yes
9930,TODO this should grab interface,Yes,Yes,Yes
9931,TODO action required that updates the endpoint,,,Yes
9932,TODO,Yes,Yes,Yes
9935,TODO,,,Yes
9936,TODO,,,Yes
9937,TODO now under task,Yes,Yes,Yes
9938,TODO #998,,,Yes
9939,remove columns that are all zero or 'NO DATA',No,Yes,Yes
9941,TODO,Yes,Yes,Yes
9943,TODO check endpoints to see if any of them apply,Yes,Yes,Yes
9944,TODO check already applied acls and remove if endpoint no longer applies,Yes,Yes,Yes
9945,TODO update faucet.yaml and apply acls,,,Yes
9946,TODO add endpoint metadata about acl history,,,Yes
9948,TODO acl by port - potentially later update rules in acls to be mac\/ip specific,Yes,Yes,Yes
9949,TODO ignore trunk ports?,,,Yes
9950,TODO,Yes,Yes,Yes
9951,TODO apply acls for that rule and endpoint,,,Yes
9952,TODO,,,Yes
9955,delete columns with no data,No,Yes,Yes
9956,TODO: networkml currently writes its decisions directly to redis; so this function is not used.,,,Yes
9957,TODO: history for IP address changes isn't accumulated yet.,,,Yes
9958,TODO check if this is actually True,,,Yes
9960,TODO improve logged output,Yes,Yes,Yes
9962,TODO ignore trunk ports\/stacking ports?,Yes,Yes,Yes
9963,TODO check for other files,Yes,Yes,Yes
9964,TODO: migrate to store_tool_result(),Yes,Yes,Yes
9968,TODO: not implemented.,Yes,No,Yes
9969,TODO: only updates to Poseidon's main docker-compose.yaml are currently handled.,Yes,Yes,Yes
9971,TODO this needs to be rewritten after history moves to prometheus,,,Yes
9972,TODO needs to be rewritten now that prev_state is no longer a history of state changes,,,Yes
9974,TODO acl_data,,,Yes
9976,TODO: 3.8+ and later; use importlib: https:\/\/pypi.org\/project\/importlib-metadata\/,Yes,No,Yes
9977,TODO: 3.8+ and later; use importlib: https:\/\/pypi.org\/project\/importlib-metadata\/,Yes,No,Yes
9978,TODO: 3.8+ and later; use importlib: https:\/\/pypi.org\/project\/importlib-metadata\/,Yes,No,Yes
9979,TODO merge with primitives\/acl.py,Yes,No,Yes
9981,TODO this may not be necessarily true going forward,Yes,Yes,Yes
9982,TODO: make smarter with more complex configs (backup original values; etc),,,Yes
9984,TODO coprocess_rules_files is set to None; which was previous default but removes functionality,,,Yes
9985,TODO option that doesn't require an sdn connection?,Yes,No,Yes
9987,"\""\""\""Implement some custom layers; not provided by TensorFlow. ||  || Trying to follow as much as possible the style\/standards used in || tf.contrib.layers || \""\""\""",,,Yes
9989,Maybe crop if needed.,Yes,No,Yes
9991,TODO: fix with tf.slice,Yes,No,Yes
9992,TODO: in RMSProp native code; memcpy() (for CPU) and,Yes,Yes,Yes
9993,fix for Python 3.,No,Yes,Yes
10001,TODO: use smooth_l1_loss() rather than reimplementing here,Yes,Yes,Yes
10002,TODO: Update this line to work with batch > 1. Right now it assumes all,Yes,Yes,Yes
10004,TODO: If multiple anchors have the same IoU match all of them,,,Yes
10006,TODO: use box_refinement() rather than duplicating the code here,Yes,No,Yes
10008,TODO: verify that this handles zero padded ROIs,,,Yes
10009,TODO: clean up (use tf.identify if necessary),Yes,No,Yes
10010,TODO: let DetectionLayer return normalized coordinates to avoid,Yes,Yes,Yes
10012,TODO: move resizing to mold_image(),,,Yes
10014,TODO: Build and use this function to reduce code duplication,,,Yes
10018,This is needed to display the images.,,,Yes
10021,unused when using sampled softmax loss.,,,Yes
10022,metric: larger is better,No,Yes,Yes
10024,workaround the --data-location problem,,,Yes
10028,Since we load everything in a new graph; this is not needed,No,Yes,Yes
10032,TODO(haoyuzhang): maybe use these values for visualization.,,,Yes
10034,expect user to set `num_eval_epochs` to >1; which will leave some unused,,,Yes
10035,This is needed to display the images.,,,Yes
10039,the labels here maybe chaos at those non-positive positions,,,Yes
10044,This is needed to display the images.,No,No,Yes
10045,"We \""pool\"" the model by simply taking the hidden state corresponding",No,Yes,Yes
10046,The convention in BERT is:,No,No,Yes
10047,'''This script optimizes feature columns in the model by removing error handling || and redundant nodes. Flag wide_and_deep_large_ds should be enabled for the additional || optimization for wide_and_deep_large_ds_model which involves fusion of categorical  || and numeric columns''',No,Yes,Yes
10048,"\""\""\"" ||   This function maps input columns (feature_placeholders) to  ||   tensors that can be inputted into the graph  ||   (similar in purpose to the output of our input functions) ||   In this particular case; we need to accomodate the sparse fields (strings) ||   so we have to do a slight modification to expand their dimensions;  ||   just like in the input functions || \""\""\""",,,Yes
10049,All categorical columns are strings for this dataset,No,Yes,Yes
10050,This is needed since the notebook is stored in the object_detection folder.,,,Yes
10051,This is needed to display the images.,No,No,Yes
10052,'''This script optimizes feature columns in the model by removing error handling || and redundant nodes. Flag wide_and_deep_large_ds should be enabled for the additional || optimization for wide_and_deep_large_ds_model which involves fusion of categorical || and numeric columns''',No,Yes,Yes
10054,"\""\""\"" ||   This function maps input columns (feature_placeholders) to ||   tensors that can be inputted into the graph ||   (similar in purpose to the output of our input functions) ||   In this particular case; we need to accomodate the sparse fields (strings) ||   so we have to do a slight modification to expand their dimensions; ||   just like in the input functions || \""\""\""",No,Yes,Yes
10059,All models: Tags which should appear in absolutely every MLPerf model.,No,Yes,Yes
10060,is needed; please file an issue under:,Yes,Yes,Yes
10061,should simply provide a good starting point to an interested party.,,,Yes
10062,necessarily when it begins to apply gradients; rather; it should be placed at,No,Yes,Yes
10064,Extra print is needed for the reference NCF because of tqdm.,Yes,Yes,Yes
10068,necessarily when it begins to apply gradients; rather; it should be placed at,No,Yes,Yes
10069,This tag should be emitted whenever the submission ends an evaluation pass,No,Yes,Yes
10073,The convention in BERT is:,,,Yes
10076,"What we really want to return is \""Steve Smith\"".",No,No,Yes
10077,(2) Blank lines between documents. Document boundaries are needed so,,,Yes
10078,The convention in BERT is:,,,Yes
10079,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
10080,The convention in BERT is:,No,No,Yes
10081,"What we really want to return is \""Steve Smith\"".",,,Yes
10082,"\""\""\""Defines NeuMF model for NCF framework. ||  || Some abbreviations used in the code base: || NeuMF: Neural Matrix Factorization || NCF: Neural Collaborative Filtering || GMF: Generalized Matrix Factorization || MLP: Multi-Layer Perceptron ||  || GMF applies a linear kernel to model the latent feature interactions; and MLP || uses a nonlinear kernel to learn the interaction function from data. NeuMF model || is a fused model of GMF and MLP to better model the complex user-item || interactions; and unifies the strengths of linearity of MF and non-linearity of || MLP for modeling the user-item latent structures. ||  || In NeuMF model; it allows GMF and MLP to learn separate embeddings; and combine || the two models by concatenating their last hidden layer. || \""\""\""",No,No,Yes
10084,perform matrix multiplications very quickly. This is similar to np.argwhere.,No,Yes,Yes
10086,No loss scaling is needed for fp32,,,Yes
10088,'''This script optimizes feature columns in the model by removing error handling || and redundant nodes. Flag wide_and_deep_large_ds should be enabled for the additional || optimization for wide_and_deep_large_ds_model which involves fusion of categorical  || and numeric columns''',,,Yes
10089,'''This script optimizes feature columns in the model by removing error handling || and redundant nodes. Flag wide_and_deep_large_ds should be enabled for the additional || optimization for wide_and_deep_large_ds_model which involves fusion of categorical || and numeric columns''',No,Yes,Yes
10090,"\""\""\"" ||   This function maps input columns (feature_placeholders) to  ||   tensors that can be inputted into the graph  ||   (similar in purpose to the output of our input functions) ||   In this particular case; we need to accomodate the sparse fields (strings) ||   so we have to do a slight modification to expand their dimensions;  ||   just like in the input functions || \""\""\""",No,Yes,Yes
10093,"\""\""\""Library to upload benchmark generated by BenchmarkLogger to remote repo. ||  || This library require google cloud bigquery lib as dependency; which can be || installed with: ||   > pip install --upgrade google-cloud-bigquery || \""\""\""",,,Yes
10096,Calculate largest length penalty (the larger penalty; the better score).,No,Yes,Yes
10097,"\""\""\""Input pipeline for the transformer model to read; filter; and batch examples. ||  || Two things to note in the pipeline: ||  || 1. Batching scheme ||  ||    The examples encoded in the TFRecord files contain data in the format: ||      {\""inputs\"": [variable length array of integers]; ||       \""targets\"": [variable length array of integers]} ||    Where integers in the arrays refer to tokens in the English and German vocab ||    file (named `vocab.ende.32768`). ||  ||    Prior to batching; elements in the dataset are grouped by length (max between ||    \""inputs\"" and \""targets\"" length). Each group is then batched such that: ||      group_batch_size * length <= batch_size. ||  ||    Another way to view batch_size is the maximum number of tokens in each batch. ||  ||    Once batched; each element in the dataset will have the shape: ||      {\""inputs\"": [group_batch_size; padded_input_length]; ||       \""targets\"": [group_batch_size; padded_target_length]} ||    Lengths are padded to the longest \""inputs\"" or \""targets\"" sequence in the batch ||    (padded_input_length and padded_target_length can be different). ||  ||    This batching scheme decreases the fraction of padding tokens per training ||    batch; thus improving the training speed significantly. ||  || 2. Shuffling ||  ||    While training; the dataset is shuffled in two places in the code. The first ||    is the list of training files. Second; while reading records using ||    `parallel_interleave`; the `sloppy` argument is used to generate randomness ||    in the order of the examples. || \""\""\""",No,Yes,Yes
10098,TODO: investigate whether removing code branching improves performance.,Yes,No,Yes
10104,TODO: Look into prefetch_input_elements for performance optimization.,,,Yes
10105,subtoken_dict; count how often the resulting subtokens appear; and update,No,No,Yes
10107,The convention in BERT is:,,,Yes
10109,The convention in BERT is:,No,No,Yes
10111,TODO: Do we need this; or remove,Yes,Yes,Yes
10112,TODO: verify if it is working,,,Yes
10116,sub-sample data by dropping zero targets; if needed,No,Yes,Yes
10117,pre-process data if needed,No,Yes,Yes
10120,save args (recompute data_size if needed),,,Yes
10121,(e.g. if same random samples needed across epochs),,,Yes
10123,feed target data to blobs if needed,No,Yes,Yes
10126,#NAME?,No,Yes,Yes
10127,ONNX does not support SparseLengthsSum operator directly. A workaround,,,Yes
10128,#NAME?,,,Yes
10132,TODO: Does this really work well? not sure..,,,Yes
10134,TODO: cannot simply apply for batch,,,Yes
10135,better to implement efficient function,No,Yes,Yes
10136,Presets known to work good.,No,Yes,Yes
10138,need to hack up run_aligner more..,,,Yes
10139,this is to fix festival if we somehow kill in the middle of training :(,Yes,No,Yes
10140,really; really; REALLY weird,Yes,Yes,Yes
10141,2>&1 needed to make it work?? really sketchy,Yes,Yes,Yes
10145,make cache folder if needed,No,Yes,Yes
10146,TODO: add arguments for CUDA,Yes,Yes,Yes
10151,TODO: After finalize; we can not add data anymore,Yes,Yes,Yes
10152,TODO: we may support size = -1 in the future,,,Yes
10153,TODO: this data format is related to output. Leave for future work,Yes,Yes,Yes
10156,TODO: fix by reading the .dimensions file,,,Yes
10161,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
10162,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
10163,actually a directory; using model_outfile to conform to Trainer naming convention,No,Yes,Yes
10165,actually a directory; using model_outfile to conform to Trainer naming convention,,,Yes
10169,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
10170,model_outfile is actually a directory; using model_outfile to conform to Trainer naming convention,,,Yes
10173,TODO: make a view not copy whenever possible,,,Yes
10175,this creates a copy of the source data (perhaps view could be more efficient),,,Yes
10176,TODO: check data and target indices are compatible,Yes,No,Yes
10178,TODO: process errors in tasks,,,Yes
10181,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10182,TODO: for -> np,Yes,Yes,Yes
10187,"\""\""\"" Hieu Pham et al. \""`Efficient Neural Architecture Search via Parameter Sharing || <https:\/\/arxiv.org\/abs\/1802.03268>`_\"" || \""\""\""",,,Yes
10188,full shape is needed,No,Yes,Yes
10189,TODO: make a view not copy if not shuffled,Yes,Yes,Yes
10191,TODO: for -> np,,,Yes
10192,"\""\""\"" Howard A. et al. \""`MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications || <https:\/\/arxiv.org\/abs\/1704.04861>`_\"" ||  || Sandler M. et al. \""`Inverted Residuals and Linear Bottlenecks: || Mobile Networks for Classification; Detection and Segmentation || <https:\/\/arxiv.org\/abs\/1801.04381>`_\"" || \""\""\""",,,Yes
10193,parse coordinate number from needed output name,No,No,Yes
10194,addition term if needed,No,Yes,Yes
10195,todo: implement copy(),Yes,No,Yes
10202,WTF,,,Yes
10209,TODO Extract to utilities,Yes,Yes,Yes
10214,If needed; make arguments for pointwise part and call it,No,Yes,Yes
10215,they both have same shape; if connection between them is needed;,No,Yes,Yes
10217,Make upsample\/block args; as well as prepare the skip connection if needed,No,Yes,Yes
10222,they both have same shape; if connection between them is needed;,,,Yes
10223,If inputs use different data formats; you need to manually control this parameter,Yes,Yes,Yes
10224,TODO: Think about it. Do we need load?,,,Yes
10225,TODO: We need progress bar,,,Yes
10226,TODO: If we will run heavy pipeline with run; worker will be killed. Fix it.,,,Yes
10228,TODO: process `device` to simplify nested list construction,Yes,Yes,Yes
10229,preload data if needed,No,No,Yes
10232,Fetch all the needed tensors,No,Yes,Yes
10233,preload data if needed,No,No,Yes
10234,TODO: Think about it. Do we need load?,Yes,No,Yes
10235,TODO: process `device` to simplify nested list construction,,,Yes
10236,TODO: Think about it. Do we need load?,Yes,No,Yes
10237,TODO: process `device` to simplify nested list construction,,,Yes
10240,preload data if needed,No,No,Yes
10241,TODO: Rework temporary fix,,,Yes
10242,TODO: Rework temporary fix,,,Yes
10243,FIXME,Yes,Yes,Yes
10244,FIXME,Yes,Yes,Yes
10248,FIXME,,,Yes
10252,Create a better repr of pylint report: remove markdown-related warnings,,,Yes
10254,Clone is needed due to bug in PyTorch v1.3. May be removed later,Yes,Yes,Yes
10256,Clone is needed due to bug in PyTorch v1.3. May be removed later,,,Yes
10257,Additionally imports `ipykernel`; `notebook`; `nbconvert` and `pylint`; if needed,,,Yes
10259,Split data into microbatches; if needed,No,Yes,Yes
10261,Apply decay to learning rate; if needed,No,Yes,Yes
10262,used when truncating a Sampler. If we cannot obtain a needed amount of points,No,Yes,Yes
10264,Additionally imports `ipykernel`; `notebook`; `nbconvert` and `pylint`; if needed,,,Yes
10265,Additionally imports 'requests`; 'ipykernel`; `notebook`; `nbconvert` and `pylint`; if needed,No,Yes,Yes
10267,Use obtained grad to move to the local maxima,No,Yes,Yes
10268,Use obtained grad to move to the local maxima,,,Yes
10269,Use obtained grad to move to the local maxima,,,Yes
10270,Used when truncating a Sampler. If we cannot obtain a needed amount of points,No,Yes,Yes
10274,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
10275,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
10276,this flush method is needed for python 3 compatibility.,,,Yes
10278,TODO: run callbacks,Yes,No,Yes
10280,TODO: run callbacks,,,Yes
10281,in order to implement CD-k\/ PCd-k we need to scan over the function that implement one gibbs step k times,,,Yes
10284,TODO: CODE EXACTLY WHAT NEEDS TO BE DONE HERE. (PUT NEG PHASE HERE.),Yes,Yes,Yes
10285,TODO: right now this will only work for one unitary...,Yes,Yes,Yes
10286,''' || A class that allows torch to handle complex algebra. || ----------------------------------------------------------------------------------------- || SYNTAX \/ ORDERING OF INDICES || matrices \/ tensors: m[2][i][j] >>> 2 = real and imaginary part ||                                >>> i = number of rows in the real and imaginary parts ||                                >>> j = number of columns in the real and imaginary parts ||  || vectors: v[2][i]               >>> 2 = real and imaginary part || \t\t\t\t\t\t\t   >>> i = nmber of rows in the real and imaginary parts ||  || scalars: s[2]                  >>> 2 = real and imaginary part || ----------------------------------------------------------------------------------------- || ''',,,Yes
10287,maybe add sampling of phase here too...,,,Yes
10290,TODO: must make these complex...,Yes,Yes,Yes
10292,TODO: right now this will only work for one unitary...,Yes,Yes,Yes
10294,''' || A class that allows torch to handle complex algebra. || ----------------------------------------------------------------------------------------- || SYNTAX \/ ORDERING OF INDICES || matrices \/ tensors: m[2][i][j] >>> 2 = real and imaginary part ||                                >>> i = number of rows in the real and imaginary parts ||                                >>> j = number of columns in the real and imaginary parts ||  || vectors: v[2][i]               >>> 2 = real and imaginary part || \t\t\t\t\t\t\t   >>> i = nmber of rows in the real and imaginary parts ||  || scalars: s[2]                  >>> 2 = real and imaginary part || ----------------------------------------------------------------------------------------- || ''',No,Yes,Yes
10295,maybe add sampling of phase here too...,Yes,Yes,Yes
10296,TODO: ADD NEG PHASE??? ASK GIACOMO,,,Yes
10297,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10298,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10300,TODO  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!,,,Yes
10301,TODO  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!,,,Yes
10302,TODO  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!,Yes,Yes,Yes
10303,-- Options for todo extension ----------------------------------------------,,,Yes
10304,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10305,"\""\""\"" || A module that allows torch to handle complex algebra. || --------- || SYNTAX \/ ORDERING OF INDICES || matrices \/ tensors: m[2][i][j] >>> 2 = real and imaginary part ||                                >>> i = number of rows in the real and imaginary parts ||                                >>> j = number of columns in the real and imaginary parts ||  || vectors: v[2][i]               >>> 2 = real and imaginary part ||                                >>> i = nmber of rows in the real and imaginary parts ||  || scalars: s[2]                  >>> 2 = real and imaginary part || --------- || \""\""\""",,,Yes
10307,"\""\""\"" || A class that allows torch to handle complex algebra. || --------- || SYNTAX \/ ORDERING OF INDICES || matrices \/ tensors: m[2][i][j] >>> 2 = real and imaginary part || \t\t\t\t\t\t\t   >>> i = number of rows in the real and imaginary parts || \t\t\t\t\t\t\t   >>> j = number of columns in the real and imaginary parts ||  || vectors: v[2][i]               >>> 2 = real and imaginary part || \t\t\t\t\t\t\t   >>> i = nmber of rows in the real and imaginary parts ||  || scalars: s[2]                  >>> 2 = real and imaginary part || --------- || \""\""\""",No,Yes,Yes
10312,TODO: numerical grads are NAN here if I don't do this if statement (july 16),Yes,Yes,Yes
10313,# NOTE: The 'full_unitaries' argument is not needed for training\/sampling.,No,No,Yes
10315,NOTE: The 'full_unitaries' argument is not needed for training\/sampling.,,,Yes
10316,# TODO: numerical grads are NAN here if I don't do this if statement (july 16),Yes,Yes,Yes
10317,TODO THIS LOOP IS THE MAIN BOTTLENECK,Yes,Yes,Yes
10319,Check how many local bases rotations appear in basis,No,No,Yes
10320,Must be using the :math:`\\sigma_i = 0; 1` convention.,No,Yes,Yes
10322,convert to +\/- 1 convention; after computing the,No,Yes,Yes
10323,TODO: do division here,Yes,No,Yes
10324,TODO: divide psi_-i \/ psi_i using complex math,Yes,Yes,Yes
10329,TODO: make this a generator function,Yes,Yes,Yes
10331,fix the mentornet parameters,No,Yes,Yes
10332,It is more memory efficient than very deep residual network and has,No,Yes,Yes
10334,move permuted ground truths back to GPU,No,Yes,Yes
10335,ugly function that turns contents of torch variables to numpy,,,Yes
10336,Initialize parameters to lazily compute them once needed,No,Yes,Yes
10338,Fix noise parameters for all models except top fidelity,,,Yes
10340,#NAME?,,,Yes
10342,columns count is 1 for continuous plus 1 for discrete plus number of categories,,,Yes
10343,Initialize parameters to lazily compute them once needed,No,Yes,Yes
10346,Transpose here is needed to handle input dimensions,,,Yes
10347,Loop through batch winners (lower value better),No,No,Yes
10348,predict Y at inputs (needed by q-EI),No,Yes,Yes
10349,too many columns,Yes,No,Yes
10351,TODO: improve here,Yes,Yes,Yes
10353,to generalize better; possibly; to occlusions of what we're,No,Yes,Yes
10357,Append all the columns to an array and generate a dask dataframe from it with the data,,,Yes
10359,Transform the data for each of the columns.,No,Yes,Yes
10360,Renaming columns in the users dataframe to avoid ambiguity,No,Yes,Yes
10361,Renaming columns in the sessions dataframe to avoid ambiguity,No,No,Yes
10363,@todo Check request origin for all API requests,Yes,Yes,Yes
10364,Append all the columns to an array and generate a dask dataframe from it with the data,,,Yes
10365,Get the time columns.,No,Yes,Yes
10366,Transform the data for each of the columns.,No,Yes,Yes
10368,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
10370,For extended xyz format; plain is needed since ase can not parse the extxyz it writes,Yes,Yes,Yes
10372,ToDo: change Docstring or squeeze(),Yes,No,Yes
10375,TODO: Introduce periodic boundary conditions,,,Yes
10376,TODO: This is not the nicest way; but h5py does not seem to support life update of metadata,,,Yes
10377,TODO: Could be made a torch nn.Module,Yes,No,Yes
10378,Check if normal GLE or GLE for ring polymers is needed:,,,Yes
10382,TODO: Should no longer be necessary,Yes,No,Yes
10383,TODO: the transpose here should be wrong!,,,Yes
10384,TODO: CHECK TRANSPOSE,Yes,No,Yes
10385,TODO: CHECK TRANSPOSE,Yes,No,Yes
10387,TODO rewrite to enable single-precision evaluation,Yes,No,Yes
10388,TODO: Options should be given here,,,Yes
10389,TODO: Could be moved to global attrs if available,Yes,Yes,Yes
10391,todo: check here,Yes,No,Yes
10393,todo: check,Yes,No,Yes
10394,todo: remove,Yes,No,Yes
10395,Training Ends,,,Yes
10397,There could be better solutions,Yes,Yes,Yes
10398,shape convention (shift index; molecule index; atom index; 3),,,Yes
10399,todo: add check here,Yes,No,Yes
10400,todo: remove,Yes,No,Yes
10401,todo: fix,Yes,No,Yes
10402,todo: continue,Yes,Yes,Yes
10404,Conversion from ppm to atomic units. Alpha is the fine structure constant and 1e6 are the ppm,No,No,Yes
10405,The main file parser is always needed,,,Yes
10407,Check if normal GLE or GLE for ring polymers is needed:,,,Yes
10408,TODO: Only required if one is interested in the conserved,Yes,Yes,Yes
10409,TODO: Is no problem; as NM transformation never mixes atom dimension,,,Yes
10410,TODO: fragmentation should be applied here,,,Yes
10412,TODO: Maybe change to error; so user has to delete it per hand,Yes,Yes,Yes
10414,TODO: Much better to move this to a state dict?,,,Yes
10415,TODO: There might be a more efficient way of doing this than a loop,,,Yes
10416,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10417,TODO: speficy pandas in dependencies,Yes,No,Yes
10418,TODO: some factorization of what is common for distances;,,,Yes
10420,TODO vectorize these functions (accept arrays),Yes,No,Yes
10424,so we either have to implement login into _fetch_data,No,Yes,Yes
10425,TODO: look for uncompressed files when download result is zippped.,,,Yes
10426,does a lot of thing; maybe makes sense to group the argument into,,,Yes
10428,so we either have to implement login into _fetch_data,,,Yes
10429,TODO: look for uncompressed files when download result is zippped.,Yes,Yes,Yes
10430,does a lot of thing; maybe makes sense to group the argument into,Yes,Yes,Yes
10431,the url ends with \/,No,No,Yes
10433,columns such as full_name,No,Yes,Yes
10436,Here is how the columns are distributed,No,No,Yes
10437,maybe not an ideal design; should we mark,Yes,Yes,Yes
10438,Separating clean; and dirty columns as well a a column we will try to predict,No,Yes,Yes
10439,All the clean columns are encoded once and for all; but we since we,No,Yes,Yes
10441,Choosing clean columns,,,Yes
10443,Some numerical columns (Gross pay; etc..) and some obvious categorical,No,Yes,Yes
10446,Some numerical columns (Gross pay; etc..) and some obvious categorical,No,Yes,Yes
10447,columns such as full_name,No,Yes,Yes
10448,for other categorical columns  such as Employee position title:,No,Yes,Yes
10449,To delete unused OneHotEncoder attributes,No,Yes,Yes
10450,To delete unused OneHotEncoder attributes,,,Yes
10454,"r\""\""\"" || Fitting scalable; non-linear models on data with dirty categories || ================================================================= || Non-linear models form a very large model class. Among others; this class || includes: ||  || * Neural Networks || * Tree-based methods such as Random Forests; and the very powerful Gradient ||   Boosting Machines [#xgboost]_ || * Kernel Methods. ||  ||  || Non-linear models can sometimes outperform linear ones; as they are able to || grasp more complex relationships between the input and the output of a machine || learning problem. However; using a non-linear model model often comes at a || cost: ||  || * for neural networks; this cost is an extended model tuning time; in order to ||   achieve good optimization and network architecture. || * gradient boosting machines do not tend to scale extremely well with ||   increasing sample size; as all the data needs to be loaded into the main ||   memory. || * for kernel methods; parameter fitting requires the inversion of a gram matrix ||   of size :math:`n \\times m` (:math:`n` being the number of samples); yiedling ||   a quadratic dependency (with n) in the final compmutation time. ||  ||  || All is not lost though. For kernel methods; there exists approximation || algorithms; that drops the quadratic dependency with the sample size while || ensuring almost the same model capacity. ||  || In this example; you will learn how to: ||     1. build a ML pipeline that uses a kernel method. ||     2. make this pipeline scalable. ||  ||  || .. note:: ||    This example assumes the reader to be familiar with similarity encoding and ||    its use-cases. ||  ||    * For an introduction to dirty categories; see :ref:`this example<sphx_glr_auto_examples_01_dirty_categories.py>`. ||    * To learn with dirty categories using the SimilarityEncoder; see :ref:`this example<sphx_glr_auto_examples_02_predict_employee_salaries.py>`. ||  ||  || .. |NYS| replace:: :class:`Nystroem <sklearn.kernel_approximation.Nystroem>` ||  || .. |NYS_EXAMPLE| ||     replace:: :ref:`scikit-learn documentation <nystroem_kernel_approx>` ||  || .. |RBF| ||     replace:: :class:`RBFSampler <sklearn.kernel_approximation.RBFSampler>` ||  || .. |SE| replace:: :class:`SimilarityEncoder <dirty_cat.SimilarityEncoder>` ||  || .. |SGDClassifier| replace:: ||     :class:`SGDClassifier <sklearn.linear_model.SGDClassifier>` ||  || .. |APS| replace:: ||     :func:`average_precision_score <sklearn.metrics.average_precision_score>` ||  || .. |OHE| replace:: ||     :class:`OneHotEncoder <sklearn.preprocessing.OneHotEncoder>` ||  || .. |SGDClassifier_partialfit| replace:: ||     :func:`partial_fit <sklearn.linear_model.SGDClassifier.partial_fit>` ||  || .. |Pipeline| replace:: ||     :class:`Pipeline <sklearn.pipeline.Pipeline>` ||  || \""\""\""",No,Yes,Yes
10455,To compute the |APS|; a binary version of the lables are needed; so a |OHE|,,,Yes
10457,observation) is needed. Fortunately; for a fair amount of interesting cost,,,Yes
10460,tend to lead to good prediction performance; but with more computational,,,Yes
10462,TODO: hook into pandas.core?,Yes,No,Yes
10464,TODO: return the status of all of the updates,Yes,No,Yes
10465,TODO: add into update_carto funciton as subfunction?,,,Yes
10466,TODO: add table schema to the metadata,Yes,Yes,Yes
10467,TODO: see how geopandas does it,,,Yes
10468,TODO: add check of current schema with metadata schema,Yes,Yes,Yes
10469,"\""\""\"" || Monkey patching pandas to add utilities for CARTO tables || Andy Eschbacher and Stuart Lynn; 2017 ||  || Project goals ||     * Like geopandas; have a .cartomap() method which gives back the data ||       as a map using carto's maps api and turbocartocss on an optional ||       attribute ||  || Features to add: ||     * create a dataframe from scratch ||         * establish cartodb_id ||         * set metadata manually ||         * register with carto ||  || Notes on propagating pandas metadata: ||     * https:\/\/github.com\/pandas-dev\/pandas\/issues\/2485 ||     * geopandas does a good job of propagating metadata; seems to be by ||       subclassing Dataframes: ||       https:\/\/github.com\/geopandas\/geopandas\/blob\/v0.2.1\/geopandas\/geodataframe.py#L54 ||       similar to what we tried in cartopandas.py. ||       A geodataframe stores it's own metadata: ||       https:\/\/github.com\/geopandas\/geopandas\/blob\/v0.2.1\/geopandas\/geodataframe.py#L47 || \""\""\""",,,Yes
10470,TODO: make less buggy about the diff between NaNs and nulls,,,Yes
10471,create new column if needed,No,No,Yes
10472,drop column if needed,,,Yes
10477,TODO: extract to column,,,Yes
10478,TODO: instead of doing row by row; build up a list of queries,Yes,Yes,Yes
10481,TODO: add datetype conversion,Yes,No,Yes
10482,TODO: include in uriencode in mapconfig?,Yes,Yes,Yes
10483,TODO: instead of doing row by row; build up a list of queries,Yes,Yes,Yes
10484,TODO: make less buggy about the diff between NaNs and nulls,Yes,Yes,Yes
10487,TODO: build this,,,Yes
10490,TODO: make this agnostic (for urllib) for python 2 v 3,Yes,No,Yes
10491,TODO: find more robust way to check which metadata item was checked,Yes,Yes,Yes
10492,TODO: what happens if rows are removed?,,,Yes
10494,TODO: batch UPDATES into a transaction,Yes,No,Yes
10498,exclude geometry columns if asked,,,Yes
10499,TODO: include_geom in cdb_client structure?,Yes,No,Yes
10500,TODO: how to handle NaNs deterministically?,Yes,Yes,Yes
10501,TODO: add table schema to the metadata,Yes,Yes,Yes
10503,TODO: add datetype conversion,Yes,No,Yes
10504,TODO: make less buggy about the diff between NaNs and nulls,Yes,Yes,Yes
10505,TODO: build this,Yes,No,Yes
10506,create new column if needed,,,Yes
10509,TODO: make this agnostic (for urllib) for python 2 v 3,Yes,No,Yes
10511,TODO: find more robust way to check which metadata item was checked,Yes,Yes,Yes
10512,TODO: fill this in,Yes,No,Yes
10514,TODO: add into sync_carto function as subfunction?,Yes,No,Yes
10515,TODO: add datetype conversion,Yes,No,Yes
10517,TODO: if onprem; use the specified template\/domain? instead,Yes,Yes,Yes
10519,TODO: change this to be a list of colnames,Yes,No,Yes
10523,if they share columns; throw an error,,,Yes
10524,TODO: replace with `pd.read_carto(query='')`,Yes,No,Yes
10527,TODO: fix the geomtype piece; and is_org_user may be important (or some,,,Yes
10528,TODO: would it be better to cartodbfy after the inserts?,Yes,Yes,Yes
10529,TODO: how to ensure some consistency between old index and new one? can cartodb_id be zero-valued?,Yes,Yes,Yes
10531,add columns,No,Yes,Yes
10532,NOTE: carto utility columns are not pulled down. These include:,No,Yes,Yes
10535,TODO: find more robust way to check which metadata item was checked,,,Yes
10537,TODO: replace with bounding box extent instead,,,Yes
10539,TODO: not used anywhere,,,Yes
10540,TODO: do type checking instead of the casting-to-string checking,Yes,No,Yes
10541,TODO: generalize this for onprem,Yes,No,Yes
10543,TODO: match marker line color to basemap color,,,Yes
10545,TODO: This won't persist with non-inplace pandas operations,Yes,Yes,Yes
10550,TODO: wrap into self._table_exists() method that could probably,Yes,Yes,Yes
10551,TODO: make space for checking if the table_name is a sync table. If,,,Yes
10554,TODO: this should go with the import api code below,,,Yes
10556,TODO: wrap up this into a private method that can be reused if looping,,,Yes
10558,TODO: add layers preprocessing method like,,,Yes
10559,TODO: write this as a private matehod,Yes,Yes,Yes
10560,TODO: put self.(base_url; api_key; username; auth_client; and sql_client),Yes,Yes,Yes
10562,TODO: put self.(base_url; api_key; username; auth_client; and sql_client),,,Yes
10563,TODO: wrap up this into a private method that can be reused if looping,Yes,No,Yes
10565,#          'columns in CARTO if you need to map off of numeric ',No,Yes,Yes
10566,#          'columns. See issue #131 for a proposed solution: ',Yes,No,Yes
10568,TODO: write this as a private matehod,Yes,Yes,Yes
10569,TODO: make this a batch job if it is a large dataframe,Yes,Yes,Yes
10570,TODO: replace this with a function,Yes,No,Yes
10571,TODO: make this a batch job if it is a large dataframe or move,,,Yes
10572,TODO: replace this with a function,Yes,No,Yes
10573,TODO: make this a batch job if it is a large dataframe or move,Yes,Yes,Yes
10574,TODO: replace this with a function,Yes,No,Yes
10575,TODO: add layers preprocessing method like,,,Yes
10576,TODO: write this as a private method,Yes,No,Yes
10578,TODO: change this to a dict,Yes,No,Yes
10579,TODO: what happens if there are no data layers? E.g.; only a BaseMap,Yes,No,Yes
10581,TODO: This could be handled but just doing a direct comparison of the,Yes,Yes,Yes
10582,should have requested columns + utility columns from CARTO,No,No,Yes
10584,should have requested columns + utility columns from CARTO,No,No,Yes
10585,specify order of columns,No,Yes,Yes
10586,TODO: remove the named map templates,Yes,Yes,Yes
10587,table exists but columns don't,,,Yes
10588,TODO: change this to a dict,Yes,No,Yes
10590,util columns + new column of type number,No,No,Yes
10591,alter non-util columns that are not text type,No,No,Yes
10592,TODO: replace this with a function,,,Yes
10593,ensure columns are in expected order,,,Yes
10594,no rows or columns,No,Yes,Yes
10596,TODO: error on this as NotImplementedError,Yes,Yes,Yes
10597,ensure columns are in expected order,No,Yes,Yes
10599,ensure columns are in expected order,,,Yes
10600,no rows or columns,No,Yes,Yes
10601,no rows or columns,,,Yes
10602,no rows or columns,No,Yes,Yes
10603,TODO: make this a batch job if it is a large dataframe or move,Yes,Yes,Yes
10604,get schema of style columns,No,Yes,Yes
10605,style columns as keys; data types as values,No,Yes,Yes
10606,TODO: move these if\/else branches to individual methods,,,Yes
10607,get scheme if exists. if not; one will be chosen later if needed,No,Yes,Yes
10614,TODO: make this work for general queries,Yes,Yes,Yes
10615,TODO: replace the following error catching with Import API,Yes,No,Yes
10616,TODO: replace the following error catching with Import API,,,Yes
10619,TODO: replace the following error catching with Import API,Yes,No,Yes
10620,TODO: break into timerange search here?,Yes,Yes,Yes
10621,TODO: make this work for general queries,Yes,Yes,Yes
10624,TODO: use Import API here instead with a combo of sql\/table_name,,,Yes
10629,TODO: create a function out of this?,,,Yes
10633,TODO: move all of the below to the utils module,Yes,Yes,Yes
10634,specify order of columns,,,Yes
10635,FIXME if geom_col is None persist with no geom_col,Yes,Yes,Yes
10636,FIXME if geom_col is None persist with no geom_col,Yes,Yes,Yes
10640,# table exists but columns don't,Yes,Yes,Yes
10641,set(boundaries.columns)),No,No,Yes
10643,meta_columns = set((,No,Yes,Yes
10644,self.assertSetEqual(set(meta.columns); meta_columns;,,,Yes
10645,msg='metadata columns are all there'),No,No,Yes
10648,set(data.columns) - origcols),,,Yes
10649,util columns + new column of type number,No,No,Yes
10651,should have requested columns + utility columns from CARTO,,,Yes
10653,FIXME does not work in python 2.7 (COPY stucks and blocks the table; fix after,,,Yes
10654,FIXME does not work in python 2.7 (COPY stucks and blocks the table; fix after,Yes,Yes,Yes
10655,FIXME in https:\/\/github.com\/CartoDB\/cartoframes\/issues\/580,,,Yes
10656,set(df_index.columns)),No,No,Yes
10658,TODO: use Import API here instead with a combo of sql\/table_name,Yes,Yes,Yes
10659,alter non-util columns that are not type text,,,Yes
10660,TODO add check,,,Yes
10663,drop unneeded columns to lighten the query,,,Yes
10665,FIXME https:\/\/github.com\/CartoDB\/cartoframes\/issues\/593,Yes,No,Yes
10666,TODO add check,Yes,No,Yes
10667,FIXME https:\/\/github.com\/CartoDB\/cartoframes\/issues\/593,Yes,No,Yes
10674,ensure columns are in expected order,No,Yes,Yes
10675,FIXME: https:\/\/github.com\/CartoDB\/cartoframes\/issues\/594,Yes,No,Yes
10676,TODO: move all of the below to the utils module,,,Yes
10678,TODO add check,Yes,No,Yes
10680,drop description columns to lighten the query,,,Yes
10681,FIXME https:\/\/github.com\/CartoDB\/cartoframes\/issues\/593,,,Yes
10683,TODO: replace the following error catching with Import API,Yes,No,Yes
10684,TODO: replace the following error catching with Import API,,,Yes
10685,TODO: move all of the below to the utils module,,,Yes
10687,TODO: replace the following error catching with Import API,Yes,No,Yes
10688,FIXME https:\/\/github.com\/CartoDB\/cartoframes\/issues\/593,,,Yes
10691,drop description columns to lighten the query,,,Yes
10695,TODO: refactor,Yes,No,Yes
10698,TODO: use from_geodataframe,Yes,No,Yes
10699,TODO: obtain from the Dataset,,,Yes
10701,TODO: error control (https:\/\/github.com\/CartoDB\/cartoframes\/issues\/669),Yes,No,Yes
10702,TODO: error control (https:\/\/github.com\/CartoDB\/cartoframes\/issues\/669),Yes,No,Yes
10704,TODO: uncomment when we support GeoDataFrame,,,Yes
10705,TODO: error control,Yes,No,Yes
10706,TODO: uncomment when we support GeoDataFrame,,,Yes
10707,TODO: add more geom generation cases,Yes,No,Yes
10708,FIXME: https:\/\/github.com\/CartoDB\/carto-python\/issues\/122,Yes,No,Yes
10709,TODO: Dataframe,,,Yes
10710,FIXME: https:\/\/github.com\/CartoDB\/cartoframes\/issues\/594,Yes,No,Yes
10713,TODO: Dataframe,Yes,No,Yes
10715,FIXME: api_key not used,Yes,Yes,Yes
10716,FIXME: api_key not used,Yes,Yes,Yes
10720,FIXME python 2.7 compatibility,Yes,Yes,Yes
10721,FIXME python 2.7 compatibility,,,Yes
10722,"TODO: the current implementation of \""fetch\"" is using the Dataset class.",,,Yes
10723,FIXME: api_key not used,,,Yes
10726,get schema of style columns,No,Yes,Yes
10728,TODO: create a function out of this?,Yes,No,Yes
10729,TODO: make this work for general queries,,,Yes
10730,drop description columns to lighten the query,No,Yes,Yes
10735,TODO: either report new (ng+nn) and changed (cg+cn) records; or we could,Yes,No,Yes
10737,TODO: what if result is empty? Wjhat should we return then? And what should the caller do with that?,,,Yes
10738,TODO: handle this either by uploading the dataset;,,,Yes
10740,TODO: handle this either by uploading the dataset;,,,Yes
10744,TODO: Confirm which properties from the DDL we should include here,Yes,Yes,Yes
10745,TODO,Yes,Yes,Yes
10750,TODO: upload to temporary table if necessary,Yes,No,Yes
10752,TODO: this is redundant with `center`,Yes,No,Yes
10754,"\""SELECT cdb_cartodbfytable({table})\"".format(table=table_name)  # TODO: support for org users",Yes,No,Yes
10757,TODO: only if not saved to table? (table_name is None?),,,Yes
10758,TODO: either report new (ng+nn) and changed (cg+cn) records; or we could,,,Yes
10759,TODO: should we return a Dataframe if the input was a Dataframe,Yes,No,Yes
10761,FIXME: more robust to check first for query (hasattr(input_dataset; 'query')),Yes,No,Yes
10763,TODO: decorator to authenticate,Yes,Yes,Yes
10764,TODO: process column name in metadata; remove spaces and points,Yes,Yes,Yes
10766,TODO: decorator to authenticate,,,Yes
10767,TODO: detect geometries,,,Yes
10768,TODO: detect geometries,,,Yes
10771,<-- TODO: change to Dataset,Yes,Yes,Yes
10773,TODO: Add data table ref in fields of filters,Yes,Yes,Yes
10774,<-- TODO: change to Dataset,,,Yes
10775,TODO: Add data table ref in fields of filters,Yes,Yes,Yes
10776,TODO: decorator to authenticate,,,Yes
10778,TODO: decorator to authenticate,Yes,Yes,Yes
10781,TODO: Map properties,,,Yes
10782,TODO: Map properties,Yes,Yes,Yes
10783,TODO: Map properties,Yes,Yes,Yes
10784,TODO: Map properties,,,Yes
10786,TODO: Map properties,Yes,Yes,Yes
10789,TODO: Add data table ref in fields of filters,Yes,Yes,Yes
10790,TODO: Map properties,,,Yes
10791,TODO: Map properties,,,Yes
10792,TODO: Map properties,Yes,Yes,Yes
10793,TODO: Map properties,Yes,Yes,Yes
10795,TODO: Map properties,,,Yes
10796,TODO: Map properties,,,Yes
10797,FIXME python 2.7 compatibility,,,Yes
10798,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
10799,TODO: decorator to authenticate,,,Yes
10801,allows to assign individual metadata attributes to columns,No,Yes,Yes
10802,allows to assign individual status attributes to columns,No,Yes,Yes
10803,TODO: should remove the cartodb_id column from the result,,,Yes
10810,TODO,Yes,Yes,Yes
10812,TODO: This file contains both the subscriptions endpoint functions,,,Yes
10814,TODO: implement DOSubscriptionInfoManager,,,Yes
10815,TODO: check if the dataframe has a geometry column if not exception,Yes,Yes,Yes
10817,TODO: refactor to share code with geocode() and call self._geocode() here instead,,,Yes
10818,TODO: process column name in metadata; remove spaces and points,,,Yes
10819,TODO: process column name in metadata; remove spaces and points,Yes,Yes,Yes
10822,TODO: Use a single transaction so that reported changes (posterior - prior queries),Yes,No,Yes
10823,FIXME: Python SDK should return proper exceptions,Yes,Yes,Yes
10824,TODO: GeocodeResult object,,,Yes
10825,Exclude duplicated geom columns when the geometry column (normalized),,,Yes
10827,TODO: check if the dataframe has a geometry column if not exception,,,Yes
10829,TODO: should remove the cartodb_id column from the result,,,Yes
10830,TODO: refactor to share code with geocode() and call self._geocode() here instead,,,Yes
10833,TODO: This class reuses existing classes from the dataset registry.,Yes,Yes,Yes
10834,TODO how to check if the dataset is public,,,Yes
10835,TODO,Yes,Yes,Yes
10836,we could have filtered columns in the df. See DataframeColumnsInfo,,,Yes
10837,we could have filtered columns in the df. See DataframeColumnsInfo,,,Yes
10844,allows to assign individual status attributes to columns,,,Yes
10852,TODO: refactor,Yes,No,Yes
10853,FIXME,,,Yes
10855,FIXME,,,Yes
10856,FIXME,,,Yes
10862,TODO custom exception,Yes,Yes,Yes
10873,TODO fix this crap,,,Yes
10874,TODO custom exception,,,Yes
10876,TODO validate field names,,,Yes
10877,TODO custom exception,,,Yes
10879,TODO: make it compatible with polygons,Yes,Yes,Yes
10880,TODO: disabled temporaly; remove it before merging the PR,,,Yes
10882,TODO: rename strategy,,,Yes
10883,TODO: `autoplay: False` is not working on Airship;,,,Yes
10884,so it should be fixed when autoplay param is exposed in CF API,Yes,Yes,Yes
10885,Equal columns: truncate table,No,No,Yes
10886,Diff columns: drop + add columns,,,Yes
10887,TODO: review logic copy_from,Yes,Yes,Yes
10888,plane_instance parameter; padding zero to fix size,,,Yes
10890,todo: pass in config to operation constructor; i.e.; oper_cls(config),,,Yes
10895,TODO: add .vocab.count handling to wrapper,Yes,No,Yes
10896,If the bug contains the strings `github` and `w3c`; it's likely a feature implementing a w3c spec.,No,Yes,Yes
10897,TODO: Add any [XXX:YYY] that appears in the whiteboard as [XXX: only,Yes,Yes,Yes
10898,TODO: Make get_labels directly return a dict.,Yes,Yes,Yes
10902,"TODO: Text cleanup (replace stack traces with \""STACK_TRACE\""; replace file references with \""FILE_REFERENCE\""; etc.)",,,Yes
10904,Turn bug IDs into integers and labels into booleans.,No,Yes,Yes
10907,TODO: Handle changes to product and component.,,,Yes
10911,TODO: Ignore this for now. Example usage in 1101478.,Yes,Yes,Yes
10912,TODO: Ignore this for now. Example usage in 1437575.,Yes,No,Yes
10915,TODO: Ignore this for now. Example usage in 1369255.,,,Yes
10917,TODO: Remove when https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1513956 and https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1513995 are fixed.,Yes,Yes,Yes
10918,TODO: Ignore this for now. Example usage in 1162372 or 1389926.,Yes,No,Yes
10919,TODO: Ignore changes to attachments for now.,Yes,Yes,Yes
10922,TODO: https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1513981.,,,Yes
10923,TODO: Re-enable when we'll support bug snapshotting (#5).,,,Yes
10927,Bugs that go from not having dev-doc-needed to having dev-doc-complete are bugs,,,Yes
10930,This is only a temporary hack: Should be removed after the template issue with reviewers (https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1528938),,,Yes
10932,TODO: Remove when https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1550104 is fixed,Yes,Yes,Yes
10933,TODO: Remove once https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1550120 is fixed.,,,Yes
10934,TODO: Remove once https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1550128 is fixed.,Yes,Yes,Yes
10935,TODO: Remove once https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1550129 is fixed.,,,Yes
10936,TODO: We can delete anything older than 90 days at this point.,Yes,No,Yes
10941,TODO: Remove this once calculate_experiences is faster and less memory hungry.,,,Yes
10942,TODO: always assert here; once https:\/\/bugzilla.mozilla.org\/show_bug.cgi?id=1514415 is fixed.,Yes,Yes,Yes
10947,Override the Docker image tag if needed,No,No,Yes
10950,TODO: We should probably schedule chunks of bugs to avoid jobs that,,,Yes
10953,TODO: Classify could choke on a single bug which could make the whole,Yes,Yes,Yes
10954,"TODO: It should actually be applied on \""raw_text\"".",Yes,Yes,Yes
10958,TODO: Set to 2 years and 6 months. If it takes too long; make the task work incrementally like microannotate-generate.,Yes,Yes,Yes
10963,Workaround: handle multi class case for force_plot to work correctly,Yes,Yes,Yes
10964,Get IDs of bugs which caused regressions fixed by commits (useful for the regressor model).,,,Yes
10965,TODO: Move http_service under bugbug to solve this import name,Yes,Yes,Yes
10967,TODO: Might be better storing it in the file,Yes,No,Yes
10968,version = file_path_parts[14:]  # TODO: Use version,Yes,Yes,Yes
10970,TODO: Use limit,,,Yes
10971,Change time could be None if it's a security bug,,,Yes
10973,TODO: Support group reviewers somehow.,Yes,No,Yes
10978,TODO Remove this hack after a few runs on the new deployment,Yes,Yes,Yes
10980,TODO: Should we consider a merge of the commits of the stack?,Yes,No,Yes
10982,XXX: Consider using the runnable jobs artifact from the Gecko Decision task.,Yes,Yes,Yes
10989,"TODO: The \""\"" choice can be removed when all users have been updated to pass a correct phabricator_deployment.",Yes,Yes,Yes
10990,TODO: This can be removed when all users have been updated to pass a correct phabricator_deployment.,Yes,No,Yes
10993,Custom __init__ is needed to support *args; and object.__setattr__ is,Yes,Yes,Yes
10994,needed for 'frozen=True'.,No,Yes,Yes
10996,that limit. Connections are established as needed; so using a large value,No,Yes,Yes
10997,XXX: We have to support items in the cache that were added,No,Yes,Yes
11000,XXX: Move this back to adr.config.cache.has to avoid regenerating,Yes,Yes,Yes
11006,"Handle \""meaningless\"" labeling changes (\""meaningless\"" as they shouldn't really affect test scheduling).",Yes,Yes,Yes
11007,TODO: we should consider the probabilities of `task1 failure -> task2 failure` and,,,Yes
11008,Regenerate results which don't contain the fix revision.,Yes,Yes,Yes
11011,TODO: Figure out why.,,,Yes
11013,TODO: Figure out what to do with bugs we couldn't download (security bugs).,Yes,No,Yes
11015,A bug that was moved out of 'Invalid Bugs' is definitely a legitimate bug.,,,Yes
11020,Only add to the map bugs we are interested in; and bugs that block other bugs (needed for the bug_to_types call).,No,Yes,Yes
11022,TODO: The whole thing!\uFFFF,,,Yes
11023,"\""\""\""TODO: top level package documentation for Intel-PNI toolkit goes here || \""\""\""",,,Yes
11025,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
11026,Set Wi to a subset of columns of the identity matrix of size voxels by TRs,No,Yes,Yes
11029,FIXME Workaround for using the Intel compiler by setting the CC env var,Yes,No,Yes
11030,specify the random state to fix the random numbers,,,Yes
11032,move closer to their correct values before GP is introduced.,No,Yes,Yes
11035,default that all columns are conditions of interest,No,No,Yes
11036,the first tells the number of columns in this condition,,,Yes
11039,No columns in X0 can be explained by the,No,Yes,Yes
11040,The two flags above dictates whether columns corresponding to,No,Yes,Yes
11042,specify the random state to fix the random numbers,,,Yes
11043,"\""\""\""Full Correlation Matrix Analysis (FCMA) ||  || Correlation related high performance routines || \""\""\""",No,Yes,Yes
11045,"\""\""\""Distributed Searchlight SRM Example. ||  || This example runs searchlight srm on time segment matching experiment using Sherlock || dataset.  ||  || Example Usage || ------- || If run 4 ranks: ||     $ mpirun -n 4 python3 searchlight_srm_example.py ||  || Author || ------- || Hejia Zhang (Princeton University ELE Department) ||  || Notes || ------- || It's an implementation of: || Zhang; Hejia; et al. \""A Searchlight Factor Model Approach for Locating Shared  || Information in Multi-Subject fMRI Analysis.\"" arXiv preprint arXiv:1609.09432 (2016). || https:\/\/arxiv.org\/abs\/1609.09432 ||  || \""\""\""",No,Yes,Yes
11046,"\""\""\""Generic image functionality.\""\""\""",No,Yes,Yes
11048,regressors needed to account for the covariance,No,No,Yes
11049,Pull out information that is needed,,,Yes
11051,If pairwise; apply sign-flips by rows and columns,,,Yes
11053,Return signal needed,,,Yes
11056,FIXME workaround for Theano failure on macOS Conda builds,Yes,Yes,Yes
11058,FIXME workaround for pymanopt only working with tensorflow 1.,Yes,Yes,Yes
11059,"\""\""\"" || Some properties of the matrix-variate normal distribution || --------------------------------------------------------- ||  || .. math:: ||     \\\\DeclareMathOperator{\\\\Tr}{Tr} ||     \\\ || ewcommand{\\\\trp}{^{T}} % transpose ||     \\\ || ewcommand{\\\\trace}{\\\\text{Trace}} % trace ||     \\\ || ewcommand{\\\\inv}{^{-1}} ||     \\\ || ewcommand{\\\\mb}{\\\\mathbf{b}} ||     \\\ || ewcommand{\\\\M}{\\\\mathbf{M}} ||     \\\ || ewcommand{\\\\C}{\\\\mathbf{C}} ||     \\\ || ewcommand{\\\\G}{\\\\mathbf{G}} ||     \\\ || ewcommand{\\\\A}{\\\\mathbf{A}} ||     \\\ || ewcommand{\\\\R}{\\\\mathbf{R}} ||     \\\\renewcommand{\\\\S}{\\\\mathbf{S}} ||     \\\ || ewcommand{\\\\B}{\\\\mathbf{B}} ||     \\\ || ewcommand{\\\\Q}{\\\\mathbf{Q}} ||     \\\ || ewcommand{\\\\mH}{\\\\mathbf{H}} ||     \\\ || ewcommand{\\\\U}{\\\\mathbf{U}} ||     \\\ || ewcommand{\\\\mL}{\\\\mathbf{L}} ||     \\\ || ewcommand{\\\\diag}{\\\\mathrm{diag}} ||     \\\ || ewcommand{\\\\etr}{\\\\mathrm{etr}} ||     \\\\renewcommand{\\\\H}{\\\\mathbf{H}} ||     \\\ || ewcommand{\\\\vecop}{\\\\mathrm{vec}} ||     \\\ || ewcommand{\\\\I}{\\\\mathbf{I}} ||     \\\ || ewcommand{\\\\X}{\\\\mathbf{X}} ||     \\\ || ewcommand{\\\\Y}{\\\\mathbf{Y}} ||     \\\ || ewcommand{\\\\Z}{\\\\mathbf{Z}} ||     \\\\renewcommand{\\\\L}{\\\\mathbf{L}} ||  ||  || The matrix-variate normal distribution is a generalization to matrices of the || normal distribution. Another name for it is the multivariate normal || distribution with kronecker separable covariance. || The distributional intuition is as follows: if || :math:`X \\\\sim \\\\mathcal{MN}(M;R;C)` then || :math:`\\\\mathrm{vec}(X)\\\\sim\\\\mathcal{N}(\\\\mathrm{vec}(M); C \\\\otimes R)`; || where :math:`\\\\mathrm{vec}(\\\\cdot)` is the vectorization operator and || :math:`\\\\otimes` is the Kronecker product. If we think of X as a matrix of TRs || by voxels in the fMRI setting; then this model assumes that each voxel has the || same TR-by-TR covariance structure (represented by the matrix R); || and each volume has the same spatial covariance (represented by the matrix C). || This assumption allows us to model both covariances separately. || We can assume that the spatial covariance itself is kronecker-structured; || which implies that the spatial covariance of voxels is the same in the X; || Y and Z dimensions. ||  || The log-likelihood for the matrix-normal density is: ||  || .. math:: ||     \\\\log p(X\\\\mid \\\\M;\\\\R; \\\\C) = -2\\\\log mn - m \\\\log|\\\\C| -  n \\\\log|\\\\R| - ||     \\\\Tr\\\\left[\\\\C\\\\inv(\\\\X-\\\\M)\\\\trp\\\\R\\\\inv(\\\\X-\\\\M)\\\\right] ||  || Here :math:`X` and :math:`M` are both :math:`m\\\\times n` matrices; :math:`\\\\R` || is :math:`m\\\\times m` and :math:`\\\\C` is :math:`n\\\\times n`. ||  || The `brainiak.matnormal` package provides structure to infer models that || can be stated in the matrix-normal notation that are useful for fMRI analysis. || It provides a few interfaces. `MatnormModelBase` is intended as a || base class for matrix-variate models. It provides a wrapper for the tensorflow || optimizer that provides convergence checks based on thresholds on the function || value and gradient; and simple verbose outputs. It also provides an interface || for noise covariances (`CovBase`). Any class that follows the interface || can be used as a noise covariance in any of the matrix normal models. The || package includes a variety of noise covariances to work with. ||  || Matrix normal marginals || ------------------------- ||  || Here we extend the multivariate gaussian marginalization identity to matrix || normals. This is used in a number of the models in the package. Below; we || use lowercase subscripts for sizes to make dimensionalities easier to track. || Uppercase subscripts for covariances help keep track where they come from. ||  || .. math:: ||     \\\\mathbf{X}_{ij} &\\\\sim \\\\mathcal{MN}(\\\\mathbf{A}_{ij}; ||     \\\\Sigma_{\\\\mathbf{X}i};\\\\Sigma_{\\\\mathbf{X}j})\\\\\\\\ ||     \\\\mathbf{Y}_{jk} &\\\\sim \\\\mathcal{MN}(\\\\mathbf{B}_{jk}; ||      \\\\Sigma_{\\\\mathbf{Y}j};\\\\Sigma_{\\\\mathbf{Y}k})\\\\\\\\ ||     \\\\mathbf{Z}_{ik}\\\\mid\\\\mathbf{X}_{ij};\\\\mathbf{Y}_{jk} &\\\\sim ||      \\\\mathcal{MN}(\\\\mathbf{X}_{ij}\\\\mathbf{Y}_{jk} + \\\\mathbf{C}_{ik}; ||       \\\\Sigma_{\\\\mathbf{Z}_i}; \\\\Sigma_{\\\\mathbf{Z}_k})\\\\\\\\ ||  ||  || We vectorize; and convert to a form we recognize as || :math:`y \\\\sim \\\\mathcal{N}(Mx+b; \\\\Sigma)`. ||  || .. math:: ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij};\\\\mathbf{Y}_{jk} &\\\\sim ||      \\\\mathcal{N}(\\\\vecop(\\\\X_{ij}\\\\mathbf{Y}_{jk}+\\\\mathbf{C}_{ik}); ||      \\\\Sigma_{\\\\mathbf{Z}_k}\\\\otimes\\\\Sigma_{\\\\mathbf{Z}_i})\\\\\\\\ ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij};\\\\mathbf{Y}_{jk} ||     &\\\\sim \\\\mathcal{N}((\\\\I_k\\\\otimes\\\\X_{ij})\\\\vecop(\\\\mathbf{Y}_{jk}) ||      + \\\\vecop(\\\\mathbf{C}_{ik}); ||      \\\\Sigma_{\\\\mathbf{Z}_k}\\\\otimes\\\\Sigma_{\\\\mathbf{Z}_i}) ||  ||  || Now we can use our standard gaussian marginalization identity: ||  || .. math:: ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij} \\\\sim ||     \\\\mathcal{N}((\\\\I_k\\\\otimes\\\\X_{ij})\\\\vecop(\\\\mathbf{B}_{jk}) + ||      \\\\vecop(\\\\mathbf{C}_{ik}); ||      \\\\Sigma_{\\\\mathbf{Z}_k}\\\\otimes\\\\Sigma_{\\\\mathbf{Z}_i} + ||      (\\\\I_k\\\\otimes\\\\X_{ij})(\\\\Sigma_{\\\\mathbf{Y}_k}\\\\otimes ||      \\\\Sigma_{\\\\mathbf{Y}_j})(\\\\I_k\\\\otimes\\\\X_{ij})\\\\trp ) ||  ||  || Collect terms using the mixed-product property of kronecker products: ||  || .. math:: ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij} \\\\sim ||      \\\\mathcal{N}(\\\\vecop(\\\\X_{ij}\\\\mathbf{B}_{jk}) + ||       \\\\vecop(\\\\mathbf{C}_{ik}); \\\\Sigma_{\\\\mathbf{Z}_k}\\\\otimes ||       \\\\Sigma_{\\\\mathbf{Z}_i} + \\\\Sigma_{\\\\mathbf{Y}_k}\\\\otimes ||        \\\\X_{ij}\\\\Sigma_{\\\\mathbf{Y}_j}\\\\X_{ij}\\\\trp) ||  ||  || Now; we can see that the marginal density is a matrix-variate normal only if || :math:`\\\\Sigma_{\\\\mathbf{Z}_k}= \\\\Sigma_{\\\\mathbf{Y}_k}` -- that is; the || variable we're marginalizing over has the same covariance in the dimension || we're *not* marginalizing over as the marginal density. Otherwise the densit || is well-defined but the covariance retains its kronecker structure. So we let || :math:`\\\\Sigma_k:=\\\\Sigma_{\\\\mathbf{Z}_k}= \\\\Sigma_{\\\\mathbf{Y}_k}`; factor; || and transform it back into a matrix normal: ||  || .. math:: ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij} &\\\\sim ||      \\\\mathcal{N}(\\\\vecop(\\\\X\\\\mathbf{B}_{jk}) + \\\\vecop(\\\\mathbf{C}_{ik}); ||       \\\\Sigma_{k}\\\\otimes\\\\Sigma_{\\\\mathbf{Z}_i} + \\\\Sigma_{_k}\\\\otimes ||       \\\\X\\\\Sigma_{\\\\mathbf{Y}_j}\\\\X\\\\trp)\\\\\\\\ ||     \\\\vecop(\\\\mathbf{Z}_{ik})\\\\mid\\\\mathbf{X}_{ij} &\\\\sim ||      \\\\mathcal{N}(\\\\vecop(\\\\X\\\\mathbf{B}_{jk}) + \\\\vecop(\\\\mathbf{C}_{ik}); ||       \\\\Sigma_{k}\\\\otimes(\\\\Sigma_{\\\\mathbf{Z}_i} ||       +\\\\X\\\\Sigma_{\\\\mathbf{Y}_j}\\\\X\\\\trp))\\\\\\\\ ||     \\\\mathbf{Z}_{ik}\\\\mid\\\\mathbf{X}_{ij} &\\\\sim ||      \\\\mathcal{MN}(\\\\X\\\\mathbf{B}_{jk} + \\\\mathbf{C}_{ik}; ||       \\\\Sigma_{\\\\mathbf{Z}_i} +\\\\X\\\\Sigma_{\\\\mathbf{Y}_j}\\\\X\\\\trp;\\\\Sigma_{k}) ||  ||  || We can do it in the other direction as well; because if || :math:`\\\\X \\\\sim \\\\mathcal{MN}(M; U; V)` then :math:`\\\\X\\\\trp \\\\sim || \\\\mathcal{MN}(M\\\\trp; V; U)`: ||  || .. math:: ||     \\\\mathbf{Z\\\\trp}_{ik}\\\\mid\\\\mathbf{X}_{ij};\\\\mathbf{Y}_{jk} &\\\\sim ||     \\\\mathcal{MN}(\\\\mathbf{Y}_{jk}\\\\trp\\\\mathbf{X}_{ij}\\\\trp + ||     \\\\mathbf{C}\\\\trp_{ik}; \\\\Sigma_{\\\\mathbf{Z}_k};\\\\Sigma_{\\\\mathbf{Z}_i})\\\\\\\\ ||     \\\\mbox{let } \\\\Sigma_i := ||      \\\\Sigma_{\\\\mathbf{Z}_i}=\\\\Sigma_{\\\\mathbf{X}_i} \\\\\\\\ ||     \\\\cdots\\\\\\\\ ||     \\\\mathbf{Z\\\\trp}_{ik}\\\\mid\\\\mathbf{Y}_{jk} &\\\\sim ||      \\\\mathcal{MN}(\\\\mathbf{A}_{jk}\\\\trp\\\\mathbf{X}_{ij}\\\\trp + ||       \\\\mathbf{C}\\\\trp_{ik}; \\\\Sigma_{\\\\mathbf{Z}_k} + ||        \\\\Y\\\\trp\\\\Sigma_{\\\\mathbf{Y}_j}\\\\Y;\\\\Sigma_{\\\\mathbf{Z}_i})\\\\\\\\ ||     \\\\mathbf{Z}_{ik}\\\\mid\\\\mathbf{Y}_{jk} &\\\\sim ||      \\\\mathcal{MN}(\\\\mathbf{X}_{ij}\\\\mathbf{A}_{jk}+ ||       \\\\mathbf{C}_{ik};\\\\Sigma_{\\\\mathbf{Z}_i};\\\\Sigma_{\\\\mathbf{Z}_k} + ||        \\\\Y\\\\trp\\\\Sigma_{\\\\mathbf{Y}_j}\\\\Y) ||  || These marginal likelihoods are implemented relatively efficiently in || `MatnormModelBase.matnorm_logp_marginal_row` and || `MatnormModelBase.matnorm_logp_marginal_col`. ||  || Partitioned matrix normal conditionals || -------------------------------------- ||  || Here we extend the multivariate gaussian conditional identity to matrix || normals. This is used for prediction in some models. Below; we || use lowercase subscripts for sizes to make dimensionalities easier to track. || Uppercase subscripts for covariances help keep track where they come from. ||  ||  || Next; we do the same for the partitioned gaussian identity. First two || vectorized matrix-normals that form our partition: ||  || .. math:: ||     \\\\mathbf{X}_{ij} &\\\\sim \\\\mathcal{MN}(\\\\mathbf{A}_{ij}; \\\\Sigma_{i}; ||     \\\\Sigma_{j}) \\\\rightarrow \\\\vecop[\\\\mathbf{X}_{ij}] \\\\sim ||     \\\\mathcal{N}(\\\\vecop[\\\\mathbf{A}_{ij}]; \\\\Sigma_{j}\\\\otimes\\\\Sigma_{i})\\\\\\\\ ||     \\\\mathbf{Y}_{ik} &\\\\sim \\\\mathcal{MN}(\\\\mathbf{B}_{ik}; \\\\Sigma_{i}; ||     \\\\Sigma_{k}) \\\\rightarrow \\\\vecop[\\\\mathbf{Y}_{ik}] \\\\sim ||     \\\\mathcal{N}(\\\\vecop[\\\\mathbf{B}_{ik}]; \\\\Sigma_{k}\\\\otimes\\\\Sigma_{i})\\\\\\\\ ||     \\\\begin{bmatrix}\\\\vecop[\\\\mathbf{X}_{ij}] \\\\\\\\ \\\\vecop[\\\\mathbf{Y}_{ik}] ||     \\\\end{bmatrix} ||     & \\\\sim \\\\mathcal{N}\\\\left(\\\\vecop\\\\begin{bmatrix}\\\\mathbf{A}_{ij} ||     \\\\\\\\ \\\\mathbf{B}_{ik} ||     \\\\end{bmatrix} ||     ; \\\\begin{bmatrix} \\\\Sigma_{j}\\\\otimes \\\\Sigma_i  & ||      \\\\Sigma_{jk} \\\\otimes \\\\Sigma_i  \\\\\\\\ ||     \\\\Sigma_{kj}\\\\otimes \\\\Sigma_i & \\\\Sigma_{k} \\\\otimes ||      \\\\Sigma_i\\\\end{bmatrix}\\\\right) ||  || We apply the standard partitioned Gaussian identity and simplify using the || properties of the :math:`\\\\vecop` operator and the mixed product property || of kronecker products: ||  || .. math:: ||     \\\\vecop[\\\\X_{ij}] \\\\mid \\\\vecop[\\\\Y_{ik}]\\\\sim ||     \\\\mathcal{N}(&\\\\vecop[\\\\A_{ij}] + (\\\\Sigma_{jk}\\\\otimes\\\\Sigma_i) ||     (\\\\Sigma_k\\\\inv\\\\otimes\\\\Sigma_i\\\\inv)(\\\\vecop[\\\\Y_{ik}]-\\\\vecop[\\\\B_{ik}]);\\\\\\\\ ||     & \\\\Sigma_j\\\\otimes\\\\Sigma_i -  (\\\\Sigma_{jk}\\\\otimes\\\\Sigma_i) ||     (\\\\Sigma_k\\\\inv\\\\otimes\\\\Sigma_i\\\\inv) (\\\\Sigma_{kj}\\\\otimes\\\\Sigma_i))\\\\\\\\ ||     =\\\\mathcal{N}(&\\\\vecop[\\\\A_{ij}] + ||      (\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\otimes\\\\Sigma_i\\\\Sigma_i\\\\inv) ||      (\\\\vecop[\\\\Y_{ik}]-\\\\vecop[\\\\B_{ik}]); \\\\\\\\ ||      & \\\\Sigma_j\\\\otimes\\\\Sigma_i - ||      (\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\Sigma_{kj}\\\\otimes ||      \\\\Sigma_i\\\\Sigma_i\\\\inv \\\\Sigma_i))\\\\\\\\ ||     =\\\\mathcal{N}(&\\\\vecop[\\\\A_{ij}] + (\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\otimes\\\\I) ||     (\\\\vecop[\\\\Y_{ik}]-\\\\vecop[\\\\B_{ik}]); \\\\\\\\ ||      & \\\\Sigma_j\\\\otimes\\\\Sigma_i - ||      (\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\Sigma_{kj}\\\\otimes\\\\Sigma_i)\\\\\\\\ ||     =\\\\mathcal{N}(&\\\\vecop[\\\\A_{ij}] + ||     \\\\vecop[\\\\Y_{ik}-\\\\B_{ik}\\\\Sigma_k\\\\inv\\\\Sigma_{kj}]; ||      (\\\\Sigma_j-\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\Sigma_{kj})\\\\otimes\\\\Sigma_i) ||  ||  || Next; we recognize that this multivariate gaussian is equivalent to the || following matrix variate gaussian: ||  || .. math:: ||     \\\\X_{ij} \\\\mid \\\\Y_{ik}\\\\sim \\\\mathcal{MN}(\\\\A_{ij} + ||     (\\\\Y_{ik}-\\\\B_{ik})\\\\Sigma_k\\\\inv\\\\Sigma_{kj}; \\\\Sigma_i; ||     \\\\Sigma_j-\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\Sigma_{kj}) ||  || The conditional in the other direction can be written by working through the || same algebra: ||  || .. math:: ||     \\\\Y_{ik} \\\\mid \\\\X_{ij}\\\\sim \\\\mathcal{MN}(\\\\B_{ik} +(\\\\X_{ij}- ||     \\\\A_{ij})\\\\Sigma_j\\\\inv\\\\Sigma_{jk}; \\\\Sigma_i; ||     \\\\Sigma_k-\\\\Sigma_{kj}\\\\Sigma_j\\\\inv\\\\Sigma_{jk}) ||  || Finally; vertical rather than horizontal concatenation (yielding a partitioned || row rather than column covariance) can be written by recognizing the behavior || of the matrix normal under transposition: ||  || .. math:: ||     \\\\X\\\\trp_{ji} \\\\mid \\\\Y\\\\trp_{ki}\\\\sim \\\\mathcal{MN}(&\\\\A\\\\trp_{ji} + ||     \\\\Sigma_{jk}\\\\Sigma_k\\\\inv(\\\\Y\\\\trp_{ki}-\\\\B\\\\trp_{ki}); ||      \\\\Sigma_j-\\\\Sigma_{jk}\\\\Sigma_k\\\\inv\\\\Sigma_{kj}; \\\\Sigma_i)\\\\\\\\ ||     \\\\Y\\\\trp_{ki} \\\\mid \\\\X\\\\trp_{ji}\\\\sim \\\\mathcal{MN}(&\\\\B\\\\trp_{ki} + ||     \\\\Sigma_{kj}\\\\Sigma_j\\\\inv(\\\\X\\\\trp_{ji}-\\\\A\\\\trp_{ji}); ||      \\\\Sigma_k-\\\\Sigma_{kj}\\\\Sigma_j\\\\inv\\\\Sigma_{jk}; \\\\Sigma_i) ||  || These conditional likelihoods are implemented relatively efficiently || in `MatnormModelBase.matnorm_logp_conditional_row` and || `MatnormModelBase.matnorm_logp_conditional_col`. ||  || \""\""\""",,,Yes
11061,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
11062,"\""\""\"" || Probabilistic machine learning module for Python || ================================================= || pmlearn is a Python module for practical probabilistic machine || learning built on top of scikit-learn and PymC3. ||  || It aims to provide simple and efficient solutions to learning problems || that are accessible to everybody and reusable in various contexts: || machine-learning as a versatile tool for science and engineering. || See http:\/\/pymc-learn.org for complete documentation. || \""\""\""",No,Yes,Yes
11063,TODO: make this more efficient; right now; it's very explicit so I understand it.,Yes,Yes,Yes
11065,TODO: As Manjari mentioned; we should take input data to the interface,,,Yes
11072,TODO: fix this,Yes,No,Yes
11073,Why does np.nonzero\/np.flatnonzero create so much problems?,,,Yes
11074,TODO: check that where is actually needed here,Yes,No,Yes
11075,Cython fix for Python3,,,Yes
11076,TODO: This may be easily deprecated in favor of,Yes,No,Yes
11077,maybe improved later,,,Yes
11078,unparseable. Maybe git-describe is misbehaving?,,,Yes
11079,maybe improved later,Yes,No,Yes
11081,TODO: Number of trials?? Add argument put also put a default.,Yes,No,Yes
11082,TODO: a default\/best moptconfig would help,Yes,Yes,Yes
11084,TODO voici et voila,,,Yes
11086,TODO?? Default resource from environmental,Yes,No,Yes
11087,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
11088,Fork if it is needed,No,Yes,Yes
11090,XXX: Reminder for future DB implementations:,,,Yes
11092,TODO Accept a string parsed out from args or config,Yes,Yes,Yes
11094,TODO gaussian == normal == norm -> real,Yes,Yes,Yes
11099,TODO builders,Yes,Yes,Yes
11101,Change that .@#$% scipy convention for uniform.,Yes,No,Yes
11102,TODO algorithm injects requirements on space; as a class variable (<- Transformer PR),,,Yes
11105,TODO check requirements,Yes,No,Yes
11106,TODO cascade Transformation through `Factory`,Yes,Yes,Yes
11107,TODO substitute with transformed space,Yes,Yes,Yes
11108,TODO Transform back to the original space,Yes,Yes,Yes
11109,(TODO) To be removed; when `refers` is settled.,,,Yes
11110,white box hack,No,No,Yes
11111,XXX: Complete this on both end of interval when scipy bug is fixed,Yes,Yes,Yes
11112,TODO: No need for read_and_write here; because unique indexes,,,Yes
11115,TODO: No need for read_and_write here; because unique indexes,Yes,Yes,Yes
11116,TODO Expose these 4 USER oriented goodfellows to a orion configuration file :),Yes,Yes,Yes
11120,Get database perhaps from default locs,,,Yes
11123,TODO: Default resource from environmental (localhost),Yes,No,Yes
11124,Hack it into being discoverable,Yes,No,Yes
11126,TODO Write classes and instantiate transformers accordingly,,,Yes
11127,TODO Create Adaptor instances,Yes,Yes,Yes
11132,TODO: Meh; ugly,Yes,Yes,Yes
11133,# TODO: Detect marked renaming and resolve properly,Yes,Yes,Yes
11135,TODO: Does not work !!!! * * * * FIX  FIX FIX,Yes,Yes,Yes
11136,TODO: When refactoring experiment managenent; is_different_from,Yes,Yes,Yes
11137,TODO: Find out how we should pass those arguments (--config-change-type; etc),Yes,Yes,Yes
11139,"\""\""\"" || :mod:`orion.core.io.database.ephemeraldb` -- Non permanent database || =================================================================== ||  || .. module:: database ||    :platform: Unix ||    :synopsis: Implement non permanent version of :class:`orion.core.io.database.AbstractDB` ||  || \""\""\""",No,Yes,Yes
11142,Hack it into being discoverable,Yes,No,Yes
11144,TODO: Where should we define this,,,Yes
11145,TODO: Move trials_history into PrimaryAlgo during the refactoring of Algorithm with,,,Yes
11148,"\""\""\"" || :mod:`orion.core.io.database.pickleddb` -- Pickled Database || =========================================================== ||  || .. module:: database ||    :platform: Unix ||    :synopsis: Implement permanent version of :class:`orion.core.io.database.EphemeralDB` ||  || \""\""\""",No,Yes,Yes
11149,"\""\""\"" || :mod:`orion.algo.asha` -- TODO || ====================================================================== ||  || .. module:: asha  ||    :platform: Unix ||    :synopsis: TODO ||  || \""\""\""",Yes,Yes,Yes
11153,TODO Expose these 4 USER oriented goodfellows to a orion configuration file :),Yes,Yes,Yes
11155,TODO: Add assertion for content of config file,,,Yes
11156,TODO: Remove this method but still create config file.,Yes,Yes,Yes
11157,"\""\""\"" || :mod:`orion.algo.asha` -- TODO || ====================================================================== ||  || .. module:: asha  ||    :platform: Unix ||    :synopsis: TODO ||  || \""\""\""",Yes,Yes,Yes
11158,TODO: Add fidelity here based on `space`,Yes,Yes,Yes
11159,TODO: Hash point (without fidelity) to get a unique trial id,Yes,Yes,Yes
11162,"\""\""\"" || :mod:`orion.storage.base -- Generic Storage Protocol || ==================================================== ||  || .. module:: base ||    :platform: Unix ||    :synopsis: Implement a generic protocol to allow Orion to communicate using ||    different storage backend ||  || \""\""\""",,,Yes
11165,TODO: Remove this line when views gets fully configured,Yes,Yes,Yes
11167,TODO: Views are not fully configured until configuration is refactored,Yes,Yes,Yes
11168,TODO: Views are not fully configured until configuration is refactored,,,Yes
11170,TODO: Views are not fully configured until configuration is refactored,Yes,Yes,Yes
11172,TODO: Views are not fully configured until configuration is refactored,Yes,Yes,Yes
11174,TODO: Fix these singletons to remove Legacy; MongoDB; PickledDB and EphemeralDB.,Yes,Yes,Yes
11175,TODO: Configure this,Yes,No,Yes
11176,TODO: Configure this,Yes,No,Yes
11177,probably should be 6,No,No,Yes
11180,FIXME =False worked before the vector refactor; fixing requires re-ordering load\/store indices; but they aren't the faster option so not worth time right now,Yes,Yes,Yes
11185,This can result in more efficient kernels; but requires runtime checking to ensure the specified,,,Yes
11188,Tensile will allocate additional VGPR in Global Store phase if needed to,No,Yes,Yes
11192,ShiftPtr does not support very small problem dims < global load vector width since the shift,Yes,Yes,Yes
11193,would move outside the array bounds.,Yes,Yes,Yes
11194,how much info to print. 0=none; 1=standard; 2=verbose,No,Yes,Yes
11195,both options were supported until a refactoring of the short-vector code (necessary to enable assembly) broke it. Since =True always seems to be faster; no time has been spend on fixing =False,,,Yes
11197,in opencl for some compilers; performance improved by putting a memfence after each subiteration; it prevented the loads of one subiteration from being moved,No,Yes,Yes
11198,+ Less VGPRS (32b offset vs 64-bit) needed for addressing,,,Yes
11199,These conditions should be checked using Assert - TODO,,,Yes
11203,This can improve utilization; in particular if macro-tile is larger than the lower dimensions.,,,Yes
11204,Tensile will allocate additional VGPR in Global Store phase if needed to,No,Yes,Yes
11205,integer ammount of padding to put into LDS; in 2016 this didn't seem to help performance; profilers were showing that channel conflicts weren't really hurting,,,Yes
11206,performance so this has been deprecated and probably doesn't work,,,Yes
11208,ShiftPtr does not support very small problem dims < global load vector width since the shift,Yes,Yes,Yes
11211,both options were supported until a refactoring of the short-vector code (necessary to enable assembly) broke it. Since =True always seems to be faster; no time has been spend on fixing =False,Yes,Yes,Yes
11213,in opencl for some compilers; performance improved by putting a memfence after each subiteration; it prevented the loads of one subiteration from being moved,No,Yes,Yes
11214,+ Less VGPRS (32b offset vs 64-bit) needed for addressing,No,No,Yes
11223,add gls or slc after global memory read\/writes to change cacheing; not cacheing the writes is promising and improved performance a tiny bit,,,Yes
11224,ShiftPtr does not support very small problem dims < global load vector width since the shift,Yes,Yes,Yes
11225,would move outside the array bounds.,Yes,Yes,Yes
11226,how much info to print. 0=none; 1=standard; 2=verbose,,,Yes
11227,both options were supported until a refactoring of the short-vector code (necessary to enable assembly) broke it. Since =True always seems to be faster; no time has been spend on fixing =False,Yes,Yes,Yes
11228,FIXME =False worked before the vector refactor; fixing requires re-ordering load\/store indices; but they aren't the faster option so not worth time right now,,,Yes
11233,This can result in more efficient kernels; but requires runtime checking to ensure the specified,No,Yes,Yes
11234,wraps to next J.  TODO - might be useful to change this?,Yes,Yes,Yes
11236,Tensile will allocate additional VGPR in Global Store phase if needed to,,,Yes
11237,integer ammount of padding to put into LDS; in 2016 this didn't seem to help performance; profilers were showing that channel conflicts weren't really hurting,Yes,Yes,Yes
11239,add gls or slc after global memory read\/writes to change cacheing; not cacheing the writes is promising and improved performance a tiny bit,Yes,Yes,Yes
11240,ShiftPtr does not support very small problem dims < global load vector width since the shift,,,Yes
11241,would move outside the array bounds.,Yes,Yes,Yes
11242,TODO - not needed; but seems to help performance:,Yes,No,Yes
11243,bozo; move to appropriate spot,,,Yes
11244,It might be possible to fix globalWriteBatch to handle this case but these,,,Yes
11245,TODO - For GlobalSplitU; perhaps need to do this before the GSU workgroup assignment?  Or NumWorkGroups0,Yes,Yes,Yes
11248,TODO - not needed; but seems to help performance:,,,Yes
11250,"TODO: change to kStr += \""  COMPUTE_DATA_TYPE rC[TT%s*TT%s];%s\"" \\ % (self.tileChar0; self.tileChar1; self.endLine )",Yes,Yes,Yes
11254,TODO - For GlobalSplitU; perhaps need to do this before the GSU workgroup assignment?  Or NumWorkGroups0,,,Yes
11258,implement later generic,,,Yes
11261,Setup store config for number of sgpr and vgpr needed,No,Yes,Yes
11262,so will use VGPR from consec elements? TODO,,,Yes
11263,VGPR to use for element data; needed for atomic or beta,,,Yes
11264,implement wider stores,No,Yes,Yes
11265,TODO - someday make this a one-stop shop to also save the coord0 and coord1,,,Yes
11266,TODO - could tune these for store mode (BufferStore; edge; etc):,Yes,Yes,Yes
11268,implement wider stores,No,Yes,Yes
11269,Setup store config for number of sgpr and vgpr needed,No,Yes,Yes
11270,VGPR to use for element data; needed for atomic or beta,No,No,Yes
11271,TODO - someday make this a one-stop shop to also save the coord0 and coord1,,,Yes
11272,TODO - could tune these for store mode (BufferStore; edge; etc):,Yes,Yes,Yes
11275,implement wider stores,No,Yes,Yes
11276,Setup store config for number of sgpr and vgpr needed,No,Yes,Yes
11277,so will use VGPR from consec elements? TODO,,,Yes
11279,TODO - someday make this a one-stop shop to also save the coord0 and coord1,Yes,Yes,Yes
11280,implement wider stores,No,Yes,Yes
11281,"GEMM csv files contain \""LDD\"" \""LDC\"" \""LDA\"" \""LDB\"" columns",No,No,Yes
11282,might be able to refactor this to eliminate signed math,Yes,Yes,Yes
11283,TODO - fix for GSU; need LOCAL_DEPTHU*GSUp,Yes,Yes,Yes
11284,Change offset for subsequent dims (if needed),No,No,Yes
11285,might be able to refactor this to eliminate signed math,Yes,Yes,Yes
11287,one address for each element write; maybe should div vw?,Yes,Yes,Yes
11288,TODO - may generate extra inst at batch start,Yes,Yes,Yes
11289,TODO - review firstBatch; lastCoord; should be set in this function,Yes,Yes,Yes
11290,TODO; this is only needed for edge and eventually not there either,,,Yes
11291,coord0Vgpr : TODO,Yes,Yes,Yes
11292,TODO; do we need edge?,Yes,Yes,Yes
11294,TODO; this is only needed for edge and eventually not there either,Yes,Yes,Yes
11295,Move the row ptr,No,No,Yes
11298,TODO - might be able to eliminate this,Yes,Yes,Yes
11302,TODO - maybe this should be encapulated in the SS setup code,Yes,Yes,Yes
11303,TODO-packed - modify to ignore packed; perhaps:,Yes,Yes,Yes
11305,approx psuedocode; probably not quite right:,,,Yes
11306,TODO - for PreciseBoundsCheckStore we could set bounds on C to tile dim,Yes,Yes,Yes
11308,TODO - maybe this should be encapulated in the SS setup code,,,Yes
11312,TODO - might be able to eliminate this,Yes,Yes,Yes
11316,numElementsPerBatch=min(2;numElementsPerBatch) # hack to control number of batches,Yes,Yes,Yes
11317,hack to avoid re-using address vgpr across rows,Yes,Yes,Yes
11318,TODO - add in BPE here too,Yes,Yes,Yes
11321,TODO - change to use SetConstStrideB,Yes,No,Yes
11322,no unpacking from prev needed:,,,Yes
11323,-  The notation follows 'convolution' convention so fastest-moving dimensions are last;,,,Yes
11326,TODO; check?,Yes,Yes,Yes
11328,-  The notation follows 'convolution' convention so fastest-moving dimensions are last;,,,Yes
11329,since it reduces addressing overhead and will produce a more efficient kernel,No,No,Yes
11330,Default is 1; multiple dimensions will be created if needed for strides or otrher cases.,No,Yes,Yes
11334,cidx is first summation index; filter summations follow as needed,No,No,Yes
11336,spatial summations (if needed),,,Yes
11338,TODO - could modify this to support other problem types or optimizations,,,Yes
11341,TODO: will have to add all valid instruction combinations; for now add the type we're implementing,,,Yes
11343,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,,,Yes
11344,spatial summations (if needed),No,No,Yes
11345,debug flag to allocate dummy \/ unused sgpr,No,Yes,Yes
11349,TODO: Remove debug code when finished,,,Yes
11353,spatial summations (if needed),No,No,Yes
11355,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,Yes,Yes,Yes
11356,spatial summations (if needed),No,No,Yes
11357,debug flag to allocate dummy \/ unused sgpr,No,Yes,Yes
11359,debug flag to allocate dummy \/ unused sgpr,,,Yes
11361,TODO calc,Yes,No,Yes
11362,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,,,Yes
11363,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,Yes,Yes,Yes
11365,TODO calc,Yes,No,Yes
11367,TODO - remove this when logic files have been updated,Yes,Yes,Yes
11369,TODO - PackSummationDims handling needs to handle multiple sum dims,,,Yes
11370,TODO - refactor since only WG2 is supported and this is always batch,Yes,No,Yes
11371,TODO: Remove debug code when finished,Yes,No,Yes
11372,TODO Broadcast code,Yes,Yes,Yes
11374,TODO controls instruction tile shape; recalc if definition changes,,,Yes
11376,TODO StoreVectorWidth,,,Yes
11378,TODO Based on instruction size,Yes,Yes,Yes
11380,TODO; check),,,Yes
11381,TODO; check?,,,Yes
11382,TODO calc,,,Yes
11383,TODO probably fix for LDS,,,Yes
11387,spatial summations (if needed),No,No,Yes
11388,TODO calc,Yes,No,Yes
11390,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,Yes,Yes,Yes
11391,debug flag to allocate dummy \/ unused sgpr,,,Yes
11393,TODO - PackSummationDims handling needs to handle multiple sum dims,Yes,Yes,Yes
11394,TODO - refactor since only WG2 is supported and this is always batch,,,Yes
11395,If 1; summation dims are packed into a single loop and extracted as needed using mod\/shift.  The innermost summation,No,Yes,Yes
11396,If 1; summation dims are packed into a single loop and extracted as needed using mod\/shift.  The innermost summation,No,Yes,Yes
11397,TODO - could modify this to support other problem types or optimizations,Yes,Yes,Yes
11399,TODO: change back to 1,,,Yes
11401,TODO: Remove debug code when finished,Yes,No,Yes
11404,TODO controls instruction tile shape; recalc if definition changes,Yes,Yes,Yes
11406,TODO StoreVectorWidth,,,Yes
11407,TODO Currently only works for 32x32x1x2; revisit calc and element loop,,,Yes
11415,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,Yes,Yes,Yes
11421,TODO: change back to 1,Yes,No,Yes
11422,debug flag to allocate dummy \/ unused sgpr,No,Yes,Yes
11423,if we have multiple free strides - what is expected behavior?,No,Yes,Yes
11424,TODO - PackSummationDims handling needs to handle multiple sum dims,,,Yes
11426,TODO: Remove debug code when finished,Yes,No,Yes
11428,TODO controls instruction tile shape; recalc if definition changes,Yes,Yes,Yes
11429,TODO Based on instruction size,Yes,Yes,Yes
11430,TODO: Remove debug code when finished,,,Yes
11431,TODO Broadcast code,,,Yes
11432,TODO Fix for > tile,,,Yes
11433,TODO controls instruction tile shape; recalc if definition changes,Yes,Yes,Yes
11434,TODO 32???,Yes,No,Yes
11435,TODO StoreVectorWidth?,Yes,No,Yes
11436,TODO Currently only works for 32x32x1x2; revisit calc and element loop,Yes,Yes,Yes
11437,TODO Based on instruction size,,,Yes
11438,TODO; check),,,Yes
11440,"if (state[\""WorkGroup\""][0] * state[\""WorkGroup\""][1]) % (state[\""MatrixInstM\""] * state[\""InstSplit\""]) != 0: # TODO rejection for ABlocks",,,Yes
11442,TODO probably fix for LDS,Yes,No,Yes
11443,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,Yes,Yes,Yes
11445,spatial summations (if needed),,,Yes
11446,TODO StoreVectorWidth,,,Yes
11447,TODO Based on instruction size,,,Yes
11451,mulitple by 4 for row-starting id for each matrixN columns (static for mfma32\/mfma16),No,Yes,Yes
11454,TODO 4x4 MFMA requires fix,Yes,Yes,Yes
11455,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,,,Yes
11456,spatial summations (if needed),,,Yes
11457,debug flag to allocate dummy \/ unused sgpr,,,Yes
11458,if we have multiple free strides - what is expected behavior?,No,Yes,Yes
11459,TODO - PackSummationDims handling needs to handle multiple sum dims,Yes,Yes,Yes
11460,TODO - refactor since only WG2 is supported and this is always batch,,,Yes
11461,TODO: Remove debug code when finished,,,Yes
11462,TODO avoid s_nop if its possible,,,Yes
11464,TODO Fix for > tile,Yes,Yes,Yes
11470,TODO review below code,,,Yes
11471,TODO needs work on d1 mapping its not really  clean yet.  d1= holds B blocks and TT1\/vectorWdith column blocks,Yes,No,Yes
11473,TODO Currently only works for 32x32x1x2; revisit calc and element loop,Yes,Yes,Yes
11474,TODO 4x4 MFMA requires fix,Yes,Yes,Yes
11475,TODO; check),,,Yes
11479,TODO probably fix for LDS,Yes,No,Yes
11480,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,,,Yes
11483,TODO - PackSummationDims handling needs to handle multiple sum dims,Yes,Yes,Yes
11484,TODO - refactor since only WG2 is supported and this is always batch,,,Yes
11485,TODO ok for all tile sizes? change for bf16,,,Yes
11489,#TODO remove and use VectorWidth once VW mapping of TT is done,Yes,Yes,Yes
11490,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,Yes,Yes,Yes
11491,spatial summations (if needed),No,No,Yes
11492,Add AssertStride*Equal for PackBatchDims; if needed,No,Yes,Yes
11493,TODO; check?,,,Yes
11494,"if (state[\""WorkGroup\""][0] * state[\""WorkGroup\""][1]) % (state[\""MatrixInstM\""] * state[\""InstSplit\""]) != 0: # TODO rejection for ABlocks",Yes,No,Yes
11495,TODO calc,,,Yes
11496,TODO probably fix for LDS,,,Yes
11497,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,Yes,Yes,Yes
11502,TODO controls instruction tile shape; recalc if definition changes,Yes,Yes,Yes
11503,TODO 32???,,,Yes
11504,TODO fix-me for ldc!=ldd,,,Yes
11508,TODO needs work on d1 mapping its not really  clean yet.  d1= holds B blocks and TT1\/vectorWdith column blocks,Yes,No,Yes
11510,TODO Currently only works for 32x32x1x2; revisit calc and element loop,Yes,Yes,Yes
11515,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,Yes,Yes,Yes
11516,TODO; check),Yes,No,Yes
11519,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,Yes,Yes,Yes
11523,TODO; check?,Yes,Yes,Yes
11524,TODO - change to use SetConstStrideB,,,Yes
11525,TODO: change back to 1,,,Yes
11529,TODO Fix for > tile,,,Yes
11531,TODO 32???,,,Yes
11532,TODO fix-me for ldc!=ldd,Yes,Yes,Yes
11533,mulitple by 4 for row-starting id for each matrixN columns (static for mfma32\/mfma16),No,Yes,Yes
11538,TODO Currently only works for 32x32x1x2; revisit calc and element loop,Yes,Yes,Yes
11539,TODO 4x4 MFMA requires fix,,,Yes
11542,TODO Broadcast code,Yes,Yes,Yes
11544,TODO: Remove debug code when finished,Yes,No,Yes
11545,TODO avoid s_nop if its possible,,,Yes
11547,TODO Fix for > tile,,,Yes
11548,TODO controls instruction tile shape; recalc if definition changes,Yes,Yes,Yes
11550,TODO fix-me for ldc!=ldd,,,Yes
11551,mulitple by 4 for row-starting id for each matrixN columns (static for mfma32\/mfma16),,,Yes
11553,TODO review below code,Yes,Yes,Yes
11554,TODO needs work on d1 mapping its not really  clean yet.  d1= holds B blocks and TT1\/vectorWdith column blocks,Yes,No,Yes
11556,TODO Currently only works for 32x32x1x2; revisit calc and element loop,Yes,Yes,Yes
11557,TODO 4x4 MFMA requires fix,Yes,Yes,Yes
11559,TODO calc,,,Yes
11560,TODO probably fix for LDS,,,Yes
11563,It might be possible to fix globalWriteBatch to handle this case but these,,,Yes
11564,numElementsPerBatch=min(2;numElementsPerBatch) # hack to control number of batches,,,Yes
11566,TODO add fp16 hpa as well,,,Yes
11569,TODO:,,,Yes
11571,TODO: should return Code.Module or string?,,,Yes
11572,TODO add fp16 hpa as well,,,Yes
11573,TODO:,Yes,No,Yes
11574,TODO,Yes,Yes,Yes
11575,TODO: should return Code.Module or string?,,,Yes
11576,TODO add fp16 hpa as well,Yes,No,Yes
11578,TODO,,,Yes
11580,TODO check can hardcode or not,,,Yes
11583,TODO Broadcast code,Yes,Yes,Yes
11584,TODO Fix for > tile,,,Yes
11587,TODO fix-me for ldc!=ldd,,,Yes
11588,mulitple by 4 for row-starting id for each matrixN columns (static for mfma32\/mfma16),,,Yes
11591,TODO needs work on d1 mapping its not really  clean yet.  d1= holds B blocks and TT1\/vectorWdith column blocks,,,Yes
11593,TODO Currently only works for 32x32x1x2; revisit calc and element loop,,,Yes
11594,TODO 4x4 MFMA requires fix,,,Yes
11595,"if (state[\""WorkGroup\""][0] * state[\""WorkGroup\""][1]) % (state[\""MatrixInstM\""] * state[\""InstSplit\""]) != 0: # TODO rejection for ABlocks",Yes,No,Yes
11596,TODO calc,Yes,No,Yes
11598,TODO MI - SubGroup0 temporarily == MIWG0; revisit later,Yes,Yes,Yes
11600,TODO: should return Code.Module or string?,Yes,Yes,Yes
11601,TODO add fp16 hpa as well,,,Yes
11602,TODO:,Yes,No,Yes
11603,TODO,Yes,Yes,Yes
11604,TODO: should return Code.Module or string?,,,Yes
11606,TODO:,Yes,No,Yes
11607,TODO,Yes,Yes,Yes
11609,optimize if no initial stride needed in A or B,No,Yes,Yes
11610,cidx is first summation index; filter summations follow as needed,No,No,Yes
11611,- provides better cache locality for most formats; but tigher looping.,No,Yes,Yes
11612,TODO - stride setconst maybe applies only for NCHW\/CNHW format not NHWC,,,Yes
11614,Add AssertStride*Equal for PackBatchDims; if needed,No,Yes,Yes
11615,since it reduces addressing overhead and will produce a more efficient kernel,,,Yes
11617,which means tail loop not needed.,No,Yes,Yes
11619,note loop counter numIterK\/numIterL hard-coded; manually hack if needed,Yes,Yes,Yes
11620,TODO - remove this when NewClient is mainstream,Yes,Yes,Yes
11621,"state[\""TLUB\""] = True # hack",Yes,Yes,Yes
11622,TODO - use named arguments,Yes,Yes,Yes
11623,TODO - rewrite this function to simplify control-flow between tail-loop \/ unroll loop,,,Yes
11624,TODO - move to top of loop; ahead of address incs.,,,Yes
11625,TODO - remove; need to update scheduler,Yes,Yes,Yes
11626,"TODO - handle GSU inc here; pass sumChar + \""_GSURemainder\""",,,Yes
11627,TODO-64,Yes,No,Yes
11628,TODO - this skips over the stagger-u wrap codes,,,Yes
11629,TODO: remove me,,,Yes
11630,maybe need to restore base too if limit 0,Yes,No,Yes
11632,TODO - remove this when NewClient is mainstream,,,Yes
11639,TODO - use named arguments,,,Yes
11640,TODO - rewrite this function to simplify control-flow between tail-loop \/ unroll loop,Yes,No,Yes
11642,maybe need to restore base too if limit 0,Yes,No,Yes
11644,TODO: remove me,,,Yes
11646,maybe need to restore base too if limit 0,Yes,No,Yes
11650,TODO - this should be mul-H??,Yes,Yes,Yes
11653,TODO-64,Yes,No,Yes
11658,spatial summations (if needed),No,No,Yes
11659,Add AssertStride*Equal for PackBatchDims; if needed,No,Yes,Yes
11662,1. move to tail open loop,,,Yes
11663,FIXME  lrvw = 1 for all precision cases,Yes,No,Yes
11664,TODO - remove this when NewClient is mainstream,,,Yes
11665,since it reduces addressing overhead and will produce a more efficient kernel,,,Yes
11668,which means tail loop not needed.,No,Yes,Yes
11676,TODO - this skips over the stagger-u wrap codes,Yes,Yes,Yes
11679,need to fix beta-clear routine to pass initial stride parms,Yes,Yes,Yes
11680,optimize if no initial stride needed in A or B,No,Yes,Yes
11681,"state[\""TLUB\""] = True # hack",,,Yes
11682,Add AssertStride*Equal for PackBatchDims; if needed,,,Yes
11686,assert problemSizes.problems[i].stridesA == None # new stride functionality only supported on new client; not here,,,Yes
11689,FIXME-problem; this ignores strides:,Yes,Yes,Yes
11691,TODO: determine whether extra regs are needed by some newly defined ArchCap,Yes,Yes,Yes
11694,TODO  - detect and print message for common error n:32 w\/o space,Yes,Yes,Yes
11695,TODO - add strideB here,Yes,Yes,Yes
11697,FIXME-problem: refactor to eliminate max; pass strides in strideB parm rather than hacked,Yes,No,Yes
11698,padEndA is list of pad ends for A dimension in order of ZeroPadA list.,,,Yes
11699,FIXME remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11701,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,,,Yes
11703,FIXME re-verify lscaOffset=0,,,Yes
11704,TODO: determine whether extra regs are needed by some newly defined ArchCap,Yes,Yes,Yes
11706,FIXME clean-up comment section of assembly code,Yes,Yes,Yes
11707,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,,,Yes
11712,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,Yes,Yes,Yes
11713,FIXME,,,Yes
11714,FIXME re-verify lscaOffset=0,,,Yes
11716,FIXME remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11717,FIXME clean-up comment section of assembly code,,,Yes
11718,FIXME remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11719,FIXME clean-up comment section of assembly code,Yes,Yes,Yes
11722,FIXME re-verify lscaOffset=0,Yes,Yes,Yes
11723,FIXME  lrvw = 1 for all precision cases,Yes,No,Yes
11726,spatial summations (if needed),No,No,Yes
11728,TODO - add this to scalar offset not vector.,,,Yes
11729,TODO - what about packbatchdims?,,,Yes
11730,TODO - clean up here:,,,Yes
11734,TODO- pass strides here; remove calls to convertLeadingDims,Yes,Yes,Yes
11736,padEndA is list of pad ends for A dimension in order of ZeroPadA list.,,,Yes
11739,not supported with multiple summations; bug is maybe something with,Yes,Yes,Yes
11747,TODO clean-up comment section of assembly code,,,Yes
11749,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11750,TODO - clean up here:,,,Yes
11751,TODO - clean up here:,Yes,No,Yes
11752,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11755,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11756,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,Yes,Yes,Yes
11757,TODO re-verify lscaOffset=0,,,Yes
11758,will have Tensile::WARNING: RegisterPool::checkIn(XXX) but it was never checked out,Yes,Yes,Yes
11759,TODO,,,Yes
11760,TODO: reduce the use of 1 extra VGPR,,,Yes
11761,TODO,Yes,Yes,Yes
11762,TODO,Yes,Yes,Yes
11765,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11766,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,Yes,Yes,Yes
11767,TODO: should return Code.Module or string?,,,Yes
11768,TODO re-check,Yes,Yes,Yes
11769,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11770,TODO: reduce the use of 1 extra VGPR,,,Yes
11771,will have Tensile::WARNING: RegisterPool::checkIn(XXX) but it was never checked out,Yes,Yes,Yes
11772,TODO remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11774,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,Yes,Yes,Yes
11775,TODO: should return Code.Module or string?,Yes,Yes,Yes
11776,TODO re-check,,,Yes
11777,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11779,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11780,will have Tensile::WARNING: RegisterPool::checkIn(XXX) but it was never checked out,,,Yes
11781,TODO remove wave_offset start for global fetching  TransposeLDS,,,Yes
11783,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,,,Yes
11784,TODO: should return Code.Module or string?,Yes,Yes,Yes
11785,TODO re-check,Yes,Yes,Yes
11786,TODO re-verify lscaOffset=0,,,Yes
11790,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,,,Yes
11791,TODO re-check,Yes,Yes,Yes
11797,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11800,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11801,TODO remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11802,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11803,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,Yes,Yes,Yes
11804,TODO re-check,Yes,Yes,Yes
11805,TODO re-verify lscaOffset=0,Yes,Yes,Yes
11807,TODO remove wave_offset start for global fetching  TransposeLDS,Yes,Yes,Yes
11808,TODO clean-up comment section of assembly code,Yes,Yes,Yes
11810,TODO re-check,Yes,Yes,Yes
11811,TODO re-verify lscaOffset=0,,,Yes
11812,default; may be changed if needed to generate a valid kernel,No,No,Yes
11813,default; may be changed if needed to generate a valid kernel,No,No,Yes
11814,default; may be changed if needed to generate a valid kernel,No,No,Yes
11815,transposeLDS=1 no packing needed,,,Yes
11816,TODO need to break this if into multi if -else if - else,Yes,No,Yes
11818,default; may be changed if needed to generate a valid kernel,No,No,Yes
11819,TODO - remove when VectorStore=0 + PBD bug fixed,,,Yes
11821,TODO need to break this if into multi if -else if - else,,,Yes
11822,TODO: generalize over different MIs,,,Yes
11823,end TODO,,,Yes
11825,TODO: if numMfmaPerIter is not enough to schedule localwrite; need smarter way to distribute localWrite,Yes,Yes,Yes
11826,TODO: findNamedItem return Code.Module() if not found,,,Yes
11827,TODO: let all type have pack Module,Yes,Yes,Yes
11828,if it is empty (needed for clang++ assembler),No,Yes,Yes
11829,TODO: add some adds,,,Yes
11831,Original stagger register.  Only needed for Persistent,No,Yes,Yes
11834,TODO add fp16 hpa as well,Yes,No,Yes
11837,remainder; unused here,Yes,Yes,Yes
11838,remainder; unused here,Yes,Yes,Yes
11839,TODO remove wave_offset start for global fetching  TransposeLDS,,,Yes
11840,re-calculate tileA assignment  remove this once tileAssignmentB bug is fixed,,,Yes
11841,TODO Broadcast code,Yes,Yes,Yes
11843,TODO Fix for > tile,,,Yes
11844,TODO need to break this if into multi if -else if - else,,,Yes
11846,TODO review below code,Yes,Yes,Yes
11849,TODO calc,,,Yes
11851,TODO a bit tricky. Better to manage all GPRs solely through RegisterPool,Yes,No,Yes
11852,FIXME-ExactDict size descriptor still (but preferrably not so) uses 8-tuple for GEMM problems,,,Yes
11854,hack to avoid modifing local write address across rows to support shiftPtr in storeRemap,Yes,Yes,Yes
11858,"kStr += \""v_fma_f16 %s; %s; %s; %s%s\"" % (cStr; cStr; aStr; bStr; self.endLine) # FIXME op_sel",,,Yes
11861,64-bit C val move by 2 32-bit instructions,,,Yes
11863,See Common.py for more details; we pack the possible needed info in one value:,No,Yes,Yes
11865,TODO check if solution matches problem size for exact tile kernels,Yes,No,Yes
11866,jgolds HACK,Yes,Yes,Yes
11868,TODO: optimize scheduling to support more cases.,Yes,Yes,Yes
11869,TODO: use a function to return MatrixInstructionLatency,,,Yes
11871,TODO: make serialized store default with MI kernels,Yes,Yes,Yes
11876,4. How to design a better way to prevent from invalid kernel in rocBLAS?,No,Yes,Yes
11878,TODO: consider the rest of limiters ie sgpr,,,Yes
11879,TODO: Now in rocBLAS; lot of logic yamls are Type=NT and TLDS=1? Why aren't they rejected and how to get rid of them?,,,Yes
11880,TODO: Now in rocBLAS; lot of logic yamls are Type=NT and TLDS=1? Why aren't they rejected and how to get rid of them?,,,Yes
11882,TODO: consider the rest of limiters ie sgpr,,,Yes
11884,TODO: also consider sgpr,Yes,Yes,Yes
11885,TODO:,Yes,No,Yes
11886,TODO: consider the rest of limiters ie sgpr,Yes,Yes,Yes
11888,need to fix beta-clear routine to pass initial stride parms,,,Yes
11890,TODO:,,,Yes
11891,TODO:,Yes,No,Yes
11892,TODO: adopt component system,,,Yes
11893,vgpr needed from register pool,,,Yes
11894,TODO check if solution matches problem size for exact tile kernels,Yes,No,Yes
11895,TODO - handle vector-load,,,Yes
11903,vgpr needed from register pool,No,Yes,Yes
11907,TODO: adopt component system,,,Yes
11909,- MI 16x16x1x4 (4-block variant) with MIBlockM=4 -> (16x16)*(4x1)=64x16 tile per instruction executed,No,Yes,Yes
11913,TODO: adopt component system,,,Yes
11914,TODO - handle vector-load,Yes,Yes,Yes
11916,TODO:,,,Yes
11917,TODO: consider the rest of limiters ie sgpr,Yes,Yes,Yes
11919,TODO: break lobalReadIncCode,,,Yes
11922,"and ((state[\""LSC%c\""%tc] * numBytes) != (state[\""NumThreads\""] * 4)): \/\/ TODO:",Yes,Yes,Yes
11925,TODO: globalReadInc scheduling should not be blocked by localWriteInst,Yes,Yes,Yes
11926,we will add s_nop if needed,,,Yes
11929,during isPap; this is actually no needed; so we can skip this.,Yes,Yes,Yes
11934,TODO - AlongBatch not support GSU in HIP now,Yes,No,Yes
11936,avoid bug somehow related to GlobalSplitU + Persistent,Yes,No,Yes
11937,avoid bug somehow related to HPA + Persistent,,,Yes
11938,1. during isPap; this is actually no needed; so we can skip this.,Yes,Yes,Yes
11940,"kStr += inst(\""s_mov_b32\""; sgpr(\""PersistentLoopIter\""); 0; \""init PersistentKernelLoop Iter\"")  # Back-up: not needed now",,,Yes
11943,TODO - AlongBatch not support GSU in HIP now,Yes,No,Yes
11944,avoid bug somehow related to HPA + Persistent,Yes,Yes,Yes
11945,"self.defineSgpr(\""PersistentLoopIter\""; 1) # Back-up: The count of current persistent loop; not needed now",,,Yes
11946,"kStr += inst(\""s_mov_b32\""; sgpr(\""PersistentLoopIter\""); 0; \""init PersistentKernelLoop Iter\"")  # Back-up: not needed now",,,Yes
11947,"kStr += inst(\""s_add_u32\""; sgpr(\""PersistentLoopIter\""); sgpr(\""PersistentLoopIter\""); hex(1); \""Inc PersistentLoop Iter\"")   # Back-up: not needed now",,,Yes
11948,TODO: Instead of using input DataType check we should have an explicit AlphaType,,,Yes
11951,"and ((state[\""LSC%c\""%tc] * numBytes) != (state[\""NumThreads\""] * 4)): \/\/ TODO:",,,Yes
11953,"and ((state[\""LSC%c\""%tc] * numBytes) != (state[\""NumThreads\""] * 4)): \/\/ TODO:",,,Yes
11955,TODO future gemm size could include dictionary format so need robust preprocessing,,,Yes
11956,TODO this is slow,Yes,Yes,Yes
11962,0 sizes added; 0 kernels added; 1 kernel removed because it's unused,,,Yes
11964,TODO: latency: 40 quad-cycle for 4 word; 22 quad-cycle for 2 word; 10 quad-cycle for 1 word,,,Yes
11965,TODO: let all type have pack Module,,,Yes
11967,TODO- check (H;H;H;H;S;S),Yes,No,Yes
11968,Target: to avoid some hack-code\/workaround\/ambiguous code,,,Yes
11969,It's better to make them explict,Yes,Yes,Yes
11974,TODO: Instead of using input DataType check we should have an explicit AlphaType,Yes,Yes,Yes
11977,TODO- check (H;H;H;H;S;S),Yes,No,Yes
11981,TODO- check (H;H;H;H;S;S),,,Yes
11982,Target: to avoid some hack-code\/workaround\/ambiguous code,Yes,No,Yes
11983,It's better to make them explict,,,Yes
11989,TODO Do away with this workaround. TensileCreateLibrary.py should take function arguments and return values directly,Yes,Yes,Yes
11990,TODO fix TensileCreateLibrary build configs:,,,Yes
11991,TODO: latency: 40 quad-cycle for 4 word; 22 quad-cycle for 2 word; 10 quad-cycle for 1 word,,,Yes
11992,TODO: let all type have pack Module,,,Yes
11993,TODO schedule waitcnt\/barrier in makeSubIterSchedule(),Yes,No,Yes
11994,TODO ANT: remove SGPR NumRemainderSumElements,,,Yes
11995,still needed for vgpr resource management,,,Yes
11996,TODO: If DepthULdsDivisor>1; local read addr is incremented for each K the loop iterates; which,Yes,Yes,Yes
11997,TODO schedule waitcnt\/barrier in makeSubIterSchedule(),Yes,No,Yes
11998,TODO- We use a temp Sgpr to track this?,Yes,Yes,Yes
11999,Back-up: not needed now,Yes,No,Yes
12000,case 4: after Ord.NLL (with Beta); cnt = no needed for vmcnt,No,No,Yes
12001,"kStr += inst(\""s_mov_b32\""; sgpr(\""PersistentLoopIter\""); 0; \""init PersistentKernelLoop Iter\"")  # Back-up: not needed now",No,Yes,Yes
12002,Back-up: not needed now,,,Yes
12004,TODO- fix this; avoid the bug for now,Yes,Yes,Yes
12006,TODO: No code for -1 ?,Yes,No,Yes
12007,TODO- Need to query the max cap; just like vmcnt as well?,Yes,No,Yes
12010,r = 1;3;   shift needed,,,Yes
12011,TODO: is it possible to load only hi16 when no in tail? (need to check INT8 too),Yes,No,Yes
12016,FIXME,Yes,Yes,Yes
12017,Note - TODO- CheckStoreC also won't work for StoreRemap,Yes,Yes,Yes
12019,TODO- do we need to support PGR2 ?,Yes,Yes,Yes
12020,TODO- Need this restrict ?,Yes,Yes,Yes
12022,"TODO- Why need to x2 ? Why not (if state[\""PrefetchLocalRead\""] >= state[\""LoopIters\""]:)",Yes,Yes,Yes
12023,TODO - use the list of gfx entries returned as targets directly,,,Yes
12026,debug flag to allocate dummy \/ unused sgpr,No,Yes,Yes
12028,TODO this combo doens't work,Yes,No,Yes
12029,if it is empty (needed for clang++ assembler),No,Yes,Yes
12030,unused,Yes,No,Yes
12031,TODO- to support non-pow2; need to use mul_32 and mul_hi_32 ?,Yes,No,Yes
12032,TODO - Check if this works. But need this? MFMA would use INT8,,,Yes
12033,TODO Remove this when rocm-smi supports gfx90a,Yes,Yes,Yes
12035,Identify the returned value and get a node for it if needed,,,Yes
12036,Move the literal structures to to_inline,,,Yes
12037,Move contents of to_inline to ready,No,Yes,Yes
12038,"Move contents of \""to_inline\"" to \""ready\""",,,Yes
12039,Let go of variables that aren't needed anymore so as to reduce memory usage,,,Yes
12041,unused,Yes,No,Yes
12042,unused,Yes,No,Yes
12043,unused,,,Yes
12044,TODO lift code from here to task_util for xfgs.,Yes,No,Yes
12045,robust in cases where setup.py was invoked in some weird way (e.g. pip),No,No,Yes
12046,searchspace.add_XXX can throw a ValueError on malformed,,,Yes
12050,delay import of the rest of the module to improve `osprey -h` performance,,,Yes
12051,delay import of the rest of the module to improve `osprey -h` performance,No,Yes,Yes
12052,configurable,,,Yes
12053,bunch of fixed fields that hyperopt seems to require,,,Yes
12054,force flake8 not to complain about unused import,,,Yes
12056,delay import of the rest of the module to improve `osprey -h` performance,Yes,Yes,Yes
12058,maybe improved later,,,Yes
12059,TODO: Presumably GPy check has already been done here,,,Yes
12060,# TODO check if Import checking for GPy has been done.,Yes,No,Yes
12061,TODO there must be a better place to put all this.,Yes,Yes,Yes
12062,TODO Could use options dict to specify what type of kernel to create when,Yes,Yes,Yes
12064,TODO Catch errors here?  Estimator entry points don't catch instantiation errors,,,Yes
12066,TODO use eval to allow user to specify internal variables for kernels (e.g. V) in config file.,,,Yes
12067,TODO Catch errors here?  Estimator entry points don't catch instantiation errors,Yes,Yes,Yes
12068,TODO start minimization from a range of points and take minimum,Yes,Yes,Yes
12069,TODO make spread of points around x and take mean value.,Yes,Yes,Yes
12070,However; we want to recover the original functionality of Osprey; hence the conditional block.,,,Yes
12071,TODO use eval to allow user to specify internal variables for kernels (e.g. V) in config file.,,,Yes
12072,TODO Catch errors here?  Estimator entry points don't catch instantiation errors,,,Yes
12073,TODO make spread of points around x and take mean value.,Yes,Yes,Yes
12074,However; we want to recover the original functionality of Osprey; hence the conditional block.,,,Yes
12078,TODO length should be n_trials.  But this doesn't seem to be accessible to strategies without major re-write.,,,Yes
12080,TODO this should be a method common to both Sobol and GP.,Yes,Yes,Yes
12084,TODO length should be n_trials.  But this doesn't seem to be accessible to strategies without major re-write.,Yes,Yes,Yes
12086,TODO this should be a method common to both Sobol and GP.,,,Yes
12087,TODO use eval to allow user to specify internal variables for kernels (e.g. V) in config file.,,,Yes
12088,TODO Catch errors here?  Estimator entry points don't catch instantiation errors,Yes,Yes,Yes
12092,TODO make this come from Sobol sequences class,Yes,Yes,Yes
12093,TODO make spread of points around x and take mean value.,,,Yes
12096,hack to get the case where there's only a single choice.,Yes,Yes,Yes
12099,TODO Make all of these sklearn estimators,,,Yes
12100,TODO make this a variable.,Yes,Yes,Yes
12101,TODO check whether this is actually needed.,,,Yes
12105,However; we want to recover the original functionality of Osprey; hence the conditional block.,,,Yes
12106,# TODO length should be n_trials.  But this doesn't seem to be accessible to strategies without major re-write.,Yes,Yes,Yes
12109,TODO Why does this work when other msmbuilder imports don't?,,,Yes
12112,TODO: Check correctness of maxdepth,Yes,Yes,Yes
12114,TODO: This is kind of bad,,,Yes
12115,TODO: Should probably make this a loop,Yes,No,Yes
12116,TODO: Many-to-one,,,Yes
12120,"\""\""\"" Implement the CNN-based acoustic model of Zhang et al. 2017 ||     'Towards End-to-End Speech Recognition with Deep Convolutional Neural ||     Networks'. || \""\""\""",,,Yes
12121,Perhaps these should just be errors. Print statements might just be,Yes,Yes,Yes
12122,TODO change to indices_to_chars,Yes,Yes,Yes
12124,TODO These dimensions shouldn't be hardcoded.,Yes,Yes,Yes
12125,TODO Make more general,,,Yes
12126,TODO Currently just moves the conversational transcripts Antonis,,,Yes
12130,"TODO rename this to \""tokens2indices\"" or something similar.",,,Yes
12131,"TODO Change to \""PHONEMES\""?",Yes,Yes,Yes
12132,TODO Make prefixes not include the path ..\/data\/na\/wav\/. But note,Yes,Yes,Yes
12133,TODO To make this not 'wav'; but 'feats' I either need to move the manually,,,Yes
12136,TODO Get rid of this.,Yes,Yes,Yes
12141,TODO This could be a sign that it might just be best to use Kaldi for,Yes,Yes,Yes
12143,made fbank+pitch feats from wav to feats; or better; automate the whole,No,Yes,Yes
12144,"TODO eventually remove \""new\"" when ALTA experiments are finished.",,,Yes
12145,TODO This assumption no longer holds,,,Yes
12150,TODO Use 'labels' instead of 'phonemes' here and in corpus.py,Yes,Yes,Yes
12151,TODO Consider factoring out as non-Na specific,,,Yes
12154,TODO This sorting is Na-corpus centric and won't generalize. It,,,Yes
12155,Note that I'm shuffling after sorting; this could be better.,,,Yes
12156,data; perhaps by using the orthographic form and lowercasing.,,,Yes
12157,TODO Could probably be factored out; there's nothing so corpus-specific,,,Yes
12161,"TODO Remove explicit reference to \""fbank\""",,,Yes
12163,Filter out prefixes that have no transcription. It's probably better,,,Yes
12164,TODO Tell the user what utterances we are removing.,,,Yes
12166,TODO Na-specific stuff commented out for work on Chatino,Yes,Yes,Yes
12170,TODO Note that I'm shuffling after sorting; this could be better.,Yes,Yes,Yes
12171,"TODO Remove explicit reference to \""fbank\""",,,Yes
12172,Sort the training prefixes by size for more efficient training,No,Yes,Yes
12173,TODO Should be in the abstract corpus. It's common to all corpora but,Yes,No,Yes
12174,it needs to be set after self.labels. Perhaps I should use a label,No,Yes,Yes
12175,TODO These ratios can't be hardcoded,Yes,Yes,Yes
12177,TODO Could probably be factored out; there's nothing so corpus-specific,Yes,Yes,Yes
12179,"TODO Remove explicit reference to \""fbank\""",Yes,Yes,Yes
12181,TODO Assumes 10ms strides for the frames. This should generalize to,Yes,Yes,Yes
12182,Only one media_path file is needed; as long as it exists.,No,Yes,Yes
12183,TODO desperately needs refactoring,,,Yes
12184,TODO Could probably be factored out; there's nothing so corpus-specific,Yes,Yes,Yes
12187,TODO These ratios can't be hardcoded,Yes,Yes,Yes
12188,Sort the training prefixes by size for more efficient training,,,Yes
12189,TODO Should be in the abstract corpus. It's common to all corpora but,Yes,No,Yes
12191,TODO Figure out how to interface with untranscribed files.,Yes,Yes,Yes
12192,TODO Note that I'm shuffling after sorting; this could be better.,,,Yes
12195,Sort the training prefixes by size for more efficient training,No,Yes,Yes
12196,TODO Should be in the abstract corpus. It's common to all corpora but,,,Yes
12198,TODO Figure out how to interface with untranscribed files.,Yes,Yes,Yes
12199,TODO Assumes 10ms strides for the frames. This should generalize to,Yes,Yes,Yes
12201,TODO: fix these stubs,Yes,Yes,Yes
12204,TODO Surely filtering by size should be done by the corpus reader?,Yes,No,Yes
12206,results. Probably should expect < 20% LER.,No,Yes,Yes
12208,TODO assert the contents of the prefix files,Yes,Yes,Yes
12209,TODO Assert that we've filtered files with too many frames,,,Yes
12211,TODO This will break because of undefined variables.,,,Yes
12212,TODO This is going to break,,,Yes
12213,TODO This needs to be uniform throughout the package and have a single point,,,Yes
12215,TODO Assert that we've filtered files with too many frames,,,Yes
12217,replace with pydub TODO,Yes,Yes,Yes
12224,TODO log this as a warning,Yes,No,Yes
12225,TODO Make this an actual warning or do some sort of exception,,,Yes
12226,Read utterances from tgt_dir\/elan\/. Perhaps an org_dir for elan,,,Yes
12227,constructor; or should it somehow be rolled into the segmenter? Could,,,Yes
12228,Only one media_path file is needed; as long as it exists.,No,Yes,Yes
12229,TODO Make this an actual warning or do some sort of exception,Yes,Yes,Yes
12230,TODO potential bug if tier_prefixes has prefixes that are common to a,,,Yes
12231,TODO Change this to being paths everywhere,,,Yes
12233,TODO add logging here,Yes,No,Yes
12237,TODO Return pathlib.Paths,Yes,Yes,Yes
12238,TODO Use logging here,Yes,No,Yes
12241,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
12242,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
12244,TODO This download should be conditional; since a complaint is raised if,Yes,Yes,Yes
12245,TODO bkw.Corpus and elan.Corpus should take an org_dir argument.,Yes,Yes,Yes
12246,TODO Need to contemplate whether Corpus objects have Utterance,Yes,No,Yes
12250,TODO Review documentation and consider for inclusion in API.,,,Yes
12256,TODO Make this fbank_and_pitch; but then I need to install kaldi on ray,Yes,Yes,Yes
12258,TODO Change the second argument to have some upper bound. If the caller,Yes,Yes,Yes
12259,TODO Delete these; because they're not meant to be class variables.,,,Yes
12261,needs to change. They shouldn't really be instance variables either.,,,Yes
12267,TODO Delete these; because they're not meant to be class variables.,,,Yes
12268,TODO Delete these; because they're not meant to be class variables.,,,Yes
12271,TODO Change to pathlib.Path,Yes,Yes,Yes
12272,TODO Change the second argument to have some upper bound. If the caller,,,Yes
12273,TODO: write prefix files,Yes,No,Yes
12277,TODO: https:\/\/en.wikipedia.org\/wiki\/Types_of_business_entity,Yes,No,Yes
12278,TODO: Instead of using center_location and coord_system; should pass in a Transform3d,,,Yes
12280,TODO: Parse bounding box 2d,,,Yes
12281,TODO: Need to handle the randomized FOV in different frame,Yes,Yes,Yes
12282,TODO: For some reason the qx; qy; qz part of the quaternion must be flipped,Yes,Yes,Yes
12284,TODO: May just want to use the Transform3d class,,,Yes
12285,TODO: Build the transform matrix to convert from OpenCV to this coordinate system,,,Yes
12287,TODO: Need to invert the CameraToWorld matrix => WorldToCamera matrix,Yes,Yes,Yes
12289,TODO: Should merge Cuboid and Box3d,Yes,No,Yes
12292,TODO: Create a new viz object to handle the text overlay,,,Yes
12295,TODO: Should ignore? if the visualized frame already exist,,,Yes
12296,TODO: May need to add config to control the viz postfix,,,Yes
12297,TODO: May need to derive from SceneObject,Yes,Yes,Yes
12298,TODO: Sort the 3d objects in the scene from back to front (Z reducing),Yes,No,Yes
12301,TODO: Check if this is a problem if it happens before standardization,,,Yes
12302,FIXME: can I backprop error through both,,,Yes
12307,# FIXME: need better method:,Yes,No,Yes
12316,# FIXME: how to show merged weights?,Yes,No,Yes
12317,# FIXME: add these:,Yes,No,Yes
12318,## FIXME: should visualize this all the way through,Yes,No,Yes
12319,# FIXME: grabbing a couple of dimensions,Yes,Yes,Yes
12323,# FIXME: this probably isn't going to work with multi-outputs.,,,Yes
12329,# FIXME: allow working on multi-targets,,,Yes
12330,# FIXME: allow human format of inputs; if given,Yes,No,Yes
12331,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
12332,FIXME: multi outputs?,,,Yes
12333,FIXME: use output layers' minmax,Yes,No,Yes
12334,# takes too long to load; unless really needed,,,Yes
12336,# FIXME: add these for users' convenience:,Yes,No,Yes
12337,# FIXME: iwidth hack,Yes,No,Yes
12339,# Better be in correct format!,No,No,Yes
12340,# FIXME: add these for users' convenience:,Yes,No,Yes
12342,# FIXME: allow working on multi inputs,,,Yes
12343,# FIXME: allow working on multi-targets,Yes,No,Yes
12347,# FIXME: add new dataset-based checks:,,,Yes
12351,# FIXME: work on multi-input banks,,,Yes
12352,# FIXME: matrix is offset... add some values to attempt to centered it:,,,Yes
12353,# IS THIS A BETTER WAY?:,No,No,Yes
12355,# FIXME: this should be an explicit list of,,,Yes
12356,FIXME: why is input_layer even an argument here; since,,,Yes
12357,added a colorbar. FIXME: ideally; maximum red should always map to,Yes,Yes,Yes
12358,FIXME: this should be a straight path between incoming and outgoing,Yes,No,Yes
12362,# FIXME: may not be able to reshape; dynamically changing output,Yes,Yes,Yes
12363,FIXME: need a better way to set the figure size,,,Yes
12367,# FIXME: this should be an explicit list of,Yes,No,Yes
12369,<---FIXME: will this work if multiple banks?,Yes,No,Yes
12371,# FIXME: verify this:,Yes,No,Yes
12372,# FIXME: the appropriate inputs:,,,Yes
12374,# FIXME: check to make sure it is matches,Yes,Yes,Yes
12376,# FIXME: and same,Yes,No,Yes
12377,# needed to get 3d projection:,No,Yes,Yes
12378,# FIXME: set minmx of layers based on previous output layer's activations,Yes,Yes,Yes
12379,## elif (): ## FIXME: handle other bases here,Yes,Yes,Yes
12380,number of columns:,,,Yes
12381,# FIXME: can be multiple paths,Yes,No,Yes
12383,# FIXME: make more general; and set targets to [None; None; ...],,,Yes
12384,# first; find the set to skip over; if needed:,No,No,Yes
12388,# FIXME: this good; sample more; or get stats from all?,Yes,Yes,Yes
12389,# FIXME: at least one is mis-labeled:,Yes,No,Yes
12390,# M move to,No,No,Yes
12392,# FIXME: percentage of space between; FIXME: rotated,Yes,Yes,Yes
12393,# FIXME: any other virtual functions that should get a datavector warning?,Yes,Yes,Yes
12395,# FIXME: don't forget about error\/loss functions on other layers,Yes,No,Yes
12398,# FIXME: this should do it in the proper backend,Yes,No,Yes
12400,Make the seed meet C-style naming convention,,,Yes
12402,A operator has an output; so we remove the operator from the unused-operator list.,,,Yes
12403,Scan through all operators and adjust their variables' shapes if needed,,,Yes
12405,Remove unused operators,,,Yes
12406,Remove unused variables,,,Yes
12408,Check output naming convention,Yes,Yes,Yes
12409,TODO: Add some operator fusions here.,Yes,Yes,Yes
12410,ends at T' and T' is not linked,,,Yes
12411,Handle initial cell state if needed,No,Yes,Yes
12413,Initialize materials needed to create ONNX LSTM,No,No,Yes
12414,TODO: Changing input shapes of an operator is dangerous; this should be move to Topology's _fix_shapes function,,,Yes
12415,TODO: Changing input shapes of an operator is dangerous; this should be move to Topology's _fix_shapes function,Yes,Yes,Yes
12417,[TODO] Fix reduce-like shape inference. We now assume all inputs are 4-D.,,,Yes
12418,Adjust batch size if needed,,,Yes
12419,Add bias vectors at different places in the original LSTM if needed,No,Yes,Yes
12420,The output shape of runtime is 3-D while ONNX says 4-D; so we do a Reshape to fix it.,,,Yes
12421,workaround for resahpe in ONNX 1.2 not supporting INT64,,,Yes
12425,TODO: extract this piece of code to be a common method.,,,Yes
12428,No concatenation is needed; we just use the first variable's name,No,Yes,Yes
12429,is this really useful is M is specified?,,,Yes
12430,Collect input variable names and do cast if needed,,,Yes
12431,TODO: onnxruntime can't support batch_size > 1,Yes,No,Yes
12432,The other vector is (N; 2) score in two columns.,No,Yes,Yes
12433,Make the seed meet C-style naming convention,Yes,Yes,Yes
12435,A operator has an output; so we remove the operator from the unused-operator list.,,,Yes
12437,We fix this problem here.,Yes,Yes,Yes
12438,Remove unused operators,,,Yes
12440,Check input naming convention,,,Yes
12442,No concatenation is needed; we just use the first variable's name,,,Yes
12443,is this really useful is M is specified?,,,Yes
12446,unused here but in dump_data_and_model,,,Yes
12448,the most efficient way to compute the prediction.,No,No,Yes
12449,Predictions are more efficient if the graph is small.,No,No,Yes
12450,That's why the converter checks that there is no unused input.,No,No,Yes
12451,must be applied on columns of the same type.,No,No,Yes
12452,We need to remove the dropped columns and to change,,,Yes
12455,Unused inputs,Yes,No,Yes
12457,"\""\""\"" || .. _example-lightgbm: ||  || Convert a pipeline with a LightGbm model || ======================================== ||  || *sklearn-onnx* only converts *scikit-learn* models into *ONNX* || but many libraries implement *scikit-learn* API so that their models || can be included in a *scikit-learn* pipeline. This example considers || a pipeline including a *LightGbm* model. *sklearn-onnx* can convert || the whole pipeline as long as it knows the converter associated to || a *LGBMClassifier*. Let's see how to do it. ||  || A couple of errors might happen while trying to convert || your own pipeline; some of them are described || and explained in :ref:`errors-pipeline`. ||  || .. contents:: ||     :local: ||  || Train a LightGBM classifier || +++++++++++++++++++++++++++ || \""\""\""",,,Yes
12458,the default behviour is to merge columns.,No,Yes,Yes
12461,must be applied on columns of the same type.,,,Yes
12462,We need to remove the dropped columns and to change,,,Yes
12465,construct object dtype array with two columns,,,Yes
12467,if needed,No,No,Yes
12469,TODO: handle this case with an algorithm,,,Yes
12470,needed to *replay* the prediction of the model.,No,Yes,Yes
12471,"\""\""\"" || .. _l-convert-syntax: ||  || Different ways to convert a model || ================================= ||  || This example leverages some code added to implement custom converters || in an easy way. ||  || .. contents:: ||     :local: ||  || Predict with onnxruntime || ++++++++++++++++++++++++ ||  || Simple function to check the converted model || works fine. || \""\""\""",,,Yes
12473,The new differences look much better.,No,No,Yes
12474,It looks good. Let's do a better checks.,,,Yes
12475,This should not be needed.,Yes,Yes,Yes
12476,onnxruntime does not implement a specific node yet.,Yes,No,Yes
12478,"\""\""\"" || .. _example-xgboost: ||  || Convert a pipeline with a XGBoost model || ======================================== ||  || .. index:: XGBoost ||  || *sklearn-onnx* only converts *scikit-learn* models into *ONNX* || but many libraries implement *scikit-learn* API so that their models || can be included in a *scikit-learn* pipeline. This example considers || a pipeline including a *XGBoost* model. *sklearn-onnx* can convert || the whole pipeline as long as it knows the converter associated to || a *XGBClassifier*. Let's see how to do it. ||  || A couple of errors might happen while trying to convert || your own pipeline; some of them are described || and explained in :ref:`errors-pipeline`. ||  || .. contents:: ||     :local: ||  || Train a XGBoost classifier || ++++++++++++++++++++++++++ || \""\""\""",,,Yes
12479,fix opset import,,,Yes
12480,fix opset import,,,Yes
12483,HistGradientBoostingRegressor does not implement decision_path.,No,No,Yes
12486,It is just better to use strings.,No,No,Yes
12489,It works too in a more simple way.,No,No,Yes
12490,"\""\""\"" || Intermediate results and investigation || ====================================== ||  || .. index:: investigate; intermediate results ||  || There are many reasons why a user wants more than using || the converted model into ONNX. Intermediate results may be || needed; the output of every node in the graph. The ONNX || may need to be altered to remove some nodes. || Transfer learning is usually removing the last layers of || a deep neural network. Another reaason is debugging. || It often happens that the runtime fails to compute the predictions || due to a shape mismatch. Then it is useful the get the shape || of every intermediate result. This example looks into two || ways of doing it. ||  || .. contents:: ||     :local: ||  || Look into pipeline steps || ++++++++++++++++++++++++ ||  || The first way is a tricky one: it overloads || methods *transform*; *predict* and *predict_proba* || to keep a copy of inputs and outputs. It then goes || through every step of the pipeline. If the pipeline || has *n* steps; it converts the pipeline with step 1; || then the pipeline with steps 1; 2; then 1; 2; 3... || \""\""\""",,,Yes
12491,This way is usually better if you need to investigate,,,Yes
12492,A dataframe can be seen as a set of columns with,No,Yes,Yes
12493,"\""\""\"" || .. _example-lightgbm: ||  || Convert a pipeline with a LightGBM model || ======================================== ||  || .. index:: LightGBM ||  || :epkg:`sklearn-onnx` only converts :epkg:`scikit-learn` models into *ONNX* || but many libraries implement :epkg:`scikit-learn` API so that their models || can be included in a :epkg:`scikit-learn` pipeline. This example considers || a pipeline including a :epkg:`LightGBM` model. :epkg:`sklearn-onnx` can convert || the whole pipeline as long as it knows the converter associated to || a *LGBMClassifier*. Let's see how to do it. ||  || .. contents:: ||     :local: ||  || Train a LightGBM classifier || +++++++++++++++++++++++++++ || \""\""\""",No,No,Yes
12494,"\""\""\"" || .. _example-xgboost: ||  || Convert a pipeline with a XGBoost model || ======================================== ||  || .. index:: XGBoost ||  || :epkg:`sklearn-onnx` only converts :epkg:`scikit-learn` models || into :epkg:`ONNX` but many libraries implement :epkg:`scikit-learn` || API so that their models can be included in a :epkg:`scikit-learn` || pipeline. This example considers a pipeline including a :epkg:`XGBoost` || model. :epkg:`sklearn-onnx` can convert the whole pipeline as long as || it knows the converter associated to a *XGBClassifier*. Let's see || how to do it. ||  || .. contents:: ||     :local: ||  || Train a XGBoost classifier || ++++++++++++++++++++++++++ || \""\""\""",,,Yes
12495,to *DecorrelateTransformer*. Let's implement it.,,,Yes
12497,"\""\""\"" || Two ways to implement a converter || ================================= ||  || .. index:: syntax ||  || There are two ways to write a converter. The first one || is very verbose (see `ada_boost.py <https:\/\/github.com\/onnx\/ || sklearn-onnx\/blob\/master\/skl2onnx\/operator_converters\/ada_boost.py>`_ || for an example). The other is less verbose and easier to understand || (see `k_means.py <https:\/\/github.com\/onnx\/sklearn-onnx\/blob\/ || master\/skl2onnx\/operator_converters\/k_means.py>`_). ||  || The first way is used in :ref:`l-plot-custom-converter`. || This one demonstrates the second way which is usually the one || used in other converter library. It is more verbose. ||  || .. contents:: ||     :local: ||  ||  || Custom model || ++++++++++++ ||  || It basically copies what is in example || `:ref:`l-plot-custom-converter`. || \""\""\""",,,Yes
12506,the probabilities into columns. The final model produces,No,Yes,Yes
12507,fix opset import,,,Yes
12511,TODO Add additional points,,,Yes
12512,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || TODO: || - Address approx vs exact issue || - Generalize to arbitrary number of outputs || \""\""\""",,,Yes
12514,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || TODO: || - Address approx vs exact issue || - Generalize to arbitrary number of outputs || \""\""\""",,,Yes
12516,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || Random sampling. || \""\""\""",,,Yes
12517,A C1 extrapolation can get very tricky; so we implement a simple C0,,,Yes
12518,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || Cantilever beam problem from: || Liu; H.; Xu; S.; & Wang; X. Sampling strategies and metamodeling techniques for engineering design: comparison and application. In ASME Turbo Expo 2016: Turbomachinery Technical Conference and Exposition. American Society of Mechanical Engineers. June; 2016. || Cheng; G. H.; Younis; A.; Hajikolaei; K. H.; and Wang; G. G. Trust Region Based Mode Pursuing Sampling Method for Global Optimization of High Dimensional Design Problems. Journal of Mechanical Design; 137(2). 2015. || \""\""\""",,,Yes
12519,"\""\""\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||         Dr. John T. Hwang         <hwangjt@umich.edu> ||  || Water flow problem from: || Liu; H.; Xu; S.; & Wang; X. Sampling strategies and metamodeling techniques for engineering design: comparison and application. In ASME Turbo Expo 2016: Turbomachinery Technical Conference and Exposition. American Society of Mechanical Engineers. June; 2016. || Morris; M. D.; Mitchell; T. J.; and Ylvisaker; D. Bayesian Design and Analysis of Computer Experiments: Use of Derivatives in Surface Prediction. Technometrics; 35(3); pp. 243-255. 1993. || \""\""\""",,,Yes
12520,"\""\""\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||         Dr. John T. Hwang         <hwangjt@umich.edu> ||  || Welded beam problem from: || Liu; H.; Xu; S.; & Wang; X. Sampling strategies and metamodeling techniques for engineering design: comparison and application. In ASME Turbo Expo 2016: Turbomachinery Technical Conference and Exposition. American Society of Mechanical Engineers. June; 2016. || Deb; K. An Efficient Constraint Handling Method for Genetic Algorithms. Computer methods in applied mechanics and engineering; 186(2); pp. 311-338. 2000. || \""\""\""",,,Yes
12521,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || Reduced problem class - selects a subset of input variables. || \""\""\""",No,Yes,Yes
12524,"\""\""\"" || Author: Dr. John T. Hwang <hwangjt@umich.edu> ||  || N-dimensional Rosenbrock problem. || \""\""\""",No,Yes,Yes
12531,TODO: s_a is not used here. In addition; double-check this function!,,,Yes
12533,"\""\""\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||  || The kriging-correlation model functions. || \""\""\""",No,Yes,Yes
12534,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
12536,"\""\""\"" || Author: Dr. Mohamed Amine Bouhlel <mbouhlel@umich.edu> ||  || TODO: - check documentation of __init__ ||       - check documentation of _initialize ||       - apply_method ||       - analyse_results ||  || \""\""\""",Yes,Yes,Yes
12541,TODO : add variance support,Yes,No,Yes
12544,TODO : implement verbosity 'print_global',Yes,Yes,Yes
12547,TODO: variance and derivative surrogates support,,,Yes
12549,TODO: options not handled yet,Yes,Yes,Yes
12551,# TODO : normilze,Yes,Yes,Yes
12555,The following is not needed here; but it is needed later; during backprop.,Yes,Yes,Yes
12560,TODO: fix -> appveyor checks cannot find local csv files,Yes,Yes,Yes
12567,"\""\""\"" || Created on Fri May 04 10:26:49 2018 ||  || @author: Mostafa Meliani <melimostafa@gmail.com> || Multi-Fidelity co-Kriging: recursive formulation with autoregressive model of  || order 1 (AR1) || Partial Least Square decomposition added on highest fidelity level || Adapted March 2020 by Nathalie Bartoli to the new SMT version || \""\""\""",No,No,Yes
12568,FIXME : modify for coherence and use log.,,,Yes
12570,TODO : documentation,Yes,Yes,Yes
12572,TODO : Must be modified for Active KPLS,,,Yes
12573,TODO : must be modified for active KPLS,Yes,No,Yes
12574,TODO: must be modified for active KPLS,Yes,No,Yes
12575,TODO Must be modified for Active KPLS,Yes,No,Yes
12576,TODO : must be modified for Active Kriging,Yes,No,Yes
12578,TODO : must be modified for active KPLS,,,Yes
12580,TODO Must be modified for Active KPLS,Yes,No,Yes
12582,TODO : Must be modified for Active KPLS,,,Yes
12586,TODO : must be modified for Active Kriging,,,Yes
12588,TODO: Create hyperclass Kernels and a class for each kernel,,,Yes
12589,categorical columns,,,Yes
12592,add shear (TODO),Yes,Yes,Yes
12595,drop columns with only one value and tid column,No,Yes,Yes
12597,Specify the sharing strategy manually instead of relying on the,Yes,Yes,Yes
12604,TODO: remove after we validate it is not needed.,Yes,No,Yes
12605,Drop columns with only one value and tid column.,No,Yes,Yes
12607,TODO: revisit this once we allow users to specify which,Yes,Yes,Yes
12608,a domain; a random domain probably won't help us so,,,Yes
12611,Mul. In either case; these min\/max vars are not needed once replaced with,,,Yes
12613,TODO: use ei_target,Yes,No,Yes
12614,A useful hack: add previously visited points to the grid,No,No,Yes
12615,Add some extra candidates around the best so far (a useful hack),,,Yes
12616,Compute one more time (re-computing is unnecessary; oh well... TODO),Yes,Yes,Yes
12617,Optimization should always be better unless the optimization,Yes,No,Yes
12618,TODO: add optimization in here,Yes,Yes,Yes
12621,Apparently this dict generator throws an error for some people??,Yes,Yes,Yes
12622,TODO: add dict capability,,,Yes
12626,TODO: support decoupling i.e. task_names containing more than one task;,Yes,Yes,Yes
12627,TODO: implelent this,,,Yes
12629,TODO: record costs,Yes,Yes,Yes
12630,TODO: support meta-data,Yes,No,Yes
12634,TODO: THIS IS VERY DANGEROUS; BECAUSE THE TASK MIGHT NOT NAMED MAIN,,,Yes
12636,it says; if you got to a better place than you started; you're done,No,Yes,Yes
12640,TODO: see if there is a better way to encode this than base64,Yes,Yes,Yes
12642,this should hopefully guard against most errors.,No,Yes,Yes
12644,If it is a numpy array of size 1; cast it to a float (this might not be needed),No,No,Yes
12645,The multivariate Horseshoe distribution is not properly implemented right now,Yes,Yes,Yes
12646,None of these are; really. We should fix that up at some point; you might,,,Yes
12647,TODO: Good candidate for Py3K keyword-only argument,Yes,Yes,Yes
12648,TODO: optimize dfs to not recurse past the items in memo,,,Yes
12649,-- we've already computed this; move on.,,,Yes
12651,TODO: save the trial object somewhere to inspect; fix; re-insert,Yes,Yes,Yes
12653,XXX This mechanism deserves review as support for ipython,,,Yes
12654,-- hack because it's not really garbagecollected,Yes,Yes,Yes
12655,TODO: all underscore variables are completely unused throughout.,Yes,Yes,Yes
12659,TODO: argv1 never used,Yes,Yes,Yes
12660,TODO: datasets is not imported at this point,,,Yes
12661,TODO: rename jobs -> coll throughout,Yes,Yes,Yes
12669,TODO: this is really bad style; create a backend plotting,Yes,Yes,Yes
12673,TODO: where is pbest_sampled defined?,Yes,No,Yes
12674,TODO: icml07 undefined,,,Yes
12675,"while \""is ugly\""",Yes,Yes,Yes
12676,TODO: move things depending on numpy (among others too) to a library file,,,Yes
12677,XXX: figure out len,Yes,Yes,Yes
12678,XXX: move this introspection to __init__; and change,Yes,Yes,Yes
12679,XXX: think though... we want the binding to be updated if pos_args,No,Yes,Yes
12680,and named_args is modified... so maybe this is an ok way to do it?,,,Yes
12682,XXX does not work for builtin functions,,,Yes
12684,TODO: 'args' does not even exist at this point,Yes,Yes,Yes
12685,TODO: set up a registry for this,Yes,Yes,Yes
12687,XXX: in current implementation; if fs are `partial`; then,Yes,Yes,Yes
12689,TODO: introspect the named instruction; to retrieve the,Yes,Yes,Yes
12694,-- we've already computed this; move on.,,,Yes
12695,XXX: consider if it is desirable; efficient; buggy,,,Yes
12696,module already provides them; is slightly more efficient about it. Since,,,Yes
12697,searchspaces uses the same convention; we can more easily map graphs back,No,Yes,Yes
12698,but it seems sensible enough to me.,,,Yes
12699,TODO: cut_low never used,,,Yes
12702,XXX: don't know what exceptions to put here,Yes,Yes,Yes
12708,XXX refresh these values to lock down sampler,,,Yes
12711,XXX: subtracting two numbers potentially very close together.,Yes,Yes,Yes
12712,XXX: is sorting them necessary anymore?,,,Yes
12713,XXX: make TPE do a post-inference pass over the pyll graph and insert,No,Yes,Yes
12716,XXX Document me,Yes,Yes,Yes
12718,XXX: merge with import_tokens,,,Yes
12719,XXX: consider insisting on sorted idxs,Yes,Yes,Yes
12720,XXX: use np.searchsorted instead of dct,Yes,Yes,Yes
12721,TODO: consider insisting on sorted idxs,,,Yes
12722,TODO: use np.searchsorted instead of dct,Yes,No,Yes
12725,XXX,,,Yes
12726,TODO: advanced activations - 'leakyrelu'; 'prelu'; 'elu'; 'thresholdedrelu'; 'srelu',,,Yes
12727,print hidden layers config in readable way,No,Yes,Yes
12734,HACK,,,Yes
12735,# hack because the number of minibatches should be <= nenvs,Yes,Yes,Yes
12737,Create needed folders,No,No,Yes
12739,TODO: review all and rename to run_ppo2_lstm.py,Yes,Yes,Yes
12741,Create needed folders,,,Yes
12742,Remove unused parameters for training,No,Yes,Yes
12743,Create needed folders,No,No,Yes
12746,Create needed folders,No,No,Yes
12749,Remove unused parameters for training,,,Yes
12750,Remove unused parameters for training,Yes,Yes,Yes
12751,Remove unused parameters for training,Yes,Yes,Yes
12752,TODO Find a better way to check this.,Yes,Yes,Yes
12753,TODO: support other sparse update ops,,,Yes
12755,#NAME?,Yes,Yes,Yes
12756,TODO: exploit locality: read updated value from mirror,,,Yes
12758,TODO: Polish this block. Too deeply nested.,,,Yes
12762,TODO: allow dataset shard inside a function or dataset api,Yes,Yes,Yes
12767,unused,,,Yes
12768,metric: larger is better,No,Yes,Yes
12769,tgt_len -- unused,Yes,Yes,Yes
12772,TODO: the number of batches for evaluation should be automatically decided,,,Yes
12773,Minor hack to avoid H2D copy when using synthetic data,,,Yes
12775,This if statement is needed to guard the cast; because batch norm,No,Yes,Yes
12776,Unused (for 'a trous' convolutions),,,Yes
12779,"\""\""\""Vgg model configuration. ||  || Includes multiple models: vgg11; vgg16; vgg19; corresponding to ||   model A; D; and E in Table 1 of [1]. ||  || References: || [1]  Simonyan; Karen; Andrew Zisserman ||      Very Deep Convolutional Networks for Large-Scale Image Recognition ||      arXiv:1409.1556 (2014) || \""\""\""",,,Yes
12781,unused; because a RecordInput is not used,,,Yes
12782,TODO(jsimsa): Implement datasets code path,,,Yes
12783,TODO: exploit locality: read updated value from mirror,Yes,Yes,Yes
12784,TODO: Partitioning large variables can be helpful for load balancing.,Yes,No,Yes
12787,TODO: handle op_library_path,Yes,Yes,Yes
12788,TODO If we do MPI transform first; we can bring this block back to,,,Yes
12790,TODO: Allow user-defined hooks,,,Yes
12791,TODO: Handle all ps configurations,,,Yes
12792,TODO: support partitioning for multiple partitioners,Yes,Yes,Yes
12795,TODO(disktnk) fix check_output to accept several output keys.,Yes,No,Yes
12797,onnxruntime-gpu is better but prebuild version requires CUDA9.1,No,Yes,Yes
12801,TODO(take-cheeze): Workaround until this is merged:,Yes,No,Yes
12803,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
12804,label (unused),No,No,Yes
12805,todo: verify this is right,Yes,Yes,Yes
12808,unused,Yes,No,Yes
12809,TODO reshape into [batch; decode_step; question_word; 1],Yes,Yes,Yes
12810,Hack for single-threaded,Yes,Yes,Yes
12811,TODO: impl properly,,,Yes
12813,Implement these to use this test,No,Yes,Yes
12815,TODO: make len and indicator_rows work together; or remove one arg,,,Yes
12817,"\""\""\"" || From https:\/\/github.com\/bparr\/lars\/blob\/master\/lars.py ||  || Layer-wise Adaptive Rate Scaling minimizer. ||  || When tuning; a large initial_learning_rate (e.g. 1000.0) might be needed for || good results if using the default value for lars_coefficient. ||  || Based on Algorithm 1 in https:\/\/arxiv.org\/pdf\/1708.03888.pdf. ||  || Usage Example: ||   train_step = createLarsMinimizer(...) ||   with tf.Session() as sess: ||     sess.run(tf.global_variables_initializer()) ||     sess.run(train_step) ||  || This uses tf.train.get_or_create_global_step(); and increments this global step || every time the returned Operation is run. ||  || Args: ||   loss: A Tensor containing the value to minimize. ||   initial_learning_rate: A float. The base LR to use (gamma_0 in paper). ||   learning_rate_decay_steps: A scalar int32 or int64 Tensor or a Python number. ||     See https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/train\/polynomial_decay ||     documentation on decay_steps argument. ||   momentum: A Tensor or a float. The momentum. ||   weight_decay: A float. B in paper. ||   lars_coefficient: A float. eta in paper. ||   eps: A float. Used for numerical stability close to the optimum. ||   use_decay: A boolean. ||   var_list: List of tensorflow Variables. Each one will be optimized ||     individually (e.g. have its own momentum). If None; then defaults to all ||     trainable variables. ||  || Returns: ||   A tuple of (an Operation that minimizes using LARS; ||               debug function that returns dict of values given a Session). || \""\""\""",No,No,Yes
12818,TODO Just use default value of 0.0001?,,,Yes
12819,TODO Figure out a better way to handle this weights close-to-zero case.,,,Yes
12820,TODO: Remove,,,Yes
12822,TODO: Move this tap manipulation upstream;,Yes,Yes,Yes
12823,TODO: Make this block level,Yes,Yes,Yes
12824,TODO: Better naming \/ structure,,,Yes
12827,TODO: AST this all away,Yes,Yes,Yes
12828,\t\t\ttf.summary.image(k; expand_if_needed(v)),No,No,Yes
12831,TODO: tidy away later,,,Yes
12832,TODO: Remove all of this and let it run in the subsystem,Yes,Yes,Yes
12833,TODO: Merge with taps \/ remove all this,Yes,Yes,Yes
12835,TODO: Better way to split out the iteration taps,Yes,Yes,Yes
12838,hack for MNIST vs CIFAR,No,Yes,Yes
12839,Changes all columns of type object into strings,No,No,Yes
12840,Alter the table to allow the column (if needed),No,No,Yes
12841,Create a list of files and columns,,,Yes
12842,"target_columns = [\""abstract\""; \""specificAims\""]",No,Yes,Yes
12844,Changes all columns of type object into strings,No,No,Yes
12845,Create the output directory if needed,No,Yes,Yes
12847,Load the categorical columns,,,Yes
12848,Only load the similarity matrix if needed,No,No,Yes
12849,Quick hack,Yes,Yes,Yes
12850,Quick hack,Yes,Yes,Yes
12851,(special care needed for h5py unicode strings),No,Yes,Yes
12852,"''' || class item_iterator(object): ||  ||     def __init__(self; name; cmd_config=None; yield_single=False): ||  ||         # yield_single returns one item at a time; ||         # not in chunks like (table_name; f_sql) ||          ||         self.yield_single = yield_single ||  ||         score_config = simple_config.load(\""parse\"") ||         input_data_dir = score_config[\""output_data_directory\""] ||  ||         F_SQL = grab_files(\""*.csv\"";input_data_dir) ||  ||         # If there is a whitelist only keep the matching filename ||         try: ||             whitelist = cmd_config[\""command_whitelist\""].strip() ||         except: ||             whitelist = None ||         if whitelist: ||             assert(type(whitelist)==list) ||  ||             F_SQL2 = set() ||             for f_sql in F_SQL: ||                 for token in whitelist: ||                     if token in f_sql: ||                         F_SQL2.add(f_sql) ||             F_SQL = F_SQL2 ||  ||         # Randomize the order of the input files (why? not needed for scoring) ||         # F_SQL = random.sample(sorted(F_SQL); len(F_SQL)) ||  ||         DB_ITR = itertools.product(F_SQL; config[\""target_columns\""]) ||  ||         # Get database sizes for progress bar ||         self.total_items = 0 ||         for f_sql; target_col in DB_ITR: ||             conn = sqlite3.connect(f_sql; check_same_thread=False) ||             self.total_items += count_rows(conn; target_col) ||             conn.close() ||          ||         self.F_SQL = F_SQL ||         self.config = config ||  ||     def __len__(self): ||         return self.total_items ||  ||     def __iter__(self): ||  ||         # Setup the progress bar ||         progress_bar = tqdm.tqdm(total=self.total_items) ||  ||         # Rebuild the iterator ||         DB_ITR = itertools.product(self.F_SQL; ||                                    self.config[\""target_columns\""]) ||  ||         for f_sql; target_col in DB_ITR: ||  ||             conn = sqlite3.connect(f_sql; check_same_thread=False) ||  ||             args = { ||                 \""column_name\"":\""text\""; ||                 \""table_name\"" :target_col; ||                 \""conn\"":conn; ||                 #\""limit\"":_global_limit; ||                 \""shuffle\"":False; ||                 \""include_table_name\"":True; ||             } ||  ||             requires_meta = [] ||             requires_ref  = [\""document_scores\"";] ||  ||             if name in requires_meta: ||                 args[\""include_meta\""] = True ||  ||             INPUT_ITR = database_iterator(**args) ||  ||             if not self.yield_single: ||                 data = [] ||                 for item in INPUT_ITR: ||                     val = list(item) + [f_sql;] ||                     data.append(val) ||  ||             if self.yield_single: ||                 for item in INPUT_ITR: ||                     val = list(item) + [f_sql;] ||                     yield val ||                     progress_bar.update() ||  ||             if not self.yield_single: ||                 yield data || '''",Yes,Yes,Yes
12853,Load the categorical columns,No,No,Yes
12854,You can just specify the packages manually here if your project is,,,Yes
12856,Quick hack,,,Yes
12857,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
12859,TODO: allow unsqueeze to insert multiple dimensions,Yes,Yes,Yes
12860,TODO: can we use something like find_first?,Yes,Yes,Yes
12863,TODO: can we move combinations to ATen?,Yes,No,Yes
12867,TODO: can we make torch.zeros; torch.ones typeless and deviceless?,Yes,Yes,Yes
12868,TODO: exporting AEV to ONNX is not supported yet;,Yes,Yes,Yes
12869,TODO: remove this workaround after gather support broadcasting,Yes,Yes,Yes
12870,TODO: remove this workaround when gather support broadcasting,,,Yes
12872,TODO: remove this workaround after gather support broadcasting,,,Yes
12873,TODO: remove this workaround when gather support broadcasting,Yes,Yes,Yes
12874,TODO: remove this workaround after gather support broadcasting,Yes,Yes,Yes
12879,"\""\""\"" || .. _training-example-ignite: ||  || Train Your Own Neural Network Potential; Using PyTorch-Ignite || ============================================================= ||  || We have seen how to train a neural network potential by manually writing || training loop in :ref:`training-example`. TorchANI provide tools to work || with PyTorch-Ignite to simplify the writing of training code. This tutorial || shows how to use these tools to train a demo model. ||  || This tutorial assumes readers have read :ref:`training-example`. || \""\""\""",No,Yes,Yes
12881,Future: Delete BuiltinModels in a future release; it is DEPRECATED,Yes,Yes,Yes
12882,Future: Delete BuiltinsAbstract in a future release; it is DEPRECATED,,,Yes
12883,Future: Delete Builtins in a future release; it is DEPRECATED,,,Yes
12884,Future: Delete BuiltinsANI1CCX in a future release; it is DEPRECATED,,,Yes
12887,FIXME: due to PyTorch bug; we have to hard code the,Yes,Yes,Yes
12888,"\""\""\"" || Using TorchScript to serialize and deploy model || =============================================== ||  || Models in TorchANI's model zoo support TorchScript. TorchScript is a way to create || serializable and optimizable models from PyTorch code. It allows users to saved their || models from a Python process and loaded in a process where there is no Python dependency. || \""\""\""",,,Yes
12889,Scripting builtin model directly,,,Yes
12891,a bit useless maybe,No,No,Yes
12892,TODO: this should be removed when a real cuaev is merged,,,Yes
12894,No action needed if the info file can be located in the default path,No,Yes,Yes
12895,No action needed if the info file located in the default path is not zero-sized,No,Yes,Yes
12897,If you change the order of columns defined below; importing will break.,,,Yes
12898,TODO: Read data from the archive without extracting it into temporary directory,,,Yes
12899,TODO: Make importing optional,Yes,Yes,Yes
12902,TODO: Check if POST; validate data and save it.,,,Yes
12904,TODO: Log this.,Yes,No,Yes
12906,TODO: Implement the rest of the editing stuff.,Yes,Yes,Yes
12907,TODO: Check if owner is deleting.,Yes,No,Yes
12908,TODO: Show confirmation page and delete if POSTed.,Yes,Yes,Yes
12909,When there is only metadata... TODO: Move into the same template with if conditions...,Yes,No,Yes
12910,TODO: Implement this.,,,Yes
12911,TODO: Implement caching.,,,Yes
12912,TODO(roman): See if there's a better way to drop all tables.,,,Yes
12914,TODO: It's probably good idea to check if PG_CONNECT is defined.,Yes,Yes,Yes
12916,TODO(roman): See if there's a better way to drop all tables.,,,Yes
12918,FIXME: Is this important? Documentation?,Yes,No,Yes
12919,FIXME: ???,,,Yes
12920,FIXME(roman): Do we need to change this?,,,Yes
12922,TODO(roman): Maybe log this exception? (Would also be nice to provide,,,Yes
12923,TODO: Implement this.,Yes,Yes,Yes
12924,Sorting to be able to match columns in the table.,No,Yes,Yes
12926,"TODO(roman): Remove unused data (\""confusion_matrix\""; \""dataset_id\"").",,,Yes
12927,TODO: Util methods should not be in the database package,,,Yes
12928,TODO: Close connections when we're sleeping,,,Yes
12929,TODO: Keep an offline counter after every `DUMP_CHUNK_SIZE` so that,Yes,Yes,Yes
12931,TODO: Update id sequence at the end,Yes,Yes,Yes
12936,TODO: if one class is too small (1000?) we will make all of them,,,Yes
12938,TODO: We shouldn't do 1 row per transaction. Instead try and do 1000 or so,,,Yes
12939,TODO: Update id sequence at the end,Yes,Yes,Yes
12942,FIXME(roman): Ideally all these stats should be calculated in one,Yes,Yes,Yes
12944,TODO: This should return the same data as `get_job`; so,,,Yes
12945,we run 2 queries; however it would be more efficient,,,Yes
12946,TODO: Port this to new implementation (don't use protected parts):,Yes,Yes,Yes
12950,we run 2 queries; however it would be more efficient,,,Yes
12952,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
12955,TODO: Would be nice to mention class name in an error message.,Yes,Yes,Yes
12956,TODO(roman): Probably better to raise an exception there instead of returning None.,Yes,Yes,Yes
12957,TODO: This should use a bulk get method for speed,,,Yes
12958,TODO: refactor into `_get_class_for_ds`,,,Yes
12960,TODO: Not a great way of removing comments. The alternative is to catch,,,Yes
12962,TODO: Get rid of temporary directories and write directly to tar file if that's possible,Yes,No,Yes
12964,Columns to select when getting a job,,,Yes
12968,Combine feature columns for each recording into dictionary,No,Yes,Yes
12972,TODO(roman): See if there's a better way to drop all tables.,Yes,Yes,Yes
12973,TODO: Use `with tempfile.TemporaryDirectory` in Python 3,,,Yes
12976,TODO: delete,,,Yes
12977,TODO: DELETE,Yes,No,Yes
12978,Hack: Make dummy input for optimization tasks,,,Yes
12979,Hack: multiply with dummy 1-batch [[1.]] to make dataqueue send stopping signal,,,Yes
12980,Hack: steps = 1 interrups evaluation without waiting for data queue,,,Yes
12981,TODO: this is not happenning; program terminates earlier.,Yes,Yes,Yes
12982,TODO: pull this into default,Yes,No,Yes
12984,"\""\""\""Classes defined in this module implement various data iterators.\""\""\""",No,Yes,Yes
12985,"\""\""\""Inception model configuration. ||  || Includes multiple models: inception3; inception4; inception-resnet2. ||  || References: ||   Christian Szegedy; Sergey Ioffe; Vincent Vanhoucke; Alex Alemi ||   Inception-v4; Inception-ResNet and the Impact of Residual Connections on ||   Learning ||  ||   Christian Szegedy; Wei Liu; Yangqing Jia; Pierre Sermanet; Scott Reed; ||   Dragomir Anguelov; Dumitru Erhan; Vincent Vanhoucke; Andrew Rabinovich ||   Going Deeper with Convolutions ||   http:\/\/arxiv.org\/pdf\/1409.4842v1.pdf ||  ||   Christian Szegedy; Vincent Vanhoucke; Sergey Ioffe; Jonathon Shlens; ||   Zbigniew Wojna ||   Rethinking the Inception Architecture for Computer Vision ||   arXiv preprint arXiv:1512.00567 (2015) ||  ||   Inception v3 model: http:\/\/arxiv.org\/abs\/1512.00567 ||  ||   Inception v4 and Resnet V2 architectures: http:\/\/arxiv.org\/abs\/1602.07261 || \""\""\""",No,Yes,Yes
12988,Unused (for 'a trous' convolutions),Yes,No,Yes
12989,HACK This may not always work,,,Yes
12992,unused: this function returns the cached ref or value.,,,Yes
12993,"\""\""\""Vgg model configuration. ||  || Includes multiple models: vgg11; vgg16; vgg19; corresponding to ||   model A; D; and E in Table 1 of [1]. ||  || References: || [1]  Simonyan; Karen; Andrew Zisserman ||      Very Deep Convolutional Networks for Large-Scale Image Recognition ||      arXiv:1409.1556 (2014) || \""\""\""",No,No,Yes
12995,not be the good idea to expose that kind of info (like BIOS info etc).,,,Yes
12997,TODO: this is not happenning; program terminates earlier.,Yes,Yes,Yes
12999,TODO: is here effective batch size used?,Yes,No,Yes
13000,TODO(tucker): devise a way of better specifying the device set,Yes,Yes,Yes
13001,Minor hack to avoid H2D copy when using synthetic data,,,Yes
13002,TODO(b\/36217816): Once the bug is fixed; investigate if we should do,,,Yes
13003,Allow stdout to be viewed before the process ends.,No,No,Yes
13009,HACK This may not always work,Yes,No,Yes
13010,Check if a stride is needed; then use a strided 1x1 here,No,Yes,Yes
13011,"\""\""\""Shared functionality across multiple test files.\""\""\""",,,Yes
13012,for better performance.,,,Yes
13013,unused: this function returns the cached ref or value.,No,No,Yes
13014,It seems that default DataLoader is not efficient or I did not,Yes,Yes,Yes
13015,TODO: Place tensors into GPU memory. This will require rewriting,,,Yes
13016,A little bit ugly - models expect 'inference' or 'training'. Anyway; model will,Yes,Yes,Yes
13017,This is a hack to pretend we have a larger dataset. See constructor comments.,Yes,Yes,Yes
13018,simple hack to overcome this issue; we only exclude bbox labels,,,Yes
13021,Concat is faster; but DS2 uses 'sum'.,Yes,Yes,Yes
13023,TODO: Without exit call mxnet seems to hang in distributed mode.,,,Yes
13024,shortly. Now I need this functionality as soon as possible; thus it's here in this state.,Yes,Yes,Yes
13026,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
13028,Input columns,,,Yes
13029,Output columns,No,No,Yes
13033,The way how mxnet sends data to GPUs; it's better to keep all in CPU. Other possible option would be to,Yes,Yes,Yes
13035,TODO: Fix the above mentioned problem (as an example; see tensorflow_hpm.sh file).,Yes,Yes,Yes
13036,TODO: check,,,Yes
13037,XXX: distribute with package; or place in site-packages at install,No,Yes,Yes
13040,TODO: single cursors per connection,Yes,No,Yes
13041,TODO,,,Yes
13043,XXX: supposed to share state between cursors of the same connection,,,Yes
13045,TODO: see if there's a way to get error codes; rather than relying msgs,Yes,Yes,Yes
13046,XXX: Make it hashable to silence warnings; see if this can be done upstream,Yes,Yes,Yes
13047,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
13050,TODO: Fix setuptools_scm; rtd; and pkg_resources interaction to not hardcode,Yes,Yes,Yes
13051,TODO: accept first_n,Yes,Yes,Yes
13052,TODO: extra copy.,,,Yes
13053,TODO: not sure if this is standard,Yes,No,Yes
13054,TODO: Casts for pyarrow (waiting on python bindings for casting),,,Yes
13055,in integer columns; so int cols with null,,,Yes
13056,Validate that there are the same number of columns in the table,,,Yes
13057,wrap IPC functions needed,No,Yes,Yes
13058,None lets system choose suitable unused address,No,Yes,Yes
13061,TODO: validate if this is an Arrow limitation; outside this range fails,Yes,Yes,Yes
13062,need to manually specify columns since some don't currently work,Yes,Yes,Yes
13063,need to drop unsupported columns from df_in,,,Yes
13064,TODO: validate if this is an Arrow limitation; outside this range fails,Yes,Yes,Yes
13065,Figure out why,No,Yes,Yes
13068,this is needed to modify the df object for deallocate_df to work,No,Yes,Yes
13069,this is needed for some reason...,,,Yes
13079,TO-DO: support timestamps (require data to develop this with first; however!),,,Yes
13080,assume series are indexed from 0 to m-1 (can map to non-linear indices later if needed),No,No,Yes
13081,TO-DO: support timestamps,Yes,No,Yes
13082,-- Options for todo extension ----------------------------------------------,,,Yes
13083,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
13084,removes the dependency on XPandas and returns a pandas.DataFrame with m rows and d columns of pandas.Series objects,,,Yes
13085,perhaps not the best way to do this; but on the first row; initialise stored depending on the,,,Yes
13087,making threading more efficient than multiprocessing in,No,Yes,Yes
13088,Total number of intervals of all columns,,,Yes
13089,Total number of intervals of all columns,No,Yes,Yes
13092,total number of intervals of all columns,,,Yes
13093,total number of intervals of all columns,,,Yes
13094,'applied to the data columns'),No,No,Yes
13095,raise ValueError('Number of columns of input is different from what was seen',No,No,Yes
13102,TODO: (discus) why are we making the estimator pubic?,Yes,No,Yes
13104,TODO: (discuss) why do we have data here?,,,Yes
13105,TODO: (discuss) why do we have task here?,Yes,No,Yes
13106,TODO: remove check as it will never be true,Yes,No,Yes
13108,for fitting pipelines in parallel; multiprocessing is more efficient.,,,Yes
13110,TODO only handles series columns; raises error for columns with primitives,Yes,Yes,Yes
13112,TODO check input is series column; not column of primitives,,,Yes
13113,TODO if multiple columns are passed; introduce option to compute one set of shared intervals;,Yes,Yes,Yes
13114,TODO generalise to non-equal-index cases,,,Yes
13115,TODO does not handle dataframes with nested series columns and standard columns containing only primitives,Yes,Yes,Yes
13116,TODO assumes columns are typed (i.e. all rows for a given column have the same type),,,Yes
13121,TODO generalise to non-equal-index cases,Yes,Yes,Yes
13122,TODO generalise to series-to-series functions and function kwargs,Yes,Yes,Yes
13123,Works on single column; but on multiple columns only if columns have equal-length series.,Yes,Yes,Yes
13126,TODO assumes columns are typed (i.e. all rows for a given column have the same type),,,Yes
13127,TODO only handles series columns; raises error for columns with primitives,Yes,Yes,Yes
13128,Rename columns for comparing re-ordered arrays.,Yes,No,Yes
13131,TODO: save predictions,Yes,No,Yes
13133,TO-DO: thorough testing (some initial testing completed; but passing the code to David to develop,,,Yes
13134,TO-DO: check the validity of the binary info gain method and implement the early abandon as,Yes,No,Yes
13135,TO-DO: revisit contract timing - currently it's lazy (will process the last shapelet and go over the limit),,,Yes
13136,A more sensible approach would be to estimate the average\/median\/max shapelet calculation time and,,,Yes
13137,TO-DO: Transform currently only for univariate data - once all of the above is reconciled we should extend,,,Yes
13139,TO-DO: verbose output of time remaining for contract is currently in decimal format; e.g.:,,,Yes
13140,TO-DO: implement early abandon info gain for 2 classes; as per the original Ye and Keogh shapelet paper,,,Yes
13142,TODO: save results to disk\/hdd,,,Yes
13144,avg_training_time.columns = ['avg training time (in sec)'],No,Yes,Yes
13147,TO-DO: predict; predict_proba; full testing,Yes,No,Yes
13148,TODO: implement def calculate_per_dataset for the methods below,,,Yes
13149,TODO: why is it necessary to pass the data? The task already has the data.,,,Yes
13152,TODO check input is series column; not column of primitives,,,Yes
13153,TODO generalise to columns with series of unequal length,,,Yes
13154,TODO if multiple columns are passed; introduce option to compute one set of shared intervals;,Yes,Yes,Yes
13159,once the best parameter option has been estimated on the training data; perform a final pass with this parameter option,No,Yes,Yes
13160,was used previously. TO-DO: determine how to extract predictions for the best param option from GridSearchCV),Yes,Yes,Yes
13161,TODO: why is it necessary to pass the data? The task already has the data.,Yes,No,Yes
13162,todo should delta be rounded to integer?,Yes,Yes,Yes
13164,todo should delta be rounded to integer?,Yes,Yes,Yes
13166,todo warn?,Yes,No,Yes
13168,todo warn?,,,Yes
13169,todo warn?,Yes,No,Yes
13170,todo change init'd vars in other classes to None rather than -1,Yes,No,Yes
13171,todo missing values NaN messes this up!,,,Yes
13172,todo checks to make sure distance pool in correct structure; i.e.,Yes,Yes,Yes
13174,TODO generalise to columns with series of unequal length,,,Yes
13175,TODO if multiple columns are passed; introduce option to compute one set of shared intervals;,,,Yes
13177,todo,Yes,No,Yes
13180,TODO,,,Yes
13182,TODO,Yes,Yes,Yes
13183,TODO use metadata object from extended data container,Yes,Yes,Yes
13188,self._features = metadata.columns.drop(self.target),No,Yes,Yes
13189,# otherwise check for consistency against given columns names in metadata,No,Yes,Yes
13190,if not np.all(self.features.isin(metadata.columns)):,No,Yes,Yes
13193,todo add: python setup.py build_ext --inplace ? to build cython modules\uFFFF,,,Yes
13194,todo,,,Yes
13195,todo unpack panda,Yes,Yes,Yes
13196,todo unpack instances into numpy arr,Yes,Yes,Yes
13197,todo,,,Yes
13199,todo str + other builtins,,,Yes
13200,TODO input checks,,,Yes
13202,TODO replace by task-strategy compatibility lookup registry,Yes,Yes,Yes
13203,TODO check input is series column; not column of primitives,,,Yes
13204,TODO generalise to columns with series of unequal length,Yes,Yes,Yes
13207,TODO replace by task-strategy compatibility lookup registry,Yes,Yes,Yes
13211,TODO use metadata object from extended data container,,,Yes
13213,otherwise check against metadata columns,No,Yes,Yes
13214,TODO replace by task-strategy compatibility lookup registry,Yes,Yes,Yes
13217,#TODO expand as the list of backend functions grows,Yes,No,Yes
13218,TODO fix!,Yes,Yes,Yes
13219,todo warn?,,,Yes
13221,todo warn?,Yes,No,Yes
13222,todo warn?,Yes,No,Yes
13228,TODO implement for forecasting tasks,Yes,Yes,Yes
13229,TODO implement check for overwriting already saved files,Yes,Yes,Yes
13230,TODO pickling will not work for all strategies,,,Yes
13235,TODO replace by task-strategy compatibility lookup registry,Yes,Yes,Yes
13237,TODO implement for forecasting tasks,Yes,Yes,Yes
13238,assume series are indexed from 0 to m-1 (can map to non-linear indices later if needed),No,No,Yes
13239,left here for now; better elsewhere later perhaps,,,Yes
13243,if not np.all(self.features.isin(metadata.columns)):,No,Yes,Yes
13244,TODO necessary to check this here or can we safely assume obs_horizon is always either fixed or moving,Yes,No,Yes
13246,TODO input checks,Yes,No,Yes
13247,TODO BUG: write write_results_to_uea_format does not write the results property unless the probas are provided as well.,Yes,No,Yes
13248,TODO fix load from_uae_format function,,,Yes
13249,TODO BUG new line is written only if the probas are provided!!!!,Yes,Yes,Yes
13251,TODO implement task-strategy compatibility lookup registry using strategy traits,Yes,Yes,Yes
13252,TODO input checks,Yes,No,Yes
13254,TODO pickling will not work for all strategies,,,Yes
13257,TODO implement task-strategy compatibility lookup registry using strategy traits,Yes,Yes,Yes
13260,TODO input checks for forecasting,,,Yes
13265,TODO input checks for forecasting,Yes,Yes,Yes
13266,TODO should that be a mixin class instead?,Yes,No,Yes
13267,TODO pass X to estimators where the predict method accepts X,,,Yes
13269,TODO implement task-strategy compatibility lookup registry using strategy traits,,,Yes
13271,TODO add input checks,,,Yes
13272,TODO pass X only to estimators where the predict method accepts X; currenlty X is ignored,Yes,Yes,Yes
13274,TODO replace by task-strategy compatibility lookup registry,,,Yes
13276,TODO add more input checks for consistency of X and y,Yes,No,Yes
13277,TODO add additional input checks for update data; i.e. that update data is newer than data seen in fit,Yes,Yes,Yes
13284,set default feature information (all columns but target) using metadata,No,Yes,Yes
13285,TODO replace with strategy - estimator type registry lookup,,,Yes
13286,TODO add input checks for contents; ie all cells be pandas Series; numpy arrays or primitives;,Yes,Yes,Yes
13287,ultimately move checks to data container,,,Yes
13288,TODO what's a good default for window length? sqrt(len(data))?,Yes,No,Yes
13291,TODO input checks,Yes,No,Yes
13294,Check number of generated intervals\/columns.,,,Yes
13295,Check for conflicts with double-underscore convention,No,No,Yes
13296,TODO input checks,Yes,No,Yes
13297,TODO check input is series column; not column of primitives,,,Yes
13299,TODO add docstrings,Yes,No,Yes
13300,Check for conflicts with double-underscore convention,,,Yes
13301,Check for conflicts with double-underscore convention,No,No,Yes
13304,todo debug option to do helpful printing,Yes,Yes,Yes
13305,todo info gain,Yes,Yes,Yes
13308,call param_pool function giving train instances as parameter,,,Yes
13309,todo these checks could probs be \/ is defined elsewhere,Yes,Yes,Yes
13310,todo missing values NaN messes this up!,,,Yes
13313,todo comment,,,Yes
13314,todo missing values NaN messes this up!,,,Yes
13315,Check if index is the same for all columns.,No,Yes,Yes
13317,TODO add input checks for X when updating,,,Yes
13319,TODO implement check for overwriting already saved files,,,Yes
13320,TODO pickling will not work for all strategies,Yes,Yes,Yes
13327,TODO pickling will not work for all strategies,Yes,Yes,Yes
13331,num_trees = 10; # not needed for prox tree \/ stump,No,Yes,Yes
13332,num_stump_evaluations = 5 # not needed for prox stump,No,Yes,Yes
13333,TO-DO: thorough testing (some initial testing completed; but passing the code to David to develop,Yes,No,Yes
13334,TO-DO: check the validity of the binary info gain method and implement the early abandon as,,,Yes
13336,A more sensible approach would be to estimate the average\/median\/max shapelet calculation time and,No,Yes,Yes
13338,TO-DO: Currently extends TransformerMixin - class should extend the sktime transformer base class (not on dev at,,,Yes
13340,TO-DO: implement early abandon info gain for 2 classes; as per the original Ye and Keogh shapelet paper,Yes,Yes,Yes
13341,shapelets may be False. However; could be dangerous if something else uses this code later. TO-DO: decide the best place to sort,,,Yes
13345,shapelets may be False. However; could be dangerous if something else uses this code later. TO-DO: decide the best place to sort,,,Yes
13346,WORSHOP NOTE: v3 initially is a full shapelet transform (extension to random and contract should be ready to implement; but not,No,Yes,Yes
13351,TO-DO: in case of unequal length time series; we have two options:,Yes,No,Yes
13352,TO-DO: Currently extends TransformerMixin - class should extend the sktime transformer base class (not on dev at,Yes,No,Yes
13356,if this is needed.,No,Yes,Yes
13363,statsmodels decompose methods does handle multiple series (expected to be in columns of 2d array),,,Yes
13365,2d input; multiple columns,,,Yes
13366,TODO currently we loose the time index; need to add it back to Xt after slicing in time,Yes,Yes,Yes
13367,TODO make more efficient\/vectorise to work on multiple rows simultaneously,Yes,No,Yes
13369,statsmodels `seasonal_decompose` expects time series to be in columns; rather than rows; we therefore need to,No,Yes,Yes
13371,TODO does not handle dataframes with nested series columns *and* standard columns containing only primitives,,,Yes
13372,TODO input checks,Yes,No,Yes
13374,TODO add support for period\/datetime indexing,,,Yes
13376,TODO add input checks,Yes,No,Yes
13380,TODO add check inverse method after fitting transformer,Yes,Yes,Yes
13381,TODO add constant strategy,Yes,Yes,Yes
13382,if this is needed.,No,Yes,Yes
13384,TO DO: Make more efficient,Yes,No,Yes
13386,TODO concatenate exogeneous variables X to rolled window matrix X below,,,Yes
13393,compute starts; ends and lengths of the segments,,,Yes
13396,todo logging package rather than print to screen,Yes,Yes,Yes
13400,todo duck-type functions,Yes,No,Yes
13401,todo comment-up transformers \/ util classes,Yes,Yes,Yes
13402,todo use specific dimension rather than whole,Yes,Yes,Yes
13403,todo use specific dimension rather than whole thing?,Yes,Yes,Yes
13404,if isinstance(param_value; dict): # no longer require recursive param perms,,,Yes
13407,TODO: add proper checks (e.g. check if input stuff is pandas full of objects),,,Yes
13409,TO-DO: could cythonise important methods; eg the distance and info gain calculations,,,Yes
13412,Takes into account the use of the MAX shapelet calculation time to not exceed the time_limit (not exact; but likely a good guess).,No,Yes,Yes
13414,todo info gain,,,Yes
13415,todo chi sq,No,Yes,Yes
13416,call param_pool function giving train instances as parameter,No,Yes,Yes
13417,todo could randomise?,,,Yes
13419,todo logging package rather than print to screen,Yes,Yes,Yes
13421,todo constructor accept str name func \/ pointer,,,Yes
13422,todo duck-type functions,Yes,No,Yes
13423,todo comment-up transformers \/ util classes,,,Yes
13429,TODO assumes columns are typed (i.e. all rows for a given column have the same type),,,Yes
13431,Check if index is the same for all columns.,No,Yes,Yes
13432,Compare with remaining columns,,,Yes
13433,TODO: add proper checks (e.g. check if input stuff is pandas full of objects),,,Yes
13438,TODO add support for period\/datetime indexing,Yes,Yes,Yes
13441,Compare with remaining columns,No,Yes,Yes
13442,statsmodels `seasonal_decompose` expects time series to be in columns; rather than rows; we therefore need to,,,Yes
13443,TODO currently we loose the time index; need to add it back to Xt after slicing in time,Yes,Yes,Yes
13444,TODO does not handle dataframes with nested series columns *and* standard columns containing only primitives,Yes,Yes,Yes
13445,2nd attempt: always iterate over columns; but column is not 2d and thus breaks if transformer expects 2d input,Yes,No,Yes
13446,loop over columns,No,Yes,Yes
13447,append transformed columns,No,Yes,Yes
13448,concatenate transformed columns,,,Yes
13449,TODO check if for each column; all rows have equal-index series,Yes,Yes,Yes
13454,TODO add support for period\/datetime indexing,,,Yes
13457,statsmodels `seasonal_decompose` expects time series to be in columns; rather than rows; we therefore need to,No,Yes,Yes
13469,todo logging package rather than print to screen,Yes,Yes,Yes
13472,todo constructor accept str name func \/ pointer,,,Yes
13473,todo duck-type functions,Yes,No,Yes
13476,if isinstance(param_value; dict): # no longer require recursive param perms,,,Yes
13483,todo duck-type functions,,,Yes
13487,if isinstance(param_value; dict): # no longer require recursive param perms,,,Yes
13488,todo make checks optional and propogate from forest downwards,Yes,Yes,Yes
13490,loop over columns,No,Yes,Yes
13492,concatenate transformed columns,No,No,Yes
13494,2nd attempt: apply but iterate over columns; still relatively fast but still not very robust,Yes,Yes,Yes
13496,"\""\""\"" Shapelet Transform Classifier || wrapper implementation of a shapelet transform classifier pipeline that simply performs a (configurable) shapelet transform || then builds (by default) a random forest. This is a stripped down version for basic usage ||  || \""\""\""",No,Yes,Yes
13497,"\""\""\"" Shapelet Transform Classifier || wrapper implementation of a shapelet transform classifier pipeline that simply performs a (configurable) shapelet transform || then builds (by default) a random forest. This is a stripped down version for basic usage ||  || \""\""\""",,,Yes
13498,check if there are at least as many samples as columns in subset for PCA;,No,Yes,Yes
13499,as n_components will be min(n_samples; n_columns),No,Yes,Yes
13501,randomly split columns into disjoint subsets,,,Yes
13503,transform on subset of columns but all instances,,,Yes
13505,efficient than multiprocessing in that case. However; in this case;,No,Yes,Yes
13506,for fitting pipelines in parallel; multiprocessing is more efficient.,No,Yes,Yes
13508,TODO if we use strategy specific saving function; how do we know how to load them? check file endings?,Yes,Yes,Yes
13509,TODO skip data loading if all strategies are skipped in case results already exist,Yes,Yes,Yes
13511,also skip strategy if overwrite is set to False; training set predictions are needed but already exist,,,Yes
13512,TODO always try to get probabilistic predictions; compute deterministic predictions using,,,Yes
13514,TODO y_proba is currently ignored,,,Yes
13516,TODO y_proba is currently ignored,,,Yes
13517,check if there are at least as many samples as columns in subset for PCA;,,,Yes
13518,as n_components will be min(n_samples; n_columns); otherwise throws error,,,Yes
13519,shuffle columns,No,No,Yes
13520,otherwise iterate through columns; selecting random number of columns within bounds,,,Yes
13521,iterator over columns,No,Yes,Yes
13524,TODO: check if datasets are skipped entirely because predictions already exists before loading data;,Yes,Yes,Yes
13527,scale columns,No,Yes,Yes
13529,list of transformed columns indexes,No,Yes,Yes
13530,start of column indexing for transformed columns,,,Yes
13532,preallocate array for transformed columns,,,Yes
13533,"\""\""\"" Shapelet Transform Classifier || Hardcoded implementation of of a shapelet transform classifier pipeline that simply performs a (configurable) shapelet transform || then builds (by default) a random forest || \""\""\""",No,Yes,Yes
13534,check if there are at least as many samples as columns in subset for PCA;,No,Yes,Yes
13538,TODO implement check for overwriting already saved files,,,Yes
13539,TODO pickling will not work for all strategies,,,Yes
13540,this is a bit of a hack; PresplitFilesCV would need to talk to the data loader during orchestration;,Yes,Yes,Yes
13541,"\""\""\"" Shapelet Transform Classifier || wrapper implementation of a shapelet transform classifier pipeline that simply performs a (configurable) shapelet transform || then builds (by default) a random forest. This is a stripped down version for basic usage ||  || \""\""\""",No,Yes,Yes
13543,Check output indices (row indices and columns the same; time indices start from 0),,,Yes
13544,this is a bit of a hack; PresplitFilesCV would need to talk to the data loader during orchestration;,,,Yes
13547,efficient.,,,Yes
13548,efficient.,,,Yes
13551,standard columns containing only primitives,No,Yes,Yes
13552,TODO deprecate in favor of new pandas data frame based data,,,Yes
13557,efficient than multiprocessing in that case.,No,No,Yes
13558,multiprocessing is more efficient.,No,Yes,Yes
13560,haven't built functionality to deal with classes that exist in,Yes,Yes,Yes
13561,Convert one of the columns in the dataframe to numpy array,No,Yes,Yes
13562,Convert one of the columns in the dataframe to a numpy array,No,Yes,Yes
13564,Pad both ends of X,No,No,Yes
13568,TODO refactor? dicts not really needed here ...,Yes,Yes,Yes
13569,TODO use CountVectorizer instead on actual words ... ???,Yes,Yes,Yes
13572,TODO: safe memory by directly discretizing and,,,Yes
13574,TODO merge with transform???,,,Yes
13576,convert single integer to pandas index; no further checks needed,,,Yes
13578,TODO uint64?,Yes,Yes,Yes
13579,if this is needed.,No,Yes,Yes
13580,TODO a shift of 2 is only correct for alphabet size 4; log2(4)=2,Yes,No,Yes
13583,for 2d numpy array; rows represent instances; columns represent time points,No,Yes,Yes
13584,n_instances; n_columns = X.shape,No,Yes,Yes
13586,for column in range(n_columns):,No,Yes,Yes
13589,We concatenate by tabularizing all columns and then detabularizing,No,No,Yes
13590,ensure there are 4 columns in the long_format table,,,Yes
13591,ensure that all columns contain the correct data types,,,Yes
13594,todo missing values NaN messes,,,Yes
13595,todo use all dimensions \/ uneven length dataset,Yes,Yes,Yes
13596,We iterate over columns and rows to make cell-wise comparisons.,,,Yes
13597,Iterate over columns,,,Yes
13599,assuming samples in columns,No,No,Yes
13601,"\""\""\"" || Lists of datasets available from the archive on timeseriesclassification.com ||  || There are four main distinctions: univariate\/multivariate equal\/unequal length. || Array univariate lists the 128 UCR problems; as described in [1]. || Array multivariate lists the 30 UEA problems; as described in [2]; plus 3 new additions. || Array univariate_equal_length lists the 112 UCR archive problems used in [3]. || Array multivariate_equal_length lists the 26 UEA archive problems used in [4]. ||  || [1] H.Dau; A. Bagnall; K. Kamgar; C. Yeh; Y. Zhu; S. Gharghabi; C. Ratanamahatana and E. Keogh. || The  UCR  time  series  archive. IEEE\/CAA J. Autom. Sinica; 6(6):1293\u20131305; 2019 || [2] A. Bagnall; H. Dau; J. Lines; M. Flynn; J. Large; A. Bostrom; P. Southam;and  E.  Keogh. || The UEA  multivariate  time  series  classification  archive; 2018. ArXiv e-prints; arXiv:1811.00075; 2018 || [3] A. Bagnall; M. Flynn; J. Large; J. Lines and M. Middlehurst. || On the Usage and Performance of the Hierarchical Vote Collective of Transformation-Based Ensembles Version 1.0 || (HIVE-COTE v1.0). Lecture Notes in Computer Science. in proc. 5th Advanced Analytics and Learning on Temporal Data || [4] A. Pasos Ruiz; M. Flynn; J. Large; M. Middlehurst and A. Bagnall. ||     The great multivariate time series classification bake off: a review and experimental evaluation of recent ||     algorithmic advances; Data Mining and Knowledge Discovery; 2020. || \""\""\""",,,Yes
13604,# later if needed),,,Yes
13606,for _label in multi_ind_dataframe.columns:,No,Yes,Yes
13607,for _label in X.columns ],No,Yes,Yes
13608,If all the columns are nested in structure,No,No,Yes
13609,If some columns are primitive (non-nested) then first convert to,No,No,Yes
13610,multi-indexed DataFrame where the same value of these columns is,,,Yes
13612,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
13614,TODO: change DEFINE_strings to DEFINE_integer,Yes,Yes,Yes
13615,TODO: we could do a hadoop fs -ls on the directory and fetch it immediately,,,Yes
13616,FIXME: should we expose the context directly?,,,Yes
13618,TODO: what case does this code path support?,Yes,No,Yes
13619,"\""\""\"" || Usage ||  || read_tfrecord.py [--schema path_to_schema] path_to_tfrecord1 ... path_to_tfrecordN | less ||  || 0. clean up JSON output to be jq friendly [DONE] || 0.5 support sparse features || 1. clean this up; remove .py; rename it [in progress] || 2. put this in \/bin; update setup.py ||  || \""\""\""",,,Yes
13621,FIXME: TF DTypes are only partially supported:,,,Yes
13623,Is this really desired behavior?,Yes,No,Yes
13625,TODO: implement multisession support,Yes,Yes,Yes
13629,TODO: Why are we not ^2 this & getting the sqrt?,,,Yes
13630,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
13631,"\""\""\"" || References || ---------- ||  ||     .. [Giannelli2010] Giannelli et al. *Characterization of Nyquist ghost in ||       EPI-fMRI acquisition sequences implemented on two clinical 1.5 T MR scanner ||       systems: effect of readout bandwidth and echo spacing*. J App Clin Med Phy; ||       11(4). 2010. ||       doi:`10.1120\/jacmp.v11i4.3237 <http:\/\/dx.doi.org\/10.1120\/jacmp.v11i4.3237>`_. ||  ||     .. [Jenkinson2002] Jenkinson et al.; *Improved Optimisation for the Robust and ||       Accurate Linear Registration and Motion Correction of Brain Images*. ||       NeuroImage; 17(2); 825-841; 2002. ||       doi:`10.1006\/nimg.2002.1132 <http:\/\/dx.doi.org\/10.1006\/nimg.2002.1132>`_. ||  ||     .. [Nichols2013] Nichols; `Notes on Creating a Standardized Version of DVARS ||       <http:\/\/www2.warwick.ac.uk\/fac\/sci\/statistics\/staff\/academic-research\/nichols\/scripts\/fsl\/standardizeddvars.pdf>`_; ||       2013. ||  ||     .. [Power2012] Poweret al.; *Spurious but systematic correlations in functional ||       connectivity MRI networks arise from subject motion*; NeuroImage 59(3):2142-2154; ||       2012; doi:`10.1016\/j.neuroimage.2011.10.018 ||       <http:\/\/dx.doi.org\/10.1016\/j.neuroimage.2011.10.018>`_. ||  ||  ||     .. [QAP] `The QAP project ||       <https:\/\/github.com\/oesteban\/quality-assessment-protocol\/blob\/enh\/SmartQCWorkflow\/qap\/temporal_qc.py#L16>`_. || \""\""\""",No,Yes,Yes
13635,Remove failed cases from Y; append new columns to X,No,Yes,Yes
13636,columns,,,Yes
13637,We don't want to miss a bad volume somewhere in the middle; as that could be a valid artifact.,,,Yes
13638,TODO plot min\/max or mark spikes,Yes,No,Yes
13640,Remove failed cases from Y; append new columns to X,No,Yes,Yes
13641,Remove failed cases from Y; append new columns to X,No,Yes,Yes
13642,Move center of coordinates,No,Yes,Yes
13645,Move center of coordinates,No,Yes,Yes
13647,Move center of coordinates,No,Yes,Yes
13649,Drop empty columns,,,Yes
13651,downcast to reduce space consumption and improve performance,Yes,Yes,Yes
13652,maybe improved later,,,Yes
13654,maybe improved later,,,Yes
13656,all features better than noise,No,No,Yes
13658,efficient.,No,Yes,Yes
13659,changecols = vals.iloc[:; iqr > 1.e-5].columns.ravel().tolist(),,,Yes
13663,TODO: zscore_dataset was removed,,,Yes
13664,TODO: zscore_dataset was removed,Yes,No,Yes
13665,TODO: check on windows if hasattr check would work correctly and add value:,Yes,Yes,Yes
13666,XXX: This currently has no effect; but is a stand-in to remind us to figure out,,,Yes
13667,FIXME there is two type of speller; grid speller and geo-speller.,,,Yes
13668,FIXME there is two type of speller; grid speller and geo-speller.,Yes,Yes,Yes
13670,TODO: actually incorporate fNIRS somehow,Yes,Yes,Yes
13673,FIXME name are not unique,Yes,Yes,Yes
13674,TODO: actually incorporate fNIRS somehow,Yes,Yes,Yes
13676,TODO: no good cross-platform way of recording CPU info?,,,Yes
13678,TODO: no good cross-platform way of recording CPU info?,Yes,Yes,Yes
13680,FIXME name are not unique,Yes,Yes,Yes
13681,TODO: This works but is hacky,Yes,Yes,Yes
13682,Fix navigation bar to top of page?,No,Yes,Yes
13683,-- Options for todo extension ----------------------------------------------,,,Yes
13684,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
13685,FIXME: this always update the path,Yes,No,Yes
13686,FIXME: deal with run with no event (1:3) and name them,,,Yes
13687,FIXME: electrode position and name are not provided directly.,Yes,Yes,Yes
13690,grow X and labels in a memory efficient way. can be slow,,,Yes
13691,metadata have at least 3 columns; subject; session and run.,No,Yes,Yes
13694,TODO: make this work with varying offsets since not all data starts at 0,Yes,Yes,Yes
13695,FIXME not sure what are those CB1 \/ CB2,Yes,No,Yes
13696,FIXME check the value are in V and not uV.,,,Yes
13697,TODO: add plotting code here...,,,Yes
13699,Needed to assess BaseImagery,No,No,Yes
13700,better to do pip install git+https:\/\/github.com\/MIT-LCP\/wfdb-python.git,No,No,Yes
13701,.flash file can give the exact times of the flashes if necessary,No,No,Yes
13702,TODO Add custom evaluation that actually returns additional info,,,Yes
13704,better to do pip install git+https:\/\/github.com\/MIT-LCP\/wfdb-python.git,,,Yes
13705,.flash file can give the exact times of the flashes if necessary,No,No,Yes
13707,.flash file can give the exact times of the flashes if necessary,No,No,Yes
13709,.flash file can give the exact times of the flashes if necessary,No,No,Yes
13712,Can maybe look to downgrade to read only access,Yes,No,Yes
13713,Establish rights and basic options needed for all process declartion \/ iteration,No,Yes,Yes
13715,Why does this need to start at 2;2 and not 0;0 to align with the canvas? I have no idea; probably some border somewhere or something.,,,Yes
13716,''' || Hi! You can use this code as a template to create your own bot.  Also if you don't mind writing a blurb || about your bot's strategy you can put it as a comment here. I'd appreciate it; especially if I can help || debug any runtime issues that occur with your bot. || ''',,,Yes
13717,TODO: Sanitize input players give,Yes,No,Yes
13718,''' || Hi! You can use this code as a template to create your own bot.  Also if you don't mind writing a blurb || about your bot's strategy you can put it as a comment here. I'd appreciate it; especially if I can help || debug any runtime issues that occur with your bot. || ''',No,Yes,Yes
13719,Probably another struct,,,Yes
13722,Everything starts at 2;2 (I can't figure out why tkinter pains me but it does...),Yes,Yes,Yes
13723,Move blue; orange; ball,No,Yes,Yes
13727,TODO: the agent should get told this index explicitly,,,Yes
13728,Move 4 bytes past error code,No,Yes,Yes
13729,TODO: use this code piece when tf.multinomial gets better,Yes,Yes,Yes
13732,TODO: use this code piece when tf.multinomial gets better,Yes,Yes,Yes
13734,TODO read keys,Yes,No,Yes
13735,todo present data over time :),Yes,Yes,Yes
13736,Workaround for windows streams behaving weirdly when not in command prompt,,,Yes
13737,given maybe input return keras version  for your model,No,No,Yes
13738,given maybe input return keras version  for your model,No,No,Yes
13739,Workaround for windows streams behaving weirdly when not in command prompt,Yes,Yes,Yes
13741,'''\r || ranges:\r ||   A range is a configuration object which holds information about its name; possible values and loss function.\r ||   Currently represented as a tuple; where the loss function may be omitted. (varying tuple sizes seems like bad design)\r || combo_scheme:\r ||   Seems to be similar to ranges. TODO: figure out how this works in more detail\r || copies:\r ||   A `copy` is a tuple of two names where the actions of the latter (name) is forwarded to the former.\r || ''',Yes,Yes,Yes
13742,This is kinda a hack due to it being unnatural to make the player float.,Yes,Yes,Yes
13743,Hack to be able to import bot_code.* from here.,Yes,Yes,Yes
13747,axis=1 concats all the columns; so you have one large vector of all the player information,No,Yes,Yes
13749,minimum is set to 12; as at least 3 color channels are needed for correct upsampling,,,Yes
13751,we no longer require output once we are using the model,No,No,Yes
13752,'Der Mann hat xxx; es zu yyy' and similar structures,,,Yes
13754,it really is similar!,No,Yes,Yes
13755,removing question marks seems to lead to better results,,,Yes
13756,Lower scores are better.,,,Yes
13757,but would require considerable changes for very little additional functionality.,,,Yes
13759,only needed for the example,No,No,Yes
13760,TODO don't even calculate with variables when not needed,Yes,Yes,Yes
13761,todo handle within channel,Yes,Yes,Yes
13763,TODO fix shapeof in nnef2tf,Yes,Yes,Yes
13764,Not really needed,Yes,Yes,Yes
13767,TODO optimize,,,Yes
13768,TODO revise these methods; is negative pad_total possible?,,,Yes
13772,TODO something might be needed like adding axes which are not written out,Yes,Yes,Yes
13774,TODO padding?,Yes,No,Yes
13776,TODO epsilon and bias are not really the same; is this a problem?,,,Yes
13777,todo is the if needed,,,Yes
13778,TODO maybe not needed now,Yes,No,Yes
13781,TODO rename,,,Yes
13783,TODO consider changing to convert_skip_with_error,Yes,Yes,Yes
13784,Maybe this hook system is now unnecessary,,,Yes
13785,TODO find a better way to handle the case (this only happens with tf.gradients sometimes),Yes,Yes,Yes
13787,TODO add nnef types,,,Yes
13789,TODO remove (use convert),Yes,No,Yes
13790,TODO extra update?,Yes,Yes,Yes
13791,TODO check if correct,,,Yes
13794,TODO: put this optional numpy as well?,,,Yes
13796,todo: handle OSError,,,Yes
13798,TODO do inline only for unary and binary,Yes,Yes,Yes
13799,TODO: this does not have much info; so maybe remove it:,Yes,Yes,Yes
13800,normally it is not needed,No,Yes,Yes
13801,Maybe too strict,No,No,Yes
13802,TODO handle constants here,Yes,Yes,Yes
13803,default needed because box does not have groups,No,No,Yes
13805,TODO maybe support,Yes,No,Yes
13808,TODO make sure that size=4 is like o x o o in NNEF,,,Yes
13811,TODO epsilon and bias are not really the same; is this a problem?,Yes,Yes,Yes
13813,TODO what if split has -1; and fix split,,,Yes
13815,TODO remove unsqueeze\/squeeze that cancel out each other,Yes,Yes,Yes
13816,TODO: we dont have to collapse conv\/add or conv\/pad if we use ext,Yes,Yes,Yes
13818,y = reshape(y; output_shape_kept_dims) # needed?,No,Yes,Yes
13819,grad = reshape(grad; output_shape_kept_dims) # needed?,Yes,Yes,Yes
13823,TODO better,,,Yes
13825,TODO no code duplication,,,Yes
13828,"print(\""Info: Had to fix strange invocation {}\"".format(invocation.function_name))",,,Yes
13831,undocumented feature in ONNX; probably comes from pytorch,Yes,No,Yes
13832,TODO rewrite these too,Yes,Yes,Yes
13833,Flatten is needed because of MaxPoolWithArgMax objects,,,Yes
13836,TODO better,,,Yes
13837,self prob exclusion; hack with memory for effeciency,Yes,Yes,Yes
13841,set up JVM and load classes needed,No,Yes,Yes
13844,We need a pipeline to create views that are required by our model (e.g. NER is needed for WIKIFIER etc.),,,Yes
13857,add_single_ground_truth_image_info expects a single image. Fix,Yes,Yes,Yes
13858,A dictionary of metric names to classes that implement the metric. The classes,,,Yes
13861,Continuous columns,No,No,Yes
13863,Continuous columns,No,No,Yes
13866,TODO(b\/65130867): Use image_id tensor once we fix the input data,,,Yes
13867,add_single_ground_truth_image_info expects a single image. Fix,Yes,Yes,Yes
13869,in the dictionary must implement,No,Yes,Yes
13873,This is needed since the notebook is stored in the object_detection folder.,,,Yes
13879,Fix MarrNet-1; but finetune 2,,,Yes
13881,Fix D; but finetune MarrNet-2,,,Yes
13883,todo: move mesh to center,,,Yes
13885,lr_scheduler cannot affect final_lr; this is a workaround to apply lr decay,,,Yes
13888,Prepare head mask if needed,,,Yes
13890,"We \""pool\"" the model by simply taking the hidden state corresponding",No,Yes,Yes
13891,Prepare head mask if needed,No,Yes,Yes
13896,"\""\""\"" || Created on Mon Oct 29 17:24:20 2018 ||  || Script: dwx_tickdata_download.py || -- || Downloads tick data from the Darwinex tick data server. This code demonstrates || how to download data for one specific date\/hour combination; but can be  || extended easily to downloading entire assets over user-specified start\/end  || datetime ranges. ||  || Requirements: Your Darwinex FTP credentials. ||  || Result: Dictionary of pandas DataFrame objects by date\/hour. ||         (columns: float([ask; size]); index: millisecond timestamp) ||          || Example code: ||  ||     > td = DWX_Tick_Data(dwx_ftp_user='very_secure_username';  ||                          dwx_ftp_pass='extremely_secure_password'; ||                          dwx_ftp_hostname='mystery_ftp.server.com';  ||                          dwx_ftp_port=21) ||      ||     > td._download_hour_(_asset='EURNOK'; _date='2018-10-22'; _hour='00') ||      ||     > td._asset_db['EURNOK-2018-10-22-00'] ||      ||                                            ask       size ||      2018-10-22 00:00:07.097000+00:00  9.47202  1000000.0 ||      2018-10-22 00:00:07.449000+00:00  9.47188   750000.0 ||      2018-10-22 00:01:08.123000+00:00  9.47201   250000.0 ||      2018-10-22 00:01:10.576000+00:00  9.47202  1000000.0 ||                                   ...        ... ||  || @author: Darwinex Labs || @twitter: https:\/\/twitter.com\/darwinexlabs || @web: http:\/\/blog.darwinex.com\/category\/labs ||  || \""\""\""",No,Yes,Yes
13900,# Table columns,No,No,Yes
13901,taking alternate columns of weights from parent1 and parent2,No,Yes,Yes
13902,taking alternate columns of weights from parent1 and parent2,No,Yes,Yes
13906,move the snake in west,,,Yes
13907,move the snake based on the result provided,No,Yes,Yes
13909,If clipping is needed; reset all values outside of [clip_min; clip_max],No,Yes,Yes
13911,Check if more modification is needed for each sample,No,Yes,Yes
13912,Set TF random seed to improve reproducibility,No,Yes,Yes
13913,Set TF random seed to improve reproducibility,,,Yes
13915,Set TF random seed to improve reproducibility,Yes,Yes,Yes
13918,Set TF random seed to improve reproducibility,No,Yes,Yes
13923,TODO: black box attacks,,,Yes
13927,In the matrices below: rows - attacks; columns - defenses.,No,No,Yes
13929,columns - second index,No,Yes,Yes
13930,"\""\""\""Helper classes and wrappers to access Google Cloud. ||  || Google Cloud API is encapsulated with these wrappers; so it's easier to || test the code with help of fake (declared in testing\/fake_cloud_client.py). || \""\""\""",No,No,Yes
13931,load and resize adversarial image if needed,No,Yes,Yes
13932,Number of work records to read at once,No,No,Yes
13933,"\""\""\""Worker which runs all computations on Cloud VMs. ||  || Evaluation of competition is split into work pieces. One work piece is a || either evaluation of an attack on a batch of images or evaluation of a || defense on a batch of adversarial images. || All pieces of attack work are independent from each other and could be run || in parallel. Same for pieces of defense work - they are independent from each || other and could be run in parallel. But defense work could be run only after || all attack work is completed. ||  || Worker first runs all attack pieces; by querying next piece of undone work || and running it. After all attack pieces are done; worker runs all defense pieces || in a similar way. ||  || Before workers could be started; datastore has to be populated by master || with description of work to be done. See master.py for details. ||  || NOTE: Worker is designed to run on linux machine with NVidia docker || installed. Worker generally needs administrative privilege to run properly. || Also worker relies on very specific directory structure created in home || directory. That's why it's highly recommended to run worker only in VM. || \""\""\""",No,Yes,Yes
13934,No class information needed.,No,Yes,Yes
13935,Get indices of relevant columns.,,,Yes
13936,Batch size is needed because the latent codes are `tf.Variable`s and,,,Yes
13938,TODO: why normal and not uniform?,,,Yes
13939,Workaround as pyrender requires number of vertices and uv coordinates to be the same,Yes,Yes,Yes
13940,arguments needed for the predicition,No,No,Yes
13941,* update at bottom to fix MacOS issue causing askopenfile() to hang,,,Yes
13943,Better handling of errors regarding operations on windows that,,,Yes
13944,MacOS fix 2,No,Yes,Yes
13948,''' || Function: || \ttrain the model || Author: || \tCharles || \u5FAE\u4FE1\u516C\u4F17\u53F7: || \tCharles\u7684\u76AE\u5361\u4E18 || ''',,,Yes
13949,''' || Function: || \tuse image recognition algorithm to play TRexRush || Author: || \tCharles || \u5FAE\u4FE1\u516C\u4F17\u53F7: || \tCharles\u7684\u76AE\u5361\u4E18 || ''',No,Yes,Yes
13950,''' || Function: || \tuse genetic algorithm to play google's t-rex rush || Author: || \tCharles || \u5FAE\u4FE1\u516C\u4F17\u53F7: || \tCharles\u7684\u76AE\u5361\u4E18 || ''',,,Yes
13952,move according to the specified direction,No,Yes,Yes
13953,TODO,Yes,Yes,Yes
13959,TODO: change to use BFS order,Yes,Yes,Yes
13962,order to prevent any memory allocation on unused GPUs,No,Yes,Yes
13963,order to prevent any memory allocation on unused GPUs,No,Yes,Yes
13964,order to prevent any memory allocation on unused GPUs,,,Yes
13965,order to prevent any memory allocation on unused GPUs,,,Yes
13966,workaround for duplicated logs in ipython,Yes,Yes,Yes
13968,hack CERTIFICATE_VERIFY_FAILED,No,Yes,Yes
13969,dropout 0.5 is needed for protein and citation (large nets),No,No,Yes
13970,dropout 0.2 is needed for conflict and metabolic (small nets),No,No,Yes
13972,"\""Using the Output Embedding to Improve Language Models\"" (Press & Wolf 2016)",No,No,Yes
13973,Insert blank columns,No,No,Yes
13974,Remove blank columns,No,Yes,Yes
13975,Overload to fix a bug for left_context,,,Yes
13976,Insert columns,,,Yes
13977,Insert columns,No,No,Yes
13980,Insert columns (Files),No,No,Yes
13981,Insert columns (Files),No,No,Yes
13982,Insert Columns (Files),,,Yes
13983,Insert Columns (Total),,,Yes
13984,Insert Columns (Files),No,No,Yes
13986,Overload scipy.stats.mannwhitneyu to fix wrong implementation,,,Yes
13988,Fix working directory on macOS,,,Yes
13989,Columns to sort,,,Yes
13992,You can just specify the packages manually here if your project is,,,Yes
13994,TODO: add check that all data is unit-normalized,,,Yes
13997,For a single thread; less memory is needed if we just store one set,No,Yes,Yes
14001,-if needed; remove predictions for classes not in current task,No,Yes,Yes
14002,-if needed (e.g.; incremental\/multihead set-up); remove predictions for classes not in replayed task,No,Yes,Yes
14003,#NAME?,,,Yes
14006,If needed (e.g.; incremental or multihead set-up); remove predictions for classes not in current task,No,Yes,Yes
14013,#NAME?,,,Yes
14016,#NAME?,,,Yes
14017,#NAME?,,,Yes
14018,#NAME?,,,Yes
14019,# perhaps this normalization should be left out??,No,No,Yes
14024,#NAME?,,,Yes
14026,todo: fix the absolute path which I'm getting from the EC2 instance,,,Yes
14030,TODO: check config,Yes,No,Yes
14031,TODO: check config,Yes,No,Yes
14032,TODO: a proper regex that the filename is valid,Yes,No,Yes
14034,TODO,Yes,Yes,Yes
14035,TODO:,,,Yes
14039,TODO:,Yes,No,Yes
14048,TODO: check that mountDir for dockerDataRoot exists,,,Yes
14050,todo: remove it; project ID is a part of a service account credentials,,,Yes
14051,TODO: [volume.mount_dir for volume in volumes],Yes,Yes,Yes
14052,TODO: gpu count check,Yes,No,Yes
14055,TODO: remove from future versions of Spotty,Yes,Yes,Yes
14056,ends with a slash,,,Yes
14060,fix for Windows machines,,,Yes
14062,TODO: restart the instance if it stopped,Yes,No,Yes
14063,"TODO: the \""spotty start\"" command should restart the instance and the container if the instance was shutdown",Yes,Yes,Yes
14064,fix for Windows machines,No,Yes,Yes
14065,TODO: apply deletion policies,,,Yes
14066,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
14067,leave only score columns,No,No,Yes
14068,TODO(sourabhbajaj): Remove this hack once we migrate the other strategies,Yes,Yes,Yes
14070,including padding if padding is needed,,,Yes
14073,only keep columns with results,No,No,Yes
14074,only keep columns with results,No,No,Yes
14075,TODO: Fix this.,,,Yes
14076,The convention in BERT is:,,,Yes
14077,'strip_unused_nodes';,No,No,Yes
14080,OSError if use tokenizer.from_pretrained directly. we need to manually rename the json file,Yes,Yes,Yes
14081,TODO: better implementation,Yes,No,Yes
14083,could maybe be avoided.,Yes,Yes,Yes
14084,and adjust num_embeddings appropriately. Other models dont have this hack,,,Yes
14086,Attention and hidden_states will be [] or None if they aren't needed,,,Yes
14087,encoder_outputs is defined. input_ids not needed,No,No,Yes
14089,unused,Yes,No,Yes
14091,this modified initialization seems to work better; but it's very hacky,Yes,Yes,Yes
14092,m.weight.data.normal_(0; 0.02 \/ n) #this modified initialization seems to work better; but it's very hacky,Yes,Yes,Yes
14093,m.weight.data.normal_(0; math.sqrt(2. \/ n)) #this modified initialization seems to work better; but it's very hacky,Yes,Yes,Yes
14094,move centroids to origin,,,Yes
14095,move centroids back,No,Yes,Yes
14096,TODO: Move the logic somewhere else?,Yes,No,Yes
14097,TODO: Make it work with heartbeat_diff,,,Yes
14099,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
14100,"TODO probably want a smarter way of detecting which values have type \""time.\""",,,Yes
14102,TODO,,,Yes
14104,TODO: implement,Yes,Yes,Yes
14105,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
14106,The convention rule is:,,,Yes
14107,`CancelledError`. This is probably because the iterator is used by,,,Yes
14109,Uses the best sample by beam search,No,Yes,Yes
14112,Creates an additional classification layer if needed,,,Yes
14115,Needed info is constant; so we construct in numpy,No,Yes,Yes
14116,This is a hack but for some reason; gather_nd return a tensor of,Yes,Yes,Yes
14118,Uses the best sample by beam search,No,Yes,Yes
14120,TODO Reimplement fs to accept GP; not mean\/std,Yes,Yes,Yes
14121,#TODO implement bounds method for each class,Yes,No,Yes
14123,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
14124,Add the first layer if needed,No,Yes,Yes
14125,concat the dataset name and the archive name to put them in the columns s,No,Yes,Yes
14127,TODO,Yes,Yes,Yes
14130,pick the feature columns,,,Yes
14132,generate label columns for training data,,,Yes
14135,TODO for debug,Yes,No,Yes
14136,val is a list of 192 - 50 = 142 bi-dimensional array (50 rows x 25 columns),No,Yes,Yes
14137,columns,No,No,Yes
14138,maybe sklearn,,,Yes
14139,TODO: use nce,,,Yes
14140,maybe should be changed for another archs,Yes,Yes,Yes
14141,from -- bigger means better shuffling but slower start up and more,Yes,No,Yes
14142,rename columns,No,Yes,Yes
14143,rename columns,,,Yes
14145,Its dirty but sometimes the API fails and this is the easiest fix,Yes,Yes,Yes
14146,TODO,,,Yes
14156,TODO el loss continua bajando con mas de 10000 iteraciones; definir un numero mayor,Yes,Yes,Yes
14158,TODO add the weights depending on labels,,,Yes
14159,"feature_columns = [tf.contrib.layers.real_valued_column(\""\""; dimension=len(train_data[0]))]",,,Yes
14163,TODO give more weigth to anomaly classes? We want to detect always these bad anomalies,,,Yes
14164,compute full conjunctive combination (could be more efficient),,,Yes
14165,TODO Remove High Freqs,Yes,Yes,Yes
14166,Protocol version 2 was introduced in Python 2.3. It provides much more efficient pickling of new-style classes.,,,Yes
14167,TODO Save as: ?,Yes,No,Yes
14170,TODO assert that the class_ID appears with the desired order;,Yes,Yes,Yes
14172,TODO normalice to make sum up to 1?,Yes,Yes,Yes
14175,TODO Write data oversampled!,,,Yes
14176,TODO Export StandardScaler(),Yes,No,Yes
14178,TODO... continuar esta idea..abs,,,Yes
14181,TODO how compute the confident factor for the evidence??,Yes,No,Yes
14183,TODO g-mean?,Yes,Yes,Yes
14185,Univariate feature selection works by selecting the best features based on univariate statistical tests.,No,Yes,Yes
14186,Scikit-learn exposes feature selection routines as objects that implement the transform method:,,,Yes
14189,TODO: Some kind of preprocesing or clean high frequency noise?,,,Yes
14193,TODO implement this method! check to avoid NaN scores....,Yes,Yes,Yes
14195,TODO: Scale,Yes,Yes,Yes
14197,TODO: InstanceNorm,Yes,No,Yes
14198,TODO: use InstanceNorm,,,Yes
14199,TODO: useInstanceNorm,,,Yes
14200,TODO: Scale,,,Yes
14201,TODO: support padding types,,,Yes
14202,TODO: InstanceNorm,Yes,No,Yes
14203,TODO: use InstanceNorm,Yes,No,Yes
14204,TODO: useInstanceNorm,Yes,No,Yes
14205,TODO: Scale,Yes,Yes,Yes
14206,TODO: support padding types,Yes,No,Yes
14207,TODO: InstanceNorm,Yes,No,Yes
14208,TODO: use InstanceNorm,Yes,No,Yes
14212,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
14213,The convention in BERT is:,No,No,Yes
14215,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
14216,The convention in BERT is:,No,No,Yes
14221,The convention in BERT is:,No,No,Yes
14226,TODO,,,Yes
14228,Heron's formula for area #FIXME why the *2 ? Heron formula is without *2 It's the 0.5 than appears in the (0.5(cotalphaij + cotbetaij)),,,Yes
14229,fix seed,No,Yes,Yes
14230,fix seed,No,Yes,Yes
14232,TODO Change Dataloader : works -> Add release tag,Yes,Yes,Yes
14233,TODO Fix seed,Yes,Yes,Yes
14236,TODO add cool new scripts from CycleConsistentCorrespondence,Yes,Yes,Yes
14237,TODO add Theo's work as a Flag,,,Yes
14240,TODO add nice logging,Yes,Yes,Yes
14241,TODO,,,Yes
14242,TODO Change Dataloader : works -> Add release tag,,,Yes
14244,TODO add arg_parse file,Yes,Yes,Yes
14246,TODO add cool new scripts from CycleConsistentCorrespondence,,,Yes
14247,TODO add Theo's work as a Flag,,,Yes
14250,TODO add nice logging,Yes,Yes,Yes
14254,TODO : remove random here,Yes,No,Yes
14256,TODO : In dataset surreal. Keep only the loading of two large files,Yes,Yes,Yes
14257,TODO : try to make things multi-gpu friendly and try it,Yes,Yes,Yes
14259,TODO : the goal here is to ponder chamfer with area of triangles.,Yes,Yes,Yes
14260,TODO : remove random here,Yes,No,Yes
14262,TODO for what i want,Yes,No,Yes
14263,self.results.drop(self.results.columns[self.results.columns.str.contains('unnamed';case = False)];axis = 1; inplace = True),No,Yes,Yes
14265,code redundancy is introduced; however; this approach allows for,Yes,Yes,Yes
14268,TODO: can be computed in vector,,,Yes
14271,Here's where we define the internals of the efficient bottleneck layer,,,Yes
14275,Naturally; we implement the shutdown logic in `__del__` of,Yes,Yes,Yes
14277,So it is unclear to me (@ssnl) why this is needed in a finally block.,,,Yes
14280,TODO: add limited pickling support for sharing an iterator,Yes,Yes,Yes
14282,copyright notice and this permission notice appear in all copies.,No,No,Yes
14287,TODO: wheels and setup.py if wheel fails,,,Yes
14289,TODO: pynomaly speed comparison repo. use travis to run analysis code with various versions,,,Yes
14291,todo,Yes,No,Yes
14292,\u534F\u65B9\u5DEE\u77E9\u9635\u7684\u9006\u77E9\u9635  todo,Yes,Yes,Yes
14293,todo #\u53E5\u5B50\u6539\u5199\uFF0C\u540C\u4E49\u8BCD\u66FF\u6362\uFF0C\u53BB\u505C\u7528\u8BCD\u7B49,,,Yes
14295,todo \u540C\u4E49\u8BCD\u5178\u904D\u5386\u751F\u6210,,,Yes
14301,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
14303,TODO: Predict with validate dataset,,,Yes
14304,TODO: Example,Yes,No,Yes
14306,TODO: Example,,,Yes
14308,"TODO: Remove \""-1\"" or not",,,Yes
14310,TODO: [6] which contains bias,,,Yes
14313,TODO take image as a factor,,,Yes
14314,Default to big-endian; I like it better,No,Yes,Yes
14317,TODO; too dangerous here,,,Yes
14318,TODO what if url does not starts with 'http'?,Yes,Yes,Yes
14319,TODO too verbose to define two times;,,,Yes
14320,find a better way,Yes,Yes,Yes
14321,TODO try bootstrap embed-responsive-item,Yes,Yes,Yes
14322,TODO add last-updated,,,Yes
14323,TODO add last-updated,Yes,Yes,Yes
14325,TODO; this is only an ad-hoc for https:\/\/pdf.yt\/d\/jHuhj9FsOC-o9Uap,Yes,Yes,Yes
14326,TODO cannot fetch image from washingtonpost,Yes,Yes,Yes
14327,TODO what if image is encoded in data:image\/png;base64?,,,Yes
14328,TODO sort text according to their layouts,,,Yes
14329,TODO fix warning here (when keys is empty),Yes,Yes,Yes
14330,TODO tooooo inefficient,Yes,Yes,Yes
14331,TODO tooooooo redundant,Yes,No,Yes
14332,TODO should I consider auto_commit?,,,Yes
14333,TODO too verbose to define two times;,Yes,Yes,Yes
14335,TODO query.delete will fire a delete from; which won't delete,Yes,Yes,Yes
14340,"TODO add support for other units like: \""em\""; \""ex\""; \""px\""; \""in\""; \""cm\""; \""mm\""; \""pt\""; \""pc\""; \""%\""",,,Yes
14341,XXX: this is optional,,,Yes
14342,XXX: It must be renamed to benchmark.tar to be extracted.,,,Yes
14344,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",No,No,Yes
14345,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",,,Yes
14346,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",,,Yes
14347,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",No,No,Yes
14348,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",No,No,Yes
14349,"\""\""\"" || Summary:  mnist dnn pytorch example.  ||           te_err around 2%.  || Author:   Qiuqiang Kong || Usage:    $ CUDA_VISIBLE_DEVICES=1 python test9.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-3 ||           $ python mnist_dnn_pt.py train --init_type=glorot_uniform --optimizer=adam --loss=softmax --lr=1e-4 --resume_model_path=\""models\/md_3000iters.tar\"" || Created:  2017.12.09 || Modified: 2017.12.12 || \""\""\""",,,Yes
14350,"if self.ends(\""abli\""):      self.r(\""able\"")",,,Yes
14354,!TODO: Write a function to interpolate images with different pyhsical spacing,Yes,No,Yes
14356,!TODO: Print infos about the images when verbose flag is set,Yes,Yes,Yes
14357,!TODO: Add silent flag,,,Yes
14358,!TODO: Make sure that this can be used as included script,,,Yes
14359,!TODO: No real header is created for this image; fix,Yes,Yes,Yes
14360,!TODO: Move to utilities package,,,Yes
14364,!TODO: Apply the intersection window also for this to deal with different,,,Yes
14365,!TODO: Old version of labels_reduce which speed depends on the number of labels;,Yes,No,Yes
14367,!TODO: In some cases; US is not enough to hold the complete number,Yes,Yes,Yes
14368,!TODO: Add silent flag,Yes,No,Yes
14370,!TODO: When the distance matrix is already calculated here,Yes,Yes,Yes
14371,points and then it would be good to have them. What is better?,No,Yes,Yes
14373,!TODO: Move to utilities package,Yes,Yes,Yes
14378,10.5ms # !The shorter (e.g. uin8) the input data; the better!,,,Yes
14379,10.5ms # !The shorter (e.g. uin8) the input data; the better!,,,Yes
14381,!TODO: Implement,,,Yes
14384,!TODO: uint as dtype might here be better -> how to detmerine the range that is needed?,,,Yes
14387,compute edges for the far columns,No,No,Yes
14389,All classes\/applications\/scripts in this sub-package make use of some ITK and\/or VTK function or depend on functionality that uses them,No,Yes,Yes
14393,!TODO: When the distance matrix is already calculated here,,,Yes
14396,"\""\""\"" || @package medpy.graphcut.generate || Provides functionality to generate graphs efficiently from nD label-images. ||  || Functions: ||     - def graph_from_labels((label_image; ||                       fg_markers; ||                       bg_markers; ||                       regional_term = False; ||                       boundary_term = False; ||                       regional_term_args = False; ||                       boundary_term_args = False): Creates a Graph object from a nD label image. || @author Oskar Maier || @version d0.1.0 || @since 2012-01-18 || @status Development || \""\""\""",,,Yes
14397,!TODO: An empty dictionary would actually also do here ... despite the fact that,,,Yes
14401,"\""\""\"" || @package medpy.graphcut.cut || Prepares; compiles and executed graph-cut implementations using the graphs created by || the graph module of this package. ||  || Note that the functionality provided by this module depends highly on the platform; the || availability of 3rd party tools and executes foreign code. It should only be used when || completely understood. Otherwise manual execution of this step is preferable. ||  || All functions in this module are highly depend on the actual implementation of the || graph-cut algorithm they are intended to be used for. They require a minimal version || number and it can not be ensured; that they will work with other versions. ||  || See the package description for a list of the supported graph-cut implementations. ||  || Functions: ||     - def bk_mfmc_cut(source_file; gpp_location = False): Execute a graph cut using Boyov and ||                                                           Kolmogorovs max-flow\/min-cut algorithm. ||  || @author Oskar Maier || @version d0.1.0 || @since 2012-01-18 || @status Development || \""\""\""",No,Yes,Yes
14403,!TODO: Imprive the execution time of this step,Yes,Yes,Yes
14407,compute edges for the far columns,No,No,Yes
14408,"\""\""\"" || @package medpy.graphcut.parse || Parses the output returned by graph-cut implementations. ||  || When the cut module of this package has been used or a manual execution of the supported || graph-cut algorithms has been undertaken; the functionalities provided by this module can || be used to parse the results and apply it to the original images.  ||  || All functions in this module are highly depend on the actual implementation of the || graph-cut algorithm they are intended to be used for. They require a minimal version || number and it can not be ensured; that they will work with other versions. ||  || See the package description for a list of the supported graph-cut implementations. ||  || Functions: ||     - def bk_mfmc_parse(output): Parse the output of Boyov and Kolmogorovs max-flow\/min-cut algorithm. ||  || @author Oskar Maier || @version d0.1.0 || @since 2012-01-18 || @status Development || \""\""\""",No,Yes,Yes
14420,note: saving as *.nii does not work; why I do not now; probably the,,,Yes
14421,POSSIBILITY 1: guess the number of edges (in the best situation is faster but requires a little bit more memory. In the worst is slower.),No,No,Yes
14423,"\""\""\"" || @package medpy.io.save || Provides functionality connected with image saving. ||      || The supplied methods hide more complex usage of a number of third party modules. ||  || @author Oskar Maier || @version d0.1.0 || @since 2012-05-28 || @status Development || \""\""\""",,,Yes
14424,arr = arr.copy() #!TODO: See if this might still be necessary; even after copying the header,Yes,Yes,Yes
14428,!TODO: I only have to do this in the range of the atlas objects!,,,Yes
14430,generic fixed to 0.0 (single threshold),,,Yes
14431,!TODO: Is it at all possible to give a version here? Which one do I have?,,,Yes
14434,!TODO: Change to not work with the Exceptions anymore; as these hides bugs!,,,Yes
14438,"\""\""\"" || @package medpy.features.utilities || Utilities for feature handling. ||  || @author Oskar Maier || @version r0.1.0 || @since 2013-08-24 || @status Release || \""\""\""",,,Yes
14439,"\""\""\"" || @package medpy.metric.image || Provides a number of image distance and similarity measures. ||  || @author Oskar Maier || @version r0.1.0 || @since 2013-07-09 || @status Release || \""\""\""",No,No,Yes
14440,!TODO: Update these imports,Yes,Yes,Yes
14441,"\""\""\"" || Unittest for the medpy.graphcut 's graph cut algorithm approach. || Essentially executes the whole pipeline from a supplied label image; foreground markers || and background markers over graph construction; cut execution until the final || re-labelling of the original label image. || One test if performed with the region bases; and one with the voxel based term. || The test is conducted with an artificial boundary term. ||  || @author Oskar Maier || @version r0.1.2 || @since 2011-01-29 || @status Release || \""\""\""",No,Yes,Yes
14448,"\""\""\"" || @package medpy.filter.binary || Filters for binary images. ||  || Provides a number of filter that implement functionality for binary images only. ||  || Functions: ||      ||  || @author Oskar Maier || @version d0.1.1 || @since 2013-10-14 || @status Development || \""\""\""",,,Yes
14450,!TODO: Figure out if a fixed sigma is desirable here... I think that yes,Yes,Yes,Yes
14451,variance[variance < variance_global \/ 10.] = variance_global \/ 10. #!TODO: Should I keep this i.e. regularizing the variance to be at least 10% of the global one?,,,Yes
14455,"\""\""\"" || @package medpy.filter.noise || Global and local noise estimator filters. ||  || @author Oskar Maier || @version r0.1.0 || @since 2014-03-20 || @status Release || \""\""\""",No,No,Yes
14457,!TODO: Use the value defined in scikit-learn here; rather than defining it by myself,,,Yes
14459,FIXME: handle other kinds of assignments?,,,Yes
14460,"\""\""\"" Turn compiler.ast structures back into executable python code. ||  ||     The unparse method takes a compiler.ast tree and transforms it back into ||     valid python code.  It is incomplete and currently only works for ||     import statements; function calls; function definitions; assignments; and ||     basic expressions. ||  ||     Inspired by python-2.5-svn\/Demo\/parser\/unparse.py ||  ||     fixme: We may want to move to using _ast trees because the compiler for ||            them is about 6 times faster than compiler.compile. || \""\""\""",,,Yes
14461,fixme: Are From and ImportFrom handled differently?,,,Yes
14462,Check if parenthesis are needed on left side and then dispatch,No,Yes,Yes
14464,#        # XXX(jpe) what is level for?,,,Yes
14466,Fix unsupported image types using the PIL.,,,Yes
14468,TODO extention options,Yes,No,Yes
14469,## FUNCTIONALITY FOR CONDITIONAL C++ BUILD,,,Yes
14471,@TODO: there is a very strong relation to the border handle if the texture is very small (1px),,,Yes
14472,calculate differences by using Sobel-filter. (Maybe other filter kernel like Prewitt will do a better job),No,No,Yes
14473,TODO: For option b; remove the - 1; better: no option b; since I am rounding later anyway,Yes,Yes,Yes
14474,!TODO: this does not load the meta-data; find a way to load it from a series; too,Yes,Yes,Yes
14475,Needed for reshaping.,No,Yes,Yes
14476,TODO(irving;ebrevdo): This reshape is needed because,Yes,Yes,Yes
14477,pad them if needed; reverse encoder inputs and add GO to decoder.,No,Yes,Yes
14478,Assumes meteor-1.5.jar is in the same directory as meteor.py.  Change as needed.,,,Yes
14480,arrays needed for the iteration,No,Yes,Yes
14482,Iterate over the columns,No,Yes,Yes
14483,Determine the number of digits that are needed to encode all the labels in a column,No,Yes,Yes
14484,Iterate over the columns and fit an Imputer on the rows grouped by the classes in y,,,Yes
14485,Determine the columns that represent features,No,No,Yes
14487,((n_classes - 1) * n_models) columns have to be stored,,,Yes
14488,min_samples (int): List of columns to be combined.,No,Yes,Yes
14489,smoothing (float): Orders to which columns should be combined.,No,Yes,Yes
14490,if self.columns is None:,,,Yes
14492,for combo in itertools.combinations(self.columns; order):,,,Yes
14494,columns as there are models. However; if use_probas is True then,No,Yes,Yes
14495,((n_classes - 1) * n_models) columns have to be stored,No,No,Yes
14496,Default to using all the categorical columns,No,Yes,Yes
14497,TODO: log \u6BCF\u4E00\u7C7B\u7684\u6982\u7387,No,No,Yes
14498,"\""\""\"" || This is HardNet local patch descriptor. The training code is based on PyTorch TFeat implementation || https:\/\/github.com\/edgarriba\/examples\/tree\/master\/triplet || by Edgar Riba. ||  || If you use this code; please cite  || @article{HardNet2017; ||  author = {Anastasiya Mishchuk; Dmytro Mishkin; Filip Radenovic; Jiri Matas}; ||     title = \""{Working hard to know your neighbor's margins:Local descriptor learning loss}\""; ||      year = 2017} || (c) 2017 by Anastasiia Mishchuk; Dmytro Mishkin  || \""\""\""",No,Yes,Yes
14499,order to prevent any memory allocation on unused GPUs,,,Yes
14500,hack to speed up process,,,Yes
14501,"\""\""\"" || This is HardNet local patch descriptor. The training code is based on PyTorch TFeat implementation || https:\/\/github.com\/edgarriba\/examples\/tree\/master\/triplet || by Edgar Riba. ||  || If you use this code; please cite  || @article{HardNet2017; ||  author = {Anastasiya Mishchuk; Dmytro Mishkin; Filip Radenovic; Jiri Matas}; ||     title = \""{Working hard to know your neighbor's margins:Local descriptor learning loss}\""; ||      year = 2017} || (c) 2017 by Anastasiia Mishchuk; Dmytro Mishkin  || \""\""\""",No,Yes,Yes
14502,order to prevent any memory allocation on unused GPUs,,,Yes
14503,"\""\""\"" || This is HardNet local patch descriptor. The training code is based on PyTorch TFeat implementation || https:\/\/github.com\/edgarriba\/examples\/tree\/master\/triplet || by Edgar Riba. ||  || If you use this code; please cite || @article{HardNet2017; ||  author = {Anastasiya Mishchuk; Dmytro Mishkin; Filip Radenovic; Jiri Matas}; ||     title = \""{Working hard to know your neighbor's margins:Local descriptor learning loss}\""; ||      year = 2017} || (c) 2017 by Anastasiia Mishchuk; Dmytro Mishkin || \""\""\""",,,Yes
14506,order to prevent any memory allocation on unused GPUs,No,Yes,Yes
14507,hack to speed up process,Yes,No,Yes
14509,order to prevent any memory allocation on unused GPUs,No,Yes,Yes
14513,"\""\""\""Deterministic Policy Gradient Algorithm. ||  || This module demonstrates DPG on-policy model on the environment || with continuous action space in OpenAI Gym. ||  || - Author: Curt Park || - Contact: curt.park@medipixel.io || - Paper: http:\/\/proceedings.mlr.press\/v32\/silver14.pdf || \""\""\""",,,Yes
14514,"\""\""\""Deep Deterministic Policy Gradient Algorithm. ||  || This module demonstrates DDPG model on the environment || with continuous action space in OpenAI Gym. ||  || - Author: Curt Park || - Contact: curt.park@medipixel.io || - Paper: https:\/\/arxiv.org\/pdf\/1509.02971.pdf || \""\""\""",,,Yes
14515,"\""\""\""Trust Region Policy Optimization Algorithm. ||  || This module demonstrates TRPO model on the environment || with continuous action space in OpenAI Gym. ||  || - Author: Curt Park || - Contact: curt.park@medipixel.io || - Paper: http:\/\/arxiv.org\/abs\/1502.05477 || \""\""\""",No,Yes,Yes
14518,"\""\""\""Deep Deterministic Policy Gradient Algorithm. ||  || This module demonstrates DDPG model on the environment || with continuous action space in OpenAI Gym. ||  || - Author: Curt Park || - Contact: curt.park@medipixel.io || - Paper: https:\/\/arxiv.org\/pdf\/1509.02971.pdf || \""\""\""",No,Yes,Yes
14519,"\""\""\""Deterministic Policy Gradient Algorithm. ||  || This module demonstrates DPG on-policy model on the environment || with continuous action space in OpenAI Gym. ||  || - Author: Curt Park || - Contact: curt.park@medipixel.io || - Paper: http:\/\/proceedings.mlr.press\/v32\/silver14.pdf || \""\""\""",,,Yes
14522,"\""\""\""MLP module for model of algorithms ||  || - Author: Kh Kim || - Contact: kh.kim@medipixel.io || - Reference: https:\/\/github.com\/vitchyr\/rlkit\/blob\/master\/rlkit\/torch\/networks.py || \""\""\""",,,Yes
14524,"\""\""\""MLP module for model of algorithms ||  || - Author: Kh Kim || - Contact: kh.kim@medipixel.io || \""\""\""",No,Yes,Yes
14525,pre-training if needed,No,Yes,Yes
14527,pre-training if needed,,,Yes
14528,TODO: Check assert case and fix bug,Yes,No,Yes
14531,pre-training if needed,,,Yes
14535,XXX burn,Yes,Yes,Yes
14536,XXX burn with callbacks,Yes,Yes,Yes
14537,XXX leftover,,,Yes
14539,XXX continue path,Yes,Yes,Yes
14541,XXX different margins???,,,Yes
14542,Evil hack,Yes,No,Yes
14543,XXX different margins???,,,Yes
14544,XXX continue path,,,Yes
14545,Add non default cli params if needed (see argparse std lib),,,Yes
14548,XXX assumes startwidth == endwidth,,,Yes
14551,small fix,,,Yes
14552,unused,Yes,No,Yes
14554,XXX \/ uutounit(self; 1.0; 'in'),No,Yes,Yes
14555,XXX self.calc_unit_factor(),,,Yes
14558,"\""\""\"" || \/** ||  * @name Pulley ||  * @category Printed ||  * @using 1 x m3 nut; normal or nyloc ||  * @using 1 x m3x10 set screw or 1 x m3x8 grub screw ||  *\/ ||  ||  || \/\/ tuneable constants ||  || teeth = 8;\t\t\t\/\/ Number of teeth; standard Mendel T5 belt = 8; gives Outside Diameter of 11.88mm || profile = 6;\t\t\/\/ 1=MXL 2=40DP 3=XL 4=H 5=T2.5 6=T5 7=T10 8=AT5 9=HTD_3mm 10=HTD_5mm 11=HTD_8mm 12=GT2_2mm 13=GT2_3mm 14=GT2_5mm ||  || motor_shaft = 5.2;\t\/\/ NEMA17 motor shaft exact diameter = 5 || m3_dia = 3.2;\t\t\/\/ 3mm hole diameter || m3_nut_hex = 1;\t\t\/\/ 1 for hex; 0 for square nut || m3_nut_flats = 5.7;\t\/\/ normal M3 hex nut exact width = 5.5 || m3_nut_depth = 2.7;\t\/\/ normal M3 hex nut exact depth = 2.4; nyloc = 4 ||  || retainer = 0;\t\t\/\/ Belt retainer above teeth; 0 = No; 1 = Yes || retainer_ht = 1.5;\t\/\/ height of retainer flange over pulley; standard = 1.5 || idler = 0;\t\t\t\/\/ Belt retainer below teeth; 0 = No; 1 = Yes || idler_ht = 1.5;\t\t\/\/ height of idler flange over pulley; standard = 1.5 ||  || pulley_t_ht = 12;\t\/\/ length of toothed part of pulley; standard = 12 || pulley_b_ht = 8;\t\t\/\/ pulley base height; standard = 8. Set to same as idler_ht if you want an idler but no pulley. || pulley_b_dia = 20;\t\/\/ pulley base diameter; standard = 20 || no_of_nuts = 1;\t\t\/\/ number of captive nuts required; standard = 1 || nut_angle = 90;\t\t\/\/ angle between nuts; standard = 90 || nut_shaft_distance = 1.2;\t\/\/ distance between inner face of nut and shaft; can be negative. ||  ||  || \/\/\t******************************** || \/\/\t** Scaling tooth for good fit ** || \/\/\t******************************** || \/*\tTo improve fit of belt to pulley; set the following constant. Decrease or increase by 0.1mm at a time. We are modelling the *BELT* tooth here; not the tooth on the pulley. Increasing the number will *decrease* the pulley tooth size. Increasing the tooth width will also scale proportionately the tooth depth; to maintain the shape of the tooth; and increase how far into the pulley the tooth is indented. Can be negative *\/ ||  || additional_tooth_width = 0.2; \/\/mm ||  || \/\/\tIf you need more tooth depth than this provides; adjust the following constant. However; this will cause the shape of the tooth to change. ||  || additional_tooth_depth = 0; \/\/mm ||  || \/\/ calculated constants ||  || nut_elevation = pulley_b_ht\/2; || m3_nut_points = 2*((m3_nut_flats\/2)\/cos(30)); \/\/ This is needed for the nut trap ||  || \/\/ The following set the pulley diameter for a given number of teeth ||  || MXL_pulley_dia = tooth_spacing (2.032;0.254); || 40DP_pulley_dia = tooth_spacing (2.07264;0.1778); || XL_pulley_dia = tooth_spacing (5.08;0.254); || H_pulley_dia = tooth_spacing (9.525;0.381); || T2_5_pulley_dia = tooth_spaceing_curvefit (0.7467;0.796;1.026); || T5_pulley_dia = tooth_spaceing_curvefit (0.6523;1.591;1.064); || T10_pulley_dia = tooth_spacing (10;0.93); || AT5_pulley_dia = tooth_spaceing_curvefit (0.6523;1.591;1.064); || HTD_3mm_pulley_dia = tooth_spacing (3;0.381); || HTD_5mm_pulley_dia = tooth_spacing (5;0.5715); || HTD_8mm_pulley_dia = tooth_spacing (8;0.6858); || GT2_2mm_pulley_dia = tooth_spacing (2;0.254); || GT2_3mm_pulley_dia = tooth_spacing (3;0.381); || GT2_5mm_pulley_dia = tooth_spacing (5;0.5715); ||  || \/\/ The following calls the pulley creation part; and passes the pulley diameter and tooth width to that module ||  || if ( profile == 1 ) { pulley ( \""MXL\"" ; MXL_pulley_dia ; 0.508 ; 1.321 ); } || if ( profile == 2 ) { pulley ( \""40 D.P.\"" ; 40DP_pulley_dia ; 0.457 ; 1.226 ); } || if ( profile == 3 ) { pulley ( \""XL\"" ; XL_pulley_dia ; 1.27; 3.051 ); } || if ( profile == 4 ) { pulley ( \""H\"" ; H_pulley_dia ;1.905 ; 5.359 ); } || if ( profile == 5 ) { pulley ( \""T2.5\"" ; T2_5_pulley_dia ; 0.7 ; 1.678 ); } || if ( profile == 6 ) { pulley ( \""T5\"" ; T5_pulley_dia ; 1.19 ; 3.264 ); } || if ( profile == 7 ) { pulley ( \""T10\"" ; T10_pulley_dia ; 2.5 ; 6.13 ); } || if ( profile == 8 ) { pulley ( \""AT5\"" ; AT5_pulley_dia ; 1.19 ; 4.268 ); } || if ( profile == 9 ) { pulley ( \""HTD 3mm\"" ; HTD_3mm_pulley_dia ; 1.289 ; 2.27 ); } || if ( profile == 10 ) { pulley ( \""HTD 5mm\"" ; HTD_5mm_pulley_dia ; 2.199 ; 3.781 ); } || if ( profile == 11 ) { pulley ( \""HTD 8mm\"" ; HTD_8mm_pulley_dia ; 3.607 ; 6.603 ); } || if ( profile == 12 ) { pulley ( \""GT2 2mm\"" ; GT2_2mm_pulley_dia ; 0.764 ; 1.494 ); } || if ( profile == 13 ) { pulley ( \""GT2 3mm\"" ; GT2_3mm_pulley_dia ; 1.169 ; 2.31 ); } || if ( profile == 14 ) { pulley ( \""GT2 5mm\"" ; GT2_5mm_pulley_dia ; 1.969 ; 3.952 ); } ||  || \/\/ Functions ||  || function tooth_spaceing_curvefit (b;c;d) || \t= ((c * pow(teeth;d)) \/ (b + pow(teeth;d))) * teeth ; ||  || function tooth_spacing(tooth_pitch;pitch_line_offset) || \t= (2*((teeth*tooth_pitch)\/(3.14159265*2)-pitch_line_offset)) ; ||  || \/\/ Main Module ||  || module pulley( belt_type ; pulley_OD ; tooth_depth ; tooth_width ) || \t{ || \techo (str(\""Belt type = \"";belt_type;\""; Number of teeth = \"";teeth;\""; Pulley Outside Diameter = \"";pulley_OD;\""mm \"")); || \ttooth_distance_from_centre = sqrt( pow(pulley_OD\/2;2) - pow((tooth_width+additional_tooth_width)\/2;2)); || \ttooth_width_scale = (tooth_width + additional_tooth_width ) \/ tooth_width; || \ttooth_depth_scale = ((tooth_depth + additional_tooth_depth ) \/ tooth_depth) ; ||  ||  || \/\/\t************************************************************************ || \/\/\t*** uncomment the following line if pulley is wider than puller base *** || \/\/\t************************************************************************ ||  || \/\/\ttranslate ([0;0; pulley_b_ht + pulley_t_ht + retainer_ht ]) rotate ([0;180;0]) ||  || \tdifference() || \t {\t  || \t\tunion() || \t\t{ || \t\t\t\/\/base || \t || \t\t\tif ( pulley_b_ht < 2 ) { echo (\""CAN'T DRAW PULLEY BASE; HEIGHT LESS THAN 2!!!\""); } else { || \t\t\t\trotate_extrude($fn=pulley_b_dia*2) || \t\t\t\t{ || \t\t\t\t\t\tsquare([pulley_b_dia\/2-1;pulley_b_ht]); || \t\t\t\t\t\tsquare([pulley_b_dia\/2;pulley_b_ht-1]); || \t\t\t\t\t\ttranslate([pulley_b_dia\/2-1;pulley_b_ht-1]) circle(1); || \t\t\t\t} || \t\t\t} || \t || \t\tdifference() || \t\t\t{ || \t\t\t\/\/shaft - diameter is outside diameter of pulley || \t\t\t || \t\t\ttranslate([0;0;pulley_b_ht])  || \t\t\trotate ([0;0;360\/(teeth*4)])  || \t\t\tcylinder(r=pulley_OD\/2;h=pulley_t_ht; $fn=teeth*4); || \t || \t\t\t\/\/teeth - cut out of shaft || \t\t || \t\t\tfor(i=[1:teeth])  || \t\t\trotate([0;0;i*(360\/teeth)]) || \t\t\ttranslate([0;-tooth_distance_from_centre;pulley_b_ht -1])  || \t\t\tscale ([ tooth_width_scale ; tooth_depth_scale ; 1 ])  || \t\t\t{ || \t\t\tif ( profile == 1 ) { MXL();} || \t\t\tif ( profile == 2 ) { 40DP();} || \t\t\tif ( profile == 3 ) { XL();} || \t\t\tif ( profile == 4 ) { H();} || \t\t\tif ( profile == 5 ) { T2_5();} || \t\t\tif ( profile == 6 ) { T5();} || \t\t\tif ( profile == 7 ) { T10();} || \t\t\tif ( profile == 8 ) { AT5();} || \t\t\tif ( profile == 9 ) { HTD_3mm();} || \t\t\tif ( profile == 10 ) { HTD_5mm();} || \t\t\tif ( profile == 11 ) { HTD_8mm();} || \t\t\tif ( profile == 12 ) { GT2_2mm();} || \t\t\tif ( profile == 13 ) { GT2_3mm();} || \t\t\tif ( profile == 14 ) { GT2_5mm();} || \t\t\t} ||  || \t\t\t} || \t\t\t || \t\t\/\/belt retainer \/ idler || \t\tif ( retainer > 0 ) {translate ([0;0; pulley_b_ht + pulley_t_ht ])  || \t\trotate_extrude($fn=teeth*4)   || \t\tpolygon([[0;0];[pulley_OD\/2;0];[pulley_OD\/2 + retainer_ht ; retainer_ht];[0 ; retainer_ht];[0;0]]);} || \t\t || \t\tif ( idler > 0 ) {translate ([0;0; pulley_b_ht - idler_ht ])  || \t\trotate_extrude($fn=teeth*4)   || \t\tpolygon([[0;0];[pulley_OD\/2 + idler_ht;0];[pulley_OD\/2 ; idler_ht];[0 ; idler_ht];[0;0]]);} || \t || \t\t} || \t    || \t\t\/\/hole for motor shaft || \t\ttranslate([0;0;-1])cylinder(r=motor_shaft\/2;h=pulley_b_ht + pulley_t_ht + retainer_ht + 2;$fn=motor_shaft*4); || \t\t\t\t || \t\t\/\/captive nut and grub screw holes || \t || \t\tif ( pulley_b_ht < m3_nut_flats ) { echo (\""CAN'T DRAW CAPTIVE NUTS; HEIGHT LESS THAN NUT DIAMETER!!!\""); } else { || \t\tif ( (pulley_b_dia - motor_shaft)\/2 < m3_nut_depth + 3 ) { echo (\""CAN'T DRAW CAPTIVE NUTS; DIAMETER TOO SMALL FOR NUT DEPTH!!!\""); } else { || \t || \t\t\tfor(j=[1:no_of_nuts]) rotate([0;0;j*nut_angle]) || \t\t\ttranslate([0;0;nut_elevation])rotate([90;0;0]) || \t || \t\t\tunion() || \t\t\t{ || \t\t\t\t\/\/entrance || \t\t\t\ttranslate([0;-pulley_b_ht\/4-0.5;motor_shaft\/2+m3_nut_depth\/2+nut_shaft_distance]) cube([m3_nut_flats;pulley_b_ht\/2+1;m3_nut_depth];center=true); || \t || \t\t\t\t\/\/nut || \t\t\t\tif ( m3_nut_hex > 0 ) || \t\t\t\t\t{ || \t\t\t\t\t\t\/\/ hex nut || \t\t\t\t\t\ttranslate([0;0.25;motor_shaft\/2+m3_nut_depth\/2+nut_shaft_distance]) rotate([0;0;30]) cylinder(r=m3_nut_points\/2;h=m3_nut_depth;center=true;$fn=6); || \t\t\t\t\t} else { || \t\t\t\t\t\t\/\/ square nut || \t\t\t\t\t\ttranslate([0;0.25;motor_shaft\/2+m3_nut_depth\/2+nut_shaft_distance]) cube([m3_nut_flats;m3_nut_flats;m3_nut_depth];center=true); || \t\t\t\t\t} || \t || \t\t\t\t\/\/grub screw hole || \t\t\t\trotate([0;0;22.5])cylinder(r=m3_dia\/2;h=pulley_b_dia\/2+1;$fn=8); || \t\t\t} || \t\t}} || \t } || \t    || \t} ||  ||  || \/\/ Tooth profile modules || \""\""\""",No,Yes,Yes
14559,Add non default cli params if needed (see argparse std lib),,,Yes
14564,Change settings of default edges if needed. E.g.:,No,No,Yes
14566,move down \/ left before,No,Yes,Yes
14567,Move back down,No,Yes,Yes
14568,Move right,No,Yes,Yes
14570,XXX,,,Yes
14571,Add non default cli params if needed (see argparse std lib),,,Yes
14572,XXX,No,Yes,Yes
14574,XXX be smarter about space,Yes,Yes,Yes
14578,Add non default cli params if needed (see argparse std lib),,,Yes
14581,Add non default cli params if needed (see argparse std lib),,,Yes
14582,Add non default cli params if needed (see argparse std lib),No,Yes,Yes
14584,Add non default cli params if needed (see argparse std lib),No,Yes,Yes
14586,Add non default cli params if needed (see argparse std lib),No,Yes,Yes
14587,XXX util::speed_of_sound(self.air_temperature); \/\/ in m\/s,No,Yes,Yes
14588,edges needed on the top for this wall segment,No,Yes,Yes
14590,XXX,No,Yes,Yes
14592,XXX,No,Yes,Yes
14594,Add non default cli params if needed (see argparse std lib),No,Yes,Yes
14595,Add non default cli params if needed (see argparse std lib),,,Yes
14596,Fix previous edge length,No,Yes,Yes
14597,Upper: second tab width if needed,No,No,Yes
14600,Add non default cli params if needed (see argparse std lib),,,Yes
14601,Add non default cli params if needed (see argparse std lib),No,Yes,Yes
14602,Fix previous edge length,,,Yes
14607,TODO TODO TODD0,Yes,Yes,Yes
14608,TODO TODO TODO TODO TODO,Yes,Yes,Yes
14609,TODO ADD learning_rate,Yes,Yes,Yes
14611,TODO,,,Yes
14612,"self.b_projection = tf.get_variable(\""b_projection\""; shape=[self.num_classes])  #TODO [label_size]",,,Yes
14613,TODO o.k to use batch_size in first demension?,Yes,No,Yes
14614,400 TODO,Yes,Yes,Yes
14620,TODO ADD ONE e.g.[2;12;13;10],Yes,Yes,Yes
14621,#TODO ADD ONE e.g.[2;12;13;10],Yes,Yes,Yes
14623,TODO binary=True,,,Yes
14627,attention. [batch_size;num_units*4]. TODO add multi-head 2018-05-31,Yes,Yes,Yes
14628,h = tf.concat([h; sentence_encoded2]; axis=1) #TODO add 2018-05-27,,,Yes
14629,('last_hidden_state2:'; (LSTMStateTuple(c=<tf.Tensor 'bi_lstm_uni_lstm\/rnn\/while\/Exit_3:0' shape=(128; 128) dtype=float32>; #TODO why has two last hidden states.,Yes,Yes,Yes
14631,TODO bi-gram. [batch_size;2;hidden_size],Yes,Yes,Yes
14634,TODO need update,,,Yes
14635,[batch_size;seq_length;num_units]. TODO NEED ADD multiply SCALE V_a.,Yes,Yes,Yes
14637,TODO add normalize number ADD 2018.06.11,Yes,Yes,Yes
14638,TODO add normalize number ADD 2018.06.11,,,Yes
14640,#TODO ADD ONE e.g.[2;12;13;10],Yes,Yes,Yes
14642,TODO [batch;?;hidden_size*2] ADD 2018.07.02,,,Yes
14644,Y_deathpenalty.append(y_deathpenalty) #TODO REMOVE 2018.07.02,Yes,No,Yes
14645,TODO,Yes,Yes,Yes
14647,Y_deathpenalty.append(y_deathpenalty) #TODO REMOVE 2018.07.02,Yes,No,Yes
14648,TODO,Yes,Yes,Yes
14649,TODO add normalize number ADD 2018.06.11,Yes,Yes,Yes
14650,TODO add 2018.07.04,,,Yes
14653,TODO,,,Yes
14656,TODO add 2018.07.04,Yes,No,Yes
14658,TODO add normalize number ADD 2018.06.11,,,Yes
14659,todo you need use this line,Yes,Yes,Yes
14660,TODO here should be: 'data_valid_checked.json',,,Yes
14661,TODO here should be: 'cail2018_big.json',Yes,No,Yes
14662,TODO add 2018-05-27,,,Yes
14663,word_attention=tf.concat([word_attention;word_encodeded2];axis=1) #TODO add 2018-05-27,Yes,No,Yes
14665,h = tf.concat([h; sentence_encoded2]; axis=1) #TODO add 2018-05-27,Yes,Yes,Yes
14669,TODO double num_filters,Yes,Yes,Yes
14671,TODO bi-gram. [batch_size;2;hidden_size],,,Yes
14673,h_article_concated=tf.concat([h;h_accusation];axis=-1) #TODO [batch;?;hidden_size*2] ADD 2018.07.02,Yes,Yes,Yes
14674,h_article = tf.nn.dropout(h_article;keep_prob=self.dropout_keep_prob) # TODO ADD 2018.07.02,Yes,No,Yes
14676,h_deathpenalty = tf.nn.dropout(h_deathpenalty;keep_prob=self.dropout_keep_prob) # TODO ADD 2018.07.02,,,Yes
14677,h_lifeimprisonment = tf.nn.dropout(h_lifeimprisonment;keep_prob=self.dropout_keep_prob) # TODO ADD 2018.07.02,Yes,No,Yes
14684,TODO e.g.[2;12;13;10],Yes,Yes,Yes
14685,dictt['imprisonment'] =imprisonment #TODO,Yes,Yes,Yes
14688,if csv_save_path was given; the xxx.csv file will be saved,No,Yes,Yes
14689,TODO PSROIPOOL ANALYSIS,Yes,Yes,Yes
14690,TODO scale analysis,,,Yes
14691,TODO optimizer passed in,Yes,No,Yes
14692,TODO learning rate change function,,,Yes
14693,TODO horizontal flip,Yes,Yes,Yes
14695,TODO: view,,,Yes
14696,TODO: UpsamplingNearest2d,Yes,No,Yes
14699,Caffe Implement BatchNorm = BatchNorm + Affine,No,Yes,Yes
14700,TODO: View,Yes,No,Yes
14701,"\""\""\"" || How to support a new layer type: ||  layer_name=log.add_layer(layer_type_name) ||  top_blobs=log.add_blobs(<output of that layer>) ||  layer=caffe_net.Layer_param(xxx) ||  <set layer parameters> ||  [<layer.add_data(*datas)>] ||  log.cnet.add_layer(layer) || \""\""\""",No,No,Yes
14703,TODO dilation;ceil_mode;return indices,Yes,Yes,Yes
14704,TODO w;h different kernel; stride and padding,,,Yes
14706,TODO: reshpae added to nn_tools layer,Yes,Yes,Yes
14708,TODO: the batch size!=1 view operations,,,Yes
14711,TODO max in one tensor,Yes,Yes,Yes
14712,TODO Dear user; please change these paths:,Yes,No,Yes
14714,TODO specify target path: where should Stylized-ImageNet be stored?,,,Yes
14717,TODO: update,,,Yes
14719,TODO: Could make it sparse also? Well; maybe not... at the beginning it's quite non-sparse,Yes,Yes,Yes
14720,TODO: Can we make a fast non-tree version of update in the AISTATS paper?,Yes,Yes,Yes
14725,TODO: figure out why Unicode sometimes causes an issue with loading after pickling,Yes,Yes,Yes
14726,TODO: make this faster; it's slower than it should be,Yes,Yes,Yes
14730,RLE is a simple yet efficient format for storing binary masks. RLE,,,Yes
14731,If a (top-k) sequence ends early in decoding; `h_n` contains,No,Yes,Yes
14732,temporary patch because of pretrainedmodels bug,,,Yes
14733,Assumes meteor-1.5.jar is in the same directory as meteor.py.  Change as needed.,No,Yes,Yes
14734,Assumes spice.jar is in the same directory as spice.py.  Change as needed.,,,Yes
14736,M_inv: Inverted normalized transformation matrix --> Needed for grid sample,No,No,Yes
14737,TODO check this,,,Yes
14739,trapezium mask not needed for only two lanes,No,Yes,Yes
14741,trapezium mask not needed for only two lanes,No,Yes,Yes
14744,TODO get acc,Yes,Yes,Yes
14747,TODO check intersections,Yes,Yes,Yes
14749,TODO check this,,,Yes
14750,TODO : use torch.inverse over batch (is possible since pytorch 1.0.0),,,Yes
14753,todo: accurate Value,,,Yes
14755,Ploting (To-do),,,Yes
14757,Todo: create file which contains all supported activation,,,Yes
14758,TODO: Check if path is unique if not then don't evaluate this ant,Yes,Yes,Yes
14759,TODO: introduce pheromone importance,,,Yes
14760,TODO: Generate hash value to save memory space,Yes,Yes,Yes
14761,Todo: create file which contains all supported activation,Yes,Yes,Yes
14762,TODO: add support for average,Yes,Yes,Yes
14763,"Workaround to prevent Keras from throwing an exception (\""All layer names should be unique.\"")",,,Yes
14764,If old model is better then skip this sub-path,,,Yes
14765,Restore the weights if performance did not improve,No,Yes,Yes
14767,I am using `.trim()`; It would be better to do this in the plot itself.,Yes,Yes,Yes
14768,Also probably better to do the sizing in the plot too.,No,Yes,Yes
14769,capture a list of columns that will be used for prediction,No,Yes,Yes
14772,implement early stopping,,,Yes
14773,implement early stopping,No,Yes,Yes
14779,todo: change this to use append; and concatenate along columns,,,Yes
14780,we'll need number of variables for each for the labels; maybe by running it once and checking width this is a good idea at the fit stage; run on one series;,No,Yes,Yes
14781,todo: change this to use append; and concatenate along columns,,,Yes
14782,make sure the number of labels corresponds to the number of columns in X,No,No,Yes
14784,todo,Yes,No,Yes
14787,Support for this is coming with Keras; however; in a feature rep pipeline this would involve,No,Yes,Yes
14790,todo: implement advance X,Yes,Yes,Yes
14793,todo: remove np array,Yes,Yes,Yes
14794,todo: reconstruct tensor ts,,,Yes
14797,calculates the homography matrix needed to convert between,No,Yes,Yes
14799,\t# make tuple of needed metaclasses in specified priority order,,,Yes
14800,\tif needed_metas in memoized_metaclasses_map:,No,No,Yes
14801,\t\treturn memoized_metaclasses_map[needed_metas],No,Yes,Yes
14802,\t# nope: compute; memoize and return needed conflict-solving meta,,,Yes
14804,\telif len(needed_metas) == 1:  # another trivial case,No,No,Yes
14805,\t\tmeta = needed_metas[0],,,Yes
14806,\telif needed_metas == bases:,,,Yes
14808,\t\tmetaname = '_' + ''.join([m.__name__ for m in needed_metas]),No,Yes,Yes
14809,\t\tmeta = classmaker()(metaname; needed_metas; {}),,,Yes
14810,\t\tmemoized_metaclasses_map[needed_metas] = meta,No,Yes,Yes
14812,TODO: \u52A0\u5165\u66F4\u591A\u540C\u540D\u4E0D\u540C\u5B9E\u4F53\u7684\u6D88\u6B67\u7B56\u7565,,,Yes
14817,move the predicted boundary to the nearest original one to align,No,Yes,Yes
14818,and this results in NaN's. A workaround is to add a very small positive number \u03B5 to the sum.,Yes,No,Yes
14819,and this results in NaN's. A workaround is to add a very small positive number \u03B5 to the sum.,Yes,No,Yes
14820,todo,,,Yes
14824,Fix this...,,,Yes
14825,Training - [5452 rows x 66 columns],,,Yes
14828,"text = \""How much would it cost to purchase a 2-foot-square party tent ; with sides ; ?\""",,,Yes
14832,-- Hack for ReadTheDocs ------------------------------------------------------,Yes,Yes,Yes
14834,"\""\""\"" || This is a skeleton file that can serve as a starting point for a Python || console script. To run this script uncomment the following line in the || entry_points section in setup.cfg: ||  ||     console_scripts = ||      fibonacci = qas.skeleton:run ||  || Then run `python setup.py install` which will install the command `fibonacci` || inside your current environment. || Besides console scripts; the header (i.e. until _logger...) of this file can || also be used as template for Python modules. ||  || Note: This skeleton file can be safely removed if not needed! || \""\""\""",No,Yes,Yes
14835,"\""\""\"" || This is a skeleton file that can serve as a starting point for a Python || console script. To run this script uncomment the following line in the || entry_points section in setup.cfg: ||  ||     console_scripts = ||      fibonacci = qas.skeleton:run ||  || Then run `python setup.py install` which will install the command `fibonacci` || inside your current environment. || Besides console scripts; the header (i.e. until _logger...) of this file can || also be used as template for Python modules. ||  || Note: This skeleton file can be safely removed if not needed! || \""\""\""",No,Yes,Yes
14837,"\""\""\"" || start_time = time() || en_nlp = spacy.load(\""en_core_web_md\"") || dta = pandas.read_csv('corpus\/qclassifier_trainer.csv'; sep='|') || # get_data_info(dta) ||  || y = dta.pop('Class') || dta.pop('#Question') || dta.pop('WH-Bigram') ||  || X_train = pre_process(dta) ||  || # print(X_train.shape) ||  || # print(len(column_list)) ||  || question = 'Who is Linus Torvalds ?' || # question = 'What is the colour of apple ?' || en_doc = en_nlp(u'' + question) ||  || question_data = get_question_predict_data(en_doc) || X_predict = pre_process(question_data) || # print(X_predict) || # print(X_train) ||  || X_train; X_predict = transform_data_matrix(X_train; X_predict) ||  || # print(naive_bayes_classifier(X_train; y; X_predict)) || print(support_vector_machine(X_train; y; X_predict)) || end_time = time() || print(\""Total time :\""; end_time - start_time) || \""\""\""",No,No,Yes
14838,FIXME: No support for negations with conjunctions,,,Yes
14839,xpe.img_extract()     # TODO: Save with Elasticsearch,,,Yes
14840,TODO change the signs from '>=' to '==' like we did on adam_qas\/requirements.txt,,,Yes
14842,pad the height if needed,,,Yes
14843,A hack for now; later I'll fork my own dataset API,Yes,Yes,Yes
14844,Maybe we need to delete a previous checkpoint,No,Yes,Yes
14845,pad the width if needed,,,Yes
14847,HACK to preserve backwards compatibility,Yes,Yes,Yes
14849,TODO(jerry): discounting can be done better\/more efficient,Yes,Yes,Yes
14850,For now let's fix discrete action space; I'll generalize it later,,,Yes
14851,For now let's fix discrete action space; I'll generalize it later,,,Yes
14852,This probably should be moved to the buffer?,Yes,No,Yes
14855,XXX(john): remove timelimit argument after gym is upgraded to allow double wrapping,,,Yes
14857,I'm quite unsure if this is the right way to combine these; but this is what paper seems to be suggesting,Yes,Yes,Yes
14858,and I don't know any better way.,,,Yes
14859,"TODO: Record \""full_oof_predictions\""",Yes,Yes,Yes
14860,"TODO: Record \""full_holdout_predictions\""",Yes,Yes,Yes
14863,FLAG: Try to implement something like below to ensure other attributes aren't modified (except predictions by Predictors),Yes,Yes,Yes
14864,"TODO: Look into \""from tabulate import tabulate\"" tables for temporary advanced logging",,,Yes
14868,Now; lets perform another Experiment that does a bit better than our intentionally miserable one,,,Yes
14869,TODO: Add confusion matrix example,,,Yes
14870,"TODO: If \""G.Env.save_full_predictions is True\""; add callbacks to record full_predictions for the 3 dataset types",Yes,Yes,Yes
14871,# TODO: Switch from below direct calls to preprocessor.execute_pipeline() call,,,Yes
14875,TODO: ... Either 1) Set `runs` = 1 (this would mess with the environment key); or...,Yes,Yes,Yes
14876,TODO: ... 2) Set the results of all subsequent runs to the results of the first run (this could be difficult),,,Yes
14878,self.full_test_predictions = 0  # (n_splits * n_repeats * runs) intermediate columns,,,Yes
14879,self.full_holdout_predictions = 0  # (n_splits * n_repeats * runs) intermediate columns,,,Yes
14880,TODO: Call self.intra_cv_preprocessing() - Ensure the 4 fold input\/target attributes (from on_fold_start) are changed,Yes,No,Yes
14881,TODO: Instead of forcing len() == 2; merge self.fitting_guide into self.pipeline.,,,Yes
14882,TODO: Max valid length == 4 after adding fit_sets(subset of transform_sets); transform_sets,Yes,Yes,Yes
14883,TODO: If len > 4; throw WARNING that extra values will be ignored and continue,Yes,Yes,Yes
14885,"TODO: New method name should be something like: \""__dynamic_pipeline_method_{}\"".format(step[1].__name__ or i)",,,Yes
14886,TODO: Actual name that would be called would be mangled because of double underscore prefix,,,Yes
14888,"TODO: Make changes to \""name\"" here",Yes,Yes,Yes
14891,TODO: Combine `path` and `key` to produce actual filepaths,,,Yes
14892,# TODO: Update this to iterate through contents of `experiments_dir_path`; for each do:,,,Yes
14894,# TODO: Make clearer distinction between supplying an Experiment vs a filepath,Yes,Yes,Yes
14895,TODO: Resolve cases where `data` contains an aliased column for a metric; but the current experiment uses the,Yes,Yes,Yes
14898,"TODO: Fix documentation of \""Returns\"" section to be in line with those of the rest of the project",,,Yes
14899,"TODO: Can probably remove \""return_list\"" kwarg",Yes,No,Yes
14900,TODO: Consider adding Dict[str; str],Yes,Yes,Yes
14901,None - No sub-columns specified,,,Yes
14902,Iterables of ints; specifying min size for individual sub-columns,No,Yes,Yes
14904,Default min size for all sub-columns,No,No,Yes
14912,TODO: Add `reporting_type` as kwarg to `__init__`; with options: logging; advanced,Yes,Yes,Yes
14915,TODO: Finish this,,,Yes
14918,TODO: This isn't working,,,Yes
14919,"\""\""\"" || May actually be faster to do an isinstance check for a str path || $ python -m timeit -s \""x = [1]\"" \""x[0]\"" || 10000000 loops; best of 3: 0.0207 usec per loop || $ python -m timeit -s \""x = [1]\"" \""try: x[0] \ || except: pass\"" || 10000000 loops; best of 3: 0.029 usec per loop || $ python -m timeit -s \""x = [1]\"" \""try: x[1] \ || except: pass\"" || 1000000 loops; best of 3: 0.315 usec per loop || # setting up try\/except is fast; only around 0.01us || # actually triggering the exception takes almost 10x as long || $ python -m timeit -s \""x = [1]\"" \""isinstance(x; basestring)\"" || 10000000 loops; best of 3: 0.141 usec per loop || $ python -m timeit -s \""x = [1]\"" \""isinstance(x; str)\"" || 10000000 loops; best of 3: 0.131 usec per loop || $ python -m timeit -s \""x = [1]\"" \""try: x.split('.')\ ||  except: pass\"" || 1000000 loops; best of 3: 0.443 usec per loop || $ python -m timeit -s \""x = [1]\"" \""try: x.split('.') \ || except AttributeError: pass\"" || 1000000 loops; best of 3: 0.544 usec per loop || \""\""\""",,,Yes
14923,TODO: enter() return (False; items) to continue traverse but cancel copy?,,,Yes
14924,TODO: handle False?,,,Yes
14925,TODO: typecheck?,,,Yes
14926,TODO: recollect(),Yes,No,Yes
14928,TODO: reiter(),Yes,No,Yes
14930,TODO: Figure out way to override skopt Optimizer's use of skopt Space without having to rewrite __init__,Yes,Yes,Yes
14931,TODO: importer.hook_keras_layer,Yes,No,Yes
14932,TODO: Add documentation,Yes,Yes,Yes
14934,TODO: Fill in documentation,Yes,No,Yes
14935,TODO: Add documentation,Yes,Yes,Yes
14937,TODO: Add documentation,Yes,Yes,Yes
14938,TODO: Fill in documentation description,Yes,No,Yes
14939,TODO: Shouldn't be default behavior to include `eval_set` below - Results in unexpectedly long execution times - Rework,Yes,Yes,Yes
14941,TODO: Finish documentation once UninformedOptimizationProtocol bugs have been squished,Yes,Yes,Yes
14943,TODO: If keras isn't available at all; `pass` - Wasn't installed by user,Yes,Yes,Yes
14947,TODO: Below only works on modified Keras `build_fn` during optimization if temp file still exists,,,Yes
14948,TODO: Above only works on modified Keras `build_fn` during optimization if temp file still exists,,,Yes
14949,"\""\""\""This module performs additional processing necessary when optimizing hyperparameters in the `Keras` library. Its purpose is || twofold: 1) to enable the construction of Keras models while requiring minimal syntactic changes on the user's end when defining || hyperparameter space choices; and 2) to enable thorough collection of all hyperparameters used to define a Keras model - not only || those being optimized - in order to ensure the continued usefulness of an Experiment's result files even under different || hyperparameter search constraints ||  || Related || ------- || :mod:`hyperparameter_hunter.importer` ||     Performs interception of `Keras` import to inject the hyperparameter-recording attributes || :mod:`hyperparameter_hunter.tracers` ||     Defines the new metaclass used by :mod:`hyperparameter_hunter.importer` to apply to key Keras classes (like `Layer`) || :mod:`hyperparameter_hunter.utils.parsing_utils` ||     Defines utilities to assist in parsing source code provided by users to declare Keras model-building functions || :mod:`hyperparameter_hunter.library_helpers.keras_helper` ||     Defines utilities to assist in characterizing Keras models\""\""\""",No,Yes,Yes
14950,################### Fix Duplicated Names ####################,Yes,No,Yes
14951,"prefix_regex = r\""[_\\.A-Za-z0-9]\""  # TODO: Support prefixes - To cover import aliases or importing modules to call classes",Yes,No,Yes
14956,TODO: Try to hash this; instead,,,Yes
14957,TODO: Add documentation,Yes,Yes,Yes
14958,Miscellaneous Unused Utilities,Yes,No,Yes
14967,TODO: Layer selection not fully supported,,,Yes
14968,"\""\""\""This module is the core of all of the experimentation in `hyperparameter_hunter`; hence its name. It is impossible to || understand :mod:`hyperparameter_hunter.experiments` without first having a grasp on what || :meta:`hyperparameter_hunter.experiment_core.ExperimentMeta` is doing. This module serves to bridge the gap between Experiments; || and :mod:`hyperparameter_hunter.callbacks` by dynamically making Experiments inherit various callbacks depending on the inputs || given in order to make Experiments completely functional ||  || Related || ------- || :mod:`hyperparameter_hunter.experiments` ||     Defines the structure of the experimentation process. While certainly very important; :mod:`hyperparameter_hunter.experiments` ||     wouldn't do much at all without :mod:`hyperparameter_hunter.callbacks`; or :mod:`hyperparameter_hunter.experiment_core` || :mod:`hyperparameter_hunter.callbacks` ||     Defines classes used as parents to the classes defined in :mod:`hyperparameter_hunter.experiments`. This not only makes it ||     very easy to find the entire workflow for a given task; but also ensures that each instance of an Experiment inherits exactly ||     the functionality that it needs. For example; if no holdout data was given; then :meta:`experiment_core.ExperimentMeta` will ||     not add :class:`callbacks.evaluators.EvaluatorHoldout`; and :class:`callbacks.predictors.PredictorHoldout` to the list of ||     callbacks inherited by the Experiment. This means that the Experiment never needs to check for the existence of holdout data ||     in order to determine how it should proceed because it literally doesn't have the code that deals with holdout data ||  || Notes || ----- || Was a metaclass really necessary here? Probably not; but it's being used for two reasons: 1) metaclasses are fun; and programming ||     (especially artificial intelligence) should be fun; and 2) it allowed for a very clean separation between the various ||     functions demanded by Experiments that are provided by :mod:`hyperparameter_hunter.callbacks`. Having each of the callbacks ||     separated in their own classes makes it very easy to debug existing functionality; and to add new callbacks in the future\""\""\""",,,Yes
14969,TODO: Add documentation,,,Yes
14974,"\""\""\""This module contains utilities for building and executing unit tests; as well as for reporting the results ||  || Related || ------- || :mod:`hyperparameter_hunter.tests` ||     This module contains all unit tests for the library; and it uses :mod:`hyperparameter_hunter.utils.test_utils` throughout\""\""\""",No,No,Yes
14975,# TODO: Add Sentinel to handle wrapping of xgboost `eval_metric` if used,Yes,No,Yes
14976,Now think about how much better your hyperparameter optimization will be when it learns from:,No,Yes,Yes
14978,"\""\""\""This module contains extra callbacks that can add commonly-used functionality to Experiments. || This module also serves as an example for how users can properly construct their own custom || callbacks using :func:`hyperparameter_hunter.callbacks.bases.lambda_callback` ||  || Related || ------- || :mod:`hyperparameter_hunter.callbacks.bases` ||     This module defines :func:`hyperparameter_hunter.callbacks.bases.lambda_callback`; which is how ||     all extra callbacks created in :mod:`hyperparameter_hunter.callbacks.recipes` are created || :mod:`hyperparameter_hunter.environment` ||     This module provides the means to use custom callbacks made by ||     :func:`hyperparameter_hunter.callbacks.bases.lambda_callback` through the `experiment_callbacks` ||     argument of :meth:`hyperparameter_hunter.environment.Environment.__init__`\""\""\""",,,Yes
14980,TODO: Note that; unlike `confusion_matrix_holdout`; this allows `lambda_callback` to automatically aggregate stats,Yes,Yes,Yes
14981,TODO: Note that; unlike `confusion_matrix_oof`; this manually handles aggregating stats,Yes,Yes,Yes
14984,"\""\""\""This module defines assorted general-use utilities used throughout the library. The contents are || primarily small functions that perform oft-repeated tasks. This module also defines deprecation || utilities; namely :class:`Deprecated`; which is used to deprecate callables ||  || Related || ------- || :mod:`hyperparameter_hunter.exceptions` ||     Defines the deprecation warnings issued by :class:`Deprecated`\""\""\""",No,Yes,Yes
14985,TODO: If string; or None; lookup callable in `sklearn.metrics`,Yes,Yes,Yes
14987,TODO: ??????????????????????????????????????????????????,No,No,Yes
14989,TODO: Fix how `key_handler` deals with instances of :class:`metrics.Metric`,Yes,No,Yes
14991,"TODO: If `sort`-ing chronologically; can use the \""experiment_#\"" column in leaderboard",,,Yes
14993,TODO: Add repetition count,Yes,Yes,Yes
14995,TODO: Prepend rep count,Yes,No,Yes
14996,TODO: Below is bugged - Does not work with minimized metrics,Yes,No,Yes
15012,TODO: If so; pass extra kwargs to below `make_hash_sha256`; which are eventually given to `hash_callable`,,,Yes
15013,TODO: Notably; `ignore_source_lines=True` should be included,Yes,Yes,Yes
15015,"... minimum to achieve full library functionality. Furthermore; \""leaderboards\"" is an invalid",,,Yes
15016,This class adds a new leaderboard file that sorts entries according to all non-id columns,,,Yes
15017,Custom recorders must subclass `recorders.BaseRecorder`; and implement these four abstract items:,No,No,Yes
15018,The reason for breaking this convention is that the JSON description file doesn't exist at the,,,Yes
15023,TODO: `drop_duplicates`' `keep` kwarg may be helpful if lb rows are sorted chronologically,Yes,Yes,Yes
15024,TODO: ... https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.drop_duplicates.html,,,Yes
15025,All the parameters necessary for the desired preprocessing functionality,,,Yes
15026,List containing strings that specify the columns to be used as input,No,No,Yes
15027,# TODO: Instead of forcing len() == 2; merge self.fitting_guide into self.pipeline.,Yes,Yes,Yes
15028,# TODO: Max valid length == 4 after adding fit_sets(subset of transform_sets); transform_sets,Yes,Yes,Yes
15031,"# TODO: New method name should be something like: \""__dynamic_pipeline_method_{}\"".format(step[1].__name__ or i)",Yes,Yes,Yes
15032,# TODO: Actual name that would be called would be mangled because of double underscore prefix,,,Yes
15036,"_name = name + \""\""  # TODO: Make changes to \""name\"" here",,,Yes
15038,# TODO: Modify fitting process to use 'which_sets' and 'self.fit_input_sets' like 'data_imputation' method,,,Yes
15040,(empty_tuple; _in_fold; _oof; _holdout);  # TODO: ORIGINAL: Might be valid now - No metrics,,,Yes
15041,({empty_tuple: roc_auc_score}; _in_fold; _oof; _holdout);  # TODO: ORIGINAL: Raises nothing; but probably should,,,Yes
15042,"({\""roc_auc_score\"": (\""a\""; \""b\"")}; _in_fold; _oof; _holdout);  # TODO: ORIGINAL: Raises AttributeError (`a`) instead of TypeError",Yes,Yes,Yes
15045,TODO: Assert that custom result files have been recorded,Yes,Yes,Yes
15046,"assert lb.columns[0] == f\""oof_{request.param}\""",No,Yes,Yes
15047,TODO: Assert that custom result files have been recorded,,,Yes
15051,TODO: Might need to wrap dummy build_fns in `KerasClassifier\/Regressor` - That is what actually happens,,,Yes
15053,TODO: 1-26-19 - Actually is hashing below instance; but doesn't save source anywhere - Probably because un-traced objects,Yes,Yes,Yes
15058,TODO: Replace above two with `general_utils.subdict` call that modifies key to a slice,,,Yes
15061,TODO: Replace above with `general_utils.subdict` call that modifies key to a slice,Yes,Yes,Yes
15063,TODO: Replace above with `general_utils.subdict`,,,Yes
15065,"...  # TODO: Execute all steps in \""pre_cv\"" stage",Yes,Yes,Yes
15067,"FLAG: Tally number of columns \""transformed\"" and \""added\"" at each step and report",,,Yes
15068,def _compare_hash_(columns_a: dict; columns_b: dict):,,,Yes
15069,columns_a,No,No,Yes
15071,columns_added = dict(),,,Yes
15072,columns_dropped = dict(),,,Yes
15073,columns_modified = dict(),,,Yes
15075,def compare_dataset_columns(datasets_a: dict; datasets_b: dict):,,,Yes
15078,TODO: Move their validations to properties here,,,Yes
15079,TODO: Below only works on modified Keras `build_fn` during optimization if temp file still exists,Yes,No,Yes
15080,TODO: Also; check `a_mirror.original_full_path` somehow; or object equality,,,Yes
15081,TODO: Above only works on modified Keras `build_fn` during optimization if temp file still exists,Yes,Yes,Yes
15082,TODO: Assert that custom result files have been recorded,Yes,Yes,Yes
15085,TODO: Remove requirement for input arguments and return names to match,,,Yes
15086,"self.evaluate(\""oof\""; self.data_oof.target.d; self.data_oof.prediction.rep)  # TODO: Should use this when collecting transformed targets",Yes,Yes,Yes
15088,"\""holdout\""; self.holdout_data.T.target.final; self.data_holdout.prediction.final  # TODO: Should use this when collecting transformed targets",,,Yes
15090,return _confusion_matrix(data_oof.target.final; data_oof.prediction.rep)  # TODO: Should use this when collecting transformed targets,Yes,Yes,Yes
15091,return _confusion_matrix(data_oof.target.final; data_oof.prediction.final)  # TODO: Should use this when collecting transformed targets,Yes,Yes,Yes
15093,data_holdout.target.final; data_holdout.prediction.final  # TODO: Should use this when collecting transformed targets,Yes,Yes,Yes
15097,TODO: Input chunks\/wranglers probably unnecessary; since their 2 jobs are done by `CVExperiment`,Yes,Yes,Yes
15102,TODO: Input chunks\/wranglers probably unnecessary; since their 2 jobs are done by `CVExperiment`,Yes,Yes,Yes
15104,TODO: Input chunks\/wranglers probably unnecessary; since their 2 jobs are done by `CVExperiment`,Yes,Yes,Yes
15105,"\""\""\""This module defines callbacks that descend from || :class:`~hyperparameter_hunter.callbacks.bases.BasePredictorCallback`. Predictor wrangler callbacks || are concerned with managing the prediction chunks of an experiment's datasets. This module acts as a || liaison between :class:~hyperparameter_hunter.experiments.BaseCVExperiment` and the prediction chunk || classes defined in :mod:`hyperparameter_hunter.data.data_chunks.prediction_chunks`. Each callback || defined herein is responsible for ensuring the proper execution of precisely one descendant of || :class:`~hyperparameter_hunter.data.data_chunks.prediction_chunks.BasePredictorChunk`; defined in || :mod:`~hyperparameter_hunter.data.data_chunks.prediction_chunks`. ||  || Predictors are the busiest of all three wrangler callbacks. While we only actually get predictions || when we first hit `on_run_end`; we need to keep track of them across runs; folds and reps; so || predictions need to be cleared out during the \""...start\"" callback methods. There are two || mission-critical tasks for which we need predictions: 1) Evaluation against targets; and || 2) Recording - not only to ensure our model is behaving as expected; but also for ensembling. || Ensembling is a real pain if you're trying to do it; using only evaluation metrics as a guide; and || re-running selected experiments so you can save the predictions this time; just to figure out if || the ensemble actually performs in the end. ||  || Once again; feature engineering throws a monkey-wrench into our expectations for the predictor || callbacks. If we're performing any kind of target transformation (which is often the case); then || evaluations need to be made using transformed predictions and targets. Calculating f1-score would || not go well if we tried to give the metric function the stringified iris dataset labels of || \""setosa\""; \""versicolor\""; or \""virginica\"". It's gonna want the transformed; numerical representation || of the targets. Similarly; averaging predictions across divisions uses transformed predictions || because it requires values that can actually be averaged. For the purposes of recording; we may || want either transformed or inverted (original form) prediction - or both. Lots of weird things || start misbehaving in lots of confusing ways if our predictor wranglers aren't carefully managing || predictions across all the experiment's divisions; and in both forms: transformed; and || inverted (original form). ||  || Related || ------- || :mod:`hyperparameter_hunter.data.data_chunks.prediction_chunks` ||     Defines the prediction data chunk classes; each of which has one counterpart\/handler defined in ||     :mod:`~hyperparameter_hunter.callbacks.wranglers.predictors`\""\""\""",No,Yes,Yes
15109,Very nice spot from Tilii : https:\/\/www.kaggle.com\/tilii7,No,Yes,Yes
15113,"\""\""\""This module tests performance of hyperparameter optimization on feature engineering steps\""\""\""",,,Yes
15116,TODO: Make sure this doesn't screw up when no `inverse_transform` call,Yes,No,Yes
15118,"\""\""\""This module tests that the `optimizer` of informed Optimization Protocols is `tell`-ed about || hyperparameters in their proper format. ||  || The tests herein are regression tests for a bug that would cause Optimization Protocols to break at || some point on (or after) the tenth optimization round when attempting to invoke || `self.optimizer.tell` with `EngineerStep`s still formatted as dicts; rather than proper instances. ||  || This bug was a bit tricky to track down for a few reasons: || 1. Limited to `Categorical` optimization of `EngineerStep`\/functions within `FeatureEngineer` || 2. Limited to results being read in from saved experiment description files || 3. Following #2; required that the optimization protocol in question be preceded by either: ||     * Another optimization protocol whose search space was compatible with the current space; or ||     * An experiment; whose result would fit in the current search space || 4. Only came up on (or after) the 10th optimization round; so limited to protocols with 10 or more ||    samples || 5. Despite #4; this was not necessarily the optimization round that actually caused the error - ||    in fact; it usually wasn't ||  || See PR #139 (https:\/\/github.com\/HunterMcGushion\/hyperparameter_hunter\/pull\/139)\""\""\""",Yes,Yes,Yes
15121,"\""\""\""This module defines utilities for comparing versions of the library; as well as deprecation || utilities; namely :class:`Deprecated` ||  || Related || ------- || :mod:`hyperparameter_hunter.exceptions` ||     Defines the deprecation warnings issued by :class:`Deprecated`\""\""\""",,,Yes
15123,TODO: Basically only enforcing correct main segment; since not using `re.fullmatch`,Yes,Yes,Yes
15124,TODO: Probably want `re.fullmatch` here - Currently ignoring any potentially invalid suffix,,,Yes
15125,"TODO: Add `condition=\""__version__ < '...'\""` to `xfail` when supported",Yes,Yes,Yes
15126,"\""\""\""This example is a classic shotgun approach to hyperparameter optimization. As the script's name || suggests; you'll need to install the wonderful `imblearn` library. The only \""problem\"" with || `imblearn` is that they have way too many fascinating and useful re-sampling techniques! How could || we ever choose one; and just call our search over? Let's not do that. Instead; we'll choose 18 and || let HyperparameterHunter figure out the best `imblearn` tool for this problem. ||  || All of the 18 engineer step functions follow the same pattern and use the `_sampler_helper` function || defined at the top; so once you've seen one of them; you've pretty much seen them all. Then just || scroll all the way to the bottom of the script to see the actual optimization part!\""\""\""",No,Yes,Yes
15128,TODO: Rename to `remaining_n_points`,,,Yes
15130,TODO: Clean up below - Looks like the 4 extend\/append blocks may be duplicated,Yes,Yes,Yes
15132,TODO: Rename `values` - Maybe `utilities`?,,,Yes
15133,TODO: Add docstring,Yes,No,Yes
15134,XXX scale + 1. might not actually be a float after scale if scale is very large,,,Yes
15135,XXX: The distribution is for sampling in the transformed space.,No,Yes,Yes
15137,TODO: Below behavior seems odd. If categories=[1; 3; 5; 7]; then `transformed_size`=1,Yes,Yes,Yes
15139,TODO: Below `any` should prolly be `all`,Yes,Yes,Yes
15141,`ask` returns random points; which is why `x0` and `x1` must be different,No,Yes,Yes
15143,TODO: This breaks if `Integer.rvs` called with `n_samples`=None - Raises TypeError,Yes,No,Yes
15145,"`transform=\""identity\""`; so apparently there's a good reason for it...",No,Yes,Yes
15146,TODO: Use `learning_utils.get_breast_cancer_data`. Will need to change expected `env_keys`,Yes,Yes,Yes
15147,TODO: Refactor horrifying section above - Was this before past-Hunter knew about indirectly,,,Yes
15149,TODO: Move above to new prep method that can be called before `go` - Called by `go` if not,,,Yes
15152,TODO: Add option to print table of all candidates and their `match_status` values,Yes,Yes,Yes
15153,TODO: Remove below once loss_functions are hashed in description files,Yes,Yes,Yes
15154,`pd.util.hash_pandas_object` ignores columns; so return them as well,No,Yes,Yes
15155,TODO: Also; check `a_mirror.original_full_path` somehow; or object equality,Yes,Yes,Yes
15159,Maybe we're feeling a bit confused; though. Which Experiment attributes do we need for our next,,,Yes
15162,FIXME: using numpy.roll with a random shift might be faster,Yes,Yes,Yes
15164,TODO: modify this to use embedding,,,Yes
15166,Quick hack to create folders,Yes,Yes,Yes
15167,is needed for .scatter(),,,Yes
15169,TODO: breaks if nets are not identical,,,Yes
15170,TODO: won't copy buffers; e.g. for batch norm,Yes,Yes,Yes
15172,TODO: determine dummy data shape automatically,Yes,Yes,Yes
15173,Move to device,,,Yes
15176,TODO: determine dummy data shape automatically,Yes,Yes,Yes
15180,TODO: implement dot_product and other non-local formats,Yes,Yes,Yes
15181,criterions; and centers if needed.,,,Yes
15183,If needed; calculate Top 5 prediction,No,Yes,Yes
15186,If needed; calculate Top 5 prediction,No,Yes,Yes
15188,Store parameters that are needed later,No,Yes,Yes
15189,Convert the image and annotation dtypes to tf.float32 if needed,No,Yes,Yes
15190,Define your supervisor for running a managed session. Do not run the summary_op automatically or else it will consume too much memory,Yes,Yes,Yes
15192,best validate: python validate.py --structure fcn32s --validate_model_state_dict fcn32s_camvid_9.pt,No,Yes,Yes
15193,please refer the origin implement and I will just use the code for my own usage,No,No,Yes
15194,Implement stateful ConvLSTM,No,Yes,Yes
15196,For additional features. Unused now.,Yes,Yes,Yes
15198,TODO: Input dropout layer?,Yes,Yes,Yes
15200,TODO: remove pandas dependency,,,Yes
15201,TODO: Add conditional statements for layer option use_bias=False.,,,Yes
15204,TODO: Fix this rubbish,Yes,Yes,Yes
15205,TODO: can this be None? Think about layer reuse in series.,,,Yes
15207,TODO: re-order node_indices by depth,,,Yes
15208,TODO: Check if these exceptions need to be raised,,,Yes
15210,TODO: Consider removing these variables; here for readability purposes only,Yes,Yes,Yes
15212,TODO: replace repeat with tile,Yes,No,Yes
15213,TODO: This breaks layer sharing. Does it matter for this class?,Yes,Yes,Yes
15215,TODO: try getattr(layer; 'units'; getattr(layer; 'filters')) if useful,Yes,Yes,Yes
15217,TODO: this is a bit crap; maybe use channel indices everywhere,Yes,Yes,Yes
15218,TODO: Assumes that nodes only have a single output tensor. Check!,Yes,No,Yes
15219,TODO: Fix this; will it be reached with the node argument?,Yes,No,Yes
15220,This call is needed to initialise input_shape and output_shape,No,No,Yes
15229,currently; this step converts all pandas.Categorial columns back to pandas.Series,No,Yes,Yes
15231,FIXME: gracefully handle errors here or in the caller?,,,Yes
15232,FIXME: handle other kinds of assignments?,Yes,Yes,Yes
15233,"\""\""\"" Turn compiler.ast structures back into executable python code. ||  ||     The unparse method takes a compiler.ast tree and transforms it back into ||     valid python code.  It is incomplete and currently only works for ||     import statements; function calls; function definitions; assignments; and ||     basic expressions. ||  ||     Inspired by python-2.5-svn\/Demo\/parser\/unparse.py ||  ||     fixme: We may want to move to using _ast trees because the compiler for ||            them is about 6 times faster than compiler.compile. || \""\""\""",Yes,Yes,Yes
15234,fixme: Are From and ImportFrom handled differently?,,,Yes
15236,Check if parenthesis are needed on the right side and then dispatch,,,Yes
15240,Methods are columns and performances are rows,No,Yes,Yes
15241,TODO: could use bottleneck.nanargmin for speed,,,Yes
15242,TODO add support for sample weights,Yes,Yes,Yes
15243,maybe improved later,Yes,No,Yes
15245,maybe improved later,Yes,No,Yes
15250,sort each time point (columns) by risk score (descending),No,No,Yes
15251,"\""\""\""SE MobileNet v1 models for Keras. ||  || # Reference || - [MobileNets: Efficient Convolutional Neural Networks for ||    Mobile Vision Applications](https:\/\/arxiv.org\/pdf\/1704.04861.pdf)) || \""\""\""",No,Yes,Yes
15252,TODO: add custom,Yes,Yes,Yes
15254,TODO: add custom,Yes,Yes,Yes
15255,TODO: Scale,Yes,Yes,Yes
15257,TODO: InstanceNorm,Yes,No,Yes
15258,TODO: use InstanceNorm,Yes,No,Yes
15259,TODO: useInstanceNorm,Yes,No,Yes
15263,plt.plot([num_points_hack[0];num_points_hack[-1]];[old_mean[0];old_mean[0]];'r-';label='siggraph17 (auto)'),No,No,Yes
15266,"\""\""\"" || File: train_emotion_classifier.py || Author: Octavio Arriaga || Email: arriaga.camargo@gmail.com || Github: https:\/\/github.com\/oarriaga || Description: Train emotion classification model || \""\""\""",,,Yes
15267,TODO implement a logging to save all the results inside the experiment's folder,,,Yes
15268,TODO The operations implemented in the Pytorch Version are slightly different,,,Yes
15270,Matplotlib backend. Apparently the DISPLAY variable is not set in Windows,No,No,Yes
15273,TODO Return torch tensor?,Yes,No,Yes
15275,TODO Check if is in range 0 - 255,,,Yes
15276,TODO Check if the dimensions are in the right order,,,Yes
15277,TODO Extend this part to an arbitrary number of scales,,,Yes
15280,TODO load and set best validation error,,,Yes
15283,TODO let the user select the image? Loop on all images?,,,Yes
15285,TODO Add Batch dimension,Yes,Yes,Yes
15286,TODO: Use computed width and height here?,,,Yes
15287,TODO have a option that converts time into minutes and hours as needed.,Yes,No,Yes
15288,"\""\""\""\"" || This file records Global variables used in the algorithm || Author: ||     Yu-Ren Liu ||  || Time: ||     2017.1.20 || \""\""\""",No,Yes,Yes
15289,"\""\""\"" || The class Parameter was implemented in this file. || A Parameter instance should be a necessary parameter to opt in RacosOptimization ||  || Author: ||     Yu-Ren Liu ||  || Time: ||     2017.1.20 || \""\""\""",No,Yes,Yes
15290,"\""\""\""\"" || This file records Global variables used in the algorithm || Author: ||     Yu-Ren Liu ||  || Time: ||     2017.1.20 || \""\""\""",,,Yes
15291,"\""\""\"" || The class Parameter was implemented in this file. || A Parameter instance should be a necessary parameter to opt in RacosOptimization ||  || Author: ||     Yu-Ren Liu ||  || Time: ||     2017.1.20 || \""\""\""",No,Yes,Yes
15295,TODO,Yes,Yes,Yes
15297,"\""\""\"" || The class Parameter was implemented in this file. || A Parameter instance should be a necessary parameter to opt in RacosOptimization ||  || Author: ||     Yuren Liu || \""\""\""",,,Yes
15298,"\""\""\"" || This file records Global variables used in the algorithm || Author: ||     Yuren Liu || \""\""\""",,,Yes
15299,"\""\""\"" || define a simple neural network model. ||  || Author: ||     Yuren Liu || \""\""\""",No,Yes,Yes
15300,there is no better individual than offSpring,No,No,Yes
15301,"\""\""\"" || The class Parameter was implemented in this file. || A Parameter instance should be a necessary parameter to opt in RacosOptimization ||  || Author: ||     Yuren Liu || \""\""\""",No,Yes,Yes
15304,"\""\""\"" || This module contains an example of optimizing high-dimensional sphere function with sequential random embedding. ||  || Author: ||     Yu-Ren Liu || \""\""\""",No,Yes,Yes
15305,there is no better individual than offspring,No,No,Yes
15306,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
15307,print('Storing unused nodes...'; **perr),,,Yes
15308,1 columns - could be binary,,,Yes
15311,FIND A BETTER WAY TO DO THIS,,,Yes
15312,FIND A BETTER WAY,Yes,Yes,Yes
15313,FIND A BETTER WAY TO DO THIS,Yes,Yes,Yes
15315,that's to show the columns in the correct order: name; importance; std,No,Yes,Yes
15317,TODO: perform basic logic checking;,,,Yes
15319,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
15320,TODO: perform basic logic checking;,,,Yes
15321,improve variable naming,Yes,Yes,Yes
15325,`None`. That's also strange and perhaps worthy of raising an,No,Yes,Yes
15326,Store IPython directive to enable better error messages,,,Yes
15329,FIXME: convert cv_results_ to the old list of namedtuples format so,,,Yes
15330,"\""\""\"" || Script for creating new releases ||  || Maybe I should switch to this: || https:\/\/blog.mozilla.org\/warner\/2012\/01\/31\/version-string-management-in-python-introducing-python-versioneer\/ || \""\""\""",,,Yes
15331,columns that will be interpreted as paramers,No,Yes,Yes
15333,"TODO: only eval outputs of type \""stream\"" - we have to keep a",,,Yes
15334,TODO: show warning if more than one tag,,,Yes
15335,TODO: remove entries with None values?,Yes,Yes,Yes
15337,TODO: make it work for a list of uuids,Yes,No,Yes
15340,TODO: implement _repr_html_,,,Yes
15341,TODO: make it work for a list of uuids,Yes,No,Yes
15342,TODO: how to handle a print(var) case? it removes the '' and causes a,,,Yes
15343,TODO: show warning if failing to eval at least one key,Yes,Yes,Yes
15344,way to fix it,,,Yes
15345,* Difference could be represented by the difference of the table but we could only compare two at a time,,,Yes
15346,TODO: add ratio and percentage,Yes,Yes,Yes
15348,TODO: remove this,Yes,No,Yes
15349,TODO: add ratio and percentage,,,Yes
15351,Now; we use papermill to execute the notebook with different parameters; we'll run 4 models: 2 random forest; a linear regression and a support vector regression:,No,Yes,Yes
15352,The summary that compares single-row tables includes a diff columns:,No,Yes,Yes
15355,lxml needed for NotebookCollection.py example,,,Yes
15358,TODO switch to compressed writing,,,Yes
15359,TODO # We assume that there is no distinction between male\/female here,,,Yes
15360,Maximum start position when ignoring padding on both ends of the file,,,Yes
15361,TODO needs reimplementation,,,Yes
15362,TODO  hardcoded for now,,,Yes
15364,TODO under assumption that sources are additive we can only load sources in; then add them to form mixture!,,,Yes
15365,Round resulting feature map dimensions up to nearest EVEN integer (even because up-convolution by factor two is needed),No,Yes,Yes
15367,TODO problem: silence signals cause this to be uncomputable since we divide by zero,,,Yes
15369,Random attenuation of source signals to improve generalisation performance (data augmentation),No,Yes,Yes
15371,TODO:                                                             #,Yes,No,Yes
15372,TODO:                                                               #,,,Yes
15379,TODO: Compute the softmax loss and its gradient using explicit loops.     #,,,Yes
15380,TODO: Compute the softmax loss and its gradient using no explicit loops.  #,,,Yes
15381,why this even exsist,Yes,Yes,Yes
15385,Efficient Grid Size Reduction,No,No,Yes
15386,"\""\""\""shufflenet in pytorch ||  ||  ||  || [1] Xiangyu Zhang; Xinyu Zhou; Mengxiao Lin; Jian Sun. ||  ||     ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices ||     https:\/\/arxiv.org\/abs\/1707.01083v2 || \""\""\""",No,Yes,Yes
15387,"\""\""\""mobilenet in pytorch ||  ||  ||  || [1] Andrew G. Howard; Menglong Zhu; Bo Chen; Dmitry Kalenichenko; Weijun Wang; Tobias Weyand; Marco Andreetto; Hartwig Adam ||  ||     MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications ||     https:\/\/arxiv.org\/abs\/1704.04861 || \""\""\""",No,Yes,Yes
15388,"\""\""\""squeezenet in pytorch ||  ||  ||  || [1] Song Han; Jeff Pool; John Tran; William J. Dally ||  ||     squeezenet: Learning both Weights and Connections for Efficient Neural Networks ||     https:\/\/arxiv.org\/abs\/1506.02626 || \""\""\""",,,Yes
15389,"\""\""\""shufflenetv2 in pytorch ||  ||  ||  || [1] Ningning Ma; Xiangyu Zhang; Hai-Tao Zheng; Jian Sun ||  ||     ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design ||     https:\/\/arxiv.org\/abs\/1807.11164 || \""\""\""",No,Yes,Yes
15393,"\""\""\"" || TODO:  || Add Weighted loss || \""\""\""",Yes,Yes,Yes
15394,TODO,Yes,Yes,Yes
15396,also remove the first #symbolic rows and columns.,No,Yes,Yes
15397,also remove the first #symbolic rows and columns.,No,Yes,Yes
15401,hack length from mask,,,Yes
15404,we do not hack mask from length for special reasons.,,,Yes
15410,hack length from mask,No,Yes,Yes
15411,we do not hack mask from length for special reasons.,,,Yes
15414,TODO for pytorch 2.0.4; use inside potrf for variable.,Yes,Yes,Yes
15416,we do not hack mask from length for special reasons.,No,Yes,Yes
15417,TODO masked_fill_ does not work for backprop; check for Pytorch 2.0.4,Yes,No,Yes
15418,hack to handle LSTM,Yes,Yes,Yes
15420,TODO reverse skip connection for bidirectional rnn.,,,Yes
15422,hack to handle LSTM,Yes,Yes,Yes
15423,TODO add type score to hyp scores.,Yes,No,Yes
15427,Custom object needed for inference and training,No,Yes,Yes
15428,Custom object needed for inference and training,No,Yes,Yes
15432,Custom object needed for inference and training,,,Yes
15434,"\""\""\"" || Pre-defined Performance || Implement classical methods || \""\""\""",No,Yes,Yes
15435,We can't have more than one value on y_type => The set is no more needed,No,Yes,Yes
15436,"\""\""\"" || Pre-defined oracle class || Implement classical situation || \""\""\""",,,Yes
15437,"\""\""\"" || Pre-defined query strategy. Implement classical || methods for various situation || \""\""\""",No,Yes,Yes
15440,"\""\""\"" || Implement functions for image dataset reading; processing; etc. || Will update in near future || \""\""\""",Yes,Yes,Yes
15441,"\""\""\"" || Pre-defined Performance || Implement classical methods || \""\""\""",No,Yes,Yes
15442,We can't have more than one value on y_type => The set is no more needed,Yes,Yes,Yes
15446,efficient computation of inv(Laa),,,Yes
15447,"\""\""\"" || Query strategies for feature querying setting. ||  || We implement the following strategies: ||  || 1. KDD'18: Active Feature Acquisition with Supervised Matrix Completion (AFASMC). || 2. ICDM'13: Active Matrix Completion using Query by Committee (QBC) || 3. ICDM'13: Active Matrix Completion using Committee Stability (Stability) || 4. Random || \""\""\""",,,Yes
15449,TODO check beta value,Yes,Yes,Yes
15451,TODO should we handle it here or we should handle it before calling,Yes,Yes,Yes
15452,TODO check beta value,Yes,Yes,Yes
15453,"\""\""\"" || Implement functions for image dataset reading; processing; etc. || Will update in near future || \""\""\""",,,Yes
15455,We can't have more than one value on y_type => The set is no more needed,,,Yes
15456,"\""\""\"" || Pre-defined oracle class || Implement classical situation || \""\""\""",,,Yes
15457,"\""\""\"" || Implement query strategies for cost-sensitive for hierarchical multi-label setting. ||  || 1.Cost-Effective Active Learning for Hierarchical Multi-Label Classification(IJCAI`18) || 2.Uncertainty || 3.Random || \""\""\""",No,Yes,Yes
15458,TODO should we handle it here or we should handle it before calling,,,Yes
15463,reshape the input if needed,No,No,Yes
15464,the projection trainable appears to improve parsing accuracy,,,Yes
15466,XXX(nikita): this behavior should really be controlled by an argument,Yes,Yes,Yes
15467,it's better than failing to return a valid parse.,No,Yes,Yes
15468,Rather than writing tree traversal code to delete nodes when needed during,,,Yes
15470,tokenization by introducing an extra '\/'; so we don't fix it.,Yes,Yes,Yes
15471,text. Maybe we shouldn't be training on this bad example; but for now,Yes,Yes,Yes
15472,Spans are returned as closed intervals on both ends,No,No,Yes
15473,For GPT-2; we append an eos token if special tokens are needed,No,Yes,Yes
15474,Important notes about how this works in terms of,,,Yes
15477,If memory available is less than needed; warn the user,Yes,Yes,Yes
15478,Move image,No,Yes,Yes
15480,Move image,No,Yes,Yes
15483,Temporary fix for https:\/\/github.com\/DeadSix27\/waifu2x-converter-cpp\/issues\/109,Yes,Yes,Yes
15486,WORKAROUND FOR WAIFU2X-NCNN-VULKAN,No,Yes,Yes
15488,TODO: check Java here,,,Yes
15490,stretch file path and fill columns horizontally,No,Yes,Yes
15492,TODO: more documentations on this block,,,Yes
15494,TODO,Yes,Yes,Yes
15495,TODO,,,Yes
15496,TODO: sometimes None is happens; why?,,,Yes
15498,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
15499,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
15500,"\""\""\"" || The images human portrait segmentation example. ||  || Images dataset was taken from [PicsArt](https:\/\/picsart.com\/) AI Hackathon. ||  || Dataset may be downloaded [there](https:\/\/s3.eu-central-1.amazonaws.com\/datasouls\/public\/picsart_hack_online_data.zip) ||  || For this example need to install this dependencies: || `pip install sklearn; albumentations; opencv-python` || \""\""\""",No,Yes,Yes
15501,Create needed parameters again,No,Yes,Yes
15502,should not be a problem right now. Switch to better solution is needed.,,,Yes
15503,move next batch moment,,,Yes
15504,tensorflow hub input that is not needed outside of training.,No,No,Yes
15506,it was unused by me and I was able to get a functional output.,,,Yes
15508,discard unused sentences,Yes,No,Yes
15509,maybe sth change between Pytorch versions; add func long() for compatibility,Yes,Yes,Yes
15511,fix nan due to indeterminate form,Yes,Yes,Yes
15513,add pqmf if needed,Yes,Yes,Yes
15514,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
15516,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
15517,TODO: not working,,,Yes
15519,TODO: finish the details,,,Yes
15520,TODO: refine,Yes,Yes,Yes
15522,TODO: correct this to output the appropriate vectors,,,Yes
15526,TODO: work on it here,Yes,No,Yes
15528,category_col; descp_col = df.columns.values.tolist(),,,Yes
15531,I think it's better to treat it as a simple prepostion,No,Yes,Yes
15532,This looks horrible but I haven't figured out a better way.,Yes,Yes,Yes
15533,new clause chunks are very rare; we collapse them into a single chunk,No,Yes,Yes
15535,we split them manually.,No,Yes,Yes
15536,tries to fix mistyped tokens (common in Wikipedia-pt) as ;; '' ..,,,Yes
15538,new clause chunks are very rare; we collapse them into a single chunk,No,Yes,Yes
15539,a little workaround.,Yes,Yes,Yes
15540,first; check if the sentence ends with some punctuation sign,No,No,Yes
15541,I think it's better to treat it as a simple prepostion,,,Yes
15543,we represent a dependency to root as an edge to the token itself,No,Yes,Yes
15544,or apparently sentence end,No,Yes,Yes
15545,TODO: use a more convenient name instead of network,Yes,No,Yes
15546,TODO: remove?,Yes,No,Yes
15548,"\""\""\""Wrappers for different backbones for models that follows Encoder-Decoder architecture. ||  || Encodes listed here provides easy way to swap backbone of classification\/segmentation\/detection model. || \""\""\""",No,Yes,Yes
15549,TODO: first doesn't have act?,Yes,Yes,Yes
15554,TODO: Add support for ABN; InplaceABN,Yes,Yes,Yes
15555,We do this by padding with a zero at each end when needed.,No,Yes,Yes
15558,TODO: Mark as deprecated and emit warning,Yes,No,Yes
15561,"\""\""\""Wrappers for different backbones for models that follows Encoder-Decoder architecture. ||  || Encodes listed here provides easy way to swap backbone of classification\/segmentation\/detection model. || \""\""\""",No,Yes,Yes
15563,TODO: if statement only here to tell the jit to skip emitting this when it is None,Yes,Yes,Yes
15564,TODO: Figure out padding scheme,,,Yes
15566,horizontal move,No,Yes,Yes
15567,vertical move,No,Yes,Yes
15569,I need a better distribution...,No,Yes,Yes
15570,store move data,No,Yes,Yes
15573,basically check the move,No,Yes,Yes
15574,move horizontally,No,Yes,Yes
15575,move vertically,No,Yes,Yes
15579,"logger.debug(f\""P1 NN recommend move: {move} with probability {np.max(p)}; v = {v}\"")",No,Yes,Yes
15581,move = flip_move(action),No,Yes,Yes
15582,move = ActionLabelsRed[mov_idx],,,Yes
15584,move = senv.parse_onegreen_move(''),,,Yes
15586,move = action,No,Yes,Yes
15587,move = ActionLabelsRed[mov_idx],No,Yes,Yes
15588,info depth xx pv xxx,,,Yes
15590,"logger.debug(f\""Checking move {mov}\"")",No,Yes,Yes
15592,TODO: check direction of entropy,,,Yes
15596,TODO,Yes,Yes,Yes
15599,TODO,,,Yes
15601,TODO,Yes,Yes,Yes
15602,TODO: tie-breaker,Yes,No,Yes
15604,TODO: L; R \uC744 stem; eomi \uB85C \uBC1B\uC544\uC11C \uC791\uC5C5,,,Yes
15605,TODO check postprocessing rule,,,Yes
15606,TODO extracted \uB41C canonical form \uC774 \uB2E4\uB978 \uC5B4\uBBF8\uB4E4\uACFC \uC870\uD569\uB418\uC5B4 \uB2E4\uB974\uAC8C \uD65C\uC6A9\uB420 \uC218 \uC788\uB294\uC9C0 \uD655\uC778,Yes,Yes,Yes
15607,TODO: something,Yes,Yes,Yes
15608,TODO: update adjective_stems & verb_stems ?,,,Yes
15609,TODO: replace scores with noun scores,,,Yes
15610,"\""\""\""Python package for stacking. || Author: <vecxoz@gmail.com> || \""\""\""",No,Yes,Yes
15611,do not allow several columns in y_train,No,Yes,Yes
15612,y has two or more columns,No,No,Yes
15616,Make train\/test split by hand to avoid strange errors probably related to testing suit:,Yes,No,Yes
15618,Make train\/test split by hand to avoid strange errors probably related to testing suit:,Yes,No,Yes
15619,Make train\/test split by hand to avoid strange errors probably related to testing suit:,Yes,No,Yes
15620,Make train\/test split by hand to avoid strange errors probably related to testing suit:,Yes,No,Yes
15622,TODO: make generic. size(-1)?,,,Yes
15623,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
15626,TODO: Can have a mapping from monitor names to layer names if we want different names,Yes,Yes,Yes
15627,TODO: Check monitor information to obtain size information,Yes,Yes,Yes
15630,TODO : Implement membrane potential clipping. (-1;1),Yes,Yes,Yes
15632,TODO : Implement continuous reward function.,,,Yes
15635,TODO : Build critic network.,,,Yes
15636,TODO : Implement membrane potential clipping. (-1;1),,,Yes
15637,TODO : Understand current initializing process.,,,Yes
15639,better by exploiting the timing structure.,No,Yes,Yes
15640,TODO Increase simulation running timestep by exploiting the duration\/,,,Yes
15644,TODO Delayed reward with uncertain timing.,Yes,Yes,Yes
15646,better by exploiting the timing structure.,No,Yes,Yes
15647,TODO Increase simulation running timestep by exploiting the duration\/,Yes,Yes,Yes
15648,TODO remove np uses and replace them with pytorch functions.,Yes,Yes,Yes
15651,TODO: check this if necessary,,,Yes
15652,Trace is needed for computing epsilon.,,,Yes
15655,This is needed for my implementation; but I want to reformat this away,,,Yes
15657,Trace is needed for computing epsilon.,No,Yes,Yes
15662,TODO: Work on this stuff,Yes,No,Yes
15664,It's awful I know and just the worst. I have no idea why it works.,Yes,No,Yes
15665,We'll eventually want better validating here,,,Yes
15666,TODO Remove this entirely.  It's a horrible way to work with dicts.,Yes,No,Yes
15667,TODO Document after plugin data is refactored,,,Yes
15668,"\""final_arguments=command\"" or better yet; just pass in the command itself",No,Yes,Yes
15670,TODO Document after the plugin data is refactored,Yes,Yes,Yes
15671,going to be OS specific.  If anyone has a better way to do,No,Yes,Yes
15672,TODO: finish this,Yes,Yes,Yes
15675,TODO: consider adding a timer so parsing doesn't take too long,,,Yes
15676,TODO: improve this,,,Yes
15677,TODO: seperate the server and client code and add an api to communicate between the two,Yes,Yes,Yes
15678,TODO: add require docs,Yes,No,Yes
15679,TODO: Add more methods\uFFFF,Yes,Yes,Yes
15681,TODO: add command and user selection to the nlp,,,Yes
15682,TODO: uncomment the web based lines,,,Yes
15683,TODO: fix this to be server bound,,,Yes
15684,TODO: fix jit,,,Yes
15686,TODO: fix the way the subscribing and dispatching is handled,Yes,Yes,Yes
15687,TODO: get these working,Yes,Yes,Yes
15688,TODO: remove this eventually,,,Yes
15689,TODO: eventually do this as part of the framework insetad of a standalone ui,Yes,Yes,Yes
15690,TODO: Finisht he cast function and add netflix support via splinter,Yes,Yes,Yes
15691,TODO: add netflix code here,Yes,No,Yes
15692,"\""ents_needed\"" : [\""ORG\""];",No,Yes,Yes
15695,TODO: remove this eventually,,,Yes
15696,TODO: eventually do this as part of the framework insetad of a standalone ui,,,Yes
15697,TODO: Eventually ask for netflix credentials when they aren't found,,,Yes
15699,TODO: document this more,Yes,No,Yes
15700,TODO: possibly; in the future; ask the user which of these they want or do manual parsing,Yes,Yes,Yes
15701,TODO: write in the log and config functions,Yes,No,Yes
15702,TODO: write in an eventbuilder function,Yes,Yes,Yes
15704,TODO: Make this callout valid,,,Yes
15705,TODO: add more actions; used for things like dumping events or caches,,,Yes
15706,TODO: use getattr to complete the call,Yes,No,Yes
15707,TODO: work on this,Yes,No,Yes
15709,I wish I had a more efficient way to do this,,,Yes
15710,TODO: google search,No,No,Yes
15711,TODO: figure out what's keeping threads awake; fix it and change os._exit() to sys.exit(),,,Yes
15713,TODO: ask the user about which time they want to ues,Yes,Yes,Yes
15714,TODO: add dates processing,Yes,Yes,Yes
15715,TODO: fix this and then add thread safe error handling,Yes,Yes,Yes
15716,TODO: do this with mutable and immutable settings,Yes,No,Yes
15721,TODO: use wolfram key from db,Yes,Yes,Yes
15722,TODO: use wolfram key from db,,,Yes
15723,TODO: make it so that plugin_handler can send an error,Yes,Yes,Yes
15724,TODO: accept a dict,Yes,No,Yes
15725,Not working yet: TODO: fix,,,Yes
15729,TODO: try to use ip data,Yes,Yes,Yes
15730,TODO: parse time from string,,,Yes
15732,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
15733,TODO: write a framework that allowc ahgning of notifications,Yes,Yes,Yes
15734,TODO: integrate the response framework,,,Yes
15735,''' || We'd like the following callback actions for neuron: ||  || - print metrics on the test and validation; especially surface-specific dice || --- Perhaps doable with CSVLogger? || - output graph up to current iteration for each metric || --- Perhaps call CSVLogger or some metric computing callback? || - save dice plots on validation || --- again; expand CSVLogger or similar || - save screenshots of a single test subject [Perhaps just do this as a separate callback?] || --- new callback; PlotSlices ||  || ''',No,Yes,Yes
15736,TODO: fix in one line,,,Yes
15737,WARNING: SHOULD REALLY BE shape=[batch_size; 1] !!!,Yes,Yes,Yes
15738,TODO: add Cropping3D or Cropping2D if 'valid' padding,Yes,No,Yes
15739,figure out the number of rows and columns,No,No,Yes
15741,TO MOVE (numpy softmax),No,Yes,Yes
15742,get the ends,No,No,Yes
15745,done; yey! time to celebrate - maybe visualize the quilted volume?,No,Yes,Yes
15747,TODO: should only compute this once!,,,Yes
15748,Prepare reshape by inserting dimensions with size 1 where needed,,,Yes
15751,write results to disk as needed,No,Yes,Yes
15752,TODO: I'm not sure the mean layer is the right direction,,,Yes
15754,TODO: simplify this,Yes,Yes,Yes
15756,TODO: these imports should be cleaner...,Yes,Yes,Yes
15758,TODO: these imports should be cleaner...,Yes,Yes,Yes
15759,TODO: switch to nice local imports...,Yes,Yes,Yes
15760,TODO use neuron unet,,,Yes
15761,TODO: these imports should be cleaner...,,,Yes
15762,TODO: add Cropping3D or Cropping2D if 'valid' padding,Yes,No,Yes
15763,ends of linear corrective function,,,Yes
15767,TODO fix this,Yes,Yes,Yes
15770,TODO extend this as an argument,Yes,No,Yes
15771,TODO fix this,Yes,Yes,Yes
15772,TODO swich zoom back to resize,Yes,Yes,Yes
15773,remove unused batch dimension,Yes,Yes,Yes
15774,TODO: this is opposite of the normal ordering and might be confusing,Yes,Yes,Yes
15775,TODO change to ResizeTransform,Yes,Yes,Yes
15778,this is a bit hacky for basically building a segmentation-only network (no images),Yes,Yes,Yes
15779,go from vector to matrix if needed,,,Yes
15780,prepare zeros; which will be used for outputs unused in cost functions,,,Yes
15781,this is a bit hacky for basically building a segmentation-only network (no images),Yes,Yes,Yes
15782,TODO don't think this is necessary,Yes,Yes,Yes
15784,is this needed?,,,Yes
15785,TODO: change to ndims * (ndims + 1),Yes,Yes,Yes
15789,ugly bandaid but avoids crashes for now.,,,Yes
15790,TODO: simply import utils and use utils.is_affine; etc...,Yes,Yes,Yes
15792,TODO: could output more than a single timepoint!,,,Yes
15793,TODO: needs work,Yes,Yes,Yes
15794,"\""\""\"" || Detecting duplicate quora questions || feature engineering || @author: Abhishek Thakur || \""\""\""",No,Yes,Yes
15796,TODO: Implement for D3 v. 4.#.#.,Yes,Yes,Yes
15801,TODO,,,Yes
15804,+ addcol #obtain columns withouth the useless features,,,Yes
15810,only if the small cycle cross can construct better features;,,,Yes
15811,only if the medium cycle cross can construct better features;,,,Yes
15813,if larger the better; self.score; self.greedyscore = 0; 1,No,Yes,Yes
15815,only if the small cycle cross can construct better features;,No,Yes,Yes
15816,stop when no improve for the last round and no potential add feature,No,No,Yes
15817,avoid cross term twice until it is fix,Yes,No,Yes
15818,if smaller the better; self._score; self._greedyscore = 1; 0,,,Yes
15819,if larger the better; self._score; self._greedyscore = 0; 1,No,Yes,Yes
15821,avoid cross term twice until it is fix,,,Yes
15822,only if the small cycle cross can construct better features;,No,Yes,Yes
15824,I know this is ugly; but it's practical.,Yes,Yes,Yes
15826,Remove any columns that hold no data,,,Yes
15829,Make sure that all of the indexing columns only contain zeroes,,,Yes
15830,Make sure that all columns have some price data,,,Yes
15831,No missing data in the index columns,No,Yes,Yes
15832,implement model.optim_parameters(args) to handle different models' lr setting,,,Yes
15833,implement model.optim_parameters(args) to handle different models' lr setting,No,No,Yes
15836,"\""\""\"" || ============================ || Multiple Coefficient Binning || ============================ ||  || This example shows how the MCB algorithm transforms a dataset of time series of || real numbers into a list of sequences of letters. It is implemented as || :class:`pyts.quantization.MCB`. || \""\""\""",,,Yes
15839,"\""\""\"" || ================================================================ || Symbolic Aggregate approXimation in Vector Space Model (SAX-VSM) || ================================================================ ||  || This example shows how the SAX-VSM algorithm transforms a dataset || consisting of time series and their corresponding labels into a || document-term matrix using tf-idf statistics. Each class is represented || as a tfidf vector. For an unlabeled time series; the predicted label is || the label of the tfidf vector giving the highest cosine similarity with || the tf vector of the unlabeled time series. SAX-VSM algorithm is || implemented as :class:`pyts.classification.SAXVSM`. || \""\""\""",No,Yes,Yes
15841,Derive parameter values for 'auto' cases,No,Yes,Yes
15842,Little fix for max_slope = 1,No,No,Yes
15843,"\""\""\"" || ============================================== || RandOm Convolutional KErnel Transform (ROCKET) || ============================================== ||  || The RandOm Convolutional KErnel Transform (ROCKET) algorithm randomly || generates a great variety of convolutional kernels and extracts two || features for each convolution: || the maximum and the proportion of positive values. || This example illustrates basic usage of this algorithm and plots the || weights of the most relevant kernels according to mutual information. || It is implemented as :class:`pyts.transformation.ROCKET`. || \""\""\""",No,Yes,Yes
15851,TODO strip prediction and label and return word,Yes,No,Yes
15853,"\""\""\"" make reference text files needed for ROUGE evaluation \""\""\""",No,Yes,Yes
15856,FIXME eccessing 'private members' of pointer net module is bad,Yes,Yes,Yes
15857,FIXME,Yes,Yes,Yes
15860,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
15861,TODO: source_id,Yes,No,Yes
15863,check if the necessary indices exist and create them if needed,,,Yes
15864,TODO: check if the url is a valid RSS feed,,,Yes
15867,to improve performance; regex statements are compiled only once per module,,,Yes
15869,to improve performance; regex statements are compiled only once per module,No,Yes,Yes
15870,to improve performance; regex statements are compiled only once per module,Yes,Yes,Yes
15871,to improve performance; regex statements are compiled only once per module,No,Yes,Yes
15872,to improve performance; regex statements are compiled only once per module,,,Yes
15873,todo data augment,Yes,Yes,Yes
15874,this flush method is needed for python 3 compatibility.,,,Yes
15876,hack to handle LSTM,Yes,Yes,Yes
15877,hack for python2\/3 compatibility,,,Yes
15878,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. || This is an (inefficient) toy implementation that shows the algorithm. For processing large datasets; || indexing and incremental updates can be used to speed up the implementation (see learn_bpe.py). ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,,Yes
15880,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,,Yes
15882,we probably missed the best pair because of pruning; go back to full statistics,Yes,No,Yes
15883,hack for python2\/3 compatibility,Yes,Yes,Yes
15885,TODO cache computation; not inputs,,,Yes
15887,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. || This is an (inefficient) toy implementation that shows the algorithm. For processing large datasets; || indexing and incremental updates can be used to speed up the implementation (see learn_bpe.py). ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,,Yes
15888,hack for python2\/3 compatibility,Yes,Yes,Yes
15890,hack for python2\/3 compatibility,Yes,Yes,Yes
15891,we probably missed the best pair because of pruning; go back to full statistics,Yes,No,Yes
15893,hack for python2\/3 compatibility,Yes,Yes,Yes
15894,logprobs are needed to rank hypotheses,No,Yes,Yes
15895,TODO cache computation; not inputs,Yes,Yes,Yes
15896,check if additional initial attention state is needed,,,Yes
15897,TODO: simplify formating,Yes,No,Yes
15898,TODO: better handle cascade of dict items,Yes,Yes,Yes
15899,TODO: add limited pickling support for sharing an iterator,Yes,Yes,Yes
15901,TODO: Remove,Yes,No,Yes
15903,remove images with 0 octet in a ugly but efficient way :'),,,Yes
15905,TODO To remove later.,,,Yes
15907,should be WeightNorm here TODO.,Yes,Yes,Yes
15908,TODO should be WeightNorm here; but using batchNorm instead,Yes,Yes,Yes
15909,TODO should be WeightNorm here; but using batchNorm instead,Yes,Yes,Yes
15910,TODO: Make mapping from sklearn metrics to lib metrics,Yes,No,Yes
15913,easily move around and find their neighbors,No,Yes,Yes
15914,Correct the KL divergence w.r.t. the exaggeration if needed,,,Yes
15916,probably thought they had more cores; so we'll default to 1,Yes,Yes,Yes
15917,Hide box border around figure,,,Yes
15918,-- Options for todo extension ----------------------------------------------,,,Yes
15919,If true; `todo` and `todoList` produce output; else they produce nothing.,No,Yes,Yes
15920,Changing the gradients using clipping changes how the points move,,,Yes
15922,as a workaround; we let the failed points group together,,,Yes
15923,TODO try to use tensor in shared-memory instead of serializing to disk,Yes,Yes,Yes
15924,manually creates a temporary directory; that needs to be cleaned,,,Yes
15925,FIXME remove this once c10d fixes the bug it has,Yes,Yes,Yes
15927,workaround as pre-trained Caffe2 models from Detectron have all the same filename,,,Yes
15928,workaround: Caffe2 models don't have a hash; but follow the R-50 convention;,Yes,Yes,Yes
15937,ugly but works,,,Yes
15938,TODO: select only the sampled word advantage for calculation,Yes,Yes,Yes
15942,resize\/crop if needed,No,No,Yes
15945,Load Cifar10 data. Please implement your own load_data() module for your own dataset,No,No,Yes
15946,# TO-DO:,Yes,No,Yes
15950,We could use better psychological models here...,,,Yes
15951,Outer double quotes needed or else colon characters don't parse,No,No,Yes
15957,statements better.,,,Yes
15958,To verify that the file ends in \ || ; we just have to make sure the,No,No,Yes
15959,Found DISALLOW* macro outside a class declaration; or perhaps it,Yes,No,Yes
15960,though; so we punt on this one for now.  TODO.,,,Yes
15961,There shouldn't be space around unary operators,,,Yes
15962,You shouldn't have spaces before your brackets; except maybe after,No,Yes,Yes
15963,private; but needed to be public for implementation reasons.,Yes,No,Yes
15964,Also ignores cases where the previous line ends with a backslash as can be,No,No,Yes
15965,We implement a whitelist of safe macros instead of a blacklist of,No,Yes,Yes
15967,is more efficient when the operands are longer than a single,,,Yes
15968,it provides a way to workaround this warning for people who use,No,No,Yes
15970,A call-by-const-reference parameter either ends with 'const& identifier',No,Yes,Yes
15972,Function(int \/*unused_param*\/);,,,Yes
15973,"Support the UNIX convention of using \""-\"" for stdin.  Note that",No,No,Yes
15975,columns as the first row; append it to the list,No,Yes,Yes
15976,we ignore the exception (maybe the image is corrupted?),Yes,Yes,Yes
15980,max overlap with gt over classes (columns),,,Yes
15982,Compute values needed for means and stds,No,No,Yes
15983,These values will be needed for making predictions,,,Yes
15986,! Hack here to copy the classifier from the pretrained model,Yes,Yes,Yes
15987,! Hack,,,Yes
15988,Don't know why. Possibly a bug in caffe's memory optimization.,Yes,Yes,Yes
15989,columns = 8,No,Yes,Yes
15990,for i in range(1; columns * rows + 1):,,,Yes
15993,Check for GPUs and set them to dynamically grow memory as needed,,,Yes
15994,Check for GPUs and set them to dynamically grow memory as needed,,,Yes
15997,kid better than parent,No,Yes,Yes
15998,TODO: Handle empty proposals properly. Currently images with,Yes,Yes,Yes
16001,TODO: a more flexible way to configurate feat maps,Yes,No,Yes
16002,BUG: we should add relu before each extra conv,,,Yes
16006,TODO verify this part,,,Yes
16008,TODO more flexible,,,Yes
16010,TODO: remove this restriction,Yes,No,Yes
16012,TODO: use local_rank instead of rank % num_gpus,,,Yes
16015,TODO: revise _filter_imgs to be more flexible,,,Yes
16018,TODO: Handle empty proposals properly. Currently images with,Yes,Yes,Yes
16021,TODO: Handle empty proposals properly. Currently images with,,,Yes
16023,TODO: implement recall hooks for other datasets,Yes,No,Yes
16028,TODO: support multiple images per gpu (only minor changes are needed),,,Yes
16030,TODO: figure out why these two are different,,,Yes
16031,TODO: merge this method with the one in BaseDetector,Yes,Yes,Yes
16034,TODO: find a proper way to handle the shape of weight,,,Yes
16035,TODO: remove this module,Yes,No,Yes
16040,"TODO: compare mode = \""fan_in\"" or \""fan_out\""",Yes,Yes,Yes
16042,TODO: Inherit from BabiConfig,Yes,Yes,Yes
16045,TODO: Mark self.nil_word and self.data as None since they will be overriden eventually,,,Yes
16048,TODO: Same as above.,Yes,Yes,Yes
16049,FIXME: This condition makes the code more fragile!,,,Yes
16051,"''' || #TODO: various stem \/ lemmatizers. || from nltk.stem import WordNetLemmatizer || wnl = WordNetLemmatizer() || def stem(word; option=\""wnlemma\"") ||   if option == \""wnlemma\"": ||     return wnl.lemmatize(word) ||   if option == \""porter\"": ||     return porter.stem(word) || '''",,,Yes
16053,TODO: replace with apos when,Yes,No,Yes
16056,TODO: We get rid of markupMassage so that the,Yes,Yes,Yes
16058,TODO: please check that all 'words' with term annotation,Yes,Yes,Yes
16059,What happen if IOError: [Errno 5] Input\/output error?? WTF is Errno5 !!@$!%#@^$& ???!!!!@#$!%@,No,No,Yes
16060,"''' || #TODO: various tokenizers. || from nltk import word_tokenize || def tokenize(sentence; option=\""split\""): ||   if option == \""split\"": # Simply splits by whitespaces. ||     return sentence.split() ||   if option == \""word_tokenize\"": # Uses NLTK word_tokenize(). ||     return word_tokenize(sentence) || '''",Yes,Yes,Yes
16064,TODO: Do some preprocessing if necessary.,Yes,No,Yes
16068,# TODO: call optimizer object outside of this gpu environment,,,Yes
16070,# # TODO: call optimizer object outside of this gpu environment,,,Yes
16072,Resize and crop if needed.,No,No,Yes
16074,TODO: Do some preprocessing if necessary.,,,Yes
16076,Resize and crop if needed.,No,No,Yes
16078,TODO: make efficient,,,Yes
16079,TODO: add other dissimilarity measures?,,,Yes
16080,convert to numpy arrays; if needed,,,Yes
16086,TODO: iteration over 0-d array; fix this,Yes,Yes,Yes
16088,convert to numpy array; if needed,No,Yes,Yes
16091,TODO,,,Yes
16093,TODO: There are more efficient ways.,Yes,Yes,Yes
16094,TODO: There are more efficient ways.,,,Yes
16095,TODO: probably useless,Yes,No,Yes
16096,TODO: support for several bounding boxes,,,Yes
16097,TODO: fix for larger batch size,Yes,Yes,Yes
16101,TODO: Change bounding box.,Yes,No,Yes
16102,TODO: fix for larger batch size,,,Yes
16105,TODO: fix for larger batch size,,,Yes
16107,TODO: fix for larger batch size,Yes,Yes,Yes
16108,TODO: fix for larger batch size,Yes,Yes,Yes
16110,TODO: fix for larger batch size,,,Yes
16115,CAREFUL: WARN; PROBLEM; THEANO BUG! If a layer has only 1FM; the .newMu_B ends up being of type (true;) instead of vector!!! Error!!!,Yes,No,Yes
16117,WARN; PROBLEM; THEANO BUG. The below was returning (True;) instead of a vector; if I have only 1 FM. (Vector is (False;)). Think I corrected this bug.,Yes,Yes,Yes
16118,This could be renamed to be more generic.,Yes,Yes,Yes
16119,Calculate how much padding needed to fully infer the original array1; taking only the receptive field in account.,,,Yes
16120,here normally I would just .setValue(). No theano weird functions needed.,Yes,No,Yes
16121,For normalization-augmentation: Get channels' stds if needed:,No,No,Yes
16122,THIS FOR LOOP COULD PROBABLY BE DONE AS A MATRIX-OPERATION SOMEHOW. Actually; after thought probably not as matrix-op but easily parallelisable on many threads. And will save me ALOT of time when extracting. This is THE next optimization point for time efficiency..!,,,Yes
16123,NEW NOT SURE IF THIS IS NEEDED. But lets keep it simple and consistent.,Yes,No,Yes
16124,Update cnn's top achieved validation accuracy if needed: (for the autoReduction of Learning Rate.),No,Yes,Yes
16125,stride is how much I move in each dimension to acquire the next imagePart.,No,No,Yes
16128,The below is a trick to get correct number of voxels even when subsampling factor is even or not exact divisor of the number of central voxels.,,,Yes
16129,Hack; for it to work for the case that I do not use a brainMask.,,,Yes
16130,This is a hack. In case you run the script without any options; it will get here. And run for these hard-coded values.,,,Yes
16133,Check if the dice was calculated fine. If > 1.0; it was probably 999 or something; so; just put it to 0\/,No,Yes,Yes
16136,THIS IS A VERY UGLY FUNCTION because it has hardcoded 0\/4\/5 integers for each of the metric. I need to make an enumerated class for this!,Yes,Yes,Yes
16137,plt.subplots(rows;columns): returns: (figure; axes); where axes is an array; one element for each subplot; of rows and columns as I specify!,,,Yes
16139,WARN; PROBLEM; THEANO BUG. The below was returning (True;) instead of a vector; if I have only 1 FM. (Vector is (False;)). Think I corrected this bug.,Yes,Yes,Yes
16140,WARN; PROBLEM; THEANO BUG. The below was returning (True;) instead of a vector; if I have only 1 FM. (Vector is (False;)). Think I corrected this bug.,Yes,Yes,Yes
16141,The softmax function works on 2D tensors (matrices). It computes the softmax for each row. Rows are independent; eg different samples in the batch. Columns are the input features; eg class-scores.,,,Yes
16142,Checks for whether needed parameters and types were passed correctly,,,Yes
16143,Also needed for normalization-augmentation,,,Yes
16144,======= tensors; input to the CNN. Needed to be saved for later compilation after loading =======,Yes,Yes,Yes
16145,Create the needed shared variables. Number of dimensions should be correct (5 for x; 4 for y). But size is placeholder. Changes when shared.set_value during training.,Yes,Yes,Yes
16146,CAREFUL: WARN; PROBLEM; THEANO BUG! If a layer has only 1FM; the .newMu_B ends up being of type (true;) instead of vector!!! Error!!!,Yes,No,Yes
16147,Abstract implementation. Children classes should implement this.,,,Yes
16149,Ala Yani Ioannou et al; Training CNNs with Low-Rank Filters For Efficient Image Classification; ICLR 2016. Allowed Ranks: Rank=1 or 2.,No,Yes,Yes
16151,x = current epoch; x1 = epoch where linear decrease starts; x2 = epoch where linear decrease ends,No,Yes,Yes
16152,x = current epoch; x1 = epoch where linear decrease starts; x2 = epoch where linear decrease ends,,,Yes
16155,The API for these classes should resemble the API of Pathway and Cnn3d classes. But only what is needed by the sampling process of the training procedure.,No,Yes,Yes
16156,self.p_y_given_x_2d_train = ? Can I implement negativeLogLikelihood without this ?,,,Yes
16157,To iterate over if needed.,,,Yes
16158,Abstract implementation. Children classes should implement this.,,,Yes
16159,should be called only once to build. Then just call getters if needed to get upsampled layer again.,Yes,Yes,Yes
16160,Hack. The rest of this loop can work for the whole .pathways...,Yes,Yes,Yes
16161,I must make a learning-rate-manager to encapsulate all these... Very ugly currently... All othere LR schedules are at the outer loop; per epoch.,Yes,Yes,Yes
16162,VIOLATES _HIDDEN ENCAPSULATION! TEMPORARY TILL I FIX THE API (TILL AFTER DA).,,,Yes
16164,The padding \/ unpadding could probably be done more generically.,,,Yes
16166,Deprecated and currently unused.,Yes,No,Yes
16167,For normalization-augmentation: Get channels' stds if needed:,,,Yes
16168,Hack. The rest of this loop can work for the whole .pathways...,,,Yes
16170,I move exactly the number I segment in the centre of each image part (originally this was 9^3 segmented per imagePart).,,,Yes
16173,Unpad whatever needed.,Yes,Yes,Yes
16175,WARN; PROBLEM; THEANO BUG. The below was returning (True;) instead of a vector; if I have only 1 FM. (Vector is (False;)). Think I corrected this bug.,Yes,Yes,Yes
16176,The softmax function works on 2D tensors (matrices). It computes the softmax for each row. Rows are independent; eg different samples in the batch. Columns are the input features; eg class-scores.,No,Yes,Yes
16178,Placeholder. Todo: Replace with normal arguments; when input tensor is given. Eg adversarial G.,,,Yes
16179,Unused currently.,Yes,Yes,Yes
16182,Setup any parameters needed,,,Yes
16183,Probably not needed. get() does the job.,Yes,No,Yes
16184,# Needed in case any processes are hunging. worker_pool.close() does not solve this.,,,Yes
16186,TODO: Non isotropic?,No,Yes,Yes
16187,newly created images all at once.,No,Yes,Yes
16189,Unpad whatever needed.,No,Yes,Yes
16190,The below is a trick to get correct number of voxels even when subsampling factor is even or not exact divisor of the number of central voxels.,No,Yes,Yes
16192,newly created images all at once.,,,Yes
16196,TODO: Probably 0.0 would be better.,Yes,No,Yes
16198,The padding \/ unpadding could probably be done more generically.,Yes,Yes,Yes
16200,Unused,,,Yes
16201,TODO: window_ints(min; max),Yes,No,Yes
16202,TODO: linear_rescale_to(new_min; new_max),Yes,Yes,Yes
16203,Needed; so that below do not change it for other channels,No,Yes,Yes
16206,batch_size; time; num_of_input_channels; rows; columns,No,Yes,Yes
16207,batch_size; time; num_of_input_channels; rows; columns,,,Yes
16208,Abstract implementation. Children classes should implement this.,No,Yes,Yes
16211,HACK TEMPORARY,Yes,No,Yes
16212,TODO: For sampling. In eager; remove updating calc_inp_dims_of_paths_from_hr_inp,,,Yes
16213,TODO: This is for wrapper. Remove.,Yes,No,Yes
16214,Called for sampling. TODO: Remove for eager.,Yes,Yes,Yes
16215,TODO: In eager; change this to just do a fwd-pass on a tensor of the given shape...,,,Yes
16216,HACK TO TRY ZERO-INIT ON TINY,,,Yes
16217,But only what is needed by the sampling process of the training procedure.,,,Yes
16218,Placeholder. Todo: Replace with normal arguments; when input tensor is given. Eg adversarial G.,Yes,Yes,Yes
16219,TODO: SHOULD BE SIMPLY A PADDED-CONV LAYER.,,,Yes
16225,TODO: Remove for eager,,,Yes
16226,TODO: Merge the two below,Yes,No,Yes
16228,TODO: Should be rec_field_lr_path,Yes,Yes,Yes
16234,kludge,Yes,Yes,Yes
16236,monkey patch fix for SSL\/Windows per Tika-Python #54,Yes,Yes,Yes
16237,"''' || Tika Python module provides Python API client to Aapche Tika Server. ||  || **Example usage**:: ||  ||     import tika ||     from tika import parser ||     parsed = parser.from_file('\/path\/to\/file') ||     print(parsed[\""metadata\""]) ||     print(parsed[\""content\""]) ||  || Visit https:\/\/github.com\/chrismattmann\/tika-python to learn more about it. ||  || **Detect IANA MIME Type**:: ||  ||     from tika import detector ||     print(detector.from_file('\/path\/to\/file')) ||  || **Detect Language**:: ||  ||     from tika import language ||     print(language.from_file('\/path\/to\/file')) ||  || **Use Tika Translate**:: ||  ||    from tika import translate ||    print(translate.from_file('\/path\/to\/file'; 'srcLang'; 'destLang') ||    # Use auto Language detection feature ||    print(translate.from_file('\/path\/to\/file'; 'destLang') ||  ||  || '''",No,Yes,Yes
16238,FIXME: basestring is undefined,Yes,No,Yes
16239,FIXME: the above line is unreachable,Yes,Yes,Yes
16240,FIXME: basestring is undefined,Yes,No,Yes
16243,need to check if shell=true is really needed,Yes,Yes,Yes
16246,TODO: option to hardlink,Yes,Yes,Yes
16248,TODO: In general add more error exceptions,Yes,Yes,Yes
16252,TODO: Implement export,Yes,Yes,Yes
16253,TODO: Refactor to an abstract class,Yes,No,Yes
16256,TODO: In general add more error exceptions,Yes,Yes,Yes
16258,for p in range(starts[j]; ends[j]):,No,Yes,Yes
16259,for p in range(starts[i]; ends[i]):,No,Yes,Yes
16261,ends.append(nv[i] + starts[i]),,,Yes
16262,print(ends),No,No,Yes
16263,int[] ends = new int[3];,No,No,Yes
16264,ends[i] = n_svs[i] + starts[i];,,,Yes
16265,for (int k = starts[j]; k < ends[j]; k++) {,No,Yes,Yes
16267,"\""\""\"" || class Tmp { ||  ||     public static int predict(float[] atts) { ||         double[][] svs = {{5.0999999999999996; 3.5; 1.3999999999999999; 0.20000000000000001}; {4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001}; {4.7000000000000002; 3.2000000000000002; 1.3; 0.20000000000000001}; {4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001}; {5.0; 3.6000000000000001; 1.3999999999999999; 0.20000000000000001}; {5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002}; {4.5999999999999996; 3.3999999999999999; 1.3999999999999999; 0.29999999999999999}; {5.0; 3.3999999999999999; 1.5; 0.20000000000000001}; {4.4000000000000004; 2.8999999999999999; 1.3999999999999999; 0.20000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001}; {4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001}; {4.7999999999999998; 3.0; 1.3999999999999999; 0.10000000000000001}; {4.2999999999999998; 3.0; 1.1000000000000001; 0.10000000000000001}; {5.7999999999999998; 4.0; 1.2; 0.20000000000000001}; {5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002}; {5.4000000000000004; 3.8999999999999999; 1.3; 0.40000000000000002}; {5.0999999999999996; 3.5; 1.3999999999999999; 0.29999999999999999}; {5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999}; {5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001}; {5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002}; {4.5999999999999996; 3.6000000000000001; 1.0; 0.20000000000000001}; {5.0999999999999996; 3.2999999999999998; 1.7; 0.5}; {4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001}; {5.0; 3.0; 1.6000000000000001; 0.20000000000000001}; {5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002}; {5.2000000000000002; 3.5; 1.5; 0.20000000000000001}; {5.2000000000000002; 3.3999999999999999; 1.3999999999999999; 0.20000000000000001}; {4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001}; {4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001}; {5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002}; {5.2000000000000002; 4.0999999999999996; 1.5; 0.10000000000000001}; {5.5; 4.2000000000000002; 1.3999999999999999; 0.20000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.0; 3.2000000000000002; 1.2; 0.20000000000000001}; {5.5; 3.5; 1.3; 0.20000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {4.4000000000000004; 3.0; 1.3; 0.20000000000000001}; {5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001}; {5.0; 3.5; 1.3; 0.29999999999999999}; {4.5; 2.2999999999999998; 1.3; 0.29999999999999999}; {4.4000000000000004; 3.2000000000000002; 1.3; 0.20000000000000001}; {5.0; 3.5; 1.6000000000000001; 0.59999999999999998}; {5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002}; {4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001}; {4.5999999999999996; 3.2000000000000002; 1.3999999999999999; 0.20000000000000001}; {5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001}; {5.0; 3.2999999999999998; 1.3999999999999999; 0.20000000000000001}; {7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 4.5; 1.5}; {6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5}; {5.5; 2.2999999999999998; 4.0; 1.3}; {6.5; 2.7999999999999998; 4.5999999999999996; 1.5}; {5.7000000000000002; 2.7999999999999998; 4.5; 1.3}; {6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001}; {4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0}; {6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3}; {5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999}; {5.0; 2.0; 3.5; 1.0}; {5.9000000000000004; 3.0; 4.2000000000000002; 1.5}; {6.0; 2.2000000000000002; 4.0; 1.0}; {6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999}; {5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3}; {6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999}; {5.5999999999999996; 3.0; 4.5; 1.5}; {5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0}; {6.2000000000000002; 2.2000000000000002; 4.5; 1.5}; {5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001}; {5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8}; {6.0999999999999996; 2.7999999999999998; 4.0; 1.3}; {6.2999999999999998; 2.5; 4.9000000000000004; 1.5}; {6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2}; {6.4000000000000004; 2.8999999999999999; 4.2999999999999998; 1.3}; {6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999}; {6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999}; {6.7000000000000002; 3.0; 5.0; 1.7}; {6.0; 2.8999999999999999; 4.5; 1.5}; {5.7000000000000002; 2.6000000000000001; 3.5; 1.0}; {5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001}; {5.5; 2.3999999999999999; 3.7000000000000002; 1.0}; {5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2}; {6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001}; {5.4000000000000004; 3.0; 4.5; 1.5}; {6.0; 3.3999999999999999; 4.5; 1.6000000000000001}; {6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5}; {6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3}; {5.5999999999999996; 3.0; 4.0999999999999996; 1.3}; {5.5; 2.5; 4.0; 1.3}; {5.5; 2.6000000000000001; 4.4000000000000004; 1.2}; {6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999}; {5.7999999999999998; 2.6000000000000001; 4.0; 1.2}; {5.0; 2.2999999999999998; 3.2999999999999998; 1.0}; {5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3}; {5.7000000000000002; 3.0; 4.2000000000000002; 1.2}; {5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3}; {6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3}; {5.0999999999999996; 2.5; 3.0; 1.1000000000000001}; {5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3}; {6.2999999999999998; 3.2999999999999998; 6.0; 2.5}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {7.0999999999999996; 3.0; 5.9000000000000004; 2.1000000000000001}; {6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8}; {6.5; 3.0; 5.7999999999999998; 2.2000000000000002}; {7.5999999999999996; 3.0; 6.5999999999999996; 2.1000000000000001}; {4.9000000000000004; 2.5; 4.5; 1.7}; {7.2999999999999998; 2.8999999999999999; 6.2999999999999998; 1.8}; {6.7000000000000002; 2.5; 5.7999999999999998; 1.8}; {7.2000000000000002; 3.6000000000000001; 6.0999999999999996; 2.5}; {6.5; 3.2000000000000002; 5.0999999999999996; 2.0}; {6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999}; {6.7999999999999998; 3.0; 5.5; 2.1000000000000001}; {5.7000000000000002; 2.5; 5.0; 2.0}; {5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998}; {6.5; 3.0; 5.5; 1.8}; {7.7000000000000002; 3.7999999999999998; 6.7000000000000002; 2.2000000000000002}; {7.7000000000000002; 2.6000000000000001; 6.9000000000000004; 2.2999999999999998}; {6.0; 2.2000000000000002; 5.0; 1.5}; {6.9000000000000004; 3.2000000000000002; 5.7000000000000002; 2.2999999999999998}; {5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0}; {7.7000000000000002; 2.7999999999999998; 6.7000000000000002; 2.0}; {6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8}; {6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.1000000000000001}; {7.2000000000000002; 3.2000000000000002; 6.0; 1.8}; {6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8}; {6.0999999999999996; 3.0; 4.9000000000000004; 1.8}; {6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.1000000000000001}; {7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001}; {7.4000000000000004; 2.7999999999999998; 6.0999999999999996; 1.8999999999999999}; {7.9000000000000004; 3.7999999999999998; 6.4000000000000004; 2.0}; {6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.2000000000000002}; {6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5}; {6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999}; {7.7000000000000002; 3.0; 6.0999999999999996; 2.2999999999999998}; {6.2999999999999998; 3.3999999999999999; 5.5999999999999996; 2.3999999999999999}; {6.4000000000000004; 3.1000000000000001; 5.5; 1.8}; {6.0; 3.0; 4.7999999999999998; 1.8}; {6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001}; {6.7000000000000002; 3.1000000000000001; 5.5999999999999996; 2.3999999999999999}; {6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {6.7999999999999998; 3.2000000000000002; 5.9000000000000004; 2.2999999999999998}; {6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.5}; {6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998}; {6.2999999999999998; 2.5; 5.0; 1.8999999999999999}; {6.5; 3.0; 5.2000000000000002; 2.0}; {6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998}; {5.9000000000000004; 3.0; 5.0999999999999996; 1.8}}; ||         double[][] coeffs = {{1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -1.0; -0.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0}; {1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0}}; ||         double[] inters = {0.043376922607421875; 0.11445245146751404; -0.0031709671020507812}; ||         int[] classes = {0; 1; 2}; ||         double[] kernels = new double[150]; ||         double kernel; ||         for (int i = 0; i < 150; i++) { ||             kernel = 0.; ||             for (int j = 0; j < 4; j++) { ||                 kernel += Math.pow(svs[i][j] - atts[j]; 2); ||             } ||             kernels[i] = Math.exp(-0.001 * kernel); ||         } ||  ||         int[] n_svs = {50; 50; 50}; ||         int[] starts = new int[3]; ||         for (int i = 0; i < 3; i++) { ||             if (i != 0) { ||                 int start = 0; ||                 for (int j = 0; j < i; j++) { ||                     start += n_svs[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||  ||         int[] ends = new int[3]; ||         for (int i = 0; i < 3; i++) { ||             ends[i] = n_svs[i] + starts[i]; ||         } ||  ||         double[] decisions = new double[3]; ||         for (int i = 0; d = 0; l = 3; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 double tmp1 = 0.; tmp2 = 0.; ||                 for (int k = starts[j]; k < ends[j]; k++) { ||                     tmp1 += kernels[k] * coeffs[i][k]; ||                 } ||                 for (int k = starts[i]; k < ends[i]; k++) { ||                     tmp2 += kernels[k] * coeffs[j - 1][k]; ||                 } ||                 decisions[d] = tmp1 + tmp2 + inters[d++]; ||             } ||         } ||  ||         int[] votes = new int[3]; ||         for (int i = 0; d = 0; l = 3; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d++] > 0 ? i : j; ||             } ||         } ||  ||         int[] amounts = new int[3]; ||         for (int i = 0; l = 3; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         int class_val = -1; class_idx = -1; ||         for (int i = 0; l = 3; i < l; i++) { ||             if (amounts[i] > class_val) { ||                 class_val = amounts[i]; ||                 class_idx = i; ||             } ||         } ||         return classes[class_idx]; ||     } ||  ||     public static void main(String[] args) { ||         if (args.length == 4) { ||             float[] atts = new float[args.length]; ||             for (int i = 0; l = args.length; i < l; i++) { ||                 atts[i] = Float.parseFloat(args[i]); ||             } ||             System.out.println(Tmp.predict(atts)); ||         } ||     } ||  || } || \""\""\""",No,Yes,Yes
16268,TODO: Refactor depth handling,Yes,No,Yes
16269,TODO: Add indentation:,,,Yes
16270,TODO: Add indentation:,,,Yes
16272,"\""\""\"" || var predictor = function(atts) { ||  ||     var predict = function(atts) { ||  ||         var svs = [[5.0999999999999996; 3.5; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.3; 0.20000000000000001]; [4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001]; [5.0; 3.6000000000000001; 1.3999999999999999; 0.20000000000000001]; [5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002]; [4.5999999999999996; 3.3999999999999999; 1.3999999999999999; 0.29999999999999999]; [5.0; 3.3999999999999999; 1.5; 0.20000000000000001]; [4.4000000000000004; 2.8999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001]; [4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.10000000000000001]; [4.2999999999999998; 3.0; 1.1000000000000001; 0.10000000000000001]; [5.7999999999999998; 4.0; 1.2; 0.20000000000000001]; [5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002]; [5.4000000000000004; 3.8999999999999999; 1.3; 0.40000000000000002]; [5.0999999999999996; 3.5; 1.3999999999999999; 0.29999999999999999]; [5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999]; [5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001]; [5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002]; [4.5999999999999996; 3.6000000000000001; 1.0; 0.20000000000000001]; [5.0999999999999996; 3.2999999999999998; 1.7; 0.5]; [4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001]; [5.0; 3.0; 1.6000000000000001; 0.20000000000000001]; [5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002]; [5.2000000000000002; 3.5; 1.5; 0.20000000000000001]; [5.2000000000000002; 3.3999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001]; [5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002]; [5.2000000000000002; 4.0999999999999996; 1.5; 0.10000000000000001]; [5.5; 4.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.0; 3.2000000000000002; 1.2; 0.20000000000000001]; [5.5; 3.5; 1.3; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [4.4000000000000004; 3.0; 1.3; 0.20000000000000001]; [5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001]; [5.0; 3.5; 1.3; 0.29999999999999999]; [4.5; 2.2999999999999998; 1.3; 0.29999999999999999]; [4.4000000000000004; 3.2000000000000002; 1.3; 0.20000000000000001]; [5.0; 3.5; 1.6000000000000001; 0.59999999999999998]; [5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001]; [4.5999999999999996; 3.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001]; [5.0; 3.2999999999999998; 1.3999999999999999; 0.20000000000000001]; [7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 4.5; 1.5]; [6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5]; [5.5; 2.2999999999999998; 4.0; 1.3]; [6.5; 2.7999999999999998; 4.5999999999999996; 1.5]; [5.7000000000000002; 2.7999999999999998; 4.5; 1.3]; [6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001]; [4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0]; [6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3]; [5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999]; [5.0; 2.0; 3.5; 1.0]; [5.9000000000000004; 3.0; 4.2000000000000002; 1.5]; [6.0; 2.2000000000000002; 4.0; 1.0]; [6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999]; [5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3]; [6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999]; [5.5999999999999996; 3.0; 4.5; 1.5]; [5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0]; [6.2000000000000002; 2.2000000000000002; 4.5; 1.5]; [5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001]; [5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8]; [6.0999999999999996; 2.7999999999999998; 4.0; 1.3]; [6.2999999999999998; 2.5; 4.9000000000000004; 1.5]; [6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2]; [6.4000000000000004; 2.8999999999999999; 4.2999999999999998; 1.3]; [6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999]; [6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999]; [6.7000000000000002; 3.0; 5.0; 1.7]; [6.0; 2.8999999999999999; 4.5; 1.5]; [5.7000000000000002; 2.6000000000000001; 3.5; 1.0]; [5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001]; [5.5; 2.3999999999999999; 3.7000000000000002; 1.0]; [5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2]; [6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001]; [5.4000000000000004; 3.0; 4.5; 1.5]; [6.0; 3.3999999999999999; 4.5; 1.6000000000000001]; [6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5]; [6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3]; [5.5999999999999996; 3.0; 4.0999999999999996; 1.3]; [5.5; 2.5; 4.0; 1.3]; [5.5; 2.6000000000000001; 4.4000000000000004; 1.2]; [6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999]; [5.7999999999999998; 2.6000000000000001; 4.0; 1.2]; [5.0; 2.2999999999999998; 3.2999999999999998; 1.0]; [5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3]; [5.7000000000000002; 3.0; 4.2000000000000002; 1.2]; [5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3]; [6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3]; [5.0999999999999996; 2.5; 3.0; 1.1000000000000001]; [5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3]; [6.2999999999999998; 3.2999999999999998; 6.0; 2.5]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [7.0999999999999996; 3.0; 5.9000000000000004; 2.1000000000000001]; [6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8]; [6.5; 3.0; 5.7999999999999998; 2.2000000000000002]; [7.5999999999999996; 3.0; 6.5999999999999996; 2.1000000000000001]; [4.9000000000000004; 2.5; 4.5; 1.7]; [7.2999999999999998; 2.8999999999999999; 6.2999999999999998; 1.8]; [6.7000000000000002; 2.5; 5.7999999999999998; 1.8]; [7.2000000000000002; 3.6000000000000001; 6.0999999999999996; 2.5]; [6.5; 3.2000000000000002; 5.0999999999999996; 2.0]; [6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999]; [6.7999999999999998; 3.0; 5.5; 2.1000000000000001]; [5.7000000000000002; 2.5; 5.0; 2.0]; [5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998]; [6.5; 3.0; 5.5; 1.8]; [7.7000000000000002; 3.7999999999999998; 6.7000000000000002; 2.2000000000000002]; [7.7000000000000002; 2.6000000000000001; 6.9000000000000004; 2.2999999999999998]; [6.0; 2.2000000000000002; 5.0; 1.5]; [6.9000000000000004; 3.2000000000000002; 5.7000000000000002; 2.2999999999999998]; [5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0]; [7.7000000000000002; 2.7999999999999998; 6.7000000000000002; 2.0]; [6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.1000000000000001]; [7.2000000000000002; 3.2000000000000002; 6.0; 1.8]; [6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8]; [6.0999999999999996; 3.0; 4.9000000000000004; 1.8]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.1000000000000001]; [7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001]; [7.4000000000000004; 2.7999999999999998; 6.0999999999999996; 1.8999999999999999]; [7.9000000000000004; 3.7999999999999998; 6.4000000000000004; 2.0]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.2000000000000002]; [6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5]; [6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999]; [7.7000000000000002; 3.0; 6.0999999999999996; 2.2999999999999998]; [6.2999999999999998; 3.3999999999999999; 5.5999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.1000000000000001; 5.5; 1.8]; [6.0; 3.0; 4.7999999999999998; 1.8]; [6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001]; [6.7000000000000002; 3.1000000000000001; 5.5999999999999996; 2.3999999999999999]; [6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [6.7999999999999998; 3.2000000000000002; 5.9000000000000004; 2.2999999999999998]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.5]; [6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998]; [6.2999999999999998; 2.5; 5.0; 1.8999999999999999]; [6.5; 3.0; 5.2000000000000002; 2.0]; [6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998]; [5.9000000000000004; 3.0; 5.0999999999999996; 1.8]]; ||         var coeffs = [[1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -1.0; -0.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]; [1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]]; ||         var inters = [0.043376922607421875; 0.11445245146751404; -0.0031709671020507812]; ||         var classes = [0; 1; 2]; ||  ||         \/\/ exp(-y|x-x'|^2) ||         var kernels = new Array(150); ||             kernel; ||         for (var i=0; i<150; i++) { ||             kernel = 0.; ||             for (var j=0; j<4; j++) { ||                 kernel += Math.pow(svs[i][j] - atts[j]; 2); ||             } ||             kernels[i] = Math.exp(-0.001 * kernel); ||         } ||  ||         var n_svs = [50; 50; 50];var starts = new Array(3); ||         for (var i=0; i<3; i++) { ||             if (i!=0) { ||                 var start = 0; ||                 for (var j=0; j<i; j++) { ||                     start += n_svs[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||         var ends = new Array(3); ||         for (var i=0; i<3; i++) { ||             ends[i] = n_svs[i] + starts[i]; ||         } ||         var decisions = new Array(3); ||         for (var i = 0; d = 0; l = 3; i < l; i++) { ||             for (var j = i + 1; j < l; j++) { ||                 var tmp1 = 0.; tmp2 = 0.; ||                 for (var k = starts[j]; k < ends[j]; k++) { ||                    tmp1 += kernels[k] * coeffs[i][k]; ||                 } ||                 for (var k = starts[i]; k < ends[i]; k++) { ||                     tmp2 += kernels[k] * coeffs[j - 1][k]; ||                 } ||                 decisions[d] = tmp1 + tmp2 + inters[d++]; ||             } ||         }var votes = new Array(3); ||         for (var i = 0; d = 0; l = 3; i < l; i++) { ||             for (var j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d++] > 0 ? i : j; ||             } ||         } ||  ||         var amounts = Array.apply(null; Array(3)).map(Number.prototype.valueOf;0); ||         for (var i = 0; l = 3; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         var class_val = -1; class_idx = -1; ||         for (var i = 0; l = 3; i < l; i++) { ||             if (amounts[i] > class_val) { ||                 class_val = amounts[i]; ||                 class_idx = i; ||             } ||         } ||         return classes[class_idx]; ||     }; ||  ||     return predict(atts); || }; ||  || if (typeof process !== 'undefined' && typeof process.argv !== 'undefined') { ||     if (process.argv.length - 2 == 4) { ||         var argv = process.argv.slice(2); ||         var prediction = predictor(argv); ||         console.log(prediction); ||     } || } || \""\""\""",No,Yes,Yes
16274,"\""\""\"" || <?php ||  || class Tmp { ||  ||     public static function predict($atts) { ||  ||         $svs = [[5.0999999999999996; 3.5; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.3; 0.20000000000000001]; [4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001]; [5.0; 3.6000000000000001; 1.3999999999999999; 0.20000000000000001]; [5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002]; [4.5999999999999996; 3.3999999999999999; 1.3999999999999999; 0.29999999999999999]; [5.0; 3.3999999999999999; 1.5; 0.20000000000000001]; [4.4000000000000004; 2.8999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001]; [4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.10000000000000001]; [4.2999999999999998; 3.0; 1.1000000000000001; 0.10000000000000001]; [5.7999999999999998; 4.0; 1.2; 0.20000000000000001]; [5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002]; [5.4000000000000004; 3.8999999999999999; 1.3; 0.40000000000000002]; [5.0999999999999996; 3.5; 1.3999999999999999; 0.29999999999999999]; [5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999]; [5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001]; [5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002]; [4.5999999999999996; 3.6000000000000001; 1.0; 0.20000000000000001]; [5.0999999999999996; 3.2999999999999998; 1.7; 0.5]; [4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001]; [5.0; 3.0; 1.6000000000000001; 0.20000000000000001]; [5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002]; [5.2000000000000002; 3.5; 1.5; 0.20000000000000001]; [5.2000000000000002; 3.3999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001]; [5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002]; [5.2000000000000002; 4.0999999999999996; 1.5; 0.10000000000000001]; [5.5; 4.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.0; 3.2000000000000002; 1.2; 0.20000000000000001]; [5.5; 3.5; 1.3; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [4.4000000000000004; 3.0; 1.3; 0.20000000000000001]; [5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001]; [5.0; 3.5; 1.3; 0.29999999999999999]; [4.5; 2.2999999999999998; 1.3; 0.29999999999999999]; [4.4000000000000004; 3.2000000000000002; 1.3; 0.20000000000000001]; [5.0; 3.5; 1.6000000000000001; 0.59999999999999998]; [5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001]; [4.5999999999999996; 3.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001]; [5.0; 3.2999999999999998; 1.3999999999999999; 0.20000000000000001]; [7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 4.5; 1.5]; [6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5]; [5.5; 2.2999999999999998; 4.0; 1.3]; [6.5; 2.7999999999999998; 4.5999999999999996; 1.5]; [5.7000000000000002; 2.7999999999999998; 4.5; 1.3]; [6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001]; [4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0]; [6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3]; [5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999]; [5.0; 2.0; 3.5; 1.0]; [5.9000000000000004; 3.0; 4.2000000000000002; 1.5]; [6.0; 2.2000000000000002; 4.0; 1.0]; [6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999]; [5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3]; [6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999]; [5.5999999999999996; 3.0; 4.5; 1.5]; [5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0]; [6.2000000000000002; 2.2000000000000002; 4.5; 1.5]; [5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001]; [5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8]; [6.0999999999999996; 2.7999999999999998; 4.0; 1.3]; [6.2999999999999998; 2.5; 4.9000000000000004; 1.5]; [6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2]; [6.4000000000000004; 2.8999999999999999; 4.2999999999999998; 1.3]; [6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999]; [6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999]; [6.7000000000000002; 3.0; 5.0; 1.7]; [6.0; 2.8999999999999999; 4.5; 1.5]; [5.7000000000000002; 2.6000000000000001; 3.5; 1.0]; [5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001]; [5.5; 2.3999999999999999; 3.7000000000000002; 1.0]; [5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2]; [6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001]; [5.4000000000000004; 3.0; 4.5; 1.5]; [6.0; 3.3999999999999999; 4.5; 1.6000000000000001]; [6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5]; [6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3]; [5.5999999999999996; 3.0; 4.0999999999999996; 1.3]; [5.5; 2.5; 4.0; 1.3]; [5.5; 2.6000000000000001; 4.4000000000000004; 1.2]; [6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999]; [5.7999999999999998; 2.6000000000000001; 4.0; 1.2]; [5.0; 2.2999999999999998; 3.2999999999999998; 1.0]; [5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3]; [5.7000000000000002; 3.0; 4.2000000000000002; 1.2]; [5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3]; [6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3]; [5.0999999999999996; 2.5; 3.0; 1.1000000000000001]; [5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3]; [6.2999999999999998; 3.2999999999999998; 6.0; 2.5]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [7.0999999999999996; 3.0; 5.9000000000000004; 2.1000000000000001]; [6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8]; [6.5; 3.0; 5.7999999999999998; 2.2000000000000002]; [7.5999999999999996; 3.0; 6.5999999999999996; 2.1000000000000001]; [4.9000000000000004; 2.5; 4.5; 1.7]; [7.2999999999999998; 2.8999999999999999; 6.2999999999999998; 1.8]; [6.7000000000000002; 2.5; 5.7999999999999998; 1.8]; [7.2000000000000002; 3.6000000000000001; 6.0999999999999996; 2.5]; [6.5; 3.2000000000000002; 5.0999999999999996; 2.0]; [6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999]; [6.7999999999999998; 3.0; 5.5; 2.1000000000000001]; [5.7000000000000002; 2.5; 5.0; 2.0]; [5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998]; [6.5; 3.0; 5.5; 1.8]; [7.7000000000000002; 3.7999999999999998; 6.7000000000000002; 2.2000000000000002]; [7.7000000000000002; 2.6000000000000001; 6.9000000000000004; 2.2999999999999998]; [6.0; 2.2000000000000002; 5.0; 1.5]; [6.9000000000000004; 3.2000000000000002; 5.7000000000000002; 2.2999999999999998]; [5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0]; [7.7000000000000002; 2.7999999999999998; 6.7000000000000002; 2.0]; [6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.1000000000000001]; [7.2000000000000002; 3.2000000000000002; 6.0; 1.8]; [6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8]; [6.0999999999999996; 3.0; 4.9000000000000004; 1.8]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.1000000000000001]; [7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001]; [7.4000000000000004; 2.7999999999999998; 6.0999999999999996; 1.8999999999999999]; [7.9000000000000004; 3.7999999999999998; 6.4000000000000004; 2.0]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.2000000000000002]; [6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5]; [6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999]; [7.7000000000000002; 3.0; 6.0999999999999996; 2.2999999999999998]; [6.2999999999999998; 3.3999999999999999; 5.5999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.1000000000000001; 5.5; 1.8]; [6.0; 3.0; 4.7999999999999998; 1.8]; [6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001]; [6.7000000000000002; 3.1000000000000001; 5.5999999999999996; 2.3999999999999999]; [6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [6.7999999999999998; 3.2000000000000002; 5.9000000000000004; 2.2999999999999998]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.5]; [6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998]; [6.2999999999999998; 2.5; 5.0; 1.8999999999999999]; [6.5; 3.0; 5.2000000000000002; 2.0]; [6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998]; [5.9000000000000004; 3.0; 5.0999999999999996; 1.8]]; ||         $coeffs = [[1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -1.0; -0.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]; [1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]]; ||         $inters = [0.043376922607421875; 0.11445245146751404; -0.0031709671020507812]; ||         $classes = [0; 1; 2]; ||  ||         \/\/ exp(-y|x-x'|^2) ||         $kernels = array_fill(0; 150; 0); ||         for ($i = 0; $i < 150; $i++) { ||             $kernel = 0.; ||             for ($j = 0; $j < 4; $j++) { ||                 $kernel += pow($svs[$i][$j] - $atts[$j]; 2); ||             } ||             $kernels[$i] = exp(-0.001 * $kernel); ||         } ||         $n_svs = [50; 50; 50];$starts = array_fill(0; 3; 0); ||         for ($i = 0; $i < 3; $i++) { ||             if ($i != 0) { ||                 $start = 0.; ||                 for ($j = 0; $j < $i; $j++) { ||                     $start += $n_svs[$j]; ||                 } ||                 $starts[$i] = $start; ||             } else { ||                 $starts[0] = 0; ||             } ||         } ||         $ends = array_fill(0; 3; 0); ||         for ($i = 0; $i < 3; $i++) { ||             $ends[$i] = $n_svs[$i] + $starts[$i]; ||         } ||         $decisions = array_fill(0; 3; 0); ||         for ($i = 0; $d = 0; $l = 3; $i < $l; $i++) { ||             for ($j = $i + 1; $j < $l; $j++) { ||                 $tmp1 = 0.; ||                 $tmp2 = 0.; ||                 for ($k = $starts[$j]; $k < $ends[$j]; $k++) { ||                    $tmp1 += $kernels[$k] * $coeffs[$i][$k]; ||                 } ||                 for ($k = $starts[$i]; $k < $ends[$i]; $k++) { ||                     $tmp2 += $kernels[$k] * $coeffs[$j - 1][$k]; ||                 } ||                 $decisions[$d] = $tmp1 + $tmp2 + $inters[$d]; ||                 $d++; ||             } ||         } ||         $votes = array_fill(0; 3; 0); ||         for ($i = 0; $d = 0; $l = 3; $i < $l; $i++) { ||             for ($j = $i + 1; $j < $l; $j++) { ||                 $votes[$d] = $decisions[$d] > 0 ? $i : $j; ||                 $d++; ||             } ||         } ||  ||         $amounts = array_fill(0; 3; 0); ||         for ($i = 0; $l = 3; $i < $l; $i++) { ||             $amounts[$votes[$i]]++; ||         } ||  ||         $class_val = -1; ||         $class_idx = -1; ||         for ($i = 0; $l = 3; $i < $l; $i++) { ||             if ($amounts[$i] > $class_val) { ||                 $class_val = $amounts[$i]; ||                 $class_idx = $i; ||             } ||         } ||         return $classes[$class_idx]; ||     } ||  || } ||  || if ($argc > 1) { ||     array_shift($argv); ||     $prediction = Tmp::predict($argv); ||     fwrite(STDOUT; $prediction); || } || \""\""\""",No,Yes,Yes
16275,"\""\""\"" || #include <stdlib.h> || #include <stdio.h> || #include <math.h> ||  || int predict(float atts[]) { ||     int i; j; k; d; l; ||  ||     double svs[105][4] = {{4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001}; {4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001}; {5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002}; {5.0; 3.3999999999999999; 1.5; 0.20000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001}; {4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001}; {5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002}; {5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999}; {5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001}; {5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002}; {5.0999999999999996; 3.2999999999999998; 1.7; 0.5}; {4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001}; {5.0; 3.0; 1.6000000000000001; 0.20000000000000001}; {5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002}; {5.2000000000000002; 3.5; 1.5; 0.20000000000000001}; {4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001}; {4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001}; {5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001}; {4.5; 2.2999999999999998; 1.3; 0.29999999999999999}; {5.0; 3.5; 1.6000000000000001; 0.59999999999999998}; {5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002}; {4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001}; {5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001}; {7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 4.5; 1.5}; {6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5}; {5.5; 2.2999999999999998; 4.0; 1.3}; {6.5; 2.7999999999999998; 4.5999999999999996; 1.5}; {5.7000000000000002; 2.7999999999999998; 4.5; 1.3}; {6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001}; {4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0}; {6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3}; {5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999}; {5.0; 2.0; 3.5; 1.0}; {5.9000000000000004; 3.0; 4.2000000000000002; 1.5}; {6.0; 2.2000000000000002; 4.0; 1.0}; {6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999}; {5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3}; {6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999}; {5.5999999999999996; 3.0; 4.5; 1.5}; {5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0}; {6.2000000000000002; 2.2000000000000002; 4.5; 1.5}; {5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001}; {5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8}; {6.0999999999999996; 2.7999999999999998; 4.0; 1.3}; {6.2999999999999998; 2.5; 4.9000000000000004; 1.5}; {6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2}; {6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999}; {6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999}; {6.7000000000000002; 3.0; 5.0; 1.7}; {6.0; 2.8999999999999999; 4.5; 1.5}; {5.7000000000000002; 2.6000000000000001; 3.5; 1.0}; {5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001}; {5.5; 2.3999999999999999; 3.7000000000000002; 1.0}; {5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2}; {6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001}; {5.4000000000000004; 3.0; 4.5; 1.5}; {6.0; 3.3999999999999999; 4.5; 1.6000000000000001}; {6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5}; {6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3}; {5.5999999999999996; 3.0; 4.0999999999999996; 1.3}; {5.5; 2.5; 4.0; 1.3}; {5.5; 2.6000000000000001; 4.4000000000000004; 1.2}; {6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999}; {5.7999999999999998; 2.6000000000000001; 4.0; 1.2}; {5.0; 2.2999999999999998; 3.2999999999999998; 1.0}; {5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3}; {5.7000000000000002; 3.0; 4.2000000000000002; 1.2}; {5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3}; {6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3}; {5.0999999999999996; 2.5; 3.0; 1.1000000000000001}; {5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8}; {4.9000000000000004; 2.5; 4.5; 1.7}; {6.5; 3.2000000000000002; 5.0999999999999996; 2.0}; {6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999}; {5.7000000000000002; 2.5; 5.0; 2.0}; {5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998}; {6.5; 3.0; 5.5; 1.8}; {6.0; 2.2000000000000002; 5.0; 1.5}; {5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0}; {6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8}; {6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8}; {6.0999999999999996; 3.0; 4.9000000000000004; 1.8}; {7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001}; {6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5}; {6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999}; {6.4000000000000004; 3.1000000000000001; 5.5; 1.8}; {6.0; 3.0; 4.7999999999999998; 1.8}; {6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001}; {6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998}; {6.2999999999999998; 2.5; 5.0; 1.8999999999999999}; {6.5; 3.0; 5.2000000000000002; 2.0}; {6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998}; {5.9000000000000004; 3.0; 5.0999999999999996; 1.8}}; ||     double coeffs[2][105] = {{4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 4.6863813658892557; 0.0; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948}; {0.0; 0.0; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893}}; ||     double inters[] = {0.10061840191760112; 0.051748160156319709; -0.084181689668018464}; ||     int classes[] = {0; 1; 2}; ||  ||     \/\/ exp(-y|x-x'|^2) ||     double kernels[105]; ||     double kernel; ||     for (i = 0; i < 105; i++) { ||         kernel = 0.; ||         for (j = 0; j < 4; j++) { ||             kernel += pow(svs[i][j] - atts[j]; 2); ||         } ||         kernels[i] = exp(-0.001 * kernel); ||     } ||     int n_svs[] = {29; 49; 27};int starts[3]; ||     for (i = 0; i < 3; i++) { ||         if (i != 0) { ||             int start = 0; ||             for (j = 0; j < i; j++) { ||                 start += n_svs[j]; ||             } ||             starts[i] = start; ||         } else { ||             starts[0] = 0; ||         } ||     } ||  ||     int ends[3]; ||     for (i = 0; i < 3; i++) { ||         ends[i] = n_svs[i] + starts[i]; ||     } ||  ||     double decisions[3]; ||     for (i = 0; d = 0; l = 3; i < l; i++) { ||         for (j = i + 1; j < l; j++) { ||             double tmp1 = 0.; tmp2 = 0.; ||             for (k = starts[j]; k < ends[j]; k++) { ||                tmp1 += kernels[k] * coeffs[i][k]; ||             } ||             for (k = starts[i]; k < ends[i]; k++) { ||                 tmp2 += kernels[k] * coeffs[j - 1][k]; ||             } ||             decisions[d] = tmp1 + tmp2 + inters[d]; ||             d = d + 1; ||         } ||     } ||  ||     int votes[3]; ||     for (i = 0; d = 0; l = 3; i < l; i++) { ||         for (j = i + 1; j < l; j++) { ||             votes[d] = decisions[d] > 0 ? i : j; ||             d = d + 1; ||         } ||     } ||  ||     int amounts[3]; ||     for (i = 0; l = 3; i < l; i++) { ||         amounts[i] = 0; ||     } ||     for (i = 0; l = 3; i < l; i++) { ||         amounts[votes[i]] += 1; ||     } ||  ||     int class_val = -1; class_idx = -1; ||     for (i = 0; l = 3; i < l; i++) { ||         if (amounts[i] > class_val) { ||             class_val = amounts[i]; ||             class_idx = i; ||         } ||     } ||     return classes[class_idx]; || } ||  || int main(int argc; const char * argv[]) { ||     float atts[argc-1]; ||     int i = 0; ||     for (i = 1; i < argc; i++) { ||         atts[i-1] = atof(argv[i]); ||     } ||     printf(\""%d\""; predict(atts)); ||     return 0; || } || \""\""\""",Yes,Yes,Yes
16276,"\""\""\"" || class Tmp { ||  ||     public static int predict(float[] atts) { ||  ||         double[][] svs = {{4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001}; {4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001}; {5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002}; {5.0; 3.3999999999999999; 1.5; 0.20000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001}; {4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001}; {5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002}; {5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999}; {5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001}; {5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002}; {5.0999999999999996; 3.2999999999999998; 1.7; 0.5}; {4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001}; {5.0; 3.0; 1.6000000000000001; 0.20000000000000001}; {5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002}; {5.2000000000000002; 3.5; 1.5; 0.20000000000000001}; {4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001}; {4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001}; {5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001}; {5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001}; {4.5; 2.2999999999999998; 1.3; 0.29999999999999999}; {5.0; 3.5; 1.6000000000000001; 0.59999999999999998}; {5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002}; {4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999}; {5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001}; {5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001}; {7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 4.5; 1.5}; {6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5}; {5.5; 2.2999999999999998; 4.0; 1.3}; {6.5; 2.7999999999999998; 4.5999999999999996; 1.5}; {5.7000000000000002; 2.7999999999999998; 4.5; 1.3}; {6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001}; {4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0}; {6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3}; {5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999}; {5.0; 2.0; 3.5; 1.0}; {5.9000000000000004; 3.0; 4.2000000000000002; 1.5}; {6.0; 2.2000000000000002; 4.0; 1.0}; {6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999}; {5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3}; {6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999}; {5.5999999999999996; 3.0; 4.5; 1.5}; {5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0}; {6.2000000000000002; 2.2000000000000002; 4.5; 1.5}; {5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001}; {5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8}; {6.0999999999999996; 2.7999999999999998; 4.0; 1.3}; {6.2999999999999998; 2.5; 4.9000000000000004; 1.5}; {6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2}; {6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999}; {6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999}; {6.7000000000000002; 3.0; 5.0; 1.7}; {6.0; 2.8999999999999999; 4.5; 1.5}; {5.7000000000000002; 2.6000000000000001; 3.5; 1.0}; {5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001}; {5.5; 2.3999999999999999; 3.7000000000000002; 1.0}; {5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2}; {6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001}; {5.4000000000000004; 3.0; 4.5; 1.5}; {6.0; 3.3999999999999999; 4.5; 1.6000000000000001}; {6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5}; {6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3}; {5.5999999999999996; 3.0; 4.0999999999999996; 1.3}; {5.5; 2.5; 4.0; 1.3}; {5.5; 2.6000000000000001; 4.4000000000000004; 1.2}; {6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999}; {5.7999999999999998; 2.6000000000000001; 4.0; 1.2}; {5.0; 2.2999999999999998; 3.2999999999999998; 1.0}; {5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3}; {5.7000000000000002; 3.0; 4.2000000000000002; 1.2}; {5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3}; {6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3}; {5.0999999999999996; 2.5; 3.0; 1.1000000000000001}; {5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8}; {4.9000000000000004; 2.5; 4.5; 1.7}; {6.5; 3.2000000000000002; 5.0999999999999996; 2.0}; {6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999}; {5.7000000000000002; 2.5; 5.0; 2.0}; {5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999}; {6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998}; {6.5; 3.0; 5.5; 1.8}; {6.0; 2.2000000000000002; 5.0; 1.5}; {5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0}; {6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8}; {6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8}; {6.0999999999999996; 3.0; 4.9000000000000004; 1.8}; {7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001}; {6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5}; {6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999}; {6.4000000000000004; 3.1000000000000001; 5.5; 1.8}; {6.0; 3.0; 4.7999999999999998; 1.8}; {6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001}; {6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998}; {5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999}; {6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998}; {6.2999999999999998; 2.5; 5.0; 1.8999999999999999}; {6.5; 3.0; 5.2000000000000002; 2.0}; {6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998}; {5.9000000000000004; 3.0; 5.0999999999999996; 1.8}}; ||         double[][] coeffs = {{4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 4.6863813658892557; 0.0; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948}; {0.0; 0.0; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893}}; ||         double[] inters = {0.10061840191760112; 0.051748160156319709; -0.084181689668018464}; ||         int[] classes = {0; 1; 2}; ||  ||         \/\/ exp(-y|x-x'|^2) ||         double[] kernels = new double[105]; ||         double kernel; ||         for (int i=0; i<105; i++) { ||             kernel = 0.; ||             for (int j=0; j<4; j++) { ||                 kernel += Math.pow(svs[i][j] - atts[j]; 2); ||             } ||             kernels[i] = Math.exp(-0.001 * kernel); ||         } ||         int[] n_svs = {29; 49; 27};int[] starts = new int[3]; ||         for (int i=0; i<3; i++) { ||             if (i!=0) { ||                 int start = 0; ||                 for (int j=0; j<i; j++) { ||                     start += n_svs[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||  ||         int[] ends = new int[3]; ||         for (int i=0; i<3; i++) { ||             ends[i] = n_svs[i] + starts[i]; ||         } ||  ||         double[] decisions = new double[3]; ||         for (int i = 0; d = 0; l = 3; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 double tmp1 = 0.; tmp2 = 0.; ||                 for (int k = starts[j]; k < ends[j]; k++) { ||                    tmp1 += kernels[k] * coeffs[i][k]; ||                 } ||                 for (int k = starts[i]; k < ends[i]; k++) { ||                     tmp2 += kernels[k] * coeffs[j - 1][k]; ||                 } ||                 decisions[d] = tmp1 + tmp2 + inters[d++]; ||             } ||         } ||  ||         int[] votes = new int[3]; ||         for (int i = 0; d = 0; l = 3; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d++] > 0 ? i : j; ||             } ||         } ||  ||         int[] amounts = new int[3]; ||         for (int i = 0; l = 3; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         int class_val = -1; class_idx = -1; ||         for (int i = 0; l = 3; i < l; i++) { ||             if (amounts[i] > class_val) { ||                 class_val = amounts[i]; ||                 class_idx = i; ||             } ||         } ||         return classes[class_idx]; ||     } ||  ||     public static void main(String[] args) { ||         if (args.length == 4) { ||             float[] atts = new float[args.length]; ||             for (int i = 0; l = args.length; i < l; i++) { ||                 atts[i] = Float.parseFloat(args[i]); ||             } ||             System.out.println(Tmp.predict(atts)); ||         } ||     } || } || \""\""\""",,,Yes
16277,"\""\""\"" || \/\/ Array.prototype.fill polyfill: || [].fill||(Array.prototype.fill=function(a){for(var b=Object(this);c=parseInt(b.length;10);d=arguments[1];e=parseInt(d;10)||0;f=0>e?Math.max(c+e;0):Math.min(e;c);g=arguments[2];h=void 0===g?c:parseInt(g)||0;i=0>h?Math.max(c+h;0):Math.min(h;c);i>f;f++)b[f]=a;return b}); ||  || var Tmp = function(atts) { ||  ||     this.predict = function(atts) { ||         var i; j; k; d; l; ||  ||         var svs = [[4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001]; [4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001]; [5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002]; [5.0; 3.3999999999999999; 1.5; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001]; [4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001]; [5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002]; [5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999]; [5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001]; [5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002]; [5.0999999999999996; 3.2999999999999998; 1.7; 0.5]; [4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001]; [5.0; 3.0; 1.6000000000000001; 0.20000000000000001]; [5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002]; [5.2000000000000002; 3.5; 1.5; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001]; [5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001]; [4.5; 2.2999999999999998; 1.3; 0.29999999999999999]; [5.0; 3.5; 1.6000000000000001; 0.59999999999999998]; [5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001]; [5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001]; [7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 4.5; 1.5]; [6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5]; [5.5; 2.2999999999999998; 4.0; 1.3]; [6.5; 2.7999999999999998; 4.5999999999999996; 1.5]; [5.7000000000000002; 2.7999999999999998; 4.5; 1.3]; [6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001]; [4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0]; [6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3]; [5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999]; [5.0; 2.0; 3.5; 1.0]; [5.9000000000000004; 3.0; 4.2000000000000002; 1.5]; [6.0; 2.2000000000000002; 4.0; 1.0]; [6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999]; [5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3]; [6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999]; [5.5999999999999996; 3.0; 4.5; 1.5]; [5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0]; [6.2000000000000002; 2.2000000000000002; 4.5; 1.5]; [5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001]; [5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8]; [6.0999999999999996; 2.7999999999999998; 4.0; 1.3]; [6.2999999999999998; 2.5; 4.9000000000000004; 1.5]; [6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2]; [6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999]; [6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999]; [6.7000000000000002; 3.0; 5.0; 1.7]; [6.0; 2.8999999999999999; 4.5; 1.5]; [5.7000000000000002; 2.6000000000000001; 3.5; 1.0]; [5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001]; [5.5; 2.3999999999999999; 3.7000000000000002; 1.0]; [5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2]; [6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001]; [5.4000000000000004; 3.0; 4.5; 1.5]; [6.0; 3.3999999999999999; 4.5; 1.6000000000000001]; [6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5]; [6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3]; [5.5999999999999996; 3.0; 4.0999999999999996; 1.3]; [5.5; 2.5; 4.0; 1.3]; [5.5; 2.6000000000000001; 4.4000000000000004; 1.2]; [6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999]; [5.7999999999999998; 2.6000000000000001; 4.0; 1.2]; [5.0; 2.2999999999999998; 3.2999999999999998; 1.0]; [5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3]; [5.7000000000000002; 3.0; 4.2000000000000002; 1.2]; [5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3]; [6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3]; [5.0999999999999996; 2.5; 3.0; 1.1000000000000001]; [5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8]; [4.9000000000000004; 2.5; 4.5; 1.7]; [6.5; 3.2000000000000002; 5.0999999999999996; 2.0]; [6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999]; [5.7000000000000002; 2.5; 5.0; 2.0]; [5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998]; [6.5; 3.0; 5.5; 1.8]; [6.0; 2.2000000000000002; 5.0; 1.5]; [5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0]; [6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8]; [6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8]; [6.0999999999999996; 3.0; 4.9000000000000004; 1.8]; [7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001]; [6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5]; [6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999]; [6.4000000000000004; 3.1000000000000001; 5.5; 1.8]; [6.0; 3.0; 4.7999999999999998; 1.8]; [6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001]; [6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998]; [6.2999999999999998; 2.5; 5.0; 1.8999999999999999]; [6.5; 3.0; 5.2000000000000002; 2.0]; [6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998]; [5.9000000000000004; 3.0; 5.0999999999999996; 1.8]]; ||         var coeffs = [[4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 4.6863813658892557; 0.0; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 4.6863813658892557; 0.0; 0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -0.0; -0.0; -0.0; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -0.0; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -4.6863813658892557; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -0.0; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948; -2.1272220789292948]; [0.0; 0.0; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 0.0; 2.1272220789292948; 2.1272220789292948; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 47.529341773693893; 47.529341773693893; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -47.529341773693893; -0.0; -47.529341773693893]]; ||         var inters = [0.10061840191760112; 0.051748160156319709; -0.084181689668018464]; ||         var classes = [0; 1; 2]; ||  ||         \/\/ exp(-y|x-x'|^2) ||         var kernels = new Array(105); ||             kernel; ||         for (i = 0; i < 105; i++) { ||             kernel = 0.; ||             for (j = 0; j < 4; j++) { ||                 kernel += Math.pow(svs[i][j] - atts[j]; 2); ||             } ||             kernels[i] = Math.exp(-0.001 * kernel); ||         } ||         var n_svs = [29; 49; 27];var starts = new Array(3); ||         for (i = 0; i < 3; i++) { ||             if (i != 0) { ||                 var start = 0; ||                 for (j = 0; j < i; j++) { ||                     start += n_svs[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||         var ends = new Array(3); ||         for (i = 0; i < 3; i++) { ||             ends[i] = n_svs[i] + starts[i]; ||         } ||         var decisions = new Array(3); ||         for (i = 0; d = 0; l = 3; i < l; i++) { ||             for (j = i + 1; j < l; j++) { ||                 var tmp1 = 0.; tmp2 = 0.; ||                 for (k = starts[j]; k < ends[j]; k++) { ||                    tmp1 += kernels[k] * coeffs[i][k]; ||                 } ||                 for (k = starts[i]; k < ends[i]; k++) { ||                     tmp2 += kernels[k] * coeffs[j - 1][k]; ||                 } ||                 decisions[d] = tmp1 + tmp2 + inters[d++]; ||             } ||         } ||         var votes = new Array(3); ||         for (i = 0; d = 0; l = 3; i < l; i++) { ||             for (j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d++] > 0 ? i : j; ||             } ||         } ||  ||         var amounts = new Array(3).fill(0); ||         for (i = 0; l = 3; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         var class_val = -1; class_idx = -1; ||         for (i = 0; l = 3; i < l; i++) { ||             if (amounts[i] > class_val) { ||                 class_val = amounts[i]; ||                 class_idx = i; ||             } ||         } ||         return classes[class_idx]; ||     }; ||  || }; ||  || if (typeof process !== 'undefined' && typeof process.argv !== 'undefined') { ||     if (process.argv.length - 2 == 4) { ||         var argv = process.argv.slice(2); ||         var prediction = new Tmp().predict(argv); ||         console.log(prediction); ||     } || } || \""\""\""",No,Yes,Yes
16279,TODO: Replace static path definition: 'classifier',Yes,Yes,Yes
16280,TODO: Add go-relevant commands,Yes,No,Yes
16286,"\""\""\"" || class SVC ||  || \tdef initialize (nClasses; nRows; vectors; coefficients; intercepts; weights; kernel; gamma; coef0; degree) || \t\t@nClasses = nClasses || \t\t@classes = Array.new(nClasses) || \t\tfor i in 0 ... nClasses || \t\t\t@classes[i] = i || \t\tend || \t\t@nRows = nRows ||  || \t\t@vectors = vectors || \t\t@coefficients = coefficients || \t\t@intercepts = intercepts || \t\t@weights = weights ||  || \t\t@kernel = kernel.upcase || \t\t@gamma = gamma || \t\t@coef0 = coef0 || \t\t@degree = degree || \tend ||  || \tdef predict (features) ||      ||     \tkernels = Array.new(@vectors.length) ||     \tcase @kernel ||     \twhen \""LINEAR\"" ||     \t\tfor i in 0 ... @vectors.length ||     \t\t\tkernel = 0 ||     \t\t\tfor j in 0 ... @vectors[i].length ||     \t\t\t\tkernel += @vectors[i][j] * features[j] ||     \t\t\tend ||     \t\t\tkernels[i] = kernel ||     \t\tend ||     \twhen 'POLY' ||     \t\tfor i in 0 ... @vectors.length ||     \t\t\tkernel = 0 ||     \t\t\tfor j in 0 ... @vectors[i].length ||     \t\t\t\tkernel += @vectors[i][j] * features[j] ||     \t\t\tend ||     \t\t\tkernels[i] = (((@gamma * kernel) + @coef0) ** @degree) ||     \t\tend ||     \twhen \""RBF\"" ||     \t\tfor i in 0 ... @vectors.length ||     \t\t\tkernel = 0 ||     \t\t\tfor j in 0 ... @vectors[i].length ||     \t\t\t\tkernel += ((@vectors[i][j] - features[j]) ** 2) ||     \t\t\tend ||     \t\t\tkernels[i] = Math.exp(-@gamma * kernel) ||     \t\tend ||     \twhen 'SIGMOID' ||     \t\tfor i in 0 ... @vectors.length ||     \t\t\tkernel = 0 ||     \t\t\tfor j in 0 ... @vectors[i].length ||     \t\t\t\tkernel += @vectors[i][j] * features[j] ||     \t\t\tend ||     \t\t\tkernels[i] = Math.tanh((@gamma * kernel) + @coef0) ||     \t\tend ||     \tend ||      ||     \tstarts = Array.new(@nRows; 0) ||     \tfor i in 0 ... @nRows ||     \t\tif i != 0 ||     \t\t\tstart = 0 ||     \t\t\tfor j in 0 ... i ||     \t\t\t\tstart += @weights[j] ||     \t\t\tend ||     \t\t\tstarts[i] = start ||     \t\telse ||     \t\t\tstarts[0] = 0 ||     \t\tend ||     \tend ||      ||     \tends = Array.new(@nRows; 0) ||     \tfor i in 0 ... @nRows ||     \t\tends[i] = @weights[i] + starts[i] ||     \tend ||      ||     \tif @nClasses == 2 ||      ||     \t\tfor i in 0 ... kernels.length ||     \t\t\tkernels[i] = -kernels[i] ||     \t\tend ||      ||     \t\tdecision = 0 ||     \t\tfor k in starts[1] ... ends[1] ||     \t\t\tdecision += kernels[k] * @coefficients[0][k] ||     \t\tend ||     \t\tfor k in starts[0] ... ends[0] ||     \t\t\tdecision += kernels[k] * @coefficients[0][k] ||     \t\tend ||     \t\tdecision += @intercepts[0]; ||      ||     \t\tif decision > 0 ||     \t\t\treturn 0 ||     \t\tend ||     \t\treturn 1 ||      ||     \tend ||      ||     \tdecisions = Array.new(@intercepts.length; 0) ||     \td = 0 ||     \tfor i in 0 ... @nRows ||     \t\tfor j in i + 1 ... @nRows ||     \t\t\ttmp = 0 ||     \t\t\tfor k in starts[j] ... ends[j] ||     \t\t\t\ttmp += @coefficients[i][k] * kernels[k] ||     \t\t\tend ||     \t\t\tfor k in starts[i] ... ends[i] ||     \t\t\t\ttmp += @coefficients[j - 1][k] * kernels[k] ||     \t\t\tend ||     \t\t\tdecisions[d] = tmp + @intercepts[d] ||     \t\t\td = d + 1 ||     \t\tend ||     \tend ||      ||     \tvotes = Array.new(@intercepts.length; 0) ||     \td = 0 ||     \tfor i in 0 ... @nRows ||     \t\tfor j in i + 1 ... @nRows ||     \t\t\tvotes[d] = decisions[d] > 0 ? i : j ||     \t\t\td = d + 1 ||     \t\tend ||     \tend ||      ||     \tamounts = Array.new(@nClasses; 0) ||     \tfor i in 0 ... votes.length ||     \t\tamounts[votes[i]] += 1 ||     \tend ||      ||     \tclassVal = -1 ||     \tclassIdx = -1 ||     \tfor i in 0 ... amounts.length ||     \t\tif amounts[i] > classVal ||     \t\t\tclassVal = amounts[i] ||     \t\t\tclassIdx = i ||     \t\tend ||     \tend ||     \treturn @classes[classIdx] ||      ||     end ||  || end ||  || if ARGV.length == 4 ||  || \t# Features: || \tfeatures = ARGV.collect { |i| i.to_f } ||  || \t# Parameters: || \tvectors = [[5.0999999999999996; 3.5; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.0; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.3; 0.20000000000000001]; [4.5999999999999996; 3.1000000000000001; 1.5; 0.20000000000000001]; [5.0; 3.6000000000000001; 1.3999999999999999; 0.20000000000000001]; [5.4000000000000004; 3.8999999999999999; 1.7; 0.40000000000000002]; [4.5999999999999996; 3.3999999999999999; 1.3999999999999999; 0.29999999999999999]; [5.0; 3.3999999999999999; 1.5; 0.20000000000000001]; [4.4000000000000004; 2.8999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.4000000000000004; 3.7000000000000002; 1.5; 0.20000000000000001]; [4.7999999999999998; 3.3999999999999999; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.10000000000000001]; [4.2999999999999998; 3.0; 1.1000000000000001; 0.10000000000000001]; [5.7999999999999998; 4.0; 1.2; 0.20000000000000001]; [5.7000000000000002; 4.4000000000000004; 1.5; 0.40000000000000002]; [5.4000000000000004; 3.8999999999999999; 1.3; 0.40000000000000002]; [5.0999999999999996; 3.5; 1.3999999999999999; 0.29999999999999999]; [5.7000000000000002; 3.7999999999999998; 1.7; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.5; 0.29999999999999999]; [5.4000000000000004; 3.3999999999999999; 1.7; 0.20000000000000001]; [5.0999999999999996; 3.7000000000000002; 1.5; 0.40000000000000002]; [4.5999999999999996; 3.6000000000000001; 1.0; 0.20000000000000001]; [5.0999999999999996; 3.2999999999999998; 1.7; 0.5]; [4.7999999999999998; 3.3999999999999999; 1.8999999999999999; 0.20000000000000001]; [5.0; 3.0; 1.6000000000000001; 0.20000000000000001]; [5.0; 3.3999999999999999; 1.6000000000000001; 0.40000000000000002]; [5.2000000000000002; 3.5; 1.5; 0.20000000000000001]; [5.2000000000000002; 3.3999999999999999; 1.3999999999999999; 0.20000000000000001]; [4.7000000000000002; 3.2000000000000002; 1.6000000000000001; 0.20000000000000001]; [4.7999999999999998; 3.1000000000000001; 1.6000000000000001; 0.20000000000000001]; [5.4000000000000004; 3.3999999999999999; 1.5; 0.40000000000000002]; [5.2000000000000002; 4.0999999999999996; 1.5; 0.10000000000000001]; [5.5; 4.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [5.0; 3.2000000000000002; 1.2; 0.20000000000000001]; [5.5; 3.5; 1.3; 0.20000000000000001]; [4.9000000000000004; 3.1000000000000001; 1.5; 0.10000000000000001]; [4.4000000000000004; 3.0; 1.3; 0.20000000000000001]; [5.0999999999999996; 3.3999999999999999; 1.5; 0.20000000000000001]; [5.0; 3.5; 1.3; 0.29999999999999999]; [4.5; 2.2999999999999998; 1.3; 0.29999999999999999]; [4.4000000000000004; 3.2000000000000002; 1.3; 0.20000000000000001]; [5.0; 3.5; 1.6000000000000001; 0.59999999999999998]; [5.0999999999999996; 3.7999999999999998; 1.8999999999999999; 0.40000000000000002]; [4.7999999999999998; 3.0; 1.3999999999999999; 0.29999999999999999]; [5.0999999999999996; 3.7999999999999998; 1.6000000000000001; 0.20000000000000001]; [4.5999999999999996; 3.2000000000000002; 1.3999999999999999; 0.20000000000000001]; [5.2999999999999998; 3.7000000000000002; 1.5; 0.20000000000000001]; [5.0; 3.2999999999999998; 1.3999999999999999; 0.20000000000000001]; [7.0; 3.2000000000000002; 4.7000000000000002; 1.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 4.5; 1.5]; [6.9000000000000004; 3.1000000000000001; 4.9000000000000004; 1.5]; [5.5; 2.2999999999999998; 4.0; 1.3]; [6.5; 2.7999999999999998; 4.5999999999999996; 1.5]; [5.7000000000000002; 2.7999999999999998; 4.5; 1.3]; [6.2999999999999998; 3.2999999999999998; 4.7000000000000002; 1.6000000000000001]; [4.9000000000000004; 2.3999999999999999; 3.2999999999999998; 1.0]; [6.5999999999999996; 2.8999999999999999; 4.5999999999999996; 1.3]; [5.2000000000000002; 2.7000000000000002; 3.8999999999999999; 1.3999999999999999]; [5.0; 2.0; 3.5; 1.0]; [5.9000000000000004; 3.0; 4.2000000000000002; 1.5]; [6.0; 2.2000000000000002; 4.0; 1.0]; [6.0999999999999996; 2.8999999999999999; 4.7000000000000002; 1.3999999999999999]; [5.5999999999999996; 2.8999999999999999; 3.6000000000000001; 1.3]; [6.7000000000000002; 3.1000000000000001; 4.4000000000000004; 1.3999999999999999]; [5.5999999999999996; 3.0; 4.5; 1.5]; [5.7999999999999998; 2.7000000000000002; 4.0999999999999996; 1.0]; [6.2000000000000002; 2.2000000000000002; 4.5; 1.5]; [5.5999999999999996; 2.5; 3.8999999999999999; 1.1000000000000001]; [5.9000000000000004; 3.2000000000000002; 4.7999999999999998; 1.8]; [6.0999999999999996; 2.7999999999999998; 4.0; 1.3]; [6.2999999999999998; 2.5; 4.9000000000000004; 1.5]; [6.0999999999999996; 2.7999999999999998; 4.7000000000000002; 1.2]; [6.4000000000000004; 2.8999999999999999; 4.2999999999999998; 1.3]; [6.5999999999999996; 3.0; 4.4000000000000004; 1.3999999999999999]; [6.7999999999999998; 2.7999999999999998; 4.7999999999999998; 1.3999999999999999]; [6.7000000000000002; 3.0; 5.0; 1.7]; [6.0; 2.8999999999999999; 4.5; 1.5]; [5.7000000000000002; 2.6000000000000001; 3.5; 1.0]; [5.5; 2.3999999999999999; 3.7999999999999998; 1.1000000000000001]; [5.5; 2.3999999999999999; 3.7000000000000002; 1.0]; [5.7999999999999998; 2.7000000000000002; 3.8999999999999999; 1.2]; [6.0; 2.7000000000000002; 5.0999999999999996; 1.6000000000000001]; [5.4000000000000004; 3.0; 4.5; 1.5]; [6.0; 3.3999999999999999; 4.5; 1.6000000000000001]; [6.7000000000000002; 3.1000000000000001; 4.7000000000000002; 1.5]; [6.2999999999999998; 2.2999999999999998; 4.4000000000000004; 1.3]; [5.5999999999999996; 3.0; 4.0999999999999996; 1.3]; [5.5; 2.5; 4.0; 1.3]; [5.5; 2.6000000000000001; 4.4000000000000004; 1.2]; [6.0999999999999996; 3.0; 4.5999999999999996; 1.3999999999999999]; [5.7999999999999998; 2.6000000000000001; 4.0; 1.2]; [5.0; 2.2999999999999998; 3.2999999999999998; 1.0]; [5.5999999999999996; 2.7000000000000002; 4.2000000000000002; 1.3]; [5.7000000000000002; 3.0; 4.2000000000000002; 1.2]; [5.7000000000000002; 2.8999999999999999; 4.2000000000000002; 1.3]; [6.2000000000000002; 2.8999999999999999; 4.2999999999999998; 1.3]; [5.0999999999999996; 2.5; 3.0; 1.1000000000000001]; [5.7000000000000002; 2.7999999999999998; 4.0999999999999996; 1.3]; [6.2999999999999998; 3.2999999999999998; 6.0; 2.5]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [7.0999999999999996; 3.0; 5.9000000000000004; 2.1000000000000001]; [6.2999999999999998; 2.8999999999999999; 5.5999999999999996; 1.8]; [6.5; 3.0; 5.7999999999999998; 2.2000000000000002]; [7.5999999999999996; 3.0; 6.5999999999999996; 2.1000000000000001]; [4.9000000000000004; 2.5; 4.5; 1.7]; [7.2999999999999998; 2.8999999999999999; 6.2999999999999998; 1.8]; [6.7000000000000002; 2.5; 5.7999999999999998; 1.8]; [7.2000000000000002; 3.6000000000000001; 6.0999999999999996; 2.5]; [6.5; 3.2000000000000002; 5.0999999999999996; 2.0]; [6.4000000000000004; 2.7000000000000002; 5.2999999999999998; 1.8999999999999999]; [6.7999999999999998; 3.0; 5.5; 2.1000000000000001]; [5.7000000000000002; 2.5; 5.0; 2.0]; [5.7999999999999998; 2.7999999999999998; 5.0999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.2000000000000002; 5.2999999999999998; 2.2999999999999998]; [6.5; 3.0; 5.5; 1.8]; [7.7000000000000002; 3.7999999999999998; 6.7000000000000002; 2.2000000000000002]; [7.7000000000000002; 2.6000000000000001; 6.9000000000000004; 2.2999999999999998]; [6.0; 2.2000000000000002; 5.0; 1.5]; [6.9000000000000004; 3.2000000000000002; 5.7000000000000002; 2.2999999999999998]; [5.5999999999999996; 2.7999999999999998; 4.9000000000000004; 2.0]; [7.7000000000000002; 2.7999999999999998; 6.7000000000000002; 2.0]; [6.2999999999999998; 2.7000000000000002; 4.9000000000000004; 1.8]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.1000000000000001]; [7.2000000000000002; 3.2000000000000002; 6.0; 1.8]; [6.2000000000000002; 2.7999999999999998; 4.7999999999999998; 1.8]; [6.0999999999999996; 3.0; 4.9000000000000004; 1.8]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.1000000000000001]; [7.2000000000000002; 3.0; 5.7999999999999998; 1.6000000000000001]; [7.4000000000000004; 2.7999999999999998; 6.0999999999999996; 1.8999999999999999]; [7.9000000000000004; 3.7999999999999998; 6.4000000000000004; 2.0]; [6.4000000000000004; 2.7999999999999998; 5.5999999999999996; 2.2000000000000002]; [6.2999999999999998; 2.7999999999999998; 5.0999999999999996; 1.5]; [6.0999999999999996; 2.6000000000000001; 5.5999999999999996; 1.3999999999999999]; [7.7000000000000002; 3.0; 6.0999999999999996; 2.2999999999999998]; [6.2999999999999998; 3.3999999999999999; 5.5999999999999996; 2.3999999999999999]; [6.4000000000000004; 3.1000000000000001; 5.5; 1.8]; [6.0; 3.0; 4.7999999999999998; 1.8]; [6.9000000000000004; 3.1000000000000001; 5.4000000000000004; 2.1000000000000001]; [6.7000000000000002; 3.1000000000000001; 5.5999999999999996; 2.3999999999999999]; [6.9000000000000004; 3.1000000000000001; 5.0999999999999996; 2.2999999999999998]; [5.7999999999999998; 2.7000000000000002; 5.0999999999999996; 1.8999999999999999]; [6.7999999999999998; 3.2000000000000002; 5.9000000000000004; 2.2999999999999998]; [6.7000000000000002; 3.2999999999999998; 5.7000000000000002; 2.5]; [6.7000000000000002; 3.0; 5.2000000000000002; 2.2999999999999998]; [6.2999999999999998; 2.5; 5.0; 1.8999999999999999]; [6.5; 3.0; 5.2000000000000002; 2.0]; [6.2000000000000002; 3.3999999999999999; 5.4000000000000004; 2.2999999999999998]; [5.9000000000000004; 3.0; 5.0999999999999996; 1.8]] || \tcoefficients = [[1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -1.0; -0.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -0.0; -0.0; -1.0; -1.0; -1.0; -0.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]; [1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 0.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; 1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0; -1.0]] || \tintercepts = [0.043376922607421875; 0.11445245146751404; -0.0031709671020507812] || \tweights = [50; 50; 50] ||  || \t# Prediction: || \tclf = SVC.new 3; 3; vectors; coefficients; intercepts; weights; \""rbf\""; 0.001; 0.0; 3 || \testimation = clf.predict features || \tputs estimation ||  || end || \""\""\""",,Yes,Yes
16287,TODO: Add non embedded templates and remove the following line:,,,Yes
16288,"\""\""\"" || import java.io.File; || import java.io.FileNotFoundException; || import java.io.IOException; || import java.util.Scanner; || import com.google.gson.Gson; ||  ||  || class NuSVC { ||  ||     private enum Kernel { LINEAR; POLY; RBF; SIGMOID } ||     private class Classifier { ||         private int nClasses; ||         private int nRows; ||         private int[] classes; ||         private double[][] vectors; ||         private double[][] coefficients; ||         private double[] intercepts; ||         private int[] weights; ||         private String kernel; ||         private Kernel kkernel; ||         private double gamma; ||         private double coef0; ||         private double degree; ||     } ||  ||     private Classifier clf; ||  ||     public NuSVC(String file) throws FileNotFoundException { ||         String jsonStr = new Scanner(new File(file)).useDelimiter(\""\\\\Z\"").next(); ||         this.clf = new Gson().fromJson(jsonStr; Classifier.class); ||         this.clf.classes = new int[this.clf.nClasses]; ||         for (int i = 0; i < this.clf.nClasses; i++) { ||             this.clf.classes[i] = i; ||         } ||         this.clf.kkernel = Kernel.valueOf(this.clf.kernel.toUpperCase()); ||     } ||  ||     public int predict(double[] features) { ||         double[] kernels = new double[this.clf.vectors.length]; ||         double kernel; ||         switch (this.clf.kkernel) { ||             case LINEAR: ||                 \/\/ <x;x'> ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = kernel; ||                 } ||                 break; ||             case POLY: ||                 \/\/ (y<x;x'>+r)^d ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = Math.pow((this.clf.gamma * kernel) + this.clf.coef0; this.clf.degree); ||                 } ||                 break; ||             case RBF: ||                 \/\/ exp(-y|x-x'|^2) ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += Math.pow(this.clf.vectors[i][j] - features[j]; 2); ||                     } ||                     kernels[i] = Math.exp(-this.clf.gamma * kernel); ||                 } ||                 break; ||             case SIGMOID: ||                 \/\/ tanh(y<x;x'>+r) ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = Math.tanh((this.clf.gamma * kernel) + this.clf.coef0); ||                 } ||                 break; ||         } ||  ||         int[] starts = new int[this.clf.nRows]; ||         for (int i = 0; i < this.clf.nRows; i++) { ||             if (i != 0) { ||                 int start = 0; ||                 for (int j = 0; j < i; j++) { ||                     start += this.clf.weights[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||  ||         int[] ends = new int[this.clf.nRows]; ||         for (int i = 0; i < this.clf.nRows; i++) { ||             ends[i] = this.clf.weights[i] + starts[i]; ||         } ||  ||         if (this.clf.nClasses == 2) { ||             for (int i = 0; i < kernels.length; i++) { ||                 kernels[i] = -kernels[i]; ||             } ||             double decision = 0.; ||             for (int k = starts[1]; k < ends[1]; k++) { ||                 decision += kernels[k] * this.clf.coefficients[0][k]; ||             } ||             for (int k = starts[0]; k < ends[0]; k++) { ||                 decision += kernels[k] * this.clf.coefficients[0][k]; ||             } ||             decision += this.clf.intercepts[0]; ||             if (decision > 0) { ||                 return 0; ||             } ||             return 1; ||         } ||  ||         double[] decisions = new double[this.clf.intercepts.length]; ||         for (int i = 0; d = 0; l = this.clf.nRows; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 double tmp = 0.; ||                 for (int k = starts[j]; k < ends[j]; k++) { ||                     tmp += this.clf.coefficients[i][k] * kernels[k]; ||                 } ||                 for (int k = starts[i]; k < ends[i]; k++) { ||                     tmp += this.clf.coefficients[j - 1][k] * kernels[k]; ||                 } ||                 decisions[d] = tmp + this.clf.intercepts[d]; ||                 d++; ||             } ||         } ||  ||         int[] votes = new int[this.clf.intercepts.length]; ||         for (int i = 0; d = 0; l = this.clf.nRows; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d] > 0 ? i : j; ||                 d++; ||             } ||         } ||  ||         int[] amounts = new int[this.clf.nClasses]; ||         for (int i = 0; l = votes.length; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         int classVal = -1; classIdx = -1; ||         for (int i = 0; l = amounts.length; i < l; i++) { ||             if (amounts[i] > classVal) { ||                 classVal = amounts[i]; ||                 classIdx = i; ||             } ||         } ||         return this.clf.classes[classIdx]; ||     } ||  ||     public static void main(String[] args) throws FileNotFoundException { ||         if (args.length > 0 && args[0].endsWith(\"".json\"")) { ||  ||             \/\/ Features: ||             double[] features = new double[args.length-1]; ||             for (int i = 1; l = args.length; i < l; i++) { ||                 features[i - 1] = Double.parseDouble(args[i]); ||             } ||  ||             \/\/ Parameters: ||             String modelData = args[0]; ||  ||             \/\/ Estimators: ||             NuSVC clf = new NuSVC(modelData); ||  ||             \/\/ Prediction: ||             int prediction = clf.predict(features); ||             System.out.println(prediction); ||  ||         } ||     } || } || \""\""\""",No,Yes,Yes
16289,"\""\""\"" || import java.io.File; || import java.io.FileNotFoundException; || import java.io.IOException; || import java.util.Scanner; || import com.google.gson.Gson; ||  ||  || class SVC { ||  ||     private enum Kernel { LINEAR; POLY; RBF; SIGMOID } ||     private class Classifier { ||         private int nClasses; ||         private int nRows; ||         private int[] classes; ||         private double[][] vectors; ||         private double[][] coefficients; ||         private double[] intercepts; ||         private int[] weights; ||         private String kernel; ||         private Kernel kkernel; ||         private double gamma; ||         private double coef0; ||         private double degree; ||     } ||  ||     private Classifier clf; ||  ||     public SVC(String file) throws FileNotFoundException { ||         String jsonStr = new Scanner(new File(file)).useDelimiter(\""\\\\Z\"").next(); ||         this.clf = new Gson().fromJson(jsonStr; Classifier.class); ||         this.clf.classes = new int[this.clf.nClasses]; ||         for (int i = 0; i < this.clf.nClasses; i++) { ||             this.clf.classes[i] = i; ||         } ||         this.clf.kkernel = Kernel.valueOf(this.clf.kernel.toUpperCase()); ||     } ||  ||     public int predict(double[] features) { ||         double[] kernels = new double[this.clf.vectors.length]; ||         double kernel; ||         switch (this.clf.kkernel) { ||             case LINEAR: ||                 \/\/ <x;x'> ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = kernel; ||                 } ||                 break; ||             case POLY: ||                 \/\/ (y<x;x'>+r)^d ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = Math.pow((this.clf.gamma * kernel) + this.clf.coef0; this.clf.degree); ||                 } ||                 break; ||             case RBF: ||                 \/\/ exp(-y|x-x'|^2) ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += Math.pow(this.clf.vectors[i][j] - features[j]; 2); ||                     } ||                     kernels[i] = Math.exp(-this.clf.gamma * kernel); ||                 } ||                 break; ||             case SIGMOID: ||                 \/\/ tanh(y<x;x'>+r) ||                 for (int i = 0; i < this.clf.vectors.length; i++) { ||                     kernel = 0.; ||                     for (int j = 0; j < this.clf.vectors[i].length; j++) { ||                         kernel += this.clf.vectors[i][j] * features[j]; ||                     } ||                     kernels[i] = Math.tanh((this.clf.gamma * kernel) + this.clf.coef0); ||                 } ||                 break; ||         } ||  ||         int[] starts = new int[this.clf.nRows]; ||         for (int i = 0; i < this.clf.nRows; i++) { ||             if (i != 0) { ||                 int start = 0; ||                 for (int j = 0; j < i; j++) { ||                     start += this.clf.weights[j]; ||                 } ||                 starts[i] = start; ||             } else { ||                 starts[0] = 0; ||             } ||         } ||  ||         int[] ends = new int[this.clf.nRows]; ||         for (int i = 0; i < this.clf.nRows; i++) { ||             ends[i] = this.clf.weights[i] + starts[i]; ||         } ||  ||         if (this.clf.nClasses == 2) { ||             for (int i = 0; i < kernels.length; i++) { ||                 kernels[i] = -kernels[i]; ||             } ||             double decision = 0.; ||             for (int k = starts[1]; k < ends[1]; k++) { ||                 decision += kernels[k] * this.clf.coefficients[0][k]; ||             } ||             for (int k = starts[0]; k < ends[0]; k++) { ||                 decision += kernels[k] * this.clf.coefficients[0][k]; ||             } ||             decision += this.clf.intercepts[0]; ||             if (decision > 0) { ||                 return 0; ||             } ||             return 1; ||         } ||  ||         double[] decisions = new double[this.clf.intercepts.length]; ||         for (int i = 0; d = 0; l = this.clf.nRows; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 double tmp = 0.; ||                 for (int k = starts[j]; k < ends[j]; k++) { ||                     tmp += this.clf.coefficients[i][k] * kernels[k]; ||                 } ||                 for (int k = starts[i]; k < ends[i]; k++) { ||                     tmp += this.clf.coefficients[j - 1][k] * kernels[k]; ||                 } ||                 decisions[d] = tmp + this.clf.intercepts[d]; ||                 d++; ||             } ||         } ||  ||         int[] votes = new int[this.clf.intercepts.length]; ||         for (int i = 0; d = 0; l = this.clf.nRows; i < l; i++) { ||             for (int j = i + 1; j < l; j++) { ||                 votes[d] = decisions[d] > 0 ? i : j; ||                 d++; ||             } ||         } ||  ||         int[] amounts = new int[this.clf.nClasses]; ||         for (int i = 0; l = votes.length; i < l; i++) { ||             amounts[votes[i]] += 1; ||         } ||  ||         int classVal = -1; classIdx = -1; ||         for (int i = 0; l = amounts.length; i < l; i++) { ||             if (amounts[i] > classVal) { ||                 classVal = amounts[i]; ||                 classIdx = i; ||             } ||         } ||         return this.clf.classes[classIdx]; ||     } ||  ||     public static void main(String[] args) throws FileNotFoundException { ||         if (args.length > 0 && args[0].endsWith(\"".json\"")) { ||  ||             \/\/ Features: ||             double[] features = new double[args.length-1]; ||             for (int i = 1; l = args.length; i < l; i++) { ||                 features[i - 1] = Double.parseDouble(args[i]); ||             } ||  ||             \/\/ Parameters: ||             String modelData = args[0]; ||  ||             \/\/ Estimators: ||             SVC clf = new SVC(modelData); ||  ||             \/\/ Prediction: ||             int prediction = clf.predict(features); ||             System.out.println(prediction); ||  ||         } ||     } || } || \""\""\""",No,Yes,Yes
16290,TODO: parent mutated nodes need to be serialized,,,Yes
16293,TODO: find out why PLS and CCA fail. RANSAC is random,Yes,No,Yes
16296,XXX: once we may depend on python >= 2.6; this can be replaced by the,Yes,Yes,Yes
16297,GradientBoosting base estimators; maybe should,,,Yes
16299,TODO some complication with -1 label,,,Yes
16302,ugly hack to make iloc work.,Yes,Yes,Yes
16303,XXX: Generally can use 0.89 here. On Windows; LinearSVC gets,,,Yes
16304,TODO,Yes,Yes,Yes
16305,TODO:,Yes,No,Yes
16307,TODO,,,Yes
16308,hack-ish; but works (and I am not aware of a more proper way to do so),Yes,Yes,Yes
16309,NN          scalar              # columns; if specified; overrides RATIO,No,Yes,Yes
16310,TODO: implement this,Yes,Yes,Yes
16311,TODO: implement this,,,Yes
16313,TODO: implement this,,,Yes
16314,fix the saved model structure when multi_gpu > 1,No,Yes,Yes
16315,list_bars.columns = cols,,,Yes
16318,TODO 0.5PW e.g.[2;12;13;10],Yes,Yes,Yes
16319,if len(y_predict_labels)<1:    y_predict_labels=[np.argmax(y_logit_array_single)] #TODO ADD 2018.05.29,,,Yes
16321,"\""\""\"" || We employ a residual connection around each of the two sub-layers; followed by layer normalization. || That is; the output of each sub-layer is LayerNorm(x+ Sublayer(x)); where Sublayer(x) is the function implemented by the sub-layer itself. \""\""\""",No,Yes,Yes
16323,"\""\""\"" ||  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ||  main idea:  based on multiple layer self-attention model(encoder of Transformer); pretrain two tasks( masked language model and next sentence prediction task) ||              on large scale of corpus; then fine-tuning by add a single classification layer. || \""\""\""",,,Yes
16325,todo,Yes,No,Yes
16326,"\""\""\"" ||  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ||  main idea:  based on multiple layer self-attention model(encoder of Transformer); pretrain two tasks( masked language model and next sentence prediction task) ||              on large scale of corpus; then fine-tuning by add a single classification layer. || \""\""\""",No,Yes,Yes
16329,The convention in BERT is:,No,No,Yes
16330,todo: handle difficulty,Yes,No,Yes
16331,''' Furthest point sampling\r || Original author: Haoqiang Fan\r || Modified by Charles R. Qi\r || All Rights Reserved. 2017. \r || ''',,,Yes
16334,add a big value to duplicate columns,,,Yes
16335,FIXME: torch -> scipy.misc raises SEGV,Yes,Yes,Yes
16336,FIXME: torch -> scipy.misc raises SEGV,Yes,Yes,Yes
16337,XXX: It must be renamed to benchmark.tar to be extracted.,Yes,Yes,Yes
16338,XXX: shoud be set in forward,Yes,Yes,Yes
16340,this is a temporary fix - we need a better way to do this,Yes,Yes,Yes
16342,TODO: here we assume binary classification task,Yes,Yes,Yes
16343,TODO: add limited pickling support for sharing an iterator,,,Yes
16345,TODO: add fuzz match,,,Yes
16346,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
16347,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
16348,TODO: why original code need answers instead of answer; any difference,,,Yes
16351,"What we really want to return is \""Steve Smith\"".",,,Yes
16352,TODO: xiaodl,Yes,No,Yes
16354,TODO: xiaodl,Yes,No,Yes
16356,TODO: this is from BERT; needed to remove it...,,,Yes
16357,TODO: similar as function extract; preserve since it is used by extractor.py,Yes,Yes,Yes
16359,Prepare head mask if needed,,,Yes
16362,quick hack,Yes,Yes,Yes
16364,Create temporary mono track if needed,No,No,Yes
16366,breaks multiindices HDF5 tables better!,Yes,Yes,Yes
16367,Note the data is always saved in hdf - format which is an efficient format that easily allows to load the full pandas multiarray at a later stage,,,Yes
16368,list(set(DataCombined.columns.get_level_values(1))),,,Yes
16369,attention averages over color channels to keep size small \/ perhaps you want to use color information?,,,Yes
16371,frame = pd.DataFrame(a; columns = index; index = self.index),No,Yes,Yes
16372,order of labels for different scorers. Currently using only the first (as by convention the human labeler is displayed as +).,No,No,Yes
16373,small hack in case there are any 0 intensity images!,Yes,No,Yes
16374,attention averages over color channels to keep size small \/ perhaps you want to use color information?,,,Yes
16375,scorer=np.unique(Dataframe.columns.get_level_values(0))[0],No,Yes,Yes
16376,bodyparts2plot = list(np.unique(Dataframe.columns.get_level_values(1))),No,No,Yes
16377,was 12 inches (perhaps add dpi!),,,Yes
16380,attention: averages over color channels to keep size small \/ perhaps you want to use color information?,Yes,Yes,Yes
16382,"\""\""\"" || Created on Tue Oct  2 13:56:11 2018 || @author: alex ||  || DEVELOPERS: || This script tests various functionalities in an automatic way. ||  || It should take about 4:00 minutes to run this in a CPU. || It should take about 1:30 minutes on a GPU (incl. downloading the ResNet weights) ||  || It produces nothing of interesting scientifically. || \""\""\""",,,Yes
16384,row 1; span all columns,,,Yes
16388,Workaround for MAC - xlim and ylim changed events seem to be triggered too often so need to make sure that the,Yes,Yes,Yes
16390,TODO check if those times exist...,Yes,Yes,Yes
16391,TODO: CHECK FOR BOTH?,,,Yes
16392,TODO: perform detection on resized image (For speed),Yes,No,Yes
16393,TODO: Check if DLCscorer is correct? (based on lookup in pickle?),,,Yes
16394,Workaround for MAC - xlim and ylim changed events seem to be triggered too often so need to make sure that the,,,Yes
16395,bodyParts = self.Dataframe.columns.get_level_values(1),No,No,Yes
16396,small hack in case there are any 0 intensity images!,,,Yes
16397,TODO: update to pickle file!,Yes,Yes,Yes
16398,minimum of two cameras \/ TODO: clean up!,Yes,Yes,Yes
16399,TODO: use ret_camj,Yes,Yes,Yes
16404,why is video type needed?,No,Yes,Yes
16406,TODO: IMPLEMENT for different batch sizes?,,,Yes
16407,TODO: set to minimum (from pose_cfg.yaml),Yes,Yes,Yes
16408,TODO: compute all the grids etc. once for the video analysis method,,,Yes
16409,TODO: addd cropping as in video analysis!,Yes,Yes,Yes
16415,Broadcasting for efficient subtraction of X and Y coordinates,No,Yes,Yes
16417,TODO - factor in keypoint confidence (and weight by # of observations??),Yes,No,Yes
16419,FIXME Is having an empty array vs nan really that necessary?!,,,Yes
16420,TODO Heading over last couple of frames (circular average statistics),,,Yes
16424,augmentation path...; and is more computationally efficient.,,,Yes
16425,FIXME That is not robust if tracklets are short,Yes,No,Yes
16426,The algorithm works better with integer weights,No,Yes,Yes
16428,TODO Incorporate residual tracklets,Yes,Yes,Yes
16430,FIXME If no existing paths; find dense structures rather?,Yes,Yes,Yes
16431,Very efficient; avoid re-drawing the whole plot,,,Yes
16432,Good old inelegant way,,,Yes
16433,TODO Fix the code below...,Yes,Yes,Yes
16437,''' || Provides functionality for converting a given list of tokens (words) into || numbers; according to the given vocabulary. || ''',No,Yes,Yes
16439,pad them if needed; reverse encoder inputs and add GO to decoder.,,,Yes
16440,pad them if needed; reverse encoder inputs and add GO to decoder.,,,Yes
16441,pad them if needed; reverse encoder inputs and add GO to decoder.,No,Yes,Yes
16445,TODO(irving;ebrevdo): This reshape is needed because,Yes,Yes,Yes
16447,Here's where we define the internals of the efficient bottleneck layer,No,Yes,Yes
16449,work around bug in unittest.TestCase.shortDescription,Yes,Yes,Yes
16450,this is probably caused by a problem in test.__str__() and is,Yes,Yes,Yes
16452,FIXME remove plugins; have only plugin manager class,,,Yes
16453,FIXME won't work for static plugin lists,Yes,Yes,Yes
16454,needed so .can_configure gets set appropriately,,,Yes
16458,Deal with exact matches possibly needed at one or both ends.,No,No,Yes
16464,Trim junk on both ends.,Yes,No,Yes
16465,FIXME reimplement local per-dir cache?,,,Yes
16466,FIXME add any src-looking dirs seen too... need to get config for that,Yes,Yes,Yes
16470,if this is the end of the line and the line ends with,No,No,Yes
16471,segment with the same basename as our package ends up,No,No,Yes
16476,disable in < 2.4: eval can't take needed args,No,No,Yes
16477,TODO: is there a need for case-sensitive value comparison?,Yes,Yes,Yes
16483,FIXME don't think we need include\/exclude checks here?,,,Yes
16488,TODO: empty directories look like non-directory files,,,Yes
16491,XXX This should not be part of site.py; since it is needed even when,,,Yes
16495,would be better to use python logger,,,Yes
16498,todo: would be better to force spacy to use the given tokenization,Yes,Yes,Yes
16501,''' || convention_df = st.SampleCorpora.ConventionData2012.get_data() || corpus = (st.CorpusFromPandas(convention_df; ||                               category_col='party'; ||                               text_col='text'; ||                               nlp=st.whitespace_nlp_with_sentences) ||           .build() ||           .get_unigram_corpus()) ||  || term_scorer = st.MannWhitneyU(corpus).set_categories('democrat'; ['republican']) || html = st.produce_frequency_explorer( ||     corpus; ||     category='democrat'; ||     category_name='Democratic'; ||     not_category_name='Republican'; ||     y_label='Mann Whitney FDR-BH Z'; ||     scores=term_scorer.get_score_df('fdr_bh').mwu_z; ||     metadata=convention_df['speaker']; ||     grey_threshold=0 || ) || file_name = 'demo_mann_whitney.html' || open(file_name; 'wb').write(html.encode('utf-8')) || print('Open %s in Chrome or Firefox.' % file_name) || ''',No,No,Yes
16502,to do: make this more efficient by only having self.sents,,,Yes
16504,TODO: Fix yandex search,Yes,Yes,Yes
16507,TODO: I cannot get good results with this yet,Yes,No,Yes
16508,TODO:,,,Yes
16509,TODO:,Yes,No,Yes
16510,Presets known to work good.,,,Yes
16511,TODO: Does this really work well? not sure..,Yes,Yes,Yes
16513,TODO: cannot simply apply for batch,,,Yes
16514,better to implement efficient function,,,Yes
16515,Not currently needed...,,,Yes
16516,need to hack up run_aligner more..,Yes,No,Yes
16518,really; really; REALLY weird,,,Yes
16519,2>&1 needed to make it work?? really sketchy,Yes,Yes,Yes
16521,TODO: Add -clean argument,Yes,Yes,Yes
16522,''' Furthest point sampling || Original author: Haoqiang Fan || Modified by Charles R. Qi || All Rights Reserved. 2017.  || ''',,,Yes
16524,"\""\""\"" Utility functions for processing point clouds. ||  || Author: Charles R. Qi; Hao Su || Date: November 2016 || \""\""\""",,,Yes
16525,TODO: add backend thread to load data,Yes,No,Yes
16527,"\""\""\"" || Author: Philipp Gross; https:\/\/github.com\/phipleg\/keras\/blob\/crf\/keras\/layers\/crf.py || \""\""\""",No,Yes,Yes
16529,Gold ends.,No,No,Yes
16530,Move it to a temporary location to avoid being deleted by the training supervisor.,,,Yes
16533,TODO: Change the indexing in step 1 above so that this inefficient roll operation becomes obsolete,Yes,Yes,Yes
16534,TODO: Implement box limiting directly for `(cx; cy; w; h)` so that we don't have to unnecessarily convert back and forth,Yes,Yes,Yes
16537,The following identity layer is only needed so that subsequent two lambda layers can be optional.,Yes,No,Yes
16538,...and write the maxima to the other columns...,,,Yes
16539,...and write the rest of the maxima data to the other columns...,,,Yes
16540,Set the aspect ratios for each predictor layer. These are only needed for the anchor box layers.,,,Yes
16541,The following identity layer is only needed so that subsequent two lambda layers can be optional.,Yes,No,Yes
16542,Compute how much room we have along the vertical axis to place the patch.,,,Yes
16543,Maybe shuffle the dataset initially.,,,Yes
16544,Get the images; image filenames; (maybe) image IDs; and (maybe) labels for this batch.,No,No,Yes
16545,Maybe perform image transformations.,No,Yes,Yes
16546,This isn't efficient; but it hopefully shouldn't need to be done often anyway.,,,Yes
16548,Set the columns of the matched anchor boxes to zero to indicate that they were matched.,,,Yes
16549,Second: Maybe do 'multi' matching; where each remaining anchor box will be matched to its most similar,,,Yes
16550,Do a few preparatory things like maybe shuffling the dataset initially.,No,No,Yes
16552,Get the number of characters needed to store the image ID strings in the structured array.,,,Yes
16554,# Credits goes to the original author Erik Hovland,No,No,Yes
16557,Transpose matrix for the two last columns (ignoring batch_size),No,No,Yes
16558,TODO: Incorporate proper usage of Spark master; see deepdist,Yes,Yes,Yes
16561,TODO,,,Yes
16562,TODO: Define default value,Yes,Yes,Yes
16564,TODO: Zipping like this is very likely wrong,,,Yes
16565,TODO: Eliminate Spark context (only used for first broadcast; can be extracted),Yes,Yes,Yes
16566,TODO: other default,,,Yes
16569,TODO: Eliminate Spark context (only used for first broadcast; can be extracted),,,Yes
16570,TODO: other default,,,Yes
16571,TODO: connector has to be initialized on workers,,,Yes
16572,TODO: Make dataframe the standard; but support RDDs as well,Yes,Yes,Yes
16573,TODO signature is wrong,,,Yes
16583,TODO master_optimizer,Yes,No,Yes
16585,TODO only set this for async\/hogwild mode,Yes,Yes,Yes
16587,Probably the best way to do this is by moving the sample pushing,,,Yes
16588,TODO: make efficient,,,Yes
16589,move origin coord back to the center,No,Yes,Yes
16594,TODO,,,Yes
16595,resize\/crop if needed,Yes,No,Yes
16597,Temp Fix for nn.parallel as nn.parallel crashes oc calculating gradient penalty,,,Yes
16598,activations of the Inception net (needed for FID); and also returns,No,Yes,Yes
16599,incepiton accuracy the labels of the generated class will be needed),,,Yes
16603,To-do: optionally rewrite inception metrics to use a single,,,Yes
16605,#NAME?,Yes,No,Yes
16606,"-write code to produce sample .npzs; maybe a \""sample.py\"" script.",No,Yes,Yes
16608,Design notes: In this code I pass around the full config dict a lot by,,,Yes
16609,If improved over previous best metric; save approrpiate copy,,,Yes
16611,Simple wrapper that applies EMA to a model. COuld be better done in 1.0 using,,,Yes
16613,If fix y; only sample 1 z per row,No,Yes,Yes
16614,Dimensionality of the shared embedding? Unused if not using G_shared,,,Yes
16615,# Dimensionality of the shared embedding? Unused if not using G_shared,No,Yes,Yes
16616,# Dimensionality of the shared embedding? Unused if not using G_shared,No,Yes,Yes
16618,Andy's Note: this class feels messy but I'm not really sure how to clean it up,,,Yes
16622,Silly hack: overwrite the to() method to wrap the new object,Yes,No,Yes
16624,''' Calculate Inception Moments ||  This script iterates over the dataset and calculates the moments of the  ||  activations of the Inception net (needed for FID); and also returns ||  the Inception Score of the training data. ||   ||  Note that if you don't shuffle the data; the IS of true data will be under- ||  estimated as it is label-ordered. By default; the data is not shuffled ||  so as to reduce non-determinism. ''',,,Yes
16625,Fix the graph,,,Yes
16628,TODO: make efficient,,,Yes
16629,"\""\""\"" A simple benchmark on the last.fm dataset || Compares the running time of this package vs the QMF library from Quora. ||  || On my laptop (2015 Macbook Pro ; Dual Core 3.1 GHz Intel Core i7) running || with 50 factors for 15 iterations this is the output: ||  ||     QMF finished in 547.933080912 ||     Implicit finished in 302.997884989 ||     Implicit is 1.80837262587 times faster ||  || (implicit-mf package was run separately; I estimate it at over 60;000 times || slower on the last.fm dataset - with an estimated running time of around 250 days) || \""\""\""",No,No,Yes
16631,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
16634,TODO: figure out where the issue is (best guess is in the,,,Yes
16636,dot product in CUDA; TODO: eventually should fix that code).,Yes,Yes,Yes
16637,XXX it's because CI error. should be fixed.,,,Yes
16638,TODO: figure out where the issue is (best guess is in the,Yes,No,Yes
16639,TODO: allow passing in cupy arrays on gpu,,,Yes
16640,We need efficient user lookup for case of removing own likes,No,Yes,Yes
16641,TODO: might make more sense to just changes inputs to be users by items instead,,,Yes
16642,TODO,Yes,Yes,Yes
16644,continue to next gt unless better match made,No,No,Yes
16647,TODO: calculate size online,,,Yes
16648,TODO,Yes,Yes,Yes
16649,TODO:  self.init_std\/ math.sqrt(float(dim)),Yes,No,Yes
16654,"\""\""\"" || @author: shenweichen;wcshen1994@163.com || A keras implementation of Attentional Factorization Machines || Reference: || [1] Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks || (https:\/\/arxiv.org\/abs\/1708.04617) || \""\""\""",No,Yes,Yes
16657,"\""\""\"" || @author: shenweichen;wcshen1994@163.com || A keras implementation of Deep & Cross Network || Reference: || [1] Deep & Cross Network for Ad Click Predictions (https:\/\/arxiv.org\/abs\/1708.05123) || \""\""\""",,,Yes
16658,TODO add bias term,Yes,Yes,Yes
16660,TODO: biinteraction,,,Yes
16663,"\""\""\"" ||  || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks ||     (https:\/\/arxiv.org\/abs\/1708.04617) ||  || \""\""\""",,,Yes
16664,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Deep & Cross Network for Ad Click Predictions (https:\/\/arxiv.org\/abs\/1708.05123) || \""\""\""",No,No,Yes
16666,TODO add bias term,,,Yes
16668,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Lian J; Zhou X; Zhang F; et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems[J]. arXiv preprint arXiv:1803.05170; 2018.(https:\/\/arxiv.org\/pdf\/1803.05170.pdf) || \""\""\""",No,Yes,Yes
16669,"\""\""\"" ||  || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Song W; Shi C; Xiao Z; et al. AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks[J]. arXiv preprint arXiv:1810.11921; 2018.(https:\/\/arxiv.org\/abs\/1810.11921) ||  || \""\""\""",,,Yes
16670,but needed for back prop from GPU to CPU.  This allows training RNNs,No,Yes,Yes
16671,Using `time_major = True` is a bit more efficient because it avoids,No,Yes,Yes
16672,Second part; apply the cosine to even columns and sin to odds.,,,Yes
16673,"\""\""\"" ||  || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Liu B; Tang R; Chen Y; et al. Feature Generation by Convolutional Neural Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1904.04447; 2019. ||     (https:\/\/arxiv.org\/pdf\/1904.04447) ||  || \""\""\""",No,Yes,Yes
16677,def get_varlen_vec_list(embedding_dict; features; varlen_sparse_feature_columns):,,,Yes
16678,for fc in varlen_sparse_feature_columns:,,,Yes
16679,todo not support dense,Yes,Yes,Yes
16680,check_feature_config_dict(dnn_feature_columns),,,Yes
16681,check_feature_config_dict(linear_feature_columns),No,No,Yes
16682,todo not support dense????,,,Yes
16683,todo not support dense?,,,Yes
16684,check_feature_config_dict(feature_columns),No,No,Yes
16685,feature_columns; seq_feature_list; hist_len_max),No,Yes,Yes
16686,"enumerate(feature_columns[\""sparse\""])}",No,No,Yes
16688,keys_emb_list = get_embedding_vec_list(sparse_embedding_dict; user_behavior_input; feature_columns['sparse']; return_feat_list=seq_feature_list),No,Yes,Yes
16689,deep_input_emb_list = get_embedding_vec_list(sparse_embedding_dict; sparse_input; feature_columns['sparse']),No,Yes,Yes
16690,"get_embedding_vec_list(sparse_embedding_dict; neg_user_behavior_input; feature_columns[\""sparse\""]; history_feature_list; )",,,Yes
16691,check_feature_config_dict(dnn_feature_columns),No,No,Yes
16692,dnn_feature_columns; sess_feature_list; sess_max_count; sess_len_max),No,Yes,Yes
16697,deep_emb_list; fg_deep_emb_list; _; inputs_list = preprocess_input_embedding(dnn_feature_columns;,No,Yes,Yes
16699,if not isinstance(region_feature_columns;,No,Yes,Yes
16702,todo \u9700\u8981\u4FEE\u6539,Yes,Yes,Yes
16703,varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x; VarLenSparseFeat); dnn_feature_columns)) if dnn_feature_columns else [],,,Yes
16704,check_feature_config_dict(linear_feature_columns),No,No,Yes
16705,todo not support dense,Yes,Yes,Yes
16706,check_feature_config_dict(dnn_feature_columns),,,Yes
16707,todo note support dense,Yes,Yes,Yes
16708,if not isinstance(linear_feature_columns;,No,Yes,Yes
16709,"dict) or \""sparse\"" not in linear_feature_columns or \""dense\"" not in linear_feature_columns:",,,Yes
16710,check_feature_config_dict(linear_feature_columns),,,Yes
16711,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Huang T; Zhang Z; Zhang J. FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1905.09433; 2019. || \""\""\""",No,Yes,Yes
16713,model = FNN(feature_columns;feature_columns; dnn_hidden_units=[32; 32]; dnn_dropout=0.5),,,Yes
16720,todo,Yes,No,Yes
16721,todo check version,Yes,Yes,Yes
16722,todo,,,Yes
16723,todo,Yes,No,Yes
16724,# if version.parse(tf.__version__) >= version.parse('1.14.0') : #todo check further version,Yes,No,Yes
16728,"\""\""\"" ||  || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Xiao J; Ye H; He X; et al. Attentional factorization machines: Learning the weight of feature interactions via attention networks[J]. arXiv preprint arXiv:1708.04617; 2017. ||     (https:\/\/arxiv.org\/abs\/1708.04617) ||  || \""\""\""",,,Yes
16730,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Huang T; Zhang Z; Zhang J. FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1905.09433; 2019. || \""\""\""",No,Yes,Yes
16732,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  || Reference: ||     [1] Lian J; Zhou X; Zhang F; et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems[J]. arXiv preprint arXiv:1803.05170; 2018.(https:\/\/arxiv.org\/pdf\/1803.05170.pdf) || \""\""\""",,,Yes
16733,Unused for this head.,,,Yes
16735,"\""\""\"" || Author: ||     Weichen Shen;wcshen1994@163.com ||  ||     Shuxun Zan; zanshuxun@aliyun.com ||  || Reference: ||     [1] Wang R; Fu B; Fu G; et al. Deep & cross network for ad click predictions[C]\/\/Proceedings of the ADKDD'17. ACM; 2017: 12. (https:\/\/arxiv.org\/abs\/1708.05123) ||  ||     [2] Wang R; Shivanna R; Cheng D Z; et al. DCN-M: Improved Deep & Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems[J]. 2020. (https:\/\/arxiv.org\/abs\/2008.13535) || \""\""\""",No,Yes,Yes
16737,Modification: remove unused functions and imports; add a boolean parser.,No,Yes,Yes
16739,HACK. PyTorch is changing behavior,,,Yes
16740,HACK. PyTorch is changing behavior,Yes,No,Yes
16743,Temporary fix for issue #7 https:\/\/github.com\/avinashpaliwal\/Super-SloMo\/issues\/7 -,Yes,No,Yes
16745,Change of user; all columns but one,,,Yes
16748,Fen uses the opposite color system of us. Maybe we should swap.,Yes,Yes,Yes
16751,Move it,,,Yes
16752,'back rotate' the move before printing it.,No,No,Yes
16754,Check for stalemate. If best move loses king; but not doing anything would save us.,,,Yes
16757,TODO: How do we simply make this work for black as well?,Yes,No,Yes
16758,TODO: Maybe check for check here?,Yes,No,Yes
16759,am -> avoid move; bm -> best move,No,Yes,Yes
16760,Sometimes fen doesn't include half move clocks,No,Yes,Yes
16761,TODO: Ville det v;re bedre med to tps? En for fail-high og en for fail-low?,Yes,Yes,Yes
16762,FIXME: What if we never find a fail-high?,Yes,No,Yes
16764,I think it would be nicer (and stronger) to somehow guarantee we always get at least one fail-high,Yes,Yes,Yes
16765,TODO: Ville det v;re bedre med to tps? En for fail-high og en for fail-low?,Yes,Yes,Yes
16766,FIXME: What if we never find a fail-high?,Yes,No,Yes
16767,TODO: Maybe only use table for larger depth?,Yes,No,Yes
16769,TODO: Try speeding up hash table using score for key,,,Yes
16770,TODO: Check if allowing null-move in this search has a positive effect,,,Yes
16772,TODO: What about draws?,Yes,No,Yes
16773,FIXME: Do we really need that last rule?,,,Yes
16776,Apparantly it makes a huge difference... Maybe the depth-3 version is wrong somehow?,No,No,Yes
16777,TODO: If null score gets mated; we may still want to do a,,,Yes
16778,For some reason this still doesn't improve performance much...,Yes,Yes,Yes
16780,print('Root {} fail {}. Move {}'.format(depth;,,,Yes
16781,Sometimes fen doesn't include half move clocks,,,Yes
16783,Then killer move,No,No,Yes
16785,So we make another call that must always fail high and thus produce a move.,,,Yes
16786,But is best really -MATE_UPPER when legal moves?,No,No,Yes
16787,Then killer move,,,Yes
16788,Depth <= 0 is QSearch. Here any position is searched as deeply as is needed for calmness; and so there is no reason to keep different depths in the transposition table.,No,Yes,Yes
16789,This allows us to define the moves; but only calculate them if needed.,,,Yes
16790,Maybe we just didn't like the position we were in.,,,Yes
16794,for val; move in sorted(((pos.value(move); move) for move in pos.gen_moves()); reverse=True):,,,Yes
16796,TODO: start tokens and end tokens are hard code,Yes,Yes,Yes
16799,[todo:] add evaluation for AFLW and ALFW2000,,,Yes
16800,"\""\""\"" || The pipeline of 3DDFA prediction: given one image; predict the 3d face vertices; 68 landmarks and visualization. ||  || [todo] || 1. CPU optimization: https:\/\/pmchojnacki.wordpress.com\/2018\/10\/07\/slow-pytorch-cpu-performance || 2. Refine code || \""\""\""",Yes,No,Yes
16801,pose collection; [todo: validate it],,,Yes
16802,todo: check below,Yes,No,Yes
16803,"\""\""\""  || Creates a MobileNet Model as defined in: || Andrew G. Howard Menglong Zhu Bo Chen; et.al. (2017).  || MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.  || Copyright (c) Yang Lu; 2017 ||  || Modified By cleardusk || \""\""\""",No,Yes,Yes
16804,TODO: Plug weights from dictionary into right places,Yes,Yes,Yes
16805,fix later; make random note.,,,Yes
16807,since I think this is giving the bug.,No,No,Yes
16809,TODO: remove 0.0==inf duration bug in part 7,,,Yes
16810,ANSWER: resolves at end but melody ends 1\/16 before last measure so doesn't,,,Yes
16811,BETTER FIX: iterate through; if length = 0; then bump it up to 0.125,Yes,Yes,Yes
16813,the original data. Maybe add more parts; hand-add valid instruments.,Yes,Yes,Yes
16814,TODO: remove 0.0==inf duration bug in part 7,,,Yes
16815,ANSWER: resolves at end but melody ends 1\/16 before last measure so doesn't,,,Yes
16818,Maybe just start with rounding to nearest multiple of 0.125.,,,Yes
16820,QA TODO: chop off notes with offset > 4.0.,,,Yes
16822,fix note offset problems; i.e. same offset so pruning too many.,Yes,Yes,Yes
16827,maybe change 0 back to 1 (changed for python),Yes,No,Yes
16829,TODO: time comparison using map_() and xx1 < x1[i] instead,Yes,Yes,Yes
16830,"\""\""\"" || contains functionality for fetching datasets for use in the network || \""\""\""",,,Yes
16833,TODO optimize,Yes,Yes,Yes
16836,TODO: refactor,Yes,No,Yes
16840,TODO: time comparison using map_() and xx1 < x1[i] instead,Yes,Yes,Yes
16842,TODO: Build the rest of the sequentials in a for loop.,Yes,Yes,Yes
16843,TODO: Build the rest of the sequentials in a for loop.,Yes,Yes,Yes
16844,TODO merge these,,,Yes
16847,TODO: implement __call__ in PriorBox,Yes,Yes,Yes
16849,TODO refactor,Yes,Yes,Yes
16854,append sentinel values at both ends,,,Yes
16855,TODO:,,,Yes
16856,maybe also return img id,No,Yes,Yes
16859,todo : end of coding today,,,Yes
16862,"\""\""\""Implement some custom layers; not provided by TensorFlow. ||  || Trying to follow as much as possible the style\/standards used in || tf.contrib.layers || \""\""\""",No,Yes,Yes
16865,Xception arg scope (Keras hack!),No,No,Yes
16866,Maybe crop if needed.,Yes,No,Yes
16867,Maybe pad if needed.,Yes,No,Yes
16870,Moving averages ends up in the trainable variables collection,No,No,Yes
16873,Concatenate the cluster centroids for this split of fine codes,,,Yes
16874,Add the lopq module - not needed if they are available in the python environment,No,Yes,Yes
16876,The recall is probably better than the first but worse than the second. We increased recall,No,Yes,Yes
16879,The recall is probably better than the first but worse than the second. We increased recall,,,Yes
16881,TODO try tf.image.resize_image_with_crop_or_pad and tf.image.extract_glimpse,,,Yes
16883,TODO: Replace Lambda with custom Keras layer for loss.,Yes,Yes,Yes
16892,TODO: Remove dependence on Tensorflow session.,Yes,Yes,Yes
16893,TODO: Check transpose flag when implementing fully connected layers.,,,Yes
16898,TODO: Remove or add option for static implementation.,Yes,Yes,Yes
16899,TODO: Repeat_elements and tf.split doesn't support dynamic splits.,Yes,Yes,Yes
16901,TODO: Remove extra computation shared with yolo_head.,Yes,Yes,Yes
16905,TODO: Something must be done about this ugly hack!,Yes,Yes,Yes
16907,TODO: Replace Lambda with custom Keras layer for loss.,,,Yes
16909,fix seed,No,Yes,Yes
16911,TODO: Rewrite third_party imports.,Yes,Yes,Yes
16912,TODO: Make this a public api in slim arg_scope.py.,Yes,No,Yes
16913,TODO: Find a way to not depend on the private members.,,,Yes
16914,TODO: Remove with tf.device when top_k operation runs correctly on GPU.,,,Yes
16916,TODO: snake_case this method.,Yes,Yes,Yes
16917,TODO: summarize the number of matches on average.,Yes,Yes,Yes
16920,num_classes (maybe encoded as categories),No,No,Yes
16921,TODO: Have an argument called `aggregated_processor_tensor_keys` that contains,Yes,No,Yes
16922,tensors into the `results_list` data structure that are not needed by,,,Yes
16929,Needed for fine-tuning from classification checkpoints whose,No,Yes,Yes
16930,TODO: handle agnostic mode and positive\/negative class weights,Yes,No,Yes
16931,TODO: revisit whether to always use batch size as  the number of,,,Yes
16935,TODO: double check documentaion.,Yes,No,Yes
16936,TODO: Make this a public function.,,,Yes
16937,TODO: Consider replacing with tf.contrib.filter_variables in,,,Yes
16938,fix this only the indexer specific,Yes,Yes,Yes
16939,fix this only the indexer specific,Yes,Yes,Yes
16940,TODO: make reshape an option for the clip_to_window op,Yes,Yes,Yes
16941,TODO: Rewrite third_party imports.,Yes,Yes,Yes
16942,TODO: Make this a public api in slim arg_scope.py.,Yes,No,Yes
16944,TODO: Remove with tf.device when top_k operation runs correctly on GPU.,,,Yes
16947,TODO: summarize the number of matches on average.,Yes,Yes,Yes
16950,num_classes (maybe encoded as categories),No,No,Yes
16951,TODO: Have an argument called `aggregated_processor_tensor_keys` that contains,Yes,No,Yes
16955,Unused by updated loading code.,Yes,Yes,Yes
16956,TODO: Support batch tf example inputs.,Yes,No,Yes
16958,Get logical indices of ignored and unmatched columns as tf.int64,,,Yes
16960,TODO: handle agnostic mode and positive\/negative class weights,Yes,No,Yes
16962,TODO: Load variables selectively using scopes.,,,Yes
16963,TODO: Figure out if it is needed when image batch size is bigger.,Yes,Yes,Yes
16967,TODO: Consider replacing with tf.contrib.filter_variables in,,,Yes
16969,Create dir for ranked results if needed,,,Yes
16970,TODO: optimize this using batching,Yes,No,Yes
16974,TODO: worker task fails same reason as above,,,Yes
16975,TODO: convert this into batched updated.,,,Yes
16976,TODO try tf.image.resize_image_with_crop_or_pad and tf.image.extract_glimpse,Yes,Yes,Yes
16977,TODO: optimize this using batching,,,Yes
16979,TODO: optimize this using batching,,,Yes
16981,TODO: optimize this using batching,,,Yes
16983,TODO: Implement this,Yes,Yes,Yes
16984,TODO improve this by either having a seperate broadcast queues or using last update timestampl,,,Yes
16987,TODO Check if this is correct,Yes,No,Yes
16988,move this to compose command after git pull.,Yes,Yes,Yes
16993,TODO: make reshape an option for the clip_to_window op,Yes,Yes,Yes
16996,TODO: Handle the case where some boxes in selected_boxes do not,Yes,Yes,Yes
16997,TODO: Remove with tf.device when top_k operation runs correctly on GPU.,,,Yes
16998,TODO: Make sure the static shapes are preserved.,Yes,Yes,Yes
16999,TODO: This method pulls in all the implementation dependencies into,,,Yes
17000,TODO: This method pulls in all the implementation dependencies into core.,,,Yes
17001,TODO: Add label_handler that decodes from 'image\/object\/class\/text',Yes,Yes,Yes
17002,TODO: Use image_id tensor once we fix the input data,Yes,No,Yes
17003,TODO: result_dict contains batches of images; while,Yes,No,Yes
17006,num_classes (maybe encoded as categories),No,No,Yes
17007,TODO: Have an argument called `aggregated_processor_tensor_keys` that contains,,,Yes
17014,TODO: Support batch tf example inputs.,,,Yes
17017,TODO: revisit whether to always use batch size as  the number of,,,Yes
17020,simple hack to overcome this issue; we only exclude bbox labels,Yes,Yes,Yes
17024,Resize and crop if needed.,No,No,Yes
17025,TODO: Handle the case where host manager has not responded to last and itself has died,Yes,Yes,Yes
17026,"\""\""\"" || A simple wrapper around Deep Video Analytics REST API || \""\""\""",No,Yes,Yes
17027,TODO: make fast_rcnn irrelevant,Yes,Yes,Yes
17028,max overlap with gt over classes (columns),No,Yes,Yes
17031,These values will be needed for making predictions,,,Yes
17032,TODO \u8FD9\u4E2A\u540E\u671F\u53EF\u80FD\u8FD8\u9700\u8981\u4FEE\u6539\uFF0C\u6BD5\u7ADF\u5982\u679C\u4F7F\u7528\u7684\u662F\u5B57\u7B26\u7684\u7247\u6BB5\uFF0C\u90A3\u4E2A\u6B63\u6837\u672C\u7684\u6570\u91CF\u662F\u5F88\u591A\u7684\u3002,Yes,No,Yes
17034,TODO: make fast_rcnn irrelevant,,,Yes
17039,TODO: wait for Celery bug fix https:\/\/github.com\/celery\/celery\/issues\/3620,Yes,No,Yes
17040,TODO: worker fails due to,Yes,Yes,Yes
17041,TODO remove this once requirements.txt is updated,,,Yes
17042,TODO optimize this by doing matmul rather than calling for each entry,Yes,Yes,Yes
17046,Needed to ensure the 2 and 3 are balanced under new subnode,No,Yes,Yes
17047,TODO: Use Node.add() here; to simplify future balancing improvements.,,,Yes
17048,fix it,Yes,Yes,Yes
17052,FIXME: Load the actual file here.,Yes,No,Yes
17053,TODO: Make sure changes are saved.,Yes,Yes,Yes
17054,XXX: Very nasty way of converting types to QVariant methods :P,,,Yes
17055,TODO: Prompt user to save labels etc.,Yes,Yes,Yes
17056,TODO,Yes,Yes,Yes
17057,TODO: Tune value,Yes,Yes,Yes
17058,TODO:,,,Yes
17061,TODO:,Yes,No,Yes
17062,FIXME: Project point to pixmap's edge when getting out too fast.,Yes,Yes,Yes
17063,TODO:,,,Yes
17064,FIXME:,Yes,No,Yes
17069,XXX: What if user wants to remove label file?,No,Yes,Yes
17070,TODO: Add to list of labels.,Yes,No,Yes
17072,XXX: What if user wants to remove label file?,No,Yes,Yes
17074,FIXME,Yes,Yes,Yes
17076,go outside of the shape's area for some reason. XXX,No,No,Yes
17078,FIXME: Validation and trimming are completely broken if the,Yes,Yes,Yes
17079,FIXME,,,Yes
17080,TODO: Error handling.,Yes,No,Yes
17084,- [maybe] Find optimal epsilon value.,Yes,Yes,Yes
17085,TODO:,,,Yes
17090,TODO(wkentaro): Move to labelme\/utils.py,,,Yes
17091,FIXME: QSettings.value can return None on PyQt4,,,Yes
17092,XXX: need to add some actions here to activate the shortcut,Yes,Yes,Yes
17094,XXX: with pyproject.toml and without --no-use-pep517;,,,Yes
17097,TODO: make it with torch instead of numpy,Yes,Yes,Yes
17098,hack for python2\/3 compatibility,Yes,Yes,Yes
17100,hack for python2\/3 compatibility,,,Yes
17101,we probably missed the best pair because of pruning; go back to full statistics,Yes,No,Yes
17103,TODO: Also update the `freq`; although it is not likely to be used.,Yes,Yes,Yes
17104,TODO: expand to batch operation.,Yes,No,Yes
17105,TODO: Try different terminate conditions.,,,Yes
17106,TODO: Translate bpe encoded files,Yes,Yes,Yes
17107,TODO: Batch translation,Yes,No,Yes
17110,TODO: Hacked values for now,,,Yes
17111,TODO: Hacked values for now,,,Yes
17112,TODO: Hacked values for now,,,Yes
17113,TODO: more efficient approach,,,Yes
17114,TODO: more efficient approach,,,Yes
17116,TODO: Hacked values for now,Yes,Yes,Yes
17117,TODO: more efficient approach,Yes,Yes,Yes
17118,TODO: Fix up these metrics!,Yes,Yes,Yes
17119,TODO: Fix sparse correlation -- it is close but has precision issues,,,Yes
17120,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
17122,TODO: reimplement with quaternions to avoid singularity,,,Yes
17123,TODO: more efficient approach,Yes,Yes,Yes
17127,TODO: set up transform data,,,Yes
17130,TODO: set up transform data,Yes,Yes,Yes
17133,TODO: set up transform data,,,Yes
17134,TODO: Handle connected component issues properly,,,Yes
17135,TODO: Remove debugging code,,,Yes
17137,TODO: set up transform data,Yes,Yes,Yes
17140,needed to sklearn comparability,No,Yes,Yes
17141,TODO: set up transform data,Yes,Yes,Yes
17143,needed to sklearn comparability,No,Yes,Yes
17144,TODO: set up transform data,Yes,Yes,Yes
17146,TODO: figure out the right thing to do here,,,Yes
17147,needed to sklearn comparability,No,Yes,Yes
17149,TODO: Handle connected component issues properly,,,Yes
17150,needed to sklearn comparability,No,Yes,Yes
17151,TODO: set up transform data,,,Yes
17152,TODO: Handle connected component issues properly,Yes,Yes,Yes
17155,Fix #179,No,Yes,Yes
17156,needed to sklearn comparability,Yes,Yes,Yes
17158,TODO: Handle connected component issues properly,,,Yes
17160,TODO: Hacked values for now,Yes,Yes,Yes
17161,Fix #179,,,Yes
17162,needed to sklearn comparability,No,Yes,Yes
17163,TODO: set up transform data,Yes,Yes,Yes
17165,needed to sklearn comparability,,,Yes
17167,TODO: Handle connected component issues properly,Yes,Yes,Yes
17168,TODO: Hacked values for now,Yes,Yes,Yes
17170,TODO: set up transform data,Yes,Yes,Yes
17171,TODO: Handle connected component issues properly,,,Yes
17173,TODO: Hacked values for now,Yes,Yes,Yes
17175,TODO: set up transform data,,,Yes
17176,TODO: Handle connected component issues properly,,,Yes
17177,TODO: Hacked values for now,Yes,Yes,Yes
17179,TODO: set up transform data,,,Yes
17180,TODO: Handle connected component issues properly,,,Yes
17181,TODO: We can likely make this more efficient and not recompute each time,Yes,No,Yes
17182,"u = DataFrameUMAP(metrics=[(\""e\""; \""euclidean\""; \""bad_columns\"")])",No,Yes,Yes
17184,needed as there is no assertion nor,,,Yes
17186,TODO: allow disconnection_distance on precomputed so that a user can upper bound connectivity.,,,Yes
17187,TODO: filter dists,Yes,No,Yes
17189,TODO: filter dists,Yes,No,Yes
17190,needed to sklearn comparability,,,Yes
17191,TODO: set up transform data,Yes,Yes,Yes
17192,TODO: Handle connected component issues properly,,,Yes
17194,print('mouse move'; self.pos),,,Yes
17195,fix window siz,,,Yes
17198,[hack] hard-coded,,,Yes
17200,[hack] after 150 iterations; do not change the order of the results,Yes,Yes,Yes
17203,[hack] after 150 iterations; do not change the order of the results,Yes,Yes,Yes
17204,[hack],,,Yes
17206,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
17207,FIXME : should work with uppercase in sentence,Yes,No,Yes
17209,cdecl calling convention,,,Yes
17210,''' || You can implement your own Converter; check example ConverterMasked.py || ''',No,Yes,Yes
17211,''' || You can implement your own model. Check examples. || ''',,,Yes
17212,''' || You can implement your own TrainingDataGenerator || ''',No,No,Yes
17213,''' || You can implement your own SampleGenerator || ''',No,No,Yes
17217,currently unused,Yes,Yes,Yes
17219,fix opencv bug when window size more than screen size,,,Yes
17221,"\""\""\"" || output_sample_types = [ ||                         {} opts; ||                         ... ||                       ] ||                        || opts: ||     'types' : (S;S;...;S) ||         where S: ||             'IMG_SOURCE' ||             'IMG_WARPED' ||             'IMG_WARPED_TRANSFORMED'' ||             'IMG_TRANSFORMED' ||             'IMG_LANDMARKS_ARRAY' #currently unused ||             'IMG_PITCH_YAW_ROLL' ||              ||             'FACE_TYPE_HALF' ||             'FACE_TYPE_FULL' ||             'FACE_TYPE_HEAD'    #currently unused ||             'FACE_TYPE_AVATAR'  #currently unused ||  ||             'FACE_MASK_FULL'  ||             'FACE_MASK_EYES' #currently unused ||  ||             'MODE_BGR'         #BGR ||             'MODE_G'           #Grayscale ||             'MODE_GGG'         #3xGrayscale ||             'MODE_M'           #mask only ||             'MODE_BGR_SHUFFLE' #BGR shuffle ||          ||     'resolution' : N ||         ||     'motion_blur' : (chance_int; range) - chance 0..100 to apply to face (not mask); and range [1..3] where 3 is highest power of motion blur ||  || \""\""\""",,,Yes
17222,"\""\""\"" ||  ||         RANDOM_CLOSE               = 0x00000040; #currently unused ||         MORPH_TO_RANDOM_CLOSE      = 0x00000080; #currently unused ||  || if f & SPTF.RANDOM_CLOSE != 0: ||                 img_type += 10 ||             elif f & SPTF.MORPH_TO_RANDOM_CLOSE != 0: ||                 img_type += 20 || if img_type >= 10 and img_type <= 19: #RANDOM_CLOSE ||     img_type -= 10 ||     img = close_sample_bgr ||     cur_sample = close_sample ||  || elif img_type >= 20 and img_type <= 29: #MORPH_TO_RANDOM_CLOSE ||     img_type -= 20 ||     res = sample.shape[0] ||  ||     s_landmarks = sample.landmarks.copy() ||     d_landmarks = close_sample.landmarks.copy() ||     idxs = list(range(len(s_landmarks))) ||     #remove landmarks near boundaries ||     for i in idxs[:]: ||         s_l = s_landmarks[i] ||         d_l = d_landmarks[i] ||         if s_l[0] < 5 or s_l[1] < 5 or s_l[0] >= res-5 or s_l[1] >= res-5 or \\ ||             d_l[0] < 5 or d_l[1] < 5 or d_l[0] >= res-5 or d_l[1] >= res-5: ||             idxs.remove(i) ||     #remove landmarks that close to each other in 5 dist ||     for landmarks in [s_landmarks; d_landmarks]: ||         for i in idxs[:]: ||             s_l = landmarks[i] ||             for j in idxs[:]: ||                 if i == j: ||                     continue ||                 s_l_2 = landmarks[j] ||                 diff_l = np.abs(s_l - s_l_2) ||                 if np.sqrt(diff_l.dot(diff_l)) < 5: ||                     idxs.remove(i) ||                     break ||     s_landmarks = s_landmarks[idxs] ||     d_landmarks = d_landmarks[idxs] ||     s_landmarks = np.concatenate ( [s_landmarks; [ [0;0]; [ res \/\/ 2; 0]; [ res-1; 0]; [0; res\/\/2]; [res-1; res\/\/2] ;[0;res-1] ;[res\/\/2; res-1] ;[res-1;res-1] ] ] ) ||     d_landmarks = np.concatenate ( [d_landmarks; [ [0;0]; [ res \/\/ 2; 0]; [ res-1; 0]; [0; res\/\/2]; [res-1; res\/\/2] ;[0;res-1] ;[res\/\/2; res-1] ;[res-1;res-1] ] ] ) ||     img = imagelib.morph_by_points (sample_bgr; s_landmarks; d_landmarks) ||     cur_sample = close_sample || else: ||     \""\""\""",No,Yes,Yes
17223,todo https:\/\/github.com\/plaidml\/plaidml\/issues\/301,,,Yes
17224,"\""\""\"" ||                 elif self.converter.type == Converter.TYPE_IMAGE_WITH_LANDMARKS: ||                     #currently unused ||                     if filename_path.suffix == '.png': ||                         dflimg = DFLPNG.load( str(filename_path) ) ||                     elif filename_path.suffix == '.jpg': ||                         dflimg = DFLJPG.load ( str(filename_path) ) ||                     else: ||                         dflimg = None ||  ||                     if dflimg is not None: ||                         image_landmarks = dflimg.get_landmarks() ||  ||                         image = self.converter.convert_image(image; image_landmarks; self.debug)  ||  ||                         if self.debug: ||                             raise NotImplementedError ||                             #for img in image: ||                             #    io.show_image ('Debug convert'; img ) ||                             #    cv2.waitKey(0) ||                         faces_processed = 1 ||                     else: ||                         self.log_err (\""%s is not a dfl image file\"" % (filename_path.name) ) ||                          || \""\""\""",Yes,No,Yes
17227,unused in end user workflow,Yes,Yes,Yes
17228,todo https:\/\/github.com\/plaidml\/plaidml\/issues\/301,,,Yes
17229,unused in end user workflow,,,Yes
17230,"\""\""\"" || Leras.  ||  || like lighter keras. || This is my lightweight neural network library written from scratch || based on pure tensorflow without keras. ||  || Provides: || + full freedom of tensorflow operations without keras model's restrictions  || + easy model operations like in PyTorch; but in graph mode (no eager execution) || + convenient and understandable logic ||  || Reasons why we cannot import tensorflow or any tensorflow.sub modules right here: || 1) change env variables based on DeviceConfig before import tensorflow || 2) multiprocesses will import tensorflow every spawn || \""\""\""",No,No,Yes
17232,Fix for linux,,,Yes
17236,fix for Linux ; Ignoring :,,,Yes
17238,unused in end user workflow,Yes,Yes,Yes
17239,unused in end user workflow,,,Yes
17240,todo green bg,No,No,Yes
17241,unused in end user workflow,Yes,Yes,Yes
17243,unused in end user workflow,,,Yes
17244,Fix arrays,,,Yes
17245,"Works much better than solvePnP if landmarks from \""3DFAN\""",No,Yes,Yes
17247,TODO \u9700\u8981\u533A\u5206hdf5\u548Ccsv\u4E0D\u540C\u5B58\u8D2E\u60C5\u51B5\uFF0Ccsv\u5B58\u8D2E\u6A21\u5F0F\u4E0B\u53EF\u4EE5\u5E76\u884C\u8BFB\u5199,,,Yes
17249,TODO \u7F29\u77ED E_MARKET_TARGET_US\uFF0D>US,,,Yes
17250,TODO EMarketDataSplitMode\u79FB\u52A8\u5230\u5E02\u573A\u8BF7\u6C42\u76F8\u5173\u5BF9\u5E94\u7684\u6A21\u5757\u4E2D,Yes,No,Yes
17253,TODO \u5C06log\u62BD\u51FA\u6765\u4ECEenv\u4E2D,,,Yes
17255,TODO Iterable\u548Csix.string_types\u7684\u5224\u65AD\u62BD\u51FA\u6765\u653E\u5728\u4E00\u4E2A\u6A21\u5757\uFF0C\u505A\u4E3AIterable\u7684\u5224\u65AD\u6765\u4F7F\u7528,,,Yes
17256,batches. Better reduce the batch size a bit to limit the,Yes,No,Yes
17258,will change with every new kernel instance. This hack,Yes,No,Yes
17259,Hack to detect functions not defined at the module-level,,,Yes
17260,TODO: Maybe add a warning here?,Yes,No,Yes
17263,XXX: Should this use inspect.formatargvalues\/formatargspec?,,,Yes
17264,XXX: Not using logging framework,,,Yes
17265,XXX: There might be a more efficient way of doing this,,,Yes
17266,workaround is to view the array as bytes before,,,Yes
17267,XXX: This conflicts with the debug flag used in children class,,,Yes
17269,FIXME: Too much logic duplicated,,,Yes
17273,FIXME: The statements below should be try\/excepted,Yes,Yes,Yes
17274,XXX: Should use an exception logger,,,Yes
17276,XXX: Should be using warnings; and giving stacklevel,Yes,Yes,Yes
17279,XXX: Bad explanation of the None value of cachedir,Yes,Yes,Yes
17280,_mk_exception. Note: in Python 2; if you implement __init__,,,Yes
17282,BZ2File doesn't implement the file object context manager in python 2,,,Yes
17283,XXX: Not using the logger framework: need to,Yes,Yes,Yes
17285,"\""\""\""Custom implementation of multiprocessing.Pool with custom pickler. ||  || This module provides efficient ways of working with data stored in || shared memory with numpy.memmap arrays without inducing any memory || copy between the parent and child processes. ||  || This module should not be imported if multiprocessing is not || available as it implements subclasses of multiprocessing Pool || that uses a custom alternative to SimpleQueue. ||  || \""\""\""",,,Yes
17287,TODO: check scipy sparse datastructure if scipy is installed,Yes,Yes,Yes
17288,XXX: implement an explicit reference counting scheme to make it,,,Yes
17289,Let us use a closure to workaround this limitation.,Yes,Yes,Yes
17290,"Workaround  occasional \""[Error 5] Access is denied\"" issue",Yes,Yes,Yes
17291,The circular doubly linked list starts and ends with a sentinel element.,,,Yes
17293,TODO: \u5982\u679C\u5B50\u7B56\u7565\u4E2D\u4F7F\u7528skip_days\u9891\u7387\u9AD8\uFF0C\u52A0\u4E2A\u88C5\u9970\u5668\uFF0C\u5B50\u7C7B\u4F9D\u636E\u60C5\u51B5\u9009\u62E9\u662F\u5426\u88C5\u9970,,,Yes
17294,TODO Iterable\u548Csix.string_types\u7684\u5224\u65AD\u62BD\u51FA\u6765\u653E\u5728\u4E00\u4E2A\u6A21\u5757\uFF0C\u505A\u4E3AIterable\u7684\u5224\u65AD\u6765\u4F7F\u7528,,,Yes
17295,TODO \u9700\u8981\u91CD\u6784\u8FD9\u4E2A\u7C7B\uFF0C\u592A\u957F\u4E86,,,Yes
17296,FIXME \u6700\u597D\u4E0D\u8981\u4F7F\u7528ClassifierMixin\u5224\u5B9A\u5B66\u4E60\u5668\u7C7B\u578B\uFF0C\u56E0\u4E3A\u9650\u5B9A\u4E86sklearn,,,Yes
17297,# FIXME \u6700\u597D\u4E0D\u8981\u4F7F\u7528RegressorMixin; AbuMLCreater\u4E2D\u5F15\u7528\u4E86hmmlearn\uFF0Cxgboost\u7B49\u7B2C\u4E09\u65B9\u5E93,Yes,Yes,Yes
17299,\u7B2C\u4E00\u6B65\u8FC7\u6EE4\u4E0D\u5728\u5728\u7279\u5F81\u5217\u4E2D\u7684feature_columns\u5143\u7D20,No,No,Yes
17301,\u7B2C\u4E09\u6B65\u8FC7\u6EE4feature_columns\u5143\u7D20\u4E2D\u6240\u6307\u7279\u5F81\u5217\u4E2Dunique==1\u7684\uFF0Ceg\uFF1A1\u5217\u5168\u662F1\uFF0C\u5168\u662F0\uFF0C\u6CA1\u529E\u6CD5\u505Abin,No,No,Yes
17302,TODO \u5BF9\u5916\u7684\u7248\u672C\u6682\u65F6\u5168\u90E8\u90FD\u4F7F\u7528sklearn\u4E0D\u4ECE\u5176\u5B83\u7B2C\u4E09\u65B9\u5E93import\uFF0C\u589E\u52A0\u53EF\u9009\u5F00\u5173\u7B49\u8BBE\u7F6E,Yes,No,Yes
17303,TODO out_file path\u653E\u5012cache\u4E2D,Yes,Yes,Yes
17306,\u7531\u4E8E\u5DF2fix\u4E86trade_day.close\uFF0C\u6240\u4EE5high\uFF0Clow\uFF0Copen\u4F7F\u7528trade_day.close fix,No,Yes,Yes
17308,raise RuntimeError('df.columns must have |date|open|close|high|volume| '),No,No,Yes
17311,TODO \u53EF\u8BBE\u7F6E\u7684\u7EA2\u6DA8\u7EFF\u8DCC\uFF0C\u8FD8\u662F\u7EFF\u6DA8\u7EA2\u8DCC,No,Yes,Yes
17313,TODO \u505Apd.Panel\u6570\u636E\u5E94\u8BE5\u4FDD\u8BC1\u6BCF\u4E00\u4E2A\u5143\u7D20\u7684\u884C\u6570\u548C\u5217\u6570\u90FD\u76F8\u7B49\uFF0C\u4E0D\u662F\u7B80\u5355\u7684\u6709\u6570\u636E\u5C31\u884C,Yes,Yes,Yes
17314,TODO pd.Panel\u8FC7\u65F6,,,Yes
17315,TODO \u4F7F\u7528enum\u4EE3\u66FFK\u5E38\u91CF,,,Yes
17317,\u5C06\u8BA1\u7B97\u7ED3\u679C\u7684corr\u8F6C\u6362\u4E3Apd.DataFrame\u5BF9\u8C61\uFF0C\u884C\u548C\u5217\u7D22\u5F15\u90FD\u4F7F\u7528df.columns,,,Yes
17318,FIXME \u6682\u65F6\u5FFD\u7565\u4E00\u4E2Abug\u5982\u679C\u8BF7\u6C42\u53EF\u89C6\u5316\u65F6\u4F7F\u7528\u7684\u662Fstart\uFF0Cend\uFF0C\u65B9\u5F0F\u90A3\u4E48\u8FD9\u91CC\u53EF\u89C6\u5316\u7684\u65F6\u95F4\u6BB5\u5C31\u4E0D\u7B26\u5408\u4E86\uFF0C\u9700\u8981\u4F20\u9012\u5B8C\u6574\u7684\u4FE1\u606F,,,Yes
17319,TODO \u8FD9\u4E2A\u6982\u7387\u6700\u597D\u4F7F\u7528\u6210\u4EA4\u91CF\u5F53\u65E5\u6765\u8BA1\u7B97\u51FA\u6765,Yes,No,Yes
17321,TODO \u8FD9\u4E2A\u6982\u7387\u6700\u597D\u4F7F\u7528\u6210\u4EA4\u91CF\u5F53\u65E5\u6765\u8BA1\u7B97\u51FA\u6765,,,Yes
17322,FIXME \u8FD9\u91CC\u6CA1\u6709\u5BF9\u8D85\u51FA\u989C\u8272\u7684\u8303\u56F4\u8FDB\u884C\u5904\u7406\uFF0C\u5982\u679C\u805A\u7C7B\u4E2A\u6570\u8D85\u8FC7\u989C\u8272\uFF0C\u4F1A\u51FA\u9519,Yes,Yes,Yes
17324,TODO \u5728\u8FD9\u91CC\u5904\u7406\u6709\u70B9\u665A,Yes,Yes,Yes
17327,TODO AbuTLine\u4E2D\u6DFB\u52A0\u591A\u6761\u7EBF\u7684\u6807\u51C6\u5BF9\u6BD4\u65B9\u6CD5\uFF0C\u5DE6\u53F3\u53CC\u8F74\u548C\u6570\u636E\u53D8\u5316\u65B9\u5F0F,Yes,Yes,Yes
17328,FIXME \u9488\u5BF9\u6781\u7AEF\u6CA1\u6709\u627E\u5230\u8DB3\u591F\u7ED8\u5236\u652F\u6491\u963B\u529B\u4F4D\u7684\u60C5\u51B5\u505A\u5904\u7406,Yes,No,Yes
17329,TODO \u9700\u8981\u6839\u636Ekey\u4F7F\u7528code_to_symbol\u8FDB\u884Cfetch\u6570\u636E,Yes,No,Yes
17331,TODO \u62C6\u5F00predict\u548C\u8BAD\u7EC3\u6570\u636E\u903B\u8F91\uFF0C\u4E0D\u8981\u7EA0\u7F20\u5728\u4E00\u8D77,,,Yes
17337,TODO \u6DFB\u52A0\u5176\u5B83\u8BA1\u7B97improved\u7684\u65B9\u5F0F\uFF0C\u6216\u8005\u6743\u91CD\u80DC\u7387\u7B49\u591A\u56E0\u7D20\u51B3\u7B56improved\u503C,,,Yes
17340,TODO \u653E\u5728\u8FD9\u91CC\u4E0D\u5408\u9002\uFF0C\u8FD8\u8981\u548CABuScalerUtil\u4E2D\u7684\u88C5\u9970\u5668arr_to_pandas\u91CD\u590D\u4EE3\u7801\u8FDB\u884C\u91CD\u6784,Yes,Yes,Yes
17341,TODO \u653E\u5728\u8FD9\u91CC\u4E0D\u5408\u9002\uFF0C\u8FD8\u8981\u548CABuScalerUtil\u4E2D\u7684\u88C5\u9970\u5668arr_to_numpy\u91CD\u590D\u4EE3\u7801\u8FDB\u884C\u91CD\u6784,Yes,No,Yes
17342,TODO \u6839\u636E\u6587\u4EF6\u5927\u5C0F\uFF0C\u51B3\u5B9A\u8FD9\u91CC\u662F\u5426\u9700\u8981tip wait,Yes,No,Yes
17344,TODO ABuScalerUtil\u4E2D\u6DFB\u52A0\u4F7F\u7528\u56FA\u5B9A\u8F74\u8FDB\u884C\u7F29\u653E\u7684\u529F\u80FD,No,No,Yes
17345,TODO \u8FD9\u91CC\u9700\u8981\u53EF\u4EE5\u8BBE\u7F6E\u6807\u51C6\u5316\u4F7F\u7528\u7684\u65B9\u6CD5\uFF0C\u6682\u65F6\u90FD\u4F7F\u7528scaler_mm,Yes,No,Yes
17346,\u5C06\u8BA1\u7B97\u7ED3\u679C\u7684distance\u8F6C\u6362\u4E3Apd.DataFrame\u5BF9\u8C61\uFF0C\u884C\u548C\u5217\u7D22\u5F15\u90FD\u4F7F\u7528df.columns,,,Yes
17348,TODO random.choice\u6709\u653E\u56DE\u62BD\u53D6\u65B9\u6CD5; \u6DFB\u52A0\u53C2\u6570\u652F\u6301\u65E0\u653E\u56DE\u62BD\u53D6\u6A21\u5F0F,,,Yes
17351,TODO  start,Yes,Yes,Yes
17352,TODO end,,,Yes
17353,e.g: dist\/abupy-xxx-py2.py3-none-any.whl,No,No,Yes
17354,TODO \u63D0\u53D6AbuFutures\u57FA\u7C7B\uFF0C\u5220\u9664\u91CD\u590D\u4EE3\u7801,,,Yes
17358,TODO \u91CD\u6784\u4E0E\u4E70\u5165\u56E0\u5B50\u91CD\u590D\u4EE3\u7801\u62BD\u53D6,Yes,Yes,Yes
17359,TODO \u6839\u636EORDER\u6570\u91CF\u5927\u4E8E\u4E00\u5B9A\u9600\u503C\u542F\u52A8\u8FDB\u5EA6\u6761,Yes,No,Yes
17360,print(corr_df.columns),,,Yes
17363,TODO \u52A0\u8F7D\u66F4\u591A\u6216\u8005\u5206\u6BB5\u52A0\u8F7D\u65B9\u5F0F\uFF0C\u6682\u65F6\u53EA\u53D6\u51FA10\u4E2A\u76F8\u5173\u7684\u80A1\u7968,,,Yes
17364,TODO,,,Yes
17365,TODO \u6ED1\u70B9\u7C7B\u5B8C\u5584\u53C2\u6570\u6784\u5EFA\u7B49\u9700\u6C42,Yes,Yes,Yes
17366,TODO AbuAtrPosition\u7B56\u7565\u4E2Dstd_atr_threshold\u7684\u8BBE\u7F6E,Yes,No,Yes
17367,FIXME BUG \u4F4E\u7248\u672Cipywidgets\u4E0B\u5220\u9664\u7684\u4E0D\u5BF9,Yes,Yes,Yes
17368,TODO. flush every flush_secs; not every time.,,,Yes
17371,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
17373,TODO make doc,Yes,No,Yes
17375,TODO: use recursive parse,Yes,No,Yes
17376,a Fully Conv is: (TODO: check var1.size(0)==var2.size(0)),,,Yes
17377,a Conv with bias is: (TODO: check var1.size(0)==var2.size(0)),,,Yes
17378,0.3.1 workaround,,,Yes
17379,FIXME: only first output is considered,Yes,No,Yes
17381,Maybe we should encode the tag so slashes don't trip us up?,Yes,Yes,Yes
17382,I don't think this will mess us up; but better safe than sorry.,,,Yes
17383,Maybe we should encode the tag so slashes don't trip us up?,Yes,Yes,Yes
17386,unused,Yes,No,Yes
17387,# TODO: hack to clear the info. Should be cleaner.,Yes,No,Yes
17389,TODO (ml7): Remove try-except when PyTorch 1.0 merges PyTorch and Caffe2,Yes,Yes,Yes
17390,TODO: Visdom doesn't support embeddings yet; so this is a no-op,Yes,Yes,Yes
17393,TODO (ml7): Remove when PyTorch 1.0 merges PyTorch and Caffe2,,,Yes
17395,TODO: reverse the logic here; shoudl do the permutation in numpy,Yes,Yes,Yes
17396,workaround for pytorch\/issue#10249,Yes,No,Yes
17398,and recreated later as needed.,No,Yes,Yes
17404,"Known word preceded by a modifier (\""really good\"").",No,Yes,Yes
17405,"Unknown word. Retain modifier across small words (\""really is a good\"").",No,Yes,Yes
17409,This is a hack; because the x-scrollbar isn't updating its,,,Yes
17412,Move the text string down; if necessary.,No,Yes,Yes
17415,TODO: throughout this package variable names and docstrings need,Yes,No,Yes
17418,This looks up multiple words at once.  This is probably not,No,Yes,Yes
17419,Author: Peter Spiller <pspiller@csse.unimelb.edu.au>,,,Yes
17421,i.e. 'you' is not really a thing that can be mapped this way; so this,Yes,Yes,Yes
17422,why questions are separated into three types:,,,Yes
17423,"\""why..I\""     e.g. \""why am I here?\"" \""Why do I like cake?\""",No,No,Yes
17424,"\""why...\""    e.g. \""Why is the sky blue?\""",No,No,Yes
17427,this should probably be made more strict than it is -- e.g.; it,Yes,No,Yes
17429,"\""\""\"" || A classifier model that decides which label to assign to a token on || the basis of a tree structure; where branches correspond to conditions || on feature values; and leaves correspond to label assignments. || \""\""\""",,,Yes
17431,"\""\""\"" || A classifier model based on maximum entropy modeling framework.  This || framework considers all of the probability distributions that are || empirically consistent with the training data; and chooses the || distribution with the highest entropy.  A probability distribution is || \""empirically consistent\"" with a set of training data if its estimated || frequency with which a class and a feature vector value co-occur is || equal to the actual frequency in the data. ||  || Terminology: 'feature' || ====================== || The term *feature* is usually used to refer to some property of an || unlabeled token.  For example; when performing word sense || disambiguation; we might define a ``'prevword'`` feature whose value is || the word preceding the target word.  However; in the context of || maxent modeling; the term *feature* is typically used to refer to a || property of a \""labeled\"" token.  In order to prevent confusion; we || will introduce two distinct terms to disambiguate these two different || concepts: ||  ||   - An \""input-feature\"" is a property of an unlabeled token. ||   - A \""joint-feature\"" is a property of a labeled token. ||  || In the rest of the ``nltk.classify`` module; the term \""features\"" is || used to refer to what we will call \""input-features\"" in this module. ||  || In literature that describes and discusses maximum entropy models; || input-features are typically called \""contexts\""; and joint-features || are simply referred to as \""features\"". ||  || Converting Input-Features to Joint-Features || ------------------------------------------- || In maximum entropy models; joint-features are required to have numeric || values.  Typically; each input-feature ``input_feat`` is mapped to a || set of joint-features of the form: ||  || |   joint_feat(token; label) = { 1 if input_feat(token) == feat_val || |                              {      and label == some_label || |                              { || |                              { 0 otherwise ||  || For all values of ``feat_val`` and ``some_label``.  This mapping is || performed by classes that implement the ``MaxentFeatureEncodingI`` || interface. || \""\""\""",,,Yes
17433,"\""\""\"" || A classifier based on a support vector machine. This code uses Thorsten Joachims' || SVM^light implementation (http:\/\/svmlight.joachims.org\/); wrapped using || PySVMLight (https:\/\/bitbucket.org\/wcauchois\/pysvmlight). The default settings are to || train a linear classification kernel; though through minor modification; full SVMlight || capabilities should be accessible if needed. Only binary classification is possible at present. || \""\""\""",,,Yes
17435,calculate likelihood - FIXME: may be broken,,,Yes
17437,columns to expect for SRL data.,,,Yes
17438,optional tree columns,No,Yes,Yes
17439,Remaining columns: self,,,Yes
17440,TODO: figure out while empty documents are being returned,,,Yes
17441,is there a better way?,,,Yes
17443,fix lone &,No,Yes,Yes
17444,"fix \""\""\""",,,Yes
17445,"fix <s snum=dd> => <s snum=\""dd\""\/>",,,Yes
17449,FIXME: this won't work under python 3,Yes,Yes,Yes
17451,Move on to the next piece.,No,Yes,Yes
17452,If we're stripping comments; then make sure our block ends,No,Yes,Yes
17453,workaround for py25 which doesn't support followlinks,Yes,Yes,Yes
17455,TODO: Add in the option to manually add a new root node; this will be,Yes,Yes,Yes
17461,"Hack to keep NLTK's \""tokenize\"" module from colliding with the \""tokenize\"" in",Yes,Yes,Yes
17463,So this is really what we should do.  That way the threaded,No,Yes,Yes
17464,Somewhat of a hack; but we need a proper package reference,,,Yes
17465,the wrong thing to do.  Maybe the _interactive_download,No,Yes,Yes
17467,shown.  n.b.: we never hide the first two columns (mark and,No,Yes,Yes
17470,If columns was specified as an int; convert it to a list.,No,Yes,Yes
17474,Hide\/Show Columns,,,Yes
17476,Move it back; if we were dragging.,,,Yes
17478,TODO lf = lf.normalize('[xyz]\\d*'; 'z%d'),,,Yes
17479,Prover9 crashed; most probably due to a bug.,Yes,Yes,Yes
17482,Author: Peter Ljungl\u00F6f <peter.ljunglof@heatherleaf.se>,No,Yes,Yes
17485,TODO: change this to conform more with the standard ChartParser,,,Yes
17486,[XX] TEMPORARY HACK WARNING!  This should be replaced with,Yes,Yes,Yes
17487,Subclasses should define more efficient implementations of this;,,,Yes
17488,[xx] nb: this is not too efficient,,,Yes
17494,#NAME?,,,Yes
17496,TODO: the above can't handle zip files; but this should anyway be fixed in nltk.data.load(),Yes,Yes,Yes
17501,todo: get a more general solution to canonicalized symbols for clauses -- maybe use xmlcharrefs?,Yes,No,Yes
17502,i == 0 never happens perhaps,Yes,Yes,Yes
17503,"if self.ends(\""abli\""):      self.r(\""able\"")",No,Yes,Yes
17504,NOTE: a simple but ugly hack to make this parser happy with double '\\t's,Yes,No,Yes
17506,the word ends in 'a'? apply rule for feminine reduction,,,Yes
17508,If the word ends with a double consonant,No,No,Yes
17511,Ensure that the filename ends with '.zip',No,No,Yes
17514,Author: Peter Ljungl\u00F6f <peter.ljunglof@heatherleaf.se>,,,Yes
17516,XXX what should we do in Python 3?,No,Yes,Yes
17518,temporary hack:,Yes,No,Yes
17520,why is this needed?,No,Yes,Yes
17522,FIXME Should this raise some kind of error instead?,,,Yes
17523,"r\""\""\"" || Punkt Sentence Tokenizer ||  || This tokenizer divides a text into a list of sentences; || by using an unsupervised algorithm to build a model for abbreviation || words; collocations; and words that start sentences.  It must be || trained on a large collection of plaintext in the taret language || before it can be used. ||  || The NLTK data package includes a pre-trained Punkt tokenizer for || English. ||  ||     >>> import nltk.data ||     >>> text = ''' ||     ... Punkt knows that the periods in Mr. Smith and Johann S. Bach ||     ... do not mark sentence boundaries.  And sometimes sentences ||     ... can start with non-capitalized words.  i is a good variable ||     ... name. ||     ... ''' ||     >>> sent_detector = nltk.data.load('tokenizers\/punkt\/english.pickle') ||     >>> print('\ || -----\ || '.join(sent_detector.tokenize(text.strip()))) ||     Punkt knows that the periods in Mr. Smith and Johann S. Bach ||     do not mark sentence boundaries. ||     ----- ||     And sometimes sentences ||     can start with non-capitalized words. ||     ----- ||     i is a good variable ||     name. ||  || (Note that whitespace from the original text; including newlines; is || retained in the output.) ||  || Punctuation following sentences can be included with the realign_boundaries || flag: ||  ||     >>> text = ''' ||     ... (How does it deal with this parenthesis?)  \""It should be part of the ||     ... previous sentence.\"" ||     ... ''' ||     >>> print('\ || -----\ || '.join( ||     ...     sent_detector.tokenize(text.strip(); realign_boundaries=True))) ||     (How does it deal with this parenthesis?) ||     ----- ||     \""It should be part of the ||     previous sentence.\"" ||  || However; Punkt is designed to learn parameters (a list of abbreviations; etc.) || unsupervised from a corpus similar to the target domain. The pre-packaged models || may therefore be unsuitable: use ``PunktSentenceTokenizer(text)`` to learn || parameters from the given text. ||  || :class:`.PunktTrainer` learns parameters such as a list of abbreviations || (without supervision) from portions of text. Using a ``PunktTrainer`` directly || allows for incremental training and modification of the hyper-parameters used || to decide what is considered an abbreviation; etc. ||  || :class:`.PunktWordTokenizer` uses a regular expression to divide a text into tokens; || leaving all periods attached to words; but separating off other punctuation: ||  ||     >>> from nltk.tokenize.punkt import PunktWordTokenizer ||     >>> s = \""Good muffins cost $3.88\ || in New York.  Please buy me\ || two of them.\ || \ || Thanks.\"" ||     >>> PunktWordTokenizer().tokenize(s) ||     ['Good'; 'muffins'; 'cost'; '$3.88'; 'in'; 'New'; 'York.'; 'Please'; ||     'buy'; 'me'; 'two'; 'of'; 'them.'; 'Thanks.'] ||  || The algorithm for this tokenizer is described in:: ||  ||   Kiss; Tibor and Strunk; Jan (2006): Unsupervised Multilingual Sentence ||     Boundary Detection.  Computational Linguistics 32: 485-525. || \""\""\""",,,Yes
17525,TODO: Frequent sentence starters optionally exclude always-capitalised words,Yes,No,Yes
17526,FIXME: Problem with ending string with e.g. '!!!' -> '!! !',Yes,Yes,Yes
17528,needed after freq_threshold,,,Yes
17530,XXX: it is stated in module docs that there is no function versions,No,Yes,Yes
17531,TODO: add LabelledTree (can be used for dependency trees),Yes,Yes,Yes
17533,A semi-hack to have elegant looking code below.  As a result;,Yes,Yes,Yes
17534,"\""\""\"" || Register YAML tags in the NLTK namespace with the YAML loader; by telling it || what module and class to look for. ||  || NLTK uses simple '!' tags to mark the types of objects; but the fully-qualified || \""tag:nltk.org;2011:\"" prefix is also accepted in case anyone ends up || using it. || \""\""\""",No,Yes,Yes
17535,Work around mbcs bug in distutils.,,,Yes
17537,In order for the implementation of Kneser-Ney to be more efficient; some,No,Yes,Yes
17539,XXX what should we do in Python 3?,No,Yes,Yes
17544,FIXME: is it possible to make order stable?,Yes,Yes,Yes
17545,As more languages are implemented; this is becoming more problematic.,Yes,Yes,Yes
17546,"\""Very nice work\"" (NP) <=> \""Perhaps\"" (ADVP) + \""you\"" (NP).",,,Yes
17547,"'''Various classifier implementations. Also includes basic feature extractor || methods. ||  || Example Usage: || :: ||  ||     >>> from text.blob import TextBlob ||     >>> from text.classifiers import NaiveBayesClassifier ||     >>> train = [ ||     ...     ('I love this sandwich.'; 'pos'); ||     ...     ('This is an amazing place!'; 'pos'); ||     ...     ('I feel very good about these beers.'; 'pos'); ||     ...     ('I do not like this restaurant'; 'neg'); ||     ...     ('I am tired of this stuff.'; 'neg'); ||     ...     (\""I can't deal with this\""; 'neg'); ||     ...     (\""My boss is horrible.\""; \""neg\"") ||     ... ] ||     >>> cl = NaiveBayesClassifier(train) ||     >>> cl.classify(\""I feel amazing!\"") ||     'pos' ||     >>> blob = TextBlob(\""The beer is good. But the hangover is horrible.\"") ||     >>> for s in blob.sentences: ||     ...     print(s) ||     ...     print(s.classify()) ||     ... ||     The beer is good. ||     pos ||     But the hangover is horrible. ||     neg ||  || .. versionadded:: 0.6.0 || '''",,,Yes
17548,indexes are not built explicitely; they will be built as needed.,Yes,Yes,Yes
17550,"'''Various classifier implementations. Also includes basic feature extractor || methods. ||  || Example Usage: || :: ||  ||     >>> from text.blob import TextBlob ||     >>> from text.classifiers import NaiveBayesClassifier ||     >>> train = [ ||     ...     ('I love this sandwich.'; 'pos'); ||     ...     ('This is an amazing place!'; 'pos'); ||     ...     ('I feel very good about these beers.'; 'pos'); ||     ...     ('I do not like this restaurant'; 'neg'); ||     ...     ('I am tired of this stuff.'; 'neg'); ||     ...     (\""I can't deal with this\""; 'neg'); ||     ...     (\""My boss is horrible.\""; \""neg\"") ||     ... ] ||     >>> cl = NaiveBayesClassifier(train) ||     >>> cl.classify(\""I feel amazing!\"") ||     'pos' ||     >>> blob = TextBlob(\""The beer is good. But the hangover is horrible.\""; classifier=cl) ||     >>> for s in blob.sentences: ||     ...     print(s) ||     ...     print(s.classify()) ||     ... ||     The beer is good. ||     pos ||     But the hangover is horrible. ||     neg ||  || .. versionadded:: 0.6.0 || '''",,,Yes
17552,TODO this currently ignores the setting in,,,Yes
17554,for improved performance (evade applying matrices),No,Yes,Yes
17557,TODO,Yes,Yes,Yes
17561,this had to be written rather weird because RandomState apparently,,,Yes
17562,TODO build a custom class of RandomState with __deepcopy__ function,Yes,Yes,Yes
17563,dont use order=2 (bi-quadratic) because that is apparently currently not recommended (and throws a warning),,,Yes
17564,TODO do keypoints even have to be augmented for elastic transformations?,Yes,Yes,Yes
17565,TODO this transforms keypoints to images; augments the images; then transforms,Yes,Yes,Yes
17567,TODO build a custom class of RandomState with __deepcopy__ function,Yes,Yes,Yes
17568,We instantiate a current\/global random state here once.,,,Yes
17569,TODO,Yes,Yes,Yes
17570,move image 4 to the left,No,No,Yes
17572,TODO is a propagating hook necessary? seems to be covered by activated,Yes,No,Yes
17575,TODO this can fail for some matrices; e.g. [[0; 0; 1]],Yes,Yes,Yes
17580,TODO this can fail for some matrices; e.g. [[0; 0; 1]],Yes,Yes,Yes
17585,TODO these are the same as in class Affine; make DRY,,,Yes
17586,dont use order=2 (bi-quadratic) because that is apparently currently not recommended (and throws a warning),Yes,Yes,Yes
17587,be moved around before leaving the image);,No,No,Yes
17590,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17591,TODO rename to Resize to avoid confusion with Affine's scale,,,Yes
17592,TODO this results in an error when n_segments is 0,Yes,Yes,Yes
17596,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
17597,In some images move pixels locally around (with random,,,Yes
17599,TODO this part is largely copied from generate_documentation_images; make DRY,Yes,No,Yes
17600,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17605,TODO rename to Grayscale3D and add Grayscale that keeps the image at 1D,Yes,No,Yes
17606,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17609,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17610,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17611,TODO these are the same as in class Affine; make DRY,,,Yes
17614,TODO replace these imports with iap.XYZ,Yes,Yes,Yes
17621,TODO this is mostly copy pasted from _augment_images; make dry,Yes,Yes,Yes
17626,TODO rename to Resize to avoid confusion with Affine's scale,,,Yes
17629,this hack to make them be able to overflow,Yes,Yes,Yes
17631,TODO this always aggregates the result in high resolution space;,Yes,Yes,Yes
17632,This is efficient (coordinates of all other locations in the,,,Yes
17636,TODO use this everywhere instead of manual seed + create,Yes,Yes,Yes
17640,TODO probably more efficient to initialize an array of zeros,Yes,Yes,Yes
17642,TODO why was float32 type here replaced with complex number,Yes,Yes,Yes
17643,TODO make value range more flexible,Yes,Yes,Yes
17645,TODO make value range more flexible,Yes,Yes,Yes
17646,dont use order=2 (bi-quadratic) because that is apparently currently not recommended (and throws a warning),Yes,Yes,Yes
17648,TODO for float values spread activation over several cells,Yes,Yes,Yes
17649,TODO CoarseDropout,Yes,Yes,Yes
17650,TODO SaltAndPepper,Yes,Yes,Yes
17651,TODO CoarseSaltAndPepper,Yes,No,Yes
17654,TODO Pepper,,,Yes
17655,TODO CoarsePepper,Yes,Yes,Yes
17658,TODO BilateralBlur,Yes,No,Yes
17659,TODO WithColorspace,Yes,No,Yes
17660,TODO AddToHueAndSaturation,,,Yes
17661,TODO ChangeColorspace,,,Yes
17662,TODO Grayscale,,,Yes
17664,TODO Sharpen,,,Yes
17667,TODO DirectedEdgeDetect,Yes,No,Yes
17668,TODO AffineCv2,Yes,No,Yes
17669,TODO PiecewiseAffine,,,Yes
17670,TODO PerspectiveTransform,Yes,No,Yes
17671,TODO ElasticTransformation,No,Yes,Yes
17673,TODO restore_augmented_images_dtypes_(),,,Yes
17678,TODO SomeOf,,,Yes
17679,TODO OneOf,,,Yes
17681,TODO Alpha,,,Yes
17682,TODO AlphaElementwise,Yes,Yes,Yes
17683,TODO SimplexNoiseAlpha,Yes,Yes,Yes
17684,TODO FrequencyNoiseAlpha,Yes,Yes,Yes
17688,TODO Pad,Yes,No,Yes
17690,TODO ForceSign,,,Yes
17691,TODO move this into the loop to avoid overflows,,,Yes
17692,TODO,,,Yes
17694,TODO CoarseSaltAndPepper,Yes,No,Yes
17698,TODO CoarsePepper,,,Yes
17699,TODO BilateralBlur,,,Yes
17700,TODO WithColorspace,,,Yes
17701,TODO ChangeColorspace,Yes,No,Yes
17702,TODO Convolve,,,Yes
17703,TODO Emboss,,,Yes
17704,TODO EdgeDetect,,,Yes
17705,TODO DirectedEdgeDetect,,,Yes
17706,TODO AffineCv2,Yes,No,Yes
17707,TODO PiecewiseAffine,,,Yes
17716,TODO SimplexNoiseAlpha,Yes,Yes,Yes
17719,TODO SaltAndPepper,Yes,Yes,Yes
17720,TODO CoarseSaltAndPepper,Yes,No,Yes
17723,TODO Pepper,,,Yes
17725,TODO BilateralBlur,Yes,No,Yes
17726,TODO WithColorspace,Yes,No,Yes
17727,TODO ChangeColorspace,Yes,No,Yes
17728,TODO Convolve,Yes,Yes,Yes
17730,TODO EdgeDetect,,,Yes
17731,TODO DirectedEdgeDetect,Yes,No,Yes
17732,TODO AffineCv2,Yes,No,Yes
17733,TODO PiecewiseAffine,Yes,Yes,Yes
17734,TODO PerspectiveTransform,Yes,No,Yes
17736,TODO copy_dtypes_for_restore(),Yes,No,Yes
17739,TODO clip_augmented_images(),Yes,No,Yes
17740,TODO Augmenter,Yes,Yes,Yes
17741,TODO SimplexNoiseAlpha,,,Yes
17747,TODO CoarseSalt,Yes,No,Yes
17748,TODO Pepper,Yes,Yes,Yes
17749,TODO CoarsePepper,,,Yes
17750,TODO BilateralBlur,,,Yes
17752,TODO ChangeColorspace,Yes,No,Yes
17755,TODO EdgeDetect,Yes,Yes,Yes
17756,TODO DirectedEdgeDetect,Yes,No,Yes
17760,TODO ElasticTransformation,Yes,Yes,Yes
17761,TODO copy_dtypes_for_restore(),Yes,No,Yes
17762,TODO restore_augmented_images_dtypes_(),Yes,Yes,Yes
17763,TODO restore_augmented_images_dtypes(),Yes,No,Yes
17764,TODO clip_augmented_images_(),Yes,No,Yes
17765,TODO clip_augmented_images(),,,Yes
17767,TODO SimplexNoiseAlpha,Yes,Yes,Yes
17770,which probably should be the center-point here anyways,No,No,Yes
17771,zoom in should probably be adapted to this style,,,Yes
17772,TODO,Yes,Yes,Yes
17779,FIXME this is essentially the same behaviour as Alpha; requires inclusion of (x; y),,,Yes
17784,TODO change these to class attributes,Yes,No,Yes
17786,TODO documentation,,,Yes
17788,TODO,Yes,Yes,Yes
17789,c:c+1 here; because the additional axis is needed by imresize_single_image,No,No,Yes
17793,TODO move this into the loop to avoid overflows,,,Yes
17794,TODO this can fail for some matrices; e.g. [[0; 0; 1]],Yes,Yes,Yes
17795,TODO does this work with SomeOf(); Sequential(); ... ?,Yes,Yes,Yes
17796,TODO keep this? it is afaik not used anywhere,Yes,Yes,Yes
17797,TODO make this more abstract; not just restricted to tuple\/list,Yes,Yes,Yes
17798,TODO CoarseDropout,Yes,Yes,Yes
17801,TODO Salt,,,Yes
17802,TODO CoarseSalt,,,Yes
17803,TODO Pepper,Yes,Yes,Yes
17804,TODO CoarsePepper,,,Yes
17805,TODO MedianBlur,Yes,Yes,Yes
17806,TODO AddToHueAndSaturation,Yes,Yes,Yes
17807,TODO Grayscale,,,Yes
17808,TODO Convolve,Yes,Yes,Yes
17812,TODO PiecewiseAffine,Yes,Yes,Yes
17813,TODO PerspectiveTransform,Yes,No,Yes
17817,TODO restore_augmented_images_dtypes(),,,Yes
17818,TODO clip_augmented_images_(),,,Yes
17819,TODO clip_augmented_images(),Yes,No,Yes
17820,TODO Augmenter,Yes,Yes,Yes
17821,TODO OneOf,,,Yes
17822,TODO WithChannels,Yes,Yes,Yes
17824,TODO AlphaElementwise,Yes,Yes,Yes
17826,TODO Scale,,,Yes
17827,TODO CropAndPad,,,Yes
17829,TODO,,,Yes
17831,TODO documentation,Yes,Yes,Yes
17835,TODO,,,Yes
17837,TODO area interpolation too?,,,Yes
17838,same time apparently results in a deadlock (at least in python 2).,Yes,Yes,Yes
17842,TODO these loops somehow require a `or len(loaded) < 20*nb_workers` on Travis; but not,Yes,Yes,Yes
17845,zoom in should probably be adapted to this style,,,Yes
17851,TODO rename sizes to size?,,,Yes
17852,TODO also add to_heatmap,,,Yes
17854,TODO this always returns (H;W;C); even if input ndarray was originall (H;W),Yes,No,Yes
17856,TODO area interpolation too?,Yes,Yes,Yes
17857,which is both ugly and unexpected after calling cut_out_of_image(). Here we correct for,Yes,No,Yes
17859,TODO somehow merge this with Alpha augmenter?,,,Yes
17862,TODO add option to if_not_found_coords to reuse old keypoint coords,,,Yes
17863,TODO introduce voting here among all distance values that have min\/max values,Yes,Yes,Yes
17869,points we know where to move them.,,,Yes
17870,for small alpha; should not move if below threshold,No,Yes,Yes
17871,for small alpha (at sigma 1.0); should barely move,,,Yes
17874,We draw four columns: (1) image; (2-4) heatmaps one to three drawn on top of the image.,,,Yes
17876,Draw three columns: (1) original image; (2) original image with mask on top; (3) only mask,No,No,Yes
17883,TODO LogContrast,Yes,Yes,Yes
17886,TODO SigmoidContrast,,,Yes
17887,check basic functionality with alpha=1 or 2 (deterministic) and per_chanenl on\/off (makes,No,Yes,Yes
17889,TODO for 30x30 padded to 32x32 with 15x15 this results in paddings of 1 on each side,,,Yes
17890,TODO maybe rename this to PadToMinimumSize?,Yes,Yes,Yes
17891,TODO maybe rename this to CropToMaximumSize ?,Yes,Yes,Yes
17893,image plane. Keypoints at the bottom row or right columns might be rounded,No,Yes,Yes
17895,for small alpha; should not move if below threshold,,,Yes
17896,for small alpha (at sigma 1.0); should barely move,,,Yes
17899,FIXME on 3.7 there was at least one deadlock at the if condition (under heavy CPU load),Yes,No,Yes
17901,TODO remove this? here it is image height at BoundingBox it is bounding box height,,,Yes
17904,TODO somehow merge with BoundingBox,Yes,Yes,Yes
17905,TODO add functions: simplify() (eg via shapely.ops.simplify());,,,Yes
17906,TODO mark as deprecated,Yes,No,Yes
17907,TODO rename cut_* to clip_* in BoundingBox,Yes,Yes,Yes
17910,TODO np.clip to image plane if is_fully_within_image(); similar to how it is done for bounding boxes,Yes,Yes,Yes
17911,TODO improve efficiency by only drawing in rectangle that covers poly instead of drawing in the whole image,Yes,No,Yes
17923,TODO WithColorspace,Yes,No,Yes
17924,TODO ChangeColorspace,Yes,No,Yes
17926,check basic functionality with alpha=1 or 2 (deterministic) and per_chanenl on\/off (makes,No,Yes,Yes
17928,TODO EdgeDetect,Yes,Yes,Yes
17929,TODO DirectedEdgeDetect,,,Yes
17937,TODO using dtype=np.bool is causing this to fail as it ends up being <type bool> instead of,Yes,No,Yes
17955,TODO accept lists too as images,Yes,No,Yes
17957,"\""\""\"" || Some utility functions that are only used for unittests. || Placing them in test\/ directory seems to be agains convention; so they are part of the library. ||  || \""\""\""",No,Yes,Yes
17958,FIXME on 3.7 there was at least one deadlock at the if condition (under heavy CPU load),Yes,No,Yes
17959,TODO add k sizing via float\/percentage,,,Yes
17960,TODO make value range more flexible,Yes,Yes,Yes
17961,FIXME max replacement seems to essentially never exceed 254,Yes,Yes,Yes
17962,TODO make value range more flexible,Yes,Yes,Yes
17963,TODO add vertical gradient alpha to have clouds only at skylevel\/groundlevel,Yes,Yes,Yes
17964,TODO add vertical gradient alpha to have fog only at skylevel\/groundlevel,Yes,Yes,Yes
17967,TODO this might be too simplistic for some image sizes,,,Yes
17968,TODO snowflakes are all almost 100% white; add some grayish tones and maybe color to them,,,Yes
17969,the average of the sampled values seems to be at around 0.6-0.75,No,Yes,Yes
17970,this test could have been done a bit better by simply splitting the distance maps; one per keypoint; considering,,,Yes
17972,TODO this value is 0.48026073 in python 2.7; while 0.48026952 in 3.7 -- why?,Yes,Yes,Yes
17974,TODO maybe allow 0-sized heatmaps? in that case the min() and max() must be adjusted,,,Yes
17976,TODO remove from examples and mark as deprecated,Yes,Yes,Yes
17977,TODO switch all calls to restore_dtypes_(),Yes,Yes,Yes
17981,TODO merge with Fliplr,Yes,Yes,Yes
17982,TODO allow shape as input instead of array,Yes,Yes,Yes
17984,TODO change this so that it is dynamically created per image (or once per dtype),Yes,Yes,Yes
17986,TODO change this so that it is dynamically created per image (or once per dtype),Yes,Yes,Yes
17987,TODO add crop() function too,Yes,No,Yes
17988,TODO enable ALL here like in eg Affine,Yes,No,Yes
17991,TODO simplify this loop and the ones for heatmaps; keypoints; similar to Alpha,,,Yes
17992,TODO this uses always a tuple of 3 values for cval; even if #chans != 3; works with 1d but what in other,,,Yes
17994,TODO delete this or maybe move it somewhere else,,,Yes
17996,TODO this was moved here because putting it at the top somehow lead to errors on travis; apparently,Yes,Yes,Yes
17997,TODO see above,Yes,Yes,Yes
17999,TODO switch to gate_dtypes(),Yes,No,Yes
18000,FIXME uint64 and int64 had to be temporarily deactivated due to breaking on travis; while working locally,Yes,Yes,Yes
18001,FIXME this had to be temporarily deactivated due to erroring for float16 on,,,Yes
18002,FIXME this was float128; but that seems to break on travis - outdated numpy version?,Yes,No,Yes
18005,TODO add to_gaussian_heatmaps(); from_gaussian_heatmaps(),Yes,No,Yes
18006,TODO rename to clip_*(),,,Yes
18011,TODO maybe offer the other contrast augmenters also wrapped in this; similar to CLAHE and HistogramEqualization?,Yes,Yes,Yes
18013,if the figure is too narrow; the footer may appear and make the fig suddenly wider (ugly),Yes,No,Yes
18014,TODO replace by ia.derive_random_state(),,,Yes
18016,TODO it does have a truncate argument that truncates at x standard deviations -- maybe can be used,,,Yes
18021,TODO make dry,,,Yes
18027,TODO replace by cv2.putText()?,,,Yes
18028,TODO why was this assert added here? seems to make no sense,Yes,No,Yes
18029,Example code to directly multiply images via image*sample (uint8 only) -- apparently slower than LUT,,,Yes
18030,Using this LUT approach is significantly faster than else-block code (more than 10x speedup),,,Yes
18031,and is still faster than the simpler image*sample approach without LUT (1.5-3x speedup;,No,Yes,Yes
18034,Using this LUT approach is significantly faster than the else-block code (around 3-4x speedup),No,No,Yes
18035,2x at 224x224 -- maybe dependent on installed BLAS libraries?),,,Yes
18036,TODO open to continous; similar to Add,,,Yes
18037,TODO switch to this as numpy>=1.15 is now a requirement,Yes,Yes,Yes
18039,TODO rename (a; b) to (low; high) as in numpy?,Yes,Yes,Yes
18040,TODO add method to change from uint to int here instead of assert,Yes,Yes,Yes
18041,TODO convert to same kind as samples,Yes,Yes,Yes
18045,TODO is that system dependent?,Yes,Yes,Yes
18048,code with using cache (at best maybe 10% faster for 64x64):,No,Yes,Yes
18049,TODO use blend_alpha_() here,,,Yes
18050,TODO find more beautiful way to avoid circular imports,Yes,Yes,Yes
18052,TODO convert int to random state here,,,Yes
18056,TODO somehow integrate this with ia.pad(),Yes,Yes,Yes
18057,FIXME using ((hr - 1) - yr) here seems wrong for float-based coordinates; should likely be,,,Yes
18058,transfer; set it higher for better performance.,,,Yes
18059,TODO skip this if the input is already a generator,Yes,Yes,Yes
18063,TODO rename first\/second to foreground\/background?,,,Yes
18064,TODO merge this with Alpha,Yes,Yes,Yes
18065,TODO simplify this loop and the ones for heatmaps; keypoints; similar to Alpha,Yes,Yes,Yes
18066,FIXME this is essentially the same behaviour as Alpha; requires inclusion of (x; y) coordinates to estimate,,,Yes
18070,with the aim of removing parallel lines that essentially or really overlap,,,Yes
18071,TODO there might be some risk here that the polygon is split into multiple polygons;,Yes,Yes,Yes
18072,- Removed unused functions; such as slicing and range iteration.,No,Yes,Yes
18073,Needed for sweep-line.,No,Yes,Yes
18076,Needed for sweep-line.,No,Yes,Yes
18077,Fix red violation,,,Yes
18078,TODO remove?,,,Yes
18081,better; but can probably only be computed for pairs of valid,,,Yes
18085,TODO add IoU check here,Yes,Yes,Yes
18086,copy columns 0; 1 into 2; 3 so that 2 is always the lower value,No,Yes,Yes
18087,TODO this currently can mess up the order of points - change somehow to,Yes,Yes,Yes
18090,TODO how does flipping affect the point order?,Yes,No,Yes
18091,TODO make the below functions more DRY,Yes,No,Yes
18092,TODO enable hooks for polygons,,,Yes
18094,TODO add this to other project() functions too,,,Yes
18096,for small alpha; should not move if below threshold,No,Yes,Yes
18097,for small alpha (at sigma 1.0); should barely move,No,Yes,Yes
18100,FIXME this is not completely correct as it only evaluates corner points,Yes,Yes,Yes
18101,TODO remove this? was previously only used by Polygon.clip_*(); but that,Yes,Yes,Yes
18104,Only parents would really need to be tracked here; we could,No,Yes,Yes
18106,TODO replace partially with dtypes.restore_dtypes_(),,,Yes
18112,TODO add option to if_not_found_coords to reuse old keypoint coords,Yes,Yes,Yes
18119,which is both ugly and unexpected after calling cut_out_of_image(). Here we correct for,,,Yes
18121,TODO probably more efficient to initialize an array of zeros,Yes,Yes,Yes
18122,TODO also add to_heatmap,,,Yes
18123,TODO add this to BoundingBoxesOnImage,Yes,Yes,Yes
18125,TODO remove this? here it is image height at BoundingBox it is bounding box height,,,Yes
18127,TODO improve efficiency here by copying only once,Yes,Yes,Yes
18129,TODO somehow merge with BoundingBox,,,Yes
18130,TODO add functions: simplify() (eg via shapely.ops.simplify());,Yes,No,Yes
18131,TODO this currently can mess up the order of points - change somehow to,Yes,Yes,Yes
18132,TODO add perimeter thickness,,,Yes
18134,TODO np.clip to image plane if is_fully_within_image(); similar to how it is done for bounding boxes,,,Yes
18140,TODO remove?,Yes,Yes,Yes
18141,TODO this can be done more efficiently by caching the values and,,,Yes
18142,TODO these distances are not really the best metrics here. Something,,,Yes
18143,better; but can probably only be computed for pairs of valid,No,No,Yes
18144,polygons. Maybe something based on pointwise distances;,,,Yes
18146,copy columns 0; 1 into 2; 3 so that 2 is always the lower value,,,Yes
18147,TODO get rid of this deferred import,Yes,Yes,Yes
18150,TODO add IoU check here,Yes,Yes,Yes
18151,TODO maybe allow 0-sized heatmaps? in that case the min() and max() must be adjusted,,,Yes
18154,import only when necessary (faster startup; optional dependency; less fragile -- see issue #225),Yes,Yes,Yes
18155,TODO area interpolation too?,,,Yes
18156,TODO this always returns (H;W;C); even if input ndarray was originall (H;W),,,Yes
18158,TODO improve efficiency here by building only sub-heatmaps for classes actually,Yes,Yes,Yes
18160,TODO area interpolation too?,,,Yes
18161,TODO get rid of this deferred import,Yes,Yes,Yes
18163,TODO replace partially with dtypes.restore_dtypes_(),,,Yes
18166,TODO replace partially with dtypes.restore_dtypes_(),Yes,Yes,Yes
18170,TODO time to drop completely?,,,Yes
18171,TODO call this function wherever data is clipped,,,Yes
18173,TODO get rid of this deferred import,Yes,Yes,Yes
18174,TODO also support (H;W;C) for heatmaps of len(images) == 1,,,Yes
18176,FIXME this is not completely correct as it only evaluates corner points,Yes,Yes,Yes
18178,TODO add class name if class method,,,Yes
18184,TODO only draw line on image of size BB around line; then paste into full,,,Yes
18185,TODO get rid of this deferred import,Yes,Yes,Yes
18186,TODO merge with implementation in bbs.py,,,Yes
18187,TODO merge with line BBs,Yes,No,Yes
18189,TODO integrate into keypoints,Yes,Yes,Yes
18192,merge somehow,,,Yes
18193,TODO get rid of this deferred import:,,,Yes
18195,TODO add closed=False\/True?,,,Yes
18197,TODO Add Line class and make LineString a list of Line elements,,,Yes
18198,TODO add to_distance_maps(); compute_hausdorff_distance(); intersects();,,,Yes
18202,this would probably work if drawing was subpixel-accurate,No,No,Yes
18203,FIXME this computes distance pointwise; does not have to be identical,Yes,Yes,Yes
18205,line string that starts out of image and ends within the image plane,No,Yes,Yes
18206,line string that starts within the image plane and ends outside,,,Yes
18207,TODO integrate into polygons,,,Yes
18208,TODO intergrate into polygons,,,Yes
18213,TODO make this non-approximate,,,Yes
18214,TODO change these to class attributes,Yes,No,Yes
18215,TODO change color_fg; color_bg to color_true color_false?,Yes,Yes,Yes
18216,TODO this should be placed in some other file than edges.py as it could be,,,Yes
18217,TODO see above; this should be moved to another file,Yes,Yes,Yes
18219,TODO simplify this to rss[2].randint(5; 100+1),,,Yes
18220,would currenlty be a bit more ugly; because DiscrUniform,Yes,Yes,Yes
18222,TODO add per_channel,,,Yes
18226,TODO does OpenCV have a faster avg pooling method?,,,Yes
18229,TODO add dtype support,,,Yes
18230,TODO add floats as ksize denoting fractions of image sizes,Yes,Yes,Yes
18231,TODO extend max_pool to support pad_mode and set it here,Yes,No,Yes
18233,TODO extend pool to support pad_mode and set it here,Yes,Yes,Yes
18235,TODO extend pool to support pad_mode and set it here,Yes,Yes,Yes
18240,TODO sampling (N;) from something like 10+Uniform(0; 1) will return,Yes,Yes,Yes
18245,TODO allow 3d matrices as input (not only 2D),Yes,Yes,Yes
18246,TODO deprecate and rename to AngledEdgeDetect,,,Yes
18247,"TODO rename arg \""direction\"" to \""angle\""",,,Yes
18254,TODO examples say that iaa.AdditiveGaussianNoise(scale=(0; 0.1*255)) samples,Yes,No,Yes
18256,TODO rename to AddPoissonNoise?,,,Yes
18258,TODO verify that (a; b) still leads to a p being sampled per image and not,Yes,Yes,Yes
18260,TODO invert size_p and size_percent so that larger values denote larger,Yes,Yes,Yes
18261,areas being dropped instead of the opposite way around,No,No,Yes
18262,TODO try adding per channel somehow,Yes,Yes,Yes
18265,TODO what happens if both bounds are negative; but input dtype is uint*?,Yes,Yes,Yes
18266,TODO is the copy_* function still used anywhere,Yes,Yes,Yes
18268,TODO change this after the segmap PR was merged,Yes,Yes,Yes
18269,TODO replace this everywhere in the library with change_dtypes_,Yes,Yes,Yes
18270,TODO mark as deprecated,,,Yes
18271,TODO replace by ia.normalize_random_state(),Yes,No,Yes
18273,TODO why does this function exist if it may only be called after,,,Yes
18277,TODO allow shape as input instead of array,Yes,Yes,Yes
18285,This is fairly ugly; but in cv2 there seems to be no other way to,,,Yes
18287,TODO add list as an option,Yes,Yes,Yes
18288,TODO merge this into imresize?,Yes,Yes,Yes
18289,TODO this is the same as in Dropout; make DRY,Yes,Yes,Yes
18290,TODO add list as an option,,,Yes
18291,TODO this could also be moved into its own point sampler;,Yes,Yes,Yes
18293,TODO Add jitter points sampler that moves points around,Yes,Yes,Yes
18294,TODO don't average the alpha channel for RGBA?,,,Yes
18296,TODO vectorize,Yes,No,Yes
18298,TODO verify behaviours when image height\/width is zero,,,Yes
18301,TODO this differs from _augment_heatmaps(); which is an abstractmethod,,,Yes
18302,TODO This is almost identical to coordinate based augmentation.,Yes,Yes,Yes
18303,TODO this is almost identical to heatmap aug; merge the two,Yes,Yes,Yes
18304,FIXME is int8 here correct? shouldn't these be uint8?,,,Yes
18305,TODO add args for interpolation; borderMode; borderValue,,,Yes
18307,TODO change this to always have cubic or automatic interpolation?,Yes,Yes,Yes
18308,TODO for 30x30 padded to 32x32 with 15x15 heatmaps this results in paddings of 1 on,Yes,Yes,Yes
18312,FIXME the output of the third example makes it look like per_channel isn't,Yes,No,Yes
18314,FIXME check_segmentation_maps is not used,Yes,No,Yes
18315,TODO why is padding mode and cval here called pad_mode; pad_cval but in other,,,Yes
18317,TODO reactivate this block when np 1.17 pad with mode=linear_ramp,Yes,Yes,Yes
18318,TODO limit value ranges of samples to int16\/uint16 for,,,Yes
18319,TODO add dtype gating,Yes,Yes,Yes
18320,Since 1.17 (before maybe too?); numpy.clip() turns int32,No,Yes,Yes
18321,TODO Verify this. Is rounding needed before conversion?,,,Yes
18323,TODO replace by sample_seed function,Yes,Yes,Yes
18324,TODO This used previously the same seed as the heatmaps part,Yes,No,Yes
18325,TODO add class name if class method,,,Yes
18326,TODO replace by sample_seeds function,,,Yes
18328,TODO replace by create_seed function in imgaug.random,,,Yes
18329,TODO use a single RNG with a single call here,Yes,Yes,Yes
18331,TODO decrease pool_size in SeedSequence to 2 or 1?,,,Yes
18332,TODO any way to seed the Generator object instead of creating a new one?,Yes,Yes,Yes
18334,TODO rename to inplace,Yes,Yes,Yes
18335,TODO does this advance the RNG in 1.17? It should advance it for security,Yes,Yes,Yes
18336,TODO adapt random_state -> rng,Yes,Yes,Yes
18339,TODO copy this or in augmenter? otherwise determinism might not work,Yes,Yes,Yes
18342,TODO would copy_unless_global_rng() here and below enough?,Yes,No,Yes
18343,TODO would copy_unless_global_rng() here be enough?,Yes,No,Yes
18347,TODO rename to SUPPORTS_* or IS_SUPPORTING_*,,,Yes
18349,TODO rename _rng functions to _generator,,,Yes
18351,TODO add support for Generator's 'axis' argument,Yes,No,Yes
18353,TODO rename to supports_* or is_supporting_*,Yes,Yes,Yes
18354,TODO replace seed by constant,Yes,Yes,Yes
18357,TODO need entropy here?,Yes,No,Yes
18359,TODO update augmenter docstrings,,,Yes
18361,TODO use use_state_of_() in augment_* functions,Yes,Yes,Yes
18364,TODO rename to SUPPORTS_* or IS_SUPPORTING_*,Yes,Yes,Yes
18365,TODO rename to create_pseudo_random_rng()?,Yes,Yes,Yes
18366,TODO mark as in-place,,,Yes
18367,TODO reset the cache here too?,,,Yes
18368,TODO reset the cache here; like in np117?,Yes,Yes,Yes
18370,TODO change random_state to rng or seed,Yes,Yes,Yes
18372,TODO is this the same as the project functions in augmentables?,,,Yes
18373,FIXME astype(float32) should be before \/255.0 here?,Yes,No,Yes
18375,TODO change this so that it is dynamically created per image (or,,,Yes
18377,TODO is that used by augment_batches()?,,,Yes
18378,TODO should this simply be removed?,Yes,Yes,Yes
18379,TODO why does this exist? it seems to be identical to,Yes,Yes,Yes
18380,TODO this can be simplified using imgaug.imgaug.flatten()?,Yes,Yes,Yes
18382,TODO write a custom copying routine?,,,Yes
18387,TODO change this to some atan2 stuff?,Yes,No,Yes
18388,TODO this might also be covered by augmentables.utils or,Yes,Yes,Yes
18390,TODO does that include point_b in the result?,,,Yes
18391,TODO remove _augment_heatmaps() and _augment_keypoints() here once they are,,,Yes
18392,TODO add line strings,Yes,No,Yes
18393,TODO currently deactivated; because lambda func_bounding_boxes does not,Yes,Yes,Yes
18394,FIXME usage of cval here seems incorrect; is always the same,Yes,Yes,Yes
18395,FIXME this looks like its going to fail for polygons where all corner,Yes,Yes,Yes
18396,FIXME change to >0.5 to match _augment_images(),Yes,No,Yes
18397,TODO add _augment_keypoints and other _augment funcs; as these should do,Yes,Yes,Yes
18399,TODO add vertical gradient alpha to have clouds only at skylevel\/groundlevel,Yes,Yes,Yes
18400,TODO add vertical gradient alpha to have fog only at skylevel\/groundlevel,,,Yes
18401,Somehow the deprecation warning is lost in 2.7 on travis;,,,Yes
18402,TODO no longer used anywhere. deprecate?,Yes,Yes,Yes
18403,TODO use blend_alpha here,Yes,No,Yes
18404,extraction leads to a black border; which is both ugly and,Yes,Yes,Yes
18406,TODO change name to change_value_range()?,,,Yes
18407,TODO make this a proper shallow-copy,,,Yes
18408,TODO change output to array,,,Yes
18410,TODO just np.float32(exterior) here?,Yes,No,Yes
18412,TODO add pad; similar to LineStrings,,,Yes
18413,TODO add pad_max; similar to LineStrings,Yes,Yes,Yes
18414,TODO add prevent_zero_size; similar to LineStrings,,,Yes
18429,FIXME why are these all 1.0-jitter instead of some being just,,,Yes
18430,TODO remove these loops,Yes,Yes,Yes
18435,TODO enable ALL here; like in e.g. Affine,Yes,No,Yes
18439,TODO allow grayscale input images that have three channels,,,Yes
18441,TODO mark these as deprecated,,,Yes
18448,Overall it seems to be the better approach to use all polygons,,,Yes
18455,speedup; maybe dependent on installed BLAS libraries?),No,No,Yes
18457,TODO extend this with some shape checks,,,Yes
18461,TODO verify if tile() is here really necessary,,,Yes
18464,TODO change this so that it is dynamically created per image,Yes,Yes,Yes
18466,top left -- no changes needed; just use jitter,No,Yes,Yes
18467,TODO maybe this would be easier if augment_*() accepted a list,Yes,Yes,Yes
18468,TODO clean up this file,Yes,Yes,Yes
18472,TODO check if sampled matrices are identical over channels,,,Yes
18475,TODO this is quite inefficient,Yes,Yes,Yes
18476,TODO this is quite inefficient,Yes,Yes,Yes
18477,TODO this is not the same as for,Yes,Yes,Yes
18478,FIXME this needs to incorporate the image_shape in case,Yes,Yes,Yes
18479,FIXME this needs to incorporate the image_shape in case,Yes,Yes,Yes
18484,TODO can this somehow be integrated into the CBA functions below?,Yes,Yes,Yes
18485,we get an ugly black border for 90deg rotations,No,Yes,Yes
18487,TODO same as above,,,Yes
18492,TODO maybe reverse the order of points afterwards? the flip probably,Yes,Yes,Yes
18493,TODO how does flipping affect the point order?,,,Yes
18494,TODO pointwise=True or False makes no difference here; because,,,Yes
18495,Verify that if any augmented BB ends up with x1 > x2 that the,No,No,Yes
18497,If _augment_batch() ends up calling _augment_images() and similar,,,Yes
18498,TODO make fill_from_augmented_normalized_batch inplace,Yes,Yes,Yes
18499,improve performance a bit by saving some function calls.,,,Yes
18500,TODO add to_keypoints_on_image_() and call that wherever possible,,,Yes
18501,TODO move this into the default implementation of _augment_batch(),Yes,Yes,Yes
18503,TODO When this was wrongly sampled directly as (H;W;C) no,Yes,No,Yes
18505,after flip; y1 ends up right of y2,No,No,Yes
18506,TODO this uses the same interpolation as for images for heatmaps,,,Yes
18507,TODO vectorize this part -- especially return only one instance,,,Yes
18512,TODO this was re-used from before _augment_batch() -- reoptimize,Yes,Yes,Yes
18513,of columns leads to potential RNG misalignments.,,,Yes
18515,by Nones. We can just re-use the columns before,No,Yes,Yes
18520,TODO this is very similar to the validation in change_colorspaces_().,Yes,No,Yes
18521,TODO is image[...] a view?,Yes,Yes,Yes
18526,TODO for pad_xy=0.5 this prefers padding on the left over the right,Yes,Yes,Yes
18528,TODO move this to augmenters.size,,,Yes
18529,TODO change that,Yes,No,Yes
18530,TODO change that,Yes,No,Yes
18531,aug adds a columns at the right and row at the bottom;,,,Yes
18532,"TODO rename to \""_to_reach_aspect_ratio\""? matches other methods",Yes,Yes,Yes
18534,TODO change that,Yes,No,Yes
18535,TODO this is the same as in imgaug.py; make DRY,Yes,Yes,Yes
18539,TODO dtype support is not that correct here; because this augmenter also,Yes,Yes,Yes
18540,TODO might be possible to speed this up as the HSV conversion in OpenCV,,,Yes
18547,TODO change these to class attributes,Yes,No,Yes
18548,TODO remove these loops,,,Yes
18549,"TODO remove the abs() here. it currently only allows to \""zoom-in\"";",Yes,Yes,Yes
18550,This loop could be done a little bit faster by vectorizing it.,Yes,Yes,Yes
18551,FIXME this uses _check_value_range; which checks for a<=x<=b; but a produced,,,Yes
18552,TODO dtype support is not that correct here; because this augmenter also,Yes,Yes,Yes
18553,TODO might be possible to speed this up as the HSV conversion in OpenCV,,,Yes
18554,TODO still a lot of overlap in this method and the one of,Yes,Yes,Yes
18559,TODO dtype support is not that correct here; because this augmenter also,,,Yes
18560,TODO still a lot of overlap in this method and the one of,Yes,Yes,Yes
18563,TODO still a lot of overlap in this method and the one of,Yes,Yes,Yes
18565,This loop could be done a little bit faster by vectorizing it.,Yes,Yes,Yes
18568,TODO the validation of gradients currently doesn't work well,,,Yes
18572,TODO make Affine more efficient for translation-only transformations,,,Yes
18574,TODO get rid of this deferred import,Yes,Yes,Yes
18578,This loop could be done a little bit faster by vectorizing it.,Yes,Yes,Yes
18579,TODO allow -1 destinations,Yes,Yes,Yes
18583,TODO add something like,,,Yes
18586,TODO added squeeze here because get_arr() falsely returns,,,Yes
18588,FIXME this uses _check_value_range; which checks for a<=x<=b; but a produced,,,Yes
18590,TODO allow -1 destinations,Yes,Yes,Yes
18592,TODO vectorize this loop,Yes,No,Yes
18597,TODO add something like,Yes,Yes,Yes
18600,TODO improve efficiency by sampling once,Yes,Yes,Yes
18601,TODO This was previously a cast of image to float64. Do the,,,Yes
18602,TODO also introduce similar area_almost_equals(),,,Yes
18606,TODO this might break the semaphore used to prevent out of memory errors,Yes,Yes,Yes
18607,TODO rename to Grid,,,Yes
18612,TODO error if non-image shapes differ from image shapes,,,Yes
18613,TODO this currently draws the background in black; hence the,,,Yes
18614,"TODO \""items anyhow out of image: %d (%.2f%%)\ || \""",Yes,No,Yes
18615,"TODO \""items fully out of image: %d (%.2f%%)\ || \""",Yes,No,Yes
18619,TODO remove this once all calls switched to _remove_out_of_image_fraction_(),Yes,Yes,Yes
18623,TODO same as above,Yes,Yes,Yes
18624,TODO move that func to iap,,,Yes
18631,TODO remove the first axis; no longer needed,Yes,Yes,Yes
18632,TODO change to a single call instead of one per channel,,,Yes
18639,TODO add optional dependency,Yes,Yes,Yes
18647,TODO this is the same as in SimplexNoise; make DRY,,,Yes
18648,SegmentationMapsOnImage and that's probably better that way,No,No,Yes
18653,TODO some of the augmenters in this module broke on numpy arrays as,Yes,Yes,Yes
18654,TODO some of the augmenters in this module broke on numpy arrays as,,,Yes
18657,TODO why was this done with image flips instead of kernel flips?,,,Yes
18658,TODO this is quite inefficient,Yes,Yes,Yes
18660,TODO reduce this to 3x3,,,Yes
18662,TODO incorporate this dtype support in the dtype sections of docstrings for,Yes,No,Yes
18663,dst does not seem to improve performance here,No,Yes,Yes
18664,TODO this is a fairly low threshold; why is that the case?,,,Yes
18665,are not wrapped in prefetchers; which could lead to ugly scenarios,,,Yes
18666,TODO is this the same as the project functions in augmentables?,Yes,Yes,Yes
18667,apparently on some systems there are small differences in what,No,No,Yes
18669,go outside of the shape's area for some reason. XXX,No,No,Yes
18671,XXX: Could be completely declarative.,,,Yes
18674,needed for py3+qt4,,,Yes
18675,XXX: awful,,,Yes
18676,needed for py3+qt4,No,No,Yes
18677,XXX: awful,Yes,Yes,Yes
18678,TODO: put package requirements here,,,Yes
18681,needed for py3+qt4,,,Yes
18682,where 0 = move left,No,Yes,Yes
18683,1 = move right,No,Yes,Yes
18684,# Fix the compatible issue for qt4 and qt5. Convert the QStringList to python list,,,Yes
18688,Check the file name ends with txt,No,No,Yes
18689,Check the file name ends with xml,,,Yes
18691,TODO: Scale,Yes,Yes,Yes
18692,TODO: support padding types,Yes,No,Yes
18693,TODO: InstanceNorm,Yes,No,Yes
18695,TODO: useInstanceNorm,,,Yes
18696,TODO: if img is a 3d tensor; then unstack it into a list of images,Yes,Yes,Yes
18699,"\""\""\""Dataset class template ||  || This module provides a templete for users to implement custom datasets. || \""\""\""",No,Yes,Yes
18700,disable data shuffling; comment this line if results on randomly chosen images are needed.,No,Yes,Yes
18701,no flip; comment this line if results on flipped images are needed.,,,Yes
18703,TODO optimize with a one step detection for both images,,,Yes
18709,TODO Pass as argument,Yes,Yes,Yes
18710,TODO how to catch a specific key instead of Enter?,Yes,Yes,Yes
18712,TODO load is done in __init__ => look how to swap if possible,Yes,Yes,Yes
18715,TODO load is done in __init__ => look how to swap if possible,,,Yes
18720,unused,,,Yes
18721,"TODO suppress tensorflow deprecation warnings \""\""\""",Yes,Yes,Yes
18722,TODO: This switch between 64 and 128 is a hack for now.,Yes,Yes,Yes
18724,TODO: how to catch a specific key instead of Enter?,,,Yes
18725,TODO: Find a way to interrupt input() if the target iterations are reached.,Yes,Yes,Yes
18726,workaround for TqdmSynchronisationWarning,Yes,Yes,Yes
18728,unused,,,Yes
18731,TODO: fix file handlers for effmpeg in gui (changes what needs to be opened),,,Yes
18734,TODO select and use device with most available VRAM,,,Yes
18735,TODO create virtual devices\/allow multiple GPUs for,Yes,Yes,Yes
18736,TODO Implement this to select the device with most available VRAM,Yes,No,Yes
18738,using the CPU. Maybe look to implement further checks on,,,Yes
18739,TODO: integrate preview into gui window,Yes,Yes,Yes
18741,to hack around div by zero error,,,Yes
18745,move back to the correct scale,No,Yes,Yes
18746,move back to the correct location,,,Yes
18748,TODO investigate why this is and fix if possible,Yes,No,Yes
18749,NB: There appears to be a bug somewhere that re-inserts the first item (after,Yes,Yes,Yes
18750,TODO Fix the bug that breaks GUI if timeshift isn't the last option in it's group,Yes,Yes,Yes
18751,Hacky fix to stop multiprocessing spawning managers in child processes,,,Yes
18752,implement logging unless you can handle the conflicts,Yes,No,Yes
18753,TODO merge alignments,Yes,No,Yes
18754,TODO Roll this into ICNR_init when porting GAN 2.2,Yes,No,Yes
18756,TODO Make sure this replacement is correct,Yes,No,Yes
18757,TODO Remove this,,,Yes
18758,Workaround by simply removing it.,,,Yes
18760,TODO Look to re-instate clipnorm,Yes,Yes,Yes
18761,TODO copies aren't likey neccesary and will slow calc... used when isolating issues,Yes,Yes,Yes
18762,better error handling of special cases,Yes,No,Yes
18763,TODO find a fix for this,,,Yes
18764,TODO: use \/ impl other padding method,,,Yes
18765,TODO A more reliable way of getting the windows location,,,Yes
18766,TODO A more reliable way of getting the windows location,Yes,Yes,Yes
18767,TODO investigate why this is and fix if possible,Yes,No,Yes
18768,TODO: Replace with GPU bound keras-vgg-face,Yes,Yes,Yes
18769,TODO Expand out for cli options,,,Yes
18770,it is not needed there.,,,Yes
18771,TODO: use \/ impl other padding method when required,Yes,Yes,Yes
18773,Hacky fix to import it inside the process,Yes,Yes,Yes
18774,Naming convention inherited from Keras so ignore invalid names,Yes,Yes,Yes
18775,TODO Actually handle this properly. The following error is inconsistently output:,Yes,No,Yes
18777,currently unused,,,Yes
18780,TODO Fix preview or remove,Yes,Yes,Yes
18781,TODO Expand out for cli options,,,Yes
18783,Only pack visible columns,,,Yes
18784,TODO: retry,Yes,No,Yes
18786,TODO Run with warnings mode,Yes,Yes,Yes
18788,TODO Batching,Yes,No,Yes
18789,TODO Implement batch support,,,Yes
18790,TODO: do this nicer,Yes,No,Yes
18791,TODO remove excessive reshapes and flattens,Yes,No,Yes
18792,TODO Move these args to config and remove these deprecation warnings,Yes,Yes,Yes
18794,Random Warp # TODO change masks to have a input mask and a warped target mask,,,Yes
18796,TODO Convert landmarks_xy to numpy arrays,Yes,Yes,Yes
18800,TODO second pass .. convert to matrix,Yes,Yes,Yes
18802,Should not be needed,,,Yes
18805,Random Warp # TODO change masks to have a input mask and a warped target mask,Yes,Yes,Yes
18806,TODO - Remove the fix job after a period of time. Implemented 2019\/12\/07,Yes,No,Yes
18808,TODO This should be set in init,Yes,Yes,Yes
18809,self.columns = min(columns; self.max_columns),,,Yes
18813,Annoying explicit hack to get around our custom version of nvidia-ml=py3 being,Yes,Yes,Yes
18814,TODO This needs to be centralized. Just a hacky fix to read the allow growth config,,,Yes
18818,TODO Tensorflow appears to pass in a :class:`tensorflow.python.framework.dtypes.DType`,,,Yes
18819,TODO simplify to use MSE instead,,,Yes
18821,TODO simplify to use MSE instead,,,Yes
18822,TODO Remove lazy transpose and change points from predict to use the correct,,,Yes
18825,TODO Use output names if\/when these are fixed upstream,,,Yes
18828,TODO Face mask generation from landmarks,,,Yes
18829,TODO Handle as array not loop,,,Yes
18833,TODO This is not a robust enough check if we have more than 1 tf version,,,Yes
18836,TODO formalize,Yes,Yes,Yes
18839,TODO This should be set in init,,,Yes
18844,interpolate and rename columns to make compatible with other code,No,Yes,Yes
18845,add renamed columns to match 1D expectations,,,Yes
18846,Drop unused fields and simplify field names,Yes,Yes,Yes
18849,First verify that the required and optional columns in the dataframe,No,Yes,Yes
18850,Select runids is needed + Order per time per runid group + correct time = Increment by previous runid,No,No,Yes
18851,############## Needed ?,,,Yes
18854,Verify that the required and optional columns in the dataframe,No,Yes,Yes
18857,Verify the required and optional columns; Drop unused fields and standardise field names.,,,Yes
18858,Verify the presence of the columns required for pycoQC,No,Yes,Yes
18859,Private import as this is only needed if using jupyter,No,Yes,Yes
18860,Verify that the required and optional columns; Drop unused fields and standardise field names.,No,Yes,Yes
18862,Private import as this is only needed if using jupyter,,,Yes
18863,Verify the presence of the columns required for pycoQC,,,Yes
18864,Verify the required and optional columns; Drop unused fields,No,Yes,Yes
18865,Verify the presence of the columns required for pycoQC,,,Yes
18866,Configurable constructor,No,Yes,Yes
18867,more efficient implementation?,Yes,Yes,Yes
18869,TODO add custom initalizer to chainer.links.CRF1d,,,Yes
18870,before the columns; that's why we interchange.,No,Yes,Yes
18871,TODO: upgrade pytorch and use broadcasting,,,Yes
18872,TODO: punctuation?,,,Yes
18873,TODO: punctuation?,Yes,No,Yes
18875,TODO: punctuation?,,,Yes
18876,TODO set a default layer,Yes,Yes,Yes
18878,TODO: upgrade pytorch and use broadcasting,,,Yes
18879,TODO getting extraction layer from quest_inject_index; lay is unused,Yes,Yes,Yes
18880,TODO here: add custom collect function,Yes,Yes,Yes
18881,TODO: find a better solution for general lr scheduling policies,Yes,Yes,Yes
18884,TODO: find a better solution for general lr scheduling policies,Yes,Yes,Yes
18885,TODO. flush every flush_secs; not every time.,,,Yes
18886,Must make it valid somehow; but don't want to remove stuff,,,Yes
18888,The circular doubly linked list starts and ends with a sentinel element.,,,Yes
18893,This code is separated-out because it is needed,,,Yes
18895,The circular doubly linked list starts and ends with a sentinel element.,,,Yes
18898,XXX should this accept an arbitrary sequence?,,,Yes
18900,"\""\""\""Helper to provide extensibility for pickle. ||  || This is only useful to add pickle support for extension types defined in || C; not for instances of user-defined classes. || \""\""\""",No,Yes,Yes
18901,"\""\""\"" Generic Python Character Mapping Codec. ||  ||     Use this codec directly rather than through the automatic ||     conversion mechanisms supplied by unicode() and .encode(). ||  ||  || Written by Marc-Andre Lemburg (mal@lemburg.com). ||  || (c) Copyright CNRI; All Rights Reserved. NO WARRANTY. ||  || \""\""\""",,,Yes
18902,It doesn't say this; but apparently; it should be ASCII now,,,Yes
18903,XXX obviously wrong; see #3232,Yes,Yes,Yes
18904,Workaround for broken uuencoders by \/Fredrik Lundh,Yes,No,Yes
18906,TODO: replace the frame hack if a blessed way to know the calling,Yes,No,Yes
18908,XXX does it need to be *exactly* dict?,,,Yes
18910,then using _siftdown to move the oddball originally at index pos into place.,,,Yes
18913,The total compares needed by list.sort() on the same lists were 8627;,,,Yes
18914,heappop() compares):  list.sort() is (unsurprisingly!) more efficient,No,Yes,Yes
18915,Move the smaller child up.,,,Yes
18916,Move the larger child up.,,,Yes
18917,"\""\""\""This module provides the components needed to build your own __import__ || function.  Undocumented functions are obsolete. ||  || In most cases it is preferred you consider using the importlib module's || functionality over this module. ||  || \""\""\""",,,Yes
18919,Directly load built-in modules needed during bootstrap.,No,Yes,Yes
18920,Directly load the _thread module (needed during bootstrap).,No,No,Yes
18921,Directly load the _weakref module (needed during bootstrap).,No,No,Yes
18922,Python 2.5b3: 62101 (fix wrong code: for x; in ...),Yes,Yes,Yes
18924,Python 2.5c2: 62131 (fix wrong code: for x; in ... in listcomp\/genexp),Yes,Yes,Yes
18925,Python 3.5b2  3340 (fix dictionary display evaluation order #11205),,,Yes
18927,_setup() adds .pyw as needed.,,,Yes
18929,valid.  However; we don't have a good way of testing since an,No,Yes,Yes
18930,Create needed directories.,,,Yes
18932,Directly load built-in modules needed during bootstrap.,No,Yes,Yes
18935,Directly load the _weakref module (needed during bootstrap).,,,Yes
18936,Directly load the winreg module (needed during bootstrap).,No,No,Yes
18937,newline convention.,,,Yes
18938,Yuck:  LC_MESSAGES is non-standard:  can't tell whether it exists before,Yes,No,Yes
18940,language name is needed to interpret the given encoding alias,No,Yes,Yes
18946,XXX Should we support P_DETACH?  I suppose it could fork()**2,Yes,No,Yes
18947,At the moment; Windows doesn't implement spawnvp[e];,,,Yes
18950,"\""\""\""Random variable generators. ||  ||     integers ||     -------- ||            uniform within range ||  ||     sequences ||     --------- ||            pick random element ||            pick random sample ||            pick weighted random sample ||            generate random permutation ||  ||     distributions on the real line: ||     ------------------------------ ||            uniform ||            triangular ||            normal (Gaussian) ||            lognormal ||            negative exponential ||            gamma ||            beta ||            pareto ||            Weibull ||  ||     distributions on the circle (angles 0 to 2pi) ||     --------------------------------------------- ||            circular uniform ||            von Mises ||  || General notes on the underlying Mersenne Twister core generator: ||  || * The period is 2**19937-1. || * It is one of the most extensively tested generators in existence. || * The random() method is implemented in C; executes in a single Python step; ||   and is; therefore; threadsafe. ||  || \""\""\""",,,Yes
18952,population; then tracking selections is efficient; requiring,No,Yes,Yes
18953,move non-selected item into vacancy,No,Yes,Yes
18956,Jain; pg. 499; bug fix courtesy Bill Arms,No,Yes,Yes
18958,"\""\""\""Utility functions for copying and archiving files and directory trees. ||  || XXX The functions here don't copy the resource fork or other metadata on Mac. ||  || \""\""\""",,,Yes
18959,XXX What about other special files? (sockets; devices...),,,Yes
18960,* fchownat() doesn't implement AT_SYMLINK_NOFOLLOW.,,,Yes
18963,XXX This should not be part of site.py; since it is needed even when,Yes,Yes,Yes
18966,XXX: show string offset and offending character for all errors,No,Yes,Yes
18967,move it out of the branch,Yes,Yes,Yes
18969,XXX: <fl> should add charmap optimization here,Yes,Yes,Yes
18970,The old GNU sparse format occupies some of the unused,,,Yes
18971,TarFile class. The open() method is the only one that is needed for,No,Yes,Yes
18972,Not needed,No,No,Yes
18975,This variable _was_ unused for legacy reasons; see issue 10354.,,,Yes
18977,the file (probably stderr) is invalid - this warning gets lost.,,,Yes
18979,"Naming convention: Variables named \""wr\"" are weak reference objects;",,,Yes
18987,The idea of this script is to test how much money we would have made or lost,No,Yes,Yes
18988,TODO,Yes,Yes,Yes
18992,somehow tfgan.eval.classifier_score does not work properly when splitting the datasets.,Yes,No,Yes
18993,save image if needed,No,No,Yes
18996,save image if needed,,,Yes
18997,shuffle the columns of z_batch,,,Yes
19001,move networsk to gpu,No,Yes,Yes
19002,TODO(xcyan): implement blending,,,Yes
19005,(2) Blank lines between documents. Document boundaries are needed so,No,Yes,Yes
19006,The convention in BERT is:,No,No,Yes
19007,"We \""pool\"" the model by simply taking the hidden state corresponding",No,Yes,Yes
19009,The convention in BERT is:,,,Yes
19010,"What we really want to return is \""Steve Smith\"".",No,No,Yes
19011,The convention in BERT is:,No,No,Yes
19012,The convention in BERT is:,No,No,Yes
19013,Consistent Move Times,,,Yes
19015,centis spent playing move,,,Yes
19016,Moves where the played move is not in top 5,No,Yes,Yes
19018,1 = only one top move; 5 = all moves good,,,Yes
19019,move = move number,No,Yes,Yes
19020,join rank and move embeddings with move info,No,No,Yes
19022,join rank and move embeddings with move info,,,Yes
19023,merge move stats with move options,,,Yes
19024,join rank and move embeddings with move info,,,Yes
19025,merge move stats with move options,No,Yes,Yes
19026,isolated consideration of move blocks,No,Yes,Yes
19027,elapsed move time,,,Yes
19028,elapsed move time \/ average,,,Yes
19032,TODO: was 200,Yes,No,Yes
19033,unused_port(),,,Yes
19036,unused_port(),,,Yes
19037,"\""\""\""This module contains WebServer class ||     TODO || \""\""\""",Yes,Yes,Yes
19038,TODO move to specific module,Yes,Yes,Yes
19041,Let users know if they're missing any of our hard dependencies,,,Yes
19042,"\""\""\""This module contains WebServer class ||     TODO DOC || \""\""\""",Yes,Yes,Yes
19043,TODO This case requires support on client side.,,,Yes
19044,super naive way,Yes,Yes,Yes
19045,TODO this and the line above it are likely to break,,,Yes
19047,TODO how to do this bilinear product ?!?!?!,Yes,No,Yes
19048,TODO,,,Yes
19051,TODO,,,Yes
19054,''' || Created on Sep; 2018 ||  || @author: hugo ||  || ''',,,Yes
19055,''' || Created on Sep; 2017 ||  || @author: hugo ||  || ''',,,Yes
19056,''' || Created on Sep; 2017 ||  || @author: hugo ||  || ''',,,Yes
19057,''' || Created on Sep; 2017 ||  || @author: hugo ||  || ''',No,Yes,Yes
19060,''' || Created on Sep; 2017 ||  || @author: hugo ||  || ''',,,Yes
19063,TODO: Write simplification algotherm,,,Yes
19064,don't really want to troubleshoot why; so here's a workaround,Yes,Yes,Yes
19067,additional frames needed depending on sequence length,,,Yes
19071,somehow this expression is buggy; so we must do it manually,Yes,Yes,Yes
19072,somehow this expression is buggy; so we must do it manually,Yes,Yes,Yes
19074,additional frames needed depending on sequence length,No,Yes,Yes
19078,additional frames needed depending on sequence length,,,Yes
19081,reshape data into 3D array (columns; rows; channels),,,Yes
19083,todo: how many block?,Yes,No,Yes
19084,todo: how many block?,No,No,Yes
19086,TODO: add custom,Yes,Yes,Yes
19087,TODO check whether using the cpu type,Yes,Yes,Yes
19090,Remember the action tensor. name is needed when restoring the graph,,,Yes
19091,QUESTION: Should this be a variable or a placeholder? Maybe a variable???,,,Yes
19093,self.summary. This is a hacky workaround in order to support OffPolicyAgent,Yes,Yes,Yes
19095,# (TODO): Restore BLR variables,Yes,Yes,Yes
19098,Clear previous data if needed,No,Yes,Yes
19099,var ends up being diag(sigma**2 + matmul(matmul(X; w_Sigma); X.T)),,,Yes
19101,Compute the IDS action - ugly way,,,Yes
19103,Compute the IDS action - ugly way,,,Yes
19105,Compute the IDS action - ugly way,,,Yes
19107,"TODO: Allow for reading histograms and for tags starting with \""debug\""",Yes,Yes,Yes
19108,TODO:,Yes,No,Yes
19117,TODO: Fix this after super() is removed everywhere,,,Yes
19118,TODO: Uncomment these after super() is removed everywhere,,,Yes
19120,TODO: Add TB here,,,Yes
19121,TODO: Remove this - currently used in Agent log_stats,Yes,No,Yes
19122,TODO: Add TB here,Yes,No,Yes
19123,TODO: Remove this - currently used in Agent log_stats,Yes,No,Yes
19124,Store the value function for the next state. Needed to compute GAE(lambda),,,Yes
19125,TODO: Assert pi_grad is not too close to 0,Yes,No,Yes
19126,todo lose data get all data,,,Yes
19132,Needed to generate model_preds if they don't exist yet,No,Yes,Yes
19134,Needed to generate model_preds if they don't exist yet,No,Yes,Yes
19136,File format: text files; each line is an image record containing 6 columns; delimited by TAB.,No,No,Yes
19137,Moving averages ends up in the trainable variables collection,No,No,Yes
19138,Moving averages ends up in the trainable variables collection,No,No,Yes
19139,Moving averages ends up in the trainable variables collection,,,Yes
19140,Moving averages ends up in the trainable variables collection,,,Yes
19141,the columns contain the following information,,,Yes
19142,Moving averages ends up in the trainable variables collection,,,Yes
19146,Extract subsequence if needed,,,Yes
19147,Load last model if needed,No,No,Yes
19151,TODO,Yes,Yes,Yes
19152,TODO: Would be slightly faster if we called step on the entire,,,Yes
19156,TODO - save results to json as well; to be able to re-plot,Yes,Yes,Yes
19160,TODO,,,Yes
19162,TODO sparse_softmax_cross_entropy_with_logits,Yes,Yes,Yes
19164,TODO check that memory usage is ok,Yes,No,Yes
19169,FIXME this takes forever,,,Yes
19170,TODO consider updating IndexedSlices right away,Yes,Yes,Yes
19171,TODO device?,,,Yes
19176,TODO,Yes,Yes,Yes
19178,TODO how will this work with multi-GPU?,Yes,Yes,Yes
19180,TODO,,,Yes
19181,reorder columns to match the UI,,,Yes
19182,FIXME don't we need non_continuation_log_p here as well?,,,Yes
19187,TODO: use keras backend instead of tf.,Yes,No,Yes
19189,TODO # We assume that there is no distinction between male\/female here,Yes,No,Yes
19190,TODO  hardcoded for now,Yes,Yes,Yes
19193,TODO proper filename,,,Yes
19194,Creating unsupervised batch generator if needed,,,Yes
19195,Sadly; this one cannot split if we want to capture author abbreviations,No,Yes,Yes
19196,content of this field will be analyzed by dictionary matchers but not indexed (setup in preconfigured Solr schema for better performance),No,Yes,Yes
19200,"\""\""\""def _bottleneck_block_v1(inputs; filters; training; projection_shortcut; ||                          strides; data_format): ||   A single block for ResNet v1; with a bottleneck. ||   Similar to _building_block_v1(); except using the \""bottleneck\"" blocks ||   described in: ||     Convolution then batch normalization then ReLU as described by: ||       Deep Residual Learning for Image Recognition ||       https:\/\/arxiv.org\/pdf\/1512.03385.pdf ||       by Kaiming He; Xiangyu Zhang; Shaoqing Ren; and Jian Sun; Dec 2015. ||   Args: ||     inputs: A tensor of size [batch; channels; height_in; width_in] or ||       [batch; height_in; width_in; channels] depending on data_format. ||     filters: The number of filters for the convolutions. ||     training: A Boolean for whether the model is in training or inference ||       mode. Needed for batch normalization. ||     projection_shortcut: The function to use for projection shortcuts ||       (typically a 1x1 convolution when downsampling the input). ||     strides: The block's stride. If greater than 1; this block will ultimately ||       downsample the input. ||     data_format: The input format ('channels_last' or 'channels_first'). ||   Returns: ||     The output tensor of the block; shape should match inputs. ||    ||   shortcut = inputs ||  ||   if projection_shortcut is not None: ||     shortcut = projection_shortcut(inputs) ||     shortcut = batch_norm(inputs=shortcut; training=training; ||                           data_format=data_format) ||  ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=filters; kernel_size=1; strides=1; ||       data_format=data_format) ||   inputs = batch_norm(inputs; training; data_format) ||   inputs = tf.nn.relu(inputs) ||  ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=filters; kernel_size=3; strides=strides; ||       data_format=data_format) ||   inputs = batch_norm(inputs; training; data_format) ||   inputs = tf.nn.relu(inputs) ||  ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=4 * filters; kernel_size=1; strides=1; ||       data_format=data_format) ||   inputs = batch_norm(inputs; training; data_format) ||   inputs += shortcut ||   inputs = tf.nn.relu(inputs) ||  ||   return inputs ||  ||  || def _bottleneck_block_v2(inputs; filters; training; projection_shortcut; ||                          strides; data_format): ||   A single block for ResNet v2; with a bottleneck. ||   Similar to _building_block_v2(); except using the \""bottleneck\"" blocks ||   described in: ||     Convolution then batch normalization then ReLU as described by: ||       Deep Residual Learning for Image Recognition ||       https:\/\/arxiv.org\/pdf\/1512.03385.pdf ||       by Kaiming He; Xiangyu Zhang; Shaoqing Ren; and Jian Sun; Dec 2015. ||   Adapted to the ordering conventions of: ||     Batch normalization then ReLu then convolution as described by: ||       Identity Mappings in Deep Residual Networks ||       https:\/\/arxiv.org\/pdf\/1603.05027.pdf ||       by Kaiming He; Xiangyu Zhang; Shaoqing Ren; and Jian Sun; Jul 2016. ||   Args: ||     inputs: A tensor of size [batch; channels; height_in; width_in] or ||       [batch; height_in; width_in; channels] depending on data_format. ||     filters: The number of filters for the convolutions. ||     training: A Boolean for whether the model is in training or inference ||       mode. Needed for batch normalization. ||     projection_shortcut: The function to use for projection shortcuts ||       (typically a 1x1 convolution when downsampling the input). ||     strides: The block's stride. If greater than 1; this block will ultimately ||       downsample the input. ||     data_format: The input format ('channels_last' or 'channels_first'). ||   Returns: ||     The output tensor of the block; shape should match inputs. ||    ||   shortcut = inputs ||   inputs = batch_norm(inputs; training; data_format) ||   inputs = tf.nn.relu(inputs) ||  ||   # The projection shortcut should come after the first batch norm and ReLU ||   # since it performs a 1x1 convolution. ||   if projection_shortcut is not None: ||     shortcut = projection_shortcut(inputs) ||  ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=filters; kernel_size=1; strides=1; ||       data_format=data_format) ||  ||   inputs = batch_norm(inputs; training; data_format) ||   inputs = tf.nn.relu(inputs) ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=filters; kernel_size=3; strides=strides; ||       data_format=data_format) ||  ||   inputs = batch_norm(inputs; training; data_format) ||   inputs = tf.nn.relu(inputs) ||   inputs = conv2d_fixed_padding( ||       inputs=inputs; filters=4 * filters; kernel_size=1; strides=1; ||       data_format=data_format) ||  ||   return inputs + shortcut\""\""\""",No,Yes,Yes
19204,Created in SparseApply if needed.,No,Yes,Yes
19205,Created in SparseApply if needed.,No,Yes,Yes
19206,Created in SparseApply if needed.,,,Yes
19208,These are the weights that inform how much each feature contributes to,,,Yes
19210,default values; in case of empty columns,No,Yes,Yes
19211,default values; in case of empty columns,No,Yes,Yes
19212,default values; in case of empty columns,No,Yes,Yes
19213,Get the columns from the decoded CSV file,,,Yes
19215,todo Get the prediction accuracy,,,Yes
19219,TODO: There is a bug which enforces the sample num to be the bath size.,,,Yes
19220,TODO: There is a bug which enforces the sample num to be the bath size.,,,Yes
19221,TODO: Solve bug with the generator which generates unmatched images.,,,Yes
19224,"\""\""\""Contains convenience wrappers for various Neural Network TensorFlow losses. ||  ||   All the losses defined here add themselves to the LOSSES_COLLECTION ||   collection. ||  ||   l1_loss: Define a L1 Loss; useful for regularization; i.e. lasso. ||   l2_loss: Define a L2 Loss; useful for regularization; i.e. weight decay. ||   cross_entropy_loss: Define a cross entropy loss using ||     softmax_cross_entropy_with_logits. Useful for classification. || \""\""\""",,,Yes
19226,Label 0 is reserved for an (unused) background class.,,,Yes
19227,Label 0 is reserved for an (unused) background class.,No,No,Yes
19228,Label 0 is reserved for an (unused) background class.,,,Yes
19229,(used in GAN training). This is needed for a correct evaluation of the Inception\/FID score.,No,No,Yes
19230,(used in GAN training). This is needed for a correct evaluation of the Inception\/FID score.,,,Yes
19231,uncomment the following line to fix the random seed,No,Yes,Yes
19232,tgt_len -- unused,Yes,Yes,Yes
19233,metric: larger is better,,,Yes
19234,tgt_len -- unused,Yes,Yes,Yes
19236,BTO 2012-06: everyone thinks the daringfireball regex should be better; but they're wrong.,No,Yes,Yes
19237,TODO: remove obscure country domains?,Yes,No,Yes
19238,TODO should try a big precompiled lexicon from Wikipedia; Dan Ramage told me (BTO) he does this,Yes,Yes,Yes
19239,between this and the Java version. One little hack won't hurt...,Yes,Yes,Yes
19240,I remember it causing lots of trouble in the past as well.  Would be good to revisit or eliminate.,Yes,Yes,Yes
19241,nn.Dropout();  # remove `Dropout` for better performance,Yes,Yes,Yes
19242,nn.Dropout()  # remove `Dropout` for better performance,,,Yes
19243,TODO: update,,,Yes
19244,TODO: update,Yes,No,Yes
19245,TODO: modiify for batch,Yes,No,Yes
19247,TODO:,Yes,No,Yes
19248,TODO: run periodically,Yes,Yes,Yes
19249,TODO: parse output to print only moved files,Yes,No,Yes
19250,TODO: add verbose mode that prints all configs and dry-run mode to check the configs and permissions,Yes,No,Yes
19251,TODO: get current user name,Yes,Yes,Yes
19252,TODO: ssh part,,,Yes
19253,Install extra python packages; if needed,,,Yes
19255,TODO: print fleet and instance statistics,Yes,No,Yes
19256,TODO: check the response to make sure request was canceled,Yes,No,Yes
19257,TODO: consider importing and executing custom fab tasks instead,,,Yes
19259,TODO: add silent mode,,,Yes
19260,TODO: add option for user-defined tags,Yes,Yes,Yes
19265,-- Options for todo extension ----------------------------------------------,No,Yes,Yes
19266,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
19267,TODO: consider importing and executing custom fab tasks instead,Yes,No,Yes
19269,TODO: print fleet and instance statistics,Yes,No,Yes
19272,Install extra python packages; if needed,No,Yes,Yes
19273,If needed; disable strict known-hosts check,,,Yes
19274,TODO: implement,Yes,Yes,Yes
19276,\t\t# TODO: get volumes,,,Yes
19277,TODO: print volumes' details,,,Yes
19279,TODO: handle locked \/var\/lib\/dpkg\/lock,,,Yes
19281,TODO: we could get VERY fancy here by eg generating a tempfile from any,Yes,Yes,Yes
19282,TODO: would definitely be nice for Connection\/FabricConfig to expose an,,,Yes
19283,TODO: richer host object exposing stuff like .address_is_ipv6 or whatever,Yes,Yes,Yes
19286,This import is needed so that pickle knows about the class Ex2Job.,,,Yes
19290,create parameter instance that is needed for any batch computation engine,,,Yes
19291,This import is needed so that pickle knows about the class Ex1Job.,No,Yes,Yes
19292,create parameter instance that is needed for any batch computation engine,No,Yes,Yes
19293,You can just specify the packages manually here if your project is,,,Yes
19294,efficient. Use einsum instead. See below.,Yes,Yes,Yes
19297,If a logistic growth model is applied add the cap and floor columns to the input data frame,No,Yes,Yes
19300,Increasing the number of Fourier terms allows the seasonality to fit faster changing cycles;,No,Yes,Yes
19301,If a logistic growth model is applied add the cap and floor columns to the input data frame,No,Yes,Yes
19302,Re-create the request with ds and y columns,No,Yes,Yes
19303,If a logistic growth model is applied add the cap and floor columns to the future data frame,No,Yes,Yes
19304,Increasing the number of Fourier terms allows the seasonality to fit faster changing cycles;,No,Yes,Yes
19307,Finally we drop the lat and long columns and will only use the new column for clustering,No,Yes,Yes
19308,If hashed columns need to be scaled; these need to be considered when setting up the scaler as well,Yes,Yes,Yes
19309,Align the columns with the original dataset.,No,Yes,Yes
19310,Add the encoded columns to the result dataset,No,Yes,Yes
19312,If only hashed columns are being scaled; the scaler needs to be instantiated,No,Yes,Yes
19313,Add the hashed columns to the result dataset,No,Yes,Yes
19314,Add the scaled columns to the result dataset,No,Yes,Yes
19315,Finally join the columns that do not require preprocessing to the result dataset,,,Yes
19317,Split the features provided as a string into individual columns,No,Yes,Yes
19318,Convert columns by the corresponding data type,,,Yes
19319,Split the features provided as a string into individual columns,No,Yes,Yes
19321,We convert values to type SSE.Dual; and group columns into a iterable,,,Yes
19323,Group columns into a iterable and add to the the response_rows,,,Yes
19325,If scale_vectors = True join the count vectorized columns to the scaling dataframe,,,Yes
19327,If scale_vectors = True join the tfidf vectorized columns to the scaling dataframe,,,Yes
19329,Split the features provided as a string into individual columns,No,Yes,Yes
19330,Add a variable number of columns depending on the response,No,Yes,Yes
19331,Align the columns with the original dataset.,,,Yes
19332,Align the columns with the original dataset.,No,Yes,Yes
19334,return six columns: key; entity; start; end; type; description,No,Yes,Yes
19336,Sort the layers; drop unnecessart columns and save the model architecture to a new data frame,No,Yes,Yes
19337,Add columns from the Keras model's history,,,Yes
19338,Workaround for Keras issue #1406,Yes,No,Yes
19342,As per the Keras convention; samples should not be specified in the input shape.,No,Yes,Yes
19343,If we receive five columns; we expect both holidays and additional regressors,,,Yes
19345,An additional lag observation is needed if previous targets are being added to the features,,,Yes
19349,Split up the additional regressors into multiple columns,Yes,Yes,Yes
19352,A 4D shape may be valid for e.g. a ConvLSTM with (timesteps; rows; columns; features),No,Yes,Yes
19354,Set the number of placeholders needed in the response,No,Yes,Yes
19355,Workaround for Keras issue #1406,,,Yes
19357,Exclude columns that are not expected in the request data,,,Yes
19358,Workaround for Keras issue #1406,Yes,No,Yes
19359,If hashed columns need to be scaled; these need to be considered when setting up the scaler as well,Yes,Yes,Yes
19361,Add the encoded columns to the result dataset,,,Yes
19362,If scale_hashed = True join the hashed columns to the scaling dataframe,,,Yes
19363,If only hashed columns are being scaled; the scaler needs to be instantiated,Yes,Yes,Yes
19364,Add the hashed columns to the result dataset,,,Yes
19365,Add the scaled columns to the result dataset,No,Yes,Yes
19367,Sets the number of times a feature is randomly shuffled during the feature importance calculation,No,Yes,Yes
19368,TODO: convert constants,Yes,No,Yes
19370,manually reflect the tform to undo the reflection done on xyR,No,Yes,Yes
19371,Figure out if trans1 or trans2 is better,No,Yes,Yes
19373,"\""\""\""Implement some custom layers; not provided by TensorFlow. ||  || Trying to follow as much as possible the style\/standards used in || tf.contrib.layers || \""\""\""",No,Yes,Yes
19374,Maybe crop if needed.,,,Yes
19375,Maybe pad if needed.,,,Yes
19377,elipson used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.,Yes,Yes,Yes
19378,Improve performance by trimming to top anchors by score,,,Yes
19379,Pad if needed,,,Yes
19381,TODO: Rename target_bbox to target_deltas for clarity,Yes,No,Yes
19382,TODO: better to keep them normalized until later,,,Yes
19389,For positive anchors; compute shift and scale needed to transform them,,,Yes
19390,TODO: use box_refinement() rather than duplicating the code here,Yes,No,Yes
19392,TODO: verify that this handles zero padded ROIs,Yes,Yes,Yes
19393,TODO: clean up (use tf.identify if necessary),Yes,No,Yes
19395,Work-around for Windows: Keras fails on Windows when using,,,Yes
19398,TODO: Build and use this function to reduce code duplication,,,Yes
19399,TODO: cleaner to do zero unpadding upstream,,,Yes
19400,In the long run; it's more efficient to modify the code to support large,,,Yes
19401,TODO: Replace with matplotlib equivalent?,,,Yes
19403,# 5. TODO: add road from semantic prediction,,,Yes
19404,hack to handle LSTM,Yes,Yes,Yes
19405,FIXME: not work,Yes,Yes,Yes
19407,FIXME,Yes,Yes,Yes
19410,XXX: Maybe below as _fast_rcnn_loc_loss.,Yes,Yes,Yes
19411,FIXME,Yes,Yes,Yes
19413,FIXME: some of minival annotations are malformed.,,,Yes
19414,XXX: It seems not good; because it shifts mask coords.,Yes,Yes,Yes
19417,FIXME: sometimes raises error after chainermn.,Yes,Yes,Yes
19419,RLE is a simple yet efficient format for storing binary masks. RLE,No,Yes,Yes
19420,FIXME: cv2 should be imported first to avoid segfault.,,,Yes
19421,FIXME: not work on MPI mode.,Yes,Yes,Yes
19422,FIXME: MultiProcessIterator sometimes hangs,,,Yes
19423,XXX: see also evaluate.py,No,Yes,Yes
19424,XXX: see also evaluate.py,No,Yes,Yes
19425,XXX: see also demo.py,,,Yes
19427,pad=1 is different from original resnet but needed for mask-rcnn,,,Yes
19429,max_len = 6 #TODO,Yes,Yes,Yes
19430,[batch*t; max_adj_num; dir] TODO; maybe fixed,,,Yes
19435,TODO; implement automatic inference; maybe fixed,Yes,Yes,Yes
19436,TODO; implement automatic inference; maybe done,,,Yes
19437,max_len = 6 #TODO,,,Yes
19440,TODO,,,Yes
19441,and the code is written in 0.10 or 0.11 (I've forgotten the exact version D:) which is still in ckpt V1,No,Yes,Yes
19442,you can manually set this to control how many samples an epoch will train,,,Yes
19449,Fix the seed.,Yes,Yes,Yes
19450,"'''MobileNet in PyTorch. || See the paper \""MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\"" || for more details. || '''",No,No,Yes
19451,Little hack to cope with float precision issues when dealing with polygons:,Yes,Yes,Yes
19453,Fix the seed.,,,Yes
19454,decides if we are going to repeate some frames when needed for filling the desired,No,No,Yes
19461,TODO implement later,Yes,Yes,Yes
19464,Needed if you want histograms in Tensorboard.,No,Yes,Yes
19465,Pass move,,,Yes
19466,fix random seeds,No,Yes,Yes
19467,TODO: add the b-spline kernel here,,,Yes
19468,TODO: bug here - needs to be add dimension to grid_sample_global if needed,,,Yes
19469,importance sampling: hack - todo: use proper sampling,,,Yes
19470,todo: add conv3d_transpose for ffd approximation,,,Yes
19474,TODO Plot x-axis labels.,,,Yes
19475,TODO: Write librosa wrappers with good documentation and explanations.,,,Yes
19476,review: label needed?,,,Yes
19481,todo remove,Yes,Yes,Yes
19482,tf.summary.image('images'; image_batch; max_outputs=10)    # TODO: Summay options for audio?,Yes,No,Yes
19483,todo: Restore shape,,,Yes
19487,TODO: Write librosa wrappers with good documentation and explanations. Use this as a wrapper lib.,Yes,Yes,Yes
19491,label = label_queue       # TODO Reactivate,Yes,Yes,Yes
19492,TODO Sprase tensor,Yes,No,Yes
19493,TODO Documentation,Yes,Yes,Yes
19497,Number of samples between successive frames e.g. columns if a spectrogram.,,,Yes
19500,review: How many are there really?,,,Yes
19501,Review if (mfcc + mfcc_delta) are better features than pure mfcc.,Yes,Yes,Yes
19504,TODO: print both,,,Yes
19508,sample = np.concatenate([mfcc; mfcc_delta]; axis=0)   # TODO,,,Yes
19510,L8ER Move somewhere else?,Yes,No,Yes
19515,TODO: Document,Yes,No,Yes
19516,TODO delete me,,,Yes
19519,TODO: Convert to FLAGs where applicable.,Yes,No,Yes
19520,Number of samples between successive frames e.g. columns if a spectrogram.,No,No,Yes
19521,L8ER Move somewhere else?,,,Yes
19522,TODO: Word Error Rate (WER),Yes,No,Yes
19523,TODO Inputs should be strings; not tensors.,,,Yes
19526,TODO: Implement for evaluation.,Yes,Yes,Yes
19527,TODO Shuffle True,Yes,No,Yes
19531,TODO: Debug see #29,Yes,Yes,Yes
19532,TODO: tqdm Progressbar,Yes,No,Yes
19533,TODO: Documentation,Yes,Yes,Yes
19534,TODO Stopped here!,,,Yes
19535,TODO labels_length,,,Yes
19536,TODO: If WarpCTC works; this should be moved to the `loss` function. Saves 2 conversions.,Yes,Yes,Yes
19538,TODO WarpCTC crashes during evaluation. Awaiting fix. This is only a workaround.,,,Yes
19544,TODO: Document,Yes,No,Yes
19545,TODO Document,,,Yes
19546,TODO Document,,,Yes
19547,TODO cuDNN RNNs only support time major inputs.,Yes,No,Yes
19551,TODO Try None,Yes,Yes,Yes
19552,TODO: sequences = [],,,Yes
19553,TODO: dense1 = [],Yes,No,Yes
19554,TODO: dense2 = [],Yes,Yes,Yes
19555,TODO: rnn4 = [],Yes,Yes,Yes
19556,TODO: dense4 = [],,,Yes
19567,TODO: dense2 = [],Yes,Yes,Yes
19568,a softmax activation as needed; and therefore don't expect activated logits.,,,Yes
19571,TODO Document helper method.,Yes,Yes,Yes
19572,TODO reenable,,,Yes
19573,TODO Incomplete,,,Yes
19575,TODO,,,Yes
19576,TODO,,,Yes
19579,TODO incomplete,Yes,No,Yes
19581,TODO Verify that the created WAV files are okay!,Yes,No,Yes
19584,TODO,Yes,Yes,Yes
19586,TODO: Debug,,,Yes
19587,TODO: last,Yes,No,Yes
19589,TODO Define cache folder,Yes,Yes,Yes
19590,TODO Check if archive is cached; else download it,Yes,No,Yes
19592,TODO This should not be done in here; the individual dataset wrapper prepares the data,Yes,Yes,Yes
19595,TODO Documentation,,,Yes
19600,TODO Documentation,,,Yes
19601,TODO: https:\/\/tatoeba.org\/eng\/downloads --- Not sure what archive I used and if I downloaded additional sentence ratings.,,,Yes
19603,TODO Document,,,Yes
19605,TODO Documentation,Yes,Yes,Yes
19606,with tarfile.open(name=storage_path; mode='r') as tf:    TODO remove if other way works,Yes,No,Yes
19607,TODO Documentation,Yes,Yes,Yes
19612,TODO Acquire eval\/dev data.,Yes,Yes,Yes
19613,TODO Acquire prediction data.,Yes,Yes,Yes
19614,TODO Assemble hooks.,Yes,Yes,Yes
19618,TODO Implement,Yes,Yes,Yes
19619,TODO Document,,,Yes
19620,TODO Optional preprocessing.,,,Yes
19624,TODO Documentation,Yes,Yes,Yes
19630,TODO: REMOVE DEBUG STUFF,Yes,No,Yes
19633,TODO: Does this trigger some internal magic?,Yes,No,Yes
19635,TODO Documentation,,,Yes
19639,TODO: Debug defaults.,,,Yes
19640,TODO: Use CSV,Yes,No,Yes
19641,TODO Documentation,Yes,Yes,Yes
19644,TODO: Documentation,,,Yes
19645,TODO Documentation,Yes,Yes,Yes
19647,TODO: Documentation,Yes,Yes,Yes
19648,tf.flags.DEFINE_integer('num_threads'; cpu_count();     # TODO: `num_threads` still needed?,Yes,Yes,Yes
19650,TODO: Increase shuffle buffer size to number of elements in dataset.,,,Yes
19654,span_ends_list.append(span_end_list),No,No,Yes
19655,span_ends_list[question_id].append(span_end),No,No,Yes
19656,span_ends_list;,No,Yes,Yes
19657,"\""\""\"" || Created on Tue Sep 20 18:05:41 2016 ||  || @author: jan || \""\""\""",,,Yes
19659,code for switch is needed,,,Yes
19660,key: move as location on the board;,No,Yes,Yes
19661,save the move in states,No,No,Yes
19662,for each move in moved moves;judge if there's a 5-in-a-row in a top right diagonal,No,Yes,Yes
19663,for each move in moved moves;judge if there's a 5-in-a-row in a top left diagonal,No,Yes,Yes
19664,print('player %r move : %r'%(current_player;[move\/\/self.board.width;move%self.board.width])),,,Yes
19668,AI do move,No,No,Yes
19669,there's no idea which is better,No,Yes,Yes
19670,but i think maybe 0.8\/0.2 or even 0.9\/0.1 is better because i add noise in every node,,,Yes
19672,Greedily select next move.,No,No,Yes
19673,Greedily select next move.,No,No,Yes
19674,fix the playout times to 400,No,Yes,Yes
19675,here I move data from a dir to another in order to avoid I\/O conflict,,,Yes
19676,it's stupid and must have a better way to do it,,,Yes
19677,play with last best model and update it to collect data if current model is better,No,Yes,Yes
19678,save the new best model in numpy form for next time's comparision,No,Yes,Yes
19679,print('New best policy!'+'!'*50),No,Yes,Yes
19681,TODO: What should this do? The pixel is not known; so assume same lap?,Yes,Yes,Yes
19683,TODO: this means our environment died... need to die too,Yes,No,Yes
19684,TODO: This sometimes fails with a broken pipe because,Yes,Yes,Yes
19687,TODO: I'm sure this can\/should be more pythonic somehow,Yes,Yes,Yes
19690,TODO: Config or environment argument,Yes,No,Yes
19691,TODO: Config or environment argument,Yes,No,Yes
19693,TODO: Config or environment argument,Yes,No,Yes
19698,TODO: Config or environment argument,,,Yes
19700,TODO: Add pixel info to figure out health of agent and opponent.,,,Yes
19701,TODO: Read this from a config?,,,Yes
19702,RB- unused,,,Yes
19703,TODO: Possibly allow exiting an in-progress map?,Yes,No,Yes
19704,TODO: This doesn't work in Saffron City; or if healing items are,,,Yes
19706,TODO: Allow custom opponent level.,Yes,Yes,Yes
19708,TODO: Possibly implement; if we want to allow exiting the map.,Yes,No,Yes
19709,TODO: Refactor this logic into its own class.,,,Yes
19711,Now that we have the HUD as needed; reset the race so we have a consistent starting frame:,No,Yes,Yes
19712,In order the pad the dataset; I had to use this hack to expand scalars to vectors.,,,Yes
19713,Undo that hack required for padding,Yes,No,Yes
19715,Filtering metadata columns to export,,,Yes
19719,Hack to flatten the 1-row matrix to an array,Yes,Yes,Yes
19720,In order the pad the dataset; I had to use this hack to expand scalars to vectors.,,,Yes
19727,TODO: Keep on buffer based on time (e.g. last X hours); and not on last N clicks,Yes,No,Yes
19728,features_input_layer = tf.feature_column.input_layer(features; params['feature_columns']),,,Yes
19729,TODO: Investigate how to share this script between ACR and NAR Python modules,Yes,Yes,Yes
19730,Filtering metadata columns to export,No,Yes,Yes
19731,Adding predictions columns for debug,No,Yes,Yes
19736,TODO: Prototype LSTM Autoencoder for reconstruction and prediction,Yes,Yes,Yes
19737,The matmul-based cosine similarity is much more efficient,,,Yes
19739,do original code; no for loop; needed.,Yes,Yes,Yes
19740,item = data['item_id']; int(data['timeframe']) todo: timeframe ?!,,,Yes
19743,fix the learning rate; no decay,Yes,Yes,Yes
19745,Pass through the data set multiple times; shuffling the training reviews each time to improve accuracy,No,Yes,Yes
19747,fix the learning rate; no decay,Yes,Yes,Yes
19752,TODO: because of pre processing; later we want to have (n_mels; T),Yes,Yes,Yes
19755,TODO: avoids NaN on CRNN,,,Yes
19757,TODO: maxpool?,,,Yes
19760,TODO: avoids NaN on CRNN,,,Yes
19763,TODO: this raises a warning when generator is singular (which it; by,Yes,Yes,Yes
19764,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
19765,"Tie broken in a \""fortunate\"" way.",,,Yes
19766,The indexing takes a few minutes each time and would be nice to just perform this calculation once,,,Yes
19768,TODO:,,,Yes
19770,TODO: weight by length here,Yes,No,Yes
19772,Build a 5 way; 5 shot task,No,Yes,Yes
19780,TODO this isn't particularly fast; use GL for drawing and display someday...,,,Yes
19781,resume checkpoint if needed,No,Yes,Yes
19783,downloads available at http:\/\/tatoeba.org\/eng\/downloads - and better,No,No,Yes
19784,displayed as a matrix; with the columns being input steps and rows being,,,Yes
19785,'api' # needed for ``make gettext`` to not die.,,,Yes
19786,'api' # needed for ``make gettext`` to not die.,No,Yes,Yes
19790,OLD piecewise linear fit library naming convention,Yes,No,Yes
19792,Loop through the rest of A to determine the other columns,No,Yes,Yes
19795,Radius search around each centroid; returning num_neighbors point indices within radius of centroid,,,Yes
19798,This is needed because the pre-activation variant does not have batch,,,Yes
19799,display hack to hide nd depth,Yes,No,Yes
19801,"We \""pool\"" the model by simply taking the hidden state corresponding",No,Yes,Yes
19802,The convention in BERT is:,No,No,Yes
19803,TODO: text classification by rnn,Yes,No,Yes
19804,I think you want to sum on axis [0;1;2],No,No,Yes
19805,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
19806,"Workaround for the \""print is a keyword\/function\"" Python 2\/3 dilemma",Yes,No,Yes
19807,TODO: Handle these explicitly in handle() or make them iterable.,,,Yes
19808,is not multipart and take the fast path (also: 3.1 workaround),No,Yes,Yes
19809,: Not a plugin; but part of the plugin API. TODO: Find a better place.,Yes,Yes,Yes
19811,Fix wsgiref for IPv6 addresses.,No,Yes,Yes
19812,Lets makes sure it is there. This _really_ improves performance.,,,Yes
19815,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
19818,TODO: data-augment:fliplr the bbox coordinate,Yes,Yes,Yes
19819,TODO: To hard example mine or not to hard example mine; that's the question,Yes,Yes,Yes
19822,For positive anchors; compute shift and scale needed to transform them,,,Yes
19823,TODO: use box_refinment() rather than duplicating the code here,,,Yes
19824,TODO: use smooth_l1_loss() rather than reimplementing here,Yes,Yes,Yes
19826,Work-around for Windows: Keras fails on Windows when using,,,Yes
19827,TODO: move resizing to mold_image(),Yes,Yes,Yes
19828,Improve performance by trimming to top anchors by score,Yes,No,Yes
19829,Pad if needed,,,Yes
19831,TODO: Rename target_bbox to target_deltas for clarity,,,Yes
19832,TF doesn't have a way to sort by two columns; so merge them and sort.,Yes,Yes,Yes
19834,TODO: track where float64 is introduced,Yes,No,Yes
19837,TODO: Filter out boxes with zero area,,,Yes
19838,TODO: Settings in args,Yes,No,Yes
19840,-- Options for todo extension ----------------------------------------------,,,Yes
19844,TODO : self.tensors['loss'] and self.tensors['correct'] must be defined.,Yes,Yes,Yes
19845,TODO : MUST handle batch = None,,,Yes
19847,TODO : don't erase log folder if not write log,,,Yes
19848,TODO : Any other options,,,Yes
19851,TODO : specify eval tensor names to save in evals folder,Yes,Yes,Yes
19852,TODO : initialize BaseTower-subclassed objects,Yes,Yes,Yes
19853,TODO : initialize BaseRunner-subclassed object,Yes,No,Yes
19854,TODO : define placeholders and put them in ph,Yes,Yes,Yes
19855,TODO : put your codes here,Yes,No,Yes
19858,TODO : define placeholders and put them in ph,Yes,Yes,Yes
19861,TODO : define your inputs to _initialize here,Yes,Yes,Yes
19862,TODO : retrieve data and store it in the numpy arrays; example shown below,Yes,Yes,Yes
19863,TODO : put more args here,,,Yes
19864,TODO : put something here; Fake data shown,Yes,No,Yes
19867,TODO : put something here; Fake data shown,Yes,No,Yes
19869,TODO : formally specify this path,Yes,Yes,Yes
19872,TODO : self.tensors['loss'] and self.tensors['correct'] must be defined.,,,Yes
19875,TODO : don't erase log folder if not write log,Yes,No,Yes
19876,TODO : Any other options,Yes,Yes,Yes
19880,TODO : initialize BaseTower-subclassed objects,,,Yes
19882,TODO : define placeholders and put them in ph,Yes,Yes,Yes
19885,TODO : define your inputs to _initialize here,Yes,Yes,Yes
19886,TODO : put more args here,Yes,No,Yes
19888,TODO : put more args here,Yes,No,Yes
19889,TODO : formally specify this path,Yes,Yes,Yes
19891,TODO : put more args here,Yes,No,Yes
19892,TODO : formally specify this path,Yes,Yes,Yes
19893,TODO : put something here; Fake data shown,Yes,No,Yes
19894,TODO : put more args here,Yes,No,Yes
19895,FIXME : adhoc (answer being last word); not ignoring single question,Yes,No,Yes
19896,TODO : put more args here,Yes,No,Yes
19897,FIXME : final state is not reshaped!,,,Yes
19899,TODO : make this a util function,Yes,No,Yes
19900,FIXME : final state is not reshaped!,Yes,Yes,Yes
19902,FIXME : this is temporary way to evaluate with hyp,Yes,Yes,Yes
19903,TODO : put more args here,,,Yes
19904,TODO : put some function that gives word_start; word_stop here,Yes,Yes,Yes
19905,FIXME : incorrect loss calculation; due to smaller \/ empty batches,Yes,Yes,Yes
19908,TODO : put more args here,,,Yes
19909,TODO : the problem is that if idxs is very short; it will only output batch for the first gpu; and zip ignores the second even if dataset div provides it,Yes,Yes,Yes
19910,TODO : put more args here,,,Yes
19912,Note that noise_x is unused in computation graph of this function since _is_training is false.,No,Yes,Yes
19913,TODO : put more args here,Yes,No,Yes
19914,TODO : wy support,Yes,No,Yes
19915,TODO : put more args here,,,Yes
19917,Needed to maintain continuity of data across batches.,No,No,Yes
19922,the next two lines implement the advantage normalization trick,No,Yes,Yes
19924,the next two lines implement GAE-Lambda advantage calculation,No,Yes,Yes
19926,the next two lines implement GAE-Lambda advantage calculation,,,Yes
19927,the next two lines implement the advantage normalization trick,No,Yes,Yes
19928,TODO: ensure policy has got better at the task,,,Yes
19930,Maybe normalize content and style weights,Yes,Yes,Yes
19932,add O-XXX for tags,,,Yes
19934,TODO build gazetteer,Yes,Yes,Yes
19937,XXX m = token_f1,,,Yes
19938,"\""\""\""Implement masked 1d convolution with max-pooling\""\""\""",No,Yes,Yes
19940,Second part; apply the cosine to even columns and sin to odds.,,,Yes
19944,FIXME how to write sum_loss; sum_accuracy to summary?,,,Yes
19946,this ugly workaround is somehow needed; Pool is working oddly when TF is loaded.,,,Yes
19947,Hack,No,No,Yes
19948,fix is set,,,Yes
19950,Hack,No,No,Yes
19955,Hack,,,Yes
19958,TODO,,,Yes
19959,TODO might have a bug here; error is larger then it should be,Yes,Yes,Yes
19960,Prewhiten the image if needed.,,,Yes
19963,TODO check if there is a better implementation to NN; use transpose coeff_b might be faster,Yes,Yes,Yes
19964,TODO implement random nn,,,Yes
19965,maybe pairs should also be transposed,No,No,Yes
19968,TODO debug this,,,Yes
19969,probably the square and the sqrt not needed,Yes,Yes,Yes
19971,maybe can do it with less memory by splitting the exponent to several parts,Yes,No,Yes
19972,TODO use fix_svd; here and matlab,Yes,Yes,Yes
19973,TODO debug this,Yes,No,Yes
19974,probably the square and the sqrt not needed,Yes,Yes,Yes
19975,move to python convention,No,Yes,Yes
19977,TODO progress bar for long operations?,,,Yes
19980,probably the square and the sqrt not needed,Yes,Yes,Yes
19981,# maybe can do it with less memory by splitting the exponent to several parts,,,Yes
19982,maybe can do it with less memory by splitting the exponent to several parts,Yes,No,Yes
19984,TODO might have a bug here; error is larger than it should be,,,Yes
19986,TODO debug this,,,Yes
19987,TODO it might be possible to do this faster,Yes,No,Yes
19988,TODO might have a bug here; with less than 10;000 images the error is very large; with more its 0,Yes,Yes,Yes
19990,TODO implement random nn,Yes,Yes,Yes
19992,"\""\""\"" || This module contains utility functions that we often use in various modules. || Unlike helper functions; these functions have to do solely with algorithmic computations. ||  || TODO move cfft; icfft; lgwt; pca_y here || \""\""\""",Yes,Yes,Yes
19994,TODO move this check before anything starts running,Yes,Yes,Yes
19996,TODO iterate instead of using recursion. this is too memoery-expensive,Yes,Yes,Yes
19999,TODO define a constant for this,Yes,Yes,Yes
20000,TODO check input,,,Yes
20003,"todo fix click.Path for \""output\"" option",Yes,Yes,Yes
20006,"TODO verify (star.data was originally \""CTFdata.data\"")",,,Yes
20008,TODO why not initialize before loop (maybe b\/c of huge stacks?),Yes,No,Yes
20010,todo what does 'h' stand for?,Yes,No,Yes
20011,"TODO verify (star.data was originally \""CTFdata.data\"")",,,Yes
20014,TODO adjust to same unified index,Yes,Yes,Yes
20017,TODO is it a reference we want to keep?,Yes,Yes,Yes
20019,Estimate the noise variance. This is needed for the covariance estimation step below.,,,Yes
20021,swap columns to align with Relion,,,Yes
20022,TODO: (from MATLAB implementation) - Check that this tolerance make sense for multiple columns in v,,,Yes
20023,TODO: numpy boolean indexing will return a 1d array (like MATLAB),Yes,No,Yes
20025,likely not needed in the final version.,Yes,Yes,Yes
20027,TODO: (from MATLAB implementation) - Check that this tolerance make sense for multiple columns in v,Yes,Yes,Yes
20028,TODO: (from MATLAB implementation) - Check that this tolerance make sense for multiple columns in v,Yes,Yes,Yes
20032,TODO: this is function could be move to base class if all standard and fast versions of 2d and 3d are using,Yes,Yes,Yes
20033,TODO: (from MATLAB implementation) - Check that this tolerance make sense for multiple columns in v,Yes,Yes,Yes
20035,TODO: Most of this stuff is duplicated in MeanEstimator - move up the hierarchy?,,,Yes
20036,TODO: This is where this differs from MeanEstimator,Yes,No,Yes
20037,TODO: Numpy has got to have a functional shortcut to avoid looping like this!,Yes,No,Yes
20038,TODO: Support regularizer when solving for volume covariance,,,Yes
20040,TODO from MATLAB code: Deal with rolled dimensions,,,Yes
20043,TODO: Move inside appropriate object,,,Yes
20044,If needed; modified through the scale() method,No,Yes,Yes
20045,TODO: This could use documentation - very unintuitive!,Yes,Yes,Yes
20046,If we have a 2d array with an even no. of columns; append the first column reversed at the right,No,No,Yes
20047,TODO: This part could do with some documentation - not intuitive!,Yes,Yes,Yes
20048,TODO: rotated_grids might as well give us correctly shaped array in the first place,Yes,No,Yes
20049,TODO: Flattening and reshaping at end may not be necessary!,Yes,Yes,Yes
20050,Populated by 'check_backends()' when first needed.,No,No,Yes
20051,TODO: move common functionality up the hierarchy,Yes,No,Yes
20055,TODO: Add ability to multiply a SourceFilter object with a Filter object to avoid attribute access below,,,Yes
20057,TODO: Determine Principal Angles and return as a dict value,Yes,Yes,Yes
20061,TODO: Should this theta adjustment be moved inside cart2sph?,,,Yes
20062,TODO: Rearranging elements to get consistent behavior with MATLAB 'randn2',Yes,No,Yes
20063,TODO: unroll\/roll are great candidates for a context manager since they're always used in conjunction.,,,Yes
20067,TODO: Check behavior if this is a single mrc file (no '@'),,,Yes
20069,TODO: Add options,Yes,No,Yes
20071,Estimate the noise variance. This is needed for the covariance estimation step below.,No,No,Yes
20072,A more advanced approach with mock\/patch is needed for this to work in a general case.,,,Yes
20073,version in maj.min.bld format - a 4th component (rev info) is added automatically if needed,,,Yes
20074,TODO: Move inside appropriate object,,,Yes
20075,"\""\""\"" || This script illustrates the covariance Wiener filtering functionality of the || ASPIRE; implemented by estimating the covariance of the unfiltered || images in a Fourier-Bessel basis and applying the Wiener filter induced by || that covariance matrix. The results can be reproduced exactly to the Matlab version || if the same methods of generating random numbers are used. || \""\""\""",No,Yes,Yes
20076,the estimated mean and the variance of the noise are needed. Again; the,No,Yes,Yes
20077,Convert a single metadata field into a list of single metadata field; since that's what the 'columns',,,Yes
20080,2 new metadata columns 'rand_value1'\/'rand_value2' added; with random values,,,Yes
20081,2 new metadata columns 'rand_value1'\/'rand_value2' added; for SPECIFIC indices,No,Yes,Yes
20082,TODO: Check behavior if this is a single mrc file (no '@'),Yes,No,Yes
20083,Get the 'mode' (data type) - TODO: There's probably a more direct way to do this.,,,Yes
20084,TODO: Is this a bug?,Yes,No,Yes
20085,TODO: Is there an amplitude field in Relion?,,,Yes
20088,TODO: Check p and a_p should be real or not ?,Yes,Yes,Yes
20090,Estimate the noise variance. This is needed for the covariance estimation step below.,No,No,Yes
20091,Make sure it automatically calls get_mean if needed.,,,Yes
20096,Since FFBBasis2D doesn't yet implement dtype; we'll set this to double to match its built in types.,Yes,Yes,Yes
20097,Since FFBBasis2D doesn't yet implement dtype; we'll set this to double to match its built in types.,,,Yes
20098,because we implement them here ourselves.,No,Yes,Yes
20099,Note: The size of ntheta can be reduced by half if only evaluate_t function is needed as,No,Yes,Yes
20101,TODO: need check the initial condition x0 can improve the results or not.,Yes,Yes,Yes
20102,mask_radius is of the form xxx.5,,,Yes
20105,TODO move this check before anything starts running,Yes,Yes,Yes
20108,To eliminate that; we require that det(G)=1+2abc-(a^2+b^2+c^2) is large.,,,Yes
20111,Only half of each ray is needed,No,Yes,Yes
20113,mask_radius is of the form xxx.5,No,No,Yes
20116,Only half of ray is needed,,,Yes
20118,zero; the conditions (i != j) && (j != k) are not needed; since,No,Yes,Yes
20121,A*V1'=R1 and A*V2=R2 are the columns of the rotations matrices.,,,Yes
20122,Recover the rotations. The first two columns of all rotation,No,Yes,Yes
20123,Columns of the shift variables that correspond to the current pair [i; j],No,Yes,Yes
20124,tics; since the peak might move a little bit due to wrong k images,No,Yes,Yes
20126,TODO: Currently finufftpy is hardcoded as doubles only right now,,,Yes
20129,For now; we hack to store it in memory as I understand and just lie about the indexing to python.,,,Yes
20133,TODO: need to implement it by pipline,Yes,Yes,Yes
20134,TODO: need to implement it by pipline,,,Yes
20135,TODO: Is this a bug?,,,Yes
20136,TODO: figure out how why the result of einsum requires reshape,,,Yes
20137,# TODO: rotated_grids might as well give us correctly shaped array in the first place,Yes,No,Yes
20139,TODO: maybe replace with ascontiguousarray,Yes,No,Yes
20140,# TODO: rotated_grids might as well give us correctly shaped array in the first place,,,Yes
20141,RCOPT; this image reference is a single image 8;8. Transpose no needed.,,,Yes
20145,Since FFBBasis2D doesn't yet implement dtype; we'll set this to double to match its built in types.,,,Yes
20146,TODO: decide if should just warn; raise; or convert here.,,,Yes
20147,TODO: decide if should just warn; raise; or convert here.,Yes,Yes,Yes
20148,TODO: Decide if this should simply infer from src or basis.,Yes,Yes,Yes
20149,TODO: check all of these handle C ordered im data (currently unused).,,,Yes
20151,TODO: check all of these handle C ordered im data (currently unused).,Yes,No,Yes
20152,If needed; modified through the scale() method,,,Yes
20154,TODO: Rearranging elements to get consistent behavior with MATLAB 'randn2',Yes,No,Yes
20156,TODO: Rearranging elements to get consistent behavior with MATLAB 'randn2',,,Yes
20157,TODO: maybe replace with ascontiguousarray,Yes,No,Yes
20158,TODO: Currently\/historically finufftpy is hardcoded as doubles only (inside the binding layer).,Yes,Yes,Yes
20159,TODO: Things get messed up unless we ensure a 'C' ordering here - investigate why,,,Yes
20160,TODO: (from MATLAB implementation) - Check that this tolerance make sense for multiple columns in v,Yes,Yes,Yes
20165,TODO: The implementation of these functions should move directly inside the appropriate Image methods that call them.,Yes,Yes,Yes
20168,TODO: rotated_grids might as well give us correctly shaped array in the first place,,,Yes
20169,Since FFBBasis2D doesn't yet implement dtype; we'll set this to double to match its built in types.,Yes,Yes,Yes
20170,TODO: The implementation of these functions should move directly inside the appropriate Image methods that call them.,,,Yes
20171,TODO: figure out how why the result of einsum requires reshape,Yes,Yes,Yes
20172,probably not needed; transition,,,Yes
20178,In real use; you would probably bring your own stack of images;,No,No,Yes
20179,In real use; you would probably bring your own stack of images;,,,Yes
20180,Convert a single metadata field into a list of single metadata field; since that's what the 'columns',,,Yes
20181,The pandas .loc indexer does work with missing columns (as long as not ALL of them are missing),No,Yes,Yes
20183,TODO constants should be added to self.args in net_master.py,Yes,Yes,Yes
20186,TODO clean up code!!!,,,Yes
20187,TODO make sure h is of power 2 (fulfilled),,,Yes
20188,TODO calculate a reasonable waveform_length from the longest h obtained IN TOTAL!!!,Yes,Yes,Yes
20190,TODO: CRAZY FIX INFO AND ROOM POS NUMBER TO DATABASE,,,Yes
20191,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
20195,`kw` catches `env=None` needed for newer sphinx while maintaining,No,Yes,Yes
20197,TODO: Only exposing first environments state,,,Yes
20198,TODO: Only exposing first environments state,,,Yes
20201,TODO: Implement,Yes,Yes,Yes
20203,TODO: int should be a string in api version  F.FReactionsAddApiVersion(B; '0.1.0'),Yes,Yes,Yes
20205,TODO: support inference of only one dimension based on knowns,,,Yes
20206,TODO: Only exposing first environments state,,,Yes
20207,Upper Part(Columns),No,No,Yes
20208,goal_pos_x = environment.description.configurable('GoalTransformX').observation,,,Yes
20210,TODO: WARN ABOUT WHEN INDIVIDUAL OBSERVATIONS AND UNOBSERVABLES ARE UNAVAILABLE,Yes,No,Yes
20212,TODO: WARN ABOUT WHEN INDIVIDUAL OBSERVATIONS AND UNOBSERVABLES ARE UNAVAILABLE,Yes,No,Yes
20213,#NAME?,,,Yes
20214,space = deserialise_space(self._configurable_space) #Already done,,,Yes
20216,fset.columns = fset.columns.droplevel('channel'),No,Yes,Yes
20218,TODO -> filters table?,Yes,No,Yes
20219,TODO program?,,,Yes
20220,TODO better numpy integration,Yes,Yes,Yes
20222,TODO y-axis units...?,Yes,No,Yes
20223,TODO replace with (script; div) method,,,Yes
20225,TODO how to choose a good default?,Yes,Yes,Yes
20226,TODO change limits,Yes,Yes,Yes
20228,TODO: Ensure that it's okay for anyone to read any comment,Yes,Yes,Yes
20233,TODO where do we get the instrument info?,,,Yes
20235,TODO where do we get the instrument info?,Yes,Yes,Yes
20236,TODO can we remove `autouse` here?,Yes,Yes,Yes
20237,TODO how to check plot?,Yes,No,Yes
20239,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
20241,TODO remove magic number; where can this logic live?,,,Yes
20245,TODO better numpy integration,,,Yes
20246,"\""\""\""TODO migrate this to broker tools\""\""\""",Yes,Yes,Yes
20248,elif file_uri.startswith('http:\/\/'): # TODO is this reliable?,,,Yes
20249,TODO delete file after deleting row,Yes,Yes,Yes
20250,TODO can't serve from outside static\/,Yes,Yes,Yes
20253,TODO decorator\/context manager?,Yes,Yes,Yes
20255,TODO: handle invalid source ID,Yes,No,Yes
20256,TODO decorator\/context manager?,,,Yes
20257,TODO decorator\/context manager?,Yes,Yes,Yes
20261,TODO: check the obstime format,,,Yes
20266,TODO Do we need a delete handler? If so; what should it do? Old; unsaved,Yes,Yes,Yes
20267,TODO replace `eval` with Namespaces,Yes,Yes,Yes
20269,TODO : implement permissions checking,Yes,No,Yes
20270,TODO: implement permissions checking,Yes,No,Yes
20272,TODO: deal with the same name but different groups?,Yes,Yes,Yes
20273,TODO how to check plot?,Yes,No,Yes
20274,TODO: spec.csv shouldn't hard code the,Yes,Yes,Yes
20275,TODO: load multiple files,,,Yes
20280,TODO how to check plot?,Yes,No,Yes
20284,TODO decorator\/context manager?,Yes,Yes,Yes
20285,subclasses *must* implement the method below,,,Yes
20288,after validating the indices; ensure that the columns they,,,Yes
20289,NOTE: It is probably possible to grab the full Obj records here instead of,Yes,Yes,Yes
20290,ORM mappings; so we would have to explicity re-label the columns here.,,,Yes
20291,Fix the header keyword for the input system; if needed,Yes,Yes,Yes
20293,Support True\/False and true\/false convention,No,No,Yes
20294,Helper classes\/functions below provide a workaround for PostgreSQL functions,Yes,Yes,Yes
20295,returning multiple columns; unsupported by SA,Yes,Yes,Yes
20298,Declare ORM table views. Note that the view contains old and new columns!,,,Yes
20299,Update single user group name if needed,No,Yes,Yes
20300,TODO decorator\/context manager?,,,Yes
20301,TODO how to check plot?,,,Yes
20302,TODO: uncomment once API is refactored - this is currently commented,,,Yes
20304,TODO: Add ownership logic to taxonomy,,,Yes
20306,TODO replace `eval` with Namespaces,,,Yes
20307,TODO decorator\/context manager?,,,Yes
20308,The height is manually computed like this instead of using built in aspect_ratio\/sizing options,Yes,Yes,Yes
20309,number of items in the legend can alter the needed heights of the plot; using built-in Bokeh options,No,Yes,Yes
20311,"\""\""\""Move weather data to separate table ||  || Revision ID: 8f086f8c0c21 || Revises: 3e1852612f34 || Create Date: 2021-03-30 10:30:39.368099 ||  || \""\""\""",No,No,Yes
20312,TODO: Update dataset loading as soon as https:\/\/github.com\/src-d\/backlog\/issues\/1212 done,Yes,No,Yes
20313,FIXME(zurk): change to simple function. Vadim Markovtsev comments:,,,Yes
20314,FIXME(zurk): change to simple function. Vadim Markovtsev comments:,,,Yes
20315,read last two columns as identifiers,No,Yes,Yes
20317,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
20318,Do all the stuff needed to train the classifier here,,,Yes
20321,XXX maybe do other than squared Euclidean?,Yes,Yes,Yes
20322,XXX is this really necessary?,Yes,Yes,Yes
20324,TODO: This has to actually do something useful!,,,Yes
20325,TODO: Can we make this use a pre-calculated powerspectrum?,Yes,Yes,Yes
20327,Calculate a better estimate of the fundamental frequency spacing:,,,Yes
20328,TODO: Only one setting for now...,Yes,No,Yes
20329,We should really use tempfile.TemporaryDirectory instead; but it seems,Yes,Yes,Yes
20330,TODO: This should obviously be removed once we start running for real,,,Yes
20331,We should really use tempfile.TemporaryDirectory instead; but it seems,,,Yes
20333,"FIXME: Should be \""UNIQUE\""; but something is weird in ETE-6?!",Yes,No,Yes
20334,"FIXME: Should be \""UNIQUE\""; but something is weird in ETE-6?!",Yes,No,Yes
20337,Generate TODO file if it is needed:,Yes,No,Yes
20339,"TODO: Come up with better name than \""datalevel\""?",Yes,No,Yes
20342,TODO: Use TaskManager for this?,,,Yes
20343,FIXME: Can we get rid of this?,Yes,Yes,Yes
20347,TODO: Use TaskManager for this?,,,Yes
20350,Define here because it is needed by self.labels() used below,No,Yes,Yes
20351,TODO: This should obviously be removed once we start running for real,,,Yes
20354,Create as 2D array; which as main-frequency number for rows; and harmonic number for columns.,,,Yes
20355,TODO: Subtract peak first?,,,Yes
20356,TODO: Also reject on SNR,Yes,Yes,Yes
20357,TODO: Only include classes from the current level,Yes,Yes,Yes
20358,TODO: Use TaskManager for this?,Yes,No,Yes
20360,FIXME: Only keeping the first label,,,Yes
20361,Must be a better way to do this!,,,Yes
20362,TODO: This should obviously be removed once we start running for real,Yes,Yes,Yes
20364,TODO: Add these as inputs,Yes,No,Yes
20365,Create as 2D array; which as main-frequency number for rows; and harmonic number for columns.,No,Yes,Yes
20368,TODO: Is this even needed?,Yes,No,Yes
20370,TODO: Only include classes from the current level,,,Yes
20371,TODO: Use TaskManager for this?,Yes,No,Yes
20374,TODO: Add check of data validation!,Yes,No,Yes
20375,FIXMe: HORRIBLE HACK!,Yes,No,Yes
20380,Remove tables that are not needed,Yes,Yes,Yes
20381,This is a hacky way to do it; but the only way under the current framework,Yes,Yes,Yes
20383,This will download IERS data needed for astropy.Time transformations:,No,Yes,Yes
20387,Add units to columns:,Yes,No,Yes
20390,Remove columns that are all NaN:,No,No,Yes
20391,TODO: Should we throw an error if a classifier is not run at all?,Yes,Yes,Yes
20392,TODO: Remove NaNs? Or set them to -1?,Yes,Yes,Yes
20393,TODO: What about NaN values?,,,Yes
20394,TODO: Add these to classifier object?,Yes,Yes,Yes
20395,TODO: Why is it needed to re-normalize the lightcurve here?,Yes,Yes,Yes
20397,TODO: Level 1 classes hardcoded!,Yes,Yes,Yes
20399,FIXME: Should the be allowed to change?,Yes,No,Yes
20400,TODO: Check if results are already present,Yes,Yes,Yes
20401,needed for building the todolist; it only needs to exist.,,,Yes
20402,None \/ save_dir + 'xxx.pickle',No,No,Yes
20404,hacky way of saying it is LocalMininet,Yes,Yes,Yes
20407,check for batch size when needed,No,No,Yes
20409,TODO: to be replaced with better type definition,,,Yes
20411,TODO: this should use the step config from an overridden commit,Yes,No,Yes
20412,TODO: this really shouldn't be necessary!,Yes,No,Yes
20415,TODO: We could check whether the commit is known already,,,Yes
20419,Extra gymnastics needed because `click.arguments` mutates the kwargs here,,,Yes
20420,TODO: Add multiline support for the remaining table formats:,,,Yes
20421,TODO: refactor column alignment in single-line and multiline modes,Yes,Yes,Yes
20422,columns have to be transposed,,,Yes
20423,pad with empty headers for initial columns if necessary,No,Yes,Yes
20424,format rows and columns; convert numeric values to strings,No,Yes,Yes
20426,TODO: Remove in 2020.,Yes,No,Yes
20427,TODO: Remove this if numpy insert is as fast as append,Yes,Yes,Yes
20430,TODO: Needs redesign to remove hack,Yes,Yes,Yes
20432,TODO: selection is not used. WHY?,,,Yes
20434,extend the list if needed -,Yes,No,Yes
20435,2012-09-01 - (jdw) Revise tokenizer to better handle embedded quoting.,,,Yes
20436,loop_ data processing ends if -,No,No,Yes
20438,loop_ data processing ends if -,,,Yes
20439,TODO Need to find a better pickle-compatible way which is deleted at end,Yes,Yes,Yes
20440,TODO: Missing CIPCode unsetting,Yes,No,Yes
20441,TODO: Set PDB double bonds,Yes,No,Yes
20442,Once the section description has finished create a map from names to columns,No,Yes,Yes
20446,traditional PDB counterparts; but diverge in columns 71-79 inclusive (where the first character in the line,No,Yes,Yes
20452,TautomerTransform('formamidinesulfinic acid f'; '[O;N;!H0]-[C]=[S;Se;Te]=[O]'; bonds='=--');  # TODO: WAT!?,,,Yes
20455,TODO: This cant possibly work,,,Yes
20456,An ugly hack to silence non-prefixed logging messages,Yes,Yes,Yes
20457,Columns printed by the __str__ method,No,Yes,Yes
20458,Generic setter in the pandas table. Maybe we should use actual indices instead.,,,Yes
20459,A ligand - a hack to allow multiple groups overriding key. See _findRes,Yes,Yes,Yes
20460,Png render may be a bit better -,,,Yes
20461,TODO: Use BLOSUM62?,,,Yes
20463,TODO: Can remove this. Barely any speedup,Yes,Yes,Yes
20464,TODO: After deleting labels it breaks. Better don't delete or fix the code,Yes,Yes,Yes
20470,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
20472,Take care however as the protonation will a) move atoms to optimize hydrogen networks b) add missing sidechains,,,Yes
20473,We are using the PDB convention of left aligning the name in 4 spaces to signify ion\/metal,No,Yes,Yes
20474,TODO: Should we remove bonds between metals and protein? Should we remove metals before guessing bonds and add them back in? Might crash otherwise?,Yes,No,Yes
20475,Dirty hack to remove the 'END' line from the PDBs since babel hates it,,,Yes
20476,End of dirty hack,,,Yes
20478,TODO: ask bid pricing,,,Yes
20479,TODO: ask bid pricing,Yes,Yes,Yes
20481,"columns = [\""amount\""; \""price\""; \""fee\""]",,,Yes
20483,TODO: avoid long codes,Yes,Yes,Yes
20488,if sum(pl.columns.str.endswith(reference_to_check)) == len(portfolio.positions):,,,Yes
20489,pos_values * ratios_values; columns=position.columns; index=idx,,,Yes
20493,FIXME: docstring in the file,Yes,No,Yes
20495,This looks ugly but iloc is very slow compare to that. I don't get why.,,,Yes
20496,FIXME: docstring in the file,Yes,No,Yes
20497,FIXME: Specify column by string,Yes,Yes,Yes
20498,This looks ugly but iloc is very slow compare to that. I don't get why.,Yes,Yes,Yes
20499,If true; `todo` and `todoList` produce output; else they produce nothing.,Yes,Yes,Yes
20500,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
20504,Sheets that are needed for calculations but we want to hide,Yes,No,Yes
20507,TODO: Adjust formula recoveries to be dynamic and not address dependent.,,,Yes
20508,smallest_list_length number of elements; move,,,Yes
20509,where the list ends (in_list.stop).,,,Yes
20510,where the list ends (in_list.stop).,No,No,Yes
20512,"the number of \""columns\"" of this array must be 1.",,,Yes
20513,numpy array; where the number of columns is dimension.,,,Yes
20516,Extend s by an array with 2 rows and 3 columns. The number of,,,Yes
20518,Extend s by an array with 1 row and 3 columns. The number of,,,Yes
20519,Thus s.recent[:s.stop] is an array with 4 rows and 3 columns.,No,Yes,Yes
20520,of 1 row and 3 columns; versus APPENDING a rank-1 array consisting,No,Yes,Yes
20521,Thus s.recent[:s.stop] is an array with 5 rows and 3 columns.,,,Yes
20525,and add. Include more functions when needed.,,,Yes
20528,Zero out the unused part of self.recent. This step isn't,No,Yes,Yes
20529,where the list ends (in_list.stop).,No,No,Yes
20530,write to datastore - maybe use another process?,,,Yes
20531,Split a stream into exactly two streams.,,,Yes
20532,Split a stream into exactly TWO streams.,No,Yes,Yes
20534,The number of features (i.e. columns of the array) is set on the,,No,Yes
20537,Implement single process with thread.,,Yes,Yes
20539,Split a stream into exactly TWO streams.,,Yes,Yes
20541,Alternative Ranks (TODO):,,,Yes
20544,TODO:,,,Yes
20545,TODO: plot top consensus known and novel genes -- use 'gene_ranking_boxplot' from ClassifierEvaluator class,,Yes,Yes
20548,TODO: IPA analysis for top hits,,No,Yes
20549,extract interesting columns from dfs,,,Yes
20550,TODO: if possible; remove horrible hack that uses Index instead of pd.merge,,Yes,Yes
20552,TODO: add comments?,,No,Yes
20553,TO-DO: test that hiding seed genes works for the non-Generic classifier too,,No,Yes
20554,return if no matching columns exist,,Yes,Yes
20555,TODO: check if that's redundant with essential_mouse_df,,No,Yes
20558,Find index of feature columns with correlation greater than thres,,,Yes
20559,TODO: incomplete function,,,Yes
20560,TODO: check what caret does,,No,Yes
20561,TODO,,Yes,Yes
20562,TODO: needs fixing to allow plotting of more than 1 categorical variable,,No,Yes
20564,"\""\""\""\r || Author: Dimitrios Vitsios; 2018\r || \r || - Class for compiling full feature table\r || \""\""\""",,,Yes
20566,TODO: use this section for debugging only,,,Yes
20567,feature_cols = train_data.drop([self.cfg.Y]; axis=1).columns.values,,Yes,Yes
20568,TODO: beta,,Yes,Yes
20569,TODO: 3D PCA scatterplot -- https:\/\/plot.ly\/python\/3d-scatter-plots,,Yes,Yes
20570,TODO: complete automated nested-clustering,,,Yes
20571,TODO: clustering of t-SNE plot and Pathway Enrichment analysis of CoInterest with PANTHER\/IPA,,,Yes
20573,Implement random sorting of rows with same value,,Yes,Yes
20574,TODO: check <= vs <,,Yes,Yes
20576,TO-DO: calc correlation between primary and synonymous p-values,,No,Yes
20577,Implement random sorting of rows with same value,,,Yes
20580,TODO:,,,Yes
20585,print(agg_df.columns),,,Yes
20589,TODO: Implement box limiting directly for `(cx; cy; w; h)` so that we don't have to unnecessarily convert back and forth.,,Yes,Yes
20590,Set the aspect ratios for each predictor layer. These are only needed for the anchor box layers.,,,Yes
20593,TODO geometry will not be computed,,,Yes
20594,Is padding needed?,,No,Yes
20596,It will be needed,,No,Yes
20598,FIXME: this does not yet take the original label of the,,,Yes
20600,TODO: again; I am ignoring the weight of vertices and,,,Yes
20604,TODO: check whether the labels are in [0; num_labels - 1],,Yes,Yes
20605,TODO: rewrite weight assigner class to support lists,,No,Yes
20608,TODO: make configurable,,,Yes
20609,Determine the number of columns to select for the desired,,,Yes
20612,TODO: make configurable,,,Yes
20613,the individual iterations in its columns.,,,Yes
20614,TODO: need to discuss whether this is 'allowed' or smart,,Yes,Yes
20615,TODO: need to discuss whether this is 'allowed' or smart,,,Yes
20619,because it is probably a lot faster.,,Yes,Yes
20620,TODO: rewrite this into a broadcasted version of the same loop,,Yes,Yes
20621,because it is probably a lot faster.,,,Yes
20622,FIXME: why does this not work? Even if the two conditions are,,,Yes
20623,TODO: make power configurable?,,Yes,Yes
20625,TODO: might need this later on?,,,Yes
20626,TODO: can this be made more efficient?,,No,Yes
20627,TODO: this should not be necessary,,,Yes
20630,TODO: this flag is somewhat redundant given the flag above; need,,,Yes
20631,FIXME: older version of calculating label,,No,Yes
20633,TODO: this flag is somewhat redundant given the flag above; need,,,Yes
20634,TODO: make configurable,,Yes,Yes
20636,TODO: make this configurable?,,Yes,Yes
20639,TODO: this is only used if `use_vertex_weights` is True;,,,Yes
20642,TODO: make configurable,,,Yes
20643,TODO: this is only used if `use_vertex_weights` is True;,,,Yes
20644,length of the created feature vector.,,Yes,Yes
20645,FIXME: older version of calculating label,,,Yes
20646,FIXME: this is the old way of calculating label,,,Yes
20648,TODO: make power configurable?,,Yes,Yes
20652,The multiple of 64 is needed to ensure smooth scaling of feature,,,Yes
20653,Improve performance by trimming to top anchors by score,,No,Yes
20657,TODO: Filter out boxes with zero area,,No,Yes
20659,TODO: use smooth_l1_loss() rather than reimplementing here,,Yes,Yes
20660,TODO: Update this line to work with batch > 1. Right now it assumes all,,Yes,Yes
20661,TODO: will be removed in a future update in favor of augmentation,,,Yes
20662,TODO: To hard example mine or not to hard example mine; that's the question,,,Yes
20663,TODO: If multiple anchors have the same IoU match all of them,,,Yes
20667,A hack to get around Keras's bad support for constants,,Yes,Yes
20668,TODO: verify that this handles zero padded ROIs,,,Yes
20669,TODO: clean up (use tf.identify if necessary),,No,Yes
20670,Work-around for Windows: Keras fails on Windows when using,,,Yes
20672,TODO: Remove this after the notebook are refactored to not use it,,No,Yes
20673,TODO: Build and use this function to reduce code duplication,,Yes,Yes
20674,TODO: cleaner to do zero unpadding upstream,,Yes,Yes
20675,In the long run; it's more efficient to modify the code to support large,,Yes,Yes
20676,TODO: Replace with matplotlib equivalent?,,No,Yes
20678,##### Pylint Configurations ends here########,,,Yes
20681,Apply gradients.  IMPORTANT!!  need to be task-specific; if we don't split Adaptive Optimizer between tasks; the weights needed fixed might be changed,,,Yes
20683,Moving averages ends up in the trainable variables collection,,No,Yes
20685,Moving averages ends up in the trainable variables collection,,,Yes
20686,Moving averages ends up in the trainable variables collection,,,Yes
20687,The 'weights' part of the name is needed for the quantization library,,No,Yes
20689,TODO: !!!,,,Yes
20690,TODO: API token should contain (url; api_key and namespace),,,Yes
20691,TODO: posortowanie kolumn,,,Yes
20692,TODO: tags - czy teraz jest ok?,,Yes,Yes
20693,TODO,,,Yes
20695,num_images; unused,,,Yes
20698,TODO: Used in choosing best action,,Yes,Yes
20700,TODO: maybe move into ACS2Utils class,,No,Yes
20702,TODO: check,,,Yes
20703,TODO: maybe __eq__ in Classifier could be used ...,,,Yes
20705,TODO: change to t_alp,,No,Yes
20706,TODO: check if updated only in ALP,,Yes,Yes
20707,TODO: check this line,,No,Yes
20708,Maybe this is redundant,,,Yes
20713,TODO .copy(),,,Yes
20714,TODO: added by me,,No,Yes
20715,TODO: added be me,,,Yes
20717,TODO: I'm not sure about this part,,No,Yes
20718,TODO: p5 exp=0; r=0 (paper),,Yes,Yes
20720,TODO: p5 maybe also take into consideration cl.E = # (paper),,,Yes
20726,TODO p2: Maybe checking wheter marked sometimes does not work..,,,Yes
20728,TODO  need to add to self?,,Yes,Yes
20733,move to C8,,,Yes
20734,maybe check numerosity,,No,Yes
20737,return go.str_to_action(env._state.board; move),,Yes,Yes
20738,TODO: check if needed,,,Yes
20739,TODO: p5 maybe also take into consideration cl.E = # (paper),,,Yes
20740,TODO: p5 exp=0; r=0 (paper),,,Yes
20741,TODO: removed from GYM after 0.9 :(,,No,Yes
20743,Only cfg.length and cfg.wildcard are needed,,,Yes
20747,TODO: continue from here,,Yes,Yes
20749,TODO: p5 exp=0; r=0 (paper),,,Yes
20750,TODO: implement,,Yes,Yes
20753,TODO: think - maybe it's useless. In this moment might be used in,,Yes,Yes
20757,TODO: collect metrics,,Yes,Yes
20758,TODO: rest of the code,,,Yes
20760,TODO: think,,No,Yes
20762,TODO: for rACS this,,No,Yes
20764,space needed for new classifiers,,Yes,Yes
20766,TODO: if PEEs are implemented; 'isEnhanced()' should be added,,Yes,Yes
20767,TODO: you can do it better,,,Yes
20768,information whether it was best possible move,,,Yes
20769,this way allows situation to be either str or Perception,,Yes,Yes
20771,and had better results with same solution as hosford42,,No,Yes
20772,Doubling _run_trials_explore would cause too many issues.,,Yes,Yes
20773,TODO: EspilonGreedy,,No,Yes
20775,ToDo: Jeep Grand Cherokee !!!,,Yes,Yes
20777,ToDo: Rename e.g. TextClsfrCreateDetails to TextClassifierCreateDetails ...,,No,Yes
20786,ToDo: Find a better way to move image from OpenCV to base64 than writing to disk.,,Yes,Yes
20789,ToDo: Find a better way to move image from OpenCV to base64 than writing to disk.,,Yes,Yes
20793,quick fix for multitrack; melody in almost every song on midi[0],,,Yes
20795,TODO,,Yes,Yes
20797,quick fix for multitrack; melody in almost every song on midi[0],,Yes,Yes
20801,save if model better than before,,No,Yes
20805,TODO TEMP for more sequences,,Yes,Yes
20807,TODO TEMP for more sequences,,Yes,Yes
20808,else: quick fix for multitrack; melody in almost every song on midi[0],,No,Yes
20811,save if model better than before,,No,Yes
20812,(2) Blank lines between documents. Document boundaries are needed so,,Yes,Yes
20813,The convention in BERT is:,,No,Yes
20814,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
20815,The convention in BERT is:,,No,Yes
20816,"What we really want to return is \""Steve Smith\"".",,No,Yes
20819,Set origin; move x axis labels,,No,Yes
20820,goal_pos_x = environment.description.configurable('GoalTransformX').observation,,No,Yes
20826,TODO: INVESTIGATE CONFIGURATION that are reset to,,,Yes
20827,return len(self.tree) #TODO: DOES NOT RETURN NUMBER OF ELEMENTS ADDED BUT TREE INDEX SIZE,,No,Yes
20829,"warn(f'Length of statistical values are <=1; measure \""{key}\"" maybe ill-defined')",,Yes,Yes
20831,configuration[2].configurable_value,,No,Yes
20832,goal_pos_y = environment.description.configurable('GoalTransformY_').configurable_value,,,Yes
20833,goal_pos_y = environment.description.configurable('ActorTransformY_').configurable_value,,,Yes
20835,goal_pos_y = environment.description.configurable('ActorTransformY_').configurable_value,,Yes,Yes
20837,goal_pos_y = environment.description.configurable('ActorTransformY_').configurable_value,,,Yes
20842,''' ||  || Description || A pole is attached by an un-actuated joint to a cart; which moves along a frictionless track. The pendulum  || starts upright; and the goal is to prevent it from falling over by increasing and reducing the cart's  || velocity. ||  || Source || This environment corresponds to the version of the cart-pole problem described by Barto; Sutton; and Anderson ||  || Observation || Type: Box(4) ||  || Num\tObservation\tMin\tMax || 0\tCart Position\t-2.4\t2.4 || 1\tCart Velocity\t-Inf\tInf || 2\tPole Angle\t~ -41.8\u00B0\t~ 41.8\u00B0 || 3\tPole Velocity At Tip\t-Inf\tInf || Actions || Type: Discrete(2) ||  || Num\tAction || 0\tPush cart to the left || 1\tPush cart to the right ||  || Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is  || pointing. This is because the center of gravity of the pole increases the amount of energy needed to move  || the cart underneath it ||  || Reward || Reward is 1 for every step taken; including the termination step ||  || Starting State || All observations are assigned a uniform random value between \u00B10.05 ||  || Episode Termination || Pole Angle is more than \u00B112\u00B0 || Cart Position is more than \u00B12.4 (center of the cart reaches the edge of the display) || Episode length is greater than 200 || Solved Requirements || Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials. ||  || ''',,,Yes
20843,the next two lines implement GAE-Lambda advantage calculation,,Yes,Yes
20844,TODO: Should use discounted reward instead,,Yes,Yes
20846,TODO: ExplorationSpec,,No,Yes
20847,TODO: support individual reset of environments vector,,,Yes
20848,TODO: this assumes that all actions are available in each state,,,Yes
20850,TODO: support individual reset of environments vector,,,Yes
20852,TODO: this assumes all actions are available in every state,,,Yes
20855,TODO: this assumes all actions are available in every state,,Yes,Yes
20858,TODO:,,,Yes
20860,TODO: DOES NOTHING; as is overwritten everywhere,,Yes,Yes
20861,obs = numpy.clip(state.observables; -10; 10) # TODO: Clipping,,,Yes
20862,TODO: Figure out,,,Yes
20866,self.columns = self.data.columns.levels[0],,No,Yes
20867,if data_name in self.meta_valid.columns:,,Yes,Yes
20868,several checks to make sure the right types; columns... are used,,,Yes
20871,self.columns = np.array(new_data.columns),,No,Yes
20872,self.columns = np.array(self.data.columns),,No,Yes
20875,if not data.columns == WEST_name_conversion['raw_data_name'],,Yes,Yes
20876,print('raw data columns should be the same as the raw data colum values given in WEST_name_conversion'),,No,Yes
20877,"\""\""\"" || Created on Wed Sep 16 10:21:52 2015 ||  || @author: Cha\u00EFm De Mulder; chaim.demulder@ugent.be || @purpose: provide functions to read datafiles and return them as pd.dataframe;  || provide possibility to concatenate read files || @copyright: (c) 2015; Cha\u00EFm De Mulder || \""\""\""",,Yes,Yes
20878,using pandas set_index function to set the columns with timevalues,,Yes,Yes
20879,using pandas set_index function to set the columns with timevalues,,,Yes
20880,same; but checking in this way still needs to happen because of,,Yes,Yes
20881,same; but checking in this way still needs to happen because of,,Yes,Yes
20883,interpolation are filled; needed to prevent other; already present NaN values,,,Yes
20884,TODO: put package requirements here,,No,Yes
20886,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,,Yes
20887,sometimes(iaa.ElasticTransformation(alpha=(0.5; 3.5); sigma=0.25)); # move pixels locally around (with random strengths),,No,Yes
20888,sometimes(iaa.PiecewiseAffine(scale=(0.01; 0.05))) # sometimes move parts of the image around,,,Yes
20889,NOTE: probably more efficient to sort then stride by nt_regions,,Yes,Yes
20890,NOTE: probably more efficient to sort then stride by ns_regions,,,Yes
20891,TODO: could check that structures are not decendents of eachother,,No,Yes
20892,TODO: change to classmethod constructor,,,Yes
20894,# NOTE: probably more efficient to sort then stride by nt_regions,,Yes,Yes
20896,TODO :: check allensdk.core.reference_space.many_structure_masks(),,No,Yes
20897,"\""\""\""Permutes row\/columns by ...\""\""\""",,,Yes
20898,TODO :: incorp save\/load into Mask class,,Yes,Yes
20900,# TODO : IPSI\/CONTRA,,No,Yes
20901,masked columns,,Yes,Yes
20903,masked columns,,,Yes
20904,TODO : better error statement,,,Yes
20905,TODO: look into cleaning up check for disjoint,,,Yes
20906,TODO : better error statement,,Yes,Yes
20908,TODO : better error statement,,Yes,Yes
20909,NOTE: probably more efficient to sort then stride by nt_regions,,,Yes
20910,but much more memory efficient to compute sum first,,Yes,Yes
20911,NOTE: probably more efficient to sort then stride by ns_regions,,,Yes
20912,TODO : eval overwrite of K (kernel),,,Yes
20915,raw namedtuple is very memory efficient as it packs the attributes,,,Yes
20916,TODO : finish Mask docstring (examples),,No,Yes
20917,TODO : implement,,,Yes
20918,TODO : docs and example,,,Yes
20919,TODO : replace with json of wanted structures,,No,Yes
20920,TODO: look into cleaning up check for disjoint,,,Yes
20924,TODO : docs and example,,No,Yes
20926,TODO: eval_gradient,,No,Yes
20927,TODO accept_sparse=['csr'; 'csc'; 'coo']? check sopt.nnls,,,Yes
20930,TODO accept_sparse=['csr'; 'csc'; 'coo']? check sopt.nnls,,Yes,Yes
20932,TODO: add support for sparse,,No,Yes
20933,TODO: flip option,,,Yes
20939,TODO,,Yes,Yes
20943,TODO: docstring,,No,Yes
20948,TODO: flip option,,Yes,Yes
20949,TODO: better error,,,Yes
20951,TODO: docstring,,No,Yes
20952,needed for compatibility with LinearModel.predict() (decision_function),,No,Yes
20957,this is needed for some reason...,,,Yes
20958,"\""\""\"" || ========================== || Nadaraya-Watson Regression || ========================== ||  || .. note:: ||     This example is in part a copy of ``plot_kernel_ridge_regressions`` by ||     Jan Hendrik Metzen found in the package Scikit-Learn. ||  || .. currentmodule:: mcmodels.regressors.nonparametric ||  || Nadaraya-Watos (NW) regression learns a non-linear function by using a kernel- || weighted average of the data. Fitting NW can be done in closed-form and is || typically very fast. However; the learned model is non-sparse and thus suffers || at prediction-time. ||  || TALK ABOUT EFFICIENT LOOCV!! ||  || This example illustrates NW on an artificial dataset; which || consists of a sinusoidal target function and strong noise added to every fifth || datapoint. || \""\""\""",,,Yes
20959,"\""\""\"" || Python package providing mesoscale connectivity models for mouse || ================================================================ ||  || mcmodels is a Python package containing the models for mesoscale connectivty || in mouse developed at the Allen Institute for Brain Science. ||  || See https:\/\/AllenInstitute.githib.io\/mouse_connectivity_models for complete || documentation. || \""\""\""",,,Yes
20961,TODO: implement __repr__,,,Yes
20964,TODO accept_sparse=['csr'; 'csc'; 'coo']? check sopt.nnls,,Yes,Yes
20971,'''Script to build the regionalized connectivity in every region annotated at 100 micron. ||  || NOTE: This script takes quite a while to run. If you are simply interested in ||       the connectivity within the set summary structures (or any disjoint ||       structure set); using the RegionalizedModel class will be much more ||       efficient. || ''',,,Yes
20972,TODO: bilateral for now; should improve in future,,Yes,Yes
20973,move iterator,,Yes,Yes
20974,TODO: error handling,,No,Yes
20975,TODO: work in above,,No,Yes
20976,NOTE: better error message,,No,Yes
20977,TODO : replace with json of wanted structures,,,Yes
20978,TODO: breakup,,No,Yes
20979,TODO: curr_val should be taken from iterator,,No,Yes
20980,TODO: remove tolist() in mask_idx & reomove np.asarray(),,No,Yes
20981,move iterator,,,Yes
20982,TODO: remove tolist(),,Yes,Yes
20986,todo: Is gp must use on cross-entropy,,No,Yes
20989,todo: recover the status from interrupt,,No,Yes
20990,The following functions aren't needed for calculating the FID,,Yes,Yes
20991,Todo: use uniform distribution as noise will cause mode collaspe,,,Yes
20995,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
20996,This is needed since the notebook is stored in the object_detection folder.,,,Yes
20997,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
20999,We should probably switch to using build_conv2d_layer and,,Yes,Yes
21000,once we refactor Faster RCNN models to set is_training through an outer,,Yes,Yes
21001,TODO(mttang): This method is needed because the current,,Yes,Yes
21002,Remember original dtype to so we can convert back if needed,,No,Yes
21003,TODO(rathodv): delete unused `use_display_name` argument once we change,,Yes,Yes
21005,in the dictionary must implement,,Yes,Yes
21006,TODO(b\/65130867): Use image_id tensor once we fix the input data,,,Yes
21008,Unused.,,Yes,Yes
21009,Mul. In either case; these min\/max vars are not needed once replaced with,,,Yes
21010,TO-DO replace this with label map,,,Yes
21014,Get logical indices of ignored and unmatched columns as tf.int64,,Yes,Yes
21017,Needed for fine-tuning from classification checkpoints whose,,,Yes
21019,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
21020,Follow the convention by adding back the batch dimension,,No,Yes
21021,This is needed since the notebook is stored in the object_detection folder.,,,Yes
21022,Follow the convention by adding back the batch dimension,,,Yes
21023,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
21025,This is needed since the notebook is stored in the object_detection folder.,,,Yes
21027,Follow the convention by adding back the batch dimension,,No,Yes
21028,TODO(rathodv): Come up with a better way to generate scope names,,Yes,Yes
21029,max overlap with gt over classes (columns),,Yes,Yes
21031,Compute values needed for means and stds,,No,Yes
21032,These values will be needed for making predictions,,Yes,Yes
21037,- Secondly; we fix a bunch of command line arguments.,,,Yes
21041,Transpose dataFrame to arrange columns as pathways and rows as genes,,,Yes
21042,Transpose dataFrame to arrange columns as pathways and rows as genes,,Yes,Yes
21043,Get relevant columns for survival information,,Yes,Yes
21044,Rearrange columns,,Yes,Yes
21050,FIXME why isn't this used?,,Yes,Yes
21051,TODO replace these temp paths with proper usage of tempfile,,,Yes
21052,Columns of the ComPath mapping data frame,,,Yes
21053,Expected columns to do ORA analysis,,,Yes
21054,TODO: Generate the AUC PR,,Yes,Yes
21055,Get relevant columns,,No,Yes
21059,Temporary fix until converted into a package...,,,Yes
21060,Temporary fix until converted into a package...,,,Yes
21061,Temporary fix until converted into a package...,,Yes,Yes
21063,"\""\""\""Defines the models for the JWQL web app. ||  || ** CURRENTLY NOT IN USE ** ||  || In Django; \""a model is the single; definitive source of information || about your data. It contains the essential fields and behaviors of the || data you\u2019re storing. Generally; each model maps to a single database || table\"" (from Django documentation). Each model contains fields; such || as character fields or date\/time fields; that function like columns in || a data table. This module defines models that might be used to store || data related to the JWQL webpage. Interacts with the database located || at jwql\/website\/db.sqlite3. ||  || Authors || ------- ||     - Lauren Chambers ||  || Use || --- ||     This module is used as such: ||  ||     :: ||         from models import MyModel ||         data = MyModel.objects.filter(name=\""JWQL\"") ||  || References || ---------- || For more information please see: ||     https:\/\/docs.djangoproject.com\/en\/2.0\/topics\/db\/models\/ ||  || \""\""\""",,No,Yes
21065,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21066,Temporary workaround for noncompliant files in filesystem,,,Yes
21067,"\""\""\"" Logging functions for the James Webb Quicklook automation platform ||  || Working notes:  || 1) Will definitely want the same type of decorators that WFC3 QL uses - one || to track failures and one to track useful system information. Are there || any other things we will want to create a decorator for? Also which  || module version information will we want to track with our info decorator? ||  || 2) Do we want to follow the same naming convention stuff? Have the make_log_file  || function preform the same way? ||  ||  ||  ||  || Authors || ------- || Catherine Martlin 2018 ||  ||  || Use || ___ ||  ||  || Dependencies || ____________ ||  ||  || References || __________ ||  || Code will likely be adopted from python routine written by Alex Viana; 2013  || for the WFC3 Quicklook automation platform. ||  || Notes || _____ ||  ||  ||  || \""\""\""",,Yes,Yes
21068,"\""\""\"" || A module to interact with the JWQL postgresql database ``jwqldb`` ||  || The ``load_connection()`` function within this module allows the user || to connect to the ``jwqldb`` database via the ``session``; ``base``; || and ``engine`` objects (described below).  The classes within serve as || ORMs (Object-relational mappings) that define the individual tables of || the relational database. ||  || The ``engine`` object serves as the low-level database API and perhaps || most importantly contains dialects which allows the ``sqlalchemy`` || module to communicate with the database. ||  || The ``base`` object serves as a base class for class definitions.  It || produces ``Table`` objects and constructs ORMs. ||  || The ``session`` object manages operations on ORM-mapped objects; as || construced by the base.  These operations include querying; for || example. ||  || Authors || ------- ||     Joe Filippazzo; Johannes Sahlmann; Matthew Bourque ||  || \""\""\""",,Yes,Yes
21071,full detector. This is needed for mosaicking NIRCam,,Yes,Yes
21072,Get the columns,,No,Yes
21073,Temporary workaround for noncompliant files in filesystem,,Yes,Yes
21075,full detector. This is needed for mosaicking NIRCam,,,Yes
21076,"\""\""\""Module to interface the JWST Engineering Database. ||  || This module provides ``jwql`` with functions to interface and query the ||  JWST Engineering Database. ||  || The module provides functionality to query database mnemonics. ||  || Authors || ------- ||  ||     - Johannes Sahlmann ||  || Use || --- ||  ||     This module can be imported and used with ||  ||     :: ||  ||         from jwql.interface_engineering_database.interface_edb import query_meta_data ||         query_meta_data(mnemonic_identifier) ||  ||     Required arguments: ||  ||     ``mnemonic_identifier`` - String representation of a mnemonic name. ||  || Notes || ----- ||  ||     Some code was adapted from the EngDB.py script my Andre Martel. ||  || TODO || ---- ||  ||     Identify list of valid mnemonics (at runtime?) ||  || \""\""\""",,,Yes
21077,"params = {\""columns\"":\""filename\"";\""filters\"":[{\""paramName\"":\""filename\""; \""values\"":[rootname]}]}",,Yes,Yes
21081,There is a better way to do this... but we don't know what the column,,Yes,Yes
21084,Implement it,,No,Yes
21086,Temporary workaround for noncompliant files in filesystem,,,Yes
21087,Initialize dictionary that will contain all needed data,,,Yes
21088,TODO if cookie not set; don't hit auth.mast,,Yes,Yes
21089,TODO if the user already has a token; don't re-authorize,,,Yes
21090,TODO set cookie properties safely,,No,Yes
21093,could eventually be moved to constants.py,,,Yes
21095,Temporary workaround for noncompliant files in filesystem,,Yes,Yes
21101,convert numerical ID to str for homogenity (all columns are str),,Yes,Yes
21102,loop over filled fields and implement simple AND logic,,Yes,Yes
21103,Define the columns,,Yes,Yes
21104,Get the columns that are True,,,Yes
21105,Columns specific to all monitor ORMs,,,Yes
21106,Get monitor-specific columns,,Yes,Yes
21107,Pack all needed variables into a Python dictionary,,No,Yes
21111,Pack all needed variables into a Python dictionary,,No,Yes
21112,Basic metadata that will be needed later,,No,Yes
21113,loop over filled fields and implement simple AND logic,,Yes,Yes
21115,Define the columns,,Yes,Yes
21117,Columns specific to all monitor ORMs,,,Yes
21121,Implement it,,,Yes
21122,Get the columns,,No,Yes
21123,Get the columns that are True,,,Yes
21124,Get the columns,,No,Yes
21127,Get the columns,,No,Yes
21128,full detector. This is needed for mosaicking NIRCam,,,Yes
21131,starting; ending; and step size. Step size is needed for MIRI; where,,Yes,Yes
21133,Ensure the ORM exists and contains appropriate columns,,Yes,Yes
21134,Get the columns that are True,,Yes,Yes
21135,Get the columns,,No,Yes
21136,Define the columns,,Yes,Yes
21138,probably should pre-screen to merge continuation lines,,,Yes
21139,Temporary workaround for noncompliant files in filesystem,,,Yes
21140,Determine which database tables are needed based on instrument,,,Yes
21145,Determine which database tables are needed based on instrument,,,Yes
21146,starting; ending; and step size. Step size is needed for MIRI; where,,,Yes
21148,Calculate median values of each amplifier for odd\/even columns,,Yes,Yes
21150,Temporary workaround for noncompliant files in filesystem,,,Yes
21152,TODO query_history,,Yes,Yes
21158,"\""\""\""This module contains code for the bad\/dead pixel monitor; XXX || XXXXXXXXXXXXXX THIS DOCSTRING NEEDS TO BE UPDATED ||  || If enough new files for a given instrument\/aperture combination || (currently the files must be identified as dark current files in the || ``exp_type`` header keyword) are present in the filesystem at the time || the ``dark_monitor`` is called; the files are first run through the the || appropriate pipeline steps to produce slope images. ||  || A mean slope image as well as a standard deviation slope image is || created by sigma-clipping on a pixel by pixel basis. The mean and || standard deviation images are saved to a fits file; the name of which || is entered into the ``<Instrument>DarkCurrent`` database table. ||  || The mean slope image is then normalized by an existing baseline slope || image. New hot pixels are identified as those with normalized signal || rates above a ``hot_threshold`` value. Similarly; pixels with || normalized signal rates below a ``dead_threshold`` are flagged as new || dead pixels. ||  || The standard deviation slope image is normalized by a baseline || (historical) standard deviation image. Pixels with normalized values || above a noise threshold are flagged as newly noisy pixels. ||  || New hot; dead; and noisy pixels are saved to the ``DarkPixelStats`` || database table. ||  || Next; the dark current in the mean slope image is examined. A histogram || of the slope values is created for the pixels in each amplifier; as || well as for all pixels on the detector. In all cases; a Gaussian is fit || to the histogram. Currently for NIRCam and NIRISS; a double Gaussian is || also fit to the histogram from the entire detector. ||  || The histogram itself as well as the best-fit Gaussian and double || Gaussian parameters are saved to the DarkDarkCurrent database table. ||  ||  || Author || ------ ||  ||     - Bryan Hilbert ||  || Use || --- ||  ||     This module can be used from the command line as such: ||  ||     :: ||  ||         python bad_pixel_monitor.py ||  ||  ||  || Development notes: ||  || This can't be used with NIRCam since NIRCam has no internal lamp and therefore || will not be taking any more internal flat field images. Could perhaps be used with || a series of external undithered observations... ||  || Dead pixel algorithem was designed to use flats for all instruments except MIRI; which uses || darks. (Would anything useful result if using darks for NIRCam?) ||  || Templates to use: FGS_INTFLAT; NIS_LAMP; NRS_LAMP; MIR_DARK ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  || \""\""\""",,,Yes
21160,TODO Record readnoise stats,,Yes,Yes
21167,a.k.a. Dec 1; 2015 == CV3  # TODO remove this and uncomment above,,Yes,Yes
21169,## perhaps it would make sense to display inputs at the top so all of the information is on one page? Or adjust form as enter data on same page?,,Yes,Yes
21171,## perhaps it would make sense to display inputs at the top so all of the information is on one page? Or adjust form as enter data on same page?,,Yes,Yes
21175,from flask_wtf import FlaskForm,,,Yes
21176,writer.writerow(df.columns.values),,No,Yes
21177,"params = {\""columns\"": \""filename\"";",,,Yes
21178,"params = {\""columns\"": \""filename; expstart; filter; readpatt; date_beg; date_end; apername; exp_type\"";",,Yes,Yes
21179,move these into utils.constants.py,,Yes,Yes
21180,"\""\""\"" || Created on Fri Sep 18 04:30:18 2020 ||  || @author: bsunnquist || \""\""\""",,,Yes
21183,Determine which database tables are needed based on instrument,,,Yes
21184,"params = {\""columns\"": \""filename; expstart; filter; readpatt; date_beg; date_end; apername; exp_type\"";",,Yes,Yes
21185,TODO PLACEHOLDER - erase when done,,Yes,Yes
21187,Initialize dictionary that will contain all needed data,,No,Yes
21189,Initialize dictionary that will contain all needed data,,No,Yes
21190,Temporary workaround for noncompliant files in filesystem,,Yes,Yes
21191,Initialize dictionary that will contain all needed data,,No,Yes
21192,Temporary workaround for noncompliant files in filesystem,,,Yes
21193,"params = {\""columns\"": \""*\"";",,,Yes
21194,this is what would ideally work,,,Yes
21195,for instrument in JWST_INSTRUMENT_NAMES: #TODO,,Yes,Yes
21196,Make a separate plot for each amp and odd\/even columns,,Yes,Yes
21197,Determine which database tables are needed based on instrument,,Yes,Yes
21200,Add space around sides of figure,,,Yes
21202,Ensure the file has all the needed entries with expected data types,,Yes,Yes
21203,TODO: Check that level is a reasonable number,,Yes,Yes
21204,TODO: Check types,,No,Yes
21205,TODO: Convert stride kwarg to tuple,,,Yes
21206,TODO: Actual convolution; not correlation,,,Yes
21210,TODO: Check that level is a reasonable number,,,Yes
21211,TODO: Check types,,No,Yes
21214,TODO: Check types,,,Yes
21215,TODO: Convert to Wavelet\/Filter class,,No,Yes
21217,TODO: Understand,,Yes,Yes
21218,TODO: Should we actually expand the dimension?,,No,Yes
21221,TODO: Periodic extention; not zero-padding,,,Yes
21222,TODO: Actual convolution; not correlation,,Yes,Yes
21223,py = ixy*tform[:;1]  # faster than p=Ixy*tform if no normalization needed (affine only),,,Yes
21225,clear rectange hack for tooltip image x;y,,No,Yes
21226,py = ixy*tform[:;1]  # faster than p=Ixy*tform if no normalization needed (affine only),,Yes,Yes
21229,Batch2 may work better with tripod; currently camera is tilting a little,,No,Yes
21234,TODO: Rewrite this to work,,No,Yes
21237,TODO: This is not correct,,No,Yes
21239,This is needed for conversion between HOOMD and TensorFlow memory spaces,,Yes,Yes
21240,This is needed for conversion between HOOMD and TensorFlow memory spaces,,,Yes
21242,TODO,,Yes,Yes
21244,TODO,,Yes,Yes
21245,check if training is needed,,No,Yes
21247,can't do the beautiful simple way as before. Need to slice out the stupid box,,,Yes
21248,for TF2.4.1 we hack the box to have leading batch dimension,,Yes,Yes
21250,Needed to be able to use git submodule...,,Yes,Yes
21252,TODO: It just a tech preview; implement it properly!,,Yes,Yes
21253,Only this is needed from the TSV handler...,,Yes,Yes
21257,TODO: B\u00E1lint: command should be the usual names e.g. \/emMorph; \/emDep; etc.,,Yes,Yes
21262,Needed to be able to use git submodule...,,Yes,Yes
21263,TODO: B\u00E1lint: command should be the usual names e.g. \/emMorph; \/emDep; etc.,,Yes,Yes
21264,TODO: It just a tech preview; implement it properly!,,Yes,Yes
21265,TODO: B\u00E1lint: legyen a neve emSeqTag,,No,Yes
21267,TODO: B\u00E1lint: command should be the usual names e.g. \/emMorph; \/emDep; etc.,,Yes,Yes
21268,TODO: It just a tech preview; implement it properly!,,Yes,Yes
21270,TODO: em_tag.required,,No,Yes
21272,TODO: dt.required,,No,Yes
21273,TODO: em_chunk.required,,Yes,Yes
21274,TODO: em_dep.required,,,Yes
21276,TODO: Same in flask. Per request build pipeline like above and stream the output...,,Yes,Yes
21277,TODO: e.g. 127.0.0.1:5000\/morph\/pos\/chunk,,,Yes
21279,TODO: B\u00E1lint: legyen a neve emSeqTag,,No,Yes
21286,Needed to be able to use git submodule...,,,Yes
21287,TODO: B\u00E1lint: command should be the usual names e.g. \/emMorph; \/emDep; etc.,,,Yes
21288,Needed to be able to use git submodule...,,Yes,Yes
21289,TODO: Hack; Rework PyJNIus import: detecting if PyJNIus is loaded is not work!,,,Yes
21291,TODO: Fill this variable if module requires JAVA...,,No,Yes
21294,TODO: Need singletons from init_everything because the aliases!,,Yes,Yes
21295,Suppress warning. # TODO: Add --verbose CLI option for this warning!,,Yes,Yes
21297,TODO: Maybe enable per request setting of allowing conll-style comments,,No,Yes
21299,TODO: Hide options as it rarely needed!,,,Yes
21302,"\""\""\"" || Disable OBSOLETE emDep instance || # emDep ################################################################################################################ ||  || sys.path.append(os.path.join(os.path.dirname(__file__); 'emdeppy'))  # Needed to be able to use git submodule... || from emdeppy import EmDepPy || jnius_config.add_classpath(EmDepPy.class_path) ||  || em_dep = (EmDepPy; (); {'source_fields': {'form'; 'lemma'; 'upostag'; 'feats'}; ||                         'target_fields': ['id'; 'deprel'; 'head']}) || \""\""\""",,,Yes
21303,Needed to be able to use git submodule...,,Yes,Yes
21304,TODO: Set from CLI -i and -o,,Yes,Yes
21306,Pass or hold back the header TODO: Maybe there shoud be an option to modify it,,,Yes
21307,TODO: Remove the need of sys.path.append with smart imports...,,Yes,Yes
21310,TODO review,,,Yes
21312,"\""\""\"" || @note: An implementation of Non-Negative Sparse auto_encoders || This is based on the papers: ||     A. Lemme; R. F. Reinhart and J. J. Steil. ||     \""Online learning and generalization of parts-based image representations ||      by Non-Negative Sparse auto_encoders\"". Submitted to Neural Networks; ||                               And ||     A. Lemme; R. F. Reinhart and J. J. Steil. \""Efficient online learning of ||     a non-negative sparse auto_encoder\"". In Proc. ESANN; 2010. || \""\""\""",,Yes,Yes
21313,Save better model if optimization achieves a lower accuracy,,,Yes
21316,TODO: Remove condition.,,,Yes
21318,"TODO: Consider removing \""automated driving\"" from terms blacklist.",,,Yes
21319,"TODO: Consider removing \""autonomous driving\"" from terms blacklist.",,No,Yes
21320,TODO: Consider adding category cs.CV.,,Yes,Yes
21321,TODO: Consider removing terms from blacklist: automated driving; autonomous driving; heart; cancer; myocardial,,Yes,Yes
21325,Update list as needed.,,,Yes
21328,TODO: Consider category cs.RO or whitelisting ID 1707.07217,,,Yes
21331,TODO: To hard example mine or not to hard example mine; that's the question,,,Yes
21332,A crowd box in COCO is a bounding box around several instances. Exclude,,No,Yes
21335,TODO: use box_refinement() rather than duplicating the code here,,,Yes
21336,TODO: Build and use this function to reduce code duplication,,Yes,Yes
21337,TODO: can this be optimized to avoid duplicating the anchors?,,,Yes
21338,A hack to get around Keras's bad support for constants,,Yes,Yes
21346,TF doesn't have a way to sort by two columns; so merge them and sort.,,,Yes
21347,Improve performance by trimming to top anchors by score,,No,Yes
21348,Pad if needed,,,Yes
21349,TODO: Update this line to work with batch > 1. Right now it assumes all,,,Yes
21350,TODO: cleaner to do zero unpadding upstream,,Yes,Yes
21352,TODO: can this be optimized to avoid duplicating the anchors?,,Yes,Yes
21354,"\""\""\""MobileNet v1 models for Keras. ||  || MobileNet is a general architecture and can be used for multiple use cases. || Depending on the use case; it can use different input layer size and || different width factors. This allows different width models to reduce || the number of multiply-adds and thereby || reduce inference cost on mobile devices. ||  || MobileNets support any input size greater than 32 x 32; with larger image sizes || offering better performance. || The number of parameters and number of multiply-adds || can be modified by using the `alpha` parameter; || which increases\/decreases the number of filters in each layer. || By altering the image size and `alpha` parameter; || all 16 models from the paper can be built; with ImageNet weights provided. ||  || The paper demonstrates the performance of MobileNets using `alpha` values of || 1.0 (also called 100 % MobileNet); 0.75; 0.5 and 0.25. || For each of these `alpha` values; weights for 4 different input image sizes || are provided (224; 192; 160; 128). ||  || The following table describes the size and accuracy of the 100% MobileNet || on size 224 x 224: || ---------------------------------------------------------------------------- || Width Multiplier (alpha) | ImageNet Acc |  Multiply-Adds (M) |  Params (M) || ---------------------------------------------------------------------------- || |   1.0 MobileNet-224    |    70.6 %     |        529        |     4.2     | || |   0.75 MobileNet-224   |    68.4 %     |        325        |     2.6     | || |   0.50 MobileNet-224   |    63.7 %     |        149        |     1.3     | || |   0.25 MobileNet-224   |    50.6 %     |        41         |     0.5     | || ---------------------------------------------------------------------------- ||  || The following table describes the performance of || the 100 % MobileNet on various input sizes: || ------------------------------------------------------------------------ ||       Resolution      | ImageNet Acc | Multiply-Adds (M) | Params (M) || ------------------------------------------------------------------------ || |  1.0 MobileNet-224  |    70.6 %    |        529        |     4.2     | || |  1.0 MobileNet-192  |    69.1 %    |        529        |     4.2     | || |  1.0 MobileNet-160  |    67.2 %    |        529        |     4.2     | || |  1.0 MobileNet-128  |    64.4 %    |        529        |     4.2     | || ------------------------------------------------------------------------ ||  || The weights for all 16 models are obtained and translated || from TensorFlow checkpoints found at || https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/slim\/nets\/mobilenet_v1.md ||  || # Reference ||  || - [MobileNets: Efficient Convolutional Neural Networks for ||    Mobile Vision Applications](https:\/\/arxiv.org\/pdf\/1704.04861.pdf)) || \""\""\""",,,Yes
21355,TODO Change path to v1.1,,No,Yes
21356,"\""\""\""NASNet-A models for Keras. ||  || NASNet refers to Neural Architecture Search Network; a family of models || that were designed automatically by learning the model architectures || directly on the dataset of interest. ||  || Here we consider NASNet-A; the highest performance model that was found || for the CIFAR-10 dataset; and then extended to ImageNet 2012 dataset; || obtaining state of the art performance on CIFAR-10 and ImageNet 2012. || Only the NASNet-A models; and their respective weights; which are suited || for ImageNet 2012 are provided. ||  || The below table describes the performance on ImageNet 2012: || -------------------------------------------------------------------------------- ||       Architecture       | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M) || -------------------------------------------------------------------------------- || |   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    | || |   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9    | || -------------------------------------------------------------------------------- ||  || Weights obtained from the official TensorFlow repository found at || https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/slim\/nets\/nasnet ||  || # References ||  ||  - [Learning Transferable Architectures for Scalable Image Recognition] ||     (https:\/\/arxiv.org\/abs\/1707.07012) ||  || This model is based on the following implementations: ||  ||  - [TF Slim Implementation] ||    (https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/slim\/nets\/nasnet\/nasnet.py) ||  - [TensorNets implementation] ||    (https:\/\/github.com\/taehoonlee\/tensornets\/blob\/master\/tensornets\/nasnets.py) || \""\""\""",,No,Yes
21358,the numbers of columns and ImageNet classes are not identical.,,,Yes
21359,"\""\""\""MobileNet v1 models for Keras. || MobileNet is a general architecture and can be used for multiple use cases. || Depending on the use case; it can use different input layer size and || different width factors. This allows different width models to reduce || the number of multiply-adds and thereby || reduce inference cost on mobile devices. || MobileNets support any input size greater than 32 x 32; with larger image sizes || offering better performance. || The number of parameters and number of multiply-adds || can be modified by using the `alpha` parameter; || which increases\/decreases the number of filters in each layer. || By altering the image size and `alpha` parameter; || all 16 models from the paper can be built; with ImageNet weights provided. || The paper demonstrates the performance of MobileNets using `alpha` values of || 1.0 (also called 100 % MobileNet); 0.75; 0.5 and 0.25. || For each of these `alpha` values; weights for 4 different input image sizes || are provided (224; 192; 160; 128). || The following table describes the size and accuracy of the 100% MobileNet || on size 224 x 224: || ---------------------------------------------------------------------------- || Width Multiplier (alpha) | ImageNet Acc |  Multiply-Adds (M) |  Params (M) || ---------------------------------------------------------------------------- || |   1.0 MobileNet-224    |    70.6 %     |        529        |     4.2     | || |   0.75 MobileNet-224   |    68.4 %     |        325        |     2.6     | || |   0.50 MobileNet-224   |    63.7 %     |        149        |     1.3     | || |   0.25 MobileNet-224   |    50.6 %     |        41         |     0.5     | || ---------------------------------------------------------------------------- || The following table describes the performance of || the 100 % MobileNet on various input sizes: || ------------------------------------------------------------------------ ||       Resolution      | ImageNet Acc | Multiply-Adds (M) | Params (M) || ------------------------------------------------------------------------ || |  1.0 MobileNet-224  |    70.6 %    |        529        |     4.2     | || |  1.0 MobileNet-192  |    69.1 %    |        529        |     4.2     | || |  1.0 MobileNet-160  |    67.2 %    |        529        |     4.2     | || |  1.0 MobileNet-128  |    64.4 %    |        529        |     4.2     | || ------------------------------------------------------------------------ || The weights for all 16 models are obtained and translated || from TensorFlow checkpoints found at || https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/slim\/nets\/mobilenet_v1.md || # Reference || - [MobileNets: Efficient Convolutional Neural Networks for ||    Mobile Vision Applications](https:\/\/arxiv.org\/pdf\/1704.04861.pdf)) || \""\""\""",,No,Yes
21360,TODO Change path to v1.1,,No,Yes
21361,TODO: Replace with matplotlib equivalent?,,No,Yes
21363,TODO: Implement,,,Yes
21368,TODO: Implement,,,Yes
21369,TODO: Implement,,Yes,Yes
21370,TODO refactor data,,,Yes
21372,commented while unused,,Yes,Yes
21374,TODO this is real ipfs address,,,Yes
21378,TODO strange call for change state after job complete (eth filter glitch),,,Yes
21380,TODO conduct a more in-depth study of the states,,Yes,Yes
21381,skip events listening by time  previous block mining (most cheapest way),,Yes,Yes
21385,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
21386,-- Options for todo extension ----------------------------------------------,,Yes,Yes
21387,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21390,TODO: insert Cuda check; Remove harcoded cuda device,,Yes,Yes
21391,TODO: Implement Conv Transpose,,,Yes
21392,TODO: insert Cuda check; Remove harcoded cuda device,,Yes,Yes
21395,TODO: Make it work with any padding,,Yes,Yes
21396,TODO: Implement Conv Transpose,,,Yes
21397,TODO: Make it work with any padding,,,Yes
21399,handle columns with nans,,Yes,Yes
21400,filters out columns with long string values,,,Yes
21402,add handle columns,,Yes,Yes
21407,# Todo: make initial sequence evolvable,,Yes,Yes
21412,TODO remove check once v 0.7 is pip installable,,Yes,Yes
21413,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21416,Hack around making dynamic routes for flask,,,Yes
21418,"HACK: JSONifed respose; I don't know if this has the \""message\"" field.",,Yes,Yes
21420,TODO add by user flag to connection,,,Yes
21421,config parameter needed to save variables when using GPU,,,Yes
21423,config parameter needed to save variables when using GPU,,Yes,Yes
21424,config parameter needed to save variables when using GPU,,Yes,Yes
21425,config parameter needed to save variables when using GPU,,,Yes
21427,config parameter needed to save variables when using GPU,,Yes,Yes
21428,tx: columns; ty: rows,,Yes,Yes
21429,config parameter needed to save variables when using GPU,,Yes,Yes
21430,config parameter needed to save variables when using GPU,,,Yes
21431,config parameter needed to save variables when using GPU,,Yes,Yes
21432,config parameter needed to save variables when using GPU,,Yes,Yes
21433,no idea why uniform does not give any broadcastable dimensions,,,Yes
21434,just a hack to return placeholder shape when eval,,Yes,Yes
21435,TODO: float16 overflow,,,Yes
21437,TODO: float16 overflow; unsupport DeepCopyOps,,,Yes
21438,TODO: bizarre degradation in performance if not specify device=gpu,,Yes,Yes
21440,convert to tuple if needed,,,Yes
21441,prepare dimshuffle pattern inserting broadcastable axes as needed,,Yes,Yes
21442,no idea why uniform does not give any broadcastable dimensions,,,Yes
21443,TODO,,,Yes
21444,needed if we want to do something like:,,,Yes
21446,dirty hack,,Yes,Yes
21447,TODO,,,Yes
21449,====== Append columns ====== #,,Yes,Yes
21450,all columns,,Yes,Yes
21456,maybe rollback,,No,Yes
21457,no idea why uniform does not give any broadcastable dimensions,,,Yes
21458,TODO: error here,,,Yes
21459,no idea why uniform does not give any broadcastable dimensions,,Yes,Yes
21460,TODO: pygpu (libgpuarray) still not support diag,,,Yes
21462,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
21463,Fix unsupported image types using the Pillow.,,Yes,Yes
21464,how many columns can we fit within MAX_MEM_BLOCK?,,Yes,Yes
21465,seems that small value is better;,,No,Yes
21467,hack to prevent infinite useless loop of transpose,,,Yes
21469,how many columns can we fit within MAX_MEM_BLOCK?,,,Yes
21470,seems that small value is better;,,No,Yes
21471,TODO: think about what to do with new Ops here,,,Yes
21472,convert to tuple if needed,,,Yes
21473,====== compute STFT if needed ====== #,,Yes,Yes
21474,TODO: check label transform here,,,Yes
21475,this is ugly but work well,,,Yes
21476,TODO: fix here,,No,Yes
21478,TODO: add EER value later,,No,Yes
21479,TODO,,Yes,Yes
21481,the config log look better.,,Yes,Yes
21483,TODO: add different pca prefix (e.g. pca_full_mspec; pca_sami_mspec),,Yes,Yes
21484,TODO: add PCA visualization,,,Yes
21485,orthogonalize the columns,,Yes,Yes
21487,TODO: better strategy for mixup here,,Yes,Yes
21490,# orthogonalize the columns,,No,Yes
21491,smaller is better,,,Yes
21493,by convention; use 2 as OOV word,,Yes,Yes
21494,TODO: split feed_dict into minibatches,,Yes,Yes
21497,TODO: check if mini batch return the right order and same values,,Yes,Yes
21498,TODO: new style for confusion matrix (using small and big dot),,No,Yes
21499,TODO: fix bug of the scatter method,,,Yes
21500,TODO: fix bug of the scatter method,,No,Yes
21503,network architecture for efficient modeling of long temporal contexts.,,Yes,Yes
21504,so they are needed to be excluded in new_variables,,Yes,Yes
21505,TODO: update rollback mechanism,,Yes,Yes
21508,TODO: add multi-threading interface,,,Yes
21509,TODO: finish this,,Yes,Yes
21511,TODO: search for module in sys.path,,Yes,Yes
21512,no idea why we need this,,,Yes
21516,* TF-autograph is good and easy way; but still get a lot of issues,,Yes,Yes
21517,create tensorflow dataset; a bit ugly with many if-then-else,,,Yes
21519,TODO: not a good solution here; history make recursive reference,,Yes,Yes
21521,TODO: not a good solution here; history make recursive reference,,,Yes
21523,TODO: this list is to be updated; or a smarter solution for automatically,,,Yes
21528,TODO,,Yes,Yes
21529,TODO: add stack for setting framework context,,,Yes
21531,Applying the cosine to even columns and sin to odds.,,Yes,Yes
21532,(i - i % 2) create a sequence of (0;0;1;1;2;2;...) which is needed,,No,Yes
21533,TODO: validate this implementation,,,Yes
21535,(i - i % 2) create a sequence of (0;0;1;1;2;2;...) which is needed,,,Yes
21536,simple hack make Lambda for flexible,,Yes,Yes
21537,it seems adding tf.function don't improve much performance,,,Yes
21538,Can deep network fix posterior mode collapse due to loc initialization,,Yes,Yes
21539,TODO: support give instance of DistributionLambda directly,,,Yes
21540,TODO: better specifying complex distribution,,,Yes
21541,TODO: support dilations > 1 (atrous_conv2d_transpose),,Yes,Yes
21542,generalization error (smaller is better),,Yes,Yes
21543,progression (bigger is better),,No,Yes
21544,TODO: improve performance of VAE,,No,Yes
21545,TODO: FactorVAE still not working!,,,Yes
21546,"the reconstruction will be very \""ugly\""",,,Yes
21547,TODO,,Yes,Yes
21549,"TODO: sometimes the folder or file \""accidently\"" exists",,,Yes
21550,fix random state,,Yes,Yes
21551,TODO: in theory beam_size could be larger than dictionary size; but,,Yes,Yes
21552,TODO: new style for confusion matrix (using small and big dot),,No,Yes
21553,====== Append columns ====== #,,,Yes
21554,all columns,,Yes,Yes
21556,This is a little hack to ignore MCMC dimension in the decoder,,,Yes
21557,## no extraction needed,,,Yes
21559,generalization error (smaller is better),,Yes,Yes
21560,progression (bigger is better),,,Yes
21561,TODO: Fix overlap import with odin.bay here,,,Yes
21563,smaller is better,,Yes,Yes
21564,higher is better,,Yes,Yes
21568,a single columns,,Yes,Yes
21570,use all columns for unique,,Yes,Yes
21572,memory complexity O(n*n*d); better do it on CPU,,,Yes
21573,smaller is better,,Yes,Yes
21574,higher is better,,Yes,Yes
21575,prepare columns,,,Yes
21577,print the log (3 columns text),,No,Yes
21578,generalization error (smaller is better),,Yes,Yes
21580,TODO: still hard for broadcastable here,,Yes,Yes
21583,TODO,,Yes,Yes
21585,memory complexity O(n*n*d); better do it on CPU,,,Yes
21587,higher is better,,Yes,Yes
21588,TODO,,Yes,Yes
21590,TODO: calculate llk and kl here,,No,Yes
21591,Use a stable sorting algorithm so that when alpha is fixed,,,Yes
21592,applying softmax after matmul results much better diversity in the,,No,Yes
21593,Use a stable sorting algorithm so that when alpha is fixed,,Yes,Yes
21594,TODO: check if deepcopy possible here,,No,Yes
21596,Use a stable sorting algorithm so that when alpha is fixed,,Yes,Yes
21600,TODO,,Yes,Yes
21601,TODO: another choice for prior here,,,Yes
21604,>0 <=> improvement (bigger is better),,,Yes
21607,TODO:,,,Yes
21608,TODO: no exactly a dimension reduction method here,,,Yes
21609,TODO,,Yes,Yes
21611,1) Linear scaling is better,,,Yes
21612,2) 0.2 is better than 0.5,,No,Yes
21613,TODO: tf.reduce_any(mi_mask),,,Yes
21615,TODO,,,Yes
21616,reshape to matrix. Apparently for speed -MK,,Yes,Yes
21617,The convention in BERT is:,,No,Yes
21618,FIXME,,,Yes
21619,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21621,propertoes loaded. So here we return 0 if no key property loaded as a workaround,,,Yes
21622,bug fix; scope is an optional attribute,,,Yes
21623,Set missing columns to 0,,Yes,Yes
21624,print('Missing columns:\ || {}'.format(sorted(list(missing_columns)))),,,Yes
21625,TODO: Can we turn <0 into 0 and >1234 into 1234?,,Yes,Yes
21627,Feature transformers that turn Domain DataFrames into protein feature vector matrices,,Yes,Yes
21628,Wrapper for a BGC detection model than handles feature transformation and loading model definitions from JSON,,Yes,Yes
21629,Output of each transformer should be a matrix; merge all columns into one wide matrix,,Yes,Yes
21630,Wrapper for a BGC detection model than handles feature transformation and loading model definitions from JSON,,,Yes
21631,Move file.gbk.part to file.gbk,,Yes,Yes
21635,Move protein_ids and pfam_ids columns to the end,,No,Yes
21636,Find new unique proteid ID if needed,,,Yes
21637,needed for antiSMASH compatibility,,,Yes
21638,TODO add protocluster?,,,Yes
21639,TODO add meta info from all detectors?,,Yes,Yes
21649,TODO: review this and do it in fit also.,,,Yes
21650,TODO: maybe change to: if hasattr(step; 'should_resume'):,,No,Yes
21652,TODO: fix get,,,Yes
21653,TODO:,,No,Yes
21654,TODO: Mixin this or something:,,Yes,Yes
21658,"TODO: replace hard_clip with malleable max and min? also remove in doc if so (search for \""hard clip\"").",,Yes,Yes
21661,TODO: don't do last transform.,,Yes,Yes
21663,TODO: CV and rename to RandomSearchCV.,,No,Yes
21664,TODO: use `self.higher_score_is_better`.,,,Yes
21668,TODO: two return types involves no self2.,,,Yes
21669,TODO: two return values.,,No,Yes
21670,TODO: overwrite steps?,,,Yes
21671,TODO: use MetaStep*s*Mixin (plural) and review.,,Yes,Yes
21674,TODO: skip on error???,,,Yes
21677,TODO: Do we need to add a slicer. Does the data always come as numpy array with time series in axis=1.,,,Yes
21678,TODO: The slicer could a inverse_transform of the joiner. A len method should also be defined.,,Yes,Yes
21683,TODO: is order of ABC good here,,,Yes
21684,TODO: perhaps have some handle_transform functionnality in the future to pass,,Yes,Yes
21687,TODO: perhaps have some handle_transform functionnality in the future to allow,,,Yes
21689,TODO: example comments of how to call this REST API with a **json** data input example. A comment is fine here.,,Yes,Yes
21690,I suggest to delete this todo without care for now.,,No,Yes
21693,TODO: use MetaStep*s*Mixin (plural) and review.,,Yes,Yes
21694,"\""\""\"" || Idea for checkpoints :  ||  ||     The streaming pipeline algorithm could go find the optional checkpoint step for each sub pipeline. ||     In the future; a ResumableStreamingPipeline that extends this class should exist to support checkpoints. ||      ||     The Barrier should ideally join the data so that the ram does not blow up (iterable; lazy loading; cache ??) ||     Maybe we can implement a LazyLoadingDataContainer\/CachedDataContainer class or something that could be returned. ||      ||     pipeline = Pipeline([ ||         MiniBatchSequentialPipeline([ ||  ||             A(); ||             B(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||             C(); ||             D(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||         ]); ||         Model() ||     ]) ||      ||     pipeline = Pipeline([ ||         MiniBatchSequentialPipeline([ ||             ParallelWrapper([ ||                 NonFittableA(); ||                 NonFittableB(); ||             ]) ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||             C(); ||             D(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||         ]); ||         Model() ||     ]) || \""\""\""",,Yes,Yes
21695,TODO: joiner ????????,,No,Yes
21697,TODO,,Yes,Yes
21698,TODO.,,Yes,Yes
21700,TODO DOC: first is root; second is nested; and so on. This is like a stack.,,Yes,Yes
21701,TODO: might move this method elsewhere.,,No,Yes
21704,TODO: doc. First is the most stripped.,,,Yes
21705,TODO: self.hashers = List[BaseHasher]  # TODO: can chain many hashers in a list; just like savers.,,,Yes
21707,Each saver unstrips the step a bit more if needed be.,,,Yes
21709,TODO: `if saver.can_load(self): saver.load_step(self); else: break;` ???,,Yes,Yes
21710,TODO: should we print a warning if it can't ??? but without spamming the console?,,,Yes
21712,TODO: delete steps; but keep their __class__ only and their `.name` only to be able,,,Yes
21718,"\""\""\"" || Idea for checkpoints :  ||  ||     The streaming pipeline algorithm could go find the optional checkpoint step for each sub pipeline. ||     In the future; a ResumableStreamingPipeline that extends this class should exist to support checkpoints. ||      ||     The Barrier should ideally join the data so that the ram does not blow up (iterable; lazy loading; cache ??) ||     Maybe we can implement a LazyLoadingDataContainer\/CachedDataContainer class or something that could be returned. ||      ||     pipeline = Pipeline([ ||         MiniBatchSequentialPipeline([ ||  ||             A(); ||             B(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||             C(); ||             D(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||         ]); ||         Model() ||     ]) ||      ||     pipeline = Pipeline([ ||         MiniBatchSequentialPipeline([ ||             ParallelWrapper([ ||                 NonFittableA(); ||                 NonFittableB(); ||             ]) ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||             C(); ||             D(); ||             Barrier(joiner=Joiner()); ||             [Checkpoint()] ||  ||         ]); ||         Model() ||     ]) || \""\""\""",,Yes,Yes
21719,TODO doc and things,,No,Yes
21720,TODO,,Yes,Yes
21721,TODO.,,,Yes
21722,"TODO: is \"".\/\"" notation safe on windows? we should be compatible.",,,Yes
21723,TODO DOC: first is root; second is nested; and so on. This is like a stack.,,Yes,Yes
21725,TODO:,,,Yes
21726,TODO: perhaps not `not should_save`? review which side of bool we should return.,,Yes,Yes
21728,TODO: self.hashers = List[BaseHasher]  # TODO: can chain many hashers in a list; just like savers.,,,Yes
21729,TODO: is this new method needed? I feel like it might be needed once we'll fix the `Pipeline.fit` methods,,Yes,Yes
21731,TODO: read on this because we might want to override self but inside the saver: https:\/\/stackoverflow.com\/questions\/7940470\/is-it-possible-to-overwrite-self-to-point-to-another-object-inside-self-method,,No,Yes
21732,TODO: `if saver.can_load(self): saver.load_step(self); else: break;` ???,,,Yes
21733,TODO: should we print a warning if it can't ??? but without spamming the console?,,,Yes
21738,TODO: move classes below elsewhere.,,,Yes
21740,TODO: ...,,No,Yes
21741,TODO.,,Yes,Yes
21742,TODO: doc. First is the most stripped.,,Yes,Yes
21745,TODO: `if saver.can_load(self): saver.load_step(self); else: break;` ???,,,Yes
21746,TODO: should we print a warning if it can't ??? but without spamming the console?,,,Yes
21747,TODO: copy? already done in the push. review this.,,Yes,Yes
21748,TODO: delete steps; but keep their __class__ only and their `.name` only to be able,,,Yes
21751,TODO: move classes below elsewhere.,,Yes,Yes
21752,"TODO: CTRL+SHIFT+F for \""stripped_saver: BaseSaver\""",,Yes,Yes
21754,TODO: delete or refactor.,,No,Yes
21755,TODO: talk to guillaume; and make sure he pushed code that compiles,,Yes,Yes
21756,TODO: talk to guillaume about this,,,Yes
21757,TODO: assert something here,,Yes,Yes
21759,Each saver unstrips the step a bit more if needed,,No,Yes
21760,TODO: review ideas below...,,,Yes
21762,TODO: talk to guillaume; and make sure he pushed code that compiles,,,Yes
21764,TODO: talk to guillaume about this,,Yes,Yes
21767,Each saver unstrips the step a bit more if needed,,No,Yes
21768,TODO: review ideas below...,,,Yes
21769,TODO: move classes below elsewhere.,,Yes,Yes
21771,"# TODO: CTRL+SHIFT+F for \""stripped_saver: BaseSaver\""",,,Yes
21772,TODO: talk to guillaume about this,,Yes,Yes
21774,TODO: use self.set_step of the MetaStepMixin instead?,,No,Yes
21776,TODO: change this when we support multiple execution modes and data container ids \/ summary,,Yes,Yes
21777,TODO: save the context by execution mode AND data container ids \/ summary,,Yes,Yes
21778,TODO: change this when we support multiple execution modes and data container ids \/ summary,,Yes,Yes
21780,TODO: change this when we support multiple execution modes and data container ids \/ summary,,,Yes
21782,treats invalid values as having no columns activated. create a temporary column for invalid values,,,Yes
21783,treats invalid values as having no columns activated. create a temporary column for invalid values,,Yes,Yes
21784,treats invalid values as having no columns activated. create a temporary column for invalid values,,,Yes
21785,TODO.,,,Yes
21787,TODO.,,Yes,Yes
21788,todo create a data container for each job; and create a summary id for each job,,Yes,Yes
21789,todo loop through summary id for each jobs,,Yes,Yes
21790,https:\/\/stackoverflow.com\/questions\/24458645\/label-encoding-across-multiple-columns-in-scikit-learn,,Yes,Yes
21791,TODO: change default argument of scoring_function...,,,Yes
21792,TODO: change default argument of scoring_function...,,,Yes
21800,TODO: doc. First is the most stripped.,,Yes,Yes
21803,TODO: doc. First is the most stripped.,,Yes,Yes
21804,todo: when repo.subscribe_to_cache_folder_changes(observer),,,Yes
21806,TODO: verify is for quantized we do not want to do cdf(value higher) - cdf(value lower) to have pdf.,,,Yes
21809,TODO: Distribution Mixture : Treat has a standard distribution or prior distribution is all small gaussian for each distribution in the distribution mixture.,,Yes,Yes
21812,TODO : Rename function to something more meaningful like on_save_trial,,No,Yes
21814,TODO,,,Yes
21817,move training images,,No,Yes
21818,move training images,,,Yes
21819,I load the seaborn library only to benefit the nice looking feature,,Yes,Yes
21820,"and loads it into List of Dataframes with columns of \""Genes\"" and \""Accuracy\""",,Yes,Yes
21821,if len(unused_idxs) > max_experiments - len(final_combos):,,,Yes
21822,\tsamples = random.sample(unused_idxs; max_experiments - len(final_combos)),,,Yes
21823,\tsamples = unused_idxs,,Yes,Yes
21828,TODO: validate args,,No,Yes
21829,TODO: initialize MLP,,No,Yes
21831,labels = Y.columns,,,Yes
21832,labels = Y.columns,,Yes,Yes
21833,labels = Y.columns,,,Yes
21835,labels = Y.columns,,Yes,Yes
21836,labels = Y.columns,,Yes,Yes
21840,labels = Y.columns,,Yes,Yes
21841,labels = Y.columns,,Yes,Yes
21843,labels = Y.columns,,,Yes
21844,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
21845,work-around for Jupyter notebook and IPython console,,No,Yes
21847,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
21848,work-around for Jupyter notebook and IPython console,,No,Yes
21850,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
21852,labels = Y.columns,,Yes,Yes
21853,labels = Y.columns,,,Yes
21857,This is the most pythonic way I know of to split dictionaries,,Yes,Yes
21858,Fix the seed.,,Yes,Yes
21859,don't break columns,,Yes,Yes
21861,TODO: greedy sampling is still buggy!,,Yes,Yes
21862,#                 self.unused_module = torch.nn.Linear(2; 5),,,Yes
21863,TODO: use a nn.Module and call odeint_adjoint to implement higher order derivatives.,,Yes,Yes
21864,self.unused_module = torch.nn.Linear(2; 5),,,Yes
21866,Therefore; it is better to run it on the CPU only.,,,Yes
21867,needed for plotting in 3d,,Yes,Yes
21869,TODO: Remove cast when Keras supports double,,,Yes
21870,TODO: Remove cast when keras supports double,,No,Yes
21873,self.assertEqual(max_abs(func.unused_module.weight.grad); 0),,,Yes
21876,The convention in BERT is:,,,Yes
21877,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
21878,The convention in BERT is:,,No,Yes
21879,"What we really want to return is \""Steve Smith\"".",,No,Yes
21881,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
21883,A lazy way to cope with batch data. Can be more efficient,,No,Yes
21884,dim = 0 [30; xxx] -> [10; ...]; [10; ...]; [10; ...] on 3 GPUs,,Yes,Yes
21886,from -- bigger means better shuffling but slower start up and more,,,Yes
21887,TODO: This seems to be wrong. Fix it!,,,Yes
21890,This is needed because we cannot supply both fn=process_images,,Yes,Yes
21891,TODO: Add padding to image to make it 299x299.,,,Yes
21892,Move image to subdirectory.,,Yes,Yes
21893,Move image to subdirectory.,,Yes,Yes
21894,TODO: Learning rate scheduler,,,Yes
21895,Move image to subdirectory.,,Yes,Yes
21898,TODO: Needs to get fixed.,,Yes,Yes
21900,simple word; no other info needed,,Yes,Yes
21902,TODO take out methods that manage only a couple of provided strings,,,Yes
21904,TODO manage the slot value names,,,Yes
21905,Find the alternative slot value name if needed,,,Yes
21908,TODO make this reflect the state of the symbols defined before,,,Yes
21909,simple word; no other info needed,,,Yes
21910,Find the alternative slot value name if needed,,Yes,Yes
21911,TODO shouldn't generate twice the same statement,,Yes,Yes
21913,TODO keep track of already generated sentences (+max nb of attempts),,,Yes
21917,TODO manage alt slot name,,Yes,Yes
21919,TODO do this even for words,,Yes,Yes
21921,TODO check variation names are not reserved,,No,Yes
21922,Find the alternative slot value name if needed,,,Yes
21923,TODO change this,,,Yes
21924,TODO randgen name,,Yes,Yes
21925,TODO seems to be a problem with this,,No,Yes
21927,TODO improve the regex here,,Yes,Yes
21928,TODO casegen,,No,Yes
21929,TODO,,,Yes
21930,TODO check the type of each choice?,,Yes,Yes
21934,TODO should escapement be removed from there?,,No,Yes
21935,TODO check this with arg,,No,Yes
21936,self.alias_definitions = []  # TODO redo as OOP,,,Yes
21937,TODO,,Yes,Yes
21940,TODO this should be an error,,No,Yes
21941,TODO move this into unit defintions,,No,Yes
21943,TODO keep track of which randgen have been generated,,Yes,Yes
21944,TODO I think there is a bug in here,,No,Yes
21945,All possibilities will be generated TODO,,,Yes
21946,TODO check that this example hasn't been generated already,,,Yes
21949,TODO redo as OOP,,Yes,Yes
21950,TODO this code is broken,,Yes,Yes
21952,TODO check the type of each choice?,,Yes,Yes
21953,NOTE: deepcopy is needed to avoid rewriting on old data,,,Yes
21957,TODO: change the symbol to a variable from parser_utils,,No,Yes
21958,TODO: list comprehension,,No,Yes
21960,TODO: list comprehension,,No,Yes
21962,TODO check this with arg,,,Yes
21963,TODO this should be an error,,No,Yes
21964,TODO: manage variations,,No,Yes
21965,TODO: manage the slot value as well,,,Yes
21968,TODO: change the symbol to a variable from parser_utils,,,Yes
21969,All possibilities will be generated TODO,,No,Yes
21970,TODO: deprecate and rather use '|',,No,Yes
21971,"all_rules.extend(definition[variation][\""rules\""])  # TODO manage arg",,,Yes
21973,"HACK: Keep \""text\"" after having called `entity_to_rasa`",,,Yes
21975,TODO: find another way,,,Yes
21976,TODO: Add '\\t'?,,,Yes
21979,TODO DummySlotVal absolutely need to be managed differently,,Yes,Yes
21980,TODO,,,Yes
21981,TODO replace parser by self definition,,No,Yes
21982,TODO replace SubRuleType by UnitType,,No,Yes
21983,UNUSED IN NEW PARSER,,No,Yes
21984,Note there might be better ways to do this with regexes,,Yes,Yes
21985,# UNUSED IN NEW PARSER,,No,Yes
21986,UNUSED IN NEW PARSER,,No,Yes
21991,TODO support variation names and argument values,,Yes,Yes
21992,TODO cache this,,No,Yes
21995,Write to the file if needed,,No,Yes
21996,TODO support variations,,,Yes
21998,TODO support variations,,No,Yes
21999,TODO,,,Yes
22000,TODO support variations,,,Yes
22004,TODO remove the following because you should allow ? and \/ in declarations?,,,Yes
22006,TODO use this,,,Yes
22007,TODO this fix might be improved thanks to master_file_paths,,Yes,Yes
22010,TODO,,Yes,Yes
22012,Add example if needed,,,Yes
22013,Remove example if needed,,No,Yes
22014,TODO there could be a better way to use ast (singleton?),,Yes,Yes
22015,TODO make this a generator?,,Yes,Yes
22017,TODO Add LineCountFileWrapper in here,,Yes,Yes
22018,"\""\""\"" || Module `chatette.refactor_parsing.lexing.lexing_rule` || Contains the class that represent a lexing rule || in charge of checking if the rule it represents matches the input; || transforms it to labelled tokens and formulates the error if needed. || Therefore; each instance is stateful. || \""\""\""",,Yes,Yes
22019,TODO TMP,,No,Yes
22020,TODO TMP DEBUG,,No,Yes
22023,TODO find how to get this info,,,Yes
22025,TODO not sure `extract_identifier` is the best thing to use here,,,Yes
22027,TODO keep `self._furthest_matched_index` up-to-date,,No,Yes
22028,TODO maybe making a function for this would be useful,,No,Yes
22029,TODO this code doesn't seem very clean (should refactor),,Yes,Yes
22030,TODO fix the problem that choice have no by design name,,,Yes
22031,TODO put it in modifiers,,No,Yes
22033,TODO find out what this was supposed to do in old code,,,Yes
22040,TODO wouldn't it be better with a set rather than a list?,,Yes,Yes
22041,TODO keep the randgen mapping in the example? Id. for the other ones?,,Yes,Yes
22042,TODO there might be a more optimized way to do that,,,Yes
22043,TODO add a check for modifiers,,No,Yes
22044,else:  # TODO check that the variation wasn't already in there,,,Yes
22045,TODO add variation to unit,,No,Yes
22046,TODO decide what to do with `variation_name`,,,Yes
22047,HACK used by slot to prevent code duplication,,No,Yes
22049,TODO there may be a better way to get the file name,,Yes,Yes
22050,TODO,,Yes,Yes
22052,TODO do this when the new arg assignment lexing rule has been coded,,No,Yes
22053,TODO move that into AST,,,Yes
22054,TODO move that into AST,,Yes,Yes
22055,TODO opposite randgen,,Yes,Yes
22056,TODO replace this with a (stateful) iterator to make it more readable,,,Yes
22058,TODO move this out of this file and into the lexing file itself,,No,Yes
22061,TODO this looks weird; look into this,,Yes,Yes
22062,Gives a general idea of what the API has stored in it at any given moment,,Yes,Yes
22063,Wtf does this do outside Windows?,,Yes,Yes
22066,things a bit; but it would work and that'd probably,,Yes,Yes
22068,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,Yes,Yes
22070,TODO: Input plugin system goes here,,Yes,Yes
22072,Eventually I want people to be able to build custom behavior,,,Yes
22073,TODO: Move plugins to a priority system,,,Yes
22076,May eventually become unnecessary as plugins could be built to,,,Yes
22077,TODO: Output plugin system goes here,,,Yes
22078,Implement stateful ConvLSTM,,,Yes
22079,ppm (20 better) # instead of absolute 0.01 Da,,,Yes
22081,a faster way is to process them in parallel; but hard to debug,,Yes,Yes
22082,move load\/build db here?,,Yes,Yes
22084,convert the mass and tolerance to a range of columns of knapsack_matrix,,Yes,Yes
22085,found by cross-validation; TODO: don't hard-code,,Yes,Yes
22086,dev requirements are needed for training the model,,No,Yes
22088,number of columns.,,Yes,Yes
22090,For convenience; they also download the requested files if needed.,,Yes,Yes
22091,following the shape convention: (examples; channels; rows; columns),,,Yes
22092,by convention; use 2 as OOV word,,Yes,Yes
22095,# Variable Scope fix for older TF,,,Yes
22096,# Fix TF 0.12,,,Yes
22099,TODO,,Yes,Yes
22101,TODO pay attention to main.py; cuz it is also controlled there,,Yes,Yes
22103,; LstmRolloutAgent TODO,,Yes,Yes
22104,TODO pay attention to main.py; cuz it is also controlled there,,Yes,Yes
22105,TODO revise the use_gpu in the config,,Yes,Yes
22110,TODO it appears this is very very important,,No,Yes
22111,TODO revise the use_gpu in the config,,,Yes
22112,TODO attn,,Yes,Yes
22114,; LstmRolloutAgent TODO,,,Yes
22115,TODO pay attention to main.py; cuz it is also controlled there,,,Yes
22116,; LstmRolloutAgent TODO,,,Yes
22122,FIXME FATAL ERROR HERE !!!,,Yes,Yes
22124,TODO switch of mask,,,Yes
22125,TODO mask,,Yes,Yes
22127,TODO if beam search; repeat the initial states of the RNN,,Yes,Yes
22128,TODO FIXME,,Yes,Yes
22129,TODO,,Yes,Yes
22130,TODO temperature,,Yes,Yes
22131,TODO backward compatible; if batch_size == 1; we remove the nested structure,,,Yes
22137,TODO connector,,,Yes
22138,FIXME fatal error here!,,Yes,Yes
22139,TODO car type?,,No,Yes
22141,layers needed,,No,Yes
22142,layers needed,,,Yes
22143,''' ||     Load model exported by python2 with python3 will cause error: ||         ascii' codec can't decode byte 0xda in position 5 ||     The following codes will fix the bug || ''',,No,Yes
22144,TODO: make efficient,,Yes,Yes
22150,"\""\""\""\r || Created on Sun Sep 03 17:11:13 2017\r || \r || @author: Dhebar\r || modified by: Zhichao Lu 02-18-2018\r || \""\""\""",,Yes,Yes
22151,"\""\""\""\r || Created on Tue Sep 05 14:40:18 2017\r || \r || @author: Zhichao\r || \r || the selection is based on the 'dominance' check. Rank information is \r || considered obsolete here\r || \""\""\""",,No,Yes
22152,TODO: Add legend (?),,No,Yes
22154,This is not the first instance; use the (out; out) convention.,,,Yes
22156,This is not the first instance; use the (out; out) convention.,,Yes,Yes
22159,TODO: Add legend (?),,No,Yes
22160,if we divided by zero because all values in one columns are equal replace by none,,Yes,Yes
22161,TODO: would be good to add ref from source,,Yes,Yes
22162,TODO: add textract check,,No,Yes
22163,TODO: add filter?,,No,Yes
22166,check columns,,,Yes
22167,TODO add extra code here,,,Yes
22169,This is needed since the notebook is stored in the object_detection folder.,,,Yes
22171,Follow the convention by adding back the batch dimension,,,Yes
22172,This is needed to display the images.,,No,Yes
22173,This is needed since the notebook is stored in the object_detection folder.,,,Yes
22174,TODO: make reshape an option for the clip_to_window op,,,Yes
22176,TODO: Make this a public api in slim arg_scope.py.,,No,Yes
22179,TODO: Handle the case where some boxes in selected_boxes do not,,Yes,Yes
22180,TODO: num_predictions_per_location could be moved to constructor.,,Yes,Yes
22182,TODO: Merge the implementation with ConvolutionalBoxPredictor above,,Yes,Yes
22184,TODO: This method is needed because the current,,,Yes
22185,Remember original dtype to so we can convert back if needed,,No,Yes
22191,This is needed to display the images.,,,Yes
22192,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
22194,TODO: result_dict contains batches of images; while,,No,Yes
22198,in the dictionary must implement,,,Yes
22200,Unused by updated loading code.,,Yes,Yes
22202,"\""\""\""Argmax matcher implementation. ||  || This class takes a similarity matrix and matches columns to rows based on the || maximum value per column. One can specify matched_thresholds and || to prevent columns from matching to rows (generally resulting in a negative || training example) and unmatched_theshold to ignore the match (generally || resulting in neither a positive or negative training example). ||  || This matcher is used in Fast(er)-RCNN. ||  || Note: matchers are used in TargetAssigners. There is a create_target_assigner || factory function for popular implementations. || \""\""\""",,,Yes
22203,Get logical indices of ignored and unmatched columns as tf.int64,,Yes,Yes
22204,TODO: add_summaries is currently unused. Respect that directive,,No,Yes
22206,TODO: add_summaries is currently unused. Respect that directive,,No,Yes
22207,Needed for fine-tuning from classification checkpoints whose,,Yes,Yes
22208,TODO: handle agnostic mode and positive\/negative class,,No,Yes
22210,TODO: Only fixed_shape_resizer is currently supported for NASNet,,No,Yes
22211,TODO: Figure out if it is needed when image,,No,Yes
22213,TODO: Enable fused batch norm once quantization supports it.,,,Yes
22214,TODO: Change resnet endpoint to strip scope prefixes instead,,Yes,Yes
22215,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
22217,TODO: find the optimal block_length.,,,Yes
22219,TODO: Consider replacing with tf.contrib.filter_variables in,,Yes,Yes
22221,The convention in BERT is:,,,Yes
22223,The convention in BERT is:,,No,Yes
22226,no. of consecutive matches needed to establish a track,,,Yes
22227,once we refactor Faster RCNN models to set is_training through an outer,,Yes,Yes
22228,This is needed to display the images.,,No,Yes
22230,TODO(rathodv): Come up with a better way to generate scope names,,,Yes
22231,TODO(mttang): This method is needed because the current,,Yes,Yes
22235,A dictionary of metric names to classes that implement the metric. The classes,,,Yes
22236,in the dictionary must implement,,Yes,Yes
22238,This is needed since the notebook is stored in the object_detection folder.,,Yes,Yes
22239,This is needed to display the images.,,,Yes
22241,"\""\""\""Argmax matcher implementation. ||  || This class takes a similarity matrix and matches columns to rows based on the || maximum value per column. One can specify matched_thresholds and || to prevent columns from matching to rows (generally resulting in a negative || training example) and unmatched_theshold to ignore the match (generally || resulting in neither a positive or negative training example). ||  || This matcher is used in Fast(er)-RCNN. ||  || Note: matchers are used in TargetAssigners. There is a create_target_assigner || factory function for popular implementations. || \""\""\""",,,Yes
22242,Get logical indices of ignored and unmatched columns as tf.int64,,Yes,Yes
22244,TODO(rathodv): add_summaries is currently unused. Respect that directive,,,Yes
22245,Needed for fine-tuning from classification checkpoints whose,,Yes,Yes
22246,TODO(chensun): Figure out if it is needed when image,,Yes,Yes
22247,"\""\""\"" || Author: Dan Salo || Initial Commit: 12\/1\/2016 ||  || Purpose: Implement Convolutional Multiple Instance Learning for distributed learning over MNIST dataset || \""\""\""",,No,Yes
22248,data_directory not needed,,,Yes
22249,data_directory not needed,,,Yes
22250,TODO not working,,Yes,Yes
22251,TODO: Update folder structure,,Yes,Yes
22253,TODO: SD of the mean or what?,,Yes,Yes
22255,# TODO Not Working,,,Yes
22257,TODO: Add magic number support,,,Yes
22258,Fix the shape to the one I expect,,No,Yes
22259,TODO: Need review,,Yes,Yes
22260,TODO: Loop and averaging should be done with tensorflow instead of np or python,,No,Yes
22261,TODO: need to better deal with shape issue,,Yes,Yes
22264,increased to 100 due to high performance VI on GPU implemented on 14 April 2018 (Henry),,Yes,Yes
22266,need to fix the initial weights list shape issue sometimes,,Yes,Yes
22268,TF 1.12.0 bug workaround,,,Yes
22270,TF 1.12.0 bug workaround,,No,Yes
22273,TODO: need to take a look at this for tf2,,No,Yes
22277,XXX seems to be a dead branch,,,Yes
22281,detect if line ends are consistent in source file,,,Yes
22282,TODO: What is 3s????,,No,Yes
22285,TODO: allow named inputs too??,,Yes,Yes
22286,TODO: handle named output in the future,,Yes,Yes
22288,check if the current computed time indices less than total inices needed,,No,Yes
22289,inject custom training step if needed,,,Yes
22290,inject custom training step if needed,,Yes,Yes
22292,TODO: something is wrong here,,,Yes
22293,inject custom training step if needed,,,Yes
22295,check if the current computed time indices less than total inices needed,,No,Yes
22297,back up information we need for efficient backprop,,,Yes
22299,bad things are probably happening; break out,,Yes,Yes
22300,greedy inference. lets write it up independently; should be bit faster and simpler,,,Yes
22301,bad things are probably happening; break out,,Yes,Yes
22305,This yeilds the best performance; not sure why,,Yes,Yes
22306,this flush method is needed for python 3 compatibility.,,,Yes
22310,TODO: check if the variable scope is useless because there is no new variables here,,,Yes
22311,TODO: Performance: Concatenate all inputs together and then split them; in that case,,No,Yes
22312,TODO: Monitor: Here we could add summaries on the scores of corrupt tails and corrupt heads individually,,Yes,Yes
22313,TODO: Performance: concatenate these together to speed up,,No,Yes
22314,TODO: Performance: split these into batches using map_fn to reduce the memory usage,,No,Yes
22315,TODO: remove check numeric,,,Yes
22316,TODO: Correctness: the max_content_len is used for limiting the memory consumption; and therefore,,Yes,Yes
22317,TODO: Performance: Move the reindexing to pre-processing due to the high cost,,No,Yes
22318,TODO: Performance: If eval_targets_set is too large; break it into small batches instead,,No,Yes
22319,TODO: add a semantic background embedding extracted from content;,,Yes,Yes
22320,Release memory before the function ends,,No,Yes
22321,TODO: check if the variable scope is useless because there is no new; global variables here,,,Yes
22322,and engineering hack; the correct way should be without replacement.),,No,Yes
22323,TODO: Performance: Concatenate all inputs together and then split them; in that case,,,Yes
22324,TODO: Monitor: Here we could add summaries on the scores of corrupt tails and corrupt heads individually,,,Yes
22325,and engineering hack; the correct way should be without replacement.),,No,Yes
22326,TODO: add a semantic background embedding extracted from content;,,,Yes
22328,"\""\""\"" || Created on Sat Sep 16 15:12:46 2017 ||  || @author: Administrator || \""\""\""",,,Yes
22329,adjust the constant as needed,,No,Yes
22332,implement of global spatial attention,,,Yes
22334,implement of temporal attention,,Yes,Yes
22335,Needed for reshaping.,,Yes,Yes
22337,the implement of decoder,,Yes,Yes
22340,fix batch norm nodes,,,Yes
22342,left edge crossed; move right.,,Yes,Yes
22343,right edge crossed; move left.,,,Yes
22344,top edge crossed; move down.,,Yes,Yes
22345,bottom edge crossed; move up.,,,Yes
22346,Move box down.,,Yes,Yes
22350,TODO Change path to v1.1,,No,Yes
22352,Move box down.,,Yes,Yes
22353,"\""\""\"" || Preprocessing script to extract actions; rewards; ground truth from text files ||  || TODO: negative rewards || TODO: preprocess images ? || \""\""\""",,,Yes
22354,TODO: negative rewards,,,Yes
22358,#FIX,,No,Yes
22359,TODO toPlot = get_states_for_images(specific_images),,Yes,Yes
22360,FIX,,,Yes
22361,TODO: add vertical color bar for representing reward values  https:\/\/matplotlib.org\/examples\/api\/colorbar_only.html,,Yes,Yes
22364,TODO : extend for other datasets for comparison; e.g. babbling.,,No,Yes
22368,a=fig.add_subplot(rows_in_mosaic; columns_in_mosaic; 4+i)#2+i),,,Yes
22369,TODO,,,Yes
22372,not needed any longer with read_config()  #data_folder = get_data_folder_from_model_name(path_to_model)  # DEFAULT_DATASET,,Yes,Yes
22373,not needed any longer with read_config()  #data_folder = get_data_folder_from_model_name(path_to_model),,Yes,Yes
22374,not needed any longer with read_config()  #\t    data_folder = get_data_folder_from_model_name(path_to_model),,No,Yes
22378,TODO : AT THE MOMENT THE SPEED IS TOO FAST; SO using GIFMAKER.ME INSTEAD,,,Yes
22382,; columns = header)   print mse_df.head()    print models_df.head(),,,Yes
22384,not used yet; TODO,,,Yes
22385,# TODO: does not work properly; plus needs imageio installation; GIF created has to be rendered slower; other ideas in https:\/\/stackoverflow.com\/questions\/24688802\/saving-an-animated-gif-in-pillow,,Yes,Yes
22386,#TODO toPlot = get_states_for_images(specific_images),,Yes,Yes
22387,#FIX,,,Yes
22389,FIX,,Yes,Yes
22390,TODO: add vertical color bar for representing reward values  https:\/\/matplotlib.org\/examples\/api\/colorbar_only.html,,Yes,Yes
22393,TODO : extend for other datasets for comparison; e.g. babbling.,,No,Yes
22395,TODO: 1d plot + PCA for more dimensions,,,Yes
22397,not used yet; TODO,,,Yes
22398,# TODO: does not work properly; plus needs imageio installation; GIF created has to be rendered slower; other ideas in https:\/\/stackoverflow.com\/questions\/24688802\/saving-an-animated-gif-in-pillow,,,Yes
22399,#TODO toPlot = get_states_for_images(specific_images),,Yes,Yes
22400,#FIX,,No,Yes
22405,plt.colorbar()  #TODO WHY IT DOES NOT SHOW AND SHOWS A PALETTE INSTEAD?,,,Yes
22406,TODO : extend for other datasets for comparison; e.g. babbling.,,No,Yes
22409,TODO everywhere else is use_cuda; change; but keep to default true (use_cuda = true)?,,,Yes
22411,not used yet; TODO,,Yes,Yes
22412,# TODO: does not work properly; plus needs imageio installation; GIF created has to be rendered slower; other ideas in https:\/\/stackoverflow.com\/questions\/24688802\/saving-an-animated-gif-in-pillow,,,Yes
22413,#TODO toPlot = get_states_for_images(specific_images),,Yes,Yes
22414,#FIX,,No,Yes
22415,TODO toPlot = get_states_for_images(specific_images),,,Yes
22416,FIX,,Yes,Yes
22418,TODO make function based on rewards_cardinal AND dataset,,No,Yes
22419,plt.colorbar()  #TODO WHY IT DOES NOT SHOW AND SHOWS A PALETTE INSTEAD?,,,Yes
22420,TODO : extend for other datasets for comparison; e.g. babbling.,,No,Yes
22423,th.cuda.set_device(1)  # Mat Uses 0; Tim 1   In most cases it\u2019s better to use CUDA_VISIBLE_DEVICES environmental variable.,,,Yes
22425,TODO everywhere else is use_cuda; change; but keep to default true (use_cuda = true)?,,Yes,Yes
22426,TODO save EXPERIMENT_PATH to  CONFIG.json file,,No,Yes
22428,TODO: 1d plot,,No,Yes
22429,TODO: use a validation set,,No,Yes
22432,subplot: (i; j; k) ith plot; j rows; k columns,,Yes,Yes
22434,Apparently due to seg fault,,Yes,Yes
22435,Remove `data\/` from the path if needed,,,Yes
22436,TODO: normalize true states,,Yes,Yes
22439,TODO: add squeezeNet support,,No,Yes
22443,TODO: plot reconstructed image,,No,Yes
22445,TODO: plot reconstructed image,,No,Yes
22448,TODO WIP temp_coherence_loss # assumes all sequences in the dataset share at least one same 3D pos of Baxter arm,,Yes,Yes
22449,TODO: DOCUMENT THE DATA TYPE HERE; IT IS NOT TRIVIAL; e.g.: list of arrays; each containing one pair of observation ids,,,Yes
22450,Final [0] gives the array of row indexes where condition is true ([1] gives columns),,Yes,Yes
22452,TODO WIP temp_coherence_loss,,No,Yes
22453,TODO: DOCUMENT THE DATA TYPE HERE; IT IS NOT TRIVIAL; e.g.: list of arrays; each containing one pair of observation ids,,Yes,Yes
22454,Final [0] gives the array of row indexes where condition is true ([1] gives columns),,Yes,Yes
22457,(not needed when plotting or predicting states),,,Yes
22463,TODO WIP temp_coherence_loss,,No,Yes
22466,Final [0] gives the array of row indexes where condition is true ([1] gives columns),,,Yes
22467,Clip to fix numeric imprecision (1e-09 = 0),,Yes,Yes
22469,Remove `data\/` from the path if needed,,,Yes
22470,TODO: normalize true states,,Yes,Yes
22473,TODO: Remove as soon as possible (only here for backward compatibility),,No,Yes
22474,TODO: use a validation set,,No,Yes
22475,TODO: use a validation set,,,Yes
22477,TODO: Remove as soon as possible (only here for backward compatibility),,No,Yes
22478,TODO: implement residual connection,,Yes,Yes
22479,TODO: freeze less layers,,Yes,Yes
22480,TODO: freeze less layers,,Yes,Yes
22484,TODO: implement residual connection,,,Yes
22485,TODO: implement residual connection,,Yes,Yes
22486,TODO: add squeezeNet support,,No,Yes
22487,TODO: freeze less layers,,,Yes
22489,TODO: implement residual connection,,,Yes
22490,TODO: add squeezeNet support,,No,Yes
22491,TODO: freeze less layers,,,Yes
22492,TODO: implement residual connection,,Yes,Yes
22493,TODO: balance the two classes,,No,Yes
22494,TODO: balance the two classes,,,Yes
22496,TODO: classification accuracy\/loss,,,Yes
22497,TODO: classification accuracy\/loss,,No,Yes
22498,TODO: add squeezeNet support,,No,Yes
22499,TODO: freeze less layers,,Yes,Yes
22502,TODO: classification accuracy\/loss,,,Yes
22504,Preprocessing if needed,,,Yes
22507,TODO: Remove as soon as possible (only here for backward compatibility),,,Yes
22512,TODO: classification accuracy\/loss,,No,Yes
22513,Temp bug fix for dataloader,,Yes,Yes
22514,TODO: add square here to have the real KNN-MSE formula,,Yes,Yes
22518,TODO: add square here to have the real KNN-MSE formula,,Yes,Yes
22520,TODO: try with .detach() to give all the state to the decoder,,,Yes
22521,TODO: try with .detach() to give all the state to the decoder,,No,Yes
22523,TODO: try with .detach() to give all the state to the decoder,,,Yes
22524,Remove `data\/` from the path if needed,,Yes,Yes
22525,Remove `data\/` from the path if needed,,,Yes
22528,TODO: replace with mse_loss when new release is out.,,Yes,Yes
22529,Update previous dimension only if needed,,,Yes
22530,TODO: Mask dimensions,,,Yes
22532,TODO: correct indices,,No,Yes
22533,TODO: correct names (when sharing dimensions),,No,Yes
22535,TODO: make efficient,,,Yes
22536,TODO: key name may be changed,,,Yes
22541,TODO: reset canvas,,No,Yes
22543,TODO: draw triangle; rectangle; oval; text,,Yes,Yes
22545,"'''MobileNet in PyTorch. ||  || See the paper \""MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\"" || for more details. || '''",,No,Yes
22547,"'''ShuffleNetV2 in PyTorch. ||  || See the paper \""ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"" for more details. || '''",,Yes,Yes
22548,container is in [first_conv_idx - 3] apparently.,,,Yes
22549,TODO,,Yes,Yes
22550,"\""\""\"" || #TODO || indian_number_system = { ||     'zero': 0; ||     'one': 1; ||     'two': 2; ||     'three': 3; ||     'four': 4; ||     'five': 5; ||     'six': 6; ||     'seven': 7; ||     'eight': 8; ||     'nine': 9; ||     'ten': 10; ||     'twenty': 20; ||     'thirty': 30; ||     'forty': 40; ||     'fifty': 50; ||     'sixty': 60; ||     'seventy': 70; ||     'eighty': 80; ||     'ninety': 90; ||     'hundred': 100; ||     'thousand': 1000; ||     'lac': 100000; ||     'lakh': 100000; ||     'crore': 10000000 || } || \""\""\""",,No,Yes
22553,by the more efficient DeRemer and Pennello algorithm.,,Yes,Yes
22554,"consider to be good Python \""coding style.\""   Modify the code at your",,Yes,Yes
22555,=== User configurable parameters ===,,Yes,Yes
22557,unused_terminals(),,Yes,Yes
22558,unused_rules(),,No,Yes
22559,unused_precedence(),,,Yes
22560,"DeRemer; F. L.; and T. J. Pennelo: \""Efficient Computation of LALR(1)",,No,Yes
22561,If so; fix the tabmodule setting so that tables load correctly,,,Yes
22563,move,,Yes,Yes
22564,workaround for duplicated logs in ipython,,Yes,Yes
22565,workaround for duplicated logs in ipython,,,Yes
22569,TODO: remove this,,No,Yes
22570,TODO,,Yes,Yes
22571,TODO,,Yes,Yes
22572,TODO,,Yes,Yes
22574,seed for a pseudo-random number generator; perhaps?,,Yes,Yes
22575,This method is unused,,No,Yes
22576,TODO: How about BuildHyperNEATPhenotype instead,,Yes,Yes
22579,TODO: let key be a part of the experiment spec,,Yes,Yes
22582,TODO: have a call that can do this for all at once instead,,No,Yes
22585,TODO: this method may be removed in the future,,Yes,Yes
22586,TODO: remove,,No,Yes
22587,TODO: this should be removed,,,Yes
22588,visualize.. TODO: remove,,,Yes
22589,TODO: let key be a part of the experiment spec,,,Yes
22590,TODO: generalize,,No,Yes
22592,TODO: proper parsing and handling. These are single numbers.,,No,Yes
22595,TODO: implement patience for multi-objective fitness,,No,Yes
22596,TODO,,,Yes
22598,Python 2 and 3 compatibility hack,,Yes,Yes
22599,TODO: try cPickle. it might be faster.,,,Yes
22600,TODO: add ksmps argument,,No,Yes
22603,TODO: label could be more informative,,Yes,Yes
22604,TODO: actually use this,,,Yes
22605,Python 2 and 3 compatibility hack,,,Yes
22607,todo,,No,Yes
22608,Only forward pass; hence no grads needed,,,Yes
22610,pt3_needed = oppositeOrientation3 - pt2_has,,Yes,Yes
22611,"print(\""hack in evaluate! remove this!\"")",,Yes,Yes
22612,TODO how to add image_type and preprocessing_dict as addition arg in map function,,,Yes
22614,"\""\""\""DA-RNN model initialization. ||  || @author Zhenye Na 05\/21\/2018 ||  || References: ||     [1] Yao Qin; Dongjin Song; Haifeng Chen; Wei Cheng; Guofei Jiang; Garrison W. Cottrell. ||         \""A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction\"" ||         arXiv preprint arXiv:1704.02971 (2017). ||  || \""\""\""",,,Yes
22615,Fix the warning about non-contiguous memory,,,Yes
22617,TODO: apenas tuplos da rela\u00E7\u00E3o de interesse: ORG-LOC; ou PER-ORG,,Yes,Yes
22618,todo: this should be actually changed if we want to be able to,,,Yes
22619,TODO: s\u00F3 estou a usar o primeiro pattern; a frase pode ter mais,,Yes,Yes
22620,todo: this should be actually changed if we want to be able to,,Yes,Yes
22621,TODO,,,Yes
22622,TODO: select what goes and what goes not,,,Yes
22624,TODO: so estou a usar o primero pattern,,,Yes
22625,TODO: alternative; use average,,Yes,Yes
22627,TODO: s\u00F3 estou a usar 1 vector,,No,Yes
22630,TODO: s\u00F3 estou a usar o primeiro pattern; a frase pode ter mais,,Yes,Yes
22631,TODO: e se o tuple foi extraido anteriormente por este mesmo extraction pattern ?,,,Yes
22632,TODO: t e extraction_pattern nao podem ser vazios,,Yes,Yes
22633,TODO: aplicar a formula do Snowball,,,Yes
22635,TODO: remove punctuation; commas; etc.,,,Yes
22636,TODO: avoid keeping all documents in memory,,,Yes
22640,TODO: imprimir os padroes que extrairem este tuplo,,,Yes
22643,"TODO: novos patterns adicionados s\u00E3o tidos em considera\u00E7\u00E3o\""",,Yes,Yes
22644,TODO: make sure no repeated patterns are added,,Yes,Yes
22650,TODO:,,No,Yes
22653,TODO: remover stopwords do r.between,,No,Yes
22654,TODO: ver como calcular o threshold,,No,Yes
22655,TODO:,,No,Yes
22656,TODO: remover stopwords do r.between,,,Yes
22658,TODO: usar string matching entre as entidades: https:\/\/www.cs.cmu.edu\/~pradeepr\/papers\/ijcai03.pdf,,,Yes
22660,TODO: limpar as entidades ao carregar: v\u00EDrgulas; parentesis; etc.,,,Yes
22661,TODO: ver como calcular o threshold,,No,Yes
22667,TODO: fazer stemming ou normaliza\u00E7\u00E3o da palavra a usar no query,,Yes,Yes
22669,TODO: usar string matching entre as entidades: https:\/\/www.cs.cmu.edu\/~pradeepr\/papers\/ijcai03.pdf,,Yes,Yes
22670,TODO: usar a expans\u00E3o de acr\u00F3nimos; usar apenas acr\u00F3nimos da lista n\u00E3o \u00E2mbiguos,,Yes,Yes
22676,TODO: qual o melhor valor de threshold ?,,No,Yes
22678,TODO: usar a expans\u00E3o de acr\u00F3nimos; usar apenas acr\u00F3nimos da lista n\u00E3o \u00E2mbiguos,,Yes,Yes
22679,TODO: isto d\u00E1 igual: implementar o __eq__ numa relationships,,,Yes
22686,TODO: usar a expans\u00E3o de acr\u00F3nimos; usar apenas acr\u00F3nimos da lista n\u00E3o \u00E2mbiguos,,Yes,Yes
22694,TODO: string approximation matching,,Yes,Yes
22700,"TODO: ignore relationships where between is: \"";\"" \""(\""; \"")\"" ; stopwords",,Yes,Yes
22701,TODO: qual o valor ideal do PMI ?,,,Yes
22703,TODO:,,,Yes
22704,TODO: AirAsia         founder         Fernandes,,,Yes
22705,TODO: Tony Fernandes\tOrganization founded\tAirAsia,,Yes,Yes
22707,TODO: Tony Fernandes\tOrganization founded\tAirAsia,,,Yes
22712,TODO: contar com adjectivos pelo meio,,Yes,Yes
22713,TODO: The pattern limits the relation to be a verb (e.g.; invented); a verb followed immediately by,,Yes,Yes
22714,TODO: contar com adjectivos pelo meio,,Yes,Yes
22718,TODO: combinar as duas coisas; usando as palavras antes e depois em conjunto com o padr\u00E3o de Reverb.,,Yes,Yes
22720,TODO: contar com adjectivos pelo meio,,Yes,Yes
22723,TODO: a m\u00E9dia dos embeddings BEFORE; MIDDLE; e AFTER (e.g.; usando duas palavras antes\/depois da primeira\/segunda entidade);,,,Yes
22724,TODO:,,No,Yes
22725,TODO: use DBSCAN instead of Single-Pass Clustering,,Yes,Yes
22726,TODO: use DBSCAN instead of Single-Pass Clustering,,,Yes
22727,todo: this should be actually changed if we want to be able to,,,Yes
22730,TODO: use DBSCAN instead of Single-Pass Clustering,,,Yes
22732,"TODO: novos patterns adicionados s\u00E3o tidos em considera\u00E7\u00E3o\""",,Yes,Yes
22733,TODO,,,Yes
22734,TODO: fazer o merge tendo em considera\u00E7\u00E3o todos os contextos,,,Yes
22735,TODO: maybe the relational words can be in the BEF or AFT context,,,Yes
22736,TODO: maybe use other contexts for evaluation: rel.bef_words; rel.bet_words; rel.aft_words,,No,Yes
22737,TODO: this can be improved; lookt at failed matches to understand what is missing,,Yes,Yes
22739,"forced hack since _'s_ is always tagged as VBZ; (u\""'s\""; 'VBZ') and causes ReVerb to identify",,Yes,Yes
22740,TODO: before printing check the entities type,,No,Yes
22744,TODO: usar isto,,,Yes
22745,NOTE: this works; but probably can be done in a much cleaner way,,No,Yes
22746,TODO: isto \u00E9 passive voice!,,Yes,Yes
22750,Making a 2-D array only works if all the columns are the,,Yes,Yes
22751,This is actually more efficient because boxplot converts,,Yes,Yes
22754,TODO: simple sum or average,,Yes,Yes
22756,TODO: fazer ao contr\u00E1rio; come\u00E7ar com t2,,,Yes
22757,TODO: fazer ao contr\u00E1rio; come\u00E7ar com t2,,,Yes
22758,TODO: this can be done much quickly by looking at the Tree structure,,No,Yes
22759,TODO: com fcm; dist\u00E2ncia entre entidades na frase importa?,,Yes,Yes
22761,TODO: this can be done much quickly by looking at the Tree structure,,No,Yes
22763,TODO: comparision of this type of objects; list of matrices,,Yes,Yes
22769,NOTE: this works; but probably can be done in a much cleaner way,,No,Yes
22772,TODO: usar seeds em que e1; faz match com varios e2; e alterar a forma,,,Yes
22773,TODO: melhorar esta lista; incluir mais profiss\u00F5es?,,,Yes
22774,TODO: ver tambem as bigrams,,Yes,Yes
22775,TODO: ver como eh feita a subtrac\u00E7\u00E3o de conjuntos,,No,Yes
22778,TODO: ver tambem as bigrams,,Yes,Yes
22779,TODO: actualizar aqui a confidence dos padroes,,Yes,Yes
22781,TODO:  garantir que a leitura dos processed_tuples poder ser feita de forma concurrente,,,Yes
22785,TODO: garantir que cada padrao soh estah a ser lido por um unico processo,,,Yes
22786,TODO: implementar esta medida,,No,Yes
22788,TODO: regex to used depends on Config.tags_type,,,Yes
22789,TODO: run code according to Config.tags_type,,Yes,Yes
22791,TODO: depois da 1\u00BA itera\u00E7\u00E3o t\u00EAm que ser mantidos,,Yes,Yes
22794,TODO: construir o candidate tuples,,Yes,Yes
22795,NOTE: this works; but probably can be done in a much cleaner way,,No,Yes
22798,hard-coded fix,,Yes,Yes
22803,TODO: agregar todos os patterns recebidos por id,,,Yes
22806,TODO: h\u00E1 casos mais complexos; adjectivos ou adverbios pelo meio; por exemplo:,,,Yes
22811,move data pointer,,Yes,Yes
22813,let's give them a better error message,,Yes,Yes
22814,let's give them a better error message,,Yes,Yes
22815,TODO. Check,,Yes,Yes
22818,------- Create and initialize sharedVariables needed to compile the training function ------ #,,,Yes
22824,To-do. Verify receptive field with stride size other than 1,,No,Yes
22827,*** There actually exist several ways to implement ReLU activations ***,,,Yes
22828,*** There actually exist several ways to implement PReLU activations ***,,Yes,Yes
22829,TODO. Implement some other activation functions:,,,Yes
22830,TODO. Include more optimizers here,,,Yes
22834,TODO,,Yes,Yes
22835,TODO,,Yes,Yes
22837,Don't pre-allocate memory; allocate as-needed,,Yes,Yes
22840,"fix for \""RNN weights not part of single contiguous chunk of memory\"" issue",,No,Yes
22842,it does? good. let's move on,,,Yes
22843,repack if needed,,,Yes
22844,pool if needed,,Yes,Yes
22846,transpose back the results according to the input convention,,Yes,Yes
22847,columns of u; rows of v,,Yes,Yes
22849,TODO: quasi; quasibinomial; quasipoisson,,Yes,Yes
22850,TODO: change these class attributes; use valid somewhere...,,,Yes
22851,TODO: change the links class attribute in the families to hold,,Yes,Yes
22853,TODO: it *should* work for a constant n>1 actually; if data_weights,,Yes,Yes
22854,overwritten by initialize if needed but always used to initialize,,,Yes
22858,return approx_fprime_cs(mu; self)  # TODO fix breaks in `fabs,,,Yes
22860,TODO: inherit from super,,Yes,Yes
22863,better to have all zeros or all ones,,Yes,Yes
22866,output should be a list inidicating the columns of the dataframe,,,Yes
22867,output should be a list inidicating the columns of the dataframe,,Yes,Yes
22868,input should be a list inidicating the columns of the dataframe,,Yes,Yes
22869,output should be a list inidicating the columns of the dataframe,,,Yes
22870,`loss` is unused. Refactoring to avoid computing it does not,,,Yes
22871,TODO: quasi; quasibinomial; quasipoisson,,,Yes
22873,TODO: change the links class attribute in the families to hold,,Yes,Yes
22874,meaningful information instead of a list of links instances such as,,,Yes
22883,TODO: it *should* work for a constant n>1 actually; if data_weights,,Yes,Yes
22884,\/\/TODO check sum(sample_weight > 0)? Is it wrong to have the sample weight equal to zero?,,No,Yes
22887,TODO,,Yes,Yes
22888,\/\/TODO sample weight all zero,,,Yes
22890,\/\/TODO sample weight all zero,,,Yes
22891,is needed (3 chunks are fwd),,Yes,Yes
22892,First shape the hidden space as Z if needed,,Yes,Yes
22893,update weight incrementally if needed still,,Yes,Yes
22894,TODO: UNDERSTAND THIS COMPUTATION,,Yes,Yes
22896,is needed (3 chunks are fwd),,Yes,Yes
22898,update weight incrementally if needed still,,,Yes
22901,is needed (3 chunks are fwd),,Yes,Yes
22902,First shape the hidden space as Z if needed,,Yes,Yes
22903,update weight incrementally if needed still,,,Yes
22905,TODO: sup. aux losses,,,Yes
22906,TODO: sup. aux losses,,Yes,Yes
22908,TODO: not pre-loading noises from files?,,No,Yes
22909,TODO: finish this,,Yes,Yes
22910,ugly,,Yes,Yes
22912,First shape the hidden space as Z if needed,,Yes,Yes
22914,TODO: sup. aux losses,,Yes,Yes
22916,ugly,,,Yes
22917,TODO: finish this,,Yes,Yes
22919,TODO: weight new adversarial minion?,,Yes,Yes
22920,TODO: sup. aux losses,,Yes,Yes
22921,TODO: sup. aux losses,,Yes,Yes
22923,TODO: allow for different base transforms for different datasets,,No,Yes
22924,TODO: allow for different base transforms for different datasets,,,Yes
22927,fix in case wav is stereo; in which case,,Yes,Yes
22929,Calculate variables needed,,,Yes
22930,TODO: improve this with some proper transposition and stuff,,,Yes
22931,TODO: cdf_delta <= 1e-5 actually can happen. How can we choose the value,,Yes,Yes
22932,TODO: half of these useless arguments should be removed in,,Yes,Yes
22933,"TODO: Fix this shameful \""path replacement\"" assuming there is a",,,Yes
22934,''' || Tensorflow implementation of word2vec algorithm as a scikit-learn like model  || with fit; transform methods. ||  || @author: Zichen Wang (wangzc921@gmail.com) ||  || @references: ||  || https:\/\/www.kaggle.com\/c\/word2vec-nlp-tutorial\/details\/ || https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/examples\/tutorials\/word2vec\/word2vec_basic.py || https:\/\/github.com\/wangz10\/UdacityDeepLearning\/blob\/master\/5_word2vec.ipynb || ''',,Yes,Yes
22935,move the sliding window,,Yes,Yes
22937,''' || Tensorflow implementation of PV-DM algorithm as a scikit-learn like model  || with fit; transform methods. ||  || @author: Zichen Wang (wangzc921@gmail.com) ||  || @references: ||  || http:\/\/arxiv.org\/abs\/1405.4053 || ''',,,Yes
22938,move the sliding window,,Yes,Yes
22940,''' || Tensorflow implementation of Neural Variational Document Model(NVDM) algorithm as a scikit-learn like model  || with fit; transform methods. ||  || @author: Zichen Wang (wangzc921@gmail.com) ||  || @references: || https:\/\/arxiv.org\/abs\/1511.06038 || https:\/\/github.com\/ysmiao\/nvdm\/blob\/master\/nvdm.py || ''',,Yes,Yes
22941,TODO: Add refinements here,,,Yes
22942,fix random seeds for reproducing results,,Yes,Yes
22943,(2) Blank lines between documents. Document boundaries are needed so,,Yes,Yes
22944,The convention in BERT is:,,,Yes
22953,# If all enc_inputs ends up shorter dec_output; we can have smaller_value here.,,No,Yes
22954,TODO rename. this is not beam any more,,Yes,Yes
22955,TODO: Vectorized implementation here.,,,Yes
22958,todo mask the sampling results,,,Yes
22960,TODO: This is a bit of a hack,,No,Yes
22961,TODO: this shows the probabilities; we need to add the actual sampling here!,,Yes,Yes
22962,TODO: This is a bit of a hack,,No,Yes
22963,Maybe add wall,,Yes,Yes
22965,add in as vernose mode - TODO,,Yes,Yes
22966,hack 2 - from https:\/\/stackoverflow.com\/questions\/34343259\/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow,,Yes,Yes
22967,TODO,,,Yes
22969,"also work around typo in naming of original models for V1 models [Dunning\/Breckon; 2018] \""...iononv ...\""",,,Yes
22970,"also work around typo in naming of original models for V1 models [Dunning\/Breckon; 2018] \""...iononv ...\""",,Yes,Yes
22971,TODO: use local_rank instead of rank % num_gpus,,No,Yes
22973,reshape data into 3D array (columns; rows; channels),,,Yes
22974,Convert to numpy and transpose axes to fit imageio convention,,,Yes
22975,imageio convention as seen:,,Yes,Yes
22976,Convert to numpy and transpose axes to fit imageio convention,,,Yes
22978,imageio convention as seen:,,,Yes
22979,imageio convention as seen:,,,Yes
22981,TODO: remove this kl_loss term once viz is sorted,,Yes,Yes
22982,TODO replace this code with the following commented out code after viz is fixed,,Yes,Yes
22985,TO-DO: clean all these if statements,,Yes,Yes
22986,TO-DO: currently uses train datatset,,Yes,Yes
22987,TODO: sorting should be done outside of function,,,Yes
22988,TODO: add warning if use metric if no true factors of variations,,No,Yes
22990,TODO: stor in a dictionary rather than pytorch tensors,,Yes,Yes
22992,TODO Need to sort the visualisation issue here; we no longer use KL divergence in the same way for all losses,,Yes,Yes
22993,TODO: sorting should be done outside of function,,No,Yes
22998,def combine_images(width; height;image_list; nr_columns;):,,Yes,Yes
23000,TODO: Handle this more elegantly,,,Yes
23001,TODO: This sorting should happen inside the add_labels function to something cleaner,,Yes,Yes
23002,TODO: This return came in an incorrectly form from Bart; not sure how to fix it,,,Yes
23003,test if mss is better!,,,Yes
23004,TODO: Handle this more elegantly,,,Yes
23005,TODO: This sorting should happen inside the add_labels function to something cleaner,,,Yes
23006,TODO: This return came in an incorrectly form from Bart; not sure how to fix it,,Yes,Yes
23008,TODO replace this code with the following commented out code after viz is fixed,,Yes,Yes
23009,TODO Remove this when visualisation fixed,,Yes,Yes
23010,test if mss is better!,,Yes,Yes
23013,TODO replace this code with the following commented out code after viz is fixed,,,Yes
23014,TODO replace this code with the following commented out code after viz is fixed,,Yes,Yes
23015,TO-DO: clean,,,Yes
23017,from -- bigger means better shuffling but slower start up and more,,No,Yes
23018,Reshape the output into len(vocab) sized chunks - the -1 says as many as needed to evenly divide,,Yes,Yes
23019,backward_lookup keeps the words that ends at a frame,,,Yes
23021,TODO prob = 1 \/ self.idx2freq[id]  # just share evenly from the distribution.,,,Yes
23022,backward_lookup keeps the words that ends at a frame,,No,Yes
23023,backward_lookup keeps the words that ends at a frame,,,Yes
23024,recursively eval till end; this is not very efficient if a long word is the only one item,,,Yes
23025,Reshape the output into len(vocab) sized chunks - the -1 says as many as needed to evenly divide,,Yes,Yes
23026,Reshape the output into len(vocab) sized chunks - the -1 says as many as needed to evenly divide,,Yes,Yes
23027,per log for fix vocabs,,Yes,Yes
23028,Reshape the output into len(vocab) sized chunks - the -1 says as many as needed to evenly divide,,,Yes
23032,MAYBE BIGGER,,,Yes
23035,TODO: what happens if n_cpu > 1 and n_repeat > 1? Does pool get copied? Probably not...just a pointer to the same object... Seems fine.,,Yes,Yes
23036,"TODO: This is the \""correct\"" update but it is quite noisy. Add smoothing?",,Yes,Yes
23037,TODO: This should be done using sampling with replacement instead of permutation.,,,Yes
23040,TODO: If it does not work; then scale down to MNIST.(styles:number; character:font style),,,Yes
23043,Ish [: ; 2] the the number of class; which is not needed anymore!!,,Yes,Yes
23044,All downsampled images are created in one loop which is much more efficient. For instance; stage 2 and 4 are created at the same time.,,Yes,Yes
23045,this flush method is needed for python 3 compatibility.,,,Yes
23046,np.negative generates some NAN elements. no idea why,,,Yes
23047,ish [: ; 2] the the number of class; which is not needed anymore!!,,,Yes
23049,this flag is used when sweeping in one dimension is not needed. For instance if the,,,Yes
23050,ish [: ; 2] the the number of class; which is not needed anymore!!,,,Yes
23051,why it cannot work?????????,,Yes,Yes
23054,TODO: find outputformat?,,Yes,Yes
23055,TODO: verify this works,,Yes,Yes
23057,#TODO: display output                \t,,,Yes
23058,TODO: verify this works,,,Yes
23059,TODO: implement reading formats from XML; return a class derived from Format; xmlnode is lxml Element or string,,Yes,Yes
23061,TODO: protect against insertion,,No,Yes
23062,TODO: implement,,Yes,Yes
23063,TODO: Verify custom not-found messages work?,,Yes,Yes
23064,TODO: send a custom 400 (bad request) instead of 200; but with same content as GET!,,,Yes
23067,TODO: Set proper headers,,,Yes
23069,TODO: make recursive and set mode,,,Yes
23070,temporary global variable (not very elegant and not thread-safe!) #TODO: improve?,,No,Yes
23074,TODO: adapt for client versus server! (inputfile vs outputfile?),,Yes,Yes
23075,TODO,,Yes,Yes
23078,TODO: message won't show,,Yes,Yes
23080,workaround:,,No,Yes
23081,TODO: Add viewers,,,Yes
23083,TODO LATER: add pretty indentation,,Yes,Yes
23084,TODO: return response,,No,Yes
23085,TODO: implement,,,Yes
23086,TODO !!!!!!,,Yes,Yes
23088,TODO: Write new uploader with new metadata!,,Yes,Yes
23090,TODO: Resolve numbers,,,Yes
23093,TODO: delete metadata as well!,,,Yes
23098,TODO: Generate metadata,,No,Yes
23099,TODO: add support for uploading metadata files,,,Yes
23101,TODO: Remove file,,No,Yes
23103,TODO: Send HTTP DELETE,,Yes,Yes
23105,TODO: Auth support,,,Yes
23107,TODO: Adapt CLAMData for new metadata,,No,Yes
23108,TODO,,Yes,Yes
23110,TODO: Return error response if no profiles match. Returns 403 response with error message.,,,Yes
23115,TODO support for custom formats?,,Yes,Yes
23117,TODO LATER: implement,,,Yes
23118,TODO: implement,,,Yes
23119,TODO: Verify,,No,Yes
23121,TODO support for custom formats?,,Yes,Yes
23124,TODO: Write to METADATA file,,,Yes
23126,TODO: do not hard-code path!,,Yes,Yes
23131,TODO,,Yes,Yes
23132,TODO: Implement converter,,,Yes
23133,TODO: Implement converter,,No,Yes
23140,TODO,,,Yes
23141,MAYBE TODO: make more efficient,,,Yes
23142,encoding = inputfile.metadata['encoding'] #Example showing how to obtain metadata parameters,,,Yes
23143,encoding = inputfile.metadata['encoding'] #Example showing how to obtain metadata parameters,,Yes,Yes
23145,ugly hard-coded path; I know..,,,Yes
23146,TODO LATER: Implement some kind of caching,,,Yes
23147,unused_docs = [],,Yes,Yes
23149,TODO: OAUTH !!!!,,No,Yes
23150,TODO: OAUTH!!!!,,,Yes
23152,TODO: rewrite using requests,,Yes,Yes
23153,TODO: no support for openauth yet??,,,Yes
23155,TODO: not used now,,No,Yes
23159,TODO,,Yes,Yes
23164,TODO!,,Yes,Yes
23166,MAYBE TODO: Reading input sources from XML is not implemented (and not necessary at this stage),,Yes,Yes
23170,this loads a whole FoLiA document into memory! which is a bit of a waste of memory and a performance hog!,,Yes,Yes
23171,TODO: can't I merge this with validate()?,,,Yes
23174,TODO: message won't show,,,Yes
23175,TODO: all these are not implemented yet,,No,Yes
23178,TODO: message won't show,,Yes,Yes
23181,passed through then some slight changes to the logic would be needed.,,,Yes
23184,TODO: find a more sensible and secure approach or at least recommend,,,Yes
23186,TODO: add checks to confirm all necessary files are present and readable,,Yes,Yes
23187,TODO: fix this to not use globals (urggh!),,,Yes
23189,TODO: put in a better 'fitness' selection process here!!,,,Yes
23190,TODO: put in the option to do substitution here (most likely scenario;,,,Yes
23191,"the \""handle_{intent namee}\"" is merely a convention for",,,Yes
23192,TODO: look into better performance versions of this (pop(0) isn't great,,Yes,Yes
23193,apparently),,No,Yes
23196,TODO: Add error and type checking,,No,Yes
23197,TODO: find a more sensible and secure approach or at least recommend,,Yes,Yes
23198,needed.,,,Yes
23199,TODO: add checks to confirm all necessary files are present and readable,,Yes,Yes
23202,TODO: put in a better 'fitness' selection process here!!,,No,Yes
23205,TODO: look into better performance versions of this (pop(0) isn't great,,,Yes
23208,TODO: add ability to handle selection by one of a ruler's countries,,No,Yes
23210,alt way of doing this: say_text(string.Formatter().vformat(template; (); defaultdict(str; **row))),,Yes,Yes
23211,TODO: consider breaking out this mapping into a generalised helper function,,Yes,Yes
23212,# TODO: find a more sensible and secure approach or at least recommend,,Yes,Yes
23213,# needed.,,No,Yes
23214,# TODO: fix this to not use globals (urggh!),,,Yes
23216,TODO: put something to take off the final comma,,No,Yes
23217,r = requests.get(LC_URL; auth=(LC_AUTH_TOKEN; 'xxx')),,Yes,Yes
23220,AndresBug: maybe exchange 8 with samples_per_bar?,,,Yes
23224,TODO: use argparse to check,,,Yes
23225,TODO: fix so we don't have to,,Yes,Yes
23227,TODO,,,Yes
23228,TODO: use actual gvkeys,,No,Yes
23229,TODO: try without copying? could be faster,,Yes,Yes
23234,TODO: date column name should be a config,,,Yes
23236,TODO: fix this it's kind of hacky,,Yes,Yes
23237,TODO: make a config,,No,Yes
23239,TODO: date column name should be a config,,,Yes
23240,...write all one-hot columns on the right side...,,,Yes
23241,TODO: roll up as function (to be housed within _init_batch_cursor)?,,No,Yes
23242,if config.start_date is not None: # TODO: uncomment?,,Yes,Yes
23243,TODO: try without copying? could be faster,,Yes,Yes
23244,TODO: date column name should be a config,,,Yes
23245,TODO: store as set instead of as dict?,,,Yes
23246,TODO: date name should be a config,,No,Yes
23247,TODO: fix this it's kind of hacky,,Yes,Yes
23248,TODO: make a config,,,Yes
23252,...write all one-hot columns on the right side...,,,Yes
23253,if config.start_date is not None: # TODO: uncomment?,,,Yes
23254,TODO: date name should be a config,,No,Yes
23255,TODO: fix this it's kind of hacky,,Yes,Yes
23256,TODO: roll up as function (to be housed within _init_batch_cursor)?,,No,Yes
23262,TODO: Check if self._mean_squared_error_w_variance can be used here,,,Yes
23263,TODO: Make the below safe to div by zero,,,Yes
23264,TODO: What is this?,,,Yes
23265,TODO: Make the below safe to div by zero,,,Yes
23266,TODO: Make the below safe to div by zero,,Yes,Yes
23269,TODO update,,,Yes
23272,TODO: update partition of event period and nonevent period,,No,Yes
23273,"\""\""\""\r || Created on Fri Sep 29 15:28:07 2017\r || \r || @author: user\r || \""\""\""",,No,Yes
23275,# TODO : example loss weight,,No,Yes
23277,TODO handle generting new entities map,,Yes,Yes
23278,comparatively fast but a bit of a hack:,,No,Yes
23281,Clean up added space (well; maybe other also),,Yes,Yes
23282,TODO: clean this up,,No,Yes
23283,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,No,Yes
23285,we probably missed the best pair because of pruning; go back to full statistics,,No,Yes
23287,if model doesnt improve after max_decrease_epochs; stop training,,Yes,Yes
23289,restore only variables that exist in the checkpoint - needed to pre-train big models with small models,,Yes,Yes
23290,todo: make compatitble with cnn and transformer as width:dilation:take,,Yes,Yes
23291,If we've grown at this step; the tail cell shouldn't move.,,Yes,Yes
23293,TODO: check if this is correct. Some game systems might use WEST.,,No,Yes
23294,The convention in BERT is:,,No,Yes
23296,(2) Blank lines between documents. Document boundaries are needed so,,Yes,Yes
23297,The convention in BERT is:,,No,Yes
23298,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
23300,"What we really want to return is \""Steve Smith\"".",,No,Yes
23301,The convention in BERT is:,,No,Yes
23302,The convention in BERT is:,,,Yes
23303,The convention in BERT is:,,No,Yes
23304,optionally associate an ID to job (if needed later),,No,Yes
23306,optionally associate an ID to job (if needed later),,,Yes
23308,optionally associate an ID to job (if needed later),,,Yes
23309,move to GPU,,,Yes
23310,move to GPU,,Yes,Yes
23313,make dir if needed (should be non-empty),,,Yes
23315,TODO,,Yes,Yes
23318,TODO incremental clusterers,,,Yes
23319,TODO: incremental filtering,,Yes,Yes
23321,more efficient implementation?,,,Yes
23325,TODO works only for 3D periodic. For 1;2D - update np.zeros((3;3)) part,,Yes,Yes
23328,# Compute the model properties (you can speed up ASE energy prediction by not doing force backprop unless needed.),,,Yes
23329,Todo: data augmentation,,Yes,Yes
23330,Todo,,Yes,Yes
23335,FIXME: reuse for validation!,,Yes,Yes
23336,TODO: finish validation; how to accumulate correct_preds for accumulative accuracy,,Yes,Yes
23339,FIXME,,,Yes
23340,FIXME: how to use tf.image.decode_image instead of decode_jpeg?,,,Yes
23341,TODO,,,Yes
23342,adding 0 columns for columns that are not in the dataset; assuming it s only dummy columns,,Yes,Yes
23343,missing input is when we m\\are missing some columns: for instance if self.estimation_inputs contains,,No,Yes
23346,we add columns for each semi dummy features (*number of potential dummy values),,Yes,Yes
23348,Return the values that are needed in current mode #,,,Yes
23351,Return the values that are needed in current mode #,,No,Yes
23353,the eval job keeps a smoother; running average loss to tell it when to implement early stopping,,Yes,Yes
23354,Return the values that are needed in current mode #,,No,Yes
23356,the eval job keeps a smoother; running average loss to tell it when to implement early stopping,,,Yes
23358,the eval job keeps a smoother; running average loss to tell it when to implement early stopping,,Yes,Yes
23359,the eval job keeps a smoother; running average loss to tell it when to implement early stopping,,Yes,Yes
23360,Return the values that are needed in current mode #,,No,Yes
23366,Return the values that are needed in current mode #,,No,Yes
23368,Return the values that are needed in current mode #,,,Yes
23369,Put periods on the ends of lines that are missing them (this is a problem in the dataset because many image captions don't end in periods; consequently they end up in the body of the article as run-on sentences),,Yes,Yes
23370,Return the values that are needed in current mode #,,No,Yes
23372,FIXME: we should read image name,,No,Yes
23379,FIXME: load best ckpts -> export?,,No,Yes
23380,FIXME: there should be a better way doing this,,No,Yes
23381,TODO: add smooth loss,,Yes,Yes
23386,TODO: gif,,Yes,Yes
23387,TODO: add documentation of each function,,Yes,Yes
23389,TODO: \u5BEB\u4E00\u500B\u5C08\u9580\u7684 colab notebook \u5229\u7528 GPU \u4F5C\u8F49\u63DB,,,Yes
23390,TODO: gpu \/ cpu,,,Yes
23391,TODO: limit image size,,,Yes
23392,TODO: limit gif length,,,Yes
23393,TODO: add style as title,,Yes,Yes
23394,TODO: add a parser option for horizontal \/ vertical concatenate,,No,Yes
23395,TODO: tqdm,,,Yes
23397,TODO: decide wether to delete tmp dir,,Yes,Yes
23398,TODO: summary,,No,Yes
23399,TODO: batch processing,,,Yes
23401,TODO: processing mp4 possible? how about converting to mp4?,,Yes,Yes
23405,TODO: fix screwy gif,,,Yes
23408,'''Train a simple deep CNN on the CIFAR10 small images dataset using || a triangular cyclic learning rate (CLR) policy. || It gets to 75% validation accuracy in 15 epochs; and 79% after 40 epochs; || compare to 25 and 50 epochs respectively without CLR. || ''',,No,Yes
23410,"'''DenseNet and DenseNet-FCN models for Keras. ||  || DenseNet is a network architecture where each layer is directly connected || to every other layer in a feed-forward fashion (within each dense block). || For each layer; the feature maps of all preceding layers are treated as || separate inputs whereas its own feature maps are passed on as inputs to || all subsequent layers. This connectivity pattern yields state-of-the-art || accuracies on CIFAR10\/100 (with or without data augmentation) and SVHN. || On the large scale ILSVRC 2012 (ImageNet) dataset; DenseNet achieves a || similar accuracy as ResNet; but using less than half the amount of || parameters and roughly half the number of FLOPs. ||  || DenseNets support any input image size of 32x32 or greater; and are thus || suited for CIFAR-10 or CIFAR-100 datasets. There are two types of DenseNets; || one suited for smaller images (DenseNet) and one suited for ImageNet; || called DenseNetImageNet. They are differentiated by the strided convolution || and pooling operations prior to the initial dense block. ||  || The following table describes the size and accuracy of DenseNetImageNet models || on the ImageNet dataset (single crop); for which weights are provided: || ------------------------------------------------------------------------------------ ||     Model type      | ImageNet Acc (Top 1)  |  ImageNet Acc (Top 5) |  Params (M)  | || ------------------------------------------------------------------------------------ || |   DenseNet-121    |    25.02 %            |        7.71 %         |     8.0      | || |   DenseNet-169    |    23.80 %            |        6.85 %         |     14.3     | || |   DenseNet-201    |    22.58 %            |        6.34 %         |     20.2     | || |   DenseNet-161    |    22.20 %            |         -   %         |     28.9     | || ------------------------------------------------------------------------------------ ||  || DenseNets can be extended to image segmentation tasks as described in the || paper \""The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for || Semantic Segmentation\"". Here; the dense blocks are arranged and concatenated || with long skip connections for state of the art performance on the CamVid dataset. ||  || # Reference || - [Densely Connected Convolutional Networks](https:\/\/arxiv.org\/pdf\/1608.06993.pdf) || - [The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic ||    Segmentation](https:\/\/arxiv.org\/pdf\/1611.09326.pdf) ||  || This implementation is based on the following reference code: ||  - https:\/\/github.com\/gpleiss\/efficient_densenet_pytorch ||  - https:\/\/github.com\/liuzhuang13\/DenseNet ||  || '''",,,Yes
23411,is set to 12; as at least 3 color channels are needed for correct upsampling,,,Yes
23413,absolute tolerance needed when working with zeros,,,Yes
23414,TODO: removed this once the issue #25546 in the Tensorflow repo is fixed.,,No,Yes
23416,TODO: remove those files or find them owners.,,Yes,Yes
23418,TODO: use previous seed if available,,Yes,Yes
23422,FIXME: temporary solution for running on colab,,No,Yes
23423,TODO: rearrange the order of options,,Yes,Yes
23425,pre-compute the hops for each node for more efficient sampling,,,Yes
23426,generate slightly more than needed completely random non-edge indices and discard any that hit an edge,,,Yes
23428,in the future: estimate the multiplicity (currently fixed 1.3\/2.3) based on A_obs.nnz,,,Yes
23432,TODO: Find a way to do this on the GPU,,Yes,Yes
23433,Move to render directory,,No,Yes
23436,Move reference images,,,Yes
23437,TODO: Fix this (either use it; or find another way),,,Yes
23439,TODO: possibly do sparse to dense coversion after crop,,,Yes
23441,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,No,Yes
23443,fix PIL image truncated issue,,,Yes
23444,File format: text files; each line is an image record containing 6 columns; delimited by TAB.,,No,Yes
23445,Moving averages ends up in the trainable variables collection,,,Yes
23447,Moving averages ends up in the trainable variables collection,,No,Yes
23449,Moving averages ends up in the trainable variables collection,,,Yes
23452,using the multiscale discriminator often gets better results,,Yes,Yes
23453,TODO car type?,,,Yes
23455,TODO: implement the function,,Yes,Yes
23457,TODO: implement an efficient solution for very big files,,,Yes
23459,TODO extract lines with Category:,,Yes,Yes
23462,"\""\""\"" 58. Tr\u00EDch xu\u1EA5t tuples ||     T\u1EEB k\u1EBFt qu\u1EA3 ph\u00E2n t\u00EDch dependency c\u1EE7a Stanford Core NLP ||     (collapsed-dependencies); tr\u00EDch xu\u1EA5t c\u00E1c b\u1ED9 3 ||     [Subject; Predicate; Purpose] v\u00E0 in ra c\u00E1c b\u1ED9 3 n\u00E0y (c\u00E1c th\u00E0nh ph\u1EA7n ||     c\u00E1ch nhau b\u1EDFi k\u00FD t\u1EF1 tab). Subject; Predicate; Purpose \u0111\u01B0\u1EE3c x\u00E1c \u0111\u1ECBnh ||     d\u1EF1a v\u00E0o c\u00E1c ti\u00EAu chu\u1EA9n sau: ||     - Predicate: L\u00E0 word \u1EDF c\u00E1c node con (dependant) c\u1EE7a c\u00E1c dependency ||       relations: nsubj; dobj ||     - Subject: C\u00E1c node con (dependant) trong c\u00E1c quan h\u1EC7 nsubj t\u1EEB predicate ||     - Purpose: C\u00E1c node con (dependant) trong c\u00E1c quan h\u1EC7 dobj t\u1EEB predicate || \""\""\""",,Yes,Yes
23466,fix random seed for reproducibility,,,Yes
23467,fix random seed for reproducibility,,No,Yes
23470,fix random seed for reproducibility,,No,Yes
23473,fix random seed for reproducibility.,,,Yes
23474,fix random seed for reproducibility.,,,Yes
23477,fix random seed for reproducibility.,,No,Yes
23478,FIXME: deal with absent keys (new accounts),,Yes,Yes
23484,XXX Bucket returned by InfluxDB are aligne on modulo(bucket_interval); that's why,,,Yes
23488,TODO return loss and accuracy,,No,Yes
23490,TODO .detect_anomalies() produces warning messages,,Yes,Yes
23491,TODO Generic aggregation not implemented yet,,,Yes
23492,TODO Generic response handling not implemented yet,,Yes,Yes
23494,fix random seed for reproducibility.,,No,Yes
23498,XXX The buckets are currently returned in Elasticsearch format and read in IVoipModel,,,Yes
23499,TODO more checks needed,,,Yes
23500,FIXME: catching this exception here may mask some bugs.,,Yes,Yes
23501,Explanations needed.,,,Yes
23503,FIXME: duplicate function,,No,Yes
23505,TODO sanitize inputs to avoid injection!,,Yes,Yes
23507,XXX required because operator column may contain '\\r',,,Yes
23508,TODO: move this into a dedicated package to make it available for all our softwares,,Yes,Yes
23510,XXX: catch all the exception to avoid,,Yes,Yes
23511,TODO 1.4 There are very similar code in worker and CLI. Try to factorize,,Yes,Yes
23515,XXX: division by zero is evil,,No,Yes
23516,TODO integrate with setuptools,,Yes,Yes
23520,XXX: Keep broken file for troubleshooting,,Yes,Yes
23522,XXX: Warp10 buckets are labeled with the right timestamp but LoudML,,,Yes
23523,XXX As Warp10 uses the end date to identify buckets; use the same,,Yes,Yes
23524,convention,,No,Yes
23525,TODO sanitize inputs to avoid injection!,,,Yes
23526,XXX: return a copy to prevent modification by the caller,,No,Yes
23527,FIXME: find best value to distribute the workload,,,Yes
23528,FIXME: should be an input argument,,No,Yes
23530,"XXX: 'order by \""score\""' is not supported by InfluxDB",,,Yes
23531,XXX: return a copy to prevent modification by the caller,,,Yes
23532,FIXME: M-ELBO shall remove the need for this gap,,No,Yes
23533,FIXME: query abnormal points flagged,,No,Yes
23541,TODO sanitize inputs to avoid injection!,,Yes,Yes
23542,XXX: return a copy to prevent modification by the caller,,,Yes
23544,XXX: the server bind address is unknown.,,Yes,Yes
23545,TODO: consider more granular OS release extraction,,Yes,Yes
23546,TODO: OpenTSDB is capable of running multiple subquries in,,,Yes
23550,TODO: is this needed?,,No,Yes
23552,hand tiles too bad; better not call meld,,No,Yes
23553,TODO: discard a tile by your own strategy,,Yes,Yes
23554,a round ends,,No,Yes
23555,the whole game ends,,No,Yes
23556,the OBJECT of your own implemented Mahjong agent,,,Yes
23559,hand tiles too bad; better not call meld,,No,Yes
23563,xxx,,,Yes
23564,FIXME,,,Yes
23565,- Removed unused functions; such as slicing and range iteration.,,,Yes
23566,Needed for sweep-line.,,,Yes
23567,Fix red violation,,,Yes
23569,[FIXME]: dist???,,,Yes
23573,[FIXME],,Yes,Yes
23574,FIXME: to jest bardzo grozne,,Yes,Yes
23579,FIXME: punkty za kwadratowosci? (przypadki z L shape),,,Yes
23580,FIXME: zrobic 2 rodzaje haszowania (katy + pasy [blad - delta]),,,Yes
23584,XXX: pomijanie warst; lub ich wybor? (jesli mamy juz okay),,Yes,Yes
23586,FIXME: alfa\/1.5,,No,Yes
23587,FIXME: roznica???,,,Yes
23589,FIX: tensorflow#3388,,Yes,Yes
23590,FIX: tensorflow#3388,,Yes,Yes
23593,TODO,,Yes,Yes
23594,For convenience; they also download the requested files if needed.,,Yes,Yes
23595,following the shape convention: (examples; channels; rows; columns),,No,Yes
23596,by convention; use 2 as OOV word,,,Yes
23597,implement your own pre-train method.,,,Yes
23598,pad them if needed; reverse encoder inputs and add GO to decoder.,,,Yes
23600,following the shape convention: (examples; channels; rows; columns),,No,Yes
23601,by convention; use 2 as OOV word,,Yes,Yes
23602,implement your own pre-train method.,,,Yes
23605,pad them if needed; reverse encoder inputs and add GO to decoder.,,Yes,Yes
23609,# Fix for old Tensorflow,,,Yes
23610,and also change the default values if needed,,,Yes
23611,and also change the default values if needed,,,Yes
23613,fix PATH,,Yes,Yes
23615,TODO: Copy any resources,,Yes,Yes
23616,TODO: Change directory to that of running code,,Yes,Yes
23617,this ends and restarts a comment block. but need to catch this so,,No,Yes
23619,Hack-ish magic parser,,No,Yes
23620,NOTE(mauricio): Figure  out if passing the kernel around is a problem...,,Yes,Yes
23621,TODO: Add scalars and matrices?,,,Yes
23622,TODO: Faster method for non-console mode,,No,Yes
23623,TODO: Speed up completions refresh,,,Yes
23624,TODO: Faster method for non-console mode,,No,Yes
23625,this ends and restarts a comment block. but need to catch this so,,No,Yes
23627,TODO: Change this to actual cap\/noi\/qui regex,,,Yes
23631,TODO: Change this to actual cap\/noi\/qui regex,,,Yes
23633,TODO: On my Mac; the width is double what I told Stata to export,,No,Yes
23636,NOTE(mauricio): Figure  out if passing the kernel around is a problem...,,,Yes
23639,If mata was opened with a colon; :; an error ends mata,,Yes,Yes
23641,this ends and restarts a comment block. but need to catch this so,,No,Yes
23642,TODO: Instead of if\/else; just add fallbacks to .get(),,Yes,Yes
23645,TODO: Check if leading line in output,,No,Yes
23650,ends in a line continuation. In this case we hack it by adding,,,Yes
23652,TODO: Use Game Control,,No,Yes
23654,TODO: on_move(x; y),,,Yes
23657,TODO: return key's id,,No,Yes
23660,TODO : user_change  ex) 'status_text': 'In a meeting',,,Yes
23661,let's give them a better error message,,Yes,Yes
23662,TODO:,,,Yes
23663,TODO: use Toggl,,No,Yes
23665,TODO: use Toggl,,,Yes
23667,TODO: DataShuffler,,Yes,Yes
23672,TODO: check_convergence,,,Yes
23673,should implement more general initialization methods,,Yes,Yes
23674,TODO: pseudo-likelihood,,No,Yes
23675,TODO:,,No,Yes
23676,TODO: fix,,No,Yes
23678,TODO: DataShuffler,,Yes,Yes
23680,TODO:,,,Yes
23682,this deepcopy is probably not needed,,,Yes
23684,no good way to specify this right now,,,Yes
23685,TODO:,,No,Yes
23687,TODO: should import the State class from hidden.py,,Yes,Yes
23688,TODO: should import the State class from hidden.py,,Yes,Yes
23689,TODO: leave tensors as Any until we figure out a better representation,,,Yes
23690,TODO: better way of dealing with gradients,,,Yes
23691,we should probably abstract this out somehow,,Yes,Yes
23693,we should probably abstract this out somehow,,Yes,Yes
23695,TODO: worry about how much clipping gets done here!,,,Yes
23696,perhaps rescale to avoid clipping?,,Yes,Yes
23697,TODO: define this to run recursively,,,Yes
23700,TODO: use State,,,Yes
23702,TODO: vectorize,,,Yes
23706,TODO: use State,,,Yes
23707,TODO: is this efficient?,,No,Yes
23708,TODO: is this efficient?,,No,Yes
23710,TODO: method to anneal the std -> 0 so that the sampled distribution,,Yes,Yes
23712,TODO: method to anneal the std -> 0 so that the sampled distribution,,,Yes
23713,TODO: rewrite to loop over weights instead of layers,,Yes,Yes
23716,HACK:,,No,Yes
23718,TODO: make interface that this must implement,,,Yes
23719,TODO: should these really be here?,,,Yes
23720,TODO: get rid of this member...,,,Yes
23725,TODO: what does this function return?,,No,Yes
23727,TODO: a and c are not informative variable names,,Yes,Yes
23728,TODO: what does these functions do?,,,Yes
23729,"TODO: use of the term \""diagonal\"" is a bit confusing since B is a tensor",,,Yes
23730,TODO: do we want to support both?,,No,Yes
23734,TODO: move clipping into the layer function,,,Yes
23737,TODO: move clipping into the layer function,,Yes,Yes
23738,TODO: move clipping into the layer function,,Yes,Yes
23740,TODO: per sample derivatives,,No,Yes
23742,TODO: use StateTAP,,Yes,Yes
23745,TODO: use layer functions,,,Yes
23746,TODO: currently; there are three functions here,,Yes,Yes
23748,TODO: currently; there are three functions here,,Yes,Yes
23751,set the seed for the gpu generator if needed,,,Yes
23752,TODO: add beta,,Yes,Yes
23753,TODO: implement log_partition_function for OneHot layer,,Yes,Yes
23755,TODO: can we clean up this implementation?  Numpy's convention is to return,,,Yes
23756,TODO: see tany comment,,,Yes
23759,TODO: Fill in this docstring to explain what these arguments mean,,Yes,Yes
23761,TODO move the higher-order TAP scale derivatives out of the layers,,,Yes
23762,TODO: define this to run recursively,,Yes,Yes
23764,variables needed,,No,Yes
23766,Fix the warning about non-contiguous memory,,Yes,Yes
23767,TODO: there's probably a more elegant way to index this,,Yes,Yes
23769,TODO: make this MSE and make it work for multiple inputs,,,Yes
23772,Why do we transpose Y? Maybe we need to change the definition of self.Y() or beta?,,Yes,Yes
23773,TODO: change this block according to the PR of tensorflow. Maybe move it into a function?,,Yes,Yes
23774,TODO: m0 and S0 could come from the environment,,,Yes
23775,TODO: cleanup the following line,,No,Yes
23776,TODO: Maybe fix noise for better conditioning,,,Yes
23777,TODO: Change 1e-6 to the respective constant of GPflow,,Yes,Yes
23778,TODO: Clean up this,,No,Yes
23783,TODO: change distance function,,No,Yes
23784,TODO: move scope to outer indent,,Yes,Yes
23785,Checks if token ends with a fullstop.,,No,Yes
23787,Hack to enable Python2.7 to use encoding.,,Yes,Yes
23792,TODO: Actually moses_normalize(fin.read()) gives the same output,,,Yes
23793,TODO: randomize elements of the world,,,Yes
23796,FIXME,,,Yes
23797,TODO: method for resolving MSAA FBO into final FBO,,,Yes
23799,TODO: reward computation,,No,Yes
23800,TODO,,,Yes
23801,TODO: list of wall textures,,No,Yes
23804,TODO: reward computation,,,Yes
23805,TODO: compute the outline coordinates,,,Yes
23807,Transpose the rows and columns,,Yes,Yes
23808,TODO: In order to make this code faster:,,,Yes
23809,1) Implement _extract_patches as a single cuda kernel,,No,Yes
23810,An ugly hack for my KFAC implementation.,,Yes,Yes
23812,A really ugly way to save a model to CPU,,,Yes
23815,An ugly hack for my KFAC implementation.,,Yes,Yes
23818,An ugly hack to remove updates,,Yes,Yes
23821,An ugly hack to remove updates,,Yes,Yes
23822,FIXME: works only for environments with sparse rewards,,Yes,Yes
23823,TODO: reward for reaching red box?,,No,Yes
23824,TODO: make sure portals remain sorted by start position,,,Yes
23825,TODO: basic collision detection,,,Yes
23830,TODO: sample rooms proportionally to floor surface area?,,Yes,Yes
23832,TODO: if the portal width is none; use whole wall width,,Yes,Yes
23835,TODO: compute signed distance between walls,,No,Yes
23836,TODO: may want to precompute normals,,No,Yes
23837,TODO: project this wall onto the other,,,Yes
23839,FIXME: replace hx by sx,,,Yes
23840,TODO: keep the non-static entities in a different list for efficiency?,,,Yes
23842,FIXME: not used,,,Yes
23845,TODO: use SGD optimizer,,,Yes
23851,Walking into the street ends the episode,,Yes,Yes
23852,TODO: Implement choice of different optimizers ('sgd'; 'momentum'; 'nesterov'; etc.),,Yes,Yes
23858,TODO reimplement residual block,,Yes,Yes
23861,fix out-of-bounds y,,Yes,Yes
23862,Summaries needed for TensorBoard,,Yes,Yes
23864,if syllable ends in a T-4 diphthong followed by a consonant; introduce split in former diphthong,,Yes,Yes
23865,if the final word in the list of words ends with a suffix in suffixes; split the word at the suffix,,,Yes
23867,find better solution; redundant checking,,,Yes
23868,".setName(\""columns\"")",,,Yes
23869,NYT hack,,Yes,Yes
23872,if the final word in the list of words ends with a suffix in suffixes; split the word at the suffix,,Yes,Yes
23873,if syllable ends in a T-4 diphthong followed by a consonant; introduce split in former diphthong,,,Yes
23874,if the final word in the list of words ends with a suffix in suffixes; split the word at the suffix,,,Yes
23875,if syllable ends in a T-4 diphthong followed by a consonant; introduce split in former diphthong,,Yes,Yes
23876,find better solution; redundant checking,,,Yes
23879,if syllable ends in a T-4 diphthong followed by a consonant; introduce split in former diphthong,,Yes,Yes
23880,if the final word in the list of words ends with a suffix in suffixes; split the word at the suffix,,,Yes
23882,find better solution; redundant checking,,No,Yes
23883,".setName(\""columns\"")",,,Yes
23884,# fix word string problem,,,Yes
23885,# CONTRACTION FIX,,No,Yes
23886,TODO \\u0294 (glottal stop) to eSpeak? (for local dialects),,No,Yes
23889,TODO: the above few lines make sure that toAddAfter goes after the FIRST phoneme if toAdd is multiple phonemes; but works only when converting from eSpeak to non-eSpeak; it ought to work when converting from non-eSpeak to non-eSpeak also (doesn't matter when converting TO eSpeak),,,Yes
23891,TODO: 'declared' & 'declare' the 'r' after the 'E' sounds a bit 'regional' (but pretty).  but sounds incomplete w\/out 'r'; and there doesn't seem to be an E2 or E@,,Yes,Yes
23892,TODO: consider adding 'g' to words ending in 'N' (if want the 'g' pronounced in '-ng' words) (however; careful of words like 'yankee' where the 'g' would be followed by a 'k'; this may also be a problem going into the next word),,,Yes
23893,TODO: rewrite @ to 3 whenever not followed by a vowel?,,Yes,Yes
23894,"(hack for OALD's \""radio\""\/\""video\""\/\""stereo\""\/\""embryo\"" etc)",,Yes,Yes
23895,hack to accept eSpeak's pl'ak instead of pl'A:k - order was reversed in the March 2009 draft,,No,Yes
23897,"TODO if not en-rp? - if (word.endswith(\""y\"") or word.endswith(\""ie\"")) and new_e_pronunc.endswith(\""i:\""): new_e_pronunc=new_e_pronunc[:-2]+\""I\""",,Yes,Yes
23898,hack: if word ends with 'e' and dropping the 'e' leaves a valid word that's also in the dictionary; we DON'T want to drop this word on the grounds that espeak already gets it right; because if we do then adding 's' to this word may cause espeak to add 's' to the OTHER word ('-es' rule).,,,Yes
23900,hack for bbcmicro,,Yes,Yes
23903,fix prim\/sec stress markings for syllabify,,,Yes
23904,# fix word string problem,,Yes,Yes
23905,# CONTRACTION FIX,,No,Yes
23907,@TODO: bug when number of syllables in maxW is > 2 ?,,,Yes
23911,[use to implement the metrical pattern described by Derek Attridge;,,,Yes
23912,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23913,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23914,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23915,lines+=[wtok.line]  # ends up repeating lines,,,Yes
23916,initializes to all zeros...; maybe could randomize?,,,Yes
23917,[use to implement the metrical pattern described by Derek Attridge;,,,Yes
23919,[use to implement the metrical pattern described by Derek Attridge;,,,Yes
23920,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23921,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23924,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23925,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23926,[use to implement the metrical pattern described by Derek Attridge;,,Yes,Yes
23927,@HACK FOR MPI,,,Yes
23928,@HACK @TODO,,,Yes
23930,TODO: really? (could instead give a string of known-safe characters),,,Yes
23931,TODO: glottal_stop? (in regional pronunciations etc),,,Yes
23932,TODO: this is actually an a_as_in_apple variant in espeak; festival @1 is not in mrpa PhoneSet,,No,Yes
23935,Jan suggested 'hh'; but I can't get this to work on Windows XP (TODO: try newer versions of Windows),,Yes,Yes
23936,('x';var1_w); # suggested by Jan; but I can't get this to work on Windows XP (TODO: try newer versions of Windows),,,Yes
23937,TODO: is this really the best approximation?,,No,Yes
23938,TODO: may be able to convert part-of-speech (NOUN etc) to\/from some other formats e.g. Festival,,No,Yes
23946,TODO: is this the best approximation we can do?,,,Yes
23948,TODO: really? (espeak 'U' goes to opt_u_as_in_pull; and eSpeak also used U for the o in good; which sounds best with Speech's default UH4; hence the line below; but where did we get UH->oor_as_in_poor from?  Low-priority though because how often do you convert OUT of bbcmicro format),,Yes,Yes
23949,usually sounds a bit better,,No,Yes
23951,I think this should work given the way the other,,,Yes
23955,TODO: 163 AYWW = o_as_in_now a_as_in_ago ? handle in cleanup_regexps + cvtOut_regexps ?,,Yes,Yes
23956,TODO: get cleanup_regexps to clean up some of these according to what's coming next etc:,,,Yes
23958,TODO: is there a pause code?,,,Yes
23960,TODO: emphasis?,,,Yes
23961,"lex_filename not set (TODO: check what sort of lexicon is used by rsynth's \""say\"" front-end)",,,Yes
23963,BANA = Braille Authority of North America.  TODO: check if the UK accepted this standard.,,Yes,Yes
23965,(from \\u025c\\u02d0; TODO: check what happens to \\u025d),,,Yes
23966,TODO: \\u3042; \\u304a or \\u3046 depending on the word?,,Yes,Yes
23967,TODO: document KANA_V_AS_W variable.  Is vu always supported? (it doesn't seem to show up in all fonts),,,Yes
23969,sounds a bit better for words like 'with',,,Yes
23970,lengthen any word that ends up as a single kana (otherwise can be clipped badly),,,Yes
23972,(if you implement a new one; main() will detect it);,,Yes,Yes
23974,(well you could implement it if you want but the resulting ruby would be quite unwieldy),,Yes,Yes
23976,TODO: really want unbounded; but (?<=...) is fixed-length,,Yes,Yes
23977,TODO: leading 0s (0000048 goes to 0 000 048),,,Yes
23979,TODO: do we ever need to add extra consonants to the,,,Yes
23981,TODO: put this table somewhere else?,,No,Yes
23982,TODO: ;r?,,,Yes
23988,TODO: document LEXCONVERT_OMIT_READING_FROM (might be useful for the --mac-uk option),,Yes,Yes
23989,(or hyphen at start - move it to the previous),,Yes,Yes
23990,better move this splitpoint after that hyphen (TODO: move more than one character?),,No,Yes
23993,TODO: can we compress the BBC lexicon?  i.e. detect if a rule will happen anyway due to subsequent wildcard rules; and delete it if so (don't know how many bytes that would save),,,Yes
23994,Taken to the extreme; a 'find the least keystrokes' function would be some kind of data compressor; we're not doing that here as we assume this is going to be used to poke in a lexicon; which is basically ASCII with a few CHR$(128)s thrown in; this '$ operator' method is highly likely to yield the least keystrokes for that kind of data; apart from setting and using temporary string variables; but then (1) you're in the realms of data compression and (2) you require heap memory; which might not be a good idea depending on where we're putting our lexicon.,,,Yes
23995,if relocating to within this range; must move PAGE before loading RELOCAT. RELOCAT's supported range is 0xE00 to 0x5E00; omitting (PAGE-&1E00) to (PAGE+&E00),,No,Yes
23999,TODO: some sync issues persist even on the NON-Compact version in newer versions of macOS (e.g. 10.12).  This currently leads to exceptions in findW on such systems (which do say it could be due to wrong version of the voice); fixing would need looking at more sync issues as above,,Yes,Yes
24002,a 'hack' to make (at least the 2.x implementations of) textwrap ignore our chr(0) and chr(1) markers in their calculations.  Relies on textwrap calling len().,,,Yes
24004,shouldn't happen if setMultiple is called only once; but might be useful for small experiments in the Python interpreter etc,,,Yes
24008,Access the mask if needed,,No,Yes
24009,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
24011,FIXME doesnt allow default_value yet         #,,,Yes
24013,FIXME,,,Yes
24014,FIXME,,Yes,Yes
24015,FIXME,,Yes,Yes
24017,FIXME,,Yes,Yes
24018,FIXME,,Yes,Yes
24022,hack for pdfs; .pdf appended automatically by xelatex,,Yes,Yes
24024,meta.template = self.template  # FIXME implement,,No,Yes
24025,FIXME merge with dummy when        #,,,Yes
24026,airflow has better python3 support #,,No,Yes
24028,FIXME merge with dummy when        #,,,Yes
24031,TODO pull status args out of request,,Yes,Yes
24032,TODO only if allowed,,,Yes
24033,TODO only if allowed,,No,Yes
24034,TODO only if allowed,,,Yes
24035,FIXME,,Yes,Yes
24038,FIXME,,,Yes
24039,TODO,,Yes,Yes
24041,FIXME,,,Yes
24046,TODO \u53EF\u80FDloss\u672A\u4E0B\u964D\u7684\u539F\u56E0,,Yes,Yes
24047,data like {TM1:[xx;xx;xxx;xxx]},,Yes,Yes
24048,TODO step may be FRAMES\/\/2,,,Yes
24049,TODO: Allow Keras Lambda to use func arguments for output_shape?,,,Yes
24050,TODO: Remove or add option for static implementation.,,,Yes
24053,TODO: Remove extra computation shared with yolo_head.,,,Yes
24054,TODO: Adjust predictions by image width\/height for non-square images?,,Yes,Yes
24056,TODO: Expose tf.boolean_mask to Keras backend?,,Yes,Yes
24057,TODO: Something must be done about this ugly hack!,,,Yes
24058,TODO: Remove hardcoding of downscaling calculations.,,Yes,Yes
24059,TODO: It works with +1; don't know why.,,Yes,Yes
24060,TODO: Input layer size,,,Yes
24061,NOTE: support custom layers yet. Therefore; we'll need to implement,,Yes,Yes
24063,TODO: Repeat_elements and tf.split doesn't support dynamic splits.,,Yes,Yes
24067,Pad if needed,,No,Yes
24068,TF doesn't have a way to sort by two columns; so merge them and sort.,,Yes,Yes
24069,TODO: Rename target_bbox to target_deltas for clarity,,,Yes
24071,TODO: Filter out boxes with zero area,,No,Yes
24073,TODO: use smooth_l1_loss() rather than reimplementing here,,Yes,Yes
24074,TODO: Update this line to work with batch > 1. Right now it assumes all,,,Yes
24076,TODO: If multiple anchors have the same IoU match all of them,,Yes,Yes
24077,For positive anchors; compute shift and scale needed to transform them,,No,Yes
24078,TODO: use box_refinement() rather than duplicating the code here,,No,Yes
24080,TODO: verify that this handles zero padded ROIs,,Yes,Yes
24081,TODO: clean up (use tf.identify if necessary),,,Yes
24082,TODO: let DetectionLayer return normalized coordinates to avoid,,,Yes
24083,Work-around for Windows: Keras fails on Windows when using,,Yes,Yes
24084,TODO: move resizing to mold_image(),,,Yes
24087,"\""\""\"" || Training part of my solution to The 2018 Data Science Bowl || https:\/\/www.kaggle.com\/c\/data-science-bowl-2018 || Goal of the competition was to create an algorithm to || automate nucleus detection from biomedical images. ||  || author: Inom Mirzaev || github: https:\/\/github.com\/mirzaevinom || \""\""\""",,,Yes
24088,TODO: Build and use this function to reduce code duplication,,Yes,Yes
24093,TODO: Adds Fire interface,,Yes,Yes
24094,TODO: Need to wait for database to be ready before continuing,,,Yes
24097,TODO: is the contiguous necessary?,,,Yes
24100,TODO: replace with broadcasting,,,Yes
24101,TODO: NEEDS BETTER EXPLANATION\/ORGANISATION,,,Yes
24103,TODO,,Yes,Yes
24104,The polygon within the zoom; this is not needed. Therefore the option transform.,,,Yes
24106,somehow; for the numpad key in some machines; a check on Insert is needed aswell,,No,Yes
24107,Increase maybe,,Yes,Yes
24108,Move the layer up (negative offset) or down (postive offset),,No,Yes
24109,The index we want to move to,,Yes,Yes
24110,self.clearChanges() #TODO perhaps?,,No,Yes
24111,and set the required environment variables as needed; such that,,Yes,Yes
24113,and set the required environment variables as needed; such that,,Yes,Yes
24114,use a convolution with appropriate kernel; manually deal with the boundaries first,,Yes,Yes
24116,Check if C-Support is available for better performance,,No,Yes
24117,load ground truth instances; if needed,,,Yes
24118,IDs are needed.,,No,Yes
24119,IDs are needed.,,,Yes
24120,if the label is not known; but ends with a 'group' (e.g. cargroup),,No,Yes
24122,Enable mouse move events,,Yes,Yes
24124,TODO: these may only work for b33,,,Yes
24126,Configurable configuration,,,Yes
24127,A configurable that only allows one instance.,,Yes,Yes
24128,Global configurable class for shared config,,Yes,Yes
24129,A configurable preprocessor,,Yes,Yes
24132,TODO: Extract name splitter and OS Dependency.,,,Yes
24133,TODO: Extract name splitter and OS Dependency.,,Yes,Yes
24134,TODO: Add argparse and Refactor the code for sharing,,Yes,Yes
24135,Rotate model by 90 degrees around x-axis (z-up => y-up) to match ShapeNet's coordinates,,No,Yes
24137,XXX: may need this if you are lack of GPU memory,,Yes,Yes
24139,kernel_initializer=normalized_columns_initializer(1.0))[:;:;0],,Yes,Yes
24141,TODO: not sure what this architecture is (1),,No,Yes
24142,TODO: discriminator communication to get reward,,Yes,Yes
24144,XXX: don't know which way would be the best,,Yes,Yes
24145,Move the added items to the front of the path:,,No,Yes
24146,df_data = df_data.rename(columns = {'userid':'USERID'}),,Yes,Yes
24149,maybe improved later,,No,Yes
24152,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
24154,This is needed for notebook 5.0; 5.1; 5.2(maybe),,Yes,Yes
24155,# Mixin for configurable classes that work with connection files,,No,Yes
24156,This file will contain the IP; ports; and authentication key needed to connect,,,Yes
24157,Session(Configurable) configuration,,,Yes
24158,Sessions support configurable serialization via packer\/unpacker traits; and,,Yes,Yes
24162,# The kernel spec class.  This is configurable to allow subclassing of the,,,Yes
24163,If SSE S3 encryption is needed,,No,Yes
24164,If SSE KMS encryption is needed using a CMK,,,Yes
24165,"required=False; help=\""The text columns of the file. Allowed multiple; separed by comma (starting from 0)\"";",,,Yes
24166,TODO : multi-scale,,Yes,Yes
24168,very; very slowly; so do this rescaling manually,,Yes,Yes
24169,very; very slowly; so do this rescaling manually,,Yes,Yes
24171,if fetype == SINGLE:  # TODO: CHANGE!!!,,Yes,Yes
24173,TODO: why won't this right way of reading work?,,Yes,Yes
24174,TODO: not sure why there is a problem with getting the entire path for FE relations,,,Yes
24175,TODO: for now; it's only one hop,,,Yes
24176,todo map from parses to sentences,,,Yes
24177,TODO use optparse,,No,Yes
24179,TODO: clunky; there should be some inheritance; etc.,,,Yes
24180,TODO do some manual tokenization,,Yes,Yes
24181,TODO: we still don't have exemplar constituent parses,,Yes,Yes
24183,"with codecs.open(luIndex_file; \""r\""; \""utf-8\"") as xml_file: # TODO: why won't this right way of reading work?",,,Yes
24184,Hack: replace with anything the lemma is seen with.,,,Yes
24186,This is a huge hack,,No,Yes
24187,iteration to restore. recall that .solverstate file is needed!,,No,Yes
24188,iteration to restore. recall that .solverstate file is needed!,,No,Yes
24189,iteration to restore. *.solverstate file is needed!,,Yes,Yes
24190,iteration to restore. *.solverstate file is needed!,,,Yes
24191,[TODO] condition@44100,,,Yes
24192,The normal slider will move a little in the direction of mouse.And this one will move set the position,,Yes,Yes
24197,Workaround for python 2 vs python 3. _data in 2.x are length-1 strings;,,Yes,Yes
24198,haarclassifiers work better in black and white,,,Yes
24200,FIXME - code crashes here !!!,,No,Yes
24201,FIXME - libpng warning: iCCP: known incorrect sRGB profile,,No,Yes
24203,TODO check audio sounds and make decisions,,Yes,Yes
24207,TODO: Implement a space efficient character map data structure,,Yes,Yes
24210,FIXME: DON'T DO THIS!!!!!,,,Yes
24211,Fix Multiple Shadda's,,No,Yes
24213,TODO: Reinflect as backoff,,Yes,Yes
24214,TODO: Make sure this works with OSs other than Windows; Linux and Mac.,,Yes,Yes
24215,TODO: Use camel_tools.data instead (after reimplementing it).,,Yes,Yes
24218,TODO: Temporary fix to get unique analyses,,Yes,Yes
24219,TODO: Throw an error,,No,Yes
24222,TODO: This should be made more generic such that it can be leveraged by dexec and jupyter,,No,Yes
24223,Add the prime task to generate needed project files,,Yes,Yes
24224,Appends copy commands to the Dockerfile in order to add the needed Kerberos files to the correct location based on config,,Yes,Yes
24233,todo add meta files for single cells,,,Yes
24234,TODO: remove,,No,Yes
24235,TODO: finish meta,,Yes,Yes
24236,TODO,,Yes,Yes
24237,TODO,,Yes,Yes
24239,TODO,,,Yes
24240,TODO,,Yes,Yes
24241,TODO,,Yes,Yes
24244,TODO: make nice,,Yes,Yes
24247,TODO: is this really enough?,,,Yes
24251,TODO,,,Yes
24252,TODO,,,Yes
24253,TODO,,Yes,Yes
24260,TODO change place,,,Yes
24261,TODO,,,Yes
24263,TODO: this might be a bug or rather how dod i come up with this,,,Yes
24265,i.e. maybe it's better to take the ceil not the floor,,Yes,Yes
24266,TODO: the clustering should return the maximal number,,Yes,Yes
24267,i.e. maybe it's better to take the ceil not the floor,,,Yes
24268,TODO implement loglik,,Yes,Yes
24270,TODO: this needs to be solved better,,,Yes
24273,todo: switch to <str>.format,,,Yes
24274,todo: switch to <str>.format,,Yes,Yes
24275,todo: move to util,,No,Yes
24277,todo: This is a very fragile way to read and write out data,,,Yes
24279,todo: do not ignore second output of integrate.quad (errors\/warnings)?,,No,Yes
24280,todo: wrap into class,,No,Yes
24281,todo: Perhaps implement that similar to flavio or use values from flavio in the first place?,,Yes,Yes
24282,todo: move to a more elaborate plotting concept like https:\/\/scipy-cookbook.readthedocs.io\/items\/Matplotlib_UnfilledHistograms.html for unfilled histograms,,,Yes
24283,todo: use np.array rather than list!,,No,Yes
24284,fixme: not working yet,,Yes,Yes
24285,todo: writeout should be different method,,Yes,Yes
24286,todo: make method more flexible,,,Yes
24292,todo: rename this file,,,Yes
24294,todo: switch to more flexible keyword approach as below,,,Yes
24295,todo: move this script somewhere more sensible,,No,Yes
24296,todo: move to a more elaborate plotting concept,,,Yes
24302,todo: factor out the common part of scatter and fill into its own method?,,No,Yes
24303,todo: add basic command line interface?,,,Yes
24305,'Index columns' are by default the columns that hold the wilson,,Yes,Yes
24307,todo: document attributes,,No,Yes
24308,todo: implement interpolation,,,Yes
24309,todo: implement in subclass,,Yes,Yes
24310,todo: method to change cluster names or add several as different columns,,Yes,Yes
24311,todo: the available options depend on the choice of algorithm; so this should be checked for,,Yes,Yes
24313,todo: use new python path class; rather than clumsy methods,,,Yes
24314,todo: this shouldn't be necessary if setup axes worked as expected,,,Yes
24315,todo: supply our precalculated metric again?,,,Yes
24317,todo: should be same colors as above; so maybe make colors a global variable or somethign,,Yes,Yes
24318,The names of the columns that hold the bin contents,,Yes,Yes
24320,todo: supply our precalculated metric again?,,,Yes
24321,todo: should be same colors as above; so maybe make colors a global variable or somethign,,Yes,Yes
24322,we just need them at one scale it is more efficient to write them directly),,Yes,Yes
24323,todo: perhaps split up in install_requires and extras_require,,Yes,Yes
24325,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
24327,: Maximal number of columns of the subplot grid,,,Yes
24328,: The names of the columns that hold the Wilson coefficients,,Yes,Yes
24329,fixme: Maybe not take _setup_all?,,No,Yes
24331,todo: this stays untouched by decorrelation; right?,,Yes,Yes
24333,fixme,,,Yes
24335,todo: make pycharm ignore name convention pylinting in this file,,,Yes
24336,todo: update example in docstring,,No,Yes
24337,todo: move this check somewhere,,,Yes
24340,todo: set nbins ourself,,,Yes
24341,todo: docstring,,,Yes
24344,todo: I wish we could do that in a more clever way than relying on so many,,,Yes
24345,todo: make flexible,,Yes,Yes
24346,todo: perhaps read from requirements.txt,,Yes,Yes
24347,todo: this should be refactored to take the Cluster object instead,,Yes,Yes
24348,todo: option to disable legend,,,Yes
24352,todo: document,,,Yes
24354,todo: document attributes,,No,Yes
24357,fixme: no; we need something more clever; because now it's,,No,Yes
24359,todo: more general?,,,Yes
24362,todo: docstring,,No,Yes
24364,todo: document,,,Yes
24366,todo: document!,,No,Yes
24368,fixme,,Yes,Yes
24370,fixme: perhaps don't allow new_column but rather give copy method,,,Yes
24374,todo: can actually do that with setup_requires,,,Yes
24375,todo: implement set_spoints in a more general way here!,,,Yes
24377,todo: this probably doesn't work as easy as this; because linspaces will,,,Yes
24379,todo: order dict to avoid changing results,,No,Yes
24381,fixme @caveat below: perhaps we should simply do that ourselves then?,,No,Yes
24383,todo: add usage example to docstring,,No,Yes
24384,todo: ideally; we could just copy the docstrings from plot_bundles etc;,,Yes,Yes
24389,todo: use d.clusters,,No,Yes
24390,todo: do we really need to reinitialize this?,,,Yes
24391,'Index columns' are by default the columns that hold the wilson,,,Yes
24392,todo: use d.clusters,,No,Yes
24395,todo: why is this docstring not recognized in sphinx?,,,Yes
24396,todo: docs,,No,Yes
24401,todo: this is somewhat problematic; because this won't add space,,,Yes
24402,todo: perhaps use this: https:\/\/personal.sron.nl\/~pault\/,,Yes,Yes
24403,todo: perhaps this should just be done in a different way; the faded,,Yes,Yes
24405,Because of our hack with the imaginary prefix; let's first see which,,,Yes
24407,Because of our hack with the imaginary prefix; let's first see which,,,Yes
24408,todo: doc,,No,Yes
24410,todo: also allow to disable multiprocessing if there are problems.,,No,Yes
24411,todo: implement sampling as well; not just binning,,Yes,Yes
24412,Because of our hack with the imaginary prefix; let's first see which,,,Yes
24420,todo: doc,,,Yes
24421,fixme: Should already be set in worker class,,No,Yes
24424,todo: make prop,,No,Yes
24425,todo: Allow reusing of hierarchy,,No,Yes
24426,todo: Result class?,,Yes,Yes
24430,todo: document,,,Yes
24431,todo: document,,No,Yes
24432,todo: document,,,Yes
24433,todo: document,,,Yes
24434,todo: document,,No,Yes
24435,todo: expand doc,,No,Yes
24440,todo: getting the bpoint should be a different function,,,Yes
24441,todo: this is horribly inefficient,,,Yes
24442,todo: Make factory method?,,Yes,Yes
24444,todo: add cluster column setting in init,,Yes,Yes
24447,todo: configure bpoint column,,No,Yes
24449,"\""\""\"" This additional file is needed to avoid circular imports; because metric.py || has dependencies on the DWE class. || \""\""\""",,Yes,Yes
24450,todo: this calculates the full n x n matrix; even though it's symmetric,,Yes,Yes
24452,todo: type hints,,,Yes
24455,TODO: NIPALS,,No,Yes
24456,FIXME: Is this really supposed to be divided by the number of variables?,,,Yes
24461,IDEA: Shouldn't this be the quotient,,Yes,Yes
24462,TODO: This calculation is not correct,,Yes,Yes
24464,TODO: Check if this makes sense,,,Yes
24465,TODO: Clear if this is the better way of calculating A,,No,Yes
24466,TODO: Clear purpose of this line,,No,Yes
24468,Other way to calculate block importances,,Yes,Yes
24476,Adds the best performing parameter to the parameter list,,Yes,Yes
24478,Adds the best performing parameter to the parameter list,,Yes,Yes
24485,## Return whether a bee's fitness average is better than the current best fitness score,,No,Yes
24487,TODO: Add wrapper for Dragon software,,Yes,Yes
24488,16th puzzle; 25th move; base(AUGC) of move\uFFFF,,,Yes
24489,''' || data_6892344 = read_movesets(os.getcwd() + '\/movesets\/move-set-11-14-2016.txt';6892344) || print len(data_6892344) || lens = [len(x) for x in j for j in data_6892344] || print lens || print sum(lens) ||  || def encode_movesets_dataframe(moveset): ||      ||     pass ||  || columns = ['pid';'time';'base';'loc'] || edf = pd.DataFrame(index=range(sum(lens));columns=columns;dtype='float') || print edf || ''',,,Yes
24491,''' || for i;j in (zip(encoded_bf;encoded)): ||     #print i ||     for m in j: ||         #print m[1] ||         X.append(i) ||         y.append(m) ||         loc = m[1] - 1 ||         #i = i[loc].replace(m[0]) ||         i[loc] = m[0] ||  || for move in ((encoded)): ||     for i in move: ||         pass || ''',,No,Yes
24492,''' || l = [] || movesets = [[{'base':'G';'pos':3}];[{'base':'A';'pos':8};{'base':'U';'pos':12}]] || for move in movesets: ||   for i in move: ||     pass ||  || def encode_movesets_v0(moveset): ||     ms = [] ||     max_moves = longest(moveset) ||     for k in moveset: ||         #max_moves = len(max(k;key=len)) ||         #max_moves = longest(k) ||         soln = [] ||         #if k[0][0]['type'] == 'reset': ||          #   data_6892344.pop(data_6892344.index(k)) ||         for i in k: ||             n_moves = len(i) ||             i_moves = [] ||             for j in i: ||                 if 'type' in j: ||                     i_moves.append([1;12345]) ||                 elif j['base'] == 'A': ||                     i_moves.append([1;j['pos']]) ||                 elif j['base'] == 'U': ||                     i_moves.append([2;j['pos']]) ||                 elif j['base'] == 'G': ||                     i_moves.append([3;j['pos']]) ||                 elif j['base'] == 'C': ||                     i_moves.append([4;j['pos']]) ||                 elif j['type'] == 'paste' or j['type'] == 'reset': ||                     continue ||             #i_moves = [i_moves] ||             i_moves = i_moves + (max_moves - n_moves)*[[0;0]] ||             soln.append(i_moves) ||         ms.append(soln) ||  ||     return ms || ''',,Yes,Yes
24493,FIX THIS URGENT,,Yes,Yes
24494,player.append([0;0]) # FIX THIS URGENT,,,Yes
24495,columns = ['pid';'time';'base';'loc'],,,Yes
24498,player.append([1;1]) # FIX THIS URGENT,,,Yes
24499,player.append([1;1]) #continue #FIX,,No,Yes
24500,continue #player.append([0;0]) # FIX THIS URGENT,,No,Yes
24502,FIX THIS URGENT,,Yes,Yes
24503,player.append([1;1]) #continue #FIX,,No,Yes
24504,print move,,,Yes
24505,print move,,Yes,Yes
24506,''' || Implements the Domain Specific Pipeline (DSP) || Runs an MCTS modified to implement Eterna player strategies || Second process of the SAP || ''',,Yes,Yes
24507,''' || Returns move sets from a specific player ||  || :param uid: The user ID of the Eterna player || :return: The move sets of that player || :return: The list of puzzle IDs of puzzles that he\/she has solved || ''',,Yes,Yes
24508,''' || Returns move sets for a specific puzzle only 1 user has solved ||  || :param uid: The user's ID || :param pid: The puzzle ID || :param df: Whether you want the returned move sets to be in a pandas dataframe or a list || :return: The move sets either in a list or a pandas dataframe || ''',,Yes,Yes
24510,''' || Uses RNAfold to calculate energies of RNA sequences folded into target structures ||  || :param sequence: An RNA sequence || :param structure: A target structure in dot-bracket notation || :return: Gibbs free energy in kcal\/mol || ''',,Yes,Yes
24511,''' || For every move change; updates the complete sequence of the RNA; updated || to support pasting and resetting ||  || :param ms: The encoded move sets || :param struc: Encoded structure ||  || :return: List of updated base sequences for every base change || ''',,,Yes
24515,''' || Encodes the labels for locationCNN ||  || :param moveset: The move set list || :return: One-hot encoded location vectors || ''',,,Yes
24516,print move,,Yes,Yes
24524,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
24525,move the model files to the parent directory (to meet the WML convention),,Yes,Yes
24526,this is a very small range; the model should be improved in the future,,Yes,Yes
24527,This is ugly; but required - we are creating a new variable at runtime; so we,,Yes,Yes
24528,TODO: figure out what this actually does,,No,Yes
24529,TODO: parse `options`,,,Yes
24532,TODO: Parse the HTTP objects properly,,,Yes
24536,Needed in deriv2.py to create C program from network,,,Yes
24537,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24539,names of c-code files needed by deriv2.py (. for extension only),,,Yes
24540,Needed in deriv2.py to create C program from network,,,Yes
24541,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24543,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24545,Needed in evolution_gill to define evol algorithm and create initial network,,,Yes
24546,move around,,,Yes
24547,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24548,Needed in deriv2.py to create C program from network,,No,Yes
24549,Needed in evolution_gill to define evol algorithm and create initial network,,,Yes
24550,move around,,No,Yes
24551,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24552,Needed in deriv2.py to create C program from network,,No,Yes
24554,fitness functions. When running pareto optimization; network X is only considered better,,No,Yes
24556,names of c-code files needed by deriv2.py (. for extension only),,,Yes
24557,Needed in deriv2.py to create C program from network,,,Yes
24560,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
24561,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24564,move around,,No,Yes
24565,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24566,Needed in deriv2.py to create C program from network,,,Yes
24567,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24568,names of c-code files needed by deriv2.py (. for extension only),,,Yes
24569,Needed in deriv2.py to create C program from network,,,Yes
24570,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24571,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24574,names of c-code files needed by deriv2.py (. for extension only),,No,Yes
24576,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24579,Needed in evolution_gill to define evol algorithm and create initial network,,Yes,Yes
24580,move around,,No,Yes
24581,parameters needed to perform evolution.,,Yes,Yes
24583,parameters needed to perform evolution.,,Yes,Yes
24586,parameters needed to perform evolution.,,Yes,Yes
24589,parameters needed to perform evolution.,,,Yes
24590,Lists containing the ligand concentrations and dissociation times of interest. Needed for the init_history file and compte_deriv_inC.,,,Yes
24591,with previous convention s[1+ncell*size+ngene] contains P_ngene_Cell_ncell,,Yes,Yes
24592,if ends the loop; that means that there is no type consistency,,No,Yes
24595,Needed in evolution_gill to define evol algorithm and control output,,Yes,Yes
24596,"\""\""\"" ||     The dictionary_mutation[] has ; mutation will exec the key. ||      ||   The rates referring to 'mutate' change parameters.   See initialization file for samples ||     The  are in dictionary_ranges; whose keys are of form Node.attribute; see rand_modify(). ||     The lists below are names of Nodes that are subject to indicated operations; needed in various routines below || \""\""\""",,Yes,Yes
24597,with previous convention s[1+ncell*size+ngene] contains P_ngene_Cell_ncell,,Yes,Yes
24598,initialize attributs for each network needed in loop over generations,,No,Yes
24599,duplicates best half,,,Yes
24600,needed when base class in another file it appears,,,Yes
24601,needed when base class in another file it appears,,No,Yes
24604,Create a directory if needed and check if data already present,,Yes,Yes
24606,parameters needed to perform evolution.,,Yes,Yes
24607,parameters needed to perform evolution.,,Yes,Yes
24608,parameters needed to perform evolution.,,,Yes
24609,parameters needed to perform evolution.,,Yes,Yes
24610,Lists containing the ligand concentrations and dissociation times of interest. Needed for the init_history file and compte_deriv_inC.,,,Yes
24612,Needed in deriv2.py to create C program from network,,,Yes
24613,Needed in evolution_gill to define evol algorithm and create initial network,,,Yes
24614,wait here until job completion of all other processors; do not know why; should try to remove it at some point for performance,,,Yes
24615,names of c-code files needed by deriv2.py (. for extension only),,,Yes
24616,Needed in deriv2.py to create C program from network,,No,Yes
24621,"\""\""\""This script is used to fix a file we want to use as input of \""persist.py\""; when it has a particular encoding problem. || The problem seems to be related with a difference between how different Python versions handle string literals. || First; note that the input file is not a real json; but a list of Python dicts printed (i.e.; `print(dict)` vs || `print(json.dumps(dict))`). So; there are string literals. The file may be in UTF-8; but the thing is that the string || literals may contain Unicode-escaped symbols (e.g.; `\\\\xNN`; `\\\\uNN` or `\\\\UNNNN`); which represent bytes in different || encodings. In the default compiled version of CPython 3.6 in Linux; it represents them internally in UTF-8; but || in Python 2.7 apparently it does so UTF-16; or at least that's my understanding (see || https:\/\/docs.python.org\/2\/howto\/unicode.html#the-unicode-type). So Unicode-escaped symbols change. || I don't find an easy way to fix it; more than re-downloading the tweets; which is fairly fast.\""\""\""",,Yes,Yes
24623,Add the layer to unused,,Yes,Yes
24625,Check if some layers are unused,,,Yes
24626,TODO: must be slug,,,Yes
24627,this is just a hack to allow all pods to write to logs,,Yes,Yes
24628,This is a hack; in the future we need to gather the paths of the experiments,,Yes,Yes
24629,TODO,,,Yes
24630,TODO,,Yes,Yes
24633,"\""\""\"" || This module holds all configurations needed for preprocessing. || \""\""\""",,Yes,Yes
24635,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
24636,HACK; we need access to the Poly instance in order to expand the matrix!,,,Yes
24639,check each element of the tuple separately (needed for when the tuple elements are themselves batches),,No,Yes
24640,"\""\""\""Continuous-variable quantum neural network. ||  || In this demo we implement the cv-qnn of Ref XXX with the || example of function fitting. || \""\""\""",,,Yes
24641,TODO: back to multidim arrays,,No,Yes
24644,todo,,,Yes
24650,:T; #todo: implement,,,Yes
24651,:SqrtX; #todo: implement,,,Yes
24652,:SqrtSwap; #todo: implement,,,Yes
24653,:R; #todo: implement,,,Yes
24654,todo: handling of output should be better encapsulated from the plugin developers,,Yes,Yes
24662,check each element of the tuple separately (needed for when the tuple elements are themselves batches),,No,Yes
24663,todo: make this a class property,,,Yes
24665,'QubitUnitary': QubitUnitary; #todo: not natively supported by ProjectQ,,,Yes
24668,todo: update depending on https:\/\/github.com\/ProjectQ-Framework\/ProjectQ\/issues\/268,,Yes,Yes
24669,"\""\""\""Quantum Neural Network. ||  || In this demo we implement a variational classifier inspired by || Farhi & Neven 2018 (arXiv:1802.06002) and || Schuld et al. 2018 (arXiv:1804.00633). || \""\""\""",,Yes,Yes
24671,todo: remove once we no longer capture the exception further down,,,Yes
24674,todo: fix depending on how https:\/\/github.com\/XanaduAI\/openqml\/issues\/87 is resolved.,,,Yes
24676,TODO: Frombitstring!,,,Yes
24677,import traceback #todo: remove once we no longer capture the exception further down,,,Yes
24678,todo: shomehow the implementation of expval() in the classical simulator was lost!?!,,,Yes
24679,todo: fix depending on how https:\/\/github.com\/XanaduAI\/openqml\/issues\/87 is resolved.,,,Yes
24680,todo: shomehow the implementation of expval() in the classical simulator was lost!?!,,,Yes
24681,.. todo:: Potentially remove this gate depending on how https:\/\/github.com\/XanaduAI\/pennylane\/issues\/61 is resolved.,,No,Yes
24683,TODO: what is this ?,,,Yes
24684,a hack to make sure all sentences are at least 5 tokens. CNN breaks otherwise.,,Yes,Yes
24685,"\""\""\"" || Dev notes || ========= ||  || GUI interactions: ||  || * Right clicking should do ds9-style stretch adjustment. (*not* the same as ||   the ``stretch`` property - here I mean \""brightness\/contrast\"" adjustment ||   within the bounds of a given stretch) || * The user should be able to pan the view interactively.  This can be via ||   middle clicking on the new center; click-and-drag; or scrolling (i.e. with ||   touchpad a la what ginga does). The properties ``click_drag``; ||   ``click_center``; and ``scroll`` can turn on\/off these options ||   (as does the \""selection\"" mode). || * Zooming - if ``scroll_pan`` is False (probably the default); zooming is via ||   the scroll wheel. || * \""Selection mode\"" - see ``select_points`` method. || * If the user provides an NDData or fits input (assuming the fits file has ||   valid WCS); if the cursor is not turned off it shows both the pixel ||   coordinates and the WCS coordinates under the cursor. ||  || Initially; *no* keyboard shortcuts should be implemented.  Eventually there || should be a clear mapping from keyboard shortcuts to methods; but until the || methods are stabilized; the keyboard shortcuts should be avoided. ||  || Other requirements: ||  || * Should be able to hanle ~4k x 4k images without significant performance ||   lagging. || * Should be able to handle ~1000x markers without significant performance ||   degredation. || * Stretch goal: hould be able to handle ~10k x 10k images acceptable || * Extra-stretchy goal: handle very large datasets using a \""tiling\"" approach. ||   This will presumably require different ``load_*`` functions; and more ||   cleverness on the JS side. ||  || A few more notes: ||  || * We should be subclassing some kind of ipywidget; ||   likely Box is the best choice. || * If we do that; then _repr_html is unnecessary (and undesirable); because ||   the widget machinery will take care of it. || * Really like to avoid middle-click interactions; or at least I would like ||   them to have an alias that works on a trackpad or a two-button mouse. || * I'd like a little more flexibility in adding markers (i.e.; not necessarily ||   require the use of a table; though that should be one way to do it). || * I also think we need at least minimal ability to change\/set marker color; ||   shape very early on. ||  || \""\""\""",,Yes,Yes
24686,TODO: Is this the best place for this?,,No,Yes
24687,TODO: Implement more shapes,,Yes,Yes
24688,TODO: Resolve https:\/\/github.com\/ejeschke\/ginga\/issues\/672,,,Yes
24693,Thus; any C-extensions that are needed to build the documentation will *not*,,,Yes
24695,typing as a dependency for 1.6.1+ Sphinx causes issues when imported after,,No,Yes
24697,TODO: Maybe enable checking for a specific version of astropy_helpers?,,,Yes
24700,XXX: May block if either stdout or stderr fill their buffers;,,Yes,Yes
24705,TODO:,,No,Yes
24710,hack to get around no reduce_dot,,Yes,Yes
24711,TODO : Implement validation set accuracy and early stop,,Yes,Yes
24712,hack to get around no reduce_dot,,Yes,Yes
24713,TODO : Implement validation set accuracy and early stop,,,Yes
24714,"\""Perhaps you need to set num_units to the keys' dimension (%s)?\""",,No,Yes
24716,fix to include last batch,,Yes,Yes
24718,fix to include last batch,,Yes,Yes
24719,if level 0; pass. there is no rule to implement,,Yes,Yes
24720,if level 0; pass. there is no rule to implement,,,Yes
24721,remove RDR files and copy them if needed,,Yes,Yes
24723,this should be dark and maybe a little green,,,Yes
24724,got a response; move on,,Yes,Yes
24726,Punctuation that ends a sentence,,,Yes
24728,Date is probably wrong way around,,No,Yes
24729,TODO: Support multiple-char unicode fractions that,,Yes,Yes
24732,Punctuation that ends a sentence,,No,Yes
24733,TODO: These options will become settable configuration switches,,,Yes
24734,Punctuation that ends a sentence,,No,Yes
24735,TODO STILLING Klukka sameinu\u00F0,,Yes,Yes
24736,TODO STILLING Sameina \u00ED dagsetningu; bara fara \u00ED ef stilling er valin?,,,Yes
24737,TODO STILLING \u00DEarf l\u00EDka s\u00E9rstillingu fyrir a\u00F0 sn\u00FAa \u00FEessu ekki vi\u00F0; leyfa a\u00F0 standa eins og er,,,Yes
24740,TODO STILLING H\u00E9r \u00FEarf a\u00F0 vera h\u00E6gt a\u00F0 velja um a\u00F0 hafa bandstriki\u00F0 \u00ED n\u00FAmerinu - convert_telnos?,,,Yes
24742,TODO STILLING  H\u00E9r er stillingin convert_numbers notu\u00F0,,,Yes
24743,TODO STILLING H\u00E9r er stillingin convert_numbers notu\u00F0. \u00DEarf l\u00EDka a\u00F0 geta merkt sem villu.,,,Yes
24745,TODO STILLING H\u00E9r er m\u00F6guleg g\u00E6salappastilling. H\u00E9r eru g\u00E6salappir utan um stakt or\u00F0.,,Yes,Yes
24748,TODO STILLING \u00FEremur st\u00F6kum punktum breytt \u00ED \u00FEr\u00EDpunkt,,Yes,Yes
24749,TODO STILLING kommum \u00ED upphafi or\u00F0s breytt \u00ED g\u00E6salappir,,Yes,Yes
24751,TODO STILLING viljum vi\u00F0 pikka netf\u00F6ng \u00ED sundur?,,Yes,Yes
24752,TODO STILLING sleppa a\u00F0 r\u00EDfa af? Er sameina\u00F0 s\u00ED\u00F0ar ef seinni hlutinn er m\u00E6lieining; en \u00FE\u00E1 me\u00F0 bili \u00E1 milli,,Yes,Yes
24753,TODO STILLING Eitthva\u00F0 h\u00E9r \u00ED sambandi vi\u00F0 URL?,,No,Yes
24754,TODO STILLING myllumerki og samsett or\u00F0 me\u00F0 myllumerki klippt.,,Yes,Yes
24758,TODO STILLING svipa\u00F0 h\u00E9r; setja \u00ED stillingamengi lei\u00F0r\u00E9ttingar.,,,Yes
24759,TODO STILLING sko\u00F0a hva\u00F0 er gert h\u00E9r.,,Yes,Yes
24760,TODO STILLING viljum vi\u00F0 skipta \u00FEessu \u00ED tvo t\u00F3ka?,,,Yes
24761,TODO STILLING Viljum merkja sem villu fyrir m\u00E1lr\u00FDni; og hafa sem m\u00F6gulega stillingu.,,,Yes
24762,TODO STILLING Viljum geta vali\u00F0 a\u00F0 breyta bandstrikinu. Ath. \u00FE\u00F3 a\u00F0 or\u00F0i\u00F0 er sameina\u00F0 s\u00ED\u00F0ar; \u00FE\u00E1 v\u00E6ri h\u00E6gt a\u00F0 setja bandstriki\u00F0 aftur \u00E1 sinn sta\u00F0. Viljum l\u00EDka geta skipt \u00FEessu \u00ED \u00F3l\u00EDka t\u00F3ka.,,Yes,Yes
24763,TODO STILLING G\u00E6salappir,,Yes,Yes
24764,TODO STILLING Endar eitthva\u00F0 h\u00E9r? Viljum vi\u00F0 ekki geta merkt \u00FEetta sem villu? \u00DEa\u00F0 getur kannski gerst s\u00ED\u00F0ar?,,Yes,Yes
24766,TODO JA\u00D0AR Sko\u00F0a \u00FEetta betur \u00ED ja\u00F0artilvikum.,,Yes,Yes
24767,TODO STILLING H\u00E9r \u00FEyrfti a\u00F0 b\u00E6ta vi\u00F0 punkti \u00ED skammst\u00F6funina fyrir tilrei\u00F0ingar\u00FAttaki\u00F0.,,Yes,Yes
24769,TODO STILLING Skipta \u00FAt fyrir hva\u00F0? Og ekki bor\u00F0a punktinn.,,Yes,Yes
24771,TODO STILLING Sleppa a\u00F0 sameina? E\u00F0a sl\u00EDta \u00ED sundur s\u00ED\u00F0ar?,,Yes,Yes
24772,TODO JA\u00D0AR Sko\u00F0a hva\u00F0 ver\u00F0ur um \u00FEannig s\u00EDman\u00FAmer.,,,Yes
24775,"TODO STILLING Sleppa a\u00F0 sameina e\u00F0a r\u00EDfa \u00ED sundur s\u00ED\u00F0ar? H\u00E9r er l\u00EDka villa a\u00F0 \""5 mars\"" greinist sem dagsetning; vantar punktinn.",,Yes,Yes
24779,TODO STILLING sleppa a\u00F0 r\u00EDfa af? Er sameina\u00F0 s\u00ED\u00F0ar,,,Yes
24781,TODO STILLING Viljum geta vali\u00F0 a\u00F0 breyta bandstrikinu.,,No,Yes
24782,TODO STILLING Sleppa a\u00F0 sameina e\u00F0a r\u00EDfa \u00ED sundur s\u00ED\u00F0ar?,,No,Yes
24783,TODO STILLING Sleppa a\u00F0 sameina e\u00F0a sl\u00EDta \u00ED sundur?,,,Yes
24784,!!! TODO: A better solution would be to convert 2.5.1 to (2;5;1),,No,Yes
24785,Assume that this ends a sentence: cut the,,No,Yes
24786,TODO LAGA sleppa \u00FEessu??,,,Yes
24791,TODO use millisecond information in token,,Yes,Yes
24792,This is a small hack to satisfy the Mypy type checker,,No,Yes
24795,"TODO STILLING \u00ED MONTHS eru einhverjar villur eins og \""septembers\"";",,Yes,Yes
24797,TODO wrong val but correct tokenization,,,Yes
24798,Otherwise; select the child nodes needed for current iteration,,Yes,Yes
24799,parent_offsets and child_offsets contain the integer indexes needed to index into the feature and,,Yes,Yes
24801,parent_indexes and child_indexes contain the integer indexes needed to index into,,Yes,Yes
24803,no flip; comment this line if results on flipped images are needed.,,Yes,Yes
24808,TODO Virer Sans avocat,,,Yes
24814,TODO add new offsets here,,,Yes
24815,TODO REMOVE CONSEILLER,,,Yes
24817,TODO delete when not required,,,Yes
24820,TODO remove de au debut du nom,,No,Yes
24829,TODO should be 47 instead of 49,,Yes,Yes
24830,TODO set port in config,,Yes,Yes
24831,TODO remove,,Yes,Yes
24836,TODO MERGE LINES IF LOWER AT THE END FOLLOWED BY LOWER AT THE BEGINNING,,,Yes
24837,TODO MERGE LINES IF LOWER AT THE END FOLLOWED BY LOWER AT THE BEGINNING,,Yes,Yes
24838,TODO convert to assert when fixed,,Yes,Yes
24844,todo: corpus.vocab_size + 1?,,,Yes
24846,TODO: this logic should be in a pilot or modle handler part.,,Yes,Yes
24847,"\""\""\"" || Created on Wed Sep 13 21:27:44 2017 ||  || @author: wroscoe || \""\""\""",,No,Yes
24849,map absolute angle to angle that vehicle can implement.,,,Yes
24852,map absolute angle to angle that vehicle can implement.,,,Yes
24853,TODO: convert this flask app to a tornado app to minimize dependencies.,,No,Yes
24855,"\""\""\"" || Created on Sat Jun 24 20:10:44 2017 ||  || @author: wroscoe ||  || remotes.py ||  || The client and web server needed to control a car remotely. || \""\""\""",,,Yes
24856,"\""\""\"" || Scripts to drive a donkey 2 car and train a model for it. ||  || Usage: ||     manage.py (drive) [--model=<model>] [--js] [--chaos] ||     manage.py (train) [--tub=<tub1;tub2;..tubn>]  (--model=<model>) [--base_model=<base_model>] [--no_cache] ||  || Options: ||     -h --help        Show this screen. ||     --tub TUBPATHS   List of paths to tubs. Comma separated. Use quotes to use wildcards. ie \""~\/tubs\/*\"" ||     --js             Use physical joystick. ||     --chaos          Add periodic random steering when manually driving || \""\""\""",,,Yes
24858,TODO add augmentation that doesn't use opencv,,Yes,Yes
24859,"\""\""\"" || Web controller. ||  || This example shows how a user use a web controller to controll || a square that move around the image frame. ||  ||  || Usage: ||     manage.py (drive) [--model=<model>] ||     manage.py (train) [--tub=<tub1;tub2;..tubn>] (--model=<model>) ||  || \""\""\""",,No,Yes
24860,This is only needed because the part run_contion only accepts boolean,,Yes,Yes
24862,Noe that this is less memory and cpu efficient,,Yes,Yes
24863,again; not as efficient as matlab,,Yes,Yes
24864,ah; ugly. Would be better to have k = 7 in init;,,Yes,Yes
24865,"\""\""\"" || Applies Mutual Proximity (MP) [1] on a distance matrix. The return value is || converted to a distance matrix again. The resulting distance matrix || should show lower hubness. ||  || This file is part of the HUB TOOLBOX available at || http:\/\/ofai.at\/research\/impml\/projects\/hubology.html || (c) 2013; Dominik Schnitzer <dominik.schnitzer@ofai.at> ||  || Usage: ||   Dmp = mutual_proximity(D; type) - Applies MP on the distance matrix 'D' ||      using the selected variant ('type'). The transformed distance matrix ||      is returned. ||  || Possible types: ||   'empiric': Uses the Empirical distribution to perform Mutual Proximity. ||   'gauss': (requires the Statistics Toolbox (the mvncdf() function) ||      Assumes that the distances are Gaussian distributed. ||   'gaussi': Assumes that the distances are independently Gaussian ||      distributed. (fastest Variante) ||   'gammai': Assumes that the distances follow a Gamma distribution and ||      are independently distributed. ||  || [1] Local and global scaling reduce hubs in space;  || Schnitzer; Flexer; Schedl; Widmer; Journal of Machine Learning Research 2012 || This file was ported from MATLAB(R) code to Python3 || by Roman Feldbauer <roman.feldbauer@ofai.at> ||  || @author: Roman Feldbauer || @date: 2015-09-25 || \""\""\""",,No,Yes
24866,TODO CHECK CORRECTNESS!!,,Yes,Yes
24869,#TODO randomization,,,Yes
24870,# TODO vectorize to gain speed,,Yes,Yes
24872,TODO end remove,,Yes,Yes
24877,TODO implement similarity based MP,,No,Yes
24884,TODO implement,,Yes,Yes
24885,TODO change np.tile to broadcasting,,Yes,Yes
24888,pass # TODO implement,,No,Yes
24890,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
24891,# TODO calculation WRONG,,Yes,Yes
24892,TODO implement,,,Yes
24894,# TODO will need to adapt cdist call below...,,No,Yes
24895,all columns are training in this case,,Yes,Yes
24896,Use efficient version for cityblock distances,,,Yes
24897,Use efficient version for Euclidean distances,,Yes,Yes
24900,set distances of other objects TO them to NaN (columns).,,Yes,Yes
24901,XXX perhaps map to sufficiently high dim with MDS; then calc ID??,,,Yes
24902,TODO,,Yes,Yes
24903,Well; I don't understand; why it works for S and y this way;,,Yes,Yes
24904,TODO change to np.partition for PERF,,Yes,Yes
24905,TODO: implement cosine distances.,,Yes,Yes
24906,Permanently add best center candidate found in local tries,,No,Yes
24909,TODO add X_nrom_squared,,No,Yes
24913,TODO to allow different number of explicit entries per row;,,,Yes
24914,TODO That should probably also be diveded by k...,,Yes,Yes
24915,Work-around for new scikit-learn requirement of 1D arrays for LabelEncoder,,,Yes
24916,TODO: Load the data!!,,,Yes
24918,Workaround to forbid tensorflow from crashing the gpu,,Yes,Yes
24919,Fix memory leak (Keras bug),,Yes,Yes
24920,TODO: Remove this lazy hardcoded paths,,No,Yes
24921,Workaround to forbid tensorflow from crashing the gpu,,,Yes
24922,TODO: fix this stupid patch.,,,Yes
24923,Workaround to forbid tensorflow from crashing the gpu,,Yes,Yes
24925,Workaround to forbid tensorflow from crashing the gpu,,,Yes
24926,TODO: using z_color temporarily. must address this.,,No,Yes
24927,TODO: using z_color temporarily. must address this.,,No,Yes
24928,TODO: put package requirements here,,No,Yes
24930,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,Yes,Yes
24931,columns = [],,Yes,Yes
24932,columns.append([t[j] for t in sent]),,,Yes
24935,K.gather only lets us grab rows; so first transpose columns into rows,,Yes,Yes
24936,now use gather to grab the indexed columns (now rows),,,Yes
24937,now tranpose the gathered rows back to columns,,,Yes
24938,HACK to fix keras optimizer weights loading error,,Yes,Yes
24939,END HACK,,Yes,Yes
24941,observe for WAIT seconds minus time needed for computation,,Yes,Yes
24942,TODO: This is a hack. Remove.,,No,Yes
24943,"\""\""\""Output of bwm-ng csv has the following columns: || unix_timestamp;iface_name;bytes_out;bytes_in;bytes_total;packets_out;packets_in;packets_total;errors_out;errors_in || \""\""\""",,No,Yes
24945,TODO this number should be like 4k; 8k; 16k; etc.,,Yes,Yes
24948,TODO need to be able to save; work around for now,,Yes,Yes
24950,''' Simple test suite to verify the functionality of the bandwidth ||     control library. Hardcoded. ''',,,Yes
24953,Fix a bug introduced by an annoying Google extension,,No,Yes
24955,FIXME: Duration is hardcoded,,,Yes
24956,needs fix,,,Yes
24959,needs fix,,Yes,Yes
24960,maybe just allow very little variation,,,Yes
24962,TODO input_shape only 10 seconds,,Yes,Yes
24963,TODO build generator,,,Yes
24964,TODO loading all data too hard on memory; need to implement generators to save memory,,Yes,Yes
24966,TODO Context management,,,Yes
24967,''' || Loads repos from a csv file; using columns as features || ''',,Yes,Yes
24969,TODO Context management,,No,Yes
24971,TODO Configurable ls-remote timeout,,,Yes
24972,TODO Make a RepoInputSetContext which would let us store the,,Yes,Yes
24974,TODO store redundancy checks by BaseInputSetContext.handle() and add method,,Yes,Yes
24976,TODO audit use of memory (should be used sparingly),,,Yes
24977,TODO Create ctxhd_locks dict to manage a per context lock,,Yes,Yes
24978,Set list of needed input definitions if given,,,Yes
24979,Acquire the master lock to find and or create needed locks,,,Yes
24980,Take all the locks we found we needed for this parameter set,,,Yes
24981,TODO similar to MemoryRedundancyChecker; load all Operation,,,Yes
24984,TODO Add single and ismap attributes,,,Yes
24986,TODO Address the need to copy operation implementation inputs dict,,,Yes
24987,TODO raise error if longer than 1024 (validation should be done before,,No,Yes
24989,HACK This accesses _pop_action_class from ArgumentParser,,Yes,Yes
24993,NOTE This logic probably isn't what you want. Only for demo purposes.,,,Yes
24994,massage the columns in this table to your liking; and perhaps add more,,No,Yes
24995,At time of writing there are 4 plugins in skel\/ change this as needed,,,Yes
24996,TODO modify config_get to raise an error if NoDefaultValue would be the return,,,Yes
25002,TODO De-duplicate code from dffml\/base.py,,,Yes
25007,TODO There is probably an issue if multiple outputs have,,No,Yes
25010,"TODO Instead of float(\""nan\"") save accuracy value and use that.",,No,Yes
25013,TODO Add auto thread pooling of non-async functions,,,Yes
25015,TODO These ctx.add calls should probably happen after inputs are in,,,Yes
25020,TODO Add check that ctx returned is the ctx corresponding to uadd.,,,Yes
25022,TODO Make some way to cap the number of context's who have operations,,No,Yes
25024,TODO More types,,,Yes
25028,TODO Auto flow on operation conditions too,,,Yes
25029,TODO(p3) Remove fill; it doesn't get used anyway. Or use it somehow,,,Yes
25030,TODO Make it so that only one output operation gets run; the result of that,,,Yes
25032,name to pbkdf2_hmac; also make salt and iterations configurable and,,Yes,Yes
25034,TODO Implement input and presentation stages?,,No,Yes
25036,TODO http\/2,,,Yes
25038,TODO split config part of dataflow into seperate directory,,No,Yes
25040,TODO Consolidate this,,Yes,Yes
25041,TODO (p3) Remove production packages. Download full source if not already,,,Yes
25043,TODO (python3.8) Use Protocol,,No,Yes
25044,TODO Modify and compare against yaml in docs example,,,Yes
25046,TODO (python3.8) Use Protocol,,No,Yes
25049,TODO This probably isn't 100% correct. Figure out what we need,,Yes,Yes
25052,TODO Figure out a way to handle defaults so that all inputs need not be passed to the,,,Yes
25053,TODO modify config_get to raise an error if NoDefaultValue would be the return,,Yes,Yes
25054,"\""\""\"" || High level abstraction interfaces to DFFML. These are probably going to be used || in a lot of quick and dirty python files. || \""\""\""",,,Yes
25057,Needed to save updated model,,,Yes
25059,No preprocessing needed,,,Yes
25062,TODO Implement this in Python,,,Yes
25064,The convention in BERT is:,,No,Yes
25065,TODO: Potential shortcoming: Is there a way to call this source from the CLI and pass the db object (e.g. SqliteDatabase)?,,Yes,Yes
25066,"dffml list records -sources primary=dbsource -source-db_implementation sqlite -source-table_name testTable -source-db ??? -source-model_columns \""key feature_PetalLength feature_PetalWidth feature_SepalLength feature_SepalWidth target_name_confidence target_name_value\""",,,Yes
25069,TODO this is dirty! break it into small functions and add numpy style docstring.,,Yes,Yes
25070,TODO add support to have only specified target values for each example,,,Yes
25071,TODO override input; and output options,,,Yes
25077,TODO Implement 404 catch and return None,,,Yes
25080,Create output directory if needed,,,Yes
25081,TODO Create a mapping of color conversion names to their integer codes.,,Yes,Yes
25082,TODO Implement check on Windows,,Yes,Yes
25083,TODO Implement this method. We forgot to implement it when we initially,,,Yes
25084,TODO Currently only the torch.nn module has annotations,,Yes,Yes
25085,URL decode match_info values to fix bug where some versions of Python,,Yes,Yes
25086,Return list or dict (probably should do more here),,No,Yes
25087,TODO Handle cd,,Yes,Yes
25088,TODO the below code is because coverage won't go through subprocess,,No,Yes
25089,XXX asyncio.create_subprocess_exec doesn't work for piping output,,,Yes
25090,TODO XXX Raise issue with command that don't run this way,,,Yes
25091,HACK Reach into caller's (LiteralInclude.run()) local variables and,,No,Yes
25092,NOTE Duplicate feature data due to regression in oneDAL,,Yes,Yes
25093,Check that model should also work better on imbalanced data,,Yes,Yes
25095,TODO Refactor this since we have duplicate code,,,Yes
25096,TODO Go through each option and,,,Yes
25097,Move on to the next origin to validate,,Yes,Yes
25098,Temporary fix for ConfigSpace numpy incompatibility issue,,,Yes
25099,The dependency list ends when the indent level changes,,,Yes
25100,"TODO Remove?: dependencies = [line for line in dependencies if not line.startswith(\""#\"")]",,Yes,Yes
25101,Quick examples with no install commands; no venv needed,,,Yes
25104,TODO @config._asdict should NOT export; we should add a new .export(),,,Yes
25106,TODO: properly handle <UNK>,,Yes,Yes
25107,finally project down if needed,,Yes,Yes
25110,needed for iteration to work,,Yes,Yes
25111,needed for iteration to work,,Yes,Yes
25112,set variables needed for the SD reward,,Yes,Yes
25113,TODO: replace result by reclustered jet of all remaining constituents.,,No,Yes
25114,TODO: implement pseudojet option which returns a pseudojet,,,Yes
25116,- This `environment` configurable,,,Yes
25117,The `environment` configurable should be set by JupyterHub administrators to,,Yes,Yes
25118,from the configurable proxy.,,,Yes
25119,# An optional hook function that you can implement to do some bootstrapping work,,,Yes
25120,needed to access the host's user access control.,,,Yes
25121,todo 47; 67; 83?,,Yes,Yes
25123,todo upload files to Github?,,,Yes
25124,"todo try: \"" \"".join(foo.split())",,No,Yes
25125,todo do correlation check with length and acceptance.,,Yes,Yes
25126,todo do correlation check or forward\/backward by removing used words which perfectly predict acceptance.,,Yes,Yes
25127,todo more correlation.,,,Yes
25128,bag_of_words[0; word_to_idx[word]] += 1 # todo check if it works,,,Yes
25129,todo check if it works,,,Yes
25135,from the configurable proxy.,,Yes,Yes
25136,# An optional hook function that you can implement to do some bootstrapping work,,,Yes
25137,needed to access the host's user access control.,,Yes,Yes
25141,TODO check if predpath is file or dir and save appropriately,,Yes,Yes
25142,TODO remove once data flow is live,,No,Yes
25143,TODO read in live data; not harcoded; will use tmp,,Yes,Yes
25146,-- Options for todo extension ----------------------------------------------,,Yes,Yes
25147,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25148,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,No,Yes
25150,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,,Yes
25151,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,,Yes
25152,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,No,Yes
25154,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,No,Yes
25156,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,No,Yes
25157,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,,Yes
25158,Load Cifar10 data. Please implement your own load_data() module for your own dataset,,,Yes
25160,TODO: don't create dataset instance; better to move out and rename frames_from_video_clip method,,,Yes
25165,calling the model triggers download if needed,,No,Yes
25166,download and extract if needed,,Yes,Yes
25170,HOURLYDRYBULBTEMPF > HOURLYWETBULBTEMPF TODO,,Yes,Yes
25172,HOURLYWindDirection TODO - should be 0-360,,,Yes
25173,HOURLYPressureTendency TODO,,Yes,Yes
25176,TODO: add login,,No,Yes
25178,quick fix with replace (html gen),,,Yes
25180,TODO: check sample rate,,,Yes
25182,TODO: call the right method for the state here,,Yes,Yes
25187,TODO: check if 'samples' dir exists (if not; create it),,Yes,Yes
25188,TODO: make MONO samples? (freeze effect),,,Yes
25193,TODO: add standard logging output,,No,Yes
25194,valid audio files FIXME: convert to wav or support read other formats,,No,Yes
25200,TODO: add an option to skip processing if json data descriptor file exists or overwrite it (reprocess),,,Yes
25201,'sfx.logattacktime';  doesn't run properly in some systems FIXME,,Yes,Yes
25204,TODO: agregar el resto de los descriptores soportados,,No,Yes
25206,FIXME: por ej el duration no tiene sentido calcularle el 'mean',,Yes,Yes
25213,TODO: definir una interfaz; luego implementar,,Yes,Yes
25217,FIXME: lista .json q despu\u00E9s no puede abrir (?),,No,Yes
25219,TODO: implement. Clusters needs to be defined,,Yes,Yes
25220,FIXME,,Yes,Yes
25221,TODO: Falta implmementar el formato json; por ahora es una lista!,,,Yes
25223,TODO: *Remove wows; clippings; clicks & pops; rumble; hisses; process sound with crosstalk removal (sth like ambiophonics),,Yes,Yes
25224,FIXME: por ej el duration no tiene sentido calcularle el 'mean',,,Yes
25225,FIXME: por ej el duration no tiene sentido calcularle el 'mean',,Yes,Yes
25227,it should work well with less parameter searching,,,Yes
25228,it should work well with less parameter searching,,Yes,Yes
25229,it should work well with less parameter searching,,Yes,Yes
25230,it should work well with less parameter searching,,,Yes
25232,FIXME: hardcoded,,No,Yes
25235,FIXME: Time,,,Yes
25243,TODO: chequear si se usa,,Yes,Yes
25248,"TODO: ver  \""distance_to_target\"": 5.960464477539063e-08",,,Yes
25249,TODO: Generate .apicultor_config.json file with this structure,,,Yes
25251,FIXME: use urrlib2; check exceptions (Authentication credentials were not provided),,No,Yes
25254,linux bug workaround,,No,Yes
25255,TODO: add as property (start: True),,No,Yes
25256,FIXME: prior remove 'silence' sounds from DB (ETL),,Yes,Yes
25257,TODO: Add to Freesound API implementation,,Yes,Yes
25263,FIXME: prior remove 'silence' sounds from DB (ETL),,Yes,Yes
25266,some linux bug workaround,,,Yes
25269,TODO: chequear si se usa,,Yes,Yes
25272,FIXME: Time,,Yes,Yes
25273,duration = 1 #FIXME: hardcoded (default duration),,,Yes
25274,"print( \""State: %s\""%state ) # TODO: call the right method for the state here",,Yes,Yes
25276,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXME,,Yes,Yes
25277,TODO: add random variation time?,,No,Yes
25278,TODO: transpose all to the same pitch,,Yes,Yes
25279,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit,,,Yes
25283,FIXME generic call,,,Yes
25284,FIXME: use internal tool; or resolve better avconv vs ffmpeg issue,,Yes,Yes
25285,FIXME: needs two descriptors? duration and other?,,,Yes
25286,FIXME: prior remove 'silence' sounds from DB (ETL),,Yes,Yes
25287,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXM,,Yes,Yes
25288,if os.path.exists( file_chosen ) and os.path.getsize(file_chosen)>1000: #FIXME: prior remove 'silence' sounds from DB (ETL),,Yes,Yes
25291,TODO: *Remove wows; clippings; clicks and pops,,,Yes
25292,TODO: freeze effect (time scaling until achieving freeze),,,Yes
25294,take a reference (now 60 TODO update) and calculate amount of steps shift,,,Yes
25295,FIXME,,,Yes
25296,FIXME: needs two descriptors? duration and other?,,Yes,Yes
25297,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXM,,,Yes
25298,some linux bug workaround,,No,Yes
25301,TODO: chequear si se usa,,Yes,Yes
25302,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit,,,Yes
25304,TODO: add random variation time?,,,Yes
25305,TODO: transpose all to the same pitch,,,Yes
25308,linux bug workaround,,,Yes
25310,mac os #FIXME,,Yes,Yes
25313,FIXME: Time,,Yes,Yes
25314,duration = 1 #FIXME: hardcoded (default duration),,Yes,Yes
25316,TODO: Generate .apicultor_config.json file with this structure,,Yes,Yes
25317,it should work well with less parameter searching,,,Yes
25319,from control.MIDI import MIDI # TODO: make it optional (less dependencies),,No,Yes
25321,#take a reference (now 60 TODO update) and calculate amount of steps shift,,,Yes
25322,# FIXME,,No,Yes
25326,time.sleep(3) #wait for ffmpeg conversion . FIXME: wait process completion in get_one_by_mir() method,,Yes,Yes
25328,some linux bug workaround,,,Yes
25329,FIXME falta aplicar wet al proceso correspondiente,,Yes,Yes
25331,TODO: apply fx chain again,,Yes,Yes
25335,FIXME: por ej el duration no tiene sentido calcularle el 'mean',,,Yes
25338,mac os #FIXME,,,Yes
25339,TODO: definir una interfaz; luego implementar (leyendo json files y accediendo la BD),,Yes,Yes
25341,quick fix with replace (html gen),,No,Yes
25343,FIXME,,,Yes
25344,FIXME: needs two descriptors? duration and other?,,Yes,Yes
25345,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXM,,Yes,Yes
25350,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit,,Yes,Yes
25351,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXME,,,Yes
25353,TODO: transpose all to the same pitch,,,Yes
25354,TODO: addi\/use formal loggin,,Yes,Yes
25357,mac os #FIXME,,Yes,Yes
25358,TODO: chequear si se usa,,Yes,Yes
25359,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit,,Yes,Yes
25362,duration = 1 #FIXME: hardcoded (default duration),,Yes,Yes
25363,TODO: call the right method for the state here,,,Yes
25364,FIXME: prior remove 'silence' sounds from DB (ETL),,Yes,Yes
25365,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXME,,,Yes
25366,TODO: add random variation time?,,No,Yes
25367,TODO: transpose all to the same pitch,,,Yes
25369,Cs = [1.\/0.1; 1.\/0.33; 1.\/0.4; 1.\/0.6; 1.\/0.8] #it should work well with less parameter searching,,Yes,Yes
25371,TODO: check if 'samples' dir exists (if not; create it),,,Yes
25372,TODO: add standard logging output,,No,Yes
25374,valid audio files FIXME: convert to wav or support read other formats,,,Yes
25375,TODO: make MONO samples? (freeze effect),,No,Yes
25378,Cs = [1.\/0.1; 1.\/0.33; 1.\/0.4; 1.\/0.6; 1.\/0.8] #it should work well with less parameter searching,,Yes,Yes
25379,by means of correlation we still can get some good notes based on maximum strength. TODO: get chords by other degrees than thirds (fifth; fourth; seventh; ninth; etc.),,Yes,Yes
25382,FIXME: por ej el duration no tiene sentido calcularle el 'mean',,Yes,Yes
25383,it should work well with less parameter searching,,,Yes
25385,TODO: build all key profiles,,,Yes
25387,local fix; we want a better matching,,,Yes
25389,TODO: add standard logging output,,No,Yes
25390,take a reference (now 60 TODO update) and calculate amount of steps shift,,,Yes
25392,FIXME: needs two descriptors? duration and other?,,,Yes
25393,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXM,,Yes,Yes
25394,some linux bug workaround,,No,Yes
25396,mac os #FIXME,,,Yes
25399,WARNING: bad realtime practice (writing file) TODO: add to a memory buffer and write before exit. FIXME,,,Yes
25402,typing as a dependency for 1.6.1+ Sphinx causes issues when imported after,,No,Yes
25405,needed to read a .gitmodules file).,,No,Yes
25406,XXX: May block if either stdout or stderr fill their buffers;,,Yes,Yes
25407,Thus; any C-extensions that are needed to build the documentation will *not*,,,Yes
25408,except (NameError; KeyError):  # NameError is needed to support Astropy < 1.0,,,Yes
25410,A dirty hack to get around some early import\/configurations ambiguities,,,Yes
25411,TODO: need to add all settings,,,Yes
25413,TODO: make this method take SkyCoord objects,,,Yes
25414,TODO: could buffer JS call here,,,Yes
25416,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25417,def remove(self): # better integrate with Circle.remove ?,,Yes,Yes
25419,FIXME: the current solution relies on a single file; and won't support,,No,Yes
25420,TODO: need to validate reference frame,,No,Yes
25422,TODO: check if this needs to be different on Windows,,No,Yes
25424,TODO: need to generalize to not say table here,,,Yes
25426,orbit=; hence why we haven't made this a positional argument.,,Yes,Yes
25430,perhaps use a different color for each instrument?,,,Yes
25431,maybe plot in pix instead of deg? how to keep consistent,,No,Yes
25432,a more efficient method than CircleCollection of changing trait values?,,,Yes
25433,Next check for columns that start with specified names,,Yes,Yes
25434,Next check for columns that start with specified names,,,Yes
25436,TODO: need to generalize to not say table here,,No,Yes
25437,TODO: need to validate reference frame,,,Yes
25439,to make sure they have unique names that won't clash with existing columns,,Yes,Yes
25440,A series of tests that excercise the layer functionality and compare,,,Yes
25441,TODO: need a way to completely turn off sun + planets. For now we just,,,Yes
25442,as this is needed for cases where applications,,,Yes
25445,Next check for columns that start with specified names,,Yes,Yes
25446,A series of tests that excercise the layer functionality and compare,,,Yes
25447,TODO: need a way to completely turn off sun + planets. For now we just,,,Yes
25448,TODO: support:,,,Yes
25451,Convert time column; once chosen; to GMT\/UTC so WWT displays points at the expected times,,Yes,Yes
25454,The conversion only seems needed in Qt; so check the widget version,,Yes,Yes
25455,## ISSUE: better to create a new column (like cmap_att\/size_att),,No,Yes
25456,## given the column limit discussed earlier; creating new columns,,Yes,Yes
25457,## further limits the number of columns a user can provide,,Yes,Yes
25458,wwt=None tag needed to avoid linkage to 'wwt.settings.set_' type traits,,Yes,Yes
25463,report a warning somehow?,,No,Yes
25466,TODO: Find way to start scenario during pause,,,Yes
25473,Maybe return without targets,,No,Yes
25475,TODO: check these paths,,No,Yes
25476,TODO:,,No,Yes
25477,TODO:,,No,Yes
25478,TODO:,,,Yes
25479,TODO:,,No,Yes
25482,sentence analysis TODO: check sentences,,Yes,Yes
25483,TODO: create all possible pair in order to see if it appears in gold_dict['docs'],,Yes,Yes
25486,no search is needed... no information on gold dict about retrieval,,,Yes
25487,TODO: Analyse NER and TF-IDF,,,Yes
25488,sentence analysis TODO: check sentences,,Yes,Yes
25489,TODO: create all possible pair in order to see if it appears in gold_dict['docs'],,,Yes
25490,This is needed in case nothing was predicted,,,Yes
25496,"\""\""\"" || Created on Wed Sep 26 13:38:38 2018 ||  || @author: Emmanouil Theofanis Chourdakis ||  || Problog module for extracting information from a sentence using clausiepy ||  || \""\""\""",,Yes,Yes
25499,This is needed in case nothing was predicted,,,Yes
25500,This is needed in case nothing was predicted,,,Yes
25502,Move the added items to the front of the path:,,No,Yes
25504,XXX This should not be part of site.py; since it is needed even when,,,Yes
25506,TODO:,,,Yes
25507,# TODO could readd the mfcc checks for safety,,,Yes
25508,# TODO would be better to check with dataset (once cleaned),,,Yes
25511,TODO: implement clipped ReLu? Dropout?,,,Yes
25513,TODO: batch norm layer?,,,Yes
25514,TODO: sjekk om server viker; fiks data_generator og avtal m\u00F8te med Ole,,,Yes
25515,TODO: Normalize input (between 0 and 1? -1 and 1?),,No,Yes
25516,TODO: validation data?,,,Yes
25518,TODO: mergemode? default = concat; kernel_initializer? bias_initializer?,,Yes,Yes
25519,TODO: mergemode? default = concat; kernel_initializer? bias_initializer?,,,Yes
25520,"Saves the model if val_loss is improved at \""model_save\"" + \""_best\""",,No,Yes
25521,TODO - what are we going to release this as?,,No,Yes
25523,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
25524,todo die Namensgebung f\u00FCr model; calibrated_model etc. muss diskutiert un ggf. geaendert werden,,No,Yes
25526,todo more efficient implementation over numpy_repo to avoid loading all and then cutting off,,Yes,Yes
25527,\\todo make it more efficient; reading from numpy store only the subset of data defined by start_index and end_index,,Yes,Yes
25528,todo more efficient implementation over numpy_repo to avoid loading all and then cutting off,,Yes,Yes
25530,\\todo auch hier muss die referenz einschl. Namen verwendet werden,,Yes,Yes
25532,This method just takes a pandas dataframe and the specification; which columns belong to the input,,,Yes
25536,todo needs improvement; handle indices in reading,,Yes,Yes
25538,todo must be implemented,,,Yes
25540,todo include version,,,Yes
25541,todo include the version in the function call,,,Yes
25542,todo add fitted_preprocessor to repo,,,Yes
25543,todo include version,,Yes,Yes
25544,todo include the version in the function call,,Yes,Yes
25546,todo include version,,,Yes
25548,todo add fitted_preprocessor to repo,,,Yes
25550,first find the indices of the columns to select,,Yes,Yes
25551,select columns,,No,Yes
25552,todo include version,,,Yes
25554,todo grosse transaction um alles rum,,Yes,Yes
25557,"\""\""\"" This module contains a bunch of different RepoObjects. ||  || In principal; all objects that can be stored within pailab's MLRepo are called a RepoObject. So; if you need a new object apart from those  || documented here; you just have to implement the respective interfaces; so that the object can be processed by pailab.  || This may be accomplished in three different ways: ||  ||     - Inherit your class from the :py:class:`pailab.repo_objects.RepoObject` class. This may not be very pythonic; but it easily shows you which interfaces you definitively have to implement. ||     - If you have a very simple object you may use the decorator :py:class:`pailab.repo_objects.repo_object_init` in conjunction with your classe's constructor to make your class a  RepoObject. ||     - Just implement the methods needed (again look at :py:class:`pailab.repo_objects.RepoObject` to what has to be defined). ||  || \""\""\""",,Yes,Yes
25560,todo make this more efficient by just updating collections and items which are affected by this,,Yes,Yes
25562,todo: das hier muss weg,,No,Yes
25563,get submatrix with columns used for this preprocessor,,Yes,Yes
25565,append new columns from preprocessing to the end,,Yes,Yes
25566,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25568,qubit. Here; we reverse this to make it the last qubit; matching PennyLane convention.,,Yes,Yes
25569,sample Bernoulli distribution n_eval times \/ binomial distribution once,,,Yes
25572,sample Bernoulli distribution n_eval times \/ binomial distribution once,,Yes,Yes
25573,Rename for better readability,,Yes,Yes
25575,This is needed because the pre-activation variant does not have batch,,,Yes
25576,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25577,maybe 10000,,No,Yes
25578,maybe 10001,,No,Yes
25579,maybe 10001,,,Yes
25580,if the enclitics has more than (''; 'c') and the verb ends with '\u0648',,No,Yes
25582,#Move to a desired state on some conditions.,,,Yes
25583,Do some parsing if needed in the future.,,,Yes
25584,FIXME: doesn't *startswith* allow room for errors ?,,,Yes
25585,TODO: wordNode.setAttribute('certain_diacrats'; '\u0627\u0644\u062A\u0634\u0643\u064A\u0644 \u0627\u0644\u0645\u0624\u0643\u062F');,,No,Yes
25586,# Mixin for configurable classes that work with connection files,,,Yes
25590,# The kernel manager class.  This is configurable to allow subclassing of the,,,Yes
25591,FileManagerMixin(Configurable) configuration,,,Yes
25592,# The kernel spec class.  This is configurable to allow subclassing of the,,Yes,Yes
25593,TODO: Process the received audio data!,,,Yes
25594,columns per row.,,,Yes
25596,First layer: #convolution filters; (rows; columns) of convolution kernel; (width; height; depth) of image (input),,Yes,Yes
25597,(None; 15; 3; 128); somehow stuff just gets ignored if doesn't divide evenly,,Yes,Yes
25599,TODO: Resample audio?,,,Yes
25600,This is very slow! Perhaps some logging?,,Yes,Yes
25602,TODO,,Yes,Yes
25603,TODO: Fit generator.,,,Yes
25604,TODO,,,Yes
25605,TODO,,,Yes
25606,FIXME: slow!,,,Yes
25607,Add a new state to the mapping if needed,,No,Yes
25610,FIXME: Assumes that hmm[j] != -1,,No,Yes
25619,FIXME: should make a class for this,,,Yes
25621,TODO: - move output from kaldi into defined output_dir,,No,Yes
25622,TODO: - move output from kaldi into defined output_dir,,,Yes
25623,TODO - Convert mp3 into wav with sox to mono,,No,Yes
25624,TODO - Convert mp3 into wav with sox to mono,,No,Yes
25625,log transform if needed,,Yes,Yes
25626,filter low-freq rows\/columns,,No,Yes
25627,all_feature_md = list(set(exp1.feature_metadata.columns).union(set(exp2.feature_metadata.columns))),,No,Yes
25628,all_feature_md = list(set(exp1.feature_metadata.columns).union(set(exp2.feature_metadata.columns))),,,Yes
25629,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25630,TODO: make nicer (need new code from Serene),,,Yes
25632,filter low-freq rows\/columns,,No,Yes
25633,merge and remove duplicate columns,,Yes,Yes
25636,TODO why? what is width and height?,,Yes,Yes
25637,generate nice M\/Z (MZ) and retention time (RT) columns for each feature,,,Yes
25638,TODO,,Yes,Yes
25639,convert to dense for efficient slicing,,,Yes
25640,__repr__ calls; so why waste space.,,,Yes
25641,__repr__ calls; so why waste space.,,Yes,Yes
25643,this loop is a horrible brute force hack,,No,Yes
25644,TODO: This margin seems a bit arbituary.,,No,Yes
25646,i % 2 because there are only columns,,No,Yes
25647,to fix problem with 0 std divide by zero (since we permute it's ok),,,Yes
25650,rename columns in biom table if exist in feature metadata file,,,Yes
25651,generate nice M\/Z (MZ) and retention time (RT) columns for each feature,,,Yes
25654,this extenstion is needed to avoid the,,Yes,Yes
25655,fix based on: https:\/\/github.com\/spatialaudio\/nbsphinx\/issues\/24,,No,Yes
25656,drop the two columns which are not samples,,Yes,Yes
25657,switch the columns so now _feature_id (and the index) is the sequence and not the hash. The hash is copied to '_hash',,,Yes
25658,fix for qval > 1 (since we count on all features in random permutation),,,Yes
25659,we then keep only these columns in the ratio_mat,,Yes,Yes
25662,"[[\""The\""; \""DT\""]; [\""best\""; \""JJS\""]; [\""climbing\""; \""NN\""]; [\""club\""; \""NN\""]; [\""around\""; \""RB\""]; [\"".\""; \"".\""]]}",,,Yes
25663,"\""\""\"" || Given input in the .sst format; converts to the .conllulex format || (an extension of the tabular .conllu format with additional columns || for lexical semantics). ||  || A path to the reviews subdirectory of the UD_English repository || is specified in a global variable. || \""\""\""",,Yes,Yes
25665,"lexcat = data[\""lexcat\""].get(str(tokNum); '_') # TODO: is lexcat ever manually specified; or always inferred from UD + MWE annotations?",,Yes,Yes
25666,"wcat = data[\""wcat\""].get(str(tokNum); '_')  # TODO",,Yes,Yes
25668,Load CoNLL-U columns,,,Yes
25669,Load STREUSLE-specific columns,,,Yes
25672,TODO: ignore ??,,,Yes
25673,TODO: check lextag,,No,Yes
25674,TODO: check rendered MWE string,,No,Yes
25675,TODO: check lexcat,,No,Yes
25678,"- possessives in idiomatic PPs: \""on_ our _way\""; \""on_ my _own\""; etc.",,Yes,Yes
25679,This means that the MWE columns are not *completely* determined by,,Yes,Yes
25680,assert tok['wcat'] and tok['wcat']!='_'    # eventually it would be good to have a category for every weak expression,,Yes,Yes
25682,Load STREUSLE-specific columns,,Yes,Yes
25683,"\""\""\"" || Given a .conllulex file; remove all STREUSLE columns except the lextag column || (the last one). ||  || Args: inputfile ||  || @since: 2019-06-20 || @author: Nathan Schneider (@nschneid) || \""\""\""",,Yes,Yes
25684,"\""\""\"" || Given a .conllulex file; apply a consistent ordering to MWEs based || primarily on the first token offset in each expression; || and secondarily on strong vs. weak (strong comes before weak). ||  || Args: inputfile ||  || @since: 2019-06-22 || @author: Nathan Schneider (@nschneid) || \""\""\""",,,Yes
25685,TODO: iterate over tquery() output,,No,Yes
25688,"\""\""\"" || Incorporate edits to annotations in the human-readable inline rendered format || (output by streusvis.py) and produce the modified corpus as JSON. ||  || Usage: ||  ||   .\/streusvis.py --sent-ids --lexcats --colorless streusle.conllulex > updates.tsv ||  ||   [manually edit annotations in updates.tsv] ||  ||   .\/tupdate.py streusle.conllulex updates.tsv > streusle.new.json ||  || updates.tsv must contain 2 tab-separated columns: sentence IDs and rendered sentences. || The rendered sentence may be split across multiple consecutive lines; || with the sentence ID specified only in the first of these. ||  || The sentences in updates.tsv will be compared against the ones in streusle.conllulex; || and only the ones with modified annotations will be processed (so including || unmodified sentences in updates.tsv is optional). ||  || This script will not add or delete sentences from the corpus; or alter || their tokenization or syntactic parse. ||  || @author: Nathan Schneider (nschneid) || @since: 2019-09-16 || \""\""\""",,Yes,Yes
25689,"\""\""\"" || 1. Load streusvis.py-created file with potential updates to be made. || It must contain 2 tab-separated columns: sentence IDs and rendered sentences. || The rendered sentence may be split across multiple consecutive lines; || with the sentence ID specified only in the first of these. || \""\""\""",,Yes,Yes
25691,n x dim #TODO: add x_ind placeholder and use EmbeddingsLookup(y_ind) instead of placeholder?,,,Yes
25692,move embs to Variable,,No,Yes
25693,each non-empty line must contain >= 3 columns,,Yes,Yes
25694,extract tags from last 2 columns,,Yes,Yes
25695,TODO:,,No,Yes
25696,TODO:,,No,Yes
25699,"\""\""\"" || smact_distorter: Module for generating symmetry-unique substitutions on a given sub-lattice. ||  || As input it takes the ASE crystal object (as built by smact_builder) || and the sub-lattice on which substitutions are to be made.  || There is an example of how to use the code in Example_distort.py ||  || --------------------------------------------------------------------- || TODO: || Add a functionality to check two Atoms objects against one another  || for equivalence. || --------------------------------------------------------------------- ||  || \""\""\""",,Yes,Yes
25704,######### Everything below this is probably broken ##########,,No,Yes
25706,and move onto next binary combination,,,Yes
25709,TODO: Someone must know what these fields are -- and they might be useful!,,,Yes
25710,First two columns are strings and should be left intact,,No,Yes
25714,times.  As well as keeping memory usage fairly constant; this seems,,Yes,Yes
25717,HACK      axarr[1;0]; axarr[1;1];axarr[1;2];,,,Yes
25718,HACK      axarr[2;0];axarr[2;1]; axarr[2;2];,,,Yes
25719,HACK      axarr[3;0];axarr[3;1]; axarr[3;2];,,,Yes
25721,HACK axarrs = [axarr[0;0];axarr[0;1]; axarr[0;2];,,Yes,Yes
25723,Implement Structure class; c.f. dev_docs.,,Yes,Yes
25724,TODO Validate input structure,,,Yes
25726,TODO Figure out how to distinguish oxidation states,,Yes,Yes
25727,TODO Validate input structure,,,Yes
25730,NOTE The author doesn't know why they exist,,,Yes
25735,TODO Validate input structure,,,Yes
25736,TODO Confirm functionality with more complex substitutions,,,Yes
25737,NOTE The author doesn't know why they exist,,Yes,Yes
25738,NOTE The author doesn't know why they exist,,Yes,Yes
25741,This file will contain the IP; ports; and authentication key needed to connect,,Yes,Yes
25743,Sessions support configurable serialization via packer\/unpacker traits; and,,Yes,Yes
25745,will be much more efficient.,,,Yes
25747,# The kernel spec class.  This is configurable to allow subclassing of the,,Yes,Yes
25750,TODO: Should we check more things? Like shape not being None or empty for a tensor?,,,Yes
25754,"TODO: ' Tensorboard example: {\""log_dir\"": \""\/tmp\/logs\/\""}.'",,Yes,Yes
25757,TODO improve docstrings extraction,,,Yes
25758,TODO: is this ok?,,No,Yes
25759,If true; todo and todoList produce output; else they produce nothing.,,,Yes
25763,Check names to avoid overwriting the current columns,,,Yes
25766,fixme: from here,,,Yes
25767,fixme: from  here,,No,Yes
25768,fixme: from here,,No,Yes
25770,todo: need range check,,No,Yes
25771,return ngram_tab #maybe not needed?,,Yes,Yes
25774,todo: maybe user have no need to know that likelihood function should return log scaled values,,,Yes
25776,return self._ngram_tab #maybe not needed?,,No,Yes
25777,pandas values_count maybe faster for n > 5000,,,Yes
25781,todo: kekuleSmiles?,,No,Yes
25782,fixme: move choice to smc,,Yes,Yes
25785,fixme: will be removed at future,,,Yes
25786,split requests into fixed number groups,,Yes,Yes
25787,move tensor device,,Yes,Yes
25789,fix the number of ring mis-match first,,,Yes
25790,fix order mis-match,,Yes,Yes
25791,todo: kekuleSmiles?,,,Yes
25793,fix order mis-match,,Yes,Yes
25794,Extract relevant columns for pd.DataFrame input,,,Yes
25795,raise KeyError('name of columns do not match any feature set'),,,Yes
25796,raise KeyError('name of columns do not match any log-likelihood set'),,,Yes
25797,Add sentence breaks as needed:,,,Yes
25801,TODO: Should we be able to decide which deep layer?,,Yes,Yes
25802,to bring it to the correct size. TODO: Should correct size be customizable;,,,Yes
25803,Find the pooling constant needed,,,Yes
25804,TODO: add check on image_column_header: Initialize it to something like 'images_header'.,,,Yes
25805,TODO: add check on image_column_header: Initialize it to something like 'images_header'.,,,Yes
25808,Ensure a new csv wasn't created when they weren't needed; and that a new csv,,,Yes
25811,Raise error if multiple image columns are passed in without a csv,,No,Yes
25812,Featurize the data; and save it to the appropriate columns,,,Yes
25813,Ensure a new csv wasn't created when they weren't needed,,No,Yes
25814,(if there are multiple columns). Otherwise the ordering gets fucked up.,,Yes,Yes
25815,Raise error if multiple image columns are passed in without a csv,,,Yes
25819,CSVs used to test model predictions on single and multiple image columns,,,Yes
25820,Only autosample if updating the csvs and arrays for multiple image columns,,Yes,Yes
25821,Load and featurize the data corresponding to either the single or multiple image columns,,Yes,Yes
25822,TODO: label = numpy.asscalar(output.data.max(1; keepdim=True)[1]),,Yes,Yes
25823,TODO: label = numpy.asscalar(output.data.max(1; keepdim=True)[1]),,Yes,Yes
25826,TODO: format time series datapoints,,,Yes
25827,TODO: implement merge functions of sorted timings,,,Yes
25828,TODO: figure out if we need protect call with aiojobs,,No,Yes
25830,TODO: rename to something more general,,Yes,Yes
25831,TODO: add structural typing with predict method instead,,,Yes
25837,First; the needed imports. Keras tells us which backend (Theano; Tensorflow; CNTK) it will be using.,,,Yes
25839,First; the needed imports. Keras tells us which backend (Theano; Tensorflow; CNTK) it will be using.,,Yes,Yes
25840,First; the needed imports. Keras tells us which backend (Theano; Tensorflow; CNTK) it will be using.,,,Yes
25841,First; the needed imports. Keras tells us which backend (Theano; Tensorflow; CNTK) it will be using.,,Yes,Yes
25843,First; the needed imports. Keras tells us which backend (Theano;,,Yes,Yes
25844,First; the needed imports. Keras tells us which backend (Theano;,,Yes,Yes
25845,Copy data to GPU if needed,,Yes,Yes
25847,Copy data to GPU if needed,,Yes,Yes
25848,First; the needed imports.,,Yes,Yes
25851,Copy data to GPU if needed,,,Yes
25854,Copy data to GPU if needed,,Yes,Yes
25856,First; the needed imports.,,,Yes
25857,First; the needed imports.,,Yes,Yes
25859,First; the needed imports.,,,Yes
25860,First; the needed imports.,,,Yes
25863,First; the needed imports.,,Yes,Yes
25865,First; the needed imports.,,Yes,Yes
25866,First; the needed imports.,,Yes,Yes
25868,We set the remaining hyperparameters needed for fine-tuning the,,No,Yes
25869,Copy data to GPU if needed,,Yes,Yes
25870,Once your model looks good; configure its learning process with,,Yes,Yes
25871,First; the needed imports.,,Yes,Yes
25872,First; the needed imports.,,,Yes
25873,"\""Some\"" heuristc to arrive at nice looking trajectory",,,Yes
25875,'joblib' # not needed at the moment,,No,Yes
25878,TODO,,Yes,Yes
25879,TODO: assert total_n_frames (strided) coincies with the n_frames in data,,No,Yes
25880,TODO: start from the absolute maximum?,,No,Yes
25882,TODO: check results in 3-D against http:\/\/www-wales.ch.cam.ac.uk\/~wales\/CCD\/Thomson\/table.html,,No,Yes
25884,TODO: assert total_n_frames (strided) coincies with the n_frames in data,,,Yes
25885,TODO : consider storing the data in each dict. It's redundant but makes each dict kinda standalone,,Yes,Yes
25890,TODO: we don't need the vstack every time,,,Yes
25891,Listify the input in case its needed,,,Yes
25893,TODO add warnings about versions,,,Yes
25895,This is an ugly UGLY hack that I'll get rid of sometime soon,,,Yes
25899,maybe improved later,,No,Yes
25902,TODO add warnings about versions,,Yes,Yes
25903,TODO add loggers,,,Yes
25906,Listify the input in case its needed,,Yes,Yes
25907,"\""Some\"" heuristc to arrive at nice looking trajectory",,Yes,Yes
25908,TODO: assert total_n_frames (strided) coincies with the n_frames in data,,,Yes
25909,TODO: this fallunterscheidung is repeated elsewhere.Refactor and consider an own method,,Yes,Yes
25911,TODO: start from the absolute maximum?,,No,Yes
25912,todo: this can be optimized...,,Yes,Yes
25915,somehow returning the ax_wdg messes the displaying of both widgets,,No,Yes
25916,TODO FIND OUT A CLEANER WAY TO DO THIS (dict or class),,,Yes
25917,TODO find cleaner way of distinguishing these 2Dlines,,Yes,Yes
25920,Issue a ResourceWarning if implicit cleanup needed,,No,Yes
25921,XXX (ncoghlan): The following code attempts to make,,,Yes
25924,"\""Some\"" heuristc to arrive at nice looking trajectory",,,Yes
25927,TODO: extend to other inputs,,,Yes
25928,Until we get the colorcyle thing working; this is a workaround:,,No,Yes
25930,TODO write a warning?,,Yes,Yes
25931,TODO find out why this is needed,,Yes,Yes
25932,"TODO: CONSIDER PURE STRING WITH \\N INSTEAD for output \""lines\""",,Yes,Yes
25933,todo document,,No,Yes
25935,TODO: write a class instead of dictionary (easier refactoring),,,Yes
25937,TODO: avoid joining via copy_not_join,,No,Yes
25938,TODO: look closely at this x[:-2]  (bins; edges; and off-by-one errors,,Yes,Yes
25939,"TODO: retrieve the actual edges from pyemma's \""plot_free_energy\""'s axes",,,Yes
25940,todo consider kwargs for most_corr_info,,,Yes
25941,TODO nglvwidget inside terminal one should follow this comment,,Yes,Yes
25942,TODO widget.n_components won't work unless the wdg was drawn already once,,,Yes
25946,TODO: create a path through the colors that maximizes distance between averages (otherwise some colors,,No,Yes
25947,TODO: avoid joining via copy_not_join,,No,Yes
25948,TODO consider letting pyemma fail here instead of catching this,,,Yes
25956,TODO add line thickness as **kwarg,,,Yes
25958,TODO rewrite parse_atom_sel. This if condition is very BAD,,,Yes
25960,TODO : WRITE PROPER WARNINGS,,,Yes
25961,somehow not working properly,,,Yes
25962,TODO PIN TO NGLVIEW 1.0 once it's released,,Yes,Yes
25963,somehow not working properly,,,Yes
25965,TODO MOVE THESE IMPORTS,,,Yes
25966,TODO rewrite parse_atom_sel. This if condition is very BAD,,,Yes
25967,TODO: create a path through the colors that maximizes distance between averages (otherwise some colors,,,Yes
25968,TODO document,,No,Yes
25973,We initialize with two frames; it's easy to test the ends,,,Yes
25974,Hack,,No,Yes
25975,fixme: can not mock ipywidgets because of multi-inheritance within molpx,,Yes,Yes
25976,TODO: avoid joining via copy_not_join,,No,Yes
25979,TODO add build_walks in here,,Yes,Yes
25980,TODO: put package requirements here,,,Yes
25982,TODO: Add support for PUT request,,,Yes
25983,TODO: Add support for PATCH request,,,Yes
25985,TODO: Replace the hardcoded host url with cli's host url,,,Yes
25987,order the columns,,Yes,Yes
25989,order the columns,,,Yes
25990,"\""\""\"" || OSM-tag-metanalysis.py: implement a short analysis of OSM element tag genome || How to call this module? || <python3 <pathto_module.py> <pathto_data> <dataset_name> || \""\""\""",,No,Yes
25992,add `n_top_editor` columns with the number of time that each user used them,,,Yes
25993,columns=chgset_md.columns).T,,Yes,Yes
25994,FIXME yield OSMTagMetaAnalysis(self.datarep; self.dsname),,No,Yes
25995,add `n_top_editor` columns with the number of time that each user used them,,Yes,Yes
25997,TODO: Plot cluster centroids,,Yes,Yes
26000,XXX Make it more modular\/robust,,,Yes
26001,TODO: grid search on all experiments and images jointly.,,Yes,Yes
26002,TODO: move experiment wise search and final printing to wrapper.,,Yes,Yes
26004,edgetaper to better handle circular boundary condition,,Yes,Yes
26006,TODO: refactor,,,Yes
26013,TODO: \uAD6C\uAE00\uCC98\uB7FC \uC2DC\uD000\uC2A4 \uC0AC\uC774\uC988\uC5D0 \uB530\uB77C \uC801\uB2F9\uD55C \uBC84\uD0B7\uC744 \uC0AC\uC6A9\uD558\uB3C4\uB85D \uB9CC\uB4E4\uC5B4\uC11C \uC0AC\uC6A9\uD558\uB3C4\uB85D,,No,Yes
26014,TODO: \uAD6C\uAE00\uCC98\uB7FC Seq2Seq2 \uBAA8\uB378 \uC548\uC758 RNN \uC140\uC744 \uC0DD\uC131\uD558\uB294 \uBD80\uBD84\uC5D0 \uB123\uC744\uAC83,,,Yes
26015,TODO: \uAD6C\uAE00\uCC98\uB7FC \uBC84\uD0B7\uC744 \uC774\uC6A9\uD55C \uBC29\uC2DD\uC73C\uB85C \uBCC0\uACBD,,,Yes
26016,TODO: \uC138\uC158\uC744 \uB85C\uB4DC\uD558\uACE0 \uB85C\uADF8\uB97C \uC704\uD55C summary \uC800\uC7A5\uB4F1\uC758 \uB85C\uC9C1\uC744 Seq2Seq \uBAA8\uB378\uB85C \uB123\uC744 \uD544\uC694\uAC00 \uC788\uC74C,,Yes,Yes
26017,Number of nodes in the last layer is reduced by half. It gives better results.,,Yes,Yes
26018,We need to define the parts of the network needed for learning a policy,,No,Yes
26019,When choosing shuffle buffer sizes; larger sizes result in better,,Yes,Yes
26022,TODO: find the optimal block_length.,,Yes,Yes
26023,"help='specify the separator of columns of input data [default: \""%default\""]'",,Yes,Yes
26025,"help='specify the separator of columns of input data [default: \""%default\""]'",,,Yes
26027,extract tags from last 2 columns,,,Yes
26030,''' || Created on Oct 6; 2010 ||  || @author: Peter || ''',,Yes,Yes
26032,''' || Created on Oct 27; 2010 ||  || @author: Peter || ''',,Yes,Yes
26034,''' || Created on Oct 14; 2010 ||  || @author: Peter Harrington || ''',,Yes,Yes
26035,''' || Created on Oct 12; 2010 || Decision Tree Source Code for Machine Learning in Action Ch. 3 || @author: Peter Harrington || ''',,Yes,Yes
26038,''' || Created on Oct 6; 2010 || Shows montonocity of a function and the log of that function || @author: Peter || ''',,,Yes
26039,''' || Created on Oct 19; 2010 ||  || @author: Peter || ''',,Yes,Yes
26042,''' || Created on Oct 6; 2010 ||  || @author: Peter || ''',,Yes,Yes
26043,''' || Created on Oct 6; 2010 ||  || @author: Peter || ''',,Yes,Yes
26044,''' || Created on Oct 27; 2010 || Logistic Regression Working Module || @author: Peter || ''',,Yes,Yes
26045,''' || Created on Oct 6; 2010 ||  || @author: Peter || ''',,Yes,Yes
26046,''' || Created on Nov 26; 2010 ||  || @author: Peter || ''',,Yes,Yes
26047,''' || Created on Nov 22; 2010 ||  || @author: Peter || ''',,Yes,Yes
26049,''' || Created on Dec 13; 2010 ||  || @author: Peter || ''',,,Yes
26051,''' || Created on Nov 28; 2010 || Adaboost is short for Adaptive Boosting || @author: Peter || ''',,Yes,Yes
26052,''' || Created on Jan 8; 2011 ||  || @author: Peter || ''',,,Yes
26053,regularize by columns,,,Yes
26056,''' || Created on Feb 4; 2011 || Tree-Based Regression Methods || @author: Peter Harrington || ''',,Yes,Yes
26059,''' || Created on Feb 16; 2011 || k Means Clustering for Ch10 of Machine Learning in Action || @author: Peter Harrington || ''',,,Yes
26061,''' || Created on Jun 14; 2011 || FP-Growth FP means frequent pattern || the FP-Growth algorithm needs:  || 1. FP-tree (class treeNode) || 2. header table (use dict) ||  || This finds frequent itemsets similar to apriori but does not  || find association rules.   ||  || @author: Peter || ''',,,Yes
26062,''' || Created on Jun 1; 2011 ||  || @author: Peter || ''',,,Yes
26063,''' || Created on Jun 1; 2011 ||  || @author: Peter || ''',,Yes,Yes
26064,''' || Created on Jun 1; 2011 ||  || @author: Peter || ''',,Yes,Yes
26066,below is a quick hack copied from pca.pca(),,Yes,Yes
26068,''' || Created on Mar 8; 2011 ||  || @author: Peter || ''',,,Yes
26070,''' || Created on Feb 21; 2011 || Machine Learning in Action Chapter 18 || Map Reduce Job for Hadoop Streaming  || mrMeanMapper.py || @author: Peter Harrington || ''',,Yes,Yes
26071,calc mean of columns,,Yes,Yes
26072,''' || Created on Feb 21; 2011 ||  || @author: Peter || ''',,Yes,Yes
26073,''' || Created on Feb 27; 2011 || MapReduce version of Pegasos SVM || Using mrjob to automate job flow || @author: Peter || ''',,Yes,Yes
26074,so it ends up at the same reducer,,No,Yes
26078,''' || Created on Feb 27; 2011 || MapReduce version of Pegasos SVM || Using mrjob to automate job flow || @author: Peter || ''',,,Yes
26079,for col in lenses_pd.columns:                                            #\u4E3A\u6BCF\u4E00\u5217\u5E8F\u5217\u5316,,No,Yes
26082,TODO better way to check if file has changed; e.g. has_file_changed,,No,Yes
26083,TODO really deactive allow origin and disable_check_xsrf,,No,Yes
26084,TODO configure selection via environemnt flag?,,,Yes
26086,TODO add container and user information as a coment via -C,,,Yes
26088,TODO fix in nbresuse,,,Yes
26090,TODO is this really needed? - fix permission in dockerfile,,No,Yes
26091,TODO is export needed as well?,,No,Yes
26092,TODO build all,,Yes,Yes
26093,Fix permissions,,,Yes
26097,Todo: Remove usage of pexpect when ssh setup script callable non-interactively,,Yes,Yes
26098,TODO is installed manually via config in Docker,,No,Yes
26101,TODO: not needed to open this port?,,,Yes
26102,TODO: Writing comments for each fucntions,,No,Yes
26103,TODO : what if several fileS provided as csv or h5 e.g. x; label1; label2,,,Yes
26104,''' || General documentation architecture: || Home || Index || - Getting started ||     Getting started with the sequential model ||     Getting started with the functional api ||     FAQ || - Models ||     About Keras models ||         explain when one should use Sequential or functional API ||         explain compilation step ||         explain weight saving; weight loading ||         explain serialization; deserialization ||     Sequential ||     Model (functional API) || - Layers ||     About Keras layers ||         explain common layer functions: get_weights; set_weights; get_config ||         explain input_shape ||         explain usage on non-Keras tensors ||     Core Layers ||     Convolutional Layers ||     Pooling Layers ||     Locally-connected Layers ||     Recurrent Layers ||     Embedding Layers ||     Merge Layers ||     Advanced Activations Layers ||     Normalization Layers ||     Noise Layers ||     Layer Wrappers ||     Writing your own Keras layers || - Preprocessing ||     Sequence Preprocessing ||     Text Preprocessing ||     Image Preprocessing || Losses || Metrics || Optimizers || Activations || Callbacks || Datasets || Applications || Backend || Initializers || Regularizers || Constraints || Visualization || Scikit-learn API || Utils || Contributing || ''',,Yes,Yes
26105,TODO: Write minibatches for each source and destination,,Yes,Yes
26108,FIXME.xqliu Sequence of the table is not updated hence,,Yes,Yes
26110,TODO How to strip each string element before join them?,,Yes,Yes
26113,TODO: Move those business related settings to a table and make it changeable via UI.,,,Yes
26114,TODO Refer to https:\/\/github.com\/flask-admin\/flask-admin\/pull\/1209 for the current issue.,,,Yes
26118,Postgres does not support label as (func.count(t_parent.name) - (sub_tree.c.depth + 1)).label('xxx'),,No,Yes
26119,to set the query_factory function is the right way to implement a filter.,,No,Yes
26122,TODO Find a way to change MarkShipRowAction to mark_ship_row_action,,Yes,Yes
26125,Follow line is needed to persist all existing migration to DB and avoid,,,Yes
26127,TODO. Get last quarter number,,,Yes
26128,TODO: don't require Postgres on app object initialization,,,Yes
26130,TODO determine if local path or url; for now assume it's a URL?,,Yes,Yes
26131,QUESTION Should we be testing all? User option maybe?,,Yes,Yes
26133,TODO determine if local path or url; for now assume it's a URL?,,Yes,Yes
26135,TODO return file info,,Yes,Yes
26136,TODO handle creation of Inference and Instancte objects\t,,Yes,Yes
26138,TODO define options and clarify in docs,,Yes,Yes
26142,TODO create Inference() object...\t\t,,Yes,Yes
26143,TODO better handling input vs file,,No,Yes
26144,TODO return file data here if in immediate mode,,No,Yes
26147,TODO review use of deep copy,,Yes,Yes
26149,TODO review better way to update fields,,,Yes
26154,TODO make this more flexible to work with different tensor types,,No,Yes
26155,Really stupid work around,,Yes,Yes
26157,Really stupid work around,,Yes,Yes
26158,TODO optional to use temp directory,,Yes,Yes
26159,"TODO not a fan of \""return_type\"" variable name",,Yes,Yes
26160,TODO review use of deep copy,,Yes,Yes
26162,better using existing than client.predict(list),,,Yes
26163,TODO would like this to perhaps be a seperate function,,,Yes
26164,ie part of File_Constructor perhaps,,,Yes
26165,TODO could abstract code block L225 file_constructor,,Yes,Yes
26167,TODO change the general directory_list,,Yes,Yes
26168,TODO upgrade directory_list here to be 1st class objects instead of JSON,,,Yes
26170,TODO review better way to update fields,,Yes,Yes
26172,TODO replace string `joint_dir` with desired name,,Yes,Yes
26173,TODO replace string `first` with desired name,,,Yes
26176,TODO: make sure formula is in A1B1A2B2O6 order; if yes drop A1_atom ... columns,,Yes,Yes
26177,"\""\""\"" || All load* methods return the data in pandas.DataFrame. In each method a raw || data file is loaded; some preliminary transformation\/renaming\/cleaning done and || the results are returned. For specific columns returned refer to the documentation || of each function. If you plan to add a new dataset please follow the guidelines || and refer to documentation in load_castelli_perovskites for consistent docs. ||  || Naming convention guidelines: ||     - use small letters for column names consistently ||     - return only those columns that cannot be derived from other available ones ||     - use spaces between words; use _ only when it makes sense as a subscript ||         e.g. \""e_form\"" means energy of formation ||     - start with property name followed by method\/additional description:  ||         e.g. \""gap expt\"" means band gap measured experimentally ||         e.g. \""gap pbe\"" means band gap calculated via DFT using PBE functional ||     - avoid including units in the column name; instead explain in the docs ||     - roughly use a 15-character limit for column names ||  || Possible other datasets to consider: ||     matminer dielectric dataset ||     matminer piezoelectric dataset ||     https:\/\/www.nature.com\/articles\/sdata201865 (Shyam phonon) - AF ||     https:\/\/www.nature.com\/articles\/sdata201882 (JARVIS-DFT optoelectronic) ||     https:\/\/www.nature.com\/articles\/s41598-017-05402-0 (JARVIS-DFT-2D) ||     OQMD? - AF || \""\""\""",,,Yes
26182,TODO: integrate the following featurizers that require fit first,,Yes,Yes
26183,TODO: add more dos featurizers here,,,Yes
26184,self.assertGreater(len(df.columns); len(df_init.columns)),,No,Yes
26185,TODO: remove this accuracy=4 when new version of matminer is released,,Yes,Yes
26190,"\""\""\"" || -AF:  ||     TPOT is an academic open-sourced package that seems to be suitable overall to || matbench though there doesn't seem to be an explicit support for feature importance. || It uses a combination of GP and genetic algorithm to find the estimator with the || set of parameters that returns the best scoring (supports many scoring metrics) ||     pros: ||         + easy install and written in python ||         + easily accessible history of models tried and their accuracy in evaluated_individuals_ ||         + automatic global optimization already implemented ||         + seems more organized than automl ||         + writes sample pipeline to file to resume\/modify analysis ||     cons: ||         - no feature importance as far as I can tell ||         - I have had some difficulties using it in Pycharm as opposed to Terminal and Jupyter notebooks || \""\""\""",,No,Yes
26191,TODO: remove\/modify the following once preprocessing methods for str\/objects are implemented:,,No,Yes
26192,df = df.drop(list(df.columns[df.dtypes == object]); axis=1),,,Yes
26194,TODO: df=None and target should be removed from init; and should be specified in every method as args,,Yes,Yes
26198,TODO: This might not work with numpy types; haven't checked - AD,,,Yes
26200,todo: Remove once MultipleFeaturizer is fixed,,,Yes
26201,Todo: revert to MultipleFeaturizer once it is fixed,,,Yes
26210,pd.set_option('display.max_columns'; 500),,,Yes
26211,Todo: Find how to get the original labels back?  - AD,,,Yes
26215,todo: this is a WIP - AD,,No,Yes
26218,todo: Make the following conversions more robust (no lazy [0] type checking),,No,Yes
26221,todo: Make the following conversions more robust (no lazy [0] type checking),,No,Yes
26222,todo: needs MAJOR logging!!!!!!!!!!!!!!!!!,,Yes,Yes
26227,todo: Remove once MultipleFeaturizer is fixed,,,Yes
26228,todo: Add options for scaling (only on number cols. should be relabeled as _scaled) - AD,,No,Yes
26229,Ensure the order of columns is identical,,,Yes
26230,X = pd.DataFrame(columns=X.columns; data=Xmatrix),,,Yes
26231,todo: We should have the ability to ensembelize predictions based on,,,Yes
26236,todo: use the matminer version once its fixed and pushed,,No,Yes
26238,todo: implement persistence level,,Yes,Yes
26244,todo: implement persistence level,,,Yes
26245,todo: implement scoring selection,,,Yes
26246,todo: figure out CV-only,,,Yes
26247,todo: Add options for scaling (only on number cols. should be relabeled as _scaled) - AD,,,Yes
26248,Ensure the order of columns is identical,,,Yes
26249,X = pd.DataFrame(columns=X.columns; data=Xmatrix),,Yes,Yes
26251,Normalize and scale data to work better with SVM model,,,Yes
26252,If shear modulus is included as a feature it should probably show up,,Yes,Yes
26256,todo: implement persistence level,,Yes,Yes
26257,todo: Add options for scaling (only on number cols. should be relabeled as _scaled) - AD,,No,Yes
26258,If shear modulus is included as a feature it should probably show up,,Yes,Yes
26259,"self.assertTrue(\""composition\"" not in df_test.columns)",,Yes,Yes
26260,"self.assertTrue(\""composition\"" not in df_test2.columns)",,,Yes
26261,"self.assertTrue(\""G_VRH\"" in df.columns)",,No,Yes
26262,"self.assertTrue(\""K_VRH\"" in df.columns)",,Yes,Yes
26263,# If shear modulus is included as a feature it should probably show up,,,Yes
26265,"self.assertTrue(self.target + \"" predicted\"" in df_test.columns)",,No,Yes
26266,If shear modulus is included as a feature it should probably show up,,Yes,Yes
26268,todo: finish this,,,Yes
26270,todo: structure to oxidstructure + comp2oxidcomp can get called twice by _tidy_column,,No,Yes
26274,X = pd.DataFrame(columns=X.columns; data=Xmatrix),,Yes,Yes
26275,return the worse feature; knowing higher is better for both metrics,,Yes,Yes
26276,todo: PCA will not work with string columns!!!!!,,Yes,Yes
26278,TODO: HAVE THIS PUSH A NEW BENCHMARK TO LAWRENCIUM,,Yes,Yes
26279,todo: Remove this duplicated code section; maybe just make a parent class,,Yes,Yes
26284,"\""\""\"" || Classes for automatic featurization and core featurizer functionality. || \""\""\""",,Yes,Yes
26285,Take the mean of all numeric columns,,,Yes
26286,Simply fill one hot encoded columns,,,Yes
26287,Samples belonging in number columns are averaged to replace na,,,Yes
26288,extra columns; having the names of featurization cols set to the,,Yes,Yes
26289,extra columns; having the names of featurization cols set to the,,,Yes
26290,bos.columns = boston.feature_names,,Yes,Yes
26291,df.columns = boston.feature_names,,,Yes
26294,Hack to copy the CHANGES.rst file,,Yes,Yes
26296,pd.set_option('display.max_columns'; 500),,No,Yes
26298,todo: change the tpot template!!!,,,Yes
26299,extra columns; having the names of featurization cols set to the,,,Yes
26301,todo this is not working probably,,,Yes
26305,expects shape (batch; num_input_channels; input_rows; input_columns),,Yes,Yes
26307,prevent numerical instability (broad unused comps),,No,Yes
26308,split stats into (stats; extra_stats) if needed,,,Yes
26310,in a real-world scenario; we would have already manually authenticated,,,Yes
26311,add the prior precision to each posterior component if needed,,Yes,Yes
26314,TODO: automatically determine good bin sizes for histograms,,Yes,Yes
26315,TODO: get rid of seaborn dependency for despine,,Yes,Yes
26316,TODO: add legend (if legend is True),,,Yes
26317,TODO: add asserts checking compatiblity of dimensions,,Yes,Yes
26325,TODO: Maybe enable checking for a specific version of astropy_helpers?,,No,Yes
26326,doesn't exist; and the above two lines are not needed,,Yes,Yes
26328,XXX: May block if either stdout or stderr fill their buffers;,,Yes,Yes
26333,TODO have to modify so that min max works on 3D arrays for pairwise,,,Yes
26335,overwrite all columns which are not specified by the factors with 0,,Yes,Yes
26337,workaround: batch_size=num_observations,,,Yes
26338,workaround: batch_size=num_observations,,No,Yes
26339,workaround: batch_size=num_observations,,,Yes
26340,TODO: remove this warning when lrt is working,,Yes,Yes
26342,maybe improved later,,No,Yes
26344,maybe improved later,,No,Yes
26345,unparseable. Maybe git-describe is misbehaving?,,,Yes
26347,TODO handle interactions,,Yes,Yes
26349,TODO handle interactions,,,Yes
26351,# Order columns by continuous covariate.,,No,Yes
26352,# Order columns by continuous covariate.,,No,Yes
26355,# Order columns by continuous covariate.,,No,Yes
26356,TODO handle interactions,,,Yes
26357,batch_size=X.shape[0];  # workaround: batch_size=num_observations,,,Yes
26360,TODO unnecessary mean computation,,,Yes
26361,TODO: can this be done on sparse?,,No,Yes
26363,select the columns of the factors,,,Yes
26365,TODO: can this be done on sparse?,,No,Yes
26366,# Order columns by continuous covariate.,,,Yes
26368,TODO: design_loc is sometimes xarray and sometimes patsy when it arrives here;,,Yes,Yes
26369,TODO handle interactions,,,Yes
26371,TODO put into simulation.,,Yes,Yes
26372,TODO put into simulation.,,,Yes
26373,"\""\""\""A simple MNIST classifier which displays summaries in TensorBoard. ||  ||  This is an unimpressive MNIST model; but it is a good example of using || tf.name_scope to make a graph legible in the TensorBoard graph explorer; and of || naming summary tags so that they are grouped meaningfully in TensorBoard. ||  || It demonstrates the functionality of every TensorBoard dashboard. || \""\""\""",,Yes,Yes
26375,TODO(b\/64848083) Remove once uid bug is fixed,,,Yes
26377,randomness; while smaller sizes have better performance.,,,Yes
26380,Wide columns and deep columns.,,No,Yes
26381,Futher when batch_size is small; it is more efficient to run it on CPU instead of GPU,,,Yes
26383,UAI author modify the code to run on UAI platform,,,Yes
26385,RLE is a simple yet efficient format for storing binary masks. RLE,,Yes,Yes
26386,max overlap with gt over classes (columns),,,Yes
26389,These values will be needed for making predictions,,Yes,Yes
26390,Move channels (axis 3) to axis 1,,,Yes
26392,Note that the 0th index is an unused background class,,,Yes
26393,Continuous columns,,No,Yes
26394,Wide columns and deep columns.,,No,Yes
26396,TODO: Determine the optimal value using a validation data set,,Yes,Yes
26398,TODO: Transform the decoded output to a string,,Yes,Yes
26400,Continuous columns,,No,Yes
26401,Wide columns and deep columns.,,No,Yes
26407,Moving averages ends up in the trainable variables collection,,No,Yes
26408,Moving averages ends up in the trainable variables collection,,,Yes
26409,Moving averages ends up in the trainable variables collection,,,Yes
26411,or move backward edge,,,Yes
26412,move image channels to outermost,,Yes,Yes
26418,"\""\""\"" || The base convolution neural networks mainly implement some useful cnn functions || \""\""\""",,Yes,Yes
26420,Here implement a double way dict or two dict to quickly map ord and it's corresponding index,,Yes,Yes
26422,TODO,,,Yes
26423,Here implement a double way dict or two dict to quickly map ord and it's corresponding index,,Yes,Yes
26425,Move everything into depth so we can perform a single matrix multiply.,,No,Yes
26426,windows hack: we will use msmpi,,,Yes
26427,"\""\""\"" || The base convolution neural networks mainly implement some useful cnn functions || \""\""\""",,,Yes
26428,"\""\""\"" || The base convolution neural networks mainly implement some useful cnn functions || \""\""\""",,,Yes
26429,move image channels to outermost,,,Yes
26431,or move backward edge,,,Yes
26432,model prefix; In UAI Platform; should be \/data\/output\/xxx,,,Yes
26433,Cast the labels to floats; needed later,,Yes,Yes
26435,randomness; while smaller sizes have better performance.,,,Yes
26436,(2) Blank lines between documents. Document boundaries are needed so,,,Yes
26437,The convention in BERT is:,,No,Yes
26439,The convention in BERT is:,,No,Yes
26440,"What we really want to return is \""Steve Smith\"".",,,Yes
26442,labels = Y.columns,,,Yes
26443,"columns = [\""text\""] + labels",,Yes,Yes
26444,in fact that's 1D conv; but we implement it by conv2d,,No,Yes
26447,TODO: check if headers are the same,,Yes,Yes
26450,A database is a collection of tables; with rows and columns of structured data.,,,Yes
26451,A false negative is a real e-mail that ends up in the junk folder.,,,Yes
26453,[citation needed],,Yes,Yes
26455,XXX ignores weight & type,,No,Yes
26456,Which feature to split next is decided by a cost function (gini).,,,Yes
26457,"for id; type; product; _; score; title; author; review; language in shuffled(Datasheet.load(\""\/Users\/tom\/Desktop\/CLiPS\/textgain\/data\/amazon\/reviews-de.csv\""))[:4000]:",,Yes,Yes
26458,move to nearer centroid,,,Yes
26466,alone does not implement real matrix multiplications.,,Yes,Yes
26472,TODO: External arrayset loading is not yet implemented as of today.,,Yes,Yes
26478,TODO:,,No,Yes
26479,little bit more fun; we are going to use the PathList to implement the,,,Yes
26482,TODO: Saving will not work presently,,Yes,Yes
26483,copy; delete and move data around.,,,Yes
26485,do better. Let's verify,,,Yes
26486,TODO Add asserts,,,Yes
26491,TODO: check eigenvectors,,,Yes
26492,TODO: Should it rather be the normalized arrayset?,,No,Yes
26493,"\""\""\""Table models and functionality for the Replay Attack DB. || \""\""\""",,,Yes
26494,"\""\""\""This module provides the Dataset interface allowing the user to query the || replay attack database in the most obvious ways. || \""\""\""",,Yes,Yes
26495,TODO: client_ids,,No,Yes
26496,"\""\""\""Table models and functionality for the BANCA database. || \""\""\""",,,Yes
26498,TODO: dictionary interface,,,Yes
26499,TODO: client_ids,,,Yes
26500,TODO: client_ids,,,Yes
26501,"\""\""\""Table models and functionality for the Biosecure database. || \""\""\""",,Yes,Yes
26502,"\""\""\""This module provides the Dataset interface allowing the user to query the || Biosecure database in the most obvious ways. || \""\""\""",,,Yes
26503,TODO: dictionary interface,,Yes,Yes
26505,TODO: full protocol,,No,Yes
26508,"\""\""\""This module provides the Dataset interface allowing the user to query the || Multi-PIE database in the most obvious ways. || \""\""\""",,Yes,Yes
26510,TODO,,Yes,Yes
26512,"\""\""\""Table models and functionality for the Mobio database. || \""\""\""",,Yes,Yes
26515,"\""\""\""Table models and functionality for the SCFace database. || \""\""\""",,,Yes
26518,"\""\""\""Table models and functionality for the XM2VTS database. || \""\""\""",,Yes,Yes
26519,"\""\""\""This module provides the Dataset interface allowing the user to query the || XM2VTS database in the most obvious ways. || \""\""\""",,Yes,Yes
26522,"\""\""\""Table models and functionality for the BANCA_SMALL database. || \""\""\""",,,Yes
26524,TODO: fix n_blocks,,No,Yes
26526,TODO: if first_session == 0: raises an error,,Yes,Yes
26530,"\""\""\""Table models and functionality for the LFW database. || \""\""\""",,Yes,Yes
26533,TODO: constructor without argument,,No,Yes
26535,better accuracy. The main purpose of this option is to provide you the,,,Yes
26536,create all grid-nodes (create columns; from left to right),,,Yes
26537,+1. libsvm; apparently; suggests you do that for all features.,,,Yes
26546,TODO,,Yes,Yes
26548,"\""\""\""Table models and functionality for the BANCA database. || \""\""\""",,,Yes
26550,"\""\""\""Table models and functionality for the FIR database. || \""\""\""",,,Yes
26551,"\""\""\""This module provides the Dataset interface allowing the user to query the || FIR database in the most obvious ways. || \""\""\""",,,Yes
26553,Note: defining the variable q once outside the if statement makes it less efficient!,,,Yes
26556,another python sqlite wrapper (maybe supports URIs),,,Yes
26559,This is a fix to the problem of using templates\/static\/exceptions\/dynamic,,Yes,Yes
26560,report results in a readable way,,No,Yes
26561,Select image as by VLfeat (seems wrong to me),,No,Yes
26562,report results in a readable way,,No,Yes
26563,Bob c++ way,,Yes,Yes
26565,XXX use a more permanent ez_setup.py URL when available.,,,Yes
26566,Hack to download the dependencies,,,Yes
26571,TODO: add nonlinearity layer if node has output function?,,,Yes
26572,TODO: create decoded connection and probe that,,No,Yes
26574,TODO: initialize the weights here based on function\/transform,,,Yes
26577,TODO: support seed,,No,Yes
26578,TODO: synapses,,No,Yes
26581,TODO: put a dropout layer in here?,,,Yes
26583,TODO: support slicing on recurrent connection,,No,Yes
26586,note: this won't work properly if conn.function doesn't,,No,Yes
26587,TODO: some fancier registry system,,Yes,Yes
26589,TODO: create specialized operators for different neuron types,,Yes,Yes
26590,to run (otherwise they look like unused nodes and get optimized out),,Yes,Yes
26591,TODO: create specialized operators for synapses,,,Yes
26592,TODO: what to do if it is None? does this ever happen?,,No,Yes
26593,TODO: optimize out slice(None;None;None),,,Yes
26597,TODO: just rebuild the sim_process nodes,,,Yes
26598,TODO: support progress bar,,Yes,Yes
26599,TODO: create specialized operators for different neuron types,,Yes,Yes
26600,to run (otherwise they look like unused nodes and get optimized out),,,Yes
26603,TODO: support this,,No,Yes
26605,TODO: make sliced assignment work for multidimensional arrays,,Yes,Yes
26606,TODO: is this still necessary; or did it get fixed by something,,Yes,Yes
26607,TODO: merge this and assign_view somehow?,,Yes,Yes
26609,TODO: all this nested if\/else logic could be simplified a bit,,No,Yes
26610,TODO: add a probing benchmark,,,Yes
26612,TODO: why does this += make it way slower?,,No,Yes
26614,TODO: maybe do this off the GPU (to save memory)?,,No,Yes
26615,TODO: get this part to work again,,,Yes
26616,TODO: let user specify,,,Yes
26618,TODO: let user specify,,Yes,Yes
26620,TODO: support this?,,,Yes
26621,TODO: I think it is actually OK to have overlapping incs; they will,,Yes,Yes
26622,just be executed in a non-deterministic order; which is fine. but,,,Yes
26624,# TODO: merge this and assign_view somehow?,,,Yes
26627,TODO: check if this indexed-based broadcasting is faster than,,,Yes
26628,# TODO: support this,,No,Yes
26629,# TODO: make sliced assignment work for multidimensional arrays,,Yes,Yes
26630,TODO: does using variables force it to go on and off CPU,,No,Yes
26631,TODO: once we remove all the state returns from the other,,No,Yes
26636,TODO: another possibility would be to be more conservative with,,,Yes
26637,# TODO: all this nested if\/else logic could be simplified a bit,,No,Yes
26638,TODO: remove this after I'm sure it's not being used anywhere,,No,Yes
26640,TODO: is the base_vars dependency necessary with tensors?,,No,Yes
26642,TODO: do we still need to include state in the loop_vars? I think,,No,Yes
26643,TODO: is the base_vars dependency necessary with tensors?,,No,Yes
26644,TODO: add a thing that tries to rearrange arrays to minimize the number,,,Yes
26646,array blocks; allowing for more efficient multiplication (mainly,,Yes,Yes
26647,TODO: optimize gathers into full reads or stridedslices if possible,,,Yes
26648,TODO: there's something weird going on here where probe_tensors,,No,Yes
26649,TODO: detect if ops order didn't change (early termination),,Yes,Yes
26650,TODO: every few iterations; eliminate the smallest unsatisfied block,,Yes,Yes
26653,TODO: support this?,,,Yes
26657,TODO: set this up so step_blocks; loop_unroll can be controlled by,,Yes,Yes
26658,unused_variable = tf.Variable(0),,Yes,Yes
26660,TODO: do we want to do this? I don't think so; because there is,,,Yes
26661,of order; which will hopefully be fixed on future passes. however;,,,Yes
26662,TODO: do we actually want that? or if things can't be sorted fully,,,Yes
26665,TODO: remove this once we're sure we don't want to use tensors,,Yes,Yes
26666,is more efficient,,,Yes
26667,TODO: is this identity necessary?,,No,Yes
26668,TODO: implement general linear filter (using tensorarrays?),,No,Yes
26669,TODO: we could store the indices as well; so that future writes are,,Yes,Yes
26670,TODO: better solution to avoid the forced_copy,,No,Yes
26671,probe_array.flow doesn't work; although I think it should).,,Yes,Yes
26674,TODO: do we need to do the tile; or will the scatter assignment,,Yes,Yes
26676,TODO: implement general linear filter (using tensorarrays?),,,Yes
26677,filter unused operators,,No,Yes
26678,move batch dimension to front,,,Yes
26680,cases where this is more efficient? (e.g. for large; sparse arrays),,Yes,Yes
26683,TODO: what should the minibatch_size cutoff be?,,,Yes
26684,TODO: double check that this is faster than doing matmul,,No,Yes
26685,filter unused operators,,No,Yes
26687,probe_array.flow doesn't work; although I think it should).,,Yes,Yes
26688,TODO: get this part to work again,,,Yes
26690,TODO: there isn't really any advantage to having huge monolithic base,,Yes,Yes
26691,TODO: until tensorflow implements scatter_nd kernel for GPU; users,,,Yes
26693,TODO: alternatively; we could just partition based on reads; and allow,,,Yes
26694,sets to happen across base arrays (how much of a performance hit would,,,Yes
26696,TODO: could also add linear synapse outputs (depending on,,Yes,Yes
26701,TODO: there's some possible bugs with device=None and,,Yes,Yes
26710,perhaps gain by trying to sort them are not worth the added,,Yes,Yes
26712,perhaps gain by trying to sort them are not worth the added,,,Yes
26714,TODO: implement transitive-closure based planner,,,Yes
26715,TODO: maybe we should just care about duplicates (how much does the size,,,Yes
26716,TODO: we should set this up so it prefers to add new blocks,,No,Yes
26717,TODO: remove this if we're sure we're not going back to the tensor,,No,Yes
26719,TODO: use elemwise for small matrices,,No,Yes
26722,TODO: remove this and bump nengo version once there is a release,,No,Yes
26724,TODO: ideally we would just reload(tensorflow) here; but that crashes atm,,No,Yes
26725,TODO: the ._ref() is necessary due to something in tensorflow 1.0.0;,,,Yes
26727,TODO: switch allow_soft_placement to False once tensorflow,,Yes,Yes
26732,TODO: we could also merge operators sequentially (e.g.; combine,,Yes,Yes
26736,TODO: use truncated normal distribution,,Yes,Yes
26739,TODO: the dynamic_stitch approach might be faster if there were,,No,Yes
26741,run once to eliminate startup overhead,,Yes,Yes
26745,TODO: this is a temporary fix until the permanent fix is,,,Yes
26747,move batch dimension to front,,,Yes
26748,TODO: temporarily disabled until we have a nengo release with,,Yes,Yes
26750,TODO: support this?,,No,Yes
26752,TODO: set up queue to feed in data more efficiently,,No,Yes
26755,TODO: we can remove this check if we upgrade nengo dependency to,,No,Yes
26758,TODO: allow error to be passed instead of objective,,,Yes
26759,TODO: set up extra requires,,,Yes
26760,run once to eliminate startup overhead,,Yes,Yes
26761,TODO: verify the performance improvement of the simplifications,,,Yes
26762,TODO: can remove this if we upgrade minimum nengo version,,,Yes
26763,be more efficient,,,Yes
26765,TODO: double check if this is still true in 1.9.0,,,Yes
26766,TODO: support this?,,No,Yes
26769,doesn't work with nbsphinx TODO: remove this once there's an upstream fix; https:\/\/github.com\/jupyter\/nbconvert\/issues\/878,,Yes,Yes
26771,TODO: find a way to run this at the right time with one call,,Yes,Yes
26773,TODO: we can remove these redirects after a few releases,,,Yes
26775,TODO: move this logic into the respective builders,,,Yes
26776,TODO: fix link to `~nengo.builder.transform.ConvInc` once it exists,,No,Yes
26777,TODO: check if this is supported in future versions,,Yes,Yes
26778,move batch to front,,Yes,Yes
26780,move batch back to end; ops to front,,,Yes
26781,blocks; allowing for more efficient multiplication (mainly,,Yes,Yes
26784,TODO: check if this is fixed in 1.14,,,Yes
26785,has a bug with third party modules TODO: remove once there's an upstream fix; https:\/\/github.com\/timothycrosley\/isort\/issues\/882,,Yes,Yes
26786,run once to eliminate startup overhead,,,Yes
26788,TODO: nengo 3.0 adds something similar to this condition; but,,Yes,Yes
26789,implement those operations as (broadcasted) multiplies rather than,,,Yes
26791,TODO: double check if this is still true in the future,,Yes,Yes
26792,temporary variable approach seems to be slightly faster (but we,,No,Yes
26794,TODO: remove once there is a black release with this,,No,Yes
26795,to be created on the CPU if necessary; and then move it to,,Yes,Yes
26796,TODO: double check if this is still true in the future,,Yes,Yes
26797,TODO: XLA compiling doesn't seem to provide any benefit at the,,,Yes
26799,filter unused operators,,No,Yes
26800,TODO: better solution to avoid the forced_copy,,,Yes
26802,this isn't actually needed\/used; but the keras RNN code requires at least one,,Yes,Yes
26803,TODO: only add filler if needed (when there are no other inputs),,,Yes
26805,TODO: will this be called inside or outside the while loop context?,,,Yes
26808,move minibatch dimension to front,,Yes,Yes
26810,TODO: check if this is still necessary in TensorFlow 2.0,,No,Yes
26811,TODO: fix link to `~nengo.builder.transform.ConvInc` once it exists,,No,Yes
26812,move batch to front,,Yes,Yes
26813,move channel dimension back to the front,,Yes,Yes
26815,TODO: remove this if we switch completely to keras optimizers,,,Yes
26816,temporary variable approach seems to be slightly faster (but we,,,Yes
26818,TODO: possible to rework things to not require all the,,No,Yes
26819,move batch to front,,Yes,Yes
26821,move batch back to end; ops to front,,Yes,Yes
26824,wrong dtype; which we fix here,,Yes,Yes
26829,TODO: basically what we'd like to do is map _generate_inputs to each,,Yes,Yes
26830,TODO: which of this data checking is redundant with keras?,,,Yes
26836,TODO: get this working,,No,Yes
26837,TODO: this will work in eager mode,,,Yes
26838,TODO: why doesn't the gradient tape method work?,,,Yes
26842,TODO: support this using tf.random.experimental; see,,,Yes
26844,TODO: add this check back in once,,,Yes
26848,TODO: this isn't necessary in eager mode,,Yes,Yes
26850,TODO: switch to eager evaluation,,Yes,Yes
26853,TODO: this works in eager mode,,,Yes
26854,TODO: why does the gradient check fail?,,,Yes
26856,TODO: allow fallback,,No,Yes
26857,use ensemble to implement the appropriate neuron type,,Yes,Yes
26858,TODO: figure out where the tradeoffs lie between these two approaches,,,Yes
26859,add connection to implement the dense weights,,,Yes
26860,note: not clearing op.func._losses; because those are manually added,,Yes,Yes
26863,TODO: It would be good to optimize LMU performance as the NengoDL implementation,,Yes,Yes
26865,TODO: why does this cause problems if it is done before the tensornode,,No,Yes
26866,TODO: this shouldn't be necessary once we're running natively in eager,,,Yes
26867,TODO: this can be delegated to op.neurons.spiking if we increase the minimum,,No,Yes
26868,TODO: this can be delegated to op.neurons.spiking if we increase the minimum,,,Yes
26869,TODO: cache these instead of regenerating each tim,,No,Yes
26874,TODO: this fails due to a bug in tensorflow; see,,,Yes
26876,Guarantee that pathtofolder ends with a slash.,,No,Yes
26877,TODO: Implement the cumulative distribution function,,,Yes
26886,TODO Or 0.8 as previously?,,Yes,Yes
26887,samples within this component and the batch_size columns,,,Yes
26888,samples within this component and the batch_size columns,,Yes,Yes
26889,"Dictionary holding number of samples needed for the \""monte carlo\""",,,Yes
26894,"Dictionary holding number of samples needed for the \""monte carlo\""",,,Yes
26895,TODO: Reduce dim. of mean.,,Yes,Yes
26896,TODO: Reduce dim. of mean.,,,Yes
26897,"Dictionary holding number of samples needed for the \""monte carlo\""",,Yes,Yes
26899,TODO Use diagonal y ticks,,,Yes
26902,Number of categorical elements needed for reconstruction; e.g. K+1,,No,Yes
26903,Number of categorical elements needed for reconstruction; e.g. K+1,,No,Yes
26904,10 # TODO Change back,,,Yes
26906,TODO Remove,,,Yes
26907,TODO Remove,,,Yes
26908,Distances (if needed),,,Yes
26909,TODO Remove when TensorFlow Probability library is updated to v0.6,,Yes,Yes
26910,TODO Let number of samples be optional,,Yes,Yes
26912,Distances (if needed),,No,Yes
26916,Dictionary holding number of samples needed for the Monte Carlo,,No,Yes
26917,Dictionary holding number of samples needed for the Monte Carlo,,No,Yes
26921,-- Options for todo extension ----------------------------------------------,,,Yes
26923,TODO:,,,Yes
26924,TODO:,,No,Yes
26926,TODO : perform checking of tolerance,,,Yes
26927,unused,,No,Yes
26928,split and flip fm waveform to improve large-tip accuracy,,,Yes
26929,split and flip fm waveform to improve large-tip accuracy,,,Yes
26930,split and flip fm waveform to improve large-tip accuracy,,Yes,Yes
26932,TODO: more elegant solution with matrix shape should be found than custom or varying between cases,,No,Yes
26933,TODO: part of problem is that explicit formulation has different shape than nonexplicit formulation.,,,Yes
26934,TODO: Reshape nonexplicit so consistent?,,Yes,Yes
26935,TODO: CITE BASED ON DOUG NOLL'S spriallx6,,Yes,Yes
26936,split and flip fm waveform to improve large-tip accuracy,,,Yes
26937,TODO: add off-resonance,,No,Yes
26938,TODO: more elegant solution with matrix shape should be found,,No,Yes
26939,TODO: CITE BASED ON DOUG NOLL'S spriallx6,,Yes,Yes
26942,create the 2D pdf from with columns will be pulled,,Yes,Yes
26944,TODO: needs to include entire pulse in regularization ??,,Yes,Yes
26946,no mask provided; any columns,,,Yes
26947,create the 2D pdf from with columns will be pulledgit,,,Yes
26951,TODO: Average predictions,,Yes,Yes
26954,TODO: Predict only once,,,Yes
26955,TODO: Average predictions,,,Yes
26956,Accumulate scores over longer timeframes. This can be useful for better detecting longer events like footsteps;,,Yes,Yes
26957,TODO: Check for buffer overrun,,,Yes
26959,TODO: Check for buffer overrun,,No,Yes
26961,TODO: Optimize: When changing detectors rerun the last 500ms in the new detector to better,,,Yes
26962,TODO: Optimize: More error handling,,Yes,Yes
26968,todo make sure to check vocab,,Yes,Yes
26969,todo split into dense and sparse implementations,,,Yes
26970,todo: check if our ternary tree module is available,,No,Yes
26973,todo: use local vocab,,No,Yes
26974,TODO: moved from corpus; rename and use or remove,,,Yes
26976,TODO: decide how to save stopwords to metadata,,Yes,Yes
26981,oh crap; why are we not normalizing here?,,,Yes
26982,TODO: add this when we define final metadata fromat,,Yes,Yes
26984,todo use GPU,,Yes,Yes
26987,todo only support binary classification,,Yes,Yes
26988,TODO: make this less hackish,,No,Yes
26990,hack for fasttext output,,No,Yes
26991,todo lr posit; interation for deps,,Yes,Yes
26992,todo smarter split,,,Yes
26994,todo for file corpus,,,Yes
26995,todo smarter split,,Yes,Yes
26996,todo: figure out if we need this,,No,Yes
26997,todo: report which exaclt words are missing,,No,Yes
27000,todo for file corpus,,No,Yes
27001,TODO: list benchmarks,,No,Yes
27002,TODO: move this to helper module,,Yes,Yes
27008,TODO: move this logic to solver,,No,Yes
27009,TODO: implement,,Yes,Yes
27010,TODO: let all benchmarks set output path in init,,Yes,Yes
27011,TODO: move all this to the parent class,,Yes,Yes
27012,TODO: GPU,,No,Yes
27015,TODO: use vecto.corpus,,No,Yes
27017,TODO: don't do this; implement shift,,Yes,Yes
27021,"dframe.drop(\""details\""; axis=\""columns\""; inplace=True)",,Yes,Yes
27024,TODO: make lower-casing optional,,Yes,Yes
27028,TODO: fix this mess,,,Yes
27029,TODO: use logger,,No,Yes
27030,TODO: fix this,,No,Yes
27034,let us always assume dir; clean this up later if no better idea,,,Yes
27037,TODO: refactor this into intuitive method,,,Yes
27038,TODO: use pathlib everywhere,,Yes,Yes
27039,TODO: refactor this into intuitive method,,,Yes
27041,TODO: make sure dataset module support adapter.py,,No,Yes
27042,TODO: use proper path magic,,,Yes
27043,TODO: make dict a valid result as well,,Yes,Yes
27046,TODO: move method selection to benchmark class,,,Yes
27048,# let us always assume dir; clean this up later if no better idea,,No,Yes
27049,TODO: move this to proper location; reuse between senchmarks,,,Yes
27050,TODO: decide what to do with char_basrd,,Yes,Yes
27051,TODO: ckeck id the data is there,,Yes,Yes
27053,TODO: mark as obsolete and remove later,,,Yes
27054,TODO: detect where's lavel or specify format,,Yes,Yes
27057,TODO: add submodules to append to path,,Yes,Yes
27059,TODO: refactor to be understandable; check if ok after covab to UNK,,No,Yes
27060,TODO: add option for stopwords,,No,Yes
27061,TODO: mark as obsolete and remove later,,,Yes
27062,TODO: estimage file contenst size,,No,Yes
27067,Version history timeline (move to CHANGES periodically):,,Yes,Yes
27069,TODO: this should at some point replaced with argparser,,Yes,Yes
27077,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
27078,"\""\""\""\r || ###################################################################################################\r || \r || def main(opts;commline_list):\r ||     \""(main):\r ||         Driver of CheML.\r ||     \""\r ||     time_start = time.time()\r || \r || # TODO: add banner\r || # TODO: add parser function\r ||     \r ||     return 0    #successful termination of program\r ||     \r || ##################################################################################################\r || \r || if __name__==\""__main__\"":\r ||     usage_str = \""usage: %prog [options] arg\""\r ||     version_str = \""%prog \"" + PROGRAM_VERSION\r || # TODO: replace with argparser\r ||     parser = OptionParser(usage=usage_str; version=version_str)    \r || \r ||     # it is better to sort options by relevance instead of a rigid structure\r ||     parser.add_option('--job'; \r ||                       dest='input_file'; \r ||                       type='string'; \r ||                       default='input.dat'; \r ||                       help='input\/job file [default: %default]')\r || \r || \r ||     opts; args = parser.parse_args(sys.argv[1:])\r ||     if len(sys.argv) < 2:\r ||         sys.exit(\""You tried to run CheML without options.\"")\r ||     main(opts;sys.argv)   #numbering of sys.argv is only meaningful if it is launched as main\r ||     \r || else:\r ||     sys.exit(\""Sorry; must run as driver...\"")\r ||     \r || \r || if __name__ == '__main__':\r ||     pass\r || \r || \""\""\""",,No,Yes
27079,Version history timeline (move to CHANGES periodically):,,,Yes
27080,TODO:,,,Yes
27082,TODO: check typical error names\t\t,,No,Yes
27083,TODO:,,No,Yes
27084,drop object columns,,Yes,Yes
27085,drop null columns,,No,Yes
27086,TODO:,,No,Yes
27087,move,,Yes,Yes
27089,TODO: open file and read in,,,Yes
27090,TODO: this needs to be a binary read,,,Yes
27091,TODO: change binary format,,Yes,Yes
27092,TODO: this needs to be a binary write,,,Yes
27094,drop null columns,,,Yes
27095,Version history timeline (move to CHANGES periodically):,,,Yes
27096,TODO:,,No,Yes
27098,TODO: check typical error names\t\t,,,Yes
27099,TODO: sanitize activation function input,,No,Yes
27100,TODO: sanitize activation function input,,No,Yes
27101,move,,,Yes
27102,so move the dragged button (i.e. event.source()),,No,Yes
27103,todo: use utils subdirectory instead,,,Yes
27104,TODO: deepcopy is memory consuming,,Yes,Yes
27106,Todo: first fix the slurm script function at cheml.initialization,,,Yes
27107,Todo: then embede the slurm commands in this class to run the slurm script,,,Yes
27108,Todo: or make the slurm script in this function too,,,Yes
27112,Todo: first fix the slurm script function at cheml.initialization,,,Yes
27114,Todo: or make the slurm script in this function too,,No,Yes
27116,Todo: informative token should be a list of (int(edge[0];edge[1]),,,Yes
27117,unused,,No,Yes
27119,TODO: deepcopy is memory consuming,,Yes,Yes
27120,Todo: informative token should be a list of (int(edge[0];edge[1]),,No,Yes
27124,Todo: check if we can have one sent variable for two inputs,,,Yes
27129,todo: use Input and Output classes to handle inputs and outputs,,,Yes
27130,Todo: add all the metrics for regression,,No,Yes
27132,Todo: mpi code is required for the multiprocessing,,Yes,Yes
27134,Todo: bring back receivers - no need another recursive function for bidR; (currentbids - bidS = bidR),,,Yes
27135,Todo: profile the cpu\/clock time,,No,Yes
27136,print 'header: '; df.columns,,Yes,Yes
27137,Todo: custom function info on top,,,Yes
27140,"argument is negative and ends with \"".5\"". If so; add 1 to the",,,Yes
27143,Todo: change the molecules to a list of dictionaries,,,Yes
27144,drop object columns,,Yes,Yes
27146,print 'headers: '; list(df.columns),,Yes,Yes
27148,Todo: check w\/ Ram if this is what he meant to do when catch a warning: n = np.zeros(3),,,Yes
27149,Todo: polish docstrings,,Yes,Yes
27151,Todo: try to replace bare except,,Yes,Yes
27153,inverse min columns,,,Yes
27157,TODO:,,,Yes
27158,- fix python keyboardinterrupt bug:,,Yes,Yes
27159,to create a general atom mask (unused atoms are 0 padded),,Yes,Yes
27163,TODO remove path hack when greg fixes abs -> rel paths,,,Yes
27165,TODO add checking to make sure number of keys in h5 file matches number of lines in csv file,,Yes,Yes
27167,TODO add checking to make sure number of keys in h5 file matches number of lines in csv file,,,Yes
27168,TODO add checking to make sure number of keys in h5 file matches number of lines in csv file,,,Yes
27169,positions = positions[[column for column in positions.columns if 'z_' in column]],,,Yes
27170,columns += ('classLoss';),,,Yes
27172,columns = ('epoch'; 'iter'; 'reconLoss';),,Yes,Yes
27173,columns += ('classLoss';),,No,Yes
27174,columns += ('refLoss';),,,Yes
27175,columns += ('minimaxEncDLoss'; 'encDLoss'; 'minimaxDecDLoss'; 'decDLoss'; 'time'),,No,Yes
27176,logger = SimpleLogger(columns;  print_str),,Yes,Yes
27177,TODO add checking to make sure number of keys in h5 file matches number of lines in csv file,,Yes,Yes
27180,#this is the dumb hack I need to do to do parallel and save memory,,Yes,Yes
27181,#this is the dumb hack I need to do to do parallel and save memory,,Yes,Yes
27185,TODO add checking to make sure number of keys in h5 file matches number of lines in csv file,,Yes,Yes
27186,turn list of 2d or 3d arrays into single 4d array if needed,,Yes,Yes
27187,or even better,,Yes,Yes
27188,do some hack if set up for DataParallel,,Yes,Yes
27192,do some hack if set up for DataParallel,,Yes,Yes
27193,TODO: solve problem with mask of size [batch_size; total_length] when batch > 1,,No,Yes
27194,TODO: solution for now - mask[0],,No,Yes
27195,TODO: batch might have different sequence lengths,,Yes,Yes
27196,TODO: fix the batch indexing,,Yes,Yes
27197,TODO: fix the name,,Yes,Yes
27199,TODO: as we don't need the dummies here (no y needs recalling); we should add an arguements specifying if dummies are needed or not,,,Yes
27201,TODO: ctrl_start is not needed here; this is replaced by ctrl_xy,,,Yes
27202,TODO,,Yes,Yes
27203,TODO - move memory size somewhere?,,No,Yes
27204,TODO: interface!,,,Yes
27206,TODO:  REMOVE THOSE LINES.,,Yes,Yes
27207,TODO - move memory size somewhere?,,No,Yes
27208,TODO:  REMOVE THOSE LINES.,,Yes,Yes
27211,TODO - move memory size somewhere?,,No,Yes
27213,TODO!,,Yes,Yes
27216,TODO: rest;),,Yes,Yes
27218,TODO - move memory size somewhere?,,,Yes
27219,a hack for now,,No,Yes
27221,TK: TODO: move criterion to PROBLEM!,,Yes,Yes
27223,TODO: solution for now - mask[0],,No,Yes
27226,TODO: solution for now - mask[0],,,Yes
27227,Export model if better OR user simply wants to export the mode..,,,Yes
27229,TODO: fix the batch indexing,,,Yes
27231,hack for now,,Yes,Yes
27232,HARD SHIFT! TODO: Remove!,,Yes,Yes
27235,TK: TODO: move criterion to PROBLEM!,,,Yes
27236,problem.show_sample(x.view(num_rows; num_columns); y),,,Yes
27237,problem.show_sample(x.view(num_rows; num_columns); y),,Yes,Yes
27238,"#TODO CHANGE THIS SO IT DOESN\""T ASSUME TYPE OF DATA OR GET RID OF IT",,Yes,Yes
27239,TODO Eliminate,,Yes,Yes
27242,TODO: FINISH FIXING THIS,,Yes,Yes
27243,construct the three channels needed for alexnet,,Yes,Yes
27244,inputs_size = (batch_size; num_channel; numb_columns; num_rows),,Yes,Yes
27245,TODO: batch might have different sequence lengths,,,Yes
27247,TODO: batch might have different sequence lengths,,Yes,Yes
27248,TODO: fix the batch indexing,,Yes,Yes
27251,TODO: batch might have different sequence lengths,,,Yes
27253,TODO: WHY?? Fix this!,,Yes,Yes
27257,TODO: WHY?? Fix this!,,Yes,Yes
27261,TODO,,Yes,Yes
27262,source data filepath TODO: in future; should manage automatic download & storage.,,Yes,Yes
27267,TODO,,Yes,Yes
27270,add more colors here if needed,,No,Yes
27271,More channels - move channels to axis2; according to matplotilb doc it should be ok,,,Yes
27273,TODO: Set false as default!,,No,Yes
27274,TODO: U,,,Yes
27275,HARD SHIFT! TODO: Remove!,,Yes,Yes
27278,TODO: REST FROM HERE!,,,Yes
27281,TODO: will need to be avoided in the future,,,Yes
27282,TODO: check shape of encoder_outputs for attn_decoder,,,Yes
27283,TODO: fix this??,,,Yes
27284,TODO: fix the batch indexing,,Yes,Yes
27285,TODO: REMOVE! Cuts out the third subsequence.,,Yes,Yes
27286,TODO: REMOVE! Cuts out the third subsequence.,,,Yes
27287,Freeze weights - TODO: NOT IMPLEMENTED!,,,Yes
27288,TODO!,,,Yes
27289,Freeze weights - TODO: NOT IMPLEMENTED!,,,Yes
27292,TODO: fix the batch indexing,,,Yes
27293,But let's try to save it anyway; maybe it is still better than the previous one.,,,Yes
27295,TODO Make Multilayered LSTM controller in the vein of the DNC paper,,Yes,Yes
27298,But let's try to save it anyway; maybe it is still better than the previous one.,,Yes,Yes
27299,Validate on the problem if required - so we can collect the statistics needed during saving of the best model.,,,Yes
27300,"\""\""\""attention.py: implement different attention model: for now just the stacked attention exists https:\/\/arxiv.org\/abs\/1511.02274 ||  for future co-attention needs to be implemented https:\/\/arxiv.org\/abs\/1707.04968 \""\""\""",,,Yes
27301,"\""\""\""multi_hops_attention.py: implement multi hops stacked attention model\""\""\""",,Yes,Yes
27303,TODO: Anything else??,,Yes,Yes
27305,TODO Check if valid URL,,,Yes
27307,TODO Check if valid URL,,No,Yes
27311,dirty hack to go back from the,,,Yes
27312,needed for nltk.word.tokenize,,No,Yes
27316,scale by only the number of needed outputs,,No,Yes
27317,should add an arguements specifying if dummies are needed or not,,,Yes
27318,statistics needed during saving of the best model.,,No,Yes
27320,statistics needed during saving of the best model.,,No,Yes
27321,statistics needed during saving of the best model.,,,Yes
27322,get all needed parameters,,Yes,Yes
27324,"''' ||     def turn_on_cuda(self; data_tuple; aux_tuple): ||         \""\""\"" Enables computations on GPU - copies the input and target matrices (from DataTuple) to GPU. ||         This method has to be overwritten in derived class if one decides to copy other matrices as well. ||  ||         :param data_tuple: Data tuple. ||         :param aux_tuple: Auxiliary tuple (WARNING: Values stored in that variable will remain in CPU) ||         :returns: Pair of Data and Auxiliary tuples (Data on GPU; Aux on CPU). ||         \""\""\"" ||         # Unpack tuples and copy data to GPU. ||         gpu_inputs = data_tuple.inputs.cuda() ||         gpu_targets = data_tuple.targets.cuda() ||  ||         # Pack matrices to tuples. ||         data_tuple = DataTuple(gpu_inputs; gpu_targets) ||  ||         return data_tuple; aux_tuple ||  ||     def plot_preprocessing(self; data_tuple; aux_tuple; logits): ||         \""\""\"" ||         Allows for some data preprocessing before the model creates a plot for visualization during training or ||         inference. ||         To be redefined in inheriting classes. ||         :param data_tuple: Data tuple. ||         :param aux_tuple: Auxiliary tuple. ||         :param logits: Logits being output of the model. ||         :return: data_tuplem aux_tuple; logits after preprocessing. ||         \""\""\"" ||         return data_tuple; aux_tuple; logits ||  ||  ||     def curriculum_learning_initialize(self; curriculum_params): ||         \""\""\""  ||         Initializes curriculum learning - simply saves the curriculum params. ||         This method can be overwriten in the derived classes. ||  ||         :curriculum_params: Interface to parameters accessing curriculum learning view of the registry tree.  ||         \""\""\"" ||         # Save params. ||         self.curriculum_params = curriculum_params ||  ||  ||     def curriculum_learning_update_params(self; episode): ||         \""\""\"" ||         Updates problem parameters according to curriculum learning. ||         There is no general solution to curriculum learning. ||         This method should be overwriten in the derived classes. ||  ||         :param episode: Number of the current episode. ||         :returns: True informing that CL wasn't active at all (i.e. is finished). ||         \""\""\"" ||         return True || '''",,No,Yes
27325,"''' ||     def turn_on_cuda(self; data_tuple; aux_tuple): ||         \""\""\"" Enables computations on GPU - copies the input and target matrices (from DataTuple) to GPU. ||         This method has to be overwritten in derived class if one decides to copy other matrices as well. ||  ||         :param data_tuple: Data tuple. ||         :param aux_tuple: Auxiliary tuple (WARNING: Values stored in that variable will remain in CPU) ||         :returns: Pair of Data and Auxiliary tuples (Data on GPU; Aux on CPU). ||         \""\""\"" ||         # Unpack tuples and copy data to GPU. ||         gpu_inputs = data_tuple.inputs.cuda() ||         gpu_targets = data_tuple.targets.cuda() ||  ||         # Pack matrices to tuples. ||         data_tuple = DataTuple(gpu_inputs; gpu_targets) ||  ||         return data_tuple; aux_tuple ||  ||     def plot_preprocessing(self; data_tuple; aux_tuple; logits): ||         \""\""\"" ||         Allows for some data preprocessing before the model creates a plot for visualization during training or ||         inference. ||         To be redefined in inheriting classes. ||         :param data_tuple: Data tuple. ||         :param aux_tuple: Auxiliary tuple. ||         :param logits: Logits being output of the model. ||         :return: data_tuplem aux_tuple; logits after preprocessing. ||         \""\""\"" ||         return data_tuple; aux_tuple; logits ||  ||  ||     def curriculum_learning_initialize(self; curriculum_params): ||         \""\""\""  ||         Initializes curriculum learning - simply saves the curriculum params. ||         This method can be overwriten in the derived classes. ||  ||         :curriculum_params: Interface to parameters accessing curriculum learning view of the registry tree.  ||         \""\""\"" ||         # Save params. ||         self.curriculum_params = curriculum_params ||  ||  ||     def curriculum_learning_update_params(self; episode): ||         \""\""\"" ||         Updates problem parameters according to curriculum learning. ||         There is no general solution to curriculum learning. ||         This method should be overwriten in the derived classes. ||  ||         :param episode: Number of the current episode. ||         :returns: True informing that CL wasn't active at all (i.e. is finished). ||         \""\""\"" ||         return True || '''",,,Yes
27328,needed for nltk.word.tokenize,,No,Yes
27332,needed for nltk.word.tokenize,,,Yes
27335,needed for nltk.word.tokenize,,,Yes
27336,'data_folder': '~\/data\/CLEVR_v1.0\/'; # TODO!,,,Yes
27338,move batch to GPU,,,Yes
27339,needed for nltk.word.tokenize,,,Yes
27340,move batch to GPU,,Yes,Yes
27341,'data_folder': '~\/data\/CLEVR_v1.0\/'; # TODO!,,,Yes
27342,'data_folder': '~\/data\/CLEVR_v1.0\/'; # TODO!,,Yes,Yes
27345,self.reset_acc_per_family()  # TODO: Actually implement this function...,,,Yes
27347,'data_folder': '~\/data\/CLEVR_v1.0\/'; # TODO!,,,Yes
27348,needed for nltk.word.tokenize,,,Yes
27350,statistics needed during saving of the best model.,,No,Yes
27353,move batch to GPU,,Yes,Yes
27354,self.reset_acc_per_family()  # TODO: Actually implement this function...,,,Yes
27357,'data_folder': '~\/data\/CLEVR_v1.0\/'; # TODO!,,Yes,Yes
27360,needed for nltk.word.tokenize,,No,Yes
27365,--> We assume from here that the model class has all parameters values needed (either from params or,,,Yes
27368,--> We assume from here that the model class has all parameters values needed (either from params or,,Yes,Yes
27371,TODO: NOT SURE THAT THIS FN IS WORKING WELL (WITHOUT THE PRESENCE OF THE BATCH DIMENSION),,No,Yes
27372,TODO: THE DOCUMENTATION NEEDS TO BE UPDATED,,Yes,Yes
27373,TODO: NOT SURE THAT THIS FN IS WORKING WELL (WITHOUT THE PRESENCE OF THE BATCH DIMENSION),,,Yes
27376,TODO: THE DOCUMENTATION NEEDS TO BE UPDATED,,,Yes
27379,TODO: batch might have different sequence lengths,,Yes,Yes
27383,Check visualization flag - turn on visualization for last validation if needed.,,Yes,Yes
27384,TODO: Should derive the actual theoretical limit instead of a arbitrary limit.,,Yes,Yes
27386,TODO: Should derive the actual theoretical limit instead of a arbitrary limit.,,,Yes
27387,TODO: other fields to consider?,,,Yes
27388,TODO,,,Yes
27389,But let's try to save it anyway; maybe it is still better than,,Yes,Yes
27390,TODO: should also check that the order of dimension is coherent,,No,Yes
27391,perform 2-way handshake between Model and Problem,,Yes,Yes
27392,TODO: move to StatisticsAggregator for this.,,Yes,Yes
27394,TODO: move this step in validation() and handle using more than 1 batch for validation.,,Yes,Yes
27397,Check visualization flag - turn on visualization for last validation if needed.,,Yes,Yes
27398,II. & III - the loss is < threshold - only when we finished curriculum (# TODO: ?).,,Yes,Yes
27399,We still save the model as it may perform better during this episode,,Yes,Yes
27400,statistics needed during saving of the best model.,,No,Yes
27401,Move on to next episode.,,Yes,Yes
27403,move to next episode.,,Yes,Yes
27404,"\""\""\"" || grid_trainer_gpu.py: ||  ||     - This file contains the implementation of a worker spanning a grid of training experiments on\\ ||      a collection of GPUs. It works by loading a template yaml file; modifying the resulting dict; and dumping\\ ||       that as yaml into a temporary file. The ``Trainer`` is then executed using the temporary yaml file as the task.\\ ||       It will run as many concurrent jobs as possible. ||  || \""\""\""",,No,Yes
27406,check if the files are empty except for the first line TODO: Why?,,,Yes
27407,TODO: may want to enhance this,,,Yes
27408,Save plot of losses to png file  TODO: should check what that looks like,,Yes,Yes
27409,TODO: may want to enhance this,,No,Yes
27411,--> We assume from here that the model class has all parameters values needed (either from params or,,Yes,Yes
27413,TODO: other fields to consider?,,,Yes
27416,Save plot of losses to png file  TODO: should check what that looks like,,Yes,Yes
27417,TODO: may want to enhance this,,No,Yes
27418,Save plot of losses to png file  TODO: should check what that looks like,,,Yes
27420,statistics needed during saving of the best model.,,No,Yes
27421,Move on to next episode.,,Yes,Yes
27422,Check visualization flag - turn on visualization for last validation if needed.,,,Yes
27423,TODO: move this step in validation() and handle using more than 1 batch for validation.,,Yes,Yes
27424,TODO: move this step in validation() and handle using more than 1 batch for validation.,,Yes,Yes
27425,Check visualization flag - turn on visualization for last validation if needed.,,,Yes
27426,TODO: move this step in validation() and handle using more than 1 batch for validation.,,Yes,Yes
27428,statistics needed during saving of the best model.,,No,Yes
27429,Check visualization flag - turn on visualization for last validation if needed.,,Yes,Yes
27432,statistics needed during saving of the best model.,,,Yes
27433,todo: is this needed?,,No,Yes
27434,high memory usage. todo: how to systematically prevent this?,,,Yes
27436,We still save the model as it may perform better during this episode,,Yes,Yes
27437,statistics needed during saving of the best model.,,No,Yes
27438,TODO: move this step in validation() and handle using more than 1 batch for validation.,,,Yes
27439,We still save the model as it may perform better during this epoch,,Yes,Yes
27440,statistics needed during saving of the best model.,,,Yes
27442,We still save the model as it may perform better during this episode,,,Yes
27444,todo: is this needed?,,,Yes
27447,TODO: move this step in validation() and handle using more than 1 batch for validation.,,Yes,Yes
27448,We still save the model as it may perform better during this epoch,,Yes,Yes
27450,We still save the model as it may perform better during this episode,,Yes,Yes
27451,statistics needed during saving of the best model.,,,Yes
27452,We still save the model as it may perform better during this epoch,,Yes,Yes
27454,todo: is this needed?,,No,Yes
27455,Check visualization flag - turn on visualization for last validation if needed.,,,Yes
27458,perform 2-way handshake between Model and Problem,,,Yes
27459,Move on to next episode.,,Yes,Yes
27466,Move on to next episode.,,Yes,Yes
27467,Check visualization flag - turn on visualization for last validation if needed.,,Yes,Yes
27468,More channels - move channels to axis2,,,Yes
27469,io.open is needed for projects that support Python 2.7,,No,Yes
27470,You can just specify package directories manually here if your project is,,Yes,Yes
27471,needed for nltk.word.tokenize,,No,Yes
27472,TODO: check,,No,Yes
27473,"\""Move on\"" to the next episode.",,,Yes
27475,'b' is needed because we want to seek from the end. Text files,,Yes,Yes
27476,Unused.,,Yes,Yes
27480,Implement a data_dict.pop later.,,No,Yes
27486,\t\t\tMight still blow up. Perhaps memory should be resized for each batch.,,Yes,Yes
27487,For compatibility. TODO: remove return,,No,Yes
27489,needed for nltk.word.tokenize,,No,Yes
27490,TODO: linear(2*self.dim; self.dim; bias=True) ?,,Yes,Yes
27492,TODO: check,,,Yes
27494,TODO: INVESTIGATE THAT!!,,No,Yes
27496,needed for nltk.word.tokenize,,No,Yes
27497,TODO: linear(2*self.dim; self.dim; bias=True) ?,,Yes,Yes
27500,needed for nltk.word.tokenize,,No,Yes
27501,needed for nltk.word.tokenize - do it once!,,,Yes
27505,TODO ecrire le nombre de classes des donnees de ref dans un fichier txt.,,Yes,Yes
27506,Save the model if it has a better MIoU score.,,No,Yes
27507,TODO - Verifier que la bande predict est en position 0 sur le tensor.,,,Yes
27508,Loading array is much more efficient than images.,,Yes,Yes
27509,TODO: might be worth it to calculate it every n batches and then average values...,,Yes,Yes
27510,TODO: BUG. tqdm's second loop printing on multiple lines.,,Yes,Yes
27513,TODO Should output directory hold same name as config file name?,,,Yes
27517,FIXME create directories if don't exist,,,Yes
27519,TODO overwrite existing log?,,,Yes
27522,TODO use Path from pathlib instead?,,Yes,Yes
27523,TODO overwrite existing log?,,Yes,Yes
27524,FIXME if some memory is used on a GPU before call to this function; the GPU will be excluded.,,Yes,Yes
27525,note: this is a pretty 'dumb' way to add coord maps to a model; as it will add them everywhere; even,,,Yes
27526,assume background is implicitly needed (makes no sense to train with one class otherwise),,No,Yes
27527,opencv becomes a project dependency only if we need to compute distance maps here,,Yes,Yes
27531,TODO: validate this is preferred name structure,,Yes,Yes
27532,TODO: refactor as independent function,,,Yes
27535,FIXME: could this assert be done before getting into this big for loop?,,,Yes
27536,FIXME: This operation need to be optimized. Using a lot of RAM on large images.,,Yes,Yes
27539,list of GPU devices that are available and unused. If no GPUs; returns empty list,,,Yes
27540,FIXME: what if .tif is in caps (.TIF) ?,,No,Yes
27541,FIXME: why don't we load from checkpoint in classification?,,,Yes
27542,FIXME: this error happens with CrossEntropy: https:\/\/discuss.pytorch.org\/t\/is-there-anybody-happen-this-error\/17416,,No,Yes
27543,FIXME assert that f is a file,,,Yes
27544,TODO: why are we showing indices [1:-1] for lst_device_ids?,,Yes,Yes
27545,FIXME: For HPC when device 0 not available. Error: Invalid device id (in torch\/cuda\/__init__.py).,,,Yes
27547,+ 1 for background # FIXME temporary patch for num_classes problem.,,,Yes
27548,FIXME: preferred name structure? document!,,Yes,Yes
27549,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27551,FIXME: For HPC when device 0 not available. Error: Invalid device id (in torch\/cuda\/__init__.py).,,No,Yes
27553,opencv becomes a project dependency only if we need to compute distance maps here,,,Yes
27559,TODO: since list of classes are only useful for naming each heatmap; this list could be inside the heatmaps_dict; e.g. {1: {heatmap: perclass_output_PIL; class_name: 'roads'}; ...},,Yes,Yes
27561,FIXME: think this through. User will have to calculate the total number of bands including meta layers and,,Yes,Yes
27563,FIXME: could this assert be done before getting into this big for loop?,,Yes,Yes
27565,FIXME: think this through. User will have to calculate the total number of bands including meta layers and,,,Yes
27567,FIXME: could this assert be done before getting into this big for loop?,,Yes,Yes
27569,FIXME: pixel_classes dict needs to be populated with classes obtained from target,,No,Yes
27570,TODO: create a way to choose the good connection depending of the `qqch`,,Yes,Yes
27571,depth = np.random.uniform(low=-1; high=1; size=(64; 1; 7; 7)) # TODO: Talk with the team if we add noise or not,,,Yes
27573,depth = np.random.uniform(low=-1; high=1; size=(64; 1; 7; 7)) # TODO: Talk with the team if we add noise or not,,Yes,Yes
27577,Init NIR   TODO: make a proper way to read the NIR channel,,Yes,Yes
27578,TODO: change to print the place where we concatenate,,Yes,Yes
27579,TODO: need to put back up,,No,Yes
27580,TODO: change to load only the part that we want,,No,Yes
27582,TODO: or change it to match the reste of the implementation,,,Yes
27586,TODO: change to load only the part that we want,,,Yes
27588,TODO: NIR modification,,,Yes
27589,TODO: change the rest to fit the others entries,,,Yes
27591,TODO: conv 1x1 need to match the enter of the bn1,,,Yes
27596,TODO: rename this function?,,,Yes
27597,TODO: what if we want to append samples to existing hdf5?,,,Yes
27599,TODO: is this still valid?,,,Yes
27601,TODO: move as new function in utils.verifications,,Yes,Yes
27608,TODO: what to do with overlap in samples_prep (images_to_samples; l.106)? overlap doesn't need to be larger than; say; 5%,,No,Yes
27610,FIXME temporary patch for num_classes problem.,,No,Yes
27611,FIXME: think this through. User will have to calculate the total number of bands including meta layers and,,,Yes
27612,specify it in yaml. Is this the best approach? What if metalayers are added on the fly ?,,,Yes
27616,TODO: See what to do with it,,,Yes
27619,TODO: change for conc_point 9 after aspp,,Yes,Yes
27620,TODO: something if deep 9,,No,Yes
27625,FIXME: won't check if folder has datetime suffix (if multiple folders),,,Yes
27626,TODO: or change it to match the reste of the implementation,,,Yes
27629,TODO: or change it to match the reste of the implementation,,,Yes
27635,TODO: is this still valid?,,,Yes
27637,TODO: move as new function in utils.verifications,,Yes,Yes
27643,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,,Yes
27645,TODO: pathlib,,Yes,Yes
27646,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,Yes,Yes
27647,FIXME: need to match the number of channel enter in the yaml,,No,Yes
27648,TODO: remove after the merge of Remy branch with no visualization option,,Yes,Yes
27651,FIXME combine pad and pad_diff into one function,,,Yes
27653,TODO: Add verifications?,,No,Yes
27655,TODO: Temporary fix; need to be discuss; `in_tensor` is a list if the initial input as NIR with the RGB at [0].,,Yes,Yes
27656,Init NIR   TODO: make a proper way to read the NIR channel,,Yes,Yes
27657,TODO: This operation need to be optimized. Using a lot of RAM on large images.,,,Yes
27658,TODO: pathlib,,Yes,Yes
27661,TODO: move as new function in utils.verifications,,Yes,Yes
27662,TODO: Temporary fix; need to be discuss; `input_` is a list if the initial input as NIR with the RGB at [0].,,,Yes
27664,FIXME: need to match the number of channel enter in the yaml,,No,Yes
27665,TODO: remove after the merge of Remy branch with no visualization option,,Yes,Yes
27668,TODO: save histogram to metadata; then use it at radiometric trimming; if chosen.,,,Yes
27669,Init NIR   TODO: make a proper way to read the NIR channel,,Yes,Yes
27671,TODO: why don't we load from checkpoint in classification?,,,Yes
27674,FIXME: Following statements should be reconsidered to better manage inconsistencies between,,Yes,Yes
27677,FIXME assert that f is a file,,,Yes
27678,TODO: why are we showing indices [1:-1] for lst_device_ids?,,Yes,Yes
27679,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,Yes,Yes
27680,FIXME: won't check if folder has datetime suffix (if multiple folders),,No,Yes
27681,TODO: why are we showing indices [1:-1] for lst_device_ids?,,Yes,Yes
27684,TODO: or change it to match the reste of the implementation,,Yes,Yes
27685,Limit of the NIR implementation TODO: Update after each version,,,Yes
27688,import cv2 as cv  # opencv becomes a project dependency only if we need to compute distance maps here,,Yes,Yes
27691,TODO: For HPC when device 0 not available.,,Yes,Yes
27694,TODO: what to do with overlap in samples_prep (images_to_samples; l.106)?,,,Yes
27696,assume background is implicitly needed (makes no sense to predict with one class; for example.),,,Yes
27698,specify it in yaml. Is this the best approach? What if metalayers are added on the fly ?,,No,Yes
27701,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27705,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,,Yes
27706,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27709,TODO: add possibility of our own weights,,Yes,Yes
27710,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27712,FIXME: won't check if folder has datetime suffix (if multiple folders),,,Yes
27713,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27716,TODO: why are we showing indices [1:-1] for lst_device_ids?,,Yes,Yes
27717,FIXME: won't check if folder has datetime suffix (if multiple folders),,No,Yes
27718,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27720,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,Yes,Yes
27721,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27722,TODO: why are we showing indices [1:-1] for lst_device_ids?,,,Yes
27723,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27724,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27725,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27726,TODO: transform the aug.compose_transforms in a class with radiom; geom; totensor in def,,Yes,Yes
27727,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27728,TODO: why are we showing indices [1:-1] for lst_device_ids?,,,Yes
27729,FIXME: won't check if folder has datetime suffix (if multiple folders),,,Yes
27730,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,,Yes
27731,# list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27732,list of GPU devices that are available and unused. If no GPUs; returns empty list,,Yes,Yes
27733,FIXME combine pad and pad_diff into one function,,Yes,Yes
27736,Move existing data folder with a random suffix.,,Yes,Yes
27739,Move existing data folder with a random suffix.,,Yes,Yes
27740,TODO: lock decorator,,,Yes
27742,TODO: set autoscaling group properly,,No,Yes
27744,TODO(sergio): move to this code to the instance,,,Yes
27745,TODO: Implement this,,Yes,Yes
27746,the easiest way to code it; as passing a datetime time object to the,,No,Yes
27747,We know better now,,No,Yes
27748,to execute the pending closure if needed.,,Yes,Yes
27749,TODO: delete this once people update their CLI,,Yes,Yes
27750,TODO: move this exception to the controller module,,Yes,Yes
27751,TODO: can this still happen?,,,Yes
27752,TODO: The warning message was the mechanism before serverless,,,Yes
27753,TODO: do not return anything; it's always what we've got back,,Yes,Yes
27754,TODO: For backwards compatibility; remove when we adapted the CLI,,,Yes
27755,TODO: For backwards compatibility; remove when we adapted the CLI,,,Yes
27756,TODO: For backwards compatibility; remove when we adapted the CLI,,,Yes
27758,TODO: change to builds,,,Yes
27761,TODO: delete this once people update their CLI,,,Yes
27766,TODO: FIXME!,,No,Yes
27769,meta_feats = ArrayField(pw.CharField; default=[]) # TODO why?,,Yes,Yes
27770,TODO: this is messy,,Yes,Yes
27776,TODO pass in user somehow,,Yes,Yes
27779,TODO Delete corresponding file upon deleting row,,Yes,Yes
27781,TODO how to communicate to user that task failed?,,Yes,Yes
27782,TODO replace 'trace {i}' with class labels,,Yes,Yes
27783,TODO where do these belong? new module? here? inline above?,,,Yes
27785,TODO pass in executor or make class method?,,,Yes
27790,TODO: Capture --debug flag,,Yes,Yes
27792,TODO: handle config files by parsing sys.argv,,Yes,Yes
27794,TODO fix hyphenation\t,,Yes,Yes
27797,remove ugly hyphenthation,,Yes,Yes
27806,TODO remove after dev,,,Yes
27813,TODO split tree,,Yes,Yes
27814,TODO split tree,,Yes,Yes
27815,TODO finish,,,Yes
27816,TODO finish,,,Yes
27817,TODO Add syntax and db,,Yes,Yes
27819,TODO,,,Yes
27821,TODO upon old period?,,Yes,Yes
27822,TODO Add syntax and db,,,Yes
27823,TODO update link state,,No,Yes
27825,Children Lookup (needed for nesting),,,Yes
27826,XXX NOT FIXED YET,,,Yes
27827,Other issues (simple heurestic needs work finds around half),,No,Yes
27829,"\""\""\"" || This script retrains Graffitist quantized networks on ImageNet (ILSVRC2012) || training set (1.2M images) using native TF and a single worker (GPU). The  || training method (ALT) is based on the paper: ||  || \""Trained Uniform Quantization for Accurate and Efficient || Neural Network Inference on Fixed-Point Hardware\"" || https:\/\/arxiv.org\/pdf\/1903.08066.pdf ||  || Appropriate preprocessing is applied. Expects data to reside as TF-Records || generated from raw data using this script: || https:\/\/github.com\/tensorflow\/models\/blob\/r1.12.0\/research\/slim\/datasets\/build_imagenet_data.py ||  || @ author: Sambhav Jain || \""\""\""",,Yes,Yes
27832,to match with the predictions. This is not needed with,,,Yes
27835,TODO: implement a stop when the pool is empty,,Yes,Yes
27836,TODO,,Yes,Yes
27837,TODO: save results.,,,Yes
27839,maybe improved later,,No,Yes
27842,unparseable. Maybe git-describe is misbehaving?,,,Yes
27844,Could be merged with _stop_iter someday.,,Yes,Yes
27845,word index hack. see issue,,Yes,Yes
27846,TODO{qubixes}: implement validation strategy,,,Yes
27848,todo: Fail without git?,,Yes,Yes
27852,todo: Fail without git?,,Yes,Yes
27853,Number of copies needed.,,,Yes
27854,TODO,,,Yes
27855,simulation. There is a tricky hack required to get the correct row,,Yes,Yes
27856,map columns on column specification,,,Yes
27858,TODO: read index name from configuration,,,Yes
27860,TODO: Check this.,,No,Yes
27863,TODO should convert the documents to a corpus object,,,Yes
27865,TODO: and others,,,Yes
27869,not configured; so assume it's not needed,,,Yes
27870,TODO: Or should ensemble mtime be None if any mtime of sources is None?,,,Yes
27871,TODO Should mtime of Maui project always be None or how to get it?,,,Yes
27872,TODO: Should ensemble mtime be None if mtime of any source is None?,,Yes,Yes
27873,apparently the datadir was created by another thread!,,,Yes
27874,model metadata needed for serialization\/deserialization,,,Yes
27875,Temporary fix for pytorch #2830 & #1442 while pull request #3658 in not incorporated in a release,,No,Yes
27876,TODO : remove when a new release of pytorch include pull request #3658,,No,Yes
27879,The crabs data frame has 200 rows and 8 columns; describing 5 morphological measurements on 50 crabs each of two colour forms and both sexes; of the species Leptograpsus variegatus collected at Fremantle; W. Australia.,,Yes,Yes
27880,max_len = 0; unused variable,,,Yes
27882,TODO path points to directory,,Yes,Yes
27884,TODO error on two nodes,,Yes,Yes
27885,TODO problem when zero,,Yes,Yes
27886,Maybe scale delta_idf to only positive values (for Naive Bayes; etc) ?,,,Yes
27891,Resolving needed deps for this scenario,,,Yes
27893,Record solutions if needed,,,Yes
27896,removing pruning experiment entry if needed,,Yes,Yes
27897,Draw reactions; if needed,,Yes,Yes
27903,Hack,,,Yes
27904,Checking if new solution and record user if needed,,Yes,Yes
27905,Hack,,,Yes
27908,Get info about lib if needed,,No,Yes
27910,return json instead of html in show (needed for CK AI API),,,Yes
27912,pyplot.plot(normalized_df[normalized_df.columns[-1]]; label='real'),,,Yes
27913,Holtwinters workaround; must to solve,,Yes,Yes
27914,XXX this is not immune to a race condition.,,,Yes
27916,TODO: how to allow extra packages? pip packages?,,Yes,Yes
27917,TODO: implement.,,Yes,Yes
27921,TODO: remove env_name\/env_name.,,,Yes
27924,TODO: remove this hack!,,,Yes
27925,TODO: ensure the config matches the cluster spec.,,Yes,Yes
27927,TODO: experiment name?,,Yes,Yes
27928,TODO,,,Yes
27930,TODO: use internal PyPI for CPU-optimized TF.,,Yes,Yes
27932,TODO: use event queue instead?,,,Yes
27933,TODO: report per-container status via KV.,,Yes,Yes
27936,XXX this is Criteo-specific. Remove once Lake updates the container,,Yes,Yes
27938,TODO: report per-container status via KV.,,,Yes
27943,XXX the fs.defaultFS part is to make the examples work inside,,,Yes
27944,TODO: experiment name?,,Yes,Yes
27945,XXX this is Criteo-specific. Remove once Lake updates the,,Yes,Yes
27947,TODO: use internal PyPI for CPU-optimized TF.,,Yes,Yes
27948,TODO: log status on each tick?,,Yes,Yes
27951,Append more arguments if needed.,,Yes,Yes
27952,TODO maybe a better way to import this?,,,Yes
27955,TODO maybe a better way to do this?,,No,Yes
27957,TODO: Consider replacing with tf.contrib.filter_variables in,,Yes,Yes
27958,We only have 2; so add an unused dimension of size one at the back.,,,Yes
27960,once we refactor Faster RCNN models to set is_training through an outer,,,Yes
27963,TODO(rathodv): delete unused `use_display_name` argument once we change,,Yes,Yes
27964,A dictionary of metric names to classes that implement the metric. The classes,,Yes,Yes
27966,TODO(b\/65130867): Use image_id tensor once we fix the input data,,,Yes
27968,Unused.,,Yes,Yes
27969,Mul. In either case; these min\/max vars are not needed once replaced with,,,Yes
27972,"\""\""\""Argmax matcher implementation. ||  || This class takes a similarity matrix and matches columns to rows based on the || maximum value per column. One can specify matched_thresholds and || to prevent columns from matching to rows (generally resulting in a negative || training example) and unmatched_theshold to ignore the match (generally || resulting in neither a positive or negative training example). ||  || This matcher is used in Fast(er)-RCNN. ||  || Note: matchers are used in TargetAssigners. There is a create_target_assigner || factory function for popular implementations. || \""\""\""",,Yes,Yes
27975,unused. Respect that directive in the future.,,No,Yes
27976,Needed for fine-tuning from classification checkpoints whose,,,Yes
27977,TODO(chensun): Figure out if it is needed when image,,,Yes
27978,TODO(rathodv): Come up with a better way to generate scope names,,,Yes
27983,Resize and crop if needed.,,No,Yes
27984,got a response; move on,,Yes,Yes
27988,-- Options for todo extension ----------------------------------------------,,Yes,Yes
27989,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
27992,FIXME tid;sid\u306B\u3064\u3044\u3066v4.1\u3068\u540C\u3058\u554F\u984C\u304C\u3042\u308B,,Yes,Yes
27994,TODO,,,Yes
27995,TODO,,,Yes
27998,resolution of XXX,,Yes,Yes
27999,propagate area\/amount >of XXX,,,Yes
28001,propagate no <neg x >of XXX,,Yes,Yes
28002,propagate without <case x >of XXX,,Yes,Yes
28007,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
28008,"\""\""\"" || Split text into sentences ||  || Usage: ||     ssplit [options] --out=DIRECTORY SOURCE ... ||  || Options: ||     --newline_is_sentence_break     Whether to treat newlines as sentence breaks. True means that a newline is always a ||                                     sentence break. False means to ignore newlines for the purpose of sentence ||                                     splitting. This is appropriate for continuous text; when just the non-whitespace ||                                     characters should be used to determine sentence breaks. [default=False] || \""\""\""",,No,Yes
28009,"\""\""\""\r || Detect negative and uncertain findings from SOURCE and output to DEST\r || Example: python negbio\/main_chexpert.py --output=examples\/test.neg.xml examples\/1.txt examples\/2.txt\r ||          python negbio\/main_chexpert.py --skip-to-bioc --output=examples\/test.neg.xml examples\/1.xml\r || \r || Usage:\r ||     main_chexpert text [options] --output=DEST SOURCES ...\r ||     main_chexpert bioc [options] --output=DEST SOURCE\r || \r || Options:\r ||     --mention_phrases_dir=<directory>           Directory containing mention phrases for each observation.\r ||                                                 [default: negbio\/chexpert\/phrases\/mention]\r ||     --unmention_phrases_dir=<directory>         Directory containing unmention phrases  for each observation.\r ||                                                 [default: negbio\/chexpert\/phrases\/unmention]\r ||     --neg-patterns=FILE                         Negation rules [default: negbio\/chexpert\/patterns\/negation.txt]\r ||     --pre-negation-uncertainty-patterns=FILE    Pre negation uncertainty rules\r ||                                                 [default: negbio\/chexpert\/patterns\/pre_negation_uncertainty.txt]\r ||     --post-negation-uncertainty-patterns=FILE   Post negation uncertainty rules\r ||                                                 [default: negbio\/chexpert\/patterns\/post_negation_uncertainty.txt]\r ||     --bllip-model=MODEL_DIR                     Bllip parser model directory\r ||                                                 [default: ~\/.local\/share\/bllipparser\/GENIA+PubMed]\r ||     --split-document                            Split document into passages based on section titles such as \""Finding\"";\r ||                                                 \""Impression\""\r ||     --newline_is_sentence_break                 Whether to treat newlines as sentence breaks. True means that a newline\r ||                                                 is always a sentence break. False means to ignore newlines for the\r ||                                                 purpose of sentence splitting. This is appropriate for continuous text;\r ||                                                 when just the non-whitespace characters should be used to determine\r ||                                                 sentence breaks.\r ||     --verbose                                   Print more information about progress.\r || \""\""\""",,No,Yes
28016,TODO(albert): logger should fully implement output stream.,,,Yes
28017,TODO: maybe raise an exception here if status code isn't 200?,,Yes,Yes
28018,if we've gotten a decoder error; the calling code better know how,,,Yes
28020,TODO(albert): ask Soumya why join is used,,,Yes
28023,Previous prompt ends when PS1 or a blank line occurs,,Yes,Yes
28027,TODO(albert): move this to AnalyticsProtocol,,,Yes
28028,Previous prompt ends when PS1 or a blank line occurs,,Yes,Yes
28032,A hack that allows programmatic API users to plumb a custom,,,Yes
28034,TODO : Catch just SSL errors,,Yes,Yes
28035,"print(\""\ ||  Unqiue ID ends\"")",,,Yes
28036,TODO: needs the student's email to work,,No,Yes
28037,TODO: Handle cases when no questions are specified,,Yes,Yes
28038,Hack for windows:,,,Yes
28039,TODO : Catch just SSL errors,,Yes,Yes
28040,TODO: Ensure we're handling redirects.  Might also stick the 'origin',,Yes,Yes
28042,A hack that allows programmatic API users to plumb a custom,,Yes,Yes
28045,Secure Storage #  TODO: refactor persistance to one centralized location,,,Yes
28046,TODO: Use wrapper_weights (okay for now because idxmap only),,Yes,Yes
28047,TODO: non-string args!,,,Yes
28049,TODO: Hardcoded reserved ids!,,No,Yes
28050,fs439: fix embeddings?,,No,Yes
28051,"\""\""\""Encoder-Decoder with search for machine translation. ||  || In this demo; encoder-decoder architecture with attention mechanism is used for || machine translation. The attention mechanism is implemented according to || [BCB]_. The training data used is WMT15 Czech to English corpus; which you have || to download; preprocess and put to your 'datadir' in the config file. Note || that; you can use `prepare_data.py` script to download and apply all the || preprocessing steps needed automatically.  Please see `prepare_data.py` for || further options of preprocessing. ||  || .. [BCB] Dzmitry Bahdanau; Kyunghyun Cho and Yoshua Bengio. Neural ||    Machine Translation by Jointly Learning to Align and Translate. || \""\""\""",,Yes,Yes
28052,TODO: this is problematic for boundary conditions; eg. last batch,,,Yes
28053,TODO: a lot has been changed in NMT; sync respectively,,Yes,Yes
28055,"\""\""\""\""This script starts training an NMT system with blocks. This largely || follows the NMT blocks 0.1 example except the following points: ||  || - This implementation supports reshuffling between training epochs || - We introduce the --fix_embeddings parameter for fixing word  ||   embeddings in later training stages. || - The BleuValidator in the standard blocks implementation evaluates  ||   with the <\/S> symbol. We remove <\/S> before passing through to the  ||   BLEU evaluation script. || - We use reserved indices which are more compatible to the syntactical ||   MT system HiFST: 0: UNK\/eps; 1: <S>; 2: <\/S> || - The --bleu_script parameter supports the %s placeholder. This makes ||   it possible to use alternative BLEU scripts for model selection; e.g. ||   Moses' mteval_v13a.pl. || - Blocks changed the BRICK_DELIMITER variable at some point from '-' to ||   '\/'. This causes problems when trying to load old model files. ||   Therefore; we keep using the '-' character in our model files. || - The NMT implementation in blocks had a bug in creating checkpoint ||   files ||     https:\/\/github.com\/mila-udem\/blocks-examples\/issues\/97 ||     https:\/\/github.com\/mila-udem\/blocks-examples\/issues\/72 ||   Therefore; we modified the code similarly to #72 to fix this || - Dropout fix https:\/\/github.com\/mila-udem\/blocks-examples\/issues\/46 ||  || This module contains modified code directly taken from  || blocks-examples\/machine_translation. || \""\""\""",,Yes,Yes
28059,TODO: save one deepcopy (in last iteration),,,Yes
28060,"\""\""\""This is the only module outside the ``blocks`` package with || dependency on the Blocks framework. It contains the neural machine || translation predictor nmt. Code is partially taken from the neural || machine translation example in blocks. ||  || https:\/\/github.com\/mila-udem\/blocks-examples\/tree\/master\/machine_translation ||  || Note that using this predictor slows down decoding compared to the || original NMT decoding because search cannot be parallelized. However; || it is much more flexible as it can be combined with other predictors. || \""\""\""",,,Yes
28062,Apply dropout for regularization (TODO: remove?),,,Yes
28063,Apply weight noise for regularization (TODO: remove?),,Yes,Yes
28066,Empty this entry; not needed anymore,,Yes,Yes
28067,"\""\""\""This file contains common basic functionality which can be used from || anywhere. This includes the definition of reserved word indices; some || mathematical functions; and helper functions to deal with the small || quirks python sometimes has. || \""\""\""",,,Yes
28068,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
28069,"\""\""\""This is the main SGNMT package. It contains the packages ||  ||  * ``blocks``: Code with dependency on the blocks framework ||  * ``decoding``: Interfaces and implementations of decoding strategies ||  * ``predictors``: Scoring modules ||  || Direct modules are: ||  ||  * ``io``: Contains I\/O related code such as output handlers ||  * ``utils``: Common helper functions and global constants ||   || \""\""\""",,,Yes
28071,TODO: Update to use OpenFST instead of PyFST,,,Yes
28072,Make sure that it ends with EOS,,No,Yes
28073,"\""\""\""This package contains neural alignment models. Modules in this || package should implement a method ``align_with_*`` which serves as the || entry point to the module and can be called from ``align.py``.  || \""\""\""",,,Yes
28074,"\""\""\""This module is derived from the ``sampling`` module in the Blocks || NMT example; but reduced to providing functionality for model selection || according the BLEU score on the dev set. || \""\""\""",,,Yes
28076,TODO: Should be in conf,,Yes,Yes
28077,Pickle hack,,,Yes
28078,fs439: TODO works only if len(rest_shape) == 1,,,Yes
28080,TODO: Use wrapper_weights,,Yes,Yes
28082,TODO: save one deepcopy (in last iteration),,Yes,Yes
28084,TODO Marcin: add all chainer imports here,,Yes,Yes
28088,TODO Marcin: E.g.; if you feed the previous output as new input to the,,,Yes
28089,TODO Marcin: Return LSTM hidden state,,No,Yes
28090,TODO Marcin: Set the LSTM hidden state,,Yes,Yes
28092,fs439: Fix embeddings when training,,No,Yes
28093,"\""\""\""This message type is used by the decoder when a new complete  || hypothesis was found. Note that this is not necessarily the best hypo || so far; it is just the latest hypo found which ends with EOS. || \""\""\""",,,Yes
28095,TODO: Insert some TensorFlow specific imports here,,Yes,Yes
28096,fs439: Fix embeddings when training,,No,Yes
28097,TODO: add to config,,,Yes
28098,TODO: Add to config,,,Yes
28101,The following hack is necessary to prevent the problem from creating,,,Yes
28102,TODO: Use wrapper_weights,,Yes,Yes
28103,The following hack is necessary to prevent the problem from creating,,Yes,Yes
28104,The following hack is necessary to prevent the problem from creating,,Yes,Yes
28106,hacky way of making sure we've seen all non-terminals; ideally this would be independent of wmap ordering,,Yes,Yes
28107,TODO: Could be more efficient by checking is_sublist for,,Yes,Yes
28109,TODO implement,,Yes,Yes
28111,The following hack is necessary to prevent the problem from creating,,,Yes
28113,search until we have n terminal hypos with path scores better,,Yes,Yes
28115,This is the TF backend needed for MoE interpolation,,No,Yes
28116,TODO: Clean this up and make a blocks and tfnmt predictor,,Yes,Yes
28117,self._min_length_ratio = 0.25  # TODO: Make configurable,,Yes,Yes
28118,TODO: Make configurable. Default disabled,,Yes,Yes
28119,hack for python2\/3 compatibility,,Yes,Yes
28120,hack for python2\/3 compatibility,,,Yes
28121,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. || This is an (inefficient) toy implementation that shows the algorithm. For processing large datasets; || indexing and incremental updates can be used to speed up the implementation (see learn_bpe.py). ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,,Yes
28123,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,No,Yes
28124,hack for python2\/3 compatibility,,Yes,Yes
28125,we probably missed the best pair because of pruning; go back to full statistics,,No,Yes
28127,hack for python2\/3 compatibility,,,Yes
28129,TODO: Add data type; key; partial key; comment? etc.,,Yes,Yes
28132,TODO: Import db to proper db (sqlite; etc),,Yes,Yes
28133,rels are case-insensitive and the convention is lower-case,,Yes,Yes
28134,TODO: Consider removing this and making EPs immutable,,,Yes
28135,TODO: log failure,,Yes,Yes
28139,TODO: should there be only 1 link? Can there be more than 1 head?,,No,Yes
28140,FIXME hack to get it working (if tgtep...),,Yes,Yes
28142,TODO: consider removing properties,,Yes,Yes
28144,TODO: log this or something,,Yes,Yes
28146,TODO: log failure,,,Yes
28148,FIXME: currently gets CVARSORT even if the var is not a CV,,,Yes
28149,TODO: the following shouldn't throw warnings.. the code should,,,Yes
28153,FIXME: this is an awful way to do it.. is there a better way?,,Yes,Yes
28154,FIXME: consider buffering this so we don't read the whole string at once,,Yes,Yes
28155,"\""\""\"" || The MRS package of pyDelphin contains classes and methods related to || Minimal Recursion Semantics (Copestake et al. 2005). A large part of || this package is an object-oriented class system for encapsulating || information relevant to MRS; such as for |ElementaryPredication| and || |HandleConstraint|. It also contains classes for other varieties of || Minimal Recursion Semantics; such as |Node| and |Link| for DMRS. ||  || As this package is capable of handling different varieties of Minimal || Recursion Semantics; I adopt the convention of referring to the greater || formalism as XMRS (an ascii-friendly version of \\*MRS); so MRS then || refers to the original formalism. Following this convention; the main || class in this package is |Xmrs|; which is a supertype of MRS; RMRS || (planned); and DMRS. ||  || While you can certainly construct XMRS structures programmatically; most || often you will be using a serialization format (e.g. the XML formats or || SimpleMRS) to read structures from stored representations; and the || codecs to read and write such representations can be found in || :py:mod:`delphin.codecs`. || \""\""\""",,,Yes
28156,TODO: allow for multiple configs in same directory (e.g. (PID).rcfile),,,Yes
28157,this is a hack; though perhaps well-motivated,,Yes,Yes
28158,# TODO: check if there are labels?,,No,Yes
28162,FIXME: I don't have a clear answer about how LTOP links are,,,Yes
28163,keep them as a list (fixme: why not just get sets?),,Yes,Yes
28164,keep them as a list (fixme: why not just get sets?),,,Yes
28166,put it back together (maybe shouldn'ta broke it),,,Yes
28168,if nid in paths: continue  # maybe already visited in _find_paths,,No,Yes
28169,FIXME this is not done,,,Yes
28170,FIXME this is not done,,Yes,Yes
28173,order. Maybe this isn't a big deal?,,Yes,Yes
28174,continue  # maybe log this,,,Yes
28175,maybe some bad MRS with a lonely quantifier,,Yes,Yes
28176,FIXME: I don't have a clear answer about how LTOP links are,,No,Yes
28177,simplemrs is only used for functions where large MRSs are needed and,,,Yes
28179,and a broken HCONS is ok; too?  (maybe revise later),,Yes,Yes
28180,This is a bit ugly; but it avoids running this again by,,Yes,Yes
28181,Workaround for standalone backslash,,,Yes
28182,FIXME,,Yes,Yes
28184,"label equality; e.g. \""raining happens\"" (TODO: find better example)",,No,Yes
28187,except ValueError as e: # TODO: this,,,Yes
28190,hack for int-converted src\/tgt,,,Yes
28191,TODO: non-blocking io: http:\/\/stackoverflow.com\/a\/4896288\/1441112,,Yes,Yes
28192,TODO: non-blocking io: http:\/\/stackoverflow.com\/a\/4896288\/1441112,,Yes,Yes
28196,TODO 'yield from' may be useful here when Python2.7 is,,No,Yes
28197,TODO: can TDL parsing be repurposed for this variant?,,No,Yes
28201,short-term fix for Python 2,,,Yes
28203,Python2 hack,,Yes,Yes
28208,temporary Python 2 hack,,Yes,Yes
28209,check number of columns?,,,Yes
28210,this is not a great way to improve robustness when converting,,,Yes
28211,networkx 2.2 is not compatible with Python 2.7 (apparently) and 3.5,,Yes,Yes
28212,"\""\""\"" || This module contains classes and methods related to Minimal || Recursion Semantics [MRS]_. In addition to MRS; there are the related || formalisms Elementary Dependency Structures [EDS]_; and Dependency || Minimal Recursion Semantics [DMRS]_.  As a convenience; \\*MRS refers || to the collection of MRS and related formalisms (so \""MRS\"" then refers || to the original formalism); and PyDelphin accordingly defines || :class:`~delphin.mrs.xmrs.Xmrs` as the common subclass for the various || formalisms. ||  || Users will interact mostly with :class:`~delphin.mrs.xmrs.Xmrs` || objects; but will not often instantiate them directly. Instead; they || are created by serializing one of the various formats (such as || :mod:`delphin.mrs.simplemrs`; :mod:`delphin.mrs.mrx`; or || :mod:`delphin.mrs.dmrx`). No matter what serialization format (or || formalism) is used to load a \\*MRS structure; it will be stored the || same way in memory; so any queries or actions taken on these structures || will use the same methods. ||  || .. [MRS] Copestake; Ann; Dan Flickinger; Carl Pollard; ||   and Ivan A. Sag. \""Minimal recursion semantics: An introduction.\"" ||   Research on language and computation 3; no. 2-3 (2005): 281-332. || .. [EDS] Stephan Oepen; Dan Flickinger; Kristina Toutanova; and ||   Christopher D Manning. Lingo Redwoods. Research on Language and ||   Computation; 2(4):575\u2013596; 2004.; ||  ||   Stephan Oepen and Jan Tore L\u00F8nning. Discriminant-based MRS ||   banking. In Proceedings of the 5th International Conference on ||   Language Resources and Evaluation; pages 1250\u20131255; 2006. || .. [DMRS] Copestake; Ann. Slacker Semantics: Why superficiality; ||   dependency and avoidance of commitment can be the right way to go. ||   In Proceedings of the 12th Conference of the European Chapter of ||   the Association for Computational Linguistics; pages 1\u20139. ||   Association for Computational Linguistics; 2009. || \""\""\""",,,Yes
28214,"\""\""\"" || Dependency Minimal Recursion Semantics || \""\""\""",,,Yes
28217,"\""\""\"" || Dependency Minimal Recursion Semantics ([DMRS]_) ||  || .. [DMRS] Copestake; Ann. Slacker Semantics: Why superficiality; ||   dependency and avoidance of commitment can be the right way to go. ||   In Proceedings of the 12th Conference of the European Chapter of ||   the Association for Computational Linguistics; pages 1\u20139. ||   Association for Computational Linguistics; 2009. || \""\""\""",,,Yes
28218,TODO: this should be a DerivationSyntaxError but the current,,,Yes
28220,These two numbers are needed to track if changes to the,,No,Yes
28222,type checking this function is a mess; it needs a better fix,,Yes,Yes
28228,TODO: check if contiguous is really necessary,,No,Yes
28229,trying to fix the memory leak,,Yes,Yes
28230,trying to fix the memory leak,,Yes,Yes
28231,move this to the constructor? Less flexible but faster.,,Yes,Yes
28232,move this to the constructor? Less flexible but faster.,,Yes,Yes
28233,"\""\""\"" || Version of the hyperlayer that learns only over a subset of the columns of the matrix. The rest of the matrix is hardwired. ||  || This can; for instance; be used to create a layer that has 3 incoming connections for each node in the output layer; with || the connections to the input nodes beaing learned. || \""\""\""",,Yes,Yes
28236,TODO: remove inefficiency; by reversing loops,,,Yes
28237,doing this manually; the nx code produces very strange results,,Yes,Yes
28238,TODO double computation,,Yes,Yes
28240,doing this manually; the nx code produces very strange results,,,Yes
28241,compute 'offset': Vector of values in (0; 1) indicating whether points should be moved to the top or bottom half of the,,,Yes
28243,move each point to the top or bottom half of its dyadic interval,,,Yes
28244,compute 'offset': Vector of values in (0; 1) indicating whether points should be moved to the top or bottom half of the,,,Yes
28250,learnable columns,,No,Yes
28251,learnable columns,,No,Yes
28252,learnable columns,,,Yes
28253,This should be more memory efficient,,Yes,Yes
28255,TODO mult by one; this can be removed,,Yes,Yes
28259,TODO: make qt part work in thread,,Yes,Yes
28260,TODO: add check for number of cells here,,Yes,Yes
28262,TODO: add check for number of cells here,,,Yes
28264,"\""\""\""TODO: One-sentence doc string.\""\""\""",,,Yes
28265,ToDo: don't hard,,Yes,Yes
28268,TODO Draw results of multiple recognitions correctly and deal with unknown,,,Yes
28269,TODO: How do we know this?,,No,Yes
28271,Check if needed credentials are provided,,Yes,Yes
28274,TODO (John): _get_types is dropping quotation marks when getting word types;,,,Yes
28275,TODO (John): set max_seq_len empirically.,,Yes,Yes
28276,TODO (johngiorgi): is there a better way to get the dummy_word_types?,,,Yes
28279,TODO (johngiorgi): do something about paths as arguments - normalize?,,Yes,Yes
28281,TODO (johngiorgi): make sure this process is shuffling the data,,Yes,Yes
28282,not needed downsteam of here.,,,Yes
28284,TODO (johngiorgi): make a debug mode that doesnt load token embeddings and loads only some lines of dataset,,,Yes
28285,TODO (johngiorgi) considering organizing these into classes,,,Yes
28286,TODO (johngiorgi): abstract away all dataset details as single object,,Yes,Yes
28289,TODO: (johngiorgi): use the supported datatypes functions for bools: https:\/\/docs.python.org\/3.6\/library\/configparser.html#supported-datatypes,,,Yes
28291,TODO (johngiorgi): clean up the print function,,Yes,Yes
28303,fix this.,,,Yes
28308,TODO (johngiorgi): Setup learning rate decay.,,,Yes
28309,TODO (johngiorgi): make sure this process is shuffling the data,,Yes,Yes
28312,TODO (johngiorgi): predict should be more of an interface; calling it should,,,Yes
28313,TODO (johngiorgi): https:\/\/machinelearningmastery.com\/reshape-input-data-long-short-term-memory-networks-keras\/,,Yes,Yes
28316,super ugly and quick solution; need to clean this up!,,Yes,Yes
28317,super ugly and quick solution; need to clean this up!,,,Yes
28318,TODO (johngiorgi): READ: https:\/\/jeffknupp.com\/blog\/2014\/06\/18\/improve-your-python-python-classes-and-object-oriented-programming\/,,,Yes
28325,TODO (johngiorgi): use proper error handeling for load_ds \/ load_token methods,,Yes,Yes
28326,TODO (johngiorgi): need to make a decison as to whether or not,,,Yes
28330,TODO,,Yes,Yes
28334,TODO: catch any key errors,,,Yes
28335,TODO: (johngiorgi): use the supported datatypes functions for bools: https:\/\/docs.python.org\/3.6\/library\/configparser.html#supported-datatypes,,Yes,Yes
28336,TODO: (johngiorgi): not clear if the post processing is neccecary,,Yes,Yes
28337,TODO: there has to be a simpler way to do this,,,Yes
28339,which is neccecary to implement variational dropout,,,Yes
28343,TODO: Need a way to compare that is order independent.,,,Yes
28344,TODO: this seems like a sub-par solution,,No,Yes
28345,TODO: Need better error handeling here,,,Yes
28346,TODO: ugly; is there a better way to check for this?,,,Yes
28347,TODO: what if diff ds follow diff schemes?,,,Yes
28356,TODO: Some arguments still need help strings written,,Yes,Yes
28358,is not False is needed to prevent the store_true args from overriding the,,,Yes
28360,this is a bit of a hack; but need to simulate providing commands at the command line,,,Yes
28362,-- Options for todo extension ----------------------------------------------,,,Yes
28364,TODO: There has got to be a better way to do this.,,,Yes
28365,TEMP: Weird solution to a weird bug.,,No,Yes
28367,TEMP: this is a hack;,,No,Yes
28368,Load our modified tokenizer; better tokenization of biomedical text,,,Yes
28375,Search fields; result columns; etc; see:,,Yes,Yes
28376,TODO: describe,,No,Yes
28378,fields and columns can be args if we'd like to generalize this module,,Yes,Yes
28379,TODO try with HGNC rest api,,,Yes
28380,fields; columns can be parameters too if we'd generalize later,,Yes,Yes
28381,set output data columns,,Yes,Yes
28382,TODO try with HGNC rest api,,No,Yes
28383,is not False needed to prevent store_true args from overriding corresponding,,Yes,Yes
28386,reorder the columns,,Yes,Yes
28387,sort the columns and rows in the correct order,,,Yes
28389,extract the columns that contain predictions,,,Yes
28390,rename the columns and index in the analysis data frame,,Yes,Yes
28392,make sure that the columns specified in the config file actually exist,,,Yes
28393,check to make sure that the subgroup columns are all present,,,Yes
28394,filter out the responses based on flag columns,,No,Yes
28396,create a dictionary of name mapping for used columns,,,Yes
28397,find the columns where the names match the default names,,,Yes
28401,rename the custom-named columns to default values,,Yes,Yes
28403,get the feature columns,,Yes,Yes
28405,"\""\""\"" || Functions dealing with making predictions ||  || :author: Nitin Madnani (nmadnani@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :organization: ETS || \""\""\""",,,Yes
28407,"\""\""\"" || Functions dealing with report generation. ||  || :author: Nitin Madnani (nmadnani@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :organization: ETS || \""\""\""",,,Yes
28408,"\""\""\"" || Script to compare two RSMTool experiments ||  || :author: Nitin Madnani (nmadnani@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :organization: ETS || \""\""\""",,Yes,Yes
28409,"\""\""\"" || Run evaluation only experiments. ||  || :author: Nitin Madnani (nmadnani@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :organization: ETS || \""\""\""",,Yes,Yes
28410,are we filtering on any other columns?,,Yes,Yes
28411,before computing the metrics; the names for the final columns are,,Yes,Yes
28412,make sure that the columns specified in the config file actually exist,,,Yes
28414,because we want that in the other columns,,,Yes
28415,extract all of the other columns in the predictions file,,,Yes
28416,get the column names for flag columns (if any),,,Yes
28417,make sure that the columns specified in the config file actually exist,,Yes,Yes
28419,rename all columns,,Yes,Yes
28420,ensure that all the features that are needed by the model,,Yes,Yes
28422,convert any integer columns to floats in either data frame,,,Yes
28423,return a matrix of nans if the number of columns is,,No,Yes
28424,get a list of the feature columns,,,Yes
28425,reorder the columns,,,Yes
28427,basic experiment that has extra columns that are,,Yes,Yes
28431,if the name for both columns is `candidate`; we need to,,,Yes
28432,make sure that the columns specified in the config file actually exist,,,Yes
28434,the tool should be using all columns not assigned to,,Yes,Yes
28435,the tool should be using all columns not assigned to,,,Yes
28437,"\""\""\"" || Functions for comparing outputs of two rsmtool experiments. ||  || :author: Nitin Madnani (nmadnani@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :organization: ETS || \""\""\""",,Yes,Yes
28438,use the raw columns or the scale columns depending on the prefix,,,Yes
28441,ensure that all the features that are needed by the model,,Yes,Yes
28442,rsmpredict experiment with missing columns,,,Yes
28444,ensure that all the features that are needed by the model,,,Yes
28446,Test that the function exclude columns where feature value is 'inf',,Yes,Yes
28447,return the columns from the original frame that was passed in,,No,Yes
28449,we want to allow title-cased names of columns for historical reasons,,Yes,Yes
28450,"\""\""\"" || Utility to convert older feature JSON files to || newer feature files in tabular formats (csv\/tsv\/xls\/xlsx). ||  || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) || :organization: ETS || \""\""\""",,Yes,Yes
28451,"\""\""\"" || Utility to convert older feature JSON files in tests || newer feature files in tabular formats (csv\/tsv\/xls\/xlsx). ||  || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) || :organization: ETS || \""\""\""",,,Yes
28453,make sure that the main id columns are read as strings since,,No,Yes
28455,get the population standard deviation that we will need to compute SMD for all columns,,Yes,Yes
28456,reorder the columns to make it look better,,Yes,Yes
28457,reorder the columns,,Yes,Yes
28459,sort the columns and rows in the correct order,,,Yes
28460,get the population standard deviation that we will need to compute SMD for all columns,,,Yes
28461,group by the grouping_variable columns,,No,Yes
28463,rename the columns and index in the analysis data frame,,Yes,Yes
28466,"\""\""\"" || Classes related to parsing configuration files || and creating configuration objects. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,No,Yes
28467,"\""\""\"" || Classes for storing any kind of data contained || in a pd.DataFrame object. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,No,Yes
28468,"\""\""\"" || Class for dealing with training built-in or SKLL models; || as well as making predictions for new data. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,No,Yes
28469,get the columns that actually contain the feature values,,Yes,Yes
28471,we want to allow title-cased names of columns for historical reasons,,,Yes
28472,create a dictionary of name mapping for used columns,,Yes,Yes
28473,find the columns where the names match the default names,,Yes,Yes
28474,find the columns with default names reserved for other columns,,,Yes
28475,rename these columns,,Yes,Yes
28477,rename the custom-named columns to default values,,Yes,Yes
28480,by other methods; if needed.,,Yes,Yes
28484,now extract all other columns and add 'spkitemid',,Yes,Yes
28485,because we want that in the other columns,,,Yes
28486,extract all of the other columns in the predictions file,,Yes,Yes
28487,get the column names for flag columns (if any),,Yes,Yes
28489,rename all columns,,Yes,Yes
28490,add back the columns that we were requested to copy if any,,,Yes
28491,ensure that all the features that are needed by the model,,Yes,Yes
28492,"\""\""\"" || Classes for reading data files (or dictionaries) || and converting them to DataContainer objects. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,,Yes
28493,"\""\""\"" || Classes for dealing with report generation. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,,Yes
28494,"\""\""\"" || Run evaluation only experiments. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,No,Yes
28495,"\""\""\"" || Classes for writing DataContainer || DataFrames to files. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 10\/25\/2017 || :organization: ETS || \""\""\""",,No,Yes
28496,Test that the function exclude columns where std is returned as,,Yes,Yes
28498,using flag columns,,Yes,Yes
28499,basic experiment using rsmpredict with subgroups and other columns,,Yes,Yes
28500,rsmpredict experiment with missing columns,,Yes,Yes
28504,the tool should be using all columns not assigned to,,,Yes
28523,rsmtool experiment with truncations; but no min\/max columns in feature file,,Yes,Yes
28526,"\""\""\"" || Utility classes and functions related to computing fairness evaluations ||  || :author: Anastassia Loukina (aloukina@ets.org) || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :date: 07\/29\/2019 || :organization: ETS || \""\""\""",,No,Yes
28527,let's check if we have nested columns,,Yes,Yes
28530,sort all columns alphabetically,,Yes,Yes
28531,construct the arguments and keyword arguments needed for the,,Yes,Yes
28532,TODO: replace `Path(abspath(new_path))` with `Path(new_path).resolve(),,,Yes
28533,once this Windows bug is fixed: https:\/\/bugs.python.org\/issue38671,,Yes,Yes
28534,construct the arguments and keyword arguments needed for the,,Yes,Yes
28535,TODO: replace `Path(abspath(new_path))` with `Path(new_path).resolve(),,No,Yes
28536,once this Windows bug is fixed: https:\/\/bugs.python.org\/issue38671,,Yes,Yes
28537,construct the arguments and keyword arguments needed for the,,Yes,Yes
28538,construct the arguments and keyword arguments needed for the,,Yes,Yes
28539,construct the arguments and keyword arguments needed for the,,,Yes
28540,"\""\""\"" || Utility classes and functions for converting various types. ||  || :author: Jeremy Biggs (jbiggs@ets.org) || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :organization: ETS || \""\""\""",,No,Yes
28542,"\""\""\"" || Utility classes and functions related to computing test || theory based evaluations. ||  || The derivations and formulas were provided by Matt Johnson. ||  || :author: Anastassia Loukina (aloukina@ets.org) || :author: Nitin Madnani (nmadnani@ets.org) ||  || :organization: ETS || \""\""\""",,Yes,Yes
28543,the name; this is needed for the CI builds where,,Yes,Yes
28544,the name; this is needed for the CI builds where,,Yes,Yes
28548,the name; this is needed for the CI builds where,,Yes,Yes
28549,following workaround,,No,Yes
28550,TODO This needs to be replaced with the logic to obtain namespace out of JWT token,,Yes,Yes
28551,TODO This needs to be replaced with the logic to obtain namespace out of JWT token,,,Yes
28552,TODO This needs to be replaced with the logic to obtain namespace out of JWT token,,Yes,Yes
28554,TODO This needs to be replaced with the logic to obtain namespace out of JWT token,,,Yes
28555,Code needed to support Python 2,,,Yes
28557,naming convention for data parallel,,Yes,Yes
28559,# from flask_wtf.csrf import CSRFProtect,,No,Yes
28561,TODO: make this configurable,,,Yes
28565,TODO: solve this properly,,No,Yes
28566,VERY naive way to detect images...,,,Yes
28567,temporary hack,,,Yes
28568,VERY naive way to detect images...,,Yes,Yes
28571,there's probably a much better way to calculate the next prefix.,,Yes,Yes
28574,TODO: use transaction?,,No,Yes
28575,"\""\""\""Auxiliary function to implement ops.batch_exec in SQL environments.\""\""\""",,,Yes
28578,"\""\""\""Auxiliary function to implement ops.batch_exec in SQL environments.\""\""\""",,No,Yes
28580,TODO: make this more efficient,,Yes,Yes
28581,print('xxx; %s' % entity),,Yes,Yes
28583,TODO: This is very inefficient!,,Yes,Yes
28584,TODO: make this better...,,,Yes
28585,TODO: ugly...,,Yes,Yes
28588,TODO: generalize!,,No,Yes
28589,TODO,,,Yes
28590,TODO: warning ?,,No,Yes
28591,TODO: questions; imperative...,,,Yes
28593,TODO: Pathological case,,,Yes
28594,render it to avoid ugly multi-line staircases when closing,,Yes,Yes
28595,TODO: connect to parent,,Yes,Yes
28596,TODO: make parser type configurable,,,Yes
28597,TODO: error or warning?,,,Yes
28599,TODO: make parser type configurable,,No,Yes
28601,TODO: detect already existing edges in this case,,,Yes
28603,TODO: make concept resolution configurable,,Yes,Yes
28605,''' || Was that move OK? || ''',,,Yes
28606,Implement this method in every subclass,,Yes,Yes
28609,TODO: Use Xtgt.,,No,Yes
28610,TODO: Add a docstring.,,,Yes
28616,TODO: Implement this in C++; and use Boost. This is just a,,Yes,Yes
28618,"\""\""\"" This file defines code for PI2-based trajectory optimization. ||  || Optimization of trajectories with PI2 and a REPS-like KL-divergence constraint.  || References: || [1] E. Theodorou; J. Buchli; and S. Schaal. A generalized path integral control  ||     approach to reinforcement learning. JMLR; 11; 2010. || [2] F. Stulp and O. Sigaud. Path integral policy improvement with covariance  ||     matrix adaptation. In ICML; 2012. || [3] J. Peters; K. Mulling; and Y. Altun. Relative entropy policy search.  ||     In AAAI; 2010. ||  \""\""\""",,Yes,Yes
28619,TODO: allocate this more intelligently,,,Yes
28621,Pretty much copy-paste... Better method?,,,Yes
28625,@todo Do not use this?,,,Yes
28626,Is there a better way to do this by adding a representation with yaml.Dumper?,,No,Yes
28628,@todo Make this work with decorators,,Yes,Yes
28629,@todo rying to insert an element at root level seems to screw up pretty printing,,No,Yes
28630,Better method? Queues?,,,Yes
28631,Better name: element_with_name? Attributed element?,,,Yes
28633,''' || Model of a task as a state machine. We can specify this in any number of || different ways: in CoSTAR; we use a Behavior Tree; PDDL or LTL can give us a  || slightly different task plan. ||  || - add an option with an argument || -  || ''',,Yes,Yes
28634,Hack to use roscpp stuff in python,,,Yes
28635,provide the lfd object containing models; etc.; or we will not properly,,Yes,Yes
28636,provide the lfd object containing models; etc.; or we will not properly,,Yes,Yes
28637,"task.add(\""release1\""; [\""move\""]; __release_args())",,Yes,Yes
28638,Fix rotations,,,Yes
28640,"task.add(\""release1\""; [\""move\""]; __release_args())",,,Yes
28642,Maybe set the Real Time Factor?,,Yes,Yes
28644,"task.add(\""release1\""; [\""move\""]; __release_args())",,Yes,Yes
28645,"task.add(\""release1\""; [\""move\""]; __release_args())",,,Yes
28646,TODO: parse commands,,,Yes
28647,TODO: create backend,,,Yes
28648,a parameter needed for finding appropriate goal states,,,Yes
28649,TODO(ahundt) move depth image creation into tensorflow ops,,,Yes
28650,''' || Model of a task as a state machine. We can specify this in any number of || different ways: in CoSTAR; we use a Behavior Tree; PDDL or LTL can give us a  || slightly different task plan. || ''',,Yes,Yes
28651,TODO: is there a way to output a tuple (6;1),,No,Yes
28653,TODO: find a way to customize network,,Yes,Yes
28654,TODO: fix the hard coded indices,,,Yes
28655,and would probably really help improve things.,,Yes,Yes
28656,we should just quit. This also applies if we somehow blundered into,,Yes,Yes
28659,TODO: handle other stuff,,,Yes
28660,''' || This file defines models that rely just on hand-coded features -- obvious || features that we don't need to worry about so much. || ''',,Yes,Yes
28666,TODO(cpaxton): clean this up in the future; before release.,,Yes,Yes
28667,Experimental hierarchical policy models:,,Yes,Yes
28669,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28674,in the planner progress data table if needed,,,Yes
28678,TODO: fix the hard coded indices,,Yes,Yes
28679,TODO,,,Yes
28682,TODO(ahundt) maybe this needs to be inverted?,,No,Yes
28683,convention where:,,No,Yes
28686,TODO(ahundt) maybe the rotation component of this needs to be inverted due to sva implementation?,,No,Yes
28687,do the conversion needed for training,,No,Yes
28689,qa \/= np.pi KDK: TODO VERIFY,,,Yes
28690,check if K.shape; K.int_shape; or vector.get_shape().as_list()[1:] is better,,Yes,Yes
28691,check if K.shape; K.int_shape; or image.get_shape().as_list()[1:] is better,,Yes,Yes
28693,TODO: add this again,,No,Yes
28695,image frame is done with the convention:,,,Yes
28696,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28697,fixed depth is to help if you're having problems getting your point cloud to display properly,,,Yes
28698,TODO(ahundt) should displaying all clouds be a configurable option?,,,Yes
28699,workaround for V-REP bug where handles may not be correctly deleted,,Yes,Yes
28702,features that are needed for the final time step only,,Yes,Yes
28706,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28708,should be more efficient than the numpy version,,Yes,Yes
28709,TODO: enable this if we need to,,No,Yes
28711,Performance may actually be better with the xyz image,,,Yes
28714,TODO(ahundt) move squeeze steps into dataset api if possible,,,Yes
28716,TODO: re-enable albert code,,,Yes
28717,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28718,maybe need to transpose yx_coordinate?,,,Yes
28721,TODO: add this again,,No,Yes
28722,check if K.shape; K.int_shape; or vector.get_shape().as_list()[1:] is better,,,Yes
28724,TODO: add this again,,,Yes
28725,Warning: hacky workaround to get both fetches and predictions back,,,Yes
28726,workaround for when predictions aren't enabled,,,Yes
28731,TODO(ahundt) THE DIMENSIONS\/COORDINATES AREN'T RIGHT HERE; FIX IT!,,,Yes
28734,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,No,Yes
28735,TODO(ahundt) move keras_fcn directly into this repository; into keras-contrib; or make a proper installer,,,Yes
28737,MOMENTUM=0.9 seems to help training,,No,Yes
28738,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,,Yes
28741,TODO: clean this stat up,,,Yes
28742,TODO(ahundt) move keras_fcn directly into this repository; into keras-contrib; or make a proper installer,,No,Yes
28743,TODO(ahundt) move keras_fcn directly into this repository; into keras-contrib; or make a proper installer,,No,Yes
28745,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,No,Yes
28746,during the random search phase. We plan to run a separate search on enabling trainable models on one of the best models,,Yes,Yes
28747,multi stage training not yet being configurable during hyperopt.,,Yes,Yes
28748,There should probably be an assert here,,,Yes
28749,There should probably be an assert here,,No,Yes
28750,There should probably be an assert here,,No,Yes
28752,we would have just done this directly at the start if the angle_multiplier wasn't needed,,No,Yes
28753,TODO(ahundt) save histories in some nice way,,No,Yes
28754,flags.FLAGS._parse_flags() not needed for tf 1.5,,No,Yes
28755,It is needed for when two of a model are used in a network,,,Yes
28757,todo get,,No,Yes
28758,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,No,Yes
28761,Workaround for some combined tf\/keras bug,,,Yes
28762,Workaround for special evaluation call needed for jaccard regression.,,Yes,Yes
28763,TODO(ahundt) Do insane hack resetting & reloading weights for now... will fix later,,No,Yes
28765,# # TODO(ahundt) check this more carefully; currently a hack,,,Yes
28766,# TODO(ahundt) check this more carefully; currently a hack,,No,Yes
28767,TODO(ahundt) check this more carefully; currently a hack,,No,Yes
28771,TODO: remove loss if it doesn't work or make me the default in the other files if it works really well,,Yes,Yes
28772,Take the best performance regardless of the epoch,,,Yes
28773,"TODO(ahundt) difference between \""redundant\"" and regular proto parsing; figure out how to deal with grasp_success rename properly",,No,Yes
28775,in both x and y so the swap is not needed.,,,Yes
28777,TODO: need to trap better than this high-level trap,,Yes,Yes
28778,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,No,Yes
28779,during the random search phase. We plan to run a separate search on enabling trainable models on one of the best models,,Yes,Yes
28780,multi stage training not yet being configurable during hyperopt.,,,Yes
28782,we probably hit an exception so consider this infinite loss,,Yes,Yes
28783,move = GetPlanToPoseService(),,,Yes
28784,Uncomment if you want to move to a 6DOF cartesian pose instead of a,,,Yes
28785,Move to joint position,,Yes,Yes
28787,in both x and y so the swap is not needed.,,Yes,Yes
28788,the following line is needed for tf versions before 1.5,,No,Yes
28789,move to random drop location,,Yes,Yes
28791,TODO(ahundt) figure out why this was here.,,No,Yes
28792,"rospy.loginfo(\""HOME: move to pose over objects\"")",,Yes,Yes
28793,move vertically down in the z axis,,Yes,Yes
28794,move to random drop location,,Yes,Yes
28795,TODO(ahundt) make mod value configurable,,,Yes
28798,it was probably manually configured,,Yes,Yes
28799,the following line is needed for tf versions before 1.5,,No,Yes
28801,the following line is needed for tf versions before 1.5,,No,Yes
28802,the following line is needed for tf versions before 1.5,,,Yes
28804,workaround for V-REP bug where handles may not be correctly deleted,,Yes,Yes
28806,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28808,TODO(ahundt) should displaying all clouds be a configurable option?,,,Yes
28809,workaround for when predictions aren't enabled,,Yes,Yes
28811,do the conversion needed for training,,No,Yes
28812,TODO(ahundt) move squeeze steps into dataset api if possible,,No,Yes
28813,fixed depth is to help if you're having problems getting your point cloud to display properly,,No,Yes
28816,TODO: remove loss if it doesn't work or make me the default in the other files if it works really well,,Yes,Yes
28818,TODO(ahundt) Do hack which resets the session & reloads weights for now... will fix later. (Fixed in 1.8?),,No,Yes
28819,TODO(ahundt) make more efficient,,No,Yes
28820,it was probably manually configured,,,Yes
28823,# # TODO(ahundt) check this more carefully; currently a hack,,,Yes
28825,2018-07-30 maybe worth a try; vgg model which did very well on rotation; #4 of 729; and fairly good on both val_grasp_acc and val_cart_error,,Yes,Yes
28828,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,,Yes
28829,next FLAGS line might be needed in tf 1.4 but not tf 1.5,,No,Yes
28830,with pandas.option_context('display.max_rows'; None; 'display.max_columns'; None):,,Yes,Yes
28833,Look for image features to make smaller if needed,,,Yes
28834,Hack. shouldn't be duplicated here,,Yes,Yes
28836,TODO(ahundt) make the data dir user configurable again for costar_block stacking,,No,Yes
28837,We are multiplying by batch size as a hacky workaround because we want the sizing reduction,,,Yes
28838,TODO(ahundt) remove hack below or don't directly access flags and initialize it correctly above,,,Yes
28839,hack to skip training so we can run,,Yes,Yes
28840,TODO(ahundt) make the data dir user configurable again for costar_block stacking,,No,Yes
28842,rotation does much better with msle over mse,,,Yes
28845,translation does slightly better with mse over msle,,Yes,Yes
28847,TODO: Write total frames into csv file as a new column,,No,Yes
28848,TODO: incorporate tqdm progress bar,,Yes,Yes
28849,TODO: include dataset name,,,Yes
28851,TODO: include dataset name,,,Yes
28852,TODO(rexxarchl): Implement csv output,,Yes,Yes
28853,TODO(rexxarchl): implement this function,,Yes,Yes
28854,TODO: Implement csv output,,No,Yes
28856,You must upload to the test_collection then email them to move your item to,,,Yes
28859,TODO(ddohan): Figure out why this is sometimes necessary,,,Yes
28860,"\""\""\""Implement basic model.\""\""\""",,Yes,Yes
28861,Unused in output & breaks the tf.estimator.predict api; which,,Yes,Yes
28862,"\""\""\""Base class and helper functions for configurable modules.\""\""\""",,Yes,Yes
28865,If the new value is a configurable class;,,Yes,Yes
28867,Perhaps we should allow specifying a namespace\/scope,,Yes,Yes
28870,unused,,No,Yes
28871,unused,,No,Yes
28873,num_items; unused,,Yes,Yes
28874,Unused.,,,Yes
28875,FIXME: Assumes the name of the data starts with y... Need to fix so that,,Yes,Yes
28879,random initialization of the weights if needed.,,Yes,Yes
28880,random initialization of the weights if needed.,,,Yes
28881,Random initialization of the weights if needed.,,,Yes
28882,Random initialization of the weights if needed.,,Yes,Yes
28883,Checks if the referring elements model is needed. If not; return 0s,,No,Yes
28886,the asymptotic relative efficiency of the l1 loss estimator is better,,Yes,Yes
28887,unused.,,,Yes
28888,unused.,,,Yes
28889,unused.,,Yes,Yes
28890,unused.,,Yes,Yes
28891,Unused.,,Yes,Yes
28892,Unused,,No,Yes
28893,TODO(tucker): devise a way of better specifying the device set,,Yes,Yes
28896,TODO(laigd): rename 'images' to maybe 'inputs'; same below.,,Yes,Yes
28898,TODO(laigd): rename 'images' to maybe 'inputs'.,,Yes,Yes
28899,averages for a slight performance gain.,,Yes,Yes
28900,Minor hack to avoid H2D copy when using synthetic data,,No,Yes
28901,hack is enabled.,,,Yes
28906,generation is needed to deal with spurious wakeups. If self.cond.wait(),,Yes,Yes
28909,Unused (for 'a trous' convolutions),,,Yes
28910,HACK This may not always work,,,Yes
28911,"\""\""\""Contains functions related to MLPerf compliance. ||  || MLPerf requires submissions to log what the benchmark does; in order to verify || that the benchmark meets the MLPerf requirements. This module contains a global || object `logger` that is used by other files to log what tf_cnn_benchmarks does || for compliance. ||  || By default; `logger` does nothing; as the MLPerf compliance logs are verbose and || unnecessary if one is not concerned about MLPerf compliance. The logger can be || enabled by using the `mlperf_logger` context manager. ||  || To enable the logger with `mlperf_logger`; the MLPerf compliance library at || https:\/\/github.com\/mlperf\/training\/tree\/master\/compliance is required. If || the logger is not enabled; the library is not needed. || \""\""\""",,Yes,Yes
28912,logs. Entry commented out with the comment FIXME indicate that,,,Yes
28913,"\""\""\""Inception model configuration. ||  || Includes multiple models: inception3; inception4; inception-resnet2. ||  || References: ||   Christian Szegedy; Sergey Ioffe; Vincent Vanhoucke; Alex Alemi ||   Inception-v4; Inception-ResNet and the Impact of Residual Connections on ||   Learning ||  ||   Christian Szegedy; Wei Liu; Yangqing Jia; Pierre Sermanet; Scott Reed; ||   Dragomir Anguelov; Dumitru Erhan; Vincent Vanhoucke; Andrew Rabinovich ||   Going Deeper with Convolutions ||   http:\/\/arxiv.org\/pdf\/1409.4842v1.pdf ||  ||   Christian Szegedy; Vincent Vanhoucke; Sergey Ioffe; Jonathon Shlens; ||   Zbigniew Wojna ||   Rethinking the Inception Architecture for Computer Vision ||   arXiv preprint arXiv:1512.00567 (2015) ||  ||   Inception v3 model: http:\/\/arxiv.org\/abs\/1512.00567 ||  ||   Inception v4 and Resnet V2 architectures: http:\/\/arxiv.org\/abs\/1602.07261 || \""\""\""",,,Yes
28914,Assume variables in the checkpoint are following the naming convention of,,,Yes
28915,to break if there is change in naming convention of either benchmarks or,,Yes,Yes
28916,COCO evaluation requires processing COCO_NUM_VAL_IMAGES exactly once. Due,,Yes,Yes
28917,expect user to set `num_eval_epochs` to >1; which will leave some unused,,,Yes
28920,TODO(jsimsa): Implement datasets code path,,Yes,Yes
28922,"\""\""\""Shared functionality across multiple test files.\""\""\""",,,Yes
28923,List of prefixes for generating PS devices; unused here.,,,Yes
28924,for better performance.,,No,Yes
28925,unused: this function returns the cached ref or value.,,No,Yes
28929,efficient).,,No,Yes
28931,Move fingers.,,,Yes
28933,weights (frozen target network). We hack this by,,Yes,Yes
28934,weights (frozen target network). We hack this by,,,Yes
28935,unused.,,Yes,Yes
28937,Unused.,,Yes,Yes
28938,Unused.,,Yes,Yes
28939,Unused.,,Yes,Yes
28941,The following functions were taken from tensor2tensor. Needed for fast,,,Yes
28942,This implementation is the most efficient in terms of embedding lookups,,Yes,Yes
28943,amount of common code. It would be best if we could extract a,,Yes,Yes
28944,common base class; and the implement the recurrent functionality,,No,Yes
28945,"\""\""\""Efficient ImageNet input pipeline using tf.data.Dataset. ||  || Branched from: || github.com\/tensorflow\/tpu\/blob\/master\/models\/official\/resnet\/imagenet_input.py ||  || \""\""\""",,,Yes
28948,and clean this up and make it clearer which parameters are needed,,,Yes
28953,unused arg,,No,Yes
28955,>1 shards helps with faster parameter distribution on multi-GPU machines,,Yes,Yes
28958,filter. Used to implement filtering with denotation.,,,Yes
28962,Feeding logits instead of outputs (thus no linear transformation needed).,,,Yes
28964,TODO(rishabhagarwal): Fix the harcoded values,,,Yes
28966,Moving to a 2 layer architechture since the one layer didn't improve,,,Yes
28967,Hack to check whether the dataset was wikisql or wikitable,,,Yes
28968,Not super efficient...,,,Yes
28969,Unused.,,,Yes
28970,# TODO(tabakg): Figure out why summary_op is not working.,,Yes,Yes
28972,# This seems to be the convention in existing dataframes.,,Yes,Yes
28973,Unused.,,,Yes
28974,# drop unused indices,,No,Yes
28975,# re-name columns,,No,Yes
28976,# Drop columns with NaN entries.,,No,Yes
28978,q should be orthonormal - make sure it really is,,,Yes
28981,This ugly hackery is necessary to get TF to visualize when running the,,Yes,Yes
28982,eval set; apparently.,,Yes,Yes
28984,Sad ugly hack here. Setting steps=None should go through all of the,,Yes,Yes
28985,as needed.,,Yes,Yes
28987,Unused,,No,Yes
28988,Potential should be zero at two ends of the grids.,,,Yes
28990,Unused,,,Yes
28992,"\""\""\""Encapsulation around different training strategies. ||  || These loosely construct everything needed to perform training. ||  || See truncated_training.py for how this is used. || \""\""\""",,Yes,Yes
28994,hack to ensure that strings starting with @ or % are parsed as configurable,,,Yes
28996,somewhat after fixing this. Find out why this would be.,,Yes,Yes
28999,Unused.,,Yes,Yes
29001,The gamma^{alpha beta}_{alpha* beta*} are not needed for the supergravity,,Yes,Yes
29002,hence we manually split 3+-tensor contractions for better efficiency.,,,Yes
29003,Fix for numpy not handling [N; 0]-arrays well.,,,Yes
29004,So; doing a direct minimization is perhaps appropriate.,,,Yes
29006,export a complete model; and do not allow making guesses.,,Yes,Yes
29007,Our convention is that we lexicographically list those 8-choose-4,,,Yes
29012,Our convention is that we lexicographically list those 8-choose-4,,,Yes
29013,Unused.,,Yes,Yes
29015,incomplete columns.,,,Yes
29016,"\""\""\""Self-financing replicating portfolio controllers. ||  || To replicate a sold derivative on some underlying asset two basic operations are || needed: ||   1) Give an estimate; in the present market conditions; of the price of || the derivative. This determines how much initial cash is needed to initiate || the self-financing portfolio that replicates the derivative. The self-financing || portfolio is controlled to be equal in value to the derivative's payoff || at maturity. ||   2) Give an estimate; in the present market conditions; of the hedging vector || of the derivative (usually called delta; it is typically the sensitivity of || the derivative's price w.r.t. the underlying asset price vector). ||  || Both corresponding wrappers around tensorflow computation graphs are provided || here. || \""\""\""",,No,Yes
29019,[TODO]; how to add -1=[0;0;0;0] into emb_dict,,Yes,Yes
29020,TODO(yovadia): Maybe remove defaults.,,Yes,Yes
29024,The convention in BERT is:,,No,Yes
29026,Contrib is lazily loaded so this reference is needed to use the resampler op.,,,Yes
29027,TODO(debidatta): Better way to extract batch norm variables.,,Yes,Yes
29028,jpeg files. This is a workaround for a bug in PIL. The value should be,,No,Yes
29030,Shuffle the filenames to ensure better randomization.,,Yes,Yes
29033,Move everything into depth so we can perform a single matrix multiply.,,,Yes
29036,noise we use can become negative. Further experimentation is needed to,,No,Yes
29037,find if non-negativity is indeed needed.,,,Yes
29038,"The \""compute_loss\"" scope is needed for the checkpoint to load properly.",,Yes,Yes
29039,they slightly differ. Averaging rot and inv(inv_rot) gives a better,,No,Yes
29040,FIX for Bad Magic Header bug,,Yes,Yes
29043,Unused.,,Yes,Yes
29044,Unused.,,Yes,Yes
29046,TODO - use 15 val examples for imagenet?,,,Yes
29048,TODO - enable this to be set to >1,,No,Yes
29049,TODO - use 15 val examples for imagenet?,,No,Yes
29051,TODO - enable this to be set to >1,,No,Yes
29052,TODO - use 15 val examples for imagenet?,,No,Yes
29055,TODO - use 15 val examples for imagenet?,,No,Yes
29056,only construct training model if needed,,,Yes
29058,its needed for every step; and is approximated by A1; A2; A3.,,Yes,Yes
29059,This path is typically unused on TPUs; as gradients are densified.,,Yes,Yes
29062,above convention. Now the 0 index corresponds to padded tokens.,,Yes,Yes
29063,The convention in BERT is:,,No,Yes
29065,Generate the schema embeddings if needed or specified.,,Yes,Yes
29067,implement this as in version 1.5.5.,,,Yes
29068,All feature columns in the data,,Yes,Yes
29069,Fix random seeds,,,Yes
29070,transformations; taking into account of aggregated feature use.,,,Yes
29071,Fix random seeds,,Yes,Yes
29072,"\""\""\""Efficient input pipeline using tf.data.Dataset.\""\""\""",,,Yes
29073,Unused since output is constant regardless of input,,No,Yes
29074,following may be needed; so enforcing TF operation updates.,,Yes,Yes
29075,"\""\""\""Helper class that wraps around multiple different compression operators. ||  || This allows for easier testing of different operators. Rather than importing || each operator separately; this class can be used and different || compression_option values can be passed in to specifiy the operator type. ||  || compression_option: ||   1 - LowRankDecompMatrixCompressor ||   2 - SimhashMatrixCompressor || \""\""\""",,No,Yes
29076,Module names needed for mocking.,,Yes,Yes
29077,Move everything into depth so we can perform a single matrix multiply.,,,Yes
29079,Run for 1 time to create variables (but output is unused).,,No,Yes
29084,Unused.,,Yes,Yes
29086,Calculate largest length penalty (the larger penalty; the better score).,,,Yes
29087,TODO(peterjliu): Shuffle better,,Yes,Yes
29089,No padding is needed here as inputs_BxTxH is already prepended with,,,Yes
29092,not sure why this is needed - do some things have Null id's?,,Yes,Yes
29095,Mask value for the current node (1: legal move; 0: illegal move),,,Yes
29096,built in stopping if lr is way too small,,,Yes
29099,The convention in ALBERT is:,,No,Yes
29102,unused,,,Yes
29103,The convention in ALBERT is:,,,Yes
29104,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
29105,The convention in BERT is:,,No,Yes
29106,Sort to move values to diagonal,,,Yes
29107,Best param.,,Yes,Yes
29108,Will not be needed for TensorFlow1.15+.,,,Yes
29109,to the wikitext before saving it to disk. This is needed to correct,,,Yes
29110,ReLU; but it is a better guess than Glorot.,,,Yes
29112,Unused.,,,Yes
29115,Assert statement to catch if ckp path is saved in correct way.,,,Yes
29118,Unused.,,,Yes
29119,Construct a 4x4 intrinsic matrix (TODO: can it be 3x4?),,Yes,Yes
29120,Unused.,,Yes,Yes
29121,The convention in BERT is:,,No,Yes
29131,"Include all columns other than \""label\"" as features.",,Yes,Yes
29132,Best param.,,Yes,Yes
29133,constrained optimization problem. The library doesn't currently support best,,Yes,Yes
29135,Extract relevant columns,,No,Yes
29136,Set all to str so that we don't have mixed integer\/string columns,,Yes,Yes
29139,SO(3) rotation; i.e. every possible Pauli transform; is one way to prove,,,Yes
29141,compare the TODO at the beginning of class XmonArchitecture,,,Yes
29143,might be a little more efficient.,,Yes,Yes
29144,According to the indexing convention for multi-qubit states; the bitstring x,,,Yes
29145,also the rows and columns of the operator.,,,Yes
29146,The proper way to bring the active component into this format is to,,,Yes
29147,all permutations of the rows (or equivalently columns) of the identity,,Yes,Yes
29153,Subclasses must implement these methods.,,Yes,Yes
29154,Fix the placeholder.,,Yes,Yes
29155,Fix worker,,No,Yes
29157,unused,,No,Yes
29158,feature vector at middle point [batch; feature],,,Yes
29159,unused,,,Yes
29160,feature vector at middle point [batch; feature],,No,Yes
29161,Filter features_columns andkeep only protected feature_columns.,,No,Yes
29162,# Feature_columns is a list of tf.feature_column; via x[0] we are,,No,Yes
29165,Unused in robust_learning models. Adding it for min-diff approaches.,,Yes,Yes
29166,Unused in robust_learning models. Adding it for min-diff approaches.,,,Yes
29167,"\""\""\""Main model trainer from which a number of robust-learning models can be trained. ||  || Currently we support the following robust-learning approaches: ||   - robust_learning: proposed adversarial re-weighting robust learning approach ||   - baseline: a simple baseline model; which implements a fully connected ||     feedforward network with standard ERM objective. ||   - inverse_propensity_weighting: a naive re-weighting baseline using ||     inverse_propensity_weighting. ||   - adversarial_subgroup_reweighting: (modified) version of our proposed ||     approach wherein adversary has access only to protected features; ||     and learner has access to all features. || \""\""\""",,,Yes
29168,# in the corresponding custom estimator implementation by filtering feature_columns passed to the learner.,,Yes,Yes
29170,Move everything into depth so we can perform a single matrix multiply.,,No,Yes
29172,TODO - use 15 val examples for imagenet?,,No,Yes
29173,only construct training model if needed,,Yes,Yes
29174,Unused,,No,Yes
29178,The 'weights' part of the name is needed for the quantization library,,No,Yes
29179,"r\""\""\""Functions to add magnitude-based model pruning or noise based pruning. ||  || Pruning broadly refers to a set of approaches that reduce the number of || parameters in a model. Inducing sparsity by pruning should ideally lead to || model compression; acceleration at inference time + provide theoretical || insights as to why we need such large networks to begin with. ||  || \""\""\""",,Yes,Yes
29181,Fix random seeds,,,Yes
29183,This is a hack to create the tf variables of the base_model before usage.,,No,Yes
29186,This is needed ahead of time before tf.map_fn is called.,,,Yes
29189,unused arg,,No,Yes
29192,"\""\""\""Compact implementation of a Hyperbolic Rainbow agent. ||  || Specifically; we implement the following components from Rainbow: ||  ||   * n-step updates; ||   * prioritized replay; and ||   * distributional RL. ||  || Plus auxiliary tasks for hyperbolic action. ||  || These three components were found to significantly impact the performance of || the Atari game-playing agent. ||  || Furthermore; our implementation does away with some minor hyperparameter || choices. Specifically; we ||  ||   * keep the beta exponent fixed at beta=0.5; rather than increase it linearly; ||   * remove the alpha parameter; which was set to alpha=0.5 throughout the paper. ||  || Details in \""Rainbow: Combining Improvements in Deep Reinforcement Learning\"" by || Hessel et al. (2018). || \""\""\""",,Yes,Yes
29194,a fixed exponent actually performs better; except on Pong.,,Yes,Yes
29198,a fixed exponent actually performs better; except on Pong.,,Yes,Yes
29199,TODO(b\/80536437). This is not efficient when arg_element is a list.,,No,Yes
29200,By convention; if x=0; x*log(x)=0.,,Yes,Yes
29202,Orthogonalize columns of V.,,Yes,Yes
29203,convert from OpenCV convention to OpenGL,,Yes,Yes
29205,unused,,No,Yes
29207,using shared policies are better,,,Yes
29209,The convention in BERT is:,,,Yes
29210,"What we really want to return is \""Steve Smith\"".",,No,Yes
29211,"\""\""\""DCA run and evaluation. ||  || Runs DCA with the specified input parameters and evaluates it. ||  || This is weird 'hack' that launches a hyperparameter grid locally || because our grid is so large that we cannot launch one configuration || per machine. || \""\""\""",,,Yes
29212,"\""\""\""scVI run and evaluation. ||  || Runs scVI with the specified input parameters and evaluates it. ||  || This is a weird 'hack' that launches a hyperparameter grid locally || because our grid is so large that we cannot launch one configuration || per machine. || \""\""\""",,No,Yes
29214,If the value based on the utterance ends with any value below; we don't,,,Yes
29215,Hack to ensure that -0.0 gets consistently shown as 0.0.,,,Yes
29216,For e7; there actually is a better orthonormal basis:,,,Yes
29217,We found a point that apparently is close to a critical point.,,No,Yes
29219,fix to handle numerical issues where sum isn't exactly 1,,,Yes
29221,Unused.,,Yes,Yes
29223,Apparently; uflow.restore() does not work here in graph mode.,,No,Yes
29225,"\""\""\""UFlow models. ||  || This library contains the models used in UFlow. Our model is a slightly modified || version of the PWC net by Sun et al (https:\/\/arxiv.org\/pdf\/1709.02371.pdf). ||  || In particular; we change the number of layers and filters in the feature || pyramid; we introduce a pyramid-level dropout; and we normalize the features || before computing a cost volume. We found these changes to improve the || performance. || \""\""\""",,,Yes
29226,init flows with zeros for coarsest level if needed,,Yes,Yes
29228,"r\""\""\""Implementation of Splitter embedding using Gensim. ||  || =============================== ||  || This is part of the implementation accompanying the WWW 2019 paper; [_Is a || Single Embedding Enough? Learning Node Representations that Capture Multiple || Social Contexts_](https:\/\/ai.google\/research\/pubs\/pub46238). ||  || The code in this file allows one to create persona embeddings. ||  || This code was tested with gensim==0.13.2. ||  || Known issues:  The inner loop (train_batch_sg_constraints) is written in pure || python; and its speed could be greatly improved by porting to an optimized || C implementation. ||  || Citing || ------ || If you find _Persona Embedding_ useful in your research; we ask that you cite || the following paper: || > Epasto; A.; Perozzi; B.; (2019). || > Is a Single Embedding Enough? Learning Node Representations that Capture || Multiple Social Contexts. || > In _The Web Conference_. || \""\""\""",,Yes,Yes
29229,"r\""\""\""Implementation of Splitter embedding using Gensim. ||  || =============================== ||  || This is part of the implementation accompanying the WWW 2019 paper; [_Is a || Single Embedding Enough? Learning Node Representations that Capture Multiple || Social Contexts_](https:\/\/ai.google\/research\/pubs\/pub46238). ||  || The code in this file allows one to create persona embeddings. ||  || Known issues:  The inner loop (train_batch_sg_constraints) is written in pure || python; and its speed could be greatly improved by porting to an optimized || C implementation. ||  || Citing || ------ || If you find _Persona Embedding_ useful in your research; we ask that you cite || the following paper: || > Epasto; A.; Perozzi; B.; (2019). || > Is a Single Embedding Enough? Learning Node Representations that Capture || Multiple Social Contexts. || > In _The Web Conference_. || \""\""\""",,Yes,Yes
29231,unused,,,Yes
29233,Columns are not in the same order compared to the previous,,,Yes
29235,TODO(zhedong): the `axis=1` is frigile; fix this with better understading,,Yes,Yes
29236,TODO: Robbers?,,No,Yes
29238,END HACK,,Yes,Yes
29240,If you implement a subclass; you should register it in the from_config,,,Yes
29241,TODO: Properly break circular dependencies,,No,Yes
29244,"\""\""\""Defines cache replacement OpenAI gym environment. ||  || See policy.py for LRU and Belady's policies. ||  || Example usage: ||  || import config as cfg || env = CacheReplacementEnv( ||     cfg.Config.from_files_and_bindings( ||       [\""example_cache_config.json\""]; []); \""example_memtrace.csv\"") ||  || state = env.reset() || while True: ||   action = next(iter(state.action_set))  # random action ||   state; reward; done; info = env.step(action) ||   env.render() ||   if done: ||     break || \""\""\""",,Yes,Yes
29245,This is the logit offset needed to clip the maximum probability.,,,Yes
29247,TODO(christofa): Move into step after refactoring callbacks.,,,Yes
29249,Create a cache object for efficient decoding.,,Yes,Yes
29250,The multiplexer concatenates the (maybe transformed) observations\/actions.,,No,Yes
29253,"r\""\""\""Library for creating different blackbox objects. ||  || Library for creating different blackbox objects providing ways to manipulate || blackbox functions to be optimized (obtaining starting points for their || optimization; executing them and getting metaparameters needed to set || up certain algorithms optimizing them). || \""\""\""",,,Yes
29254,This is needed to input Numpy Params into network temporarily,,,Yes
29256,### This is the fix,,No,Yes
29257,there is a better result,,,Yes
29259,"\""\""\""Tests functionality of training NAM models.\""\""\""",,No,Yes
29261,Unused; num updates based off constructed model graph.,,,Yes
29262,Unused,,No,Yes
29263,only construct training model if needed,,Yes,Yes
29266,we should find a non-hack approach to initializing the state,,,Yes
29267,note: should probably store factorized cov;,,,Yes
29268,uses random as a hack to support vmap,,Yes,Yes
29269,we should find a non-hack approach to initializing the state,,No,Yes
29270,unused,,No,Yes
29271,"\""\""\""Collapsed Amortized Variational Inference for SNLDS. ||  || This is a reasonable baseline model for switching non-linear dynamical system || with the following architecture: || 1. an inference network; with Bidirectional-RNN for input embedding; and a ||    forward RNN to get the posterior distribution of `q(z[1:T] | x[1:T])`. || 2. a continuous state transition network; `p(z[t] | z[t-1]; s[t])`. || 3. a discrete state transition network that conditioned on the input; ||    `p(s[t] | s[t-1]; x[t-1])`. || 4. an emission network conditioned on the continuous hidden dynamics; ||    `p(x[t] | z[t])`. ||  || It also contains a function; `create_model()`; to help to create the SNLDS || model discribed in  ``Collapsed Amortized Variational Inference for Switching || Nonlinear Dynamical Systems``. 2019. https:\/\/arxiv.org\/abs\/1910.09588. || All the networks are configurable through function arguments `network_*`. || \""\""\""",,Yes,Yes
29273,(instead of the other way around).,,,Yes
29274,"\""\""\""Simple generator for synthetic multi-task data. ||  || This implements the generation procedure described in \""Modeling Task || Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts\"". Here; || the procedure is slightly generalized to generate multiple pairs of tasks; || where the relatedness between pairs is typically low; and the relatedness || within pairs can be controlled with a hyperparameter. || \""\""\""",,,Yes
29275,"\""\""\""Core Fast Attention Module for Flax. ||  || Implementation of the approximate fast softmax and generalized || attention mechanism leveraging structured random feature maps [RFM] techniques || and low rank decomposition of the attention matrix. || \""\""\""",,,Yes
29276,"r\""\""\""Tests for Fast Self Attention mechanism. ||  || Tests Fast Self Attention mechanism based on random feature maps. || \""\""\""",,Yes,Yes
29278,spelling_list had better still be a singleton.,,Yes,Yes
29280,TODO(liuti): Figure out a better workaround.,,Yes,Yes
29282,unused. `params` is for runtime parameters passed around by the estimator,,,Yes
29283,The unused parameters are deleted below.,,Yes,Yes
29284,learning and 1 when the search ends.,,Yes,Yes
29285,Unused.,,Yes,Yes
29287,"\""\""\""Mobile classification search space built around MobileNet V3. || \""\""\""",,,Yes
29288,examples to all of the TPU cores. This is less efficient than PER_HOST_V2.,,,Yes
29290,Unused.,,,Yes
29291,This is needed to prevent TensorFlow from generating invalid graphs in,,,Yes
29292,This logic was originally added to work around a TF bug which caused some,,No,Yes
29294,However; in an early version of the code; we were able to improve model,,,Yes
29295,theory) equivalent; cond_v2() typically works better on TPUs.,,Yes,Yes
29296,Unused,,No,Yes
29297,The mobile_classifier_factory import might look like it's unused; but,,Yes,Yes
29298,importing it will register some namedtuples that are needed for model_spec,,No,Yes
29300,Back to wider field of view. If we move forward enough; the central,,,Yes
29302,Convert categorical columns to integers.,,No,Yes
29303,TODO(rws): Maybe add other controls upon request.,,,Yes
29304,Remove some of the columns.,,,Yes
29305,Remove some different columns,,Yes,Yes
29307,Convert each categorical column for variable V into N indicator columns;,,Yes,Yes
29308,i.e. turn it into a one-hot representation; where names of the new columns,,,Yes
29309,For some reason the categorical columns are floats. Coerce them back to,,No,Yes
29310,"\""\""\""This model relies on whichever model performed best during cross-validation. ||  || The models are simple ML models trained using scikit-learn. || \""\""\""",,Yes,Yes
29311,These are currently unused.,,Yes,Yes
29312,Numeric columns are transformed using standard scaler and categorical,,,Yes
29314,Class weights: if you set this to None; you'd get much better accuracies;,,Yes,Yes
29316,Fill in explicit feature columns.,,No,Yes
29320,Prepare the core columns.,,Yes,Yes
29321,Prepare feature columns.,,,Yes
29323,"r\""\""\""Generates empirical distribution dataframe of next production rule. ||  || There are two different empirical distribution dataframes we can generate. One || is the empirical distribution of the next production rule for a partial || sequence; and the other is the empirical distribution of the next production || rule for the tail of a partial sequence. \""Tail\"" means that we just use the last || several production rules from the partial sequence. It uses limited history (or || called partial information) to determine the next production rule. ||  || Each row of the dataframe contains a string of partial sequence indices (or tail || of it); and the conditions of the complete sequence (such as leading power at || zero and leading power at inf). These are placed as multi-indices of the || dataframe. The columns of the dataframe are the probabilities of the next || production rule. ||  || Here is an example of the first kind of dataframe: || partial_sequence_indices  leading_at_0  leading_at_inf  0  1  2   ... ||         1_4_3_5                -1            -1         0  0  0.5 ... ||  || Here is an example of the second kind of dataframe with tail_length=2: || tail_partial_sequence_indices  leading_at_0  leading_at_inf  0  1  2   ... ||             3_5                     -1            -1         0  0  0.5 ... ||  || How is the dataframe computed: || For each given string of partial sequence indices (or tail of it) and || conditions; find all the matches from the training set. This gives a number of || next production rules. Compute the empirical distribution of these production || rules. Note that for the tail partial sequence; the next production rule mask of || the entire sequence is needed to ensure the validity of the proposed next || production rule. || \""\""\""",,Yes,Yes
29324,Add missing columns.,,,Yes
29325,Reorder columns.,,,Yes
29328,unused,,No,Yes
29330,the reshaping and invocation of BatchMatMul; instead of doing it manually;,,Yes,Yes
29331,TODO(ydjiang): figure out why reward cannot be converted to tensor as is,,Yes,Yes
29332,TODO(ydjiang): find better way to initialize,,,Yes
29335,TODO(schsam): Better error checking here (what if depends_on is malformed,,,Yes
29336,"\""\""\""Contains definitions for the AssembleNet [1] models. ||  || Requires the AssembleNet architecture to be specified in || FLAGS.model_structure (and optionally FLAGS.model_edge_weights). || This structure is a list corresponding to a graph representation of the || network; where a node is a convolutional block and an edge specifies a || connection from one block to another as described in [1]. ||  || Each node itself (in the structure list) is a list with the following format: || [block_level; [list_of_input_blocks]; number_filter; temporal_dilation; || spatial_stride]. [list_of_input_blocks] should be the list of node indexes whose || values are less than the index of the node itself. The 'stems' of the network || directly taking raw inputs follow a different node format: || [stem_type; temporal_dilation]. The stem_type is -1 for RGB stem and is -2 for || optical flow stem. ||  || Also note that the codes in this file could be used for one-shot differentiable || connection search by (1) giving an overly connected structure as || FLAGS.model_structure and by (2) setting FLAGS.model_edge_weights to be '[]'. || The 'agg_weights' variables will specify which connections are needed and which || are not; once trained. ||  || [1] Michael S. Ryoo; AJ Piergiovanni; Mingxing Tan; Anelia Angelova; ||     AssembleNet: Searching for Multi-Stream Neural Connectivity in Video ||     Architectures. ICLR 2020 ||     https:\/\/arxiv.org\/abs\/1905.13209 ||  || It uses (2+1)D convolutions for video representations. The main AssembleNet || takes a 4-D (N*T)HWC tensor as an input (i.e.; the batch dim and time dim are || mixed); and it reshapes a tensor to NT(H*W)C whenever a 1-D temporal conv. is || necessary. This is to run this on TPU efficiently. || \""\""\""",,Yes,Yes
29339,how much knowledge each observation gets,,,Yes
29340,dont really how it works,,,Yes
29341,hack to remove empty logs,,,Yes
29342,"bfw means \""beam feature weights\"" control method and ct means \""conditional training\"" control method",,,Yes
29344,Convert old format to new format if needed from a PyTorch state_dict,,,Yes
29345,make sure token embedding weights are still tied if needed,,,Yes
29346,hack for efficiency,,Yes,Yes
29347,"\""\""\""Uses stochastic_descent to find local optima of bang-bang protocols. ||  || Starting from a given (likely random) protocol; iterate through all of the || protocols that are Hamming distance at most k away and evaluate their || performance. The iteration proceeds in a random order; and when a better || protocol is found then jump to that one and restart the search from the new || origin. The algorithm terminates when none of the neighbors have better || performance; and this defines a local optimum. || \""\""\""",,Yes,Yes
29348,"\""\""\""Class containing a 2-DNF. ||  || A k-DNF is a disjunction (logical AND) over conjunctions (logical OR) with each || conjunction clause containing at most k literals. We will restrict ourselves to || 2-DNFs. ||  || This library contains the building blocks for producing problem instances; || as well as evaluating problems related to the DNF. || \""\""\""",,Yes,Yes
29349,TODO(izmailovpavel): check why the second condition is needed.,,Yes,Yes
29350,Note: find a better way for this.,,,Yes
29351,Note: maybe use the pre-computed (tf-idf) similarity score here. e2e,,No,Yes
29353,There are more efficient libraries but in order to avoid additional,,Yes,Yes
29354,dependencies we use a simple (perhaps somewhat brittle) regexp to reduce,,Yes,Yes
29355,the content to only what is needed. This takes 1min to execute but,,No,Yes
29356,Hack to get tfgan KID work for eager execution.,,Yes,Yes
29358,JavaTokenizer counts lines and columns from 1.,,Yes,Yes
29361,Unused.,,Yes,Yes
29364,TODO(yusef): Fix map + total number of cars.,,Yes,Yes
29365,TODO(albertyuchen): Find better basis creation tools.,,Yes,Yes
29369,HACK: Get around T2T bug by defaulting to tf.layers.,,Yes,Yes
29371,would likely perform better.,,Yes,Yes
29377,TODO(daniel) this is perhaps an older way of analyzing the data?,,Yes,Yes
29379,TODO(daniel) check if this is needed,,,Yes
29381,sampling negatives seems to converge faster,,,Yes
29383,Iterate through parts and create constraints as needed.,,,Yes
29384,Scaling the zone as needed.,,Yes,Yes
29385,"\""\""\""Cloth related tasks. ||  || Interpreting self.zone_pose[0] = (x;y;z) where x and y are the VERTICAL and || HORIZONTAL (resp.) ranges in the diagram; in METERS: ||  ||   -0.5 .... +0.5 ||   ------------  0.3 ||   |          |   : ||   |          |   : ||   |          |   : ||   ------------  0.7 ||  || The self.zone_pose corresponds to the colored yellow lines in the GUI. The || (0;0;0) location corresponds to the base of the robot. ||  || Notes from Xuchen Han: || - if reducing mass of cloth; reduce springElasticStiffness. || - recommends springDampingAllDirections=0 for realistic damping. ||  || Notes on the cloth: || - basePosition for the cloth is the CENTER of the cloth. || - started w\/mass=1.0 and elastic\/damping stiffness of 40 and 0.1. || - NxN cloth means the edge length is \""cloth length\"" divided by N-1; not N. ||  || With 10x10 (therefore; there are 9x9=81 actual _squares_ in the cloth mesh); || indices are: ||  ||   90  -->  99 ||   80  -->  89 ||   ..  ...  .. ||   10  -->  19 ||    0  -->   9 ||  || For 5x5 (so 4x4=16 squares) the indices are: ||  ||   20  -->  24 ||   15  -->  19 ||   10  -->  14 ||    5  -->   9 ||    0  -->   4 ||  || For the corner-pulling demonstrator (see implementation in tasks\/task.py); I || recommend gripping 'one corner inwards' instead of using the _actual_ || corners; except for the 5x5 case which might be too coarse-grained. ||  || We can adjust the size of both the zone and the cloth. The provided zone.obj || ranges from (-10;10) whereas cloth files from Blender scale from (-1;1); || hence the cloth scale needs to be 10x larger than the zone scale. If this || convention changes with any of the assets; adjust sizes accordingly. ||  || Reminder: add any soft body IDs to `self.def_ids`. || \""\""\""",,,Yes
29386,To reference it later for IoUs\/coverage; or to remove if needed.,,Yes,Yes
29387,Compute task stage. TODO this is a really bad hack.,,Yes,Yes
29388,But now sample the rotation; assuming we use 24 (TODO: make more,,,Yes
29390,add positional embeddings if needed,,No,Yes
29391,hack for T2T metrics,,,Yes
29392,Unused,,,Yes
29393,TODO(kalpeshk): Implement token_bias here?,,,Yes
29394,move heads to batch dimension. This is needed to reduce number of,,Yes,Yes
29396,Needed info is constant; so we construct in numpy,,,Yes
29398,TODO(kitaev): verify that tie-in is safe to remove (in light of jax fix),,,Yes
29402,level Transformer model. These representations maybe useful for sentence,,Yes,Yes
29404,JavaTokenizer counts lines and columns from 1.,,Yes,Yes
29408,Unused in this test.,,,Yes
29410,This if statement is needed to guard the cast; because batch norm,,Yes,Yes
29411,unused.,,,Yes
29412,setting the `train_epochs` for an unused stage to 0. A single stage can use,,,Yes
29413,supported on NHWC. TPU uses XLA compiler to figure out best layout.,,Yes,Yes
29414,unused.,,Yes,Yes
29415,Workaround for https:\/\/github.com\/tensorflow\/tensorflow\/issues\/26411 where,,,Yes
29420,TODO(dbieber): Move this logic into the dataset definition.,,,Yes
29421,Unused.,,Yes,Yes
29422,Unused.,,,Yes
29425,Binarize categorical columns.,,,Yes
29427,Filter out all columns except the ones specified.,,,Yes
29433,the knots can be used to sparsely activate knots if needed.,,,Yes
29435,0.5 * original_image_width to match the convention described in comment,,,Yes
29436,This is 90 degree rotation about the z-axis with the convention of,,No,Yes
29438,are scrambled together; so providing one seed is fine. This makes it easier,,Yes,Yes
29440,"\""<unused_39>\""",,No,Yes
29443,"\""<unused_42>\""",,Yes,Yes
29444,Unused by model_fn,,Yes,Yes
29447,"\""<unused_41>\""",,Yes,Yes
29448,"\""<unused_42>\""",,Yes,Yes
29449,Note that the ends here become inclusive.,,,Yes
29451,"r\""\""\""Script to validate and dedup MS Marco OpenKP dataset. ||  || Some urls appear multiple times in the MS Marco OpenKP dataset: 6x in the dev || and eval sets; ~50 urls appear ~20x in the train set. This script: || 1. creates new json files with one example per url; || 2. drops KeyPhrases that do not occur in text (no attempt to fix punctuation); || 3. keeps at most 3 KeyPhrases. ||  || OpenKPDev.jsonl: keeps 6610 examples out of 6616. || OpenKPTrain.jsonl: keeps 133724 examples out of 134894. || OpenKPEvalPublic.jsonl: keeps 6613 examples out of 6614. || \""\""\""",,No,Yes
29454,Build move parameters by dividing mass uniformly among edge types,,,Yes
29457,"added. Instead; we can manually transform the einsum \""vi;vij->j\"" into",,Yes,Yes
29458,"\""feature dimensions\"" to get an efficient implementation without",,Yes,Yes
29459,Note: This seems to help sometimes and hurt other times; in,,Yes,Yes
29460,Variant 1: move backward,,,Yes
29461,Variant 1: move backward,,No,Yes
29464,Compute the `p`th quantile of each size; maybe rounding up.,,Yes,Yes
29465,Metadata field or unused syntax.,,Yes,Yes
29469,"\""\""\""A representation of a small subset of Python as a graph schema. ||  || The goal is to allow representing some simple functions as graphs in order to || learn Python static analyses from the AST. As such; it supports basic control || flow; but intentionally simplifies away many other \""optional\"" parts of the || language (and thus probably won't support real-world code). ||  || This representation was used for the static analysis tasks in the paper. ||  || Some things that are not supported: || - Keyword arguments || - Chained assignments (such as x = y = foo(...)) || - Chained comparisons (such as x < y < z) || - Decorators || - Imports; exceptions; \""with\"" blocks; and many other AST node types that ||   haven't yet been added in (but could be added if needed) ||  || The graph representation is mostly a straightforward conversion of the AST || produced by the gast module; with a few differences: ||  || - Metadata (i.e. variable names; load\/store contexts; etc) is removed (we assume ||   relevant metadata will be captured in initial node embeddings; not in the ||   graph structure). || - Anywhere that a list of expressions or list of statements would appear; ||   special list helper nodes are inserted to track position in the list (this is ||   to simplify the schema; since otherwise every statement or expression would ||   have to have optional next\/previous edges). || \""\""\""",,Yes,Yes
29470,Reset our best validation to our current performance,,,Yes
29471,Fix validation randomness to smooth out noise.,,Yes,Yes
29472,Temporary workaround: cast `dx` to float because `jax.jvp` expects integer,,,Yes
29473,Unused.,,Yes,Yes
29474,Move the bucket's padding config into the batch metadata.,,No,Yes
29475,Improve training performance when training data is in remote storage and,,Yes,Yes
29476,TODO: fix this magic; currently we assume each expr takes at least 2 positions;,,Yes,Yes
29481,Antagonist agent not needed for baselines,,Yes,Yes
29482,Remove extra unnecessary index columns,,,Yes
29483,Move any other agents in this one's start spot back to their own start,,,Yes
29485,Highlight the cell if needed (do not highlight walls),,,Yes
29486,Expand dims is needed here because tf-agents cannot allow an observation,,Yes,Yes
29487,Strip preceding underscores; as per Wikimedia convention.,,,Yes
29488,above value; but raw repr to workaround text editor issues:,,,Yes
29489,"r\""\""\""Universal WikiNews linked mention extractor. ||  || Extract Wikipedia entity mentions and the document text they appear in; given a || WikiNews snapshot. ||  || The main input (wikinews_archive) is the jsonl archives produced by running || wiki-extractor (with namespace filtering deactivated). It has one record per || document. The records include lightly marked up text that retains <a> tags and || Section::: markings. See html_anchor_parser.WikiExtractorHTMLParser and || common.WikiNewsDocParser for details. ||  || ---------------------------------------------------- || 'dataset' mode: **intended for public consumption** || ---------------------------------------------------- || A dataset is pre-defined by the secondary inputs: docs.tsv; mentions.tsv ||  || In this mode; the program extracts the text needed as context for the provided || mentions; and verifies that all of them have been found. ||  || Outputs: ||   -Clean text is output to --output_dir_text. ||   -Intermediate mark-up documents are output to --output_dir_wiki. ||  || ---------------------------------------------------- || 'raw' mode: intended for corpus development || ---------------------------------------------------- || Runs in unconstrained mode to extract as many mentions and documents from the || input archive as possible. ||  || Outputs: ||  - docs.tsv ||  - mentions.tsv ||  - Clean text is output to --output_dir_text. ||  - Intermediate mark-up documents are output to --output_dir_wiki. || \""\""\""",,Yes,Yes
29490,TODO(daniel) check if this is needed,,,Yes
29491,Sampling negatives seems to converge faster.,,Yes,Yes
29492,"\""\""\""Utilities for model inference. ||  || Assumptions: || * All residue encoding is one hot for all models. || * Logistic and CNN models use fixed length sequence encodings || * RNN model uses variable length sequence encodings || \""\""\""",,Yes,Yes
29494,TODO(fartash): prove that flip is not needed,,Yes,Yes
29495,https:\/\/jax.readthedocs.io\/en\/latest\/notebooks\/Custom_derivative_rules_for_Python_code.html#Enforcing-a-differentiation-convention,,,Yes
29496,TODO: Fill these in automatically,,Yes,Yes
29497,TODO: Fill these in automatically,,,Yes
29498,TODO ZP do we need the concat?,,,Yes
29499,TODO ZP do we need the concat?,,Yes,Yes
29500,The convention we follow is that body_com[2] is always 0; and geom_pos[2] is the object height,,No,Yes
29502,Probably consider set to nan or ignore_label.,,No,Yes
29503,note; transpose is implemented via changing summation axis,,,Yes
29504,"r\""\""\""Approximate BLEU score. ||  || MLPerf version of BLEU calculation. || Tries to match SacreBLEU metric reasonably well. ||  || Refs: ||     tokenizer at: ||     https:\/\/github.com\/tensorflow\/models\/blob\/master\/official\/transformer\/utils\/tokenizer.py ||     original preprocessing tokenizer: ||     https:\/\/github.com\/moses-smt\/mosesdecoder\/blob\/master\/scripts\/generic\/mteval-v14.pl#L954-L983 ||     original t2t code: ||     https:\/\/github.com\/tensorflow\/tensor2tensor\/blob\/master\/tensor2tensor\/utils\/bleu_hook.py ||  || Usage: ||     refs = '''food bar brown cow ||     blee bloo dog sat ||     or please take me out ||     ''' ||     hyps = '''foo bar brown cow ||     blee bloo dog sit ||     please do take me out ||     ''' ||     bleu_local(refs.split(\""\ || \""); hyps.split(\""\ || \""))  # 39.65 || \""\""\""",,Yes,Yes
29505,If no best possible live score is better than current worst finished,,No,Yes
29509,TODO(levskaya): verify this is still needed in translation decoding.,,Yes,Yes
29511,Unbroadcast is a hack to take the output of a pmap with out_axes=0 and turn,,Yes,Yes
29512,Precompile all needed computations with fake data so as not to include,,Yes,Yes
29514,Correct rotation matrix ordering and move variable dim to axis 0.,,,Yes
29515,Add noises to regularize the density predictions if needed,,,Yes
29517,If no best possible live score is better than current worst finished,,No,Yes
29518,A tuple by convention. len(axes_tuple) then also gives the rank efficiently.,,No,Yes
29520,only needed for masks,,,Yes
29521,TODO(jekbradbury;levskaya): implement sharded native checkpoint\/restore,,Yes,Yes
29522,TODO(jekbradbury;levskaya): implement sharded T5 checkpoint\/restore,,Yes,Yes
29523,Maybe save a checkpoint on one host.,,,Yes
29526,"HACK T5's \""loss_denominator\"" correction for batchsize 2048 * 114 targetlen..",,,Yes
29529,not sure what the fix is; as this seems like the behavior we want in all,,,Yes
29532,"\""\""\""Various constants needed in the solution.\""\""\""",,,Yes
29533,We load the retriever model if it is needed.,,,Yes
29534,that it would probably be helpful to finetune,,,Yes
29535,tasks. Always true for TPUs. Maybe more resistant to weird configurations.,,Yes,Yes
29537,`json.dumps` formats dicts in a nice way when indent is specified.,,,Yes
29540,Equivalent to (but slightly more efficient and stable than):,,,Yes
29541,TODO(barron): Determine why the rays have an unused first dimension.,,Yes,Yes
29542,"r\""\""\""Library for creating different blackbox objects. ||  || Library for creating different blackbox objects providing ways to manipulate || blackbox functions to be optimized (obtaining starting points for their || optimization; executing them and getting metaparameters needed to set || up certain algorithms optimizing them). || \""\""\""",,,Yes
29544,"\""\""\""Plot simple assumptions needed to compute TCE.\""\""\""",,Yes,Yes
29546,if there is no ring buffer then the input_state isn't needed.,,,Yes
29548,This hack of wrapping up multiple train steps with a tf.function call,,Yes,Yes
29549,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
29550,"\""\""\""Implements the multi-agent gather environments. ||  || The agents must pick up (move on top of) items in the environment. || \""\""\""",,,Yes
29551,Remove wall_times data since not needed anymore.,,,Yes
29554,columns) and count the rows with zero added phrases.,,,Yes
29555,Deleted tokens (bracketed by unused) should have a segment_id of 2.,,No,Yes
29556,TODO(team): Check whether deepcopy is needed in other places too.,,Yes,Yes
29559,Grafting is a technique to fix the layerwise scale of Shampoo optimizer.,,Yes,Yes
29560,How often to compute preconditioner. Ideally set both params to 1.,,Yes,Yes
29561,even though it probably should.,,Yes,Yes
29563,flatten columns; adding level names into the flattened column names,,Yes,Yes
29568,workaround.,,,Yes
29570,To implement the fix (only need to modify HPTuner.next_trial):,,,Yes
29571,End of the workaround code,,,Yes
29573,"r\""\""\""Reads in one pair of fastq files and creates a single sstable. ||  || Notes for the Aptamers Manuscript: || The usage description below is accurate. For the flags; the values were pulled || from learning\/config.py (for example: MIN_BASE_QUALITY = 20) and used when || this module was called from our pipeline harness. || This module would be called one time for each pair of fastq files. ||  ||  || Usage: ||  (for actual run; replaced [dir] with an actual directory) ||  || run xxx\/fastq_to_sstable \\ ||  -- --fastq1=[dir]\/R1-TAAGGCGA_S1_R1_001.fastq \\ ||  --fastq2=[dir]\/R1-TAAGGCGA_S1_R2_001.fastq \\ ||  --measurement_id=1 \\ ||  --output_name=[dir]\/count_tables\/2016-07-28T21-16-29.024029\/R1.sstable ||  --alsologtostderr ||  || \""\""\""",,No,Yes
29576,TODO(shoyer): consider filtering the columns we put into Example,,Yes,Yes
29577,"r\""\""\""Run inference on random sequences many times; saving the top results. ||  || This module is designed to run inference on a trained aptamers TF model || to score many sequences and then write out the top scoring sequences to || be used in other analysis. For example; these top predicted sequences || can read in the colab picking sequences in order || to validate the TF model. ||  || This module uses the standard aptamers tensorflow infrastructure to run || the inference. This is the inferer class defined in || learning\/eval_feedforward and described in the Aptamers TensorFlow Doc. ||  || Inference is generally run in batches of sequences; so a MapFlat function || is used to combine the results of interference into a flattened list || of (sequence; score) pairs. (In other words; each map function returns || a list of (sequence; score) pairs and these results are combined into || one list of pairs. Using a standard Map function would result in a || list of lists which is not what we want.) From there; the Top.Of || combiner returns only the top results; sorted by highest score. These || are then written to a text file. ||  || For now; each batch creates its own inferer; causing each map function || to have more overhead. Because of this;batch sizes around the default of || 10000 are performant. Fixing this in the future means converting the || MapFlat to a ParDo and initializing the inferer in start_bundle. || This module runs inference 1 billion times in 50 minutes so it || is sufficient for now ||  || Run locally with: ||  ||   :search_inference -- --flume_exec_mode=UNOPT \\ ||   --target_name='target' \\ ||   --model_dir=xxx \\ ||    --checkpoint_path='model.ckpt-312500' \\ ||    --output_name=xxx\/base30_1B_inference_top2k ||  || \""\""\""",,,Yes
29579,"\""\""\""Library for generating and sampling from aptamer pools. ||  || Aptamers are generated as pandas.DataFrame objects with columns ['sequences'; || 'target_affinity'; 'serum_affinity']. || \""\""\""",,Yes,Yes
29581,unused by validate,,No,Yes
29582,wrapping the chunk allows more efficient garbage collection,,Yes,Yes
29584,padded_attributes; attributes_plus_none are both needed for friend circle,,,Yes
29585,the shape is (batch_size; num_rows; num_columns;,,,Yes
29586,the shape of the kernel is (num_rows; num_columns; num_input_channels;,,Yes,Yes
29588,padded_activation_map has a shape - (num_padded_rows; num_padded_columns),,,Yes
29589,Fix seed for determinism.,,,Yes
29590,Unused. Placeholder zeros for now.,,,Yes
29591,TODO(guom): fix this,,Yes,Yes
29593,not needed from InputOutputCompressionOp.,,Yes,Yes
29595,"\""\""\""Implement a 2-Layer MLP.\""\""\""",,Yes,Yes
29596,not needed for BlockCompressionOp.,,Yes,Yes
29598,improve performance but only generating the number of expert,,,Yes
29600,Add some regularizer to the loss if needed.,,Yes,Yes
29601,A quick hack to get the urllib.request to ignore invalid SSL certs,,,Yes
29602,TODO(unterthiner): ugly hack until the flax API supports constant state,,,Yes
29603,"\""\""\""Library parsing a preprocessing spec. ||  || A preprocessing spec is a list of preprocessing ops separated by '|' that can be || applied sequentially as a preprocessing function. The preprocessing ops are || provided as input. ||  || By convention the preprocessing function operates on dictionaries of features. || Each op can change the dictionary by modifying; adding or removing dictionary || entries. Dictionary entries should be tensors; keys are strings. || The first argument of the op must be named `features` to which the feature || dictionary will be passed. Additional positional and keyword only arguments can || be defined. The processing spec can define values that will passed to those. The || op must return the feature dictionary. ||  || For convenience ops can also operate an tensors of the feature dictionary || directly. In this case they must accept the names of the tensors (one or || multiple of _FEATURE_TENSORS} and return values for all input tensors. ||  || Example spec: 'fn1|fn2(3)|fn3(keyword=5)' || This will construct the following preprocessing function: || def preprocess_fn(features: Dict[str; tf.Tensor]) -> Dict[str; tf.Tensor]: ||   features = fn1(features) ||   features = fn2(features; 3) ||   features = fn3(features; keyword=5) ||   return features ||  || WARNING: Do not use decorators when defining ops. || \""\""\""",,Yes,Yes
29604,TODO when running on server; send this off to a different thread,,,Yes
29608,TODO: Matplotlib can't do dates of histograms.,,,Yes
29609,TODO when running on server; send this off to a different thread,,,Yes
29611,TODO: Matplotlib can't do dates of histograms.,,No,Yes
29614,TODO: These calls should be merged,,Yes,Yes
29615,TODO: should be done in the template,,No,Yes
29619,TODO: Matplotlib can't do histograms of dates.,,No,Yes
29624,The dropna() is a workaround for https:\/\/github.com\/pydata\/pandas\/issues\/13098,,,Yes
29625,TODO: These calls should be merged,,Yes,Yes
29626,TODO when running on server; send this off to a different thread,,Yes,Yes
29627,TODO Think about writing this to disk instead of caching them in strings,,,Yes
29628,The dropna() is a workaround for https:\/\/github.com\/pydata\/pandas\/issues\/13098,,No,Yes
29629,TODO: These calls should be merged,,Yes,Yes
29632,TODO: Shall not be computed several times,,No,Yes
29633,TODO: replace by a more compact notation,,,Yes
29634,TODO: replace by a more compact notation,,,Yes
29642,TODO: should be done in the template,,,Yes
29643,Fix #68; this call is not needed and brings side effects in some use cases,,No,Yes
29645,The dropna() is a workaround for https:\/\/github.com\/pydata\/pandas\/issues\/13098,,,Yes
29646,TODO: These calls should be merged,,Yes,Yes
29647,TODO when running on server; send this off to a different thread,,Yes,Yes
29650,TODO: should be done in the template,,,Yes
29652,TODO: Should improve verification when a categorical or numeric field has 3 values; it could be a categorical,,,Yes
29653,"TODO: Numeric with low Distinct count should be treated as \""Categorical\""",,,Yes
29656,TODO: find a more reliable way to find highly correlated variables; as corr(x;y) > 0.9 and corr(y;z) > 0.9 does,,,Yes
29658,TODO: fix infinite logic,,Yes,Yes
29659,TODO: check if we prefer without nan,,No,Yes
29663,TODO: move to for loop in template,,No,Yes
29664,TODO: obtain from messages (ignore),,Yes,Yes
29665,TODO: rename alert to prevent overlap with bootstrap classes,,No,Yes
29666,TODO: move histograms here,,Yes,Yes
29667,TODO: should be done in the template,,No,Yes
29671,Create separate columns for each URL part,,,Yes
29672,TODO: n - missing,,Yes,Yes
29674,"\""\""\""Functionality related to displaying the profile report in Jupyter notebooks.\""\""\""",,,Yes
29675,TODO: deep=True?,,Yes,Yes
29676,Create separate columns for each path part,,Yes,Yes
29679,TODO: solve in type system,,Yes,Yes
29681,Workaround for https:\/\/github.com\/pandas-dev\/pandas\/issues\/17372,,,Yes
29682,Hack https:\/\/stackoverflow.com\/questions\/44666207\/matplotlib-error-when-running-plotting-in-multiprocess,,Yes,Yes
29683,TODO: use matrix logic,,No,Yes
29685,TODO: resize width of progress bar \/ label,,Yes,Yes
29687,TODO: Correctly sort missing and other,,No,Yes
29688,Hack for tables with combined...,,Yes,Yes
29689,TODO: should be in cast?,,,Yes
29692,TODO: move to render,,No,Yes
29694,TODO: settings 3;3;6,,,Yes
29699,TODO: in SequeencyItem,,,Yes
29700,TODO: add dropdown to switch to specific values,,Yes,Yes
29702,TODO: merge with boolean\/categorical,,No,Yes
29703,TODO: settings 3;3;6,,No,Yes
29704,TODO: find a more reliable way to find highly correlated variables; as corr(x;y) > 0.9 and corr(y;z) > 0.9 does,,No,Yes
29706,TODO: move to structure,,No,Yes
29707,TODO: render in template,,,Yes
29708,TODO: render in template,,No,Yes
29709,TODO: move to render,,No,Yes
29711,TODO: move to render,,,Yes
29712,TODO: render in template,,No,Yes
29713,TODO: move to render,,No,Yes
29714,TODO: render in template,,No,Yes
29715,TODO: move to render,,No,Yes
29717,TODO: render in template,,No,Yes
29719,TODO: move to render,,No,Yes
29721,Drop rows and columns with NaNs,,,Yes
29722,TODO: use `Pool` for Linux-based systems,,Yes,Yes
29724,save df; compute when needed,,,Yes
29725,[description_set; report] will compute when needed,,Yes,Yes
29726,TODO: fix infinite logic,,,Yes
29729,TODO: use `Pool` for Linux-based systems,,Yes,Yes
29731,Create separate columns for each URL part,,Yes,Yes
29732,Create separate columns for each path part,,Yes,Yes
29736,TODO: use visions for type inference,,No,Yes
29737,Get supported columns,,,Yes
29739,Create separate columns for each path part,,Yes,Yes
29741,TODO: use `Pool` for Linux-based systems,,,Yes
29745,TODO: move to structure,,No,Yes
29746,TODO: move to report structure,,No,Yes
29747,Ensure that columns are strings,,Yes,Yes
29748,Get supported columns,,Yes,Yes
29750,TODO: move to report structure,,No,Yes
29751,Author: Peter Odding <peter@peterodding.com>,,Yes,Yes
29752,TODO: logging instead of warning,,No,Yes
29754,Get supported columns,,Yes,Yes
29755,TODO: move to structure,,,Yes
29756,TODO: move to report structure,,No,Yes
29759,TODO: make functional,,,Yes
29761,We can fix these issues and then continue exploring our data in more depth!,,No,Yes
29765,Intersection (some columns are not used in correlation),,,Yes
29767,TODO: preprocess (stopwords),,No,Yes
29768,TODO: configurable lowercase\/punctuation etc.,,,Yes
29770,TODO: Add informative caption,,No,Yes
29773,Workaround pending release https:\/\/github.com\/dylan-profiler\/visions\/issues\/162,,Yes,Yes
29774,Or write directly as expectation suite json in GE,,,Yes
29775,The AUC should be no better than random,,Yes,Yes
29776,accuracy should be no better than,,,Yes
29780,FIXME: add CUDNN,,No,Yes
29781,FIXME: this is the result of a double bug,,Yes,Yes
29783,FIXME: no multinomial on GPU?,,,Yes
29791,FIXME: per timestep?,,,Yes
29792,TODO. Make this a private method.,,Yes,Yes
29796,FIXME,,Yes,Yes
29797,FIXME: randomize,,Yes,Yes
29798,FIXME,,Yes,Yes
29800,FIXME,,,Yes
29801,this gives really bad initialization; Xavier better,,Yes,Yes
29802,FIXME,,,Yes
29803,FIXME volatile,,,Yes
29804,FIXME: randomize,,,Yes
29805,this gives really bad initialization; Xavier better,,Yes,Yes
29806,FIXME volatile,,,Yes
29811,FIXME,,Yes,Yes
29813,(3) maybe update the learning rate,,No,Yes
29814,(3) maybe update the learning rate,,No,Yes
29816,TODO: Fix this!,,Yes,Yes
29817,TODO: Fix this!,,Yes,Yes
29818,Hack to get around log.,,,Yes
29820,Drop the lengths needed for encoder.,,,Yes
29822,Drop the lengths needed for encoder.,,Yes,Yes
29823,fix me!,,,Yes
29824,HACK. PyTorch is changing behavior,,,Yes
29827,a temporary fix at least,,,Yes
29828,2) maybe do some extra things if verbose,,Yes,Yes
29830,TODO: context gate,,No,Yes
29831,TODO: context_gate; coverage and copy,,Yes,Yes
29834,TODO: copy,,No,Yes
29835,TODO: copy,,No,Yes
29837,TODO finish this.,,,Yes
29838,HACK: collect source feature vocabs.,,Yes,Yes
29839,TODO: This is bit hacky remove.,,Yes,Yes
29840,Hack. Can't pickle defaultdict :(,,Yes,Yes
29843,HACK: collect source feature vocabs.,,Yes,Yes
29847,Pass in needed options only when modify function definition.,,Yes,Yes
29848,TODO finish this.,,,Yes
29851,Temporary kludge solution to handle changed dim expectation,,,Yes
29852,Set up a separated copy attention layer; if needed.,,,Yes
29853,Set up a separated copy attention layer; if needed.,,Yes,Yes
29855,TODO: copy,,No,Yes
29859,Set up a separated copy attention layer; if needed.,,,Yes
29862,TODO: replace for loop with masking or boolean indexing,,,Yes
29864,TODO: replace for loop with masking or boolean indexing,,Yes,Yes
29866,could; and perhaps should; be moved outside the class definition).,,Yes,Yes
29867,Hack. Can't pickle defaultdict :(,,Yes,Yes
29868,TODO finish this.,,Yes,Yes
29870,TODO finish this.,,Yes,Yes
29871,hack for python2\/3 compatibility,,,Yes
29872,"\""\""\""Use byte pair encoding (BPE) to learn a variable-length encoding of the vocabulary in a text. || Unlike the original BPE; it does not compress the plain text; but can be used to reduce the vocabulary || of a text to a configurable number of symbols; with only a small increase in the number of tokens. ||  || Reference: || Rico Sennrich; Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units. || Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin; Germany. || \""\""\""",,,Yes
29875,TODO finish this.,,Yes,Yes
29877,Pass in needed options only when modify function definition.,,Yes,Yes
29878,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
29882,too much memory. A lazy load would be better; but later,,,Yes
29884,too much memory. A lazy load would be better; but later,,No,Yes
29885,too much memory. A lazy load would be better; but later,,,Yes
29888,TODO: fix for pytorch 0.3,,,Yes
29889,perhaps be changed.,,Yes,Yes
29892,4. Drop a checkpoint if needed.,,,Yes
29893,this hack enables to run an empty batch so that the number of processes,,,Yes
29894,this one is needed for torchtext random call (shuffled iterator),,,Yes
29896,4. Drop a checkpoint if needed.,,Yes,Yes
29899,TODO if no GPU device_id = -1,,Yes,Yes
29901,TODO change the way attns is returned dict => list or tuple (onnx),,No,Yes
29902,TODO change the way attns is returned dict => list or tuple (onnx),,,Yes
29903,TODO change the way attns is returned dict => list or tuple (onnx),,No,Yes
29904,reads in the whole corpus. Shards should be efficient at training time;,,,Yes
29905,This is a hack. Something is broken with torch pickle.,,Yes,Yes
29913,TODO: clean this up when APEX unify its optimizer API.,,No,Yes
29915,(in the future this will be done in a smarter way),,,Yes
29916,hack to dodge unpicklable `dict_keys`,,,Yes
29917,this is a hack,,No,Yes
29918,(in the future this will be done in a smarter way),,,Yes
29919,hack to dodge unpicklable `dict_keys`,,,Yes
29922,Pretend it ends with a full stop so last span is a sentence,,No,Yes
29923,TODO why?,,,Yes
29925,fix length constraint,,,Yes
29926,maybe fix some prediction at this step by modifying log_probs,,,Yes
29927,Fix CPU tensor sharing strategy,,Yes,Yes
29929,maybe prepare pretrained embeddings; if any,,,Yes
29930,this is a hack: appears quicker to apply it here,,,Yes
29931,this is a hack,,No,Yes
29934,NOTE: stride (if needed) is handled at the,,,Yes
29935,Move batch to correspond device_id when consumer iterate,,,Yes
29936,hack to dodge unpicklable `dict_keys`,,,Yes
29937,This one is needed for various tranfroms,,No,Yes
29941,hack [min_len_batch-1:] because expect <bos>,,,Yes
29943,only output label map if needed to save bandwidth,,,Yes
29944,Apparently; politicians from states further away from Distrito Federal expent more. We could perform an analysis on distance to the capital and the home state from the politician.,,Yes,Yes
29947,TODO: CREATE DISTINCTS MESSAGES ERROS FOR THE API RESULTS,,,Yes
29951,http:\/\/stackoverflow.com\/questions\/14507794\/python-pandas-how-to-flatten-a-hierarchical-index-in-columns,,Yes,Yes
29952,We can conclude that 5 hundred is indeed highly above average for this supplier (maybe not enough to really be suspicious? There is knobs available at `suspicious_predicate` that may be improved). Also note that we have different supplier names related to the same company social ID (CNPJ).,,,Yes
29953,Should we believe this algorithm is well implemented?,,,Yes
29955,In the Chamber of Deputies' CEAP; there is a list of 1;000's of meal expenses made by congresspeople. The law says that the congressperson cannot pay for any other; even being her advisor or SO. We want to work on this analysis to find possibly illegal and immoral expenses. They may have happened when the politician spent more than needed (e.g. the whole menu costs X but the bill was 2X) or too much in an specific period of time. In the end; we also want to alert about too expensive reibursements; even with an explanation behind of it.,,,Yes
29957,What if we could improve it using the type of business as a feature? e.g. restaurant; hotel; grill...,,Yes,Yes
29959,"Since there's \""significant data\"" just for 4% of the companies; we need a way for extrapolating the results for not so known ones. For doing so; we classify companies in 3 clusters using K-Means; considering mean and standard deviation of their prices as features. Once classified; we consider their threshold mean + 4 * stds of their clusters (one extra std compared to places where we have enough reimbursements to know better).",,Yes,Yes
29961,Setting companies situation_date and reimbursements issue_date columns to correct date format; and set the cpnj to a format without dash and dots.,,Yes,Yes
29962,The data is available in csv format: one csv file per state; grouped in one zip file per year. Some of the csv files from TSE contain headers. Unfortunately; this is not the case for the files we are dealing with here. For different years there are different numbers of columns; and consequently; different headers.,,Yes,Yes
29963,In this script; after downloading the files; we appropriately name the columns and select a useful subsample of columns to export for future use in Serenata Project.,,Yes,Yes
29966,In this script; after downloading the files; we appropriately name the columns and select a useful subsample of columns to export for future use in Serenata Project.,,,Yes
29967,We select 11 columns that contains relevant information for the purpose of this script. When encoded and explicit information are avaiable; we choosed explicit information; because we do not rely on their encoding. There is no guarantee that they keep the same encoding along the years. Besides; it is easier to identify when the columns get mixed due to import errors.,,Yes,Yes
29970,Creates a DataFrame copy with fewer columns,,,Yes
29976,Removes useless columns,,,Yes
29977,First we need to check if both datasets have the same columns; even in they are in the same order:,,Yes,Yes
29978,We can also make sure they have the same types for all columns,,,Yes
29980,The result above got me wondering where were those 200 statuses code we've seen before. I tested the code on the command line and they are there. So a little reasearch and I found that apparently it is not possible to run async tasks easily on a jupyter notebook [ref](http:\/\/ipywidgets.readthedocs.io\/en\/latest\/examples\/Widget%20Asynchronous.html).,,No,Yes
29981,TODO: Also filter by status_code,,No,Yes
29983,Based on those results; if we ever want to implement any of this logic in Rosie; the initial focus should be on teaching her about the Presences \/ Session Start Times datasets alongside the receipts OCR. The accuracy of that combo is the one that is more likely to return good suspicious.,,Yes,Yes
29985,The idea of this notebook is to offer an overview of congresspeople expenses with consultancies. It's simpler than a proper exploratory analysis; but I hope this help and encourage more analysis related to this subquota.,,,Yes
29988,Add hook for building doxygen xml when needed,,No,Yes
29990,TODO: fill me in,,No,Yes
29991,ToDo: Some of the tensorflow operators internaly maintain,,Yes,Yes
29993,(TODO) type?,,No,Yes
29994,hacky - we should explore a more future-proof way to,,Yes,Yes
29995,TODO cfg is not used for now,,,Yes
29997,This is needed because the pre-activation variant does not have batch,,Yes,Yes
29998,Resize and crop if needed.,,,Yes
30000,TODO: Come up with a better way to generate scope names,,No,Yes
30002,TODO: This method is needed because the current,,No,Yes
30004,TODO: Investigate if instead the function should return None if,,,Yes
30006,TODO: add_summaries is currently unused. Respect that directive,,No,Yes
30007,TODO: add_summaries is currently unused. Respect that directive,,,Yes
30010,Follow the convention by adding back the batch dimension,,No,Yes
30012,Follow the convention by adding back the batch dimension,,,Yes
30013,TODO Crop the box an run the position classifier,,,Yes
30014,TODO: How to handle this case? Is an empty classification acceptable? I think it is better than a fixed (and potentially misleading or incorrect classification; such as S3).,,Yes,Yes
30015,TODO add time index instead of time.time() to bid; ask; buy; sell orders,,Yes,Yes
30017,TODO: Fix axis labels and Title.  Commented out below.  Fail as is.,,No,Yes
30019,implement copy on buyers,,,Yes
30020,implement copy on sellers,,,Yes
30021,fix row to seller,,Yes,Yes
30022,implement replace buttons,,Yes,Yes
30023,implement replace on buyers,,No,Yes
30024,implement replace on sellers,,,Yes
30025,TODO:  Add existing file check,,Yes,Yes
30026,TODO:  Save period data file,,No,Yes
30031,self.sup_units = 0  # TODO change to demand units and supply units,,Yes,Yes
30032,self.string_sup_units = tk.StringVar()  # TODO if ^todo is agreed then will need to reformat code,,Yes,Yes
30034,TODO change file path,,Yes,Yes
30037,TODO check files and create new one,,Yes,Yes
30041,implement replace on sellers,,No,Yes
30043,appends all ends in temp dict to global dict,,,Yes
30044,TODO fix to fit with operation in spot_system (line 64),,,Yes
30045,best bid has improved,,Yes,Yes
30046,best ask has improved -- NB doesn't check if the improvement was by self,,,Yes
30048,created to make info enter table plot as columns,,Yes,Yes
30049,used to create columns in data plot,,Yes,Yes
30053,TODO look at problems of np.arrays in regular dictionaries... better if np.array(np.array)?,,Yes,Yes
30054,best bid has improved,,Yes,Yes
30055,best ask has improved -- NB doesn't check if the improvement was by self,,Yes,Yes
30059,TODO change out existing code for better code below,,Yes,Yes
30063,TODO fix spot_system or d_a_institution to allow ZIP memory,,Yes,Yes
30065,'''Below algorithm uses one dataset of bid\/ask values... || ... uses half the dataset to train; then predicts the other half || ... generates about 82% correct predictions''',,Yes,Yes
30066,TODO see if it would be possible to employ this algorithm to shock markets to equilibrium,,Yes,Yes
30068,TODO add this info to report.orders so can use in AI,,Yes,Yes
30069,TODO split into periods etc then build AI Trader,,,Yes
30074,TODO this needs to be changed to None etc.,,,Yes
30075,TODO discuss expected profit calculation,,,Yes
30076,TODO add in market shocks here,,No,Yes
30077,TODO fix ZIP response to not be hard coded... need values and type,,,Yes
30079,TODO: potential error in seller's strategy... look at most calculation,,,Yes
30080,TODO change these to your file path,,Yes,Yes
30082,TODO trader shocks happen below,,,Yes
30084,TODO round shocks happen below,,Yes,Yes
30085,TODO will be moved to tkinter dialog box,,No,Yes
30086,TODO change these to your file path,,,Yes
30087,TODO add in process to run spot_market_period,,Yes,Yes
30088,TODO create ability to save work anywhere on the computer,,No,Yes
30089,TODO:  Add existing file check,,,Yes
30090,TODO create way to automate input of trader # and strategies,,Yes,Yes
30091,TODO trader shocks happen below,,,Yes
30092,TODO period shocks happen below,,No,Yes
30093,tODO look into how trader efficiency is calculated.. should it be earns\/maxsurplus or totalearns\/surplus,,Yes,Yes
30095,TODO can it be +-?,,,Yes
30097,TODO:  Add existing file check,,,Yes
30099,TODO see if it would be possible to employ this algorithm to shock markets to equilibrium,,,Yes
30100,TODO build AI_trader that uses this algorithm to place better bids\/asks,,Yes,Yes
30102,TODO throwing error here... without self throws a reference error... with self throws type error,,,Yes
30103,TODO change these to your file path,,Yes,Yes
30105,TODO keep working on this root window!,,Yes,Yes
30106,TODO create way to automate input of trader # and strategies,,,Yes
30107,TODO trader shocks happen below,,,Yes
30108,TODO period shocks happen below,,No,Yes
30111,TODO change these to your file path,,,Yes
30113,implement copy button,,,Yes
30115,implement copy on sellers,,,Yes
30120,TODO is trader's max value still the 1st if no trade?,,,Yes
30123,TODO will be moved to tkinter dialog box,,,Yes
30127,TODO change file path,,Yes,Yes
30129,'''Below are global dictionaries that will contain information needed to execute several functions''',,No,Yes
30131,appends all ends in temp dict to global dict,,,Yes
30132,dictionary of period ends; will be used in plotting,,No,Yes
30135,TODO create way to automate input of trader # and strategies,,Yes,Yes
30137,TODO period shocks happen below,,No,Yes
30139,move to where strategy results are,,No,Yes
30140,TODO: potential error in seller's strategy... look at most calculation,,Yes,Yes
30141,best bid has improved,,Yes,Yes
30142,best ask has improved -- NB doesn't check if the improvement was by self,,,Yes
30143,trade happened and best ask price has got worse; or stayed same but quantity reduced -- assume previous best ask was lifted,,Yes,Yes
30144,self.updateEq(price)  #TODO allow equilibrium updating or no?,,,Yes
30145,TODO write error... generating extra value in excel and json files....??,,,Yes
30146,TODO getting json decode error here,,No,Yes
30148,TODO:  Add existing file check,,Yes,Yes
30152,TODO add link to github readme in display_help_messagebox,,No,Yes
30153,TODO can add this into mkt_root somehow...,,,Yes
30154,TODO need to simplify list to abbreviations?,,Yes,Yes
30157,TODO need to finish this up,,Yes,Yes
30158,TODO use same process to obtain market shocks set in market_gui!,,,Yes
30159,ends period timer,,No,Yes
30160,TODO add the tk.label information below to a json file so information can be saved to period data,,Yes,Yes
30161,TODO delete temp folder of mini images or no?,,Yes,Yes
30162,TODO need to generalize code to num sellers and num buyers,,,Yes
30163,TODO fill in with descriptions of each strategy.. maybe include link or ref to paper?,,Yes,Yes
30164,hold for user to fix parameter errors,,,Yes
30165,TODO needs to be a way to refresh combobox values if user creates new file in market_gui,,,Yes
30166,TODO add error check for p shock > num periods,,,Yes
30168,TODO add error check for r shock > num shocks,,No,Yes
30169,TODO add these shocks to run_sim(),,Yes,Yes
30170,TODO calculations below for Smith's Equilibrium Convergence Alphas will need to be checked,,Yes,Yes
30171,TODO IMPORTANT: need to clear contract list in spot system or double auction institution...,,No,Yes
30172,--> maybe clearing lists in run_sim() or spot_market_period?,,,Yes
30174,TODO IMPORTANT: add round and period shocks into run_sim()...,,No,Yes
30175,TODO IMPORTANT: fix tkinter error after sim run...,,,Yes
30176,TODO OPTIONAL: add ability for all info to be stored in json files...,,Yes,Yes
30177,TODO update the data input by tf.data,,,Yes
30180,TODO update the data input by tf.data,,,Yes
30181,Declare how many steps are needed in an iteration,,Yes,Yes
30182,would be a nice idea if the Upsampling could be learned too;,,Yes,Yes
30183,The multiple of 64 is needed to ensure smooth scaling of feature,,,Yes
30184,Improve performance by trimming to top anchors by score,,,Yes
30187,TODO: Rename target_bbox to target_deltas for clarity,,No,Yes
30190,TODO: Update this line to work with batch > 1. Right now it assumes all,,Yes,Yes
30192,TODO: To hard example mine or not to hard example mine; that's the question,,Yes,Yes
30193,For positive anchors; compute shift and scale needed to transform them,,No,Yes
30194,TODO: use box_refinement() rather than duplicating the code here,,,Yes
30197,TODO: verify that this handles zero padded ROIs,,Yes,Yes
30199,TODO: remove in about 6 months (end of 2018),,,Yes
30200,Work-around for Windows: Keras fails on Windows when using,,Yes,Yes
30201,TODO: move resizing to mold_image(),,,Yes
30202,TODO: Remove this after the notebook are refactored to not use it,,No,Yes
30203,TODO: Build and use this function to reduce code duplication,,Yes,Yes
30205,In the long run; it's more efficient to modify the code to support large,,,Yes
30206,TODO: Replace with matplotlib equivalent?,,,Yes
30208,Get relevant graph operations or nodes needed for training,,,Yes
30210,Create the top data if needed,,,Yes
30211,TODO: Estimate and rescale the values [TODO: Record and undo this scaling above],,Yes,Yes
30212,If we diverge by a factor of exp(0.25) = ~1.3; then we should check if the network is really,,,Yes
30215,convert RGB to BGR convention,,Yes,Yes
30217,convert BGR to RGB convention,,,Yes
30218,convert RGB to BGR convention,,,Yes
30220,convert BGR to RGB convention,,,Yes
30221,convert BGR to RGB convention,,Yes,Yes
30222,convert BGR to RGB convention,,Yes,Yes
30224,convert RGB to BGR convention,,,Yes
30226,convert RGB to BGR convention,,Yes,Yes
30227,convert BGR to RGB convention,,,Yes
30228,convert RGB to BGR convention,,Yes,Yes
30232,TODO Update this to one to many relation,,Yes,Yes
30233,TODO Send the face id to server here.,,,Yes
30236,TODO Send the face id to server here.,,Yes,Yes
30237,TODO Implement this,,,Yes
30239,TODO(bichen): fix the hard-coded data type below,,,Yes
30240,FIXME: doesn't work if chained directly to submit(). bug in futures? reproduce and submit report.,,No,Yes
30241,fix corr calculation bug,,,Yes
30242,Move straight down under velocity control.,,,Yes
30244,Move straight down under velocity control.,,Yes,Yes
30245,Move back up to initial position.,,,Yes
30246,Move the added items to the front of the path:,,No,Yes
30247,"\""\""\""Append module search paths for third-party packages to sys.path. ||  || **************************************************************** || * This module is automatically imported during initialization. * || **************************************************************** ||  || In earlier versions of Python (up to 1.5a3); scripts or modules that || needed to use site-specific modules would place ``import site'' || somewhere near the top of their code.  Because of the automatic || import; this is no longer necessary (but code that does it still || works). ||  || This will append site-specific paths to the module search path.  On || Unix; it starts with sys.prefix and sys.exec_prefix (if different) and || appends lib\/python<version>\/site-packages as well as lib\/site-python. || It also supports the Debian convention of || lib\/python<version>\/dist-packages.  On other platforms (mainly Mac and || Windows); it uses just sys.prefix (and sys.exec_prefix; if different; || but this is unlikely).  The resulting directories; if they exist; are || appended to sys.path; and also inspected for path configuration files. ||  || FOR DEBIAN; this sys.path is augmented with directories in \/usr\/local. || Local addons go into \/usr\/local\/lib\/python<version>\/site-packages || (resp. \/usr\/local\/lib\/site-python); Debian addons install into || \/usr\/{lib;share}\/python<version>\/dist-packages. ||  || A path configuration file is a file whose name has the form || <package>.pth; its contents are additional directories (one per line) || to be added to sys.path.  Non-existing directories (or || non-directories) are never added to sys.path; no directory is added to || sys.path more than once.  Blank lines and lines beginning with || '#' are skipped. Lines starting with 'import' are executed. ||  || For example; suppose sys.prefix and sys.exec_prefix are set to || \/usr\/local and there is a directory \/usr\/local\/lib\/python2.X\/site-packages || with three subdirectories; foo; bar and spam; and two path || configuration files; foo.pth and bar.pth.  Assume foo.pth contains the || following: ||  ||   # foo package configuration ||   foo ||   bar ||   bletch ||  || and bar.pth contains: ||  ||   # bar package configuration ||   bar ||  || Then the following directories are added to sys.path; in this order: ||  ||   \/usr\/local\/lib\/python2.X\/site-packages\/bar ||   \/usr\/local\/lib\/python2.X\/site-packages\/foo ||  || Note that bletch is omitted because it doesn't exist; bar precedes foo || because bar.pth comes alphabetically before foo.pth; and spam is || omitted because it is not mentioned in either path configuration file. ||  || After these path manipulations; an attempt is made to import a module || named sitecustomize; which can perform arbitrary additional || site-specific customizations.  If this import fails with an || ImportError exception; it is silently ignored. ||  || \""\""\""",,Yes,Yes
30250,Move the added items to the front of the path:,,No,Yes
30251,"\""\""\""Append module search paths for third-party packages to sys.path. ||  || **************************************************************** || * This module is automatically imported during initialization. * || **************************************************************** ||  || In earlier versions of Python (up to 1.5a3); scripts or modules that || needed to use site-specific modules would place ``import site'' || somewhere near the top of their code.  Because of the automatic || import; this is no longer necessary (but code that does it still || works). ||  || This will append site-specific paths to the module search path.  On || Unix; it starts with sys.prefix and sys.exec_prefix (if different) and || appends lib\/python<version>\/site-packages as well as lib\/site-python. || It also supports the Debian convention of || lib\/python<version>\/dist-packages.  On other platforms (mainly Mac and || Windows); it uses just sys.prefix (and sys.exec_prefix; if different; || but this is unlikely).  The resulting directories; if they exist; are || appended to sys.path; and also inspected for path configuration files. ||  || FOR DEBIAN; this sys.path is augmented with directories in \/usr\/local. || Local addons go into \/usr\/local\/lib\/python<version>\/site-packages || (resp. \/usr\/local\/lib\/site-python); Debian addons install into || \/usr\/{lib;share}\/python<version>\/dist-packages. ||  || A path configuration file is a file whose name has the form || <package>.pth; its contents are additional directories (one per line) || to be added to sys.path.  Non-existing directories (or || non-directories) are never added to sys.path; no directory is added to || sys.path more than once.  Blank lines and lines beginning with || '#' are skipped. Lines starting with 'import' are executed. ||  || For example; suppose sys.prefix and sys.exec_prefix are set to || \/usr\/local and there is a directory \/usr\/local\/lib\/python2.X\/site-packages || with three subdirectories; foo; bar and spam; and two path || configuration files; foo.pth and bar.pth.  Assume foo.pth contains the || following: ||  ||   # foo package configuration ||   foo ||   bar ||   bletch ||  || and bar.pth contains: ||  ||   # bar package configuration ||   bar ||  || Then the following directories are added to sys.path; in this order: ||  ||   \/usr\/local\/lib\/python2.X\/site-packages\/bar ||   \/usr\/local\/lib\/python2.X\/site-packages\/foo ||  || Note that bletch is omitted because it doesn't exist; bar precedes foo || because bar.pth comes alphabetically before foo.pth; and spam is || omitted because it is not mentioned in either path configuration file. ||  || After these path manipulations; an attempt is made to import a module || named sitecustomize; which can perform arbitrary additional || site-specific customizations.  If this import fails with an || ImportError exception; it is silently ignored. ||  || \""\""\""",,,Yes
30252,XXX This should not be part of site.py; since it is needed even when,,Yes,Yes
30254,Move the added items to the front of the path:,,No,Yes
30255,"\""\""\""Append module search paths for third-party packages to sys.path. ||  || **************************************************************** || * This module is automatically imported during initialization. * || **************************************************************** ||  || In earlier versions of Python (up to 1.5a3); scripts or modules that || needed to use site-specific modules would place ``import site'' || somewhere near the top of their code.  Because of the automatic || import; this is no longer necessary (but code that does it still || works). ||  || This will append site-specific paths to the module search path.  On || Unix; it starts with sys.prefix and sys.exec_prefix (if different) and || appends lib\/python<version>\/site-packages as well as lib\/site-python. || It also supports the Debian convention of || lib\/python<version>\/dist-packages.  On other platforms (mainly Mac and || Windows); it uses just sys.prefix (and sys.exec_prefix; if different; || but this is unlikely).  The resulting directories; if they exist; are || appended to sys.path; and also inspected for path configuration files. ||  || FOR DEBIAN; this sys.path is augmented with directories in \/usr\/local. || Local addons go into \/usr\/local\/lib\/python<version>\/site-packages || (resp. \/usr\/local\/lib\/site-python); Debian addons install into || \/usr\/{lib;share}\/python<version>\/dist-packages. ||  || A path configuration file is a file whose name has the form || <package>.pth; its contents are additional directories (one per line) || to be added to sys.path.  Non-existing directories (or || non-directories) are never added to sys.path; no directory is added to || sys.path more than once.  Blank lines and lines beginning with || '#' are skipped. Lines starting with 'import' are executed. ||  || For example; suppose sys.prefix and sys.exec_prefix are set to || \/usr\/local and there is a directory \/usr\/local\/lib\/python2.X\/site-packages || with three subdirectories; foo; bar and spam; and two path || configuration files; foo.pth and bar.pth.  Assume foo.pth contains the || following: ||  ||   # foo package configuration ||   foo ||   bar ||   bletch ||  || and bar.pth contains: ||  ||   # bar package configuration ||   bar ||  || Then the following directories are added to sys.path; in this order: ||  ||   \/usr\/local\/lib\/python2.X\/site-packages\/bar ||   \/usr\/local\/lib\/python2.X\/site-packages\/foo ||  || Note that bletch is omitted because it doesn't exist; bar precedes foo || because bar.pth comes alphabetically before foo.pth; and spam is || omitted because it is not mentioned in either path configuration file. ||  || After these path manipulations; an attempt is made to import a module || named sitecustomize; which can perform arbitrary additional || site-specific customizations.  If this import fails with an || ImportError exception; it is silently ignored. ||  || \""\""\""",,,Yes
30256,XXX This should not be part of site.py; since it is needed even when,,,Yes
30259,TODO: need to capture the metadata,,,Yes
30260,TODO: fix the way i'm doing tagging,,No,Yes
30261,TODO: Need to add meaningful label\/prediction column names,,,Yes
30262,TODO: need to deal with errors here,,,Yes
30263,TODO: what all do we expect to be here?,,,Yes
30264,TODO: Define get_experiment run,,,Yes
30265,should I fix this?,,Yes,Yes
30267,TODO: increase speed by removing for loop,,No,Yes
30271,TODO: set background to zero after resampling,,Yes,Yes
30274,TODO: crop data to the smallest shape image that contains all of the original data,,,Yes
30275,TODO: fix bounds,,No,Yes
30276,must be a better way :\\,,No,Yes
30278,TODO: change to output shape,,,Yes
30279,TODO: remove hardcoded quantization number :(,,No,Yes
30281,TODO: check if clip=True really needed,,No,Yes
30283,"add \"".gz\"" extension if needed",,,Yes
30284,TODO: change to output shape,,No,Yes
30286,TODO: figure out why this happens.,,,Yes
30287,TODO: See https:\/\/www.pyimagesearch.com\/2017\/05\/22\/face-alignment-with-opencv-and-python\/,,Yes,Yes
30290,TODO dropout,,Yes,Yes
30292,fix the ELMo,,Yes,Yes
30293,fix the ELMo,,Yes,Yes
30297,TODO: finish exporting the style modifications into a stylesheet,,,Yes
30301,drop unwanted columns; and rename the column name appropriately.,,Yes,Yes
30302,Feature columns describe how to use the input.,,No,Yes
30303,get needed merge det and delete these det,,,Yes
30304,get needed merge det and delete these det,,Yes,Yes
30307,get needed merge det and delete these det,,Yes,Yes
30308,get needed merge det and delete these det,,Yes,Yes
30309,get needed merge det and delete these det,,,Yes
30312,get needed merge det and delete these det,,Yes,Yes
30317,If needed; alert that TowerOptimizer needs to be used with model_fn.,,,Yes
30318,couldn't find better way to pass params from input_fn to model_fn,,Yes,Yes
30320,couldn't find better way to pass params from input_fn to model_fn,,,Yes
30321,couldn't find better way to pass params from input_fn to model_fn,,,Yes
30322,couldn't find better way to pass params from input_fn to model_fn,,Yes,Yes
30323,couldn't find better way to pass params from input_fn to model_fn,,Yes,Yes
30324,couldn't find better way to pass params from input_fn to model_fn,,,Yes
30327,(2) Blank lines between documents. Document boundaries are needed so,,,Yes
30328,The convention in BERT is:,,No,Yes
30329,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
30330,The convention in BERT is:,,No,Yes
30331,"What we really want to return is \""Steve Smith\"".",,No,Yes
30332,TODO: Check why terminal does not display this order,,No,Yes
30333,ends up being fed with all '1' examples followed by all '0' examples.,,No,Yes
30334,TODO: Finish documenting function,,,Yes
30335,TODO: check for invalid pooler_type,,,Yes
30336,in this matrix rows are documents; columns - features (terms' tfidf's),,No,Yes
30337,TODO: Would be slightly faster if we called step on the entire context;,,Yes,Yes
30340,XXX This should not be part of site.py; since it is needed even when,,Yes,Yes
30342,TODO: Extract picks from pdf,,Yes,Yes
30343,TODO: Extract picks from pdf,,Yes,Yes
30344,### THIS ONE NEEDS EDITING AS IT REQUIRES ARGUMENTS THAT MAY NOT BE NEEDED LIKE THIS????????,,,Yes
30345,"print(\""wells with needed curves list real\"";wellsWithNeededCurvesList_real)",,Yes,Yes
30348,### Note: these need to be in this order as we'll assume the second one will be written as 'HorID_x' by pandas as two columns can't have the same name,,,Yes
30349,"print(\""HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\"";wells_df_from_split.columns)",,No,Yes
30350,############### exclude any we're not going to use for not having the needed tops and curves. ###################,,No,Yes
30352,################ 6 and 7 in the functions below are the 6th and 7th columns... should replace with something more obvious!!!!! ##################,,,Yes
30353,Find thickness of unit in neighboring wells in training dataset. Subtract that thickness from the base pick depth in the well we're going to predict for to find where that top pick would be in the prediction well if the thickness is the same.,,Yes,Yes
30354,Neighbor thickness helper features columns will be floats representing the distance from the depth predicted from neighbor thickness and prediction well base pick.,,Yes,Yes
30355,We have reason to believe the thickness of neighbors is a good indicator or where the top will be in this well. Reasons that wouldn't be the case include: presence of faults; known local outliers; and possibly other things I haven't thought of yet.,,,Yes
30357,################ Now to clean the dataframe; rename columns; and merge with the new dataframe that has the neighbors! ##################,,,Yes
30358,################ 6 and 7 in the functions below are the 6th and 7th columns... should replace with something more obvious!!!!! ##################,,No,Yes
30363,################ Now to clean the dataframe; rename columns; and merge with the new dataframe that has the neighbors! ##################,,No,Yes
30364,################ 6 and 7 in the functions below are the 6th and 7th columns... should replace with something more obvious!!!!! ##################,,No,Yes
30365,Find thickness of unit in neighboring wells in training dataset. Subtract that thickness from the base pick depth in the well we're going to predict for to find where that top pick would be in the prediction well if the thickness is the same.,,Yes,Yes
30366,Neighbor thickness helper features columns will be floats representing the distance from the depth predicted from neighbor thickness and prediction well base pick.,,Yes,Yes
30367,We have reason to believe the thickness of neighbors is a good indicator or where the top will be in this well. Reasons that wouldn't be the case include: presence of faults; known local outliers; and possibly other things I haven't thought of yet.,,,Yes
30368,############### exclude any we're not going to use for not having the needed tops and curves. ###################,,No,Yes
30370,################ 6 and 7 in the functions below are the 6th and 7th columns... should replace with something more obvious!!!!! ##################,,,Yes
30372,"print(\""wells_df_from_split.columns\"";wells_df_from_split.columns)",,No,Yes
30374,respective SHA256 hashes. Files will be downloaded automatically when needed,,,Yes
30375,rename depth to top and bottom depths ; delete all other columns,,Yes,Yes
30376,"print(\""number of columns in len(df_all_wells_wKNN.columns)\"";len(df_all_wells_wKNN.columns))",,No,Yes
30379,#####     Identify which columns to use as training features,,No,Yes
30380,#####     Identify which columns to use as labels,,,Yes
30381,#################### At some point come back and see if I can instead use a standard list of things to not include and make the list of columns to use as features more automatically???  ############,,No,Yes
30382,###### Two lists of columns to not use as training features; Columns taken out as they aren't present often enough in the well dataset,,No,Yes
30383,######## Columns taken out as they either contain information probably captures in other columns; are related to labels too closely; or other reasons.,,,Yes
30384,############# Next few lines to combine the two lists above and take those columns out of dataframe,,,Yes
30387,Identify which columns to use as labels,,No,Yes
30389,### split based on test in trainOrTest col and drop UWI and TrainOrTest columns,,Yes,Yes
30390,#####     Identify which columns to use as training features,,No,Yes
30391,#####     Identify which columns to use as labels,,,Yes
30392,pd.set_option('display.max_columns'; 500),,,Yes
30394,#### col_list = df_all_Col_preSplit_wTrainTest_ClassBalanced.columns,,No,Yes
30395,### columns_to_not_trainOn_andNotCurves = config.columns_to_not_trainOn_andNotCurves,,No,Yes
30396,### columns_to_not_trainOn_andAreCurves = config.columns_to_not_trainOn_andAreCurves,,No,Yes
30397,list(df_train_featWithHighCount.columns),,,Yes
30401,### printing a list of all the columns that we will use further down.,,Yes,Yes
30405,####### Identify which columns to use as labels ########,,No,Yes
30406,columns_to_use_as_labels = config.columns_to_use_as_labels  ##### ['class_DistFrPick_TopTarget';'UWI';'trainOrTest';'TopTarget_DEPTH'],,No,Yes
30407,labels = df_testPlusRebalTrain_featWithHighCount[columns_to_use_as_labels],,,Yes
30410,Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.,,Yes,Yes
30411,#######  In the future; it would be nice to calculate error bars as well!!!!!    ##########,,,Yes
30413,Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.,,Yes,Yes
30416,Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.,,Yes,Yes
30417,##### OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous; since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process; e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe; unsupported; undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute; but that may cause crashes or silently produce incorrect results. For more information; please see http:\/\/openmp.llvm.org\/,,Yes,Yes
30418,##### OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous; since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process; e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe; unsupported; undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute; but that may cause crashes or silently produce incorrect results. For more information; please see http:\/\/openmp.llvm.org\/,,Yes,Yes
30421,FIXME(tmoreau89): currently IR pass breaks when output padding != (0;0),,Yes,Yes
30422,Add hook for building doxygen xml when needed,,,Yes
30423,"\""\""\""Generic opertors in TVM. || We follow the numpy naming convention for this interface || (e.g.; tvm.generic.multitply ~ numpy.multiply). || The default implementation is used by tvm.ExprOp. || \""\""\""",,Yes,Yes
30424,TODO: fill me in,,No,Yes
30428,hacky - we should explore a more future-proof way to,,Yes,Yes
30429,TODO cfg is not used for now,,Yes,Yes
30431,FIXME(tmoreau89): currently IR pass breaks when output padding != (0;0),,Yes,Yes
30433,Necessary workaround for this issue:,,,Yes
30436,TODO: Hard coding this list of props for now. There has to be a clearer way...,,Yes,Yes
30437,TODO: Hard coding this list of props for now. There has to be a clearer way...,,Yes,Yes
30438,TODO: Hard coding this list of props for now. There has to be a clearer way...,,,Yes
30441,TODO: Hard coding this list of props for now. There has to be a clearer way...,,Yes,Yes
30442,TODO deep equality here?,,,Yes
30444,TODO: validate the spec; e.g. make sure paths in it are fine,,No,Yes
30445,TODO: this should be restricted to just Git repos and not S3 and stuff like that,,No,Yes
30448,TODO: do we always return csv or do we return the same type as the,,No,Yes
30449,This is a hack to make arrays of length 1 work with the parser.,,No,Yes
30450,TODO: I get active_run_id here but mlflow.tracking.log_output_files has its own way,,No,Yes
30452,Create root directory if needed,,Yes,Yes
30453,Create default experiment if needed,,Yes,Yes
30454,TODO: This doesn't play well with the atexit.register(end_run) call; specifically each,,Yes,Yes
30455,TODO: Remove `verify=False`; currently need it to run against dev shards.,,,Yes
30456,Creating Tensorflow-specific numeric columns for input.,,Yes,Yes
30458,Creating the feature columns required for the DNNRegressor.,,Yes,Yes
30459,Since this is a DNN model; convert categorical columns from sparse,,,Yes
30460,Build a DNNRegressor; with 2x20-unit hidden layers; with the feature columns,,,Yes
30461,TODO: it would be nice to translate the docker login; tag and push to python api.,,Yes,Yes
30464,Explicitly pass order of columns to avoid lexicographic ordering (i.e.; 10 < 2),,Yes,Yes
30465,If applicable; clean up unused models and old configurations,,,Yes
30467,TODO: don't copy mlruns directory here,,,Yes
30473,Create trash folder if needed,,Yes,Yes
30474,"\""\""\"" || Converts the raw CSV form to a Parquet form with just the columns we want || \""\""\""",,,Yes
30475,Drop unused column,,Yes,Yes
30476,We will then explode this features vector into a set of columns.,,,Yes
30478,TODO: we should return pd.Dataframe the same as pyfunc serve,,Yes,Yes
30480,"\""\""\""Export and import of generic R models. ||  || This module defines generic filesystem format for R models and provides utilities || for saving and loading to and from this format. The format is self contained in the sense || that it includes all necessary information for anyone to load it and use it. Dependencies || are either stored directly with the model or referenced via a Conda environment. ||  || The convention for rfunc models is to have a ``predict`` method or function with the following || signature:: ||  ||     predict(data: DataFrame) -> DataFrame ||  || This convention is relied on by other MLflow components. ||  || Rfunc model format is defined as a directory structure containing all required data; code; and || configuration: ||  || .. code:: ||  ||     .\/dst-path\/ ||             .\/MLmodel: configuration ||  || It must contain MLmodel file in its root with \""r_function\"" format. ||  || Example: ||  || .. code:: shell ||  ||   >tree R\/mlflow\/R\/inst\/examples\/R\/lm\/model ||   \u251C\u2500\u2500 MLmodel ||   \u2514\u2500\u2500 r_model.bin ||  ||   >cat R\/mlflow\/R\/inst\/examples\/R\/lm\/model\/MLmodel ||   time_created: 1.5337659e+09 ||   flavors: ||     r_function: ||       version: 0.1.0 ||       model: r_model.bin ||  || \""\""\""",,Yes,Yes
30481,is no good workaround at the moment.,,,Yes
30483,Create Tensorflow-specific numeric columns for input.,,Yes,Yes
30484,Create the feature columns required for the DNNRegressor,,Yes,Yes
30485,Since this is a DNN model; convert categorical columns from sparse to dense.,,Yes,Yes
30487,TODO (dbczumar): Replace HTTP resolution via ``requests.get`` with an invocation of,,Yes,Yes
30488,NOTE: Tensorflow based models depend on global state (Graph and Session) given by the context.,,No,Yes
30491,than all profiles in ~\/.databrickscfg; maybe better would be to mount the necessary,,,Yes
30492,This test suite is included as a code dependency when testing PyTorch model scoring in new,,,Yes
30493,ToDo: Consider prior checks for null; type; metric name validations; ... etc.,,Yes,Yes
30496,DB helper methods to allow zero values for columns with auto increments,,Yes,Yes
30498,TODO: optimization: This is making 2 calls to backend store. Include with above call.,,,Yes
30500,TODO: Remove,,,Yes
30502,TODO: push search query into backend database layer,,Yes,Yes
30503,TODO: Replace with None for 1.0; leaving for 0.9.1 release backcompat with existing servers,,No,Yes
30504,TODO remove this after 1.0 release,,,Yes
30505,TODO: refactor this magic ...,,,Yes
30506,hostname = parsed.netloc  # TODO: support later,,Yes,Yes
30507,Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.,,Yes,Yes
30508,TODO: push search query into backend database layer,,Yes,Yes
30510,add metric steps; do not need to depend on this one. This allows us to eventually remove this,,Yes,Yes
30514,TODO: eventually may want waitress on non-win32,,No,Yes
30515,"{ \""offset\"": xxx }. However; this format is not stable; so it should not be",,Yes,Yes
30517,columns defined via backreference are available as Mapper instance attributes (e.g.;,,No,Yes
30518,If there are multiple columns with the same name; selecting the shared name,,,Yes
30519,from the DataFrame will result in another DataFrame containing the columns,,Yes,Yes
30520,Feature columns describe how to use the input.,,,Yes
30521,Create the feature columns required for the DNNRegressor,,,Yes
30522,Since this is a DNN model; convert categorical columns from sparse to dense.,,Yes,Yes
30523,Build a DNNRegressor; with 20x20-unit hidden layers; with the feature columns,,,Yes
30529,TODO: verify schema here once we add logic to initialize the registry tables if they,,,Yes
30530,TODO: Replace the MlflowException with the following line once it's possible to run,,,Yes
30532,"\""\""\"" || Internal package providing a Python CRUD interface to MLflow experiments; runs; registered models; || and model versions. This is a lower level API than the :py:mod:`mlflow.tracking.fluent` module; || and is exposed in the :py:mod:`mlflow.tracking` module. || \""\""\""",,Yes,Yes
30536,TODO: this should be restricted to just Git repos and not S3 and stuff like that,,,Yes
30537,same main query; the CASE WHEN columns need to have unique names to,,,Yes
30538,note: databricks_profile is None needed because clients using profile are mocked,,Yes,Yes
30540,"is not used; and so is set to the string \""unused\"" here",,Yes,Yes
30541,Support Python >= 2.7. TODO: update this version bound to >= 3.5 in order to drop,,,Yes
30542,Concatenating with itself to duplicate column and mess up input shape,,,Yes
30544,TODO (dbczumar): Replace HTTP resolution via ``requests.get`` with an invocation of,,,Yes
30545,setting this env variable is needed when using Spark with Arrow >= 0.15.0,,Yes,Yes
30546,TODO: remove this check once local; databricks; kubernetes execution have been refactored,,Yes,Yes
30548,make sure there are no missing columns,,Yes,Yes
30549,Preserve order from the original columns; since missing\/extra columns are likely to,,Yes,Yes
30550,test that columns are reordered; extra column is ignored,,,Yes
30551,test unnamed columns,,Yes,Yes
30552,Prevents incorrect split if fullpath ends with a '\/',,,Yes
30553,"\""\""\"" || This module contains the base interface implemented by MLflow model deployment plugins. || In particular; a valid deployment plugin module must implement: ||  || 1. Exactly one client class subclassed from :py:class:`BaseDeploymentClient`; exposing the primary ||    user-facing APIs used to manage deployments. || 2. :py:func:`run_local`; for testing deployment by deploying a model locally || 3. :py:func:`target_help`; which returns a help message describing target-specific URI format ||    and deployment config || \""\""\""",,,Yes
30555,test that invalid columns throw,,Yes,Yes
30557,parameter of ``_load_pyfunc()`` refers directly to a serialized scikit-learn model,,Yes,Yes
30559,itemsize when matching binary columns.,,Yes,Yes
30560,TODO: remove this check once kubernetes execution has been refactored,,No,Yes
30564,"TODO: we may change the delimiter to \"":\"" from \""\/\"" for key_prefix",,Yes,Yes
30567,dictionary column and filter out the other parameter-specific columns with,,Yes,Yes
30568,prevent truncating columns,,No,Yes
30572,Efficient mapping technique needs to be introduced,,Yes,Yes
30577,"Assume the inference dataframe has columns \""start\"" and \""end\""; and just one row",,Yes,Yes
30579,TODO: add more autologgable methods here (e.g. fit_regularized; from_formula; etc),,No,Yes
30580,8. np.ndarrays can be converted to dataframe but have no columns,,No,Yes
30581,ensure all columns have the same number of items,,,Yes
30582,Workaround for inability to use shutil.copytree with DBFS FUSE due to permission-denied,,Yes,Yes
30584,To avoid this bug; disable 'unused-import' on this line.,,,Yes
30585,As a workaround; use `assert_array_almost_equal` instead of `assert_array_equal`,,Yes,Yes
30586,"is not used; and so is set to the string \""unused\"" here",,Yes,Yes
30587,ensure all columns have the same number of items,,,Yes
30590,#NAME?,,,Yes
30594,TODO: load state from db for resume,,Yes,Yes
30596,FIXME: IPython < 3 compat,,No,Yes
30598,FIXME: IPython < 3 compat,,,Yes
30599,Only override if configurable-http-proxy is not on your PATH,,Yes,Yes
30601,get User columns,,,Yes
30602,maybe just filename matching would be sufficient,,,Yes
30603,This is **not** a configurable;,,Yes,Yes
30604,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
30607,FIXME: use xip.io for debugging,,,Yes
30609,TODO: this will be done by the Hub when the Hub gets service config,,Yes,Yes
30610,FIXME: remove when we can declare routes in Hub config,,,Yes
30613,not admin; maybe self,,Yes,Yes
30614,relying on deprecated 0.6 way of setting ip; port;,,,Yes
30615,FIXME: Provide example of such an URL!,,No,Yes
30616,FIXME: Provide example of such an URL!,,,Yes
30622,TODO: make async (in a Thread?),,,Yes
30625,FIXME: redirect to originating URL (OAuth loses this info),,,Yes
30627,FIXME: handle deprecated config here,,No,Yes
30628,Most basic implementers must only implement above methods,,,Yes
30629,FIXME: handle deprecated config here,,No,Yes
30630,FIXME: handle deprecated config here,,No,Yes
30631,FIXME: _headers is private; but there doesn't appear to be a public way,,No,Yes
30634,FIXME: handle deprecated config here,,No,Yes
30635,FIXME: handle deprecated config here,,,Yes
30636,FIX-ME CHECK IF STILL NEEDED,,Yes,Yes
30638,set CSP header directly to workaround bugs in jupyter\/notebook 5.0,,Yes,Yes
30639,TODO: named servers,,,Yes
30641,Add some random jitter to improve performance,,,Yes
30643,TODO: handle decryption failure,,Yes,Yes
30647,FIXME: Move this out of settings; since this isn't really a setting,,,Yes
30648,FIXME: Move this out of settings; since this isn't really a setting,,Yes,Yes
30649,What happened? Maybe something unclean in a resumed container.,,Yes,Yes
30651,constant; not configurable,,Yes,Yes
30654,left-justify and shrink-to-fit columns,,Yes,Yes
30655,what happened? Maybe spawn failed?,,No,Yes
30656,FIXME: remove when we drop Python 3.5 support,,,Yes
30658,what happened? Maybe spawn failed?,,No,Yes
30660,FIXME: use urlunparse instead?,,,Yes
30662,add any user configurable handlers. Make it first so it can override,,Yes,Yes
30664,add any user configurable handlers.,,Yes,Yes
30666,Move certs to users dir,,,Yes
30667,Move certs to users dir,,,Yes
30668,You probably want to render a template instead.,,No,Yes
30670,TODO: specify scopes,,,Yes
30673,TODO:,,,Yes
30674,TODO: save scopes;,,,Yes
30677,TODO: record redirect_uri used during oauth,,,Yes
30678,TODO: and it's sufficiently recent,,,Yes
30683,Move certs to users dir,,Yes,Yes
30685,Move certs to users dir,,Yes,Yes
30686,connectivity issue. Maybe a long one where the local caches have timed out; though PAM would,,Yes,Yes
30687,FIXME: Remove None default on removal of old signature comptability,,,Yes
30688,FIXME: scopes should give us better control than this,,,Yes
30689,FIXME: scopes should give us better control than this,,No,Yes
30690,FIXME: Remove None default on removal of old signature comptability,,Yes,Yes
30691,FIXME: Remove None default on removal of old signature compatibility,,Yes,Yes
30692,"and then... if it ends in something like \""-v1.1\"" parse the",,No,Yes
30693,maybe not the most robust way to check this?,,No,Yes
30694,FIXME: scopes should give us better control than this,,No,Yes
30695,FIXME: scopes should give us better control than this,,,Yes
30696,maybe not the most robust way to check this?,,No,Yes
30697,TODO: when these can all be done concurrently; do all of them,,,Yes
30699,TODO: properly handle deprecated signature *and* name,,Yes,Yes
30702,# TODO can we remove this debug flag?,,,Yes
30703,TODO validation_split is not used,,No,Yes
30705,TODO build_dataset shadows name from outer scope,,Yes,Yes
30706,filename='log.log'; TODO - remove these?,,,Yes
30708,"TODO - pycharm complains \""Need more values to unpack\""",,,Yes
30709,keep only the first num_classes rows and columns,,Yes,Yes
30711,This is needed because in the case of the generator decoder the,,No,Yes
30712,TODO - this is still WIP,,Yes,Yes
30716,look for an unused suffix,,No,Yes
30718,filename='log.log'; TODO - remove these?,,Yes,Yes
30719,todo deal with flush,,Yes,Yes
30720,this is needed for reproducibility,,,Yes
30721,ORRIBLE HACK; IT'S THE ONLY WAY TO REMOVE PADDING,,,Yes
30722,END OF HORRIBLE HACK,,No,Yes
30723,"# TODO - double check this - pycharm warns \""Unresolved attribute reference\""",,Yes,Yes
30724,DOTO this param is unused?,,,Yes
30726,TODO not sure rstrip() avoids the newline,,No,Yes
30728,TODO rstrip(),,No,Yes
30729,filename='log.log'; TODO - remove these?,,Yes,Yes
30730,TODO save metadata here,,Yes,Yes
30731,todo this may be useless; doublecheck,,,Yes
30733,END OF HORRIBLE HACK,,No,Yes
30737,TODO the hidden output is actually a tensor. May need modification,,Yes,Yes
30738,todo: should adapt for the case of beam > 1,,,Yes
30742,from the probability columns,,Yes,Yes
30743,TODO - not sure if this is correct,,,Yes
30744,this is needed because mpz adds a 1 at the beginning,,No,Yes
30745,TODO add multiprocessing\/multithreading,,Yes,Yes
30746,Needed to call an attribute of wandb to make DeepSource not complain,,,Yes
30747,todo: add a mechanism for letting the user decide to save it,,,Yes
30750,todo remplace with addons,,Yes,Yes
30756,todo tf2: remove obsolete code #initial_state=initial_state;,,Yes,Yes
30757,todo tf2: cleanout obsolete code,,No,Yes
30759,todo tf2 remove obsolete #tf.nn.rnn_cell.BasicRNNCell,,Yes,Yes
30760,todo tf2: need to figure out 'inputs' to next function,,,Yes
30763,todo: tf2 need to handle case of single predictor; e.g.; image,,Yes,Yes
30767,todo: tf2 debugging only,,No,Yes
30768,todo tf2: fix this,,,Yes
30769,todo: tf2 proof-of-concept code; need to be generalized,,No,Yes
30773,todo: tf2 need to rationalize to reduce redundant code,,No,Yes
30774,todo: tf2 need to handle case of single predictor; e.g.; image,,,Yes
30776,todo: tf2 clean up,,No,Yes
30777,todo: tf2;,,Yes,Yes
30778,todo: tf2 need to find function,,,Yes
30780,todo: tf2 debugging,,No,Yes
30782,todo tf2 revert to original name upon completion,,Yes,Yes
30783,todo tf2 remove,,,Yes
30790,todo: remove function after tf2 port,,,Yes
30793,todo tf2 need to add,,Yes,Yes
30795,todo tf2 remove code after tf2 port,,,Yes
30799,todo tf2 try-except for debugging purposes,,,Yes
30802,todo tf2 clean up commented code,,Yes,Yes
30806,todo tf2 - convert to tensors?,,,Yes
30807,todo tf2 - convert to tensors?,,Yes,Yes
30811,todo this may be redundant; check,,No,Yes
30817,todo: tf2 proof-of-concept code,,No,Yes
30820,import tensorflow as tf2    # todo: tf2 port,,Yes,Yes
30821,todo: tf2 proof-of-concept code; need to be generalized,,No,Yes
30822,todo: tf2 proof-of-concept,,No,Yes
30824,todo tf2 clean up commented out code,,Yes,Yes
30827,# todo tf2: fix this,,,Yes
30829,todo: tf2 add back relevant code as needed,,No,Yes
30832,todo: tf2 clean up  code,,No,Yes
30833,todo: tf2 need to rationalize to reduce redundant code,,,Yes
30834,todo: tf2 debugging,,No,Yes
30836,todo tf2: fix this,,No,Yes
30837,todo tf2: adapt for tf2,,No,Yes
30839,todo tf2: add initilization; regualrization etc.,,Yes,Yes
30841,todo tf2: reintroduce saving,,,Yes
30844,todo tf2: reintroduce tensorboard logging,,No,Yes
30845,todo tf2: reintroduce debugging mode,,No,Yes
30849,todo tf2: figure out how to reintroduce the GPU usage without session,,No,Yes
30853,todo tf2: fix this!,,No,Yes
30859,import tensorflow as tf2    # todo: tf2 port,,Yes,Yes
30861,todo tf2: reintroduce learning scheduler in different form most likely,,,Yes
30862,todo tf2: reintroduce tensorboard tracking and summaries,,,Yes
30863,todo tf2: reintroduce saving,,,Yes
30864,todo: tf2 proof-of-concept code,,No,Yes
30866,todo tf2: completed fix,,No,Yes
30868,todo tf2: reintroduce tensorboard logging,,No,Yes
30871,todo tf3: reintroduce session resume,,Yes,Yes
30873,# todo tf2: fix this,,No,Yes
30876,todo: tf2 add back relevant code as needed,,No,Yes
30877,todo tf2: figure out how to reintroduce the GPU usage without session,,No,Yes
30879,todo: tf2 need to handle case of single predictor; e.g.; image,,,Yes
30881,TODO add filter size tuples,,No,Yes
30883,todo tf2: change name from 'representation' to 'encoder`,,,Yes
30886,todo tf2: work-in-progress partial implementation,,,Yes
30891,TODO: Given the results of previous computation; it updates,,,Yes
30894,"the strategy (not needed for stateless strategies like \""grid\""",,Yes,Yes
30897,hidden_size = input_sequence.shape[-1] # todo tf2 clean up,,Yes,Yes
30899,todo: should adapt for the case of beam > 1,,,Yes
30902,todo tf2 do we need?,,,Yes
30904,TODO allow users to specify also metrics from the overall,,,Yes
30905,TODo this is duplicate code from experiment;,,Yes,Yes
30913,TODO TF2 can we eliminate use of these customer wrapper classes?,,Yes,Yes
30914,TODO TF2 refactor to better adapt for TF2 port,,Yes,Yes
30916,TODO TF2 clean up after port,,Yes,Yes
30918,None;  # todo tf2: confirm on need,,No,Yes
30919,memory_sequence_length=max_sequence_length  # todo tf2: confirm inputs or output seq length,,No,Yes
30920,############## Old code  todo tf2 remove,,No,Yes
30921,# todo tf2:  need to confirm this is correct construct,,No,Yes
30922,###### old code todo tf2,,No,Yes
30923,todo tf2 clean up,,Yes,Yes
30924,todo tf2: right now cast to tf.int32; fails if tf.int64,,No,Yes
30926,todo tf2 following code needs to be adapted for above,,Yes,Yes
30927,todo tf2 Placeholder code,,Yes,Yes
30932,todo tf2 need logits,,Yes,Yes
30938,todo tf2: reintroduce saving,,No,Yes
30939,todo: tf2 proof-of-concept code,,No,Yes
30941,todo tf2: completed fix,,No,Yes
30942,todo tf2: reintroduce restoring weights,,No,Yes
30943,todo tf2: reintroduce tensorboard logging,,No,Yes
30945,todo tf2: reintroduce debugging mode,,No,Yes
30948,# todo tf2: fix this,,No,Yes
30949,todo tf2 remove when development done,,,Yes
30951,todo: tf2 add back relevant code as needed,,No,Yes
30953,todo: tf2 need to rationalize to reduce redundant code,,No,Yes
30955,todo tf2 need to determine if the section of code is needed,,,Yes
30957,this maybe a unidirection lstm or a bidirectional gru \/ rnn,,Yes,Yes
30958,todo try to find a way to distinguish among these two cases,,Yes,Yes
30961,TODO tf2 add feed forward attention,,,Yes
30963,todo tf2 need to change to tf.int64,,Yes,Yes
30964,todo tf2 clean up candidate for removal,,,Yes
30969,todo try to find a way to distinguish among these two cases,,,Yes
30970,logtis don't work; temporary workaround,,,Yes
30972,# todo: for the tagger always take the last,,,Yes
30973,todo tf2: solve cases when predictions become 0 and then return,,No,Yes
30974,todo tf2: deal with spurious 0s in predictions,,No,Yes
30976,TODO: this should not be needed,,No,Yes
30978,remove logits; not needed for overall stats,,Yes,Yes
30979,import tensorflow as tf2    # todo: tf2 port,,Yes,Yes
30983,todo tf2: reintroduce saving,,No,Yes
30986,todo tf2: completed fix,,No,Yes
30989,# todo tf2: completed fix,,No,Yes
30992,todo: tf2 add back relevant code,,No,Yes
30993,# todo tf2: fix this,,No,Yes
30994,todo tf2 remove when development done,,,Yes
30996,todo: tf2 add back relevant code as needed,,No,Yes
30997,todo tf2: figure out how to reintroduce the GPU usage without session,,,Yes
30998,todo: tf2 need to rationalize to reduce redundant code,,No,Yes
30999,todo: tf2 need to handle case of single predictor; e.g.; image,,,Yes
31001,import tensorflow as tf2    # todo: tf2 port,,Yes,Yes
31004,todo tf2: reintroduce tensorboard tracking and summaries,,No,Yes
31005,todo tf2: reintroduce saving,,No,Yes
31010,todo tf2: reintroduce tensorboard logging,,No,Yes
31011,# todo tf2: completed fix,,,Yes
31012,todo tf2: reintroduce debugging mode,,,Yes
31013,todo tf3: reintroduce session resume,,,Yes
31014,todo: tf2 add back relevant code,,,Yes
31020,todo: tf2 need to rationalize to reduce redundant code,,No,Yes
31023,todo tf2: reintroduce this functionality,,No,Yes
31026,todo tf2: add optimizer registry in optimization_module.py,,,Yes
31028,TODO(travis): determine whether this method is still needed in TF2,,,Yes
31029,todo tf2: add optimizer registry in optimization_module.py,,Yes,Yes
31032,# todo tf2: remove obsolete code #initial_state=initial_state;,,Yes,Yes
31034,# todo tf2: cleanout obsolete code,,No,Yes
31039,todo: tf2 add back relevant code,,No,Yes
31041,todo tf2: reintroduce learning scheduler in different form most likely,,No,Yes
31043,todo tf2: reintroduce saving,,No,Yes
31046,todo tf2: completed fix,,No,Yes
31047,todo tf2: reintroduce restoring weights,,,Yes
31051,# todo tf2: fix this,,,Yes
31052,todo tf2: reintroduce saving,,No,Yes
31054,remove logits; not needed for overall stats,,Yes,Yes
31059,todo this works for obtaining the postprocessed prediction,,Yes,Yes
31060,and replace the raw ones; but some refactoring is needed to,,Yes,Yes
31061,todo if we want to save the csv of predictions uncomment block,,Yes,Yes
31063,and replace the raw ones; but some refactoring is needed to,,Yes,Yes
31065,todo maybe unify Projector and Classifier in a single class,,No,Yes
31066,todo tf2: port all these functions to tf2,,No,Yes
31067,this is needed because TF2 initialzies the weights at the first call,,,Yes
31068,this is needed because at training time is the loss is sampled,,,Yes
31069,"the strategy (not needed for stateless strategies like \""grid\""",,Yes,Yes
31071,todo tf2: add missing optimizers,,,Yes
31073,todo tf2: next is work-around allow matching function signature by,,,Yes
31074,todo this works for obtaining the postprocessed prediction,,,Yes
31075,and replace the raw ones; but some refactoring is needed to,,,Yes
31076,todo if we want to save the csv of predictions uncomment block,,,Yes
31077,todo: when https:\/\/github.com\/uber\/ludwig\/issues\/810 is closed,,No,Yes
31078,set up required directories for images if needed,,Yes,Yes
31082,todo Piero: not sure this is needed;,,,Yes
31083,obtain tesnors needed,,Yes,Yes
31084,todo refactoring: decide where to put this;,,,Yes
31089,todo future: reintroduce the bucketed batcher,,,Yes
31090,todo refactoring: check if this is relevant,,No,Yes
31092,todo v0.4: allow users to specify also metrics from the overall,,,Yes
31095,todo: add read pickle; fwf; html; father; parquet; orc; sas; spss; stata,,Yes,Yes
31096,todo: add read pickle; fwf; html; father; parquet; orc; sas; spss; stata,,Yes,Yes
31099,needed to shadow class variable,,No,Yes
31101,needed to shadow class variable,,No,Yes
31103,needed to shadow class variable,,,Yes
31104,needed to shadow class variable,,No,Yes
31105,labels_smoothing=labels_smoothing  # todo reintroduce,,Yes,Yes
31107,to the checksum calculation? maybe it's redundant,,No,Yes
31117,not unstacking. Needed because otherwise pandas casts types,,,Yes
31120,as needed convert predictions make to original value space,,Yes,Yes
31121,create csv file with 7 columns: image_path; 5 captions; and split,,No,Yes
31125,Functions needed to treat Trainer as a context manager,,,Yes
31126,Functions needed to treat Trainer as a context manager,,,Yes
31128,todo: this should actually be the size of the last fc layer;,,Yes,Yes
31129,todo: set initializer and regularization,,,Yes
31130,todo: add transformer,,,Yes
31131,is there a better way to do this?,,No,Yes
31132,TODO ray: select this more intelligently;,,,Yes
31133,TODO ray: https:\/\/github.com\/horovod\/horovod\/issues\/2702,,No,Yes
31134,TODO ray: make this more configurable by allowing YAML overrides of timeout_s; etc.,,No,Yes
31139,TODO dask: support distributed backend for prediction,,Yes,Yes
31140,TODO dask: support distributed backend for prediction,,,Yes
31143,maybe it needs a FloatTensor,,Yes,Yes
31145,maybe it needs a FloatTensor,,,Yes
31147,TODO: batches not necessarily,,No,Yes
31150,TODO: batches not necessarily,,No,Yes
31152,TODO: batches not necessarily,,,Yes
31155,maybe it needs a FloatTensor,,,Yes
31156,FIXME: need to enumerate out support when dims aren't 1.,,Yes,Yes
31157,this operation writes ones where needed,,,Yes
31158,FIXME: torch.split so tensor is differentiable,,,Yes
31162,TODO vectorize importance samples?,,No,Yes
31163,FIXME: i'm not sure if iawe math works for LR,,No,Yes
31166,TODO: make this cleaner via a trace data structure,,,Yes
31168,FIXME: this is brittle; deal with mismatched stride.,,Yes,Yes
31169,FIXME: should add batch as a trace node,,No,Yes
31173,TODO: make this as an object instead of dict?,,Yes,Yes
31174,TODO: implement via poutine layer?,,No,Yes
31175,FIXME: use tree in memory rather than copy?,,Yes,Yes
31176,TODO: leverage independence contract of map_data.,,Yes,Yes
31178,TODO handle other kinds of posterior objects...,,,Yes
31180,TODO: use itertools for speed?,,No,Yes
31181,TODO: what can be keys in python? need to stringify rv?,,No,Yes
31182,TODO: normalize,,Yes,Yes
31184,TODO: Warning; this supports mostly all normal closure behavior; e.g. adam; sgd; asgd,,Yes,Yes
31185,currently; traces are extremely conservative for lack of better implementation,,Yes,Yes
31186,XXX beware py2\/3 compatibility,,,Yes
31187,XXX add msg,,,Yes
31188,XXX need to get this behavior implemented properly,,No,Yes
31189,XXX beware of python2\/3 bugs,,Yes,Yes
31190,XXX this first branch isnt correct,,Yes,Yes
31191,XXX beware of py2\/3 bugs,,,Yes
31192,XXX what is correct behavior here,,No,Yes
31194,TODO init this somewhere else in a more principled way,,No,Yes
31196,XXX distinction between reparam and not is artificial; leads to repetition,,,Yes
31197,XXX should be doing this via reinforce(),,,Yes
31200,XXX should be its own class instead of greenlet descendant?,,No,Yes
31201,XXX call needs to override switch; how should this be defined?,,Yes,Yes
31202,XXX ignore for now?,,,Yes
31203,XXX what should be the base class here?,,Yes,Yes
31204,XXX what should g be an instance of?,,,Yes
31205,XXX get the default behavior right here,,Yes,Yes
31206,XXX not correct arguments,,Yes,Yes
31207,XXX not correct arguments?,,Yes,Yes
31209,XXX what to do here??,,,Yes
31213,XXX what to put here?,,Yes,Yes
31214,XXX should these be returned as Poutines?,,Yes,Yes
31215,XXX need to structure this better,,,Yes
31219,TODO init this somewhere else in a more principled way,,,Yes
31220,XXX need to structure this better,,No,Yes
31223,XXX Categorical not working correctly with non-Tensor vs,,Yes,Yes
31224,XXX add queue here or on call to _traces?,,Yes,Yes
31225,XXX NOTE: this won't save persistent buffers,,,Yes
31226,XXX NOTE: this won't save persistent buffers,,Yes,Yes
31228,this operation writes ones where needed,,Yes,Yes
31229,this operation writes ones where needed,,,Yes
31230,XXX should clone?,,Yes,Yes
31231,XXX should clone?,,Yes,Yes
31233,FIXME,,Yes,Yes
31234,XXX and np.ndarray?,,,Yes
31235,XXX incorrect?,,Yes,Yes
31236,XXX should raise an error here?,,,Yes
31237,XXX and np.ndarray?,,No,Yes
31240,XXX incorrect?,,Yes,Yes
31241,XXX should raise an error here?,,No,Yes
31243,TODO init this somewhere else in a more principled way,,,Yes
31246,XXX should this also be reflected in the construction of the surrogate_loss instead?,,,Yes
31248,XXX is this actually necessary?,,Yes,Yes
31250,XXX what's the best way to do this??,,No,Yes
31252,XXX should the average baseline be in the param store as below?,,,Yes
31253,XXX incorrect?,,Yes,Yes
31254,XXX should raise an error here?,,,Yes
31255,XXX is there a more elegant way to move indices up the stack?,,No,Yes
31257,XXX should raise an error here?,,,Yes
31259,XXX this isnt a good abstraction for marginal likelihood estimation,,No,Yes
31262,XXX had to change get_parents -> get_ancestors below to accomodate coarser,,,Yes
31263,XXX copy_() ?,,,Yes
31264,# XXX seems like this should happen on poutine installation; not at execution,,Yes,Yes
31265,# XXX should these be added here or during application,,Yes,Yes
31266,# XXX this should have the same call signature as torch.Tensor constructors,,,Yes
31267,not necessarily efficient torch.exp call x2; fix later,,Yes,Yes
31268,XXX had to change get_parents -> get_ancestors below to accomodate coarser,,No,Yes
31269,XXX is this actually necessary?,,Yes,Yes
31270,XXX had to change get_parents -> get_ancestors below to accommodate coarser,,No,Yes
31272,# XXX seems like this should happen on poutine installation; not at execution,,,Yes
31274,XXX this should have the same call signature as torch.Tensor constructors,,,Yes
31275,finish assembling complete downstream costs (may be missing terms from model),,,Yes
31277,XXX had to change get_parents -> get_ancestors below to accomodate coarser,,,Yes
31278,XXX is this actually necessary?,,Yes,Yes
31280,XXX incorrect?,,Yes,Yes
31281,XXX get batch size args to dist right,,,Yes
31282,XXX can we cache some of the sums over children_in_model to make things more efficient?,,Yes,Yes
31284,XXX and np.ndarray?,,No,Yes
31286,XXX this isnt a good abstraction for marginal likelihood estimation,,No,Yes
31293,XXX and np.ndarray?,,No,Yes
31294,TODO (@npradhan) - remove once #144 is resolved,,No,Yes
31297,TODO remove unnecessary,,No,Yes
31298,TODO Remove the batch_size argument.,,,Yes
31300,XXX and np.ndarray?,,,Yes
31302,TODO can probably condense this logic; keeping explicit for now,,Yes,Yes
31304,TODO check at runtime if stack is valid,,,Yes
31305,# XXX seems like this should happen on poutine installation; not at execution,,Yes,Yes
31306,since needed batch_log_pdf infrastructure missing,,Yes,Yes
31309,TODO Split this into assert_equal() and assert_close() or assert_almost_equal().,,,Yes
31310,XXX should the user be able to control inclusion of the -logq term below?,,,Yes
31312,XXX can we cache some of the sums over children_in_model to make things more efficient?,,Yes,Yes
31313,XXX should the average baseline be in the param store as below?,,Yes,Yes
31314,XXX default for baseline_beta currently set here,,Yes,Yes
31316,return empty set; since tag doesn't exist; XXX raise warning?,,,Yes
31317,make sure that that functionality is ok (XXX: do this somewhere else in the future),,,Yes
31320,XXX will this iterate over nodes?,,Yes,Yes
31321,since needed batch_log_pdf infrastructure missing,,Yes,Yes
31322,XXX why tuple?,,Yes,Yes
31324,WARNING: this is very dangerous. better method?,,Yes,Yes
31325,XXX Why is this marked non-differentiable?,,Yes,Yes
31327,WARNING: this is very dangerous. better method?,,Yes,Yes
31330,FIXME: This just fills the entire tensor with the first value,,Yes,Yes
31332,TODO fix this to broadcasting as below; e.g. by instead:,,Yes,Yes
31337,TODO remove once https:\/\/github.com\/uber\/pyro\/issues\/323 is resolved,,,Yes
31338,HACK: Helpers to create zeros\/ones on cpu\/gpu as appropriate.,,No,Yes
31340,It would be better to use z_pres to change the opacity of,,,Yes
31343,XXX Remove this after Pytorch 0.2.1.,,Yes,Yes
31346,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
31350,XXX should the user be able to control if these terms are included?,,Yes,Yes
31351,XXX Until PyTorch supports scalars; this should return (1;),,Yes,Yes
31352,XXX After PyTorch supports scalars; this should return (),,Yes,Yes
31355,TODO Convert to LongTensor or ByteTensor.,,,Yes
31357,TODO switch to OneHotCategorical,,,Yes
31358,2. Implement a new distribution in pyro.distribution and let Pyro devs move,,Yes,Yes
31361,TODO It may be useful to switch between matrix_inverse_compat() and linear_solve_compat() based on the,,Yes,Yes
31363,XXX should the user be able to control inclusion of the -logq term below?,,,Yes
31364,TODO Move this upstream to PyTorch.,,,Yes
31365,XXX: Very sensitive to HMC parameters. Biased estimate is obtained,,,Yes
31366,TODO: define noise as a Likelihood (another nn.Module beside kernel);,,No,Yes
31367,TODO: use torch.trtrs when it supports cuda tensors,,,Yes
31369,TODO these will need extra_event_dims=1,,,Yes
31370,note that 3 was summed out  TODO will become (4;),,Yes,Yes
31371,TODO this will need extra_event_dims=1,,No,Yes
31374,stateful distributions cannot implement a function interface,,,Yes
31375,TODO: define noise as a Likelihood (a nn.Module),,No,Yes
31380,TODO: use scale_tril=Lu,,,Yes
31384,TODO: re-enable once https:\/\/github.com\/uber\/pyro\/issues\/799 is resolved; with lower number of samples,,Yes,Yes
31385,awful hack to get rtd builder to install pytorch,,No,Yes
31386,Reshape to move actual_dim to target_dim.,,Yes,Yes
31393,automatically transform `z` to unconstrained space; if needed.,,,Yes
31394,automatically transform `z` to unconstrained space; if needed.,,,Yes
31395,TODO make this pass for trace_elbo,,,Yes
31396,TODO: make thresholds for too small step_size or too large step_size,,,Yes
31399,"TODO use score_parts.entropy_term to \""stick the landing\""",,,Yes
31403,TODO: push these properties to upstream torch.distributions,,,Yes
31405,fix inducing points because variance\/lengthscale highly depend on it,,Yes,Yes
31406,TODO refine this coarse dependency ordering.,,,Yes
31408,TODO fix this docstring,,,Yes
31409,"This is PyTorch convention for \""arbitrary size\""",,Yes,Yes
31410,XXX this should have the same call signature as torch.Tensor constructors,,,Yes
31411,WARNING: this is very dangerous. better method?,,Yes,Yes
31412,TODO check at runtime if stack is valid,,,Yes
31413,"\""\""\"" || Example has been adapted from [1]. It demonstrates how to do Bayesian inference using || NUTS (or; HMC) in Pyro; and use of some common inference utilities. ||  || As in the Stan tutorial; this uses the small baseball dataset of Efron and Morris [2] || to estimate players' batting average which is the fraction of times a player got a || base hit out of the number of times they went up at bat. ||  || The dataset separates the initial 45 at-bats statistics from the remaining season. || We use the hits data from the initial 45 at-bats to estimate the batting average || for each player. We then use the remaining season's data to validate the predictions || from our models. ||  || Three models are evaluated: ||  - Complete pooling model: The success probability of scoring a hit is shared ||      amongst all players. ||  - No pooling model: Each individual player's success probability is distinct and ||      there is no data sharing amongst players. ||  - Partial pooling model: A hierarchical model with partial data sharing. ||  ||  || We recommend Radford Neal's tutorial on HMC ([3]) to users who would like to get a || more comprehensive understanding of HMC and its variants; and to [4] for details on || the No U-Turn Sampler; which provides an efficient and automated way (i.e. limited || hyper-parameters) of running HMC on different problems. ||  || [1] Carpenter B. (2016); [\""Hierarchical Partial Pooling for Repeated Binary Trials\""] ||     (http:\/\/mc-stan.org\/users\/documentation\/case-studies\/pool-binary-trials.html). || [2] Efron B.; Morris C. (1975); \""Data analysis using Stein's estimator and its ||     generalizations\""; J. Amer. Statist. Assoc.; 70; 311-319. || [3] Neal; R. (2012); \""MCMC using Hamiltonian Dynamics\""; ||     (https:\/\/arxiv.org\/pdf\/1206.1901.pdf) || [4] Hoffman; M. D. and Gelman; A. (2014); \""The No-U-turn sampler: Adaptively setting ||     path lengths in Hamiltonian Monte Carlo\""; (https:\/\/arxiv.org\/abs\/1111.4246) || \""\""\""",,Yes,Yes
31416,TODO return pyro.distributions.torch.Independent(self; reinterpreted_batch_ndims),,No,Yes
31417,XXX currently this whole object is very inefficient,,Yes,Yes
31422,XXX should block,,Yes,Yes
31424,but it is unclear whether convergence would be faster if we applied,,No,Yes
31425,Evaluate log likelihoods. TODO make this more pyronic.,,Yes,Yes
31427,TODO: use torch.logsumexp once it's in PyTorch release,,No,Yes
31430,TODO move this upstream to torch.distributions,,Yes,Yes
31432,TODO: optionally check pattern match here,,No,Yes
31435,FIXME this does not handle nonstandard backends like torch_log,,No,Yes
31436,TODO: optionally check pattern match here,,,Yes
31440,TODO refine this coarse dependency ordering using time and tensor shapes.,,Yes,Yes
31441,TODO split log_factors into connected components wrt shared tensor dims.,,,Yes
31445,Pyro's TraceEnum_ELBO will find an efficient message passing scheme if one,,,Yes
31446,We'll speed up parameter tuning by caching the message passing paths,,No,Yes
31447,We expect models with higher capacity to perform better;,,,Yes
31450,"\""\""\"" || This example demonstrates how to marginalize out discrete assignment variables || in a Pyro model. ||  || Our example model is Latent Dirichlet Allocation. While the model in this || example does work; it is not the recommended way of coding up LDA in Pyro. || Whereas the model in this example treats documents as vectors of categorical || variables (vectors of word ids); it is usually more efficient to treat || documents as bags of words (histograms of word counts). || \""\""\""",,,Yes
31451,"\""\""\"" || The :mod:`pyro.contrib.glmm` module provides models and guides for || generalised linear mixed models (GLMM). It also includes the || Normal-inverse-gamma family. ||  || To create a classical Bayesian linear model; use:: ||  ||     from pyro.contrib.glmm import known_covariance_linear_model ||  ||     # Note: coef is a p-vector; observation_sd is a scalar ||     # Here; p=1 (one feature) ||     model = known_covariance_linear_model(coef_mean=torch.tensor([0.]); ||                                           coef_sd=torch.tensor([10.]); ||                                           observation_sd=torch.tensor(2.)) ||  ||     # An n x p design tensor ||     # Here; n=2 (two observations) ||     design = torch.tensor(torch.tensor([[1.]; [-1.]])) ||  ||     model(design) ||  || A non-linear link function may be introduced; for instance:: ||  ||     from pyro.contrib.glmm import logistic_regression_model ||  ||     # No observation_sd is needed for logistic models ||     model = logistic_regression_model(coef_mean=torch.tensor([0.]); ||                                       coef_sd=torch.tensor([10.])) ||  || Random effects may be incorporated as regular Bayesian regression coefficients. || For random effects with a shared covariance matrix; see :meth:`pyro.contrib.glmm.lmer_model`. || \""\""\""",,Yes,Yes
31452,TODO: Use LBFGS with line search by pytorch #8824 merged,,No,Yes
31453,Compute batch context for each non-batch dim; by convention the,,No,Yes
31454,XXX consider using list\/OrderDict to store z and r,,Yes,Yes
31455,"This is PyTorch convention for \""arbitrary size\""",,Yes,Yes
31457,TODO: revert to `torch.dot` in pytorch==1.0,,Yes,Yes
31458,TODO: change to torch.dot for pytorch 1.0,,,Yes
31459,provided that the above copyright notice appear in all copies and that,,,Yes
31460,XXX LBFGS is not supported for SVI yet,,,Yes
31463,are needed to interpret a site's value.,,Yes,Yes
31465,FIXME: is there a better trick to find accumulate min of a sequence?,,,Yes
31468,TODO replace BackwardSample with torch_sample backend to ubersum,,,Yes
31470,achieves better results),,No,Yes
31471,TODO: Simplify following line once using multivariate base distributions for multivariate flows,,Yes,Yes
31473,Return (-elbo) since by convention we do gradient descent on a loss and,,,Yes
31474,This illustrates why effect handlers are a useful PPL implementation technique:,,,Yes
31475,TODO: cache these calculations to get faster inference,,No,Yes
31483,structure ends up being faster since each program structure would,,,Yes
31484,Initialize a global module instance if needed.,,No,Yes
31485,We expect models with higher capacity to perform better;,,,Yes
31487,TODO: add support for JIT loss,,Yes,Yes
31488,TODO: Remove once https:\/\/github.com\/tqdm\/tqdm\/issues\/650 is resolved.,,No,Yes
31489,TODO move this into a Leaf implementation somehow,,No,Yes
31490,"\""\""\"" || This example shows how to marginalize out discrete model variables in Pyro. ||  || This combines Stochastic Variational Inference (SVI) with an || Expectation-Maximization (EM) algorithm; where we use enumeration to exactly || marginalize out some variables from the ELBO computation. ||  || To marginalize out discrete variables ``x`` in Pyro's SVI: || 1. Verify that the variable dependency structure in your model ||     admits tractable inference; i.e. the dependency graph among ||     enumerated variables should have narrow treewidth. || 2. Annotate each target each such sample site in the model ||     with ``infer={\""enumerate\"": \""parallel\""}`` || 3. Ensure your model can handle broadcasting of the sample values ||     of those variables || 4. Use the ``TraceEnum_ELBO`` loss inside Pyro's ``SVI``. || \""\""\""",,Yes,Yes
31492,Pyro's TraceEnum_ELBO will find an efficient message passing scheme if one,,,Yes
31493,structure ends up being faster since each program structure would,,,Yes
31494,Initialize a global module instance if needed.,,No,Yes
31495,We expect models with higher capacity to perform better;,,Yes,Yes
31497,narrow treewidth; therefore admitting efficient inference by message passing.,,Yes,Yes
31499,structure ends up being faster since each program structure would,,No,Yes
31500,Initialize a global module instance if needed.,,No,Yes
31504,narrow treewidth; therefore admitting efficient inference by message passing.,,,Yes
31505,Pyro's TraceEnum_ELBO will find an efficient message passing scheme if one,,,Yes
31506,structure ends up being faster since each program structure would,,No,Yes
31508,We expect models with higher capacity to perform better;,,,Yes
31511,Work around PyTorch 1.0.0 bug https:\/\/github.com\/pytorch\/pytorch\/issues\/14875,,,Yes
31512,TODO: Remove `prec` arg; and move usages to assert_close,,,Yes
31513,temporary hack to avoid zero-inflation issues,,Yes,Yes
31514,TODO: Modify class to support more than one eta value at a time?,,Yes,Yes
31515,TODO: Figure out why the `device` kwarg to torch.linspace seems to not work in certain situations;,,,Yes
31516,and a seemingly redundant .to(x.device) is needed below.,,No,Yes
31517,TODO: Provide a way to record divergent transitions,,,Yes
31519,and transforms needed to do this wrapping. Note that only unconstrained parameters,,Yes,Yes
31520,XXX `transforms` domains are sites' supports,,Yes,Yes
31521,FIXME: find a good pattern to deal with `transforms` arg,,Yes,Yes
31524,XXX should the average baseline be in the param store as below?,,Yes,Yes
31525,somewhat better. The reason seems to be some combination of: i) the better,,No,Yes
31528,TODO: Move upstream to allow for pickle serialization of transforms,,Yes,Yes
31529,TODO: Remove when python 2 support is removed.,,,Yes
31530,"XXX we clone CUDA tensor args to resolve the issue \""Invalid device pointer\""",,Yes,Yes
31532,Initialize a global module instance if needed.,,,Yes
31533,"TODO: Add window kwarg that defaults to float(\""inf\"")",,,Yes
31534,TODO: Be clear that these are unnormalized weights. May want to normalize later.,,,Yes
31535,TODO check perplexity,,,Yes
31536,TODO: Turn quadratic algo -> linear algo by being lazier,,Yes,Yes
31538,compute the kernel ingredients needed for SVGD,,No,Yes
31539,Handle diagonal normal distributions as an efficient special case.,,Yes,Yes
31540,TODO move this upstream to torch.distributions,,,Yes
31542,generic way to sample from distributions,,Yes,Yes
31543,seed is used to fix the RNG state when calling a model.,,,Yes
31546,XXX: check_trace=True fails for AutoLaplaceApproximation,,,Yes
31547,XXX: Record `y` as observed in the prototype trace,,,Yes
31548,Is there a better pattern to follow?,,Yes,Yes
31549,TODO: move upstream,,No,Yes
31552,TODO factor this out as a stand-alone helper.,,Yes,Yes
31553,"\""\""\"" || This example implements the Causal Effect Variational Autoencoder [1]. ||  || This demonstrates a number of innovations including: || - a generative model for causal effect inference with hidden confounders; || - a model and guide with twin neural nets to allow imbalanced treatment; and || - a custom training loss that includes both ELBO terms and extra terms needed ||   to train the guide to be able to answer counterfactual queries. ||  || **References** ||  || [1] C. Louizos; U. Shalit; J. Mooij; D. Sontag; R. Zemel; M. Welling (2017). ||     Causal Effect Inference with Deep Latent-Variable Models. ||     http:\/\/papers.nips.cc\/paper\/7223-causal-effect-inference-with-deep-latent-variable-models.pdf ||     https:\/\/github.com\/AMLab-Amsterdam\/CEVAE || \""\""\""",,,Yes
31554,The t and y sites are needed for prediction; and participate in,,,Yes
31555,"\""\""\"" || This module implements the Causal Effect Variational Autoencoder [1]; which || demonstrates a number of innovations including: ||  || - a generative model for causal effect inference with hidden confounders; || - a model and guide with twin neural nets to allow imbalanced treatment; and || - a custom training loss that includes both ELBO terms and extra terms needed ||   to train the guide to be able to answer counterfactual queries. ||  || The main interface is the :class:`CEVAE` class; but users may customize by || using components :class:`Model`; :class:`Guide`; || :class:`TraceCausalEffect_ELBO` and utilities. ||  || **References** ||  || [1] C. Louizos; U. Shalit; J. Mooij; D. Sontag; R. Zemel; M. Welling (2017). ||     | Causal Effect Inference with Deep Latent-Variable Models. ||     | http:\/\/papers.nips.cc\/paper\/7223-causal-effect-inference-with-deep-latent-variable-models.pdf ||     | https:\/\/github.com\/AMLab-Amsterdam\/CEVAE || \""\""\""",,Yes,Yes
31556,The t and y sites are needed for prediction; and participate in,,Yes,Yes
31557,XXX: we might use mvn._unbroadcasted_scale_tril here,,Yes,Yes
31561,TODO Add validation logic for broadcasted samples.,,Yes,Yes
31563,Do a bit of a hack until we merge in Reshape transform,,No,Yes
31564,TODO: move upstream,,,Yes
31565,TODO: Should this be done in log space for numerical stability?,,Yes,Yes
31567,TODO: A useful heuristic for choosing number of bins from input,,,Yes
31568,TODO Use biject_to(fn.support).inv.with_cache(1) once the following merges:,,No,Yes
31569,TODO move this upstream to torch.distributions,,,Yes
31571,TODO re-enable jitting once _SafeLog is supported by the jit.,,Yes,Yes
31573,Do a bit of a hack until we merge in Reshape transform,,No,Yes
31574,TODO refactor to an align_samples or particle_dim kwarg to MCMC.get_samples().,,Yes,Yes
31577,XXX: consider to add a try\/except here:,,,Yes
31581,TODO Consider using pyro.contrib.forecast.util.reshape_batch to,,No,Yes
31582,FIXME Delta is incompatible with relaxed inference.,,Yes,Yes
31583,"\""\""\"" ||  A toy mixture model to provide a simple example for implementing discrete enumeration. ||  ||  (A) -> [B] -> (C) ||  ||  A is an observed Bernoulli variable with Beta prior. ||  B is a hidden variable which is a mixture of two Bernoulli distributions (with Beta priors); ||  chosen by A being true or false. ||  C is observed; and like B; is a mixture of two Bernoulli distributions (with Beta priors); ||  chosen by B being true or false. ||  There is a plate over the three variables for n independent observations of data. ||  ||  Because B is hidden and discrete we wish to marginalize it out of the model. ||  This is done by: ||     1) marking the model method with `@pyro.infer.config_enumerate` ||     2) marking the B sample site in the model with `infer={\""enumerate\"": \""parallel\""}` ||     3) passing `pyro.infer.SVI` the `pyro.infer.TraceEnum_ELBO` loss function || \""\""\""",,,Yes
31589,TODO Remove import guard once funsor is a required dependency.,,Yes,Yes
31590,TODO Remove import guard once funsor is a required dependency.,,,Yes
31591,is there a better way?,,,Yes
31592,TODO: fix upstream - positive_definite has an extra dimension in front of output shape,,Yes,Yes
31593,TODO: use upstream LKJCholesky distribution,,,Yes
31598,"\""\""\"" || A standard profile HMM model [1]; which corresponds to a constant (delta || function) distribution with a MuE observation [2]. This is a standard || generative model of variable-length biological sequences (e.g. proteins) which || does not require preprocessing the data by building a multiple sequence || alignment. It can be compared to a more complex MuE model in this package; || the FactorMuE. ||  || An example dataset consisting of proteins similar to the human papillomavirus E6 || protein; collected from a non-redundant sequence dataset using jackhmmer; can || be found at || https:\/\/github.com\/debbiemarkslab\/MuE\/blob\/master\/models\/examples\/ve6_full.fasta ||  || Example run: || python ProfileHMM.py -f PATH\/ve6_full.fasta -b 10 -M 174 --indel-prior-bias 10. ||     -e 15 -lr 0.01 --jit --cuda || This should take about 9 minutes to run on a GPU. The perplexity should be || around 6. ||  || References: || [1] R. Durbin; S. R. Eddy; A. Krogh; and G. Mitchison (1998) || \""Biological sequence analysis: probabilistic models of proteins and nucleic || acids\"" || Cambridge university press ||  || [2] E. N. Weinstein; D. S. Marks (2021) || \""Generative probabilistic biological sequence models that account for || mutational variability\"" || https:\/\/www.biorxiv.org\/content\/10.1101\/2020.07.31.231381v2.full.pdf || \""\""\""",,Yes,Yes
31599,We fix r_{M+1;j} = 1 for j in {0; 1; 2},,Yes,Yes
31601,Convert between discrete HMM convention for initial state and variable,,No,Yes
31602,length HMM convention.,,,Yes
31603,Here we implement Equation S40 from the MuE paper,,,Yes
31604,Work around a bug in unfold_contraction_generic_tuple interacting with,,,Yes
31605,Needed so setup.py scripts work.,,,Yes
31607,Needed so the setup.py scripts work.,,Yes,Yes
31608,this is good enough. Maybe we need to simulate multiple actions or,,Yes,Yes
31609,Move,,Yes,Yes
31611,"\""\""\""Register\/import the maps; and offer a way to create one by name. ||  || Users of maps should import this module: ||   from pysc2 import maps || and create the maps by name: ||   maps.get(\""MapName\"") ||  || If you want to create your own map; then import the map lib and subclass Map. || Your subclass will be implicitly registered as a map that can be constructed by || name; as long as it is imported somewhere. || \""\""\""",,Yes,Yes
31612,Ignore threads if it's not needed.,,Yes,Yes
31614,Needed for multiplayer.,,Yes,Yes
31615,coords should be computed at run-time; maybe with a trigger type system in,,Yes,Yes
31616,unused,,No,Yes
31619,Needed so setup.py scripts work.,,Yes,Yes
31620,Needed for multiplayer.,,Yes,Yes
31621,unused,,No,Yes
31623,unused,,,Yes
31624,unused,,No,Yes
31625,Unused.,,,Yes
31626,Fade with alpha would be nice; but doesn't seem to work.,,Yes,Yes
31629,Needed for multiplayer.,,,Yes
31630,unused,,,Yes
31631,Unused.,,,Yes
31633,Unused,,No,Yes
31634,Currently we don't get a player result when a realtime game ends;,,,Yes
31636,Move them towards the center; make sure they move and rotate.,,,Yes
31637,Only populate the cache if it's needed.,,No,Yes
31639,unused...,,,Yes
31640,Unused.,,Yes,Yes
31642,unused,,,Yes
31645,Weird; but needed for backwards compatibility,,,Yes
31646,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
31648,instead of (predictions; labels) that users might implement,,Yes,Yes
31649,Recomputing `fake_Y` is needed since `net_D` is changed<\/span><\/td>,,,Yes
31650,Recomputing `fake_Y` is needed since `net_D` is changed,,,Yes
31651,instead of (predictions; labels) that users might implement,,,Yes
31652,Recomputing `fake_Y` is needed since `net_D` is changed,,No,Yes
31654,''' || Created on Feb 16; 2011 || Update on 2017-05-18 || k Means Clustering for Ch10 of Machine Learning in Action || Author: Peter Harrington\/\u90A3\u4F0A\u62B9\u5FAE\u7B11 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31656,''' || Created on Mar 8; 2011 || Update  on 2017-05-18 || Author: Peter Harrington\/\u5C71\u4E0A\u6709\u8BFE\u6811\/\u7247\u523B || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31657,''' || Created on Feb 27; 2011 ||  || Author: Peter || ''',,No,Yes
31658,''' || Created on Feb 27; 2011 || MapReduce version of Pegasos SVM || Using mrjob to automate job flow || Author: Peter || ''',,,Yes
31660,''' || Created on Oct 12; 2010 || Update on 2017-05-18 || Decision Tree Source Code for Machine Learning in Action Ch. 3 || Author: Peter Harrington\/\u7247\u523B || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,,Yes
31666,''' || Created on Jan 8; 2011 || Update  on 2017-05-18 || Author: Peter Harrington\/\u5C0F\u7476 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31667,''' || Created on Jan 8; 2011 || Update  on 2017-05-18 || Author: Peter Harrington\/\u5C0F\u7476 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,,Yes
31670,''' || Created on 2017-05-18 || Update  on 2017-11-17 || Author: Peter Harrington\/1988\/\u7247\u523B || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31671,''' || Created on Jun 1; 2011 || Update  on 2017-12-20 || Author: Peter Harrington\/\u7247\u523B || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31672,''' || Created on Mar 8; 2011 || Update  on 2017-12-12 || Author: Peter Harrington\/\u5C71\u4E0A\u6709\u8BFE\u6811\/\u7247\u523B\/marsjhao || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,,Yes
31675,''' || Created on Sep 16; 2010 || Update  on 2017-05-18 || Author: Peter Harrington\/\u7F8A\u4E09\/\u5C0F\u7476 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31676,''' || Created on Oct 12; 2010 || Update on 2017-05-18 || Decision Tree Source Code for Machine Learning in Action Ch. 3 || Author: Peter Harrington\/\u7247\u523B || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,,Yes
31678,"\""\""\""\r || Created on Oct 19; 2010\r || Update  on 2017-05-18\r || Author: Peter Harrington\/\u7F8A\u4E09\/\u5C0F\u7476\/BBruceyuan\r || GitHub: https:\/\/github.com\/apachecn\/AiLearning\r || \""\""\""",,,Yes
31679,"\""\""\"" || Created on Oct 27; 2010 || Update  on 2017-05-18 || Logistic Regression Working Module || Author: Peter Harrington\/\u7F8A\u4E09\/\u5C0F\u7476\/BBruceyuan || GitHub: https:\/\/github.com\/apachecn\/AiLearning || \""\""\""",,No,Yes
31682,''' || Created on Jan 8; 2011 || Update  on 2017-05-18 || Author: Peter Harrington\/\u5C0F\u7476 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31683,''' || Created on Jan 8; 2011 || Update  on 2017-05-18 || Author: Peter Harrington\/\u5C0F\u7476 || GitHub: https:\/\/github.com\/apachecn\/AiLearning || ''',,No,Yes
31690,Compute values needed for means and stds,,No,Yes
31692,TODO \u8FD9\u4E2A\u540E\u671F\u53EF\u80FD\u8FD8\u9700\u8981\u4FEE\u6539\uFF0C\u6BD5\u7ADF\u5982\u679C\u4F7F\u7528\u7684\u662F\u5B57\u7B26\u7684\u7247\u6BB5\uFF0C\u90A3\u4E2A\u6B63\u6837\u672C\u7684\u6570\u91CF\u662F\u5F88\u591A\u7684\u3002,,No,Yes
31693,TODO \u540E\u671F\u9700\u8981\u4FEE\u6539\u8FD9\u4E2A\u6700\u5C0F\u5C3A\u5BF8\uFF0C\u6539\u4E3A8\uFF1F,,,Yes
31694,TODO: make fast_rcnn irrelevant,,Yes,Yes
31695,needed for Windows,,Yes,Yes
31696,- Secondly; we fix a bunch of command line arguments.,,,Yes
31699,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,Yes,Yes
31700,# IMA configurable parameters (permissible values for each parameter provided here),,,Yes
31703,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31705,'''torch.manual_seed (1) || net = models.vgg11() ||  || ## generate vxbars from feature list in vgg11: || layer_list = [0; 3; 6; 8; 11; 13; 16; 18] || vxbar_list = [] ||  || for layer in layer_list: ||     l = net.features[layer] ||     kernel_size = l.kernel_size ||     in_channels = l.in_channels ||     out_channels = l.out_channels ||  ||     # map to a virtual xbar - each xpoint is full weight (eg: 16 bit weights) ||     numIn_vxbar = in_channels * kernel_size[0] * kernel_size[1] # num of virtual inputs to xbar ||     numOut_vxbar = out_channels # number of virtual outputs from xbar ||     wt = l.weight.data.numpy() ||     vxbar_temp = np.zeros ((numIn_vxbar; numOut_vxbar); dtype=float) ||     for i in range (numOut_vxbar): ||         vxbar_temp[:;i] = wt [i;:;:;:].reshape(numIn_vxbar) ||     vxbar_list.append (vxbar_temp) ||  ||  || # Analyzed the formed vxbar(s) || print ('See size of formed virtual xbars') || for vxbar in vxbar_list: ||     print (np.shape(vxbar)) ||  || #***************************************************************************************************************** || ## Produce actual xbar weights file based on above xbar params (bits & size) || # each list entry is a wtfile list for one vxbar || wtfile_list = [[] for i in range(len(vxbar_list))] # A list of (list of dictionaries) ||  || # hw parameters that will affect mapping (in terms of number of xbars needed) || wt_bits = param.num_bits # 16 || xbar_bits = param.xbar_bits # 2 || xbar_size = param.xbar_size # 128 ||  || for i in range (len(vxbar_list)):  # x: output; y: input; z: weight ||     # axes traversal pattern: z >> x >> y ||     [inp_size; out_size] = np.shape (vxbar_list[i]) ||     for j in range (int(math.ceil(float(out_size)\/xbar_size))): # output ||         for k in range (int(math.ceil(float(inp_size)\/xbar_size))): # input ||             col_end = min ((j+1)*xbar_size-1; out_size) ||             row_end = min ((k+1)*xbar_size-1; inp_size) ||             temp_wtfile  = vxbar_list[i][k*xbar_size:row_end+1; j*xbar_size:col_end+1] ||             temp_wtfile_fixed  = float2fixed_2d (temp_wtfile; param.int_bits; param.frac_bits) ||             for l in range (wt_bits\/xbar_bits): # weight ||                 temp_wtfile_name = 'out' + str (j) + 'inp' + str (k) + 'wt' + str (l) ||                 temp_xbar_val = getBitsFromList (temp_wtfile_fixed; l*xbar_bits; xbar_bits) #matrix; start_bits; num_bits ||                 temp_xbar_val_float = fixed2float_2d (temp_xbar_val; param.int_bits; param.frac_bits) ||                 temp_dict = {'name':temp_wtfile_name; 'xbar_val':temp_xbar_val_float} ||                 wtfile_list[i].append(temp_dict) ||  || # Saving to save time in processing again n again || np.save ('wtfile_list.npy'; wtfile_list) ||  || # Analyzed the formed xbar_files || wtfile_list = np.load ('wtfile_list.npy') || print ('See the number of xbar wt files (program files) generated for each feature layer') || for wtfile in wtfile_list: ||     print (len(wtfile)) ||  || #***************************************************************************************************************** || ## Rules for organizing xbars in tiles and ima based on num_xbar (in ima); num_ima (in tile) || # 1. Each ima maps to one layer only (even if xbars in ima remain unutilized) || # 2. Placement of xbars in imas is focussed to exploit input sharing (Other option: Output Sharing) || # 3. No xbar replication (replication can lead to improved throughput) (Other option: replicate to produce multiple || # ouputs from in an putput map in parallel) ||  || num_xbar = 8 || num_ima = 12''',,,Yes
31706,HACK - modify this based on data sharing across output tiles [IZZAT] terminology] in a node,,,Yes
31708,Defines a configurable IMA module with its methods,,Yes,Yes
31709,"\""Decode\"" stage - Reads operands (if needed) and puts into the specific data structures",,,Yes
31712,(Assumption - 1ADC can process 128 xbar columns in xbar access time),,,Yes
31713,Doesn't replicate the exact (sample and hold) functionality (just does hold),,No,Yes
31715,Defines all the components needed by a node,,Yes,Yes
31717,IMA specific modules (should not be needed),,Yes,Yes
31719,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,,Yes
31721,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31722,# Node configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31724,unless np.dot is implement using fixed point computation,,No,Yes
31730,2-bit (=xbar_bits) are fed to columns of crossbar),,No,Yes
31731,num_adc is 2*num_matrix (no adc needed for delta xbar),,,Yes
31732,read the bw-error to provide inputs across columns - read_a needs an energy\/latency model - needs UPDATE,,Yes,Yes
31733,unless np.dot is implement using fixed point computation,,,Yes
31736,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31737,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31739,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31740,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,,Yes
31741,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31746,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31747,# Tile configurable parameters (permissible values for each parameter provided here),,,Yes
31750,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,Yes,Yes
31751,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31752,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31753,# Node configurable parameters (permissible values for each parameter provided here),,,Yes
31754,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31755,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,,Yes
31756,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31759,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31760,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,,Yes
31762,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31763,# Node configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31764,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31766,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31768,# Node configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31769,in multiples of flits (data considered only - booksim consider address itself),,,Yes
31770,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,Yes,Yes
31773,# Node configurable parameters (permissible values for each parameter provided here),,,Yes
31775,# This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,Yes,Yes
31779,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31782,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31784,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31786,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31787,# Tile configurable parameters (permissible values for each parameter provided here),,,Yes
31789,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31792,split into list of 3-bit masks,,,Yes
31793,FIXME need to review it I can remove adc_lat property,,,Yes
31794,FIXME This is the option 1,,Yes,Yes
31796,# FIXME should we create a adc_array like dac_array object ?,,No,Yes
31801,FIXME Assigning cfg.num_tile_compute after the 'import' does not change,,Yes,Yes
31802,This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,Yes,Yes
31803,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31804,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31808,# IMA configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31809,# Tile configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31810,# Node configurable parameters (permissible values for each parameter provided here),,Yes,Yes
31814,This file contains the configurable parameters in DPE (all hierarchies - IMA; Tile; Node),,,Yes
31817,# Tile configurable parameters (permissible values for each parameter provided here),,,Yes
31819,in multiples of flits (data considered only - booksim consider address itself),,Yes,Yes
31820,d-xbar are not needed in Digital MVMUs xbars than f\/b,,Yes,Yes
31821,TODO: verify that performance on is not affected by batch count,,,Yes
31823,TODO: by default t2 maps have nan values - we should handle these by clipping possibly?,,,Yes
31826,TODO: implement spliting regions,,Yes,Yes
31827,TODO: implement getting quantitative values for regions regions,,,Yes
31829,TODO: implement getting quantitative values for regions regions,,,Yes
31834,TODO: implement getting quantitative values for regions regions,,No,Yes
31835,TODO: save quantitative maps,,No,Yes
31837,TODO: is resizing required? can we keep them in the same dimensions as the input,,,Yes
31838,TODO: save mask in nifti format,,Yes,Yes
31839,TODO: Add support for multiple tissues,,No,Yes
31840,TODO: Issue #2 - too many samples map outside moving image buffer,,Yes,Yes
31842,invert array for convention of SimpleITK --> (depth; row; column),,No,Yes
31843,invert array for convention of SimpleITK - array is now in form (row; column; depth),,Yes,Yes
31844,TODO: not sure if you should do +1; python is 0 indexed,,,Yes
31847,TODO: fix split volumes,,Yes,Yes
31848,"\""\""\"" || Command line interface declaration for knee-related analyses ||  || @author: Arjun Desai ||         (C) Stanford University; 2019 || \""\""\""",,Yes,Yes
31851,phi is used to determine which columns in affine matrix to flip,,,Yes
31852,Compare to baseline echos separated manually,,Yes,Yes
31853,TODO (arjundd): Refactor get\/set methods of mask to property,,,Yes
31854,TODO: Refactor to read from the preferences command line schema,,Yes,Yes
31855,TODO: Refactor to read from the preferences command line schema,,,Yes
31856,TODO: Remove epsilon if difference in performance difference is not large.,,,Yes
31857,This slight difference in the image can affect network performance.,,,Yes
31860,-- Options for todo extension ----------------------------------------------,,,Yes
31863,Author: Peter Michael Stahl <pemistahl@gmail.com>,,,Yes
31864,or next TODO: How to deal with or next instruction,,,Yes
31865,or next ? todo : how to deal with or next,,No,Yes
31867,TODO: Adapt this to our label type for pruning,,No,Yes
31868,TODO: implement memoizing for attributes that require longer computation,,No,Yes
31869,TODO: we could add a tiebreaker,,No,Yes
31870,XXX: Watch out; this will be long for large datasets; might want to use a smarter strategy,,Yes,Yes
31875,TODO: we could add a tiebreaker,,No,Yes
31878,TODO: use the tree callback to calculate the CV score each time a new depth is reached.,,,Yes
31880,TODO: CHANE RGB TO GRAYSCALE,,No,Yes
31882,TODO: add transformer for dataset?,,No,Yes
31883,TODO: REVIEW THIS AGAIN,,,Yes
31884,TODO: add transformer for dataset?,,,Yes
31885,TODO: Consider implementing as -inf or filling up action-buffers,,Yes,Yes
31887,TODO ale vs gym,,Yes,Yes
31890,TODO define better dir-name,,,Yes
31892,TODO whats that?,,,Yes
31893,TODO Gauss and others?,,,Yes
31894,TODO merge with experiment.py,,Yes,Yes
31895,TODO get rid of it somehow!,,,Yes
31896,TODO refactor to experiment,,Yes,Yes
31898,TODO stick with game_over and terminal,,,Yes
31901,TODO refactor to main,,Yes,Yes
31902,TODO define better dir-name,,,Yes
31903,TODO check more variables,,,Yes
31904,TODO steps vs frames,,Yes,Yes
31906,TODO other method than scipy?,,,Yes
31910,TODO compare to max,,Yes,Yes
31911,TODO is this projection correct?,,Yes,Yes
31912,TODO terminal if dead?,,,Yes
31913,TODO what is it doing?,,No,Yes
31915,TODO steps vs frames,,,Yes
31918,TODO define better dir-name,,,Yes
31920,TODO cpickle vs json,,Yes,Yes
31924,TODO json?,,,Yes
31925,TODO fix bug,,,Yes
31926,TODO use pop,,Yes,Yes
31928,TODO pyflann??,,,Yes
31929,TODO batch update,,,Yes
31930,TODO check np.allclose,,,Yes
31931,TODO None; None is ugly,,Yes,Yes
31935,TODO don't stop in the middle of an episode,,Yes,Yes
31936,TODO batch-update,,Yes,Yes
31938,TODO not in mfec paper,,Yes,Yes
31940,TODO not mfec paper,,,Yes
31941,TODO use some common agent-interface,,,Yes
31942,TODO np.allclose,,Yes,Yes
31943,TODO init here!,,Yes,Yes
31946,TODO not in mfec paper,,,Yes
31947,TODO not mfec paper,,Yes,Yes
31950,TODO LIVE_LOSE_PENALTY = 25,,Yes,Yes
31951,TODO stop if dead,,Yes,Yes
31952,TODO improve stats-output,,Yes,Yes
31953,TODO init-phase,,Yes,Yes
31955,TODO not in the paper,,,Yes
31957,TODO paper?,,Yes,Yes
31958,TODO paper?,,Yes,Yes
31959,TODO move all results related stuff to utils,,Yes,Yes
31963,TODO store detailed-output,,Yes,Yes
31964,TODO round reward-avg,,Yes,Yes
31969,TODO ordering instead?,,Yes,Yes
31971,#### Frequency of Age [Scaling is needed],,No,Yes
31972,### Frequency of Age [Scaling is needed],,,Yes
31973,"feature_columns = [tf.contrib.layers.real_valued_column(\""\""; dimension=4)]",,,Yes
31974,"optimizer=\""Adam\""; feature_columns=feature_columns )",,,Yes
31975,if 'Name' in df.columns:,,No,Yes
31976,if 'Surname' in df.columns:,,,Yes
31977,if 'Party_Name' in df.columns:,,No,Yes
31978,if 'Party_Surname' in df.columns:,,No,Yes
31979,if 'Policy_Holder_Area' in df.columns:,,,Yes
31980,if 'Province' in df.columns:,,No,Yes
31982,if 'index' in df.columns:,,,Yes
31983,so for now; by convention only the key PAST will be returned,,Yes,Yes
31984,Get a single inflections for the tag.  Use OOV rules if needed.,,Yes,Yes
31987,Set tensorflow configs to only grow the memory to what is needed.,,Yes,Yes
31988,"which are the components between the braces \""{xxx}\""",,Yes,Yes
31989,Hack the code to replace the overrides dictionary,,Yes,Yes
31990,Hack the code to replace the overrides dictionary,,,Yes
31994,TODO: set up the data for fitting,,,Yes
31996,TODO:,,No,Yes
31998,TODO: BayesianCorrelation\uFFFF,,,Yes
32003,TODO: should really do straight in tf;,,,Yes
32005,TODO: evaluate log_prob w\/ tf like above,,Yes,Yes
32007,TODO: evaluate log_cdf w\/ tf like above,,Yes,Yes
32010,TODO: NeuralMatrixFactorization,,,Yes
32012,TODO: implement,,,Yes
32014,TODO: ???,,,Yes
32017,TODO: wait do you need to do .sample() here?,,No,Yes
32018,TODO: ???,,No,Yes
32022,somehow need to be able to take the mean of every variational parameter...,,,Yes
32023,maybe you should also have meanify(); and meanify_args(),,No,Yes
32024,TODO: LSTM\uFFFF,,,Yes
32026,TODO: check types of x; y; and x_by.,,No,Yes
32027,TODO: same idea as log_prob above,,Yes,Yes
32028,TODO: same idea as log_prob_by above,,Yes,Yes
32029,TODO: no this isn't right; you need to be able to access the dists of,,Yes,Yes
32030,TODO: define continuous vs categorical distributions? (and inherit accordingly?),,,Yes
32031,TODO: other common distributions,,,Yes
32033,NOTE: may have to implement manually w\/ bk.Variable? in order to let the mean_model work...,,Yes,Yes
32035,TODO: Pooling layer,,Yes,Yes
32036,TODO,,,Yes
32037,TODO: build input,,,Yes
32041,TODO,,Yes,Yes
32043,TODO: hmm; well if you can compute the log loss of it then... maybe these,,,Yes
32046,TODO: this is wrong:,,No,Yes
32047,TODO: well; this returns *a* normal distribution; but is that what we want?,,,Yes
32051,that'll be inefficient tho; maybe just use ReLU?,,,Yes
32053,TODO: Probit,,,Yes
32054,TODO: shape must be list of ints,,No,Yes
32056,TODO: handle when lb (lower bound) or ub (upper bound) is not empty,,,Yes
32057,TODO: handle arbitrary types of posterior distributions?,,Yes,Yes
32058,TODO: should return a tensor generated w\/ flipout w\/ correct batch shape,,,Yes
32060,TODO: transform generated values w\/ exp (if one of ub or lb is set);,,,Yes
32061,TODO: transform w\/ exp or logit if needed (depending on if lb and ub are set),,Yes,Yes
32063,TODO: name must be str;,,,Yes
32064,TODO,,Yes,Yes
32066,TODO: have to add KL term?,,Yes,Yes
32067,TODO: transpose sign_in?,,Yes,Yes
32068,TODO,,,Yes
32070,TODO: _default_args should really only be for *tensor* (or tensor-generating),,Yes,Yes
32071,TODO: Check that the built prior shape is broadcastable w\/ self.shape,,Yes,Yes
32072,TODO: confusion_matrix (plot\/return the confusion matrix of predictions),,,Yes
32079,TODO: Softmax (?),,,Yes
32082,TODO: Exp,,,Yes
32083,TODO: Log,,No,Yes
32085,TODO: Neg,,,Yes
32088,TODO: Dense layer,,Yes,Yes
32090,TODO: _mean,,Yes,Yes
32091,TODO: _log_loss,,Yes,Yes
32092,TODO: _kl_loss,,,Yes
32093,TODO: posterior,,,Yes
32094,TODO: will have to be some way to distinguish batch_size from dimensions from number of independent dists?,,,Yes
32095,TODO: Dot (dot product),,Yes,Yes
32096,TODO: matrix multiplication?,,No,Yes
32097,TODO: Concatenate,,,Yes
32099,TODO: matrix multiplication?,,,Yes
32100,TODO: uh how can you access the sampled values of weight and bias from here?,,,Yes
32102,TODO: could just make variable and layer have same interface; ie,,Yes,Yes
32104,TODO: Logit,,,Yes
32105,TODO: Probit,,,Yes
32107,TODO: this will only work w\/ vector inputs...,,,Yes
32108,TODO: don't think this will work w\/ tensors of >2 dims...,,,Yes
32110,TODO: Logit,,,Yes
32111,TODO: Probit,,No,Yes
32112,TODO,,Yes,Yes
32113,TODO: _sample,,Yes,Yes
32116,TODO: _kl_loss,,Yes,Yes
32118,TODO: dtype?,,,Yes
32119,TODO,,Yes,Yes
32120,TODO: uh but if you call .posterior() on what this returns it will,,No,Yes
32125,TODO,,,Yes
32129,TODO: this might not be the best way to do it...,,,Yes
32130,TODO: will have to check built_obj; mean_obj; _built_obj_raw; _mean_obj_raw; _log_loss; _mean_log_loss; and _kl_loss,,,Yes
32131,TODO: x;y input should be able to be np arrays; pandas arrays; or tf dataset iterators,,,Yes
32133,TODO: will have to check built_obj; mean_obj; _built_obj_raw; _mean_obj_raw; _log_loss; _mean_log_loss; and _kl_loss,,Yes,Yes
32136,TODO: determine a good default learning rate?,,Yes,Yes
32137,TODO: print progress every so often,,Yes,Yes
32138,TODO: evaluate metrics on validation data,,,Yes
32140,TODO: time is a debugger,,Yes,Yes
32141,TODO: there's a bug somewhere...,,,Yes
32142,TODO,,Yes,Yes
32143,TODO: and then print the results,,No,Yes
32145,TODO: other layers,,,Yes
32148,TODO: how to support integer columns?,,,Yes
32149,TODO: set optimizer based on optimizer arg,,No,Yes
32150,TODO,,Yes,Yes
32157,TODO: getting an error if you try to make duplicate *non-default* names,,,Yes
32160,TODO: may want to have an option to add legends w\/ indexes,,,Yes
32161,TODO,,Yes,Yes
32170,TODO: cross-entropy; etc,,Yes,Yes
32171,TODO: how to support integer columns?,,,Yes
32173,TODO,,Yes,Yes
32175,TODO,,Yes,Yes
32180,TODO: plot if main,,No,Yes
32181,TODO: once per batch,,No,Yes
32183,TODO: plot_predictive_distribution(),,,Yes
32184,TODO,,,Yes
32192,TODO: plot if main,,No,Yes
32194,TODO: ensure y is scalar,,,Yes
32198,Inputs should have been assigned integer columns,,,Yes
32200,TODO: make a scope for this layer's variables,,,Yes
32201,TODO: make a scope for this layer's variables,,Yes,Yes
32204,TODO: need to figure out gathering samples,,No,Yes
32206,TODO,,,Yes
32208,TODO: check for when true y value is above max pred_dist val!,,,Yes
32215,need to somehow dynamically cast the logits correctly...,,Yes,Yes
32220,TODO: check if observation distribution is one for which the,,Yes,Yes
32224,TODO also setting sampling flag might be a problem when using @tf.function,,,Yes
32225,TODO: type check?,,No,Yes
32226,"\""\""\""Parameters. ||  || Parameters are values which characterize the behavior of a model.  When || fitting a model; we want to find the values of the parameters which || best allow the model to explain the data.  However; with Bayesian modeling || we want not only to find the single *best* value for each parameter; but a  || probability distribution which describes how likely any given value of  || a parameter is to be the best or true value. ||  || Parameters have both priors (probability distributions which describe how || likely we think different values for the parameter are *before* taking into || consideration the current data); and posteriors (probability distributions  || which describe how likely we think different values for the parameter are || *after* taking into consideration the current data).  The prior is set  || to a specific distribution before fitting the model.  While the *type* of  || distribution used for the posterior is set before fitting the model; the  || shape of that distribution (the value of the parameters which define the || distribution) is optimized while fitting the model. || See the :ref:`math` section for more info. ||  || The :class:`.Parameter` class can be used to create any probabilistic || parameter.  ||  || For convenience; ProbFlow also includes some classes which are special cases || of a :class:`.Parameter`: ||  || * :class:`.ScaleParameter` - standard deviation parameter || * :class:`.CategoricalParameter` - categorical parameter || * :class:`.BoundedParameter` - parameter which is bounded between 0 and 1 || * :class:`.PositiveParameter` - parameter which is always greater than 0 ||  || ---------- ||  || \""\""\""",,Yes,Yes
32230,TODO: all other ops used by probflow internals,,Yes,Yes
32231,TODO: default device (for pytorch at least),,Yes,Yes
32236,TODO: jaccard_similarity,,,Yes
32238,TODO: cross_entropy,,No,Yes
32239,TODO: fixtures if you need them,,Yes,Yes
32241,TODO: workaround for a TF req,,No,Yes
32242,TODO: check it has fit correctly,,,Yes
32243,TODO: check it has fit correctly,,No,Yes
32245,TODO: distributions should be a pf; tf; or pt distribution,,Yes,Yes
32248,TODO: check output looks correct,,,Yes
32249,TODO: mean isn't implemented,,Yes,Yes
32252,TODO,,Yes,Yes
32253,TODO: doesn't actually support DataGenerator yet b\/c doesn't get y?,,,Yes
32256,TODO: n_mc_samples (when that's implemented),,No,Yes
32258,TODO: mean isn't implemented,,,Yes
32261,TODO,,Yes,Yes
32262,TODO,,,Yes
32264,"\""\""\"" || Parameters are values which characterize the behavior of a model.  When || fitting a model; we want to find the values of the parameters which || best allow the model to explain the data.  However; with Bayesian modeling || we want not only to find the single *best* value for each parameter; but a || probability distribution which describes how likely any given value of || a parameter is to be the best or true value. ||  || Parameters have both priors (probability distributions which describe how || likely we think different values for the parameter are *before* taking into || consideration the current data); and posteriors (probability distributions || which describe how likely we think different values for the parameter are || *after* taking into consideration the current data).  The prior is set || to a specific distribution before fitting the model.  While the *type* of || distribution used for the posterior is set before fitting the model; the || shape of that distribution (the value of the parameters which define the || distribution) is optimized while fitting the model. || See the :ref:`ug_math` section for more info. ||  || The :class:`.Parameter` class can be used to create any probabilistic || parameter. ||  || For convenience; ProbFlow also includes some classes which are special cases || of a :class:`.Parameter`: ||  || * :class:`.ScaleParameter` - standard deviation parameter || * :class:`.CategoricalParameter` - categorical parameter || * :class:`.DirichletParameter` - parameter with a Dirichlet posterior || * :class:`.BoundedParameter` - parameter which is bounded between 0 and 1 || * :class:`.PositiveParameter` - parameter which is always greater than 0 || * :class:`.DeterministicParameter` - a non-probabilistic parameter || * :class:`.MultivariateNormalParameter` - parameter with a multivariate Normal posterior ||  || See the :ref:`user guide <ug_parameters>` for more information on Parameters. ||  || ---------- ||  || \""\""\""",,Yes,Yes
32265,MacOS+Python3.8 workaround,,No,Yes
32266,MacOS+Python3.8 workaround,,,Yes
32267,TODO: should also support numpy arrays + backend tensors,,,Yes
32269,assert dist.mean().numpy() == 1.0 #NOTE: pytorch doesn't implement mean(),,Yes,Yes
32270,TODO: Do we really need parent node be abstract node???,,Yes,Yes
32271,if not have_align: TODO: 16\/17 did not split,,,Yes
32274,if needed; a fixed seed could be passed here to generate same random (to help debugging),,Yes,Yes
32275,remap i to another unmatched node (move),,,Yes
32278,print if needed,,No,Yes
32279,TODO: can a virtual node be a variable node? virtual ndoe?? variable node???,,Yes,Yes
32284,TODO: delete num_deriv and visited; should still work for damrs,,Yes,Yes
32286,TODO: ugly; should use bfs instead of keeping num_deriv variable,,No,Yes
32287,TODO: compare efficiency of this and bfs slower version???,,,Yes
32289,TODO: derive comp_rhs???,,No,Yes
32291,TODO: update get_output_tree and get_output_string later,,,Yes
32292,TODO: have a strict definition of restruct rule,,,Yes
32295,"TODO: yanggao20130816 modified to allow alignment like \""jon\""~e.6",,No,Yes
32297,TODO: ygao20120820: do it more properly,,,Yes
32298,"TODO: currently only insert something like \"":modal x0\""",,,Yes
32299,TODO: assert that psrfeat is :or-op,,,Yes
32300,TODO: assert that psrfeat is :or,,No,Yes
32303,TODO: see if this variable is passed,,No,Yes
32308,TODO: third member used to be new_composed_rhs,,,Yes
32311,TODO; ugly; should use bfs instead of keeping ceo_dict,,Yes,Yes
32313,TODO: consider edge alignment such as :topic,,Yes,Yes
32314,TODO: change DerivationNode_Align to DerivationNode only!,,,Yes
32316,TODO: binarization with :topic~e.3,,No,Yes
32317,TODO: tree.children[0] or tree.children[-1] may be aligned to more than one feat; or may be unaligned,,Yes,Yes
32325,TODO: yanggao20130916: keep only uniq rules from binarization; this is buggy because seemingly duplicate rules may come from different AMR nodes,,,Yes
32326,TODO: may use up the memory,,,Yes
32328,TODO: presume lowercase; yet should have lowercased feat.edge; etc,,Yes,Yes
32329,TODO: more rules; like 11-20; 30; etc.; as well as dozen; score? four hundred; four thousand; etc,,Yes,Yes
32330,TODO: cannot handle this (p \/ phone-number-entity :value 18005551212),,,Yes
32334,TODO: parse into amr first!!!,,Yes,Yes
32335,TODO: handle case of inserting to empty file,,Yes,Yes
32336,x-coordinates of edge ends,,,Yes
32338,z-coordinates of edge ends,,No,Yes
32339,to fix,,Yes,Yes
32340,to fix,,Yes,Yes
32341,"\""\""\""# returns the membership map -> {code: membership} manually clusterized || def get_membership_map(filename; sep=\"" ; \""): ||     return {take_part(1; line; sep): take_part(2; line; sep) for line in open(filename; \""r\"")}\""\""\""",,Yes,Yes
32343,y-coordinates of edge ends,,No,Yes
32345,it's needed because ground truth can have discontinuous cluster set,,,Yes
32347,it's needed because ground truth can have discontinuous cluster set,,,Yes
32349,TODO other ways to determine the output shape,,Yes,Yes
32350,TODO other ways to determine the output shape,,Yes,Yes
32354,TODO: use keras backend instead of tf.,,No,Yes
32355,keep quotes; but move into their own token,,Yes,Yes
32356,return the most common pronouns in the text (TODO: Automate),,,Yes
32357,print(token_sentence_dict) # TODO: switch to namedTuples,,No,Yes
32361,TODO: switch to namedTuples,,Yes,Yes
32362,TODO Next: import local file to predict male\/female (he\/she) with a given list of names,,No,Yes
32363,# TODO: SAVE DICT_PARTS_SPEECH TO CSV,,No,Yes
32365,TODO: update nouns list with only named enitites,,,Yes
32366,TODO: identify dialouge to create it as its own sentence,,No,Yes
32368,TODO: update nouns list with only named enitites,,Yes,Yes
32369,TODO: predict gender with probailities to allow for abiguity,,No,Yes
32370,TODO: EXPAND PROPER NOUNS FOR COMMON WORDS AROUND WORD,,Yes,Yes
32371,"TODO: debug dialouge for \""words\"" said person \""words again\""",,No,Yes
32375,TODO: split sentences with question marks (see 20k end),,Yes,Yes
32379,looking at x sentences at a time (could be automatically re-adjusted to fix max size of text),,Yes,Yes
32382,TODO: update plotting with sentence length,,No,Yes
32384,TODO: set up progress bar for proper noun and pronoun splicing for large text,,,Yes
32390,TODO: check CAPTALIZED WORDS as their lower case counterparts before saving,,Yes,Yes
32392,TODO: FIND PRONOUNS\/PROPER NAMES close to puncation: what do you make of it? don't do it!,,,Yes
32393,TODO: add 'de' to names list to connect values: ex) Jeremiah de Saint-Amour,,,Yes
32394,TODO: find possesive 'you've' and 'my',,Yes,Yes
32395,TODO: check CAPTALIZED WORDS as their lower case counterparts before saving,,Yes,Yes
32396,TODO: move to a seperate file (up to readFile),,No,Yes
32397,if the gne ends with a connecting word; ignore the connecting name: 'Tom of the' -> 'Tom',,,Yes
32398,TODO: create sub trees for names that don't share names: 'Dr Juvenal Urbino' vs. 'Dr Lacides Olivella',,Yes,Yes
32399,TODO: genearte a gne hierachy of names,,,Yes
32403,TODO: set up trees with gender lieklyhood,,,Yes
32404,TODO: rather than find the longest name; keep a list of the most common word used between ['wendy'; 'peter pan'],,,Yes
32405,len(pronoun_noun_dict['found_proper_name_value'])\/10 # random additional amount (TODO),,No,Yes
32408,TODO: remove all captilized words from the gne tree?,,,Yes
32409,TODO: set up a way to remove elements from GNES (example: 'Dear Peter'; 'Dear Fogg'),,No,Yes
32410,TODO: remove all captilized words from the gne tree?,,Yes,Yes
32411,TODO: set up a way to remove elements from GNES (example: 'Dear Peter'; 'Dear Fogg'),,No,Yes
32412,TODO: set up gender trees,,,Yes
32413,TODO: set up gender trees,,Yes,Yes
32414,TODO: set up interactions,,Yes,Yes
32415,"TODO: update proper noun to total words with gne \""_n#\"" \/ total words",,Yes,Yes
32416,TODO: visual gender name database classifier,,,Yes
32418,TODO: move all imports to top,,Yes,Yes
32420,TODO: move all imports to top,,Yes,Yes
32421,TODO: set up gender trees,,Yes,Yes
32422,TODO: visual gender name database classifier,,,Yes
32426,TODO: set up a dotted plot line for the mean (bot),,,Yes
32429,TODO: move all imports to top,,,Yes
32430,TODO: fix pos data for gnes to run for each row rather than the last text,,,Yes
32431,TODO: set up a network with relationships with polarity over time,,Yes,Yes
32432,TODO: set up gender trees,,Yes,Yes
32433,TODO: visual gender name database classifier,,,Yes
32436,TODO: set up a network with relationships with polarity over time,,Yes,Yes
32437,TODO: original scarlet letter includes 'Old Roger Chillingworth'; new doesn't; find cause,,Yes,Yes
32438,TODO: Update counter for each name,,,Yes
32439,TODO: fix oz network (add 'wizard' and 'witch'),,No,Yes
32442,If capture_success == fail then the stone lives => valid move,,Yes,Yes
32443,Call this method only when a move is verified as a valid move,,,Yes
32444,If capture_success == fail then the stone lives => valid move,,Yes,Yes
32445,Call this method only when a move is verified as a valid move,,No,Yes
32447,Update move,,Yes,Yes
32448,convert 'gender' values to new columns,,No,Yes
32449,convert 'Embarked' values to new columns,,,Yes
32452,drop columns with null values,,,Yes
32454,drop unwanted columns,,,Yes
32455,Implement [LINEAR -> RELU]*(L-1).,,,Yes
32456,Implement [LINEAR -> RELU]*(L-1); with dropout,,Yes,Yes
32457,drop unwanted columns,,,Yes
32460,# drop unwanted columns,,No,Yes
32461,drop unwanted columns,,Yes,Yes
32462,todo,,No,Yes
32463,todo #convert this to a wrapper,,No,Yes
32465,Improve performance by trimming to top anchors by score,,No,Yes
32467,TF doesn't have a way to sort by two columns; so merge them and sort.,,,Yes
32468,TODO: Rename target_bbox to target_deltas for clarity,,No,Yes
32469,TODO: better to keep them normalized until later,,Yes,Yes
32473,TODO: use smooth_l1_loss() rather than reimplementing here,,Yes,Yes
32475,TODO: To hard example mine or not to hard example mine; that's the question,,Yes,Yes
32476,TODO: If multiple anchors have the same IoU match all of them,,,Yes
32477,For positive anchors; compute shift and scale needed to transform them,,,Yes
32483,TODO: move resizing to mold_image(),,,Yes
32485,TODO: Build and use this function to reduce code duplication,,,Yes
32488,TODO: Replace with matplotlib equivalent?,,,Yes
32491,@todo Implement a working Bayer->RGB conversion,,,Yes
32494,@todo - FIX this!,,,Yes
32498,@todo accidentally appending to an existing file could be dangerous,,Yes,Yes
32501,@todo: make datafilename autogenerated to easier batch processing,,Yes,Yes
32503,@todo accidentally appending to an existing file could be dangerous,,Yes,Yes
32506,@todo tidy up this,,,Yes
32508,@todo realtime plotting will no longer work because the averaged,,No,Yes
32509,@todo FIX if there are ambiguous dimentions; assume RGB color space,,Yes,Yes
32510,this particle; and move on,,,Yes
32511,re-scale the instensities in the image to chop off some ends,,,Yes
32512,@TODO  : create function that builds stats,,No,Yes
32513,merge regionprops statistics with a seperate bounding box columns,,No,Yes
32514,merge regionprops statistics with a seperate bounding box columns,,,Yes
32516,merge regionprops statistics with a seperate bounding box columns,,No,Yes
32517,@todo this means that processing on a mchine with pymba installed will,,,Yes
32519,@todo this means that processing on a mchine with pymba installed will,,,Yes
32520,@todo Implement a working Bayer->RGB conversion,,,Yes
32522,@todo Implement a working Bayer->RGB conversion,,Yes,Yes
32524,'probability_diatom_chain;probability_oily_gas;export name;timestamp\ || '; 'columns not properly built',,Yes,Yes
32525,@todo include saturation here too,,,Yes
32526,@todo also include particle stats here too.,,Yes,Yes
32527,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
32528,TODO: move this import to the top,,,Yes
32531,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,Yes,Yes
32532,TODO: move this import to the top,,,Yes
32533,@todo make this number of particle per image; and sum according to index later,,,Yes
32534,@todo make this number of particle per image; and sum according to index later,,Yes,Yes
32537,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,Yes,Yes
32541,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,Yes,Yes
32545,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,Yes,Yes
32548,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,Yes,Yes
32549,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,,Yes
32551,TODO: Should this be printed?,,Yes,Yes
32552,TODO: WHy is there a print here? warning should write to sys.stderr anyway,,,Yes
32554,logger.info('  Columns:  ' + str(stats.columns)),,No,Yes
32555,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
32556,"\""\""\"" || Implementation of the Deep Embedded Self-Organizing Map model || Autoencoder helper function ||  || @author Florent Forest || @version 1.0 || \""\""\""",,Yes,Yes
32557,"\""\""\"" || Implementation of the Deep Embedded Self-Organizing Map model || Main file ||  || @author Florent Forest || @version 1.0 || \""\""\""",,Yes,Yes
32558,"\""\""\"" || Implementation of the Deep Embedded Self-Organizing Map model || SOM layer ||  || @author Florent Forest || @version 1.0 || \""\""\""",,,Yes
32559,"\""\""\"" || @author XXX || DESOM benchmarking script || \""\""\""",,,Yes
32560,"\""\""\"" || Implementation of the Kerasom model (standard SOM in Keras) || Main file ||  || @author Florent Forest || @version 1.0 || \""\""\""",,Yes,Yes
32562,whether fix Mmin or nbar,,Yes,Yes
32563,number of nodes needed,,Yes,Yes
32564,move positions to redshift-space,,Yes,Yes
32565,number of nodes needed,,Yes,Yes
32568,number of nodes needed,,,Yes
32569,move particles to redshift-space,,Yes,Yes
32570,find the vector with the X-values (only needed to save the covariances),,No,Yes
32571,move ics.* to ICs folder,,Yes,Yes
32573,move particles to redshift-space,,Yes,Yes
32574,number of nodes needed,,Yes,Yes
32578,realizations of the same cosmology are needed,,,Yes
32579,realizations of the same cosmology are needed,,,Yes
32582,Test if the vector has the wrong direction (lines instead of columns),,Yes,Yes
32583,"matrix \""mode\"": the number of vars is equal to the number of columns of H",,,Yes
32584,Reduce the size of the matrix as needed,,No,Yes
32586,move particles to redshift-space,,Yes,Yes
32588,move particles to redshift-space,,Yes,Yes
32589,read only the necessary columns from the CSV,,No,Yes
32591,TODO: Add LR Scheduler,,,Yes
32592,TODO: add time to path,,No,Yes
32593,TODO: Add proper logging,,,Yes
32594,TODO: load images on the fly,,No,Yes
32595,TODO: clean up,,Yes,Yes
32597,FIXME pass custom list of harmonies,,Yes,Yes
32606,moving averages ends up in the trainable variables collection,,No,Yes
32609,would be a nice idea if the upsampling could be learned too;,,,Yes
32611,Store values needed for backpropagation,,Yes,Yes
32612,Red columns.,,No,Yes
32615,Implement classification algorithm,,,Yes
32616,Move into target folder and read genre names,,Yes,Yes
32617,Move to genre,,,Yes
32618,Implement Music Genre Classification,,,Yes
32620,Apply normalizarion to all columns,,,Yes
32621,Apply standardization to all columns,,Yes,Yes
32625,Apply centering to all columns,,Yes,Yes
32627,TODO: bug when EOS is used and BOS is not used!,,No,Yes
32628,and (xxx is not None)...,,,Yes
32633,"\""\""\"" || #   This is the application (probably basic) to find the location (almost any) in any Country  || #   according to the choices of your preference. Uses Foursquare API to get the data (geojson); || #   also uses shitty tkinter GUI for accepting data. Please provide the Access key for the API || #   if bychance not given! This then creates a custom-made http server to visualise the locations || #   in a web browser; because Folium (leaflet.js) doesn't work in GUI or Terminal LOL! || #    || #   Caution: Please don't blame me if this doesn't works; cause the data may not be present for  || #            some location; since everyone will use free services of foursquare API. || # || #   @Copyright :: Don't share this software without the permission of the author || # || #   e-mail : jimutbahanpal@yahoo.com || #    || #   Created for the purpose of final year project! :=> Almost data visualization project! || # || #   Dated : 10-02-2019 || \""\""\""",,,Yes
32634,keep only columns that include venue name; and anything that is associated with location,,,Yes
32638,keep only columns that include venue name; and anything that is associated with location,,Yes,Yes
32639,"\""\""\"" || #   This is the application (probably basic) to find the location (almost any) in any Country  || #   according to the choices of your preference. Uses Foursquare API to get the data (geojson); || #   also uses shitty tkinter GUI for accepting data. Please provide the Access key for the API || #   if bychance not given! This then creates a custom-made http server to visualise the locations || #   in a web browser; because Folium (leaflet.js) doesn't work in GUI or Terminal LOL! || #    || #   Caution: Please don't blame me if this doesn't works; cause the data may not be present for  || #            some location; since everyone will use free services of foursquare API. || # || #   @Copyright :: Don't share this software without the permission of the author || # || #   e-mail : jimutbahanpal@yahoo.com || #    || #   Created for the purpose of final year project! :=> Almost data visualization project! || #   http:\/\/www.tayloredmktg.com\/rgb\/ for selecting and customising this s\/w || #   Dated : 10-02-2019 || \""\""\""",,Yes,Yes
32640,keep only columns that include venue name; and anything that is associated with location,,Yes,Yes
32642,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,,Yes
32643,keep only columns that include venue name; and anything that is associated with location,,Yes,Yes
32644,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,,Yes
32645,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,Yes,Yes
32647,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,Yes,Yes
32648,keep only columns that include venue name; and anything that is associated with location,,Yes,Yes
32649,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,Yes,Yes
32651,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,Yes,Yes
32653,"\""\""\"" || #   This is the application (probably basic) to find the location (almost any) in any Country  || #   according to the choices of your preference. Uses Foursquare API to get the data (geojson); || #   also uses tkinter GUI for accepting data. Please provide the Access key for the API || #   if bychance not given! This then creates a custom-made http server to visualise the locations || #   in a web browser; because Folium (leaflet.js) doesn't work in GUI or Terminal. || #    || #   Caution: Please don't blame me if this doesn't works; cause the data may not be present for  || #            some location; since everyone will use free services of foursquare API. || # || #   @Copyright :: Don't share this software without the permission of the author || # || #   e-mail : jimutbahanpal@yahoo.com || #   website : https:\/\/jimut123.github.io || #   Created for the purpose of final year project! :=> Almost data visualization project! || #    || #   Dated : 10-02-2019 || \""\""\""",,Yes,Yes
32655,keep only columns that include venue name; and anything that is associated with location,,,Yes
32657,To clean the list if by chance someone has given unnecessary values or empty values or unused text entry box,,,Yes
32658,keep only columns that include venue name; and anything that is associated with location,,Yes,Yes
32659,TODO: consider using jax.random and thus drawing new samples every time;,,,Yes
32660,TODO: use median once supported by jax.numpy:,,Yes,Yes
32661,TODO: maybe check region around original input,,No,Yes
32662,fixed param: x0; b_finite; vec,,,Yes
32663,NOTICE: this improves the dual value; but it is a HACK as we optimize,,No,Yes
32668,"\""\""\""\r || Modification of the function 'DBspeech_wav_reader.py' of the deep-speaker created by philipperemy \r || Working on python 3\r || Input : DB path\r || Output : 1) Make DB structure using pd.DataFrame which has 3 columns (file id; file path; speaker id; DB id)\r ||             => 'read_DB_structure' function\r ||          2) Read a wav file from DB structure\r ||             => 'read_audio' function\r || \r || <corpus root> Speaker_robot_DB\r ||     |\r ||     .- S1_light_700_mod\/\r ||     |        |\r ||     |        .- C001F2\/\r ||     |        |     |\r ||     |        |     .- C001F2INDE001.txt\r ||     |        |     |\r ||     |        |     .- C001F2INDE001.wav\r ||     |        |     |\r ||     |        |     .- C001F2INDE002.txt\r ||     |        |     |\r ||     |        |     ...\r ||     |        |\r ||     |        .- C001M3\/\r ||     |              |\r ||     |              ...\r ||     |\r ||     .- Etri_readsent\/\r ||     |        | ...\r || \r || \""\""\""",,No,Yes
32669,order to prevent any memory allocation on unused GPUs,,Yes,Yes
32670,"\""\""\"" || Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks || https:\/\/arxiv.org\/pdf\/1511.06434 ||  || Notes: ||     Model architecture differs from paper: ||         generator ends with Sigmoid ||         inputs normalized to [0;1] ||         learning rates differ ||  || \""\""\""",,Yes,Yes
32674,scheduler.step()  TODO,,No,Yes
32675,hack for bincounting 2 arrays together,,No,Yes
32676,Store parameters that are needed later,,,Yes
32681,''' Randomly move the gate around; while keeping it inside the boundaries ''',,,Yes
32682,TODO,,,Yes
32685,TODO,,Yes,Yes
32686,TODO: If count > dataset.size; duplicate!,,,Yes
32687,TODO,,,Yes
32688,TODO: verify that,,No,Yes
32691,TODO: Is it the right method ??,,,Yes
32693,TODO: Compute from the origin,,No,Yes
32695,TODO: Save the annotation in the output CSV file,,,Yes
32697,TODO: EXPLAIN WHY IT WORKS WHEN I FLIP [2][2] AND [3][2],,Yes,Yes
32698,TODO: Set to null if the camera is within 50cm of the gate !! (cause,,,Yes
32701,TODO: Maybe also make sure it's in the field of view ?,,,Yes
32703,TODO: Move the gate center back to the image frame if it's slightly,,,Yes
32706,TODO: Make this dirty hack cleaner,,Yes,Yes
32708,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
32709,TODO: clean data and simplify the procedure of time preprocessing,,Yes,Yes
32710,TODO: let tfidf of corpus be init embeddings,,No,Yes
32712,get min values for each of columns,,,Yes
32713,TODO: is this step necessary for updating weights in rbm?,,No,Yes
32714,TODO: comment this line in production environment,,,Yes
32717,TODO: make sure using x or recon_x?,,No,Yes
32718,TODO: uncomment this line in production environment,,Yes,Yes
32719,(remove columns which are not included in PRESERV_TERMS),,No,Yes
32720,action must be a valid move,,,Yes
32723,copyright notice and this permission notice appear in all copies.,,No,Yes
32725,copyright notice and this permission notice appear in all copies.,,No,Yes
32727,move = (move[0]+direction[0]; move[1]+direction[1]),,Yes,Yes
32728,while 0<=move[0] and move[0]<n and 0<=move[1] and move[1]<n:,,No,Yes
32729,move = (move[0]+direction[0];move[1]+direction[1]),,Yes,Yes
32731,action must be a valid move,,Yes,Yes
32732,Check rows & columns for win,,,Yes
32733,move = (move[0]+direction[0]; move[1]+direction[1]),,Yes,Yes
32734,while 0<=move[0] and move[0]<n and 0<=move[1] and move[1]<n:,,No,Yes
32735,move = (move[0]+direction[0];move[1]+direction[1]),,Yes,Yes
32736,TODO shape=[batch_size; n_classes],,Yes,Yes
32741,Needed for reshaping.,,Yes,Yes
32742,Follwing packages is needed,,Yes,Yes
32744,A temprory workaround to import LightTwinSVM for running tests,,,Yes
32746,A temprory workaround to import LightTwinSVM for running tests,,Yes,Yes
32747,HACK - Check if image is from the CELEBA dataset,,Yes,Yes
32749,perform flip if needed,,Yes,Yes
32750,fix z & y for visualization,,,Yes
32751,fix z & y for visualization,,,Yes
32753,fix z for visualization,,,Yes
32754,fix z for visualization,,Yes,Yes
32755,fix z for visualization,,Yes,Yes
32756,fix z & y for visualization,,,Yes
32757,FIXME: correctly implement strided OctConv.,,Yes,Yes
32758,''' ||     TODO || ''',,No,Yes
32759,"\""\""\"" || Combined algorithm by EA : ||  || http:\/\/about.me\/emre.aydin || http:\/\/github.com\/eaydin ||  || 1) if letters < 3 : return 1 || 2) if doesn't end with \""ted\"" or \""tes\"" or \""ses\"" or \""ied\""; discard \""es\"" and \""ed\"" at the end. || 3) discard trailing \""e\""; except where ending is \""le\""; also handle \""le_exceptions\"" || 4) check if consecutive vowels exists; triplets or pairs; count them as one. || 5) count remaining vowels in word. || 6) add one if starts with \""mc\"" || 7) add one if ends with \""y\"" but is not surrouned by vowel || 8) add one if \""y\"" is surrounded by non-vowels and is not in the last word. || 9) if starts with \""tri-\"" or \""bi-\"" and is followed by a vowel; add one. || 10) if ends with \""-ian\""; should be counted as two syllables; except for \""-tian\"" and \""-cian\"" || 11) if starts with \""co-\"" and is followed by a vowel; check if exists in the double syllable dictionary; if not; check if in single dictionary and act accordingly. || 12) if starts with \""pre-\"" and is followed by a vowel; check if exists in the double syllable dictionary; if not; check if in single dictionary and act accordingly. || 13) check for \""-n't\"" and cross match with dictionary to add syllable. || 14) handling the exceptional words ||  ||  || TODO : ||  || # isn't couldn't doesn't shouldn't ... (done) ||  || # when detecting sentences; avoid \""a.m. p.m.\"" kind of usage. ||  || # exception : \""evacuate\"" \""ambulances\"" \""shuttled\"" \""anyone\"" ||  ||  || \""\""\""",,Yes,Yes
32760,"7) add one if ends with \""y\"" but is not surrouned by vowel",,,Yes
32762,"\""\""\""can change according to the structure  || needed for the song || (this one has a verse followed by a chorus  || followed by 2 verses and then a the same chorus twice) || \""\""\""",,Yes,Yes
32765,FIXME: If you set K as numpy; the following line won't work. Make it compatible with numpy.,,Yes,Yes
32767,to prove my previous statement; ive added two stats; they show how many times each rule (3n+1 or n\/2) is used per cycle (pretty obvious stuff):,,Yes,Yes
32769,if the move is legal and doesn't simply reverse the previous move,,,Yes
32770,perform the move,,Yes,Yes
32771,z is not in the context of the closure because it's not needed in the add lambda; it's smart enough to only carry around scope that's used,,Yes,Yes
32773,sha256 is prob better but whatever,,Yes,Yes
32774,"print >>sys.stderr; \""  -x                           Space columns for human readability\""",,,Yes
32775,TODO: save document if changes are made,,No,Yes
32777,TODO? Seems to work; am I missing something?,,Yes,Yes
32778,TODO,,,Yes
32779,TODO,,,Yes
32781,TODO: later,,,Yes
32783,TODO: deal with deletions,,Yes,Yes
32784,TODO: implement handling,,,Yes
32785,TODO,,Yes,Yes
32786,TODO: deal with insertions,,Yes,Yes
32787,TODO: adapt,,No,Yes
32788,TODO: find layer,,,Yes
32792,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
32793,not needed anymore,,Yes,Yes
32795,TODO: to be implemented still,,,Yes
32797,"''' || 1. \u83B7\u53D6graph\u53D8\u91CF ||         # optimize parameters of image enhancement (generator) and discriminator networks ||         generator_vars = [v for v in tf.global_variables() if v.name.startswith(\""generator\"")] ||         discriminator_vars = [v for v in tf.global_variables() if v.name.startswith(\""discriminator\"")] ||         meon_vars = [v for v in tf.global_variables() if v.name.startswith(\""conv\"") or v.name.startswith(\""subtask\"")] ||          || 2.  ||         # \u5F97\u5230\u8BE5\u7F51\u7EDC\u4E2D\uFF0C\u6240\u6709\u53EF\u4EE5\u52A0\u8F7D\u7684\u53C2\u6570; \u7528var_list = tf.contrib.framework.get_variables(scope_name)\u83B7\u53D6\u6307\u5B9Ascope_name\u4E0B\u7684\u53D8\u91CF\uFF0C ||         variables = tf.contrib.framework.get_variables_to_restore() ||         # \u5220\u9664output\u5C42\u4E2D\u7684\u53C2\u6570 ||         variables_to_resotre = [v for v in variables if v.name.startswith(\""conv\"")] ||         # \u6784\u5EFA\u8FD9\u90E8\u5206\u53C2\u6570\u7684 ||         pre_saver = tf.train.Saver(variables_to_resotre) || 3. ||         3.1.\u83B7\u53D6\u67D0\u4E2A\u64CD\u4F5C\u4E4B\u540E\u7684\u8F93\u51FA;\u7528graph.get_operations()\u83B7\u53D6\u6240\u6709op ||         3.2.\u83B7\u53D6\u6307\u5B9A\u7684var\u7684\u503C;\u7528GraphKeys\u83B7\u53D6\u53D8\u91CF;tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\u8FD4\u56DE\u6307\u5B9A\u96C6\u5408\u7684\u53D8\u91CF ||         3.3.\u83B7\u53D6\u6307\u5B9Ascope\u7684collection;tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES;scope='common_conv_xxx_net.final_logits') ||  || '''",,,Yes
32803,TODO: Take multiple images,,No,Yes
32804,TODO: compute style loss,,,Yes
32806,TODO: Close queue,,Yes,Yes
32808,"feature_columns = [tf.feature_column.numeric_column(\""x\""; shape=[2])]",,No,Yes
32810,work around bug in LSM510 software,,No,Yes
32814,TODO: convert YCbCr to RGB,,No,Yes
32815,TODO: pythonize this,,No,Yes
32816,TODO: is there a standard for character axes labels?,,,Yes
32817,LSM 2.0 ends here,,No,Yes
32820,TODO: handle image sequences,,Yes,Yes
32821,"\""\""\"" || helper_functions.py ||  || Functions for making training data ||  || @author: David Van Valen || \""\""\""",,Yes,Yes
32824,minimum number of transition steps per iteration (if an episode ends before min_trans_per_iter is reached; a new one starts),,Yes,Yes
32825,minimum number of transition steps per iteration (if an episode ends before min_trans_per_iter is reached; a new one starts),,Yes,Yes
32826,minimum number of transition steps per iteration (if an episode ends before min_trans_per_iter is reached; a new one starts),,,Yes
32828,minimum number of transition steps per iteration (if an episode ends before min_trans_per_iter is reached; a new one starts),,Yes,Yes
32829,Update when the data is full or when the episode ends,,No,Yes
32831,''' || ---- DESCRIPTION ---- ||  || Dynamics are linear (s' = s + a) and reward is sparse. || There are multiple goals; with the furthest yielding the highest reward. || The initial position is fixed and the episode ends when a reward is collected. ||  || With the default implementation; the highest reward is located in [20;20] and || needs 20 steps to be collected. To make it challenging; set max_episode_steps=25. ||  ||  || ---- HOW TO USE ---- ||  || * Place this file in gym\/gym\/envs\/classic_control || * Add to __init__.py (located in the same folder) ||  ||     from gym.envs.classic_control.toy_sparse_env import ToySparseEnv ||  || * Register the environment in your script (select the state bound) ||  ||     gym.envs.register( ||          id='ToySparse-v0'; ||          entry_point='gym.envs.classic_control:ToySparseEnv'; ||          max_episode_steps=25; ||     ) || ''',,Yes,Yes
32832,''' || ---- DESCRIPTION ---- ||  || Very simple chainwalk with linear dynamics. || The state is the agent position (x) and velocity (xd); and the bonus location (b). || The action is the acceleration. || The location of the bonus is randomly chosen at the beginning of the episode among || two possible positions: either behind the initial position of the agent; or behind the goal. || The initial position is fixed; as well as the goal position. || The agent gets the bonus is it is very close to it with almost 0 velocity. The bonus then disappears. || The episode ends when the agent is very close to the goal with almost 0 velocity. ||  ||  || ---- HOW TO USE ---- ||  || * Place this file in gym\/gym\/envs\/classic_control || * Add to __init__.py (located in the same folder) ||  ||     from gym.envs.classic_control.toy_chain_sparse_env import ToyChainSparseEnv ||  || * Register the environment in your script ||  ||     gym.envs.register( ||          id='ToyChainSparse-v0'; ||          entry_point='gym.envs.classic_control:ToyChainSparseEnv'; ||          max_episode_steps=1000; ||     ) || ''',,Yes,Yes
32833,squares on which pieces can move,,No,Yes
32834,king move exactly on the square it is happening,,Yes,Yes
32835,created just when needed,,,Yes
32838,fix initial seed for reproducibility,,,Yes
32840,fix initial seed for reproducibility,,Yes,Yes
32841,created just when needed,,Yes,Yes
32842,fix initial seed for reproducibility,,,Yes
32845,squares on which pieces can move,,No,Yes
32846,king move exactly on the square it is happening,,,Yes
32847,created just when needed,,Yes,Yes
32850,is orders of magnitude less efficient than it could be made; particularly by using a,,Yes,Yes
32851,return the move that was most visited,,,Yes
32852,squares on which pieces can move,,No,Yes
32853,TODO: optimize with chess.popcount,,Yes,Yes
32854,king move exactly on the square it is happening,,,Yes
32855,softmax of move values,,Yes,Yes
32858,"TODO: to change all print function with \""logging.debug\"" or \""logging.info\""...",,,Yes
32859,move probability matrix,,No,Yes
32862,fix initial seed for reproducibility,,Yes,Yes
32863,is orders of magnitude less efficient than it could be made; particularly by using a,,,Yes
32866,move probability matrix,,No,Yes
32867,created just when needed,,,Yes
32868,"TODO: to change all print function with \""logging.debug\"" or \""logging.info\""...",,,Yes
32870,squares on which pieces can move,,No,Yes
32871,squares on which pieces can move,,No,Yes
32873,output a 8x8x8x8 'softmaxed' value of move probability,,No,Yes
32874,todo: customizable filling color,,,Yes
32875,TODO change timestep dtype in tfrddlsim,,,Yes
32878,# more original version move,,No,Yes
32879,# more original version move,,No,Yes
32882,When choosing shuffle buffer sizes; larger sizes result in better,,Yes,Yes
32883,expanding dimensions for better performance.,,,Yes
32884,TODO: Add regularizer,,,Yes
32886,CMS convention to use power of 10,,,Yes
32888,TODO: find out which indexes to use,,Yes,Yes
32890,TODO: check if labels are integers or strings; if later we need to do something,,,Yes
32891,"\""\""\"" || File       : hep_resnet.py || Author     : Valentin Kuznetsov <vkuznet AT gmail dot com> || Description: HEP ResNet model || \""\""\""",,No,Yes
32894,TODO: implement this class,,Yes,Yes
32896,TODO: Fix dependencies for scipy.,,,Yes
32897,Interpolate depthwise if needed.,,,Yes
32898,Fix nested Namespaces.,,No,Yes
32899,Creates new dummy columns from each unique string in a particular feature,,Yes,Yes
32900,of dummy columns will be different in both. We make it the same.,,Yes,Yes
32901,TODO: Fix input pipeline bottleneck (move mo tf.Data API?),,Yes,Yes
32904,clean the original raw data by storing only the columns that we need; and removing the rest.,,Yes,Yes
32905,columns = ['Date'; 'HomeTeam'; 'AwayTeam'; 'FTHG'; 'FTAG'; 'FTR'],,Yes,Yes
32907,produces a prediction model in the form of an ensemble of weak prediction models; typically decision tree,,Yes,Yes
32908,on various sub-samples of the dataset and use averaging to improve the predictive,,No,Yes
32909,1. From raw data; remove all data but these columns below.,,Yes,Yes
32910,2. From 1; add Overall Rating columns,,,Yes
32911,3. From 2; add current status columns (current point; current goal for;against;difference; match played),,,Yes
32913,Columns that are not normalized: (Ordinal; Categorical),,,Yes
32915,TODO: Import 'GridSearchCV' and 'make_scorer',,No,Yes
32917,TODO: Initialize the classifier,,Yes,Yes
32920,1. From raw data; remove all data but these columns below.,,Yes,Yes
32921,2. From 1; add Overall Rating columns,,Yes,Yes
32922,3. From 2; add current status columns (current point; current goal for;against;difference; match played; losing\/winning streaks; last 5 games),,Yes,Yes
32923,Produces: cleaned csv modified; located in CLEANED_DATA_FILE_PATH. Now all cleaned csv from 1993-2019 have additinoal columns,,No,Yes
32924,Drop columns that are not needed and normalized each columns,,,Yes
32925,Best param in this grid search,,Yes,Yes
32928,columns = ['Date'; 'HomeTeam'; 'AwayTeam'; 'FTHG'; 'FTAG'; 'FTR'],,Yes,Yes
32929,cleanAll(RAW_DATA_FILE_PATH; RAW_CLEANED_DATA_FILE_PATH; columns),,,Yes
32930,TODO: Normalize columns before I make prediction,,No,Yes
32931,cleanAll(RAW_DATA_FILE_PATH; RAW_CLEANED_DATA_FILE_PATH; columns),,No,Yes
32933,TODO: Work on saving probability data,,,Yes
32934,Normalize each columns and remove rows that should not be predicted yet,,,Yes
32937,4. From 3; add current status columns (current point; current goal for;against;difference; match played; losing\/winning streaks; last 5 games),,Yes,Yes
32939,TODO: What if I only use the current 5 years of data or something?,,No,Yes
32940,clean the original raw data by storing only the columns that we need; and removing the rest.,,Yes,Yes
32941,clean the original raw data by storing only the columns that we need; and removing the rest.,,Yes,Yes
32943,"\""\""\"" || Bregman.py || author: xhchrn ||         chernxh@tamu.edu || last_update: 2017-12-14 ||  || Implement naive Bregman iteration algorithm and linearized Bregman ISS || algorithm. || \""\""\""",,Yes,Yes
32944,"\""\""\"" || FISTA.py || author: chernxh@tamu.edu || date  : 09\/27\/2017 ||  || Python implementation of FISTA algorithm. || \""\""\""",,,Yes
32945,"\""\""\"" || ISTA.py || author: chernxh@tamu.edu || date  : 09\/26\/2017 ||  || Python implementation of ISTA algorithm. || \""\""\""",,Yes,Yes
32946,"\""\""\"" || LBI.py || author: xhchrn ||         chernxh@tamu.edu ||  || Implementation of linearized Bregman iteration algorithm proposed by || Wotao Yin et al. Refer to https:\/\/arxiv.org\/abs\/1104.0262 || \""\""\""",,,Yes
32947,"\""\""\""\r || file  : main.py\r || author: Xiaohan Chen\r || email : chernxh@tamu.edu\r || last_modified: 2018-10-13\r || \r || Main script. Start running model from main.py.\r || \""\""\""",,No,Yes
32950,:iw: TODO,,No,Yes
32951,:pnz: TODO,,,Yes
32952,:SNR: TODO,,,Yes
32953,:init_lr: TODO,,No,Yes
32958,:init_lr: TODO,,No,Yes
32959,:decay_rate: TODO,,Yes,Yes
32962,TODO: move shrink functions to utils\/shrink.py,,No,Yes
32964,:sess: TODO,,Yes,Yes
32966,:returns: TODO,,No,Yes
32967,"\""\""\"" || file  : data.py || author: Xiaohan Chen || email : chernxh@tamu.edu || last_modified: 2018-10-16 ||  || Utility methods for the real world images compressive sensing experiments. || \""\""\""",,Yes,Yes
32972,:log : TODO,,No,Yes
32977,:iw: TODO,,No,Yes
32979,:SNR: TODO,,,Yes
32980,:init_lr: TODO,,,Yes
32982,:lr_decay: TODO,,No,Yes
32986,:init_lr: TODO,,,Yes
32987,:decay_rate: TODO,,Yes,Yes
32988,:lr_decay: TODO,,No,Yes
32996,TODO: exetnd to noisy case,,,Yes
32998,TODO: what is the actual complexity of radius_query for BallTree; KDTree; or LSHForest?,,Yes,Yes
32999,TODO: what is the actual complexity of set difference in Python,,No,Yes
33000,TODO: what is the actual complexity of set difference in Python,,No,Yes
33001,TODO: check here,,No,Yes
33003,TODO: add pre-computed distance matrix,,,Yes
33004,TODO: measure comm cost,,,Yes
33005,TODO: allow pre_clustering_routine to handle outliers,,No,Yes
33006,TODO: here the new center's weight is set to its own weight; this might be problematic(?),,Yes,Yes
33007,TODO: make the cost_func a class to unify interfaces,,,Yes
33009,"Chose either \""3 - Alpha\""; \""4 - Beta\"" or \""5 - Production\/Stable\"" as the current state of your package",,,Yes
33011,"Chose either \""3 - Alpha\""; \""4 - Beta\"" or \""5 - Production\/Stable\"" as the current state of your package",,,Yes
33014,Open the mem-mapped file and reshape it to what's needed.,,No,Yes
33015,TODO move these defaults to the .sh script?,,Yes,Yes
33019,TODO: do I want to implement ADAM or GD with momentum?,,Yes,Yes
33021,better would be actually to check breaks and term breaks but I'm lazy,,,Yes
33022,TODO: set hour to range [1;24],,Yes,Yes
33023,needed for matplotlib to keep plots opened,,No,Yes
33024,TODO: Make this a public api in slim arg_scope.py.,,,Yes
33025,TODO: Remove with tf.device when top_k operation runs,,Yes,Yes
33027,TODO: num_predictions_per_location could be moved to constructor.,,Yes,Yes
33028,TODO: Make sure the static shapes are preserved.,,Yes,Yes
33029,TODO: summarize the number of matches on average.,,,Yes
33032,TODO: Use image_id tensor once we fix the input data,,No,Yes
33039,Unused by updated loading code.,,Yes,Yes
33042,TODO: Move `unmatched_cls_target` from constructor to assign function.,,,Yes
33043,Needed for fine-tuning from classification checkpoints whose,,,Yes
33048,TODO: Make this a public function.,,No,Yes
33049,TODO: Consider replacing with tf.contrib.filter_variables in,,,Yes
33050,simple hack to overcome this issue; we only exclude bbox labels,,,Yes
33052,the CoNLL 2000 task on chunking has three columns: text; pos and np (chunk),,,Yes
33053,the GERMEVAL task only has two columns: text and ner,,,Yes
33056,word dropout only before LSTM - TODO: more experimentation needed,,Yes,Yes
33057,the CoNLL 03 task for Spanish only has two columns,,Yes,Yes
33059,mmap seems to be much more memory efficient,,Yes,Yes
33060,load_big_file is a workaround by https:\/\/github.com\/highway11git to load models on some Mac\/Windows setups,,,Yes
33062,TODO?,,Yes,Yes
33063,TODO,,Yes,Yes
33065,#TODO: not saving lines yet,,,Yes
33067,load_big_file is a workaround by https:\/\/github.com\/highway11git to load models on some Mac\/Windows setups,,Yes,Yes
33068,load_big_file is a workaround by https:\/\/github.com\/highway11git to load models on some Mac\/Windows setups,,Yes,Yes
33069,move sentence embeddings to device,,,Yes
33070,move token embeddings to device,,Yes,Yes
33071,TODO: this can only be removed once the implementations of word_dropout and locked_dropout have a batch_first mode,,No,Yes
33072,TODO: Decide how to initialize the hidden state variables,,,Yes
33073,TODO: this assumes a) only one direction & b) eye matrix for inputs,,,Yes
33075,fix serialized models,,Yes,Yes
33076,TODO: this assumes only eye matrix,,No,Yes
33079,fix serialized models,,Yes,Yes
33084,TODO: this can only be removed once the implementations of word_dropout and locked_dropout have a batch_first mode,,,Yes
33088,TODO: remove in future versions,,Yes,Yes
33091,TODO: keep for backwards compatibility; but remove in future,,Yes,Yes
33094,TODO: some transformers have CLS token at different position,,,Yes
33096,tokenize and truncate to 512 subtokens (TODO: check better truncation strategies),,,Yes
33097,tokenize and truncate to 512 subtokens (TODO: check better truncation strategies),,,Yes
33099,FIXME This assumes that entities aren't nested; we have to ensure that beforehand,,No,Yes
33106,Uses dynamic programming approach to calculate maximum independent set in interval graph,,Yes,Yes
33108,Fix for CLEF HIPE models (avoid overwriting best-lm.pt in cache_dir),,Yes,Yes
33110,Fix for CLEF HIPE models (avoid overwriting best-lm.pt in cache_dir),,,Yes
33113,tokenize and truncate to 512 subtokens (TODO: check better truncation strategies),,,Yes
33114,tokenize and truncate to 512 subtokens (TODO: check better truncation strategies),,,Yes
33117,fix serialized models,,Yes,Yes
33118,Fix for CLEF HIPE models (avoid overwriting best-lm.pt in cache_dir),,,Yes
33119,TODO: keep for backwards compatibility; but remove in future,,Yes,Yes
33120,FIXME: Use nersuite annotations because conll annotation seem to be broken,,Yes,Yes
33122,TODO For split entities we also annotate everything in-between which might be a bad idea?,,,Yes
33123,Try to fix incorrect annotations,,Yes,Yes
33125,rename according to train - test - dev - convention,,Yes,Yes
33126,rename according to train - test - dev - convention,,,Yes
33127,rename according to train - test - dev - convention,,Yes,Yes
33128,rename according to train - test - dev - convention,,Yes,Yes
33129,TODO: MAKE CORPUS + DEFINE COLUMNS,,No,Yes
33130,TODO: DOWNLOAD DATA,,,Yes
33134,TODO: MAKE CORPUS + DEFINE COLUMNS,,,Yes
33136,CHECK: PROBABLY NEED TO BE PREPROCESSED; ADJUST COLUMNS ABOVE LATER,,Yes,Yes
33137,TODO: DEFINE ATTRIBUTES,,Yes,Yes
33140,TODO: keep for backwards compatibility; but remove in future,,Yes,Yes
33145,TODO: MAKE CORPUS + DEFINE COLUMNS,,No,Yes
33146,TODO: DOWNLOAD DATA,,No,Yes
33148,TODO: DEFINE ATTRIBUTES,,Yes,Yes
33149,rename according to train - test - dev - convention,,,Yes
33151,temporary fix to disable tokenizer parallelism warning,,,Yes
33154,temporary fix to disable tokenizer parallelism warning,,,Yes
33155,FIXME: Add support for a2!,,No,Yes
33157,TODO,,,Yes
33158,#TODO: not saving lines yet,,,Yes
33159,if the other annotations should be needed simply add the columns in correct order according,,,Yes
33161,self.embeddings = embeddings # TODO: are those embeddings even required? I dont think so; only the WordTransformerEmbeddings should be required.,,Yes,Yes
33163,TODO: add correct tag to each token of the sentence,,,Yes
33164,broadcasting will do the job of reshaping and is more efficient than calling repeat,,,Yes
33165,rename according to train - test - dev - convention,,Yes,Yes
33167,TODO: further implement here: loss-weights?,,No,Yes
33168,TODO: add correct tag to each token of the sentence,,No,Yes
33169,broadcasting will do the job of reshaping and is more efficient than calling repeat,,Yes,Yes
33170,self.embeddings = embeddings # TODO: are those embeddings even required? I dont think so; only the WordTransformerEmbeddings should be required.,,Yes,Yes
33171,TODO: further implement here: loss-weights?,,,Yes
33173,broadcasting will do the job of reshaping and is more efficient than calling repeat,,Yes,Yes
33175,if the other annotations should be needed simply add the columns in correct order according,,Yes,Yes
33177,move embeddings from context back to original sentence (if using context),,No,Yes
33179,move embeddings from context back to original sentence (if using context),,,Yes
33180,if sentence ends; break,,,Yes
33183,I have no idea why this is necessary; but otherwise it doesn't work,,,Yes
33187,I have no idea why this is necessary; but otherwise it doesn't work,,Yes,Yes
33189,TODO: this assumes eye matrix,,Yes,Yes
33190,TODO: remove in future versions,,Yes,Yes
33192,In case we are dealing with properly parsed rows; proceed with a regular parsing procedure,,Yes,Yes
33193,If there is no punctuation mark indicating EOS; an empty line is still needed after the EOS,,,Yes
33195,Efficient in terms both of memory and CPU utilization.,,Yes,Yes
33196,TODO: store the actual index in table in case row number is unstable between queries,,,Yes
33198,TODO:,,No,Yes
33199,TODO: replace in tutorials with get_between_ngrams and delete this,,No,Yes
33204,TODO: this currently looks only in current table;,,Yes,Yes
33205,TODO: Too slow,,No,Yes
33207,TODO: this may have issues where a phrase is linked to words on different pages,,,Yes
33208,TODO: what if this is smaller than a block?,,,Yes
33209,TODO: Make this work for higher-order relations,,Yes,Yes
33210,TODO: Is this try\/except necessary?,,,Yes
33211,This is a hack for getting the documentation to build...,,,Yes
33213,Load model kwargs needed to rebuild model,,,Yes
33214,See: https:\/\/www.twosigma.com\/insights\/a-workaround-for-non-determinism-in-tensorflow,,,Yes
33215,Add attention if needed,,No,Yes
33216,implement changes.,,,Yes
33218,and inference to be efficient even with very large cardinality; as,,Yes,Yes
33219,Save other model hyperparameters needed to rebuild model,,Yes,Yes
33223,TODO: confirm that this only has one child,,,Yes
33224,NOTE: Enforce full span matching by ensuring that regex ends with $.,,,Yes
33227,TODO: ssplit options aren't being recognized (but they don't throw any errors either...),,No,Yes
33228,certain configuration options remove 'before'\/'after' fields in output JSON (TODO: WHY?),,,Yes
33229,We use a workaround to pass in the apply kwargs,,Yes,Yes
33231,NOTE: Enforce full span matching by ensuring that regex ends with $.,,,Yes
33232,TODO: store the actual index in table in case row number is unstable between queries,,No,Yes
33235,As a workaround; just ignore the outer Figure and allow processing,,Yes,Yes
33236,TODO: Too slow,,,Yes
33238,TODO: this currently looks only in current table;,,,Yes
33240,TODO: Too slow,,No,Yes
33241,TODO: store the actual index in table in case row number is unstable,,No,Yes
33243,When a text ends with a split_token.,,No,Yes
33244,TODO: store the actual index in table in case row number is unstable,,,Yes
33246,TODO: the pytorch implementation is taking dense vector as input;,,Yes,Yes
33248,TODO: Consider batching sentences to stay below spacy's max. character limit,,Yes,Yes
33252,TODO: replace with japanese doc,,No,Yes
33253,TODO: replace with japanese doc,,,Yes
33257,candidates. This helps reduce the number of queries needed to update.,,No,Yes
33258,TODO: Classifier#_preprocess_data should assume that,,No,Yes
33259,candidates. This helps reduce the number of queries needed to update.,,No,Yes
33261,TODO: can out_queue be just Queue instead of JoinableQueue?,,,Yes
33263,TODO: upsert is too much. insert is fine as all keys are deleted.,,,Yes
33266,TODO: split is int,,No,Yes
33270,TODO: this may have issues where a sentence is linked to words on different,,,Yes
33272,TODO: the return value [None] is inconsistent with others like get_cell_ngrams,,Yes,Yes
33273,"TODO: [\""paneer\""] appears twice. Is this expected result?",,Yes,Yes
33276,"TODO: replace \""NUMBER\"" with \""CARDINAL\"" (#473)",,,Yes
33278,Such a kludge. Only restrict imports if the `import_path` has,,Yes,Yes
33280,XXX: Switch to threading backend when GIL is released.,,,Yes
33284,move west,,Yes,Yes
33287,TODO: remove this hack,,No,Yes
33288,TODO: remove this hack,,No,Yes
33290,TODO,,Yes,Yes
33292,TODO: make this work with col names shorter than three letters (ie when headers aren't read in),,Yes,Yes
33293,TODO switch similar statements to work inplace (w\/o making a copy),,Yes,Yes
33295,TODO: make sure this works with Impute=True (ie remove pred col from imputation),,Yes,Yes
33297,Calculate three imp columns,,Yes,Yes
33299,Remove DTS columns,,No,Yes
33300,TODO: make this work with col names shorter than three letters (ie when headers aren't read in),,,Yes
33301,"TODO: Fix this SettingWithCopyWarning: value trying to be set on a copy of a slice from a DataFrame\""",,Yes,Yes
33302,TODO switch similar statements to work inplace (w\/o making a copy),,,Yes
33305,Convert numeric columns to factor\/category columns,,Yes,Yes
33306,# Convert numeric columns to factor\/category columns,,No,Yes
33309,Convert numeric columns to factor\/category columns,,Yes,Yes
33310,Convert numeric columns to factor\/category columns,,,Yes
33312,TODO: switch 2-d lists to numpy array,,Yes,Yes
33313,TODO: add cutoff associated with FPR\/TPR,,,Yes
33315,TODO: refactor this logic to be simpler,,Yes,Yes
33318,Todo: count and display (via pyodbc) how many rows inserted,,,Yes
33319,Todo: count and display (via pyodbc) how many rows inserted,,No,Yes
33322,TODO: check that col types remain the same after imputation,,Yes,Yes
33325,print('\ || Dataframe after removing DTS columns:'),,Yes,Yes
33327,TODO STUB FINISH THIS,,Yes,Yes
33328,TODO,,Yes,Yes
33330,Drop columns that won't help machine learning,,,Yes
33334,TODO think about making this a static method?,,Yes,Yes
33335,Drop some columns,,Yes,Yes
33336,or simply drop columns with any nulls,,Yes,Yes
33340,remove datetime columns,,,Yes
33342,TODO implement (or avoid) these attributes; which really might be methods,,Yes,Yes
33344,TODO should probably automate null imputation?,,,Yes
33347,TODO make this more robust for other scoring metrics,,Yes,Yes
33348,TODO STUB FINISH THIS,,,Yes
33350,TODO think about making this a static method?,,Yes,Yes
33351,remove datetime columns,,No,Yes
33353,TODO make this more robust for other scoring metrics,,Yes,Yes
33354,TODO implement (or avoid) these attributes; which really might be methods,,Yes,Yes
33355,Drop some columns,,Yes,Yes
33356,TODO should probably automate null imputation?,,,Yes
33360,TODO STUB FINISH THIS,,Yes,Yes
33361,TODO we may not want to create directories (for example; we may want to just direclty save to azure),,,Yes
33362,TODO think about making this a static method?,,Yes,Yes
33364,Drop columns that won't help machine learning,,,Yes
33365,TODO STUB FINISH THIS,,,Yes
33369,TODO a similar method should be created for regression metrics,,Yes,Yes
33370,TODO make this more robust for other scoring metrics,,,Yes
33372,TODO deprecate,,Yes,Yes
33374,TODO deprecate after replacements are implemented.,,Yes,Yes
33375,TODO deprecate or tear apart the important bits.,,,Yes
33376,TODO Convenience method. Probably not needed?,,,Yes
33377,TODO: switch 2-d lists to numpy array,,Yes,Yes
33378,TODO: switch 2-d lists to numpy array,,,Yes
33380,TODO timeRan is borked,,,Yes
33383,TODO stub,,Yes,Yes
33385,Drop columns that won't help machine learning,,Yes,Yes
33386,TODO ensemble is broken,,Yes,Yes
33388,Todo: count and display (via pyodbc) how many rows inserted,,,Yes
33389,TODO timeRan is borked,,,Yes
33395,TODO we need to think about making this optional to solve the problem of rare and very predictive values,,Yes,Yes
33396,TODO swap out fake data for real databaes sql,,Yes,Yes
33397,Drop columns that won't help machine learning,,Yes,Yes
33398,TODO Now make this predict something,,,Yes
33400,- [ ] convert dataframe to numpy array (is this needed?),,,Yes
33404,TODO convert the rest of ths example to the pipeline way,,,Yes
33409,TODO ... or do we want to leave out the null dropping step - and if so; what impact will this have ML-wise?,,Yes,Yes
33411,TODO make this database agnostic,,,Yes
33412,TODO Deprecate this,,,Yes
33413,TODO Save results to db,,Yes,Yes
33415,TODO think about an exclusions list or something so that you don't have to explicitly drop the predicted column,,,Yes
33417,dataframe = dataframe[[c for c in dataframe.columns if c in self.column_names]],,,Yes
33418,TODO this may have to be classification or regression aware by using either .predict() or .predictproba(),,,Yes
33419,TODO stubs - may be implemented elsewhere and needs to be moved here.,,,Yes
33424,Drop columns that won't help machine learning,,Yes,Yes
33425,Drop columns that model expects,,Yes,Yes
33426,join top features columns to results dataframe,,,Yes
33427,Raise an error here if any of the columns the model expects are not in the prediction dataframe,,No,Yes
33428,Subset the dataframe to only columns that were saved from the original model training,,Yes,Yes
33429,Drop columns that won't help machine learning,,Yes,Yes
33431,TODO deprecate this,,Yes,Yes
33433,return figure if anyone wants to save or manipulate it in another way,,Yes,Yes
33439,TODO rename to random_forest after the other is deprecated,,No,Yes
33442,Hacky way to capture print output since simple prints output instead of returning it.,,,Yes
33445,TODO swap out fake data for real databaes sql,,Yes,Yes
33449,TODO this is broken,,Yes,Yes
33451,TODO this is really not in the right place,,Yes,Yes
33452,TODO refactor this as a tool + advanced\/simple wrapper,,No,Yes
33455,Drop columns that won't help machine learning,,Yes,Yes
33456,TODO likely deprecate this and use pandas in examples? - ask CAFE,,,Yes
33460,TODO this is really not in the right place. And it might be deprecated; since metrics can be access from TSM,,Yes,Yes
33462,TODO so; you could check for different GUIDs that could be saved in each TSM!,,Yes,Yes
33463,TODO hack to convert to array if it is a single dictionary,,Yes,Yes
33466,TODO deals with randomized search - can this be nuked?,,Yes,Yes
33467,Arrange columns in order of importance,,Yes,Yes
33468,TODO make this more elegant - figure out where\/how it should be accessed,,Yes,Yes
33469,TODO should it be part of a .random_forest() call?,,,Yes
33473,TODO random forest validation - raise error if used with another algorithm,,Yes,Yes
33474,TODO name these sanely,,,Yes
33476,TODO does this belong here or in TSM...?,,No,Yes
33480,Plot these columns,,,Yes
33481,TODO implement (or avoid) these attributes; which really might be methods,,Yes,Yes
33482,TODO this results object might be deprecated,,No,Yes
33483,TODO this is really not in the right place. And it might be deprecated; since metrics can be access from TSM,,,Yes
33484,TODO a similar method should be created for regression metrics,,,Yes
33485,TODO switch to SQLITE,,,Yes
33487,TODO deprecate after replacements are implemented.,,,Yes
33489,TODO consolidate after merges,,,Yes
33491,Drop uninformative columns,,Yes,Yes
33496,Plot these columns,,,Yes
33499,TODO Validate inputs,,,Yes
33502,Todo: count and display (via pyodbc) how many rows inserted,,No,Yes
33505,TODO Validate inputs,,No,Yes
33507,TODO ... to validate write permissions. Like sqlalchemy. Ugh.,,Yes,Yes
33508,TODO swap out fake data for real databaes sql,,,Yes
33510,TODO Save results to db,,,Yes
33512,TODO column,,No,Yes
33513,TODO: refactor this logic to be simpler,,,Yes
33515,TODO this might have the same bug the r package had,,,Yes
33516,TODO this might have the same bug the r package had,,Yes,Yes
33519,TODO this should be a return and printed elsewhere,,,Yes
33520,TODO add binary check and rename to validate_binary_classification,,Yes,Yes
33524,TODO hack to convert to array if it is a single dictionary,,,Yes
33526,TODO doesn't work,,,Yes
33527,TODO print these nicely for users,,Yes,Yes
33528,TODO either put a switch on this because it is all shared code except the last part or,,,Yes
33529,TODO doing this properly leads to a circular dependency so dirty hack string matching was needed,,Yes,Yes
33533,TODO column,,No,Yes
33534,TODO this might have the same bug the r package had,,,Yes
33537,TODO add binary check and rename to validate_binary_classification,,Yes,Yes
33542,TODO: add cutoff associated with P\/R,,Yes,Yes
33543,Drop columns that won't help machine learning,,,Yes
33546,TODO This pipeline may drop nulls in prediction rows if impute=False,,,Yes
33547,TODO See https:\/\/github.com\/HealthCatalyst\/healthcareai-py\/issues\/276,,Yes,Yes
33549,TODO so; you could check for different GUIDs that could be saved in each TSM!,,,Yes
33555,Drop uninformative columns,,,Yes
33556,Drop columns that won't help machine learning,,Yes,Yes
33557,Drop columns that won't help machine learning,,,Yes
33562,Any saved model can be inspected for properties such as plots; metrics; columns; etc. (More examples in the docs),,Yes,Yes
33564,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
33567,Identify the categorical columns,,,Yes
33568,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels determined,,,Yes
33569,Raise an error here if any of the columns the model expects are not in the prediction dataframe,,,Yes
33570,Subset the dataframe to only columns that were saved from the original model training,,Yes,Yes
33578,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels determined,,Yes,Yes
33584,TODO Modify probs and cat_weights (and expected df) once top factors is made independent of dummification,,No,Yes
33587,select only specific columns,,No,Yes
33589,TODO column,,,Yes
33590,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels determined,,Yes,Yes
33595,TODO column,,,Yes
33596,Save the original dataframe columns to the parent class,,,Yes
33597,Identify the categorical columns,,,Yes
33598,Save the original dataframe columns to the parent class,,,Yes
33600,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels,,Yes,Yes
33603,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels,,Yes,Yes
33605,TODO column,,,Yes
33606,dataframe with new category levels in two columns,,Yes,Yes
33607,Identify the categorical columns,,,Yes
33610,Check that the right number of columns are included,,Yes,Yes
33614,Check if we know what columns to scale; if not; then get all the numeric columns' names,,Yes,Yes
33616,Select all data excluding datetime columns,,No,Yes
33618,prediction column be present in the new data.  To get around this; add the prediction columns filled with,,Yes,Yes
33619,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels,,Yes,Yes
33620,If a pre-dummified dataset is expected as the input; list the pre-dummified columns instead of the dummies,,,Yes
33624,TODO Should probably use GUID rather than hard coded db.schema.table,,Yes,Yes
33625,TODO Convenience method. Probably not needed?,,,Yes
33626,TODO Convenience method. Probably not needed?,,Yes,Yes
33627,Drop columns that won't help machine learning,,Yes,Yes
33628,prediction column be present in the new data.  To get around this; add the prediction columns filled with,,,Yes
33629,Raise an error here if any of the columns the model expects are not in the prediction dataframe,,,Yes
33630,Change the dtype of the categorical columns in the prediction dataframe to 'category' with levels,,,Yes
33631,TODO stub,,,Yes
33632,TODO this might reorder class labels and screw things up...,,No,Yes
33633,TODO this might reorder class labels and screw things up...,,No,Yes
33636,checking whether all the columns mentioned in num_as_cat_list are present in X or not,,Yes,Yes
33640,Getting only Categoric columns with imputed missing values,,Yes,Yes
33641,imputing 1 columns per iteration using RandomForest  and adding it to X,,Yes,Yes
33642,tempImpute_columns = List of cols to be imputed temporarily using mode,,Yes,Yes
33643,We are passing only cat_list cols to getTempImutedData() func and later joining it with X_NumericImputed df; so that                       getTempImutedData() func will take minimum time for temporary imputation and it wil not iterate on the columns whose missing               values are already imputed(i.e Numeric Cols),,No,Yes
33649,beacuse we have intentionally converted GenderFLG column into numeric type for demonstration of numeric_columns_as_categorical feature.,,No,Yes
33652,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
33653,TODO: save a copy of the notebook with and without outputs,,,Yes
33654,If needed; select a math extensions (mathjax or pngmath):,,No,Yes
33655,Select nbsphinx and; if needed; add a math extension (mathjax or pngmath):,,,Yes
33656,"TODO: add links with \"".. only:: html\""",,,Yes
33657,TODO: ... or with custom html template?,,Yes,Yes
33658,TODO: add <style> only on pages that actually need it,,Yes,Yes
33662,Not needed for LaTeX output:,,No,Yes
33663,NB: The following stateful Jinja filters are a hack until,,Yes,Yes
33664,comes up with a better idea.,,Yes,Yes
33667,Work-around until https:\/\/github.com\/sphinx-doc\/sphinx\/pull\/5504 is done:,,No,Yes
33669,-- Work-around to support sphinxcontrib.rsvgconverter on Sphinx < 1.8 ---,,Yes,Yes
33672,require.js is also needed; which is configured with nbsphinx_requirejs_path,,Yes,Yes
33673,in language modeling; shuffle is not needed,,,Yes
33674,in language modeling; shuffle is not needed,,,Yes
33675,You have to implement how to tokenize the sentence,,Yes,Yes
33678,TODO: We need to discuss how to handle unanswerable questions,,Yes,Yes
33679,TODO lot of others too which may conflict in name. Example user is already using some another instance of,,Yes,Yes
33680,TODO Elasticsearch for other purposes,,,Yes
33681,TODO add code examples,,,Yes
33684,TODO Method is not called anywhere; Is this redundant ?,,,Yes
33685,TODO Method is Haptik Specific ?,,Yes,Yes
33687,TODO if text is lowered; why check for uppercase E; D; W,,Yes,Yes
33689,TODO outbound_message is Haptik specific ? remove relevant docs if this is removed,,Yes,Yes
33690,TODO this function works on outbound message; remove that part if Haptik specific,,Yes,Yes
33691,TODO form_check is Haptik specific ?,,Yes,Yes
33692,TODO Consider removing dependency on elastic search. This is a common entity; used widely by many. Dependency on,,,Yes
33693,TODO Consider moving Date types constants to class itself,,No,Yes
33694,TODO if text is lowered; why check for uppercase E; D; W,,Yes,Yes
33695,TODO haptik specific code,,,Yes
33696,TODO Consider removing dependency on elastic search. This is a common entity; used widely by many. Dependency on,,,Yes
33698,TODO if text is lowered; why check for uppercase E; D; W,,,Yes
33700,name of columns to keep while making conversations of coll_id; outbound; inbound from chats data,,Yes,Yes
33701,name of columns in step4,,,Yes
33703,self.df_stage2.to_csv('preprocess\/flights1.csv'; index=False; columns = KEEP_COLS),,,Yes
33706,TODO - this works differently from other connects; picks scheme from the full URL,,Yes,Yes
33709,TODO: repopulate code for crf index missing,,Yes,Yes
33710,TODO: repopulate code for crf index missing,,,Yes
33711,Units data file and their columns,,Yes,Yes
33712,TODO: built-in range is being shadowed here. fix this,,Yes,Yes
33714,columns = ['language'; 'text'; 'bot_message'; 'hh'; 'mm'; 'nn'; 'range'; 'time_type'; 'original_text'],,,Yes
33715,TODO: handling multiple detections in a single message has not been handled here,,,Yes
33716,Number range data file name and columns,,,Yes
33717,Number range data file name and columns,,Yes,Yes
33718,Number range data file name and columns,,Yes,Yes
33719,TODO: functionality is incorrect; start_range should be True in 1st and end_range should be True in second,,,Yes
33720,TODO: functionality is incorrect; when run after 1st week of Jan; detector must return 1st week of next year,,No,Yes
33721,"\""\""\"" || Note: || 'word' and 'value' mean the same in this context and hasn't been cleaned because of dependency || on other haptik repository. || TODO: Move to consistent terminology and use 'value' everywhere || \""\""\""",,,Yes
33725,TODO: Make this module python 3 compatible,,Yes,Yes
33727,"FIXME: This call order causes everyday to be taken away from \""everyday except <>\"" which means",,Yes,Yes
33728,FIXME: successive calls for everyday_except_weekends and everyday_except_weekdays return wrong results,,,Yes
33729,FIXME: This ignores any mentioned year,,Yes,Yes
33730,FIXME: Broken\/Ineffective code.,,,Yes
33731,FIXME: Assumes end_date > start_date. Also can return dates in past when date detector,,No,Yes
33732,"FIXME: This call order causes everyday to be taken away from \""everyday except <>\"" which means",,Yes,Yes
33734,FIXME: This ignores any mentioned year,,Yes,Yes
33735,FIXME: Change import to `import datetime`,,No,Yes
33738,TODO: This function should be a part of time detection package,,,Yes
33739,columns = ['language'; 'text'; 'bot_message'; 'hh'; 'mm'; 'nn'; 'range'; 'time_type'; 'original_text'],,Yes,Yes
33741,timezones data file and its columns,,Yes,Yes
33742,Todo: Add more language variations of birthday.,,No,Yes
33743,TODO: Add postprocessing after tokenization to handle titles like dr.; mr. etc,,Yes,Yes
33745,"fix to handle examples like `miami;21st street` where tokenizer gives [\""miami;21st\""; \""street\""].",,Yes,Yes
33746,TODO: Set this up via Django LOGGING,,,Yes
33748,TODO: This is not correct! actual output should not modified instead expected output should be,,No,Yes
33751,FIXME: repopulate does not consider language of the variants,,No,Yes
33752,TODO: use namedtuples,,No,Yes
33753,TODO: Bad design; rethink the API; write an abstract class DataStore implement ElasticSearchDataStore;,,,Yes
33755,Implement proper migrations for indices,,,Yes
33756,TODO: cleanup aliases ?,,,Yes
33757,FIXME: Deprecated; remove,,No,Yes
33759,TODO: Remove non functional crf code and cleanup,,No,Yes
33760,TODO: these should not be here; two different sources of literals,,,Yes
33764,TODO: use namedtuples,,,Yes
33765,TODO: cleanup aliases ?,,No,Yes
33766,FIXME: Deprecated; remove,,No,Yes
33768,"\""\""\"" || Important note: bad regexes that cause catastrophic backtracking can hang your Python processes (especially because || Python's re does not release the GIL! If you are putting this module behind a web server be wary of ReDoS attacks. || Unfortunately there is no clean way around that; so make sure to set processing killing timeouts like harakiri for || uwsgi || \""\""\""",,,Yes
33772,:TODO: Check if below is expected,,,Yes
33773,TODO: move to ner_logger.error,,No,Yes
33774,FIXME: this conversion from float -> int is lossy; consider using Decimal class,,,Yes
33775,FIXME: conversion from float -> int is lossy; consider using Decimal class,,Yes,Yes
33777,state (unused): <tf.float32>[batch_size; hidden_size],,Yes,Yes
33778,state (unused): <tf.float32>[,,,Yes
33779,Unused.,,Yes,Yes
33780,Unused.,,Yes,Yes
33782,"r\""\""\""Customized Adam. ||  ||    The key difference from the built-in AdamOptimizer is how weight_decay is ||    handeled. In the built-in Adam; `\\ell_2` penalty is included into momentum ||    terms; while here `\\ell_2` is separated from the loss; and directly applied ||    to the parameters. More details: `https:\/\/arxiv.org\/abs\/1711.05101`. ||  || \""\""\""",,Yes,Yes
33783,The convention in BERT is:,,,Yes
33784,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
33786,"\""\""\""Self-contained library for converting SQL w\/ under-specified FROM clause. ||  || This module relies on the sqlparse library; which is a non-validating || SQL parser; and additional heuristics. || TODO(petershaw): A proper parser and grammar for SQL would improve robustness! || \""\""\""",,No,Yes
33788,TODO(petershaw): Could probably speed up this up quite a bit and provide,,,Yes
33789,better error handling for ambiguous cases.,,Yes,Yes
33790,Michigan doesn't come with a gold standard of *which* columns are foreign,,,Yes
33791,(e.g.; columns that are foreign keys with different names).,,,Yes
33792,table names; and values are columns; columns have 'field name';,,Yes,Yes
33794,If it didn't execute correctly; check why.,,,Yes
33795,"r\""\""\""Binary for restoring under-specified FROM clause. ||  || This is currently only supported for Spider. || Predictions should be generated using the --fully_qualify_columns flag. ||  || The input and output format is both of the predictions files generated by || `run_inference.py`. They are newline separated serialiazed json dictionaries || containing the predicted SQL strings and their respective scores for each || example. ||  || Example usage: ||  || ${PATH_TO_BINARY} \\ ||   --spider_examples_json=${SPIDER_DIR}\/spider\/dev.json \\ ||   --spider_tables_json=${SPIDER_DIR}\/spider\/tables.json \\ ||   --input_path=${INPUT} \\ ||   --output_path=${OUTPUT} \\ ||   --alsologtostderr || \""\""\""",,,Yes
33797,to be greater than two (the default). Apparently; there's a silent bug if,,Yes,Yes
33798,unused. model_fn is batch-size agnostic.,,Yes,Yes
33805,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
33806,The convention in BERT is:,,No,Yes
33807,The convention in BERT is:,,,Yes
33811,The convention in BERT is:,,No,Yes
33815,Convert token lists into ids and add any needed tokens and padding for BERT,,Yes,Yes
33816,Convert token lists into ids and add any needed tokens and padding for BERT,,,Yes
33817,These are not needed but are made to fit the BERT api,,No,Yes
33818,Convert token lists into ids and add any needed tokens and padding for BERT,,,Yes
33819,Convert token lists into ids and add any needed tokens and padding for BERT,,Yes,Yes
33820,pad both to longer than needed,,,Yes
33825,These are not needed but are made to fit the BERT api,,,Yes
33826,Convert token lists into ids and add any needed tokens and padding for BERT,,,Yes
33827,The convention in BERT is:,,No,Yes
33828,The convention in BERT is:,,No,Yes
33832,Why should we remove checkpoints?,,,Yes
33834,This is the fix,,Yes,Yes
33835,Get mention token start and ends.,,No,Yes
33838,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
33839,"What we really want to return is \""Steve Smith\"".",,,Yes
33840,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
33841,"What we really want to return is \""Steve Smith\"".",,No,Yes
33843,input to the model.  by convention inputs are passed in,,Yes,Yes
33844,input to the model.  by convention inputs are passed in,,,Yes
33846,"What we really want to return is \""Steve Smith\"".",,No,Yes
33849,TODO(perodriguez): Determine a better thing to save on,,,Yes
33850,Move the newly exported model to a staging area.,,Yes,Yes
33852,rewind \/ didn't move.,,No,Yes
33853,Fix so that it's selecting a concat of columns instead.,,Yes,Yes
33854,Weird bug where tensor2tensor doens't like non-static shapes on CPU;,,No,Yes
33857,Ugly removal from params. These need to be dynamically set by TPUEstimator.,,Yes,Yes
33858,Maybe update best copy.,,No,Yes
33859,Remove [unused*],,Yes,Yes
33860,the higher; the better,,Yes,Yes
33861,"r\""\""\""Implementation of EmQL model on different tasks. ||  || We implement EmQL model that contains a dense retrieval with sparse filtering. || There are a few different training targets: membership; intersection; union; || follow; set_follow; metaqa2 and metaqa3. The first few targets (except for || the last two); are trained to represent a knowledge base in the embedding || space. The KB embeddings are them used in the downstream tasks metaqa2 and || metaqa3. ||  || This file mainly consists of three groups of functions: || 1. model definitions: model_xxx() and helper functions || 2. evaluation functions: run_tf_evaluation() || 3. prediction functions: get_tf_xxx_prediction() || which are called from build_model_fn(). Models and predictions are selected || and computed based on the names of targets. ||  || \""\""\""",,Yes,Yes
33862,To distinguish CVT nodes; we could add another bit to entity embeddings,,Yes,Yes
33863,Thus; we implement a constraint module to discriminate those entities.,,Yes,Yes
33864,convert it into dense matrix. This is more efficient than creating,,Yes,Yes
33869,"\""\""\""Author: Louis Thiry; All rights reserved; 2018.\""\""\""",,No,Yes
33870,"\""\""\""Author: Louis Thiry; All rights reserved; 2018.\""\""\""",,No,Yes
33872,XXX the below code seems weird. Complex numbers are already,,No,Yes
33875,hard pyfftw dependency. It should be fixed,,Yes,Yes
33877,`fetch_fsdd` function downloads the FSDD; if needed.,,Yes,Yes
33878,"TODO remove \""import backend\"" below after implementing skcuda backend",,Yes,Yes
33879,move to device,,Yes,Yes
33881,elements; thus we had to add this fix.,,No,Yes
33882,Concatenate the orders (along the j axis) if needed.,,,Yes
33884,`fetch_fsdd` function downloads the FSDD; if needed.,,,Yes
33885,n_samples)` needed for processing in a scikit-learn pipeline.,,,Yes
33886,TODO(nina): why factor np.sqrt(2),,No,Yes
33887,following the regularization convention,,Yes,Yes
33888,TODO(nina): implement with automatic differentiation.,,Yes,Yes
33889,TODO(nina): regularization needed in nD?,,,Yes
33896,TODO: remove cycle; when diag; diangonal will be vectorized,,Yes,Yes
33898,TODO: remove cycle; when diag; diangonal will be vectorized,,,Yes
33899,TODO: remove cycle; when qr will be vectorized,,Yes,Yes
33901,TODO(nina): Fix the fact that it doesn't work for [1.; 4.],,Yes,Yes
33909,XXX: Why does flake8 complain about this not being used but is fine with the,,,Yes
33910,TODO @nguigs: work around this condition,,Yes,Yes
33911,FIXME: The next line needs to be guarded against taking the sqrt of,,Yes,Yes
33912,TODO(nkoep): Should the 'bad sample tolerance' be configurable,,Yes,Yes
33920,FIXME,,Yes,Yes
33921,columns,,No,Yes
33922,FIXME: Problem in shapes,,No,Yes
33924,"\""\""\""Mean shift clustering algorithm. || Mean shift clustering aims to discover *blobs* in a smooth density of || samples. It is a centroid based algorithm; which works by updating candidates || for centroids to be the mean of the points within a given region. These || candidates are then filtered in a post-processing stage to eliminate || near-duplicates to form the final set of centroids. || Seeding is performed using a binning technique for scalability. || \""\""\""",,,Yes
33925,FIXME,,,Yes
33926,FIXME: Problem in shapes,,No,Yes
33927,FIXME,,Yes,Yes
33931,FIXME,,,Yes
33932,FIXME: this only works if the points are in,,,Yes
33933,FIXME: check positivity; implying invertibility (Yann),,No,Yes
33934,"\""\""\"" || Applies K-means on manifolds and plots the results. ||  || Two random clusters are generated in seperate regions of the || manifold. Then apply K-means is applied using the metric of the manifold || algorithm and plot the points labels as two distinct colors. For the moment || the example works on the Poincar\u00E9 Ball and the Hypersphere. || Computed means are marked as green stars. || \""\""\""",,,Yes
33935,TODO Should this stay generic? (point),,No,Yes
33937,TODO Should this stay generic? (point),,No,Yes
33938,TODO (opeltre): check positivity; implying invertibility.,,,Yes
33940,FIXME: this assumes point_type is vector,,Yes,Yes
33943,TODO: Check Precision for binomial coefficients,,No,Yes
33945,XXX(nkoep): Why do we cast to float32 instead of float64 here?,,Yes,Yes
33946,XXX(nkoep): Why do we cast to float32 instead of float64 here?,,,Yes
33947,FIXME,,Yes,Yes
33948,TODO: Check Precision for binomial coefficients,,,Yes
33952,FIXME: Problem in shapes,,No,Yes
33958,TODO(nguigs): implement it for SE(3),,Yes,Yes
33959,FIXME: einsum vectorization error for invariant_metric log in tf,,No,Yes
33964,TODO Allow einsum(str; x; y) to work when x and y have different dtypes,,,Yes
33966,TODO (ninamiolane): Allow this to work when '->' is not provided,,Yes,Yes
33967,TODO (ninamiolane): Allow this to work for cases like n...k,,,Yes
33969,TODO (ninamiolane): Allow this to work for cases like n...k,,Yes,Yes
33972,TODO: hzaatiti; tgeral68 implement kmeans initialisation,,Yes,Yes
33973,"r\""\""\""Illustrate how a Kalman-like filter can be defined on Lie groups. ||  || A generic Kalman filter class is defined for systems on Lie groups for which || the exponential is subjective. Its use is illustrated on two localization || problems; a linear and a non-linear one. In both cases; the propagation model || is known; and sparse position measurements are obtained. It thus relies on a || `model` of the system; providing the system's equations and jacobians. ||  || The former is a 1D-localization problem where the state is a 2D vector (x; v) || made of the system's position and speed. The process writes || :math:`(x_{i+1}; v_{i+1}) = (x_i + dt * v_i; v_i + dt * a_i)`; || where dt is the time-step between i and i+1; and a_i a noisy acceleration || measured by a given sensor. ||  || The latter is a 2D pose (position + orientation) estimation problem; where the || state (R; x) is made a planar rotation and 2D position; i.e. a member of SE(2). || The non-linear propagation writes || :math:`(R_{i+1}; x_{i+1}) = (R_i \\Omega_i; x_i + dt * R_i u_i)`; || where :math:`\\Omega_i; u_i` is the measured odometry of the system. || The implementation follows that of the Invariant Extended Kalman Filter (IEKF) || which was designed for such cases [BB2017]. ||  || References || ---------- || .. [BB2017] Barrau; Bonnabel; \""The Invariant Extended Kalman Filter as a Stable || Observer\""; IEEE Transactions on Automatic Control; 2017 || https:\/\/arxiv.org\/abs\/1410.1465 || \""\""\""",,Yes,Yes
33976,FIXME (nina): This is valid only for bi-invariant metrics,,Yes,Yes
33977,Deep Hashing Network for Efficient Similarity Retrieval                        #,,No,Yes
33979,Deep Visual-Semantic Quantization for Efficient Image Retrieval                #,,,Yes
33982,TODO useless placeholder,,,Yes
33985,normed_cross_entropy # TODO,,No,Yes
33986,"\""\""\"" ||  || The processed PICO files for EBMNLP (see amandalynne's project) || are formatted with 2 columns:  Token & Tag ||  || ** CONLL2003 reader requires 4 columns. ||  || Also; the PICO data is separate files for each paper instead of 1 long file. ||  || ** Concats those and adds --DOCSTART-- to mark the paaper IDS ||  || Finally; ebmnlp is annotated with I\/O tags ||  || ** Converts to BIO ||  || Also; PICO data is not sentence split; but BERT truncates if sequence is || longer than 250 tokens.  This causes bugs. ||  || ** Don't do anything fancy; just split on every '.' that isn't part of a PICO element. ||  || \""\""\""",,Yes,Yes
33987,"\""\""\"" ||  || The processed PICO files for EBMNLP || are formatted with 2 columns:  Token & Tag ||  || ** CONLL2003 reader requires 4 columns. ||  || Also; the PICO data is separate files for each paper instead of 1 long file. ||  || ** Concats those and adds --DOCSTART-- to mark the paaper IDS ||  || Also; PICO data is not sentence split; but BERT truncates if sequence is || longer than 250 tokens.  This causes bugs. ||  || ** Don't do anything fancy; just split on every '.' that isn't part of a PICO element. ||  || \""\""\""",,,Yes
33989,TODO:,,No,Yes
33991,"\""\""\"" || Moving Average Convergence\/Divergence Oscillator (MACD) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:moving_average_convergence_divergence_macd || Params:  ||     data: pandas DataFrame ||     period_long: the longer period EMA (26 days recommended) ||     period_short: the shorter period EMA (12 days recommended) ||     period_signal: signal line EMA (9 days recommended) ||     column: the name of the column with values for calculating MACD in the 'data' DataFrame ||  || Returns: ||     copy of 'data' DataFrame with 'macd_val' and 'macd_signal_line' columns added || \""\""\""",,No,Yes
33992,"\""\""\"" || Accumulation Distribution  || Source: http:\/\/stockcharts.com\/school\/doku.php?st=accumulation+distribution&id=chart_school:technical_indicators:accumulation_distribution_line || Params:  ||     data: pandas DataFrame ||     trend_periods: the over which to calculate AD ||     open_col: the name of the OPEN values column || \thigh_col: the name of the HIGH values column || \tlow_col: the name of the LOW values column || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'acc_dist' and 'acc_dist_ema[trend_periods]' columns added || \""\""\""",,,Yes
33993,"\""\""\"" || On Balance Volume (OBV) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:on_balance_volume_obv || Params:  ||     data: pandas DataFrame ||     trend_periods: the over which to calculate OBV || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'obv' and 'obv_ema[trend_periods]' columns added || \""\""\""",,No,Yes
33994,"\""\""\"" || Price-volume trend (PVT) (sometimes volume-price trend) || Source: https:\/\/en.wikipedia.org\/wiki\/Volume%E2%80%93price_trend || Params:  ||     data: pandas DataFrame ||     trend_periods: the over which to calculate PVT || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'pvt' and 'pvt_ema[trend_periods]' columns added || \""\""\""",,,Yes
33996,"\""\""\"" || Ease of Movement || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:ease_of_movement_emv || Params:  ||     data: pandas DataFrame || \tperiod: period for calculating EMV || \thigh_col: the name of the HIGH values column || \tlow_col: the name of the LOW values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'emv' and 'emv_ema_[period]' columns added || \""\""\""",,,Yes
34000,"\""\""\"" || TRIX || Source: https:\/\/www.metastock.com\/customer\/resources\/taaz\/?p=114 || Params:  ||     data: pandas DataFrame || \tperiods: the period over which to calculate the indicator value || \tsignal_periods: the period for signal moving average || \tclose_col: the name of the CLOSE values column ||  || Returns: ||     copy of 'data' DataFrame with 'trix' and 'trix_signal' columns added || \""\""\""",,,Yes
34001,"\""\""\"" || Moving Average Convergence\/Divergence Oscillator (MACD) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:moving_average_convergence_divergence_macd || Params:  ||     data: pandas DataFrame ||     period_long: the longer period EMA (26 days recommended) ||     period_short: the shorter period EMA (12 days recommended) ||     period_signal: signal line EMA (9 days recommended) ||     column: the name of the column with values for calculating MACD in the 'data' DataFrame ||  || Returns: ||     copy of 'data' DataFrame with 'macd_val' and 'macd_signal_line' columns added || \""\""\""",,,Yes
34002,"\""\""\"" || Accumulation Distribution  || Source: http:\/\/stockcharts.com\/school\/doku.php?st=accumulation+distribution&id=chart_school:technical_indicators:accumulation_distribution_line || Params:  ||     data: pandas DataFrame ||     trend_periods: the over which to calculate AD ||     open_col: the name of the OPEN values column || \thigh_col: the name of the HIGH values column || \tlow_col: the name of the LOW values column || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'acc_dist' and 'acc_dist_ema[trend_periods]' columns added || \""\""\""",,No,Yes
34003,"\""\""\"" || On Balance Volume (OBV) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:on_balance_volume_obv || Params:  ||     data: pandas DataFrame ||     trend_periods: the over which to calculate OBV || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'obv' and 'obv_ema[trend_periods]' columns added || \""\""\""",,No,Yes
34007,"\""\""\"" || Average directional movement index || Source: https:\/\/en.wikipedia.org\/wiki\/Average_directional_movement_index || Params:  ||     data: pandas DataFrame || \tperiods: period for calculating ADX (14 days recommended) || \thigh_col: the name of the HIGH values column || \tlow_col: the name of the LOW values column ||  || Returns: ||     copy of 'data' DataFrame with 'adx'; 'dxi'; 'di_plus'; 'di_minus' columns added || \""\""\""",,No,Yes
34008,"\""\""\"" || Negative Volume Index (NVI) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:negative_volume_inde || Params:  ||     data: pandas DataFrame || \tperiods: period for calculating NVI (255 days recommended) || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'nvi' and 'nvi_ema' columns added || \""\""\""",,,Yes
34009,"\""\""\"" || Positive Volume Index (PVI) || Source: https:\/\/www.equities.com\/news\/the-secret-to-the-positive-volume-index || Params:  ||     data: pandas DataFrame || \tperiods: period for calculating PVI (255 days recommended) || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'pvi' and 'pvi_ema' columns added || \""\""\""",,No,Yes
34012,"\""\""\"" || Negative Volume Index (NVI) || Source: http:\/\/stockcharts.com\/school\/doku.php?id=chart_school:technical_indicators:negative_volume_inde || Params:  ||     data: pandas DataFrame || \tperiods: period for calculating NVI (255 days recommended) || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'nvi' and 'nvi_ema' columns added || \""\""\""",,,Yes
34013,"\""\""\"" || Positive Volume Index (PVI) || Source: https:\/\/www.equities.com\/news\/the-secret-to-the-positive-volume-index || Params:  ||     data: pandas DataFrame || \tperiods: period for calculating PVI (255 days recommended) || \tclose_col: the name of the CLOSE values column || \tvol_col: the name of the VOL values column ||  || Returns: ||     copy of 'data' DataFrame with 'pvi' and 'pvi_ema' columns added || \""\""\""",,No,Yes
34015,TODO : TEMP LOCATION \/ Config,,Yes,Yes
34016,TODO for each time frame,,,Yes
34017,TODO : CONFIG TEMP LOCATION,,No,Yes
34018,TODO,,Yes,Yes
34020,TODO : temp,,No,Yes
34023,to implement in subclasses if config necessary,,Yes,Yes
34024,TODO improve,,,Yes
34025,TODO : temp class,,No,Yes
34029,TODO : improve,,,Yes
34030,TODO : prepare trade,,Yes,Yes
34031,TODO,,Yes,Yes
34032,TODO : temp,,,Yes
34037,TODO : take RT of followed users,,,Yes
34040,TODO : manage if currency\/market does not exist,,,Yes
34042,"\""\""\"" OrdersManager class will perform the supervision of each open order of the exchange trader || Data updating process is generic but a specific implementation is called for each type of order (TraderOrderTypeClasses) || The thread will perform this data update and the open orders status check each ORDER_REFRESHER_TIME seconds || This class is particularly needed when exchanges doesn't offer stop loss orders || This class has an essential role for the trader simulator || \""\""\""",,,Yes
34043,compute average move size,,No,Yes
34044,higher than time_average => high chances to be at half of the move already,,,Yes
34045,add last index if data_frame ends above threshold and last threshold_crossing_indexes inferior,,Yes,Yes
34046,TODO,,Yes,Yes
34047,TODO : use ccxt method,,Yes,Yes
34048,TODO : temp,,,Yes
34049,todo temp,,,Yes
34050,todo check if last time_frame configured,,Yes,Yes
34054,todo : > min exchange,,,Yes
34055,TODO install_requires=[];,,Yes,Yes
34057,TODO  extras_require={};,,Yes,Yes
34060,TODO temp with notification,,Yes,Yes
34061,move up to next evaluation,,Yes,Yes
34062,implement locally if the service has thread(s) to stop,,No,Yes
34064,todo add timer,,,Yes
34065,implement locally if the service shouldn't raise warning at startup if configuration is not set,,No,Yes
34068,TODO,,,Yes
34069,TODO update closed,,,Yes
34070,TODO update closed,,No,Yes
34071,TODO : bug,,No,Yes
34072,TODO : bug,,,Yes
34075,maybe later add an order remover to free up memory ?,,,Yes
34076,TODO method list,,Yes,Yes
34077,TODO string has no \/ between currency and market => need to add it !!!,,,Yes
34082,TODO check exchanges ?,,Yes,Yes
34083,to implement in subclasses if config necessary,,,Yes
34085,TODO : temp,,,Yes
34088,(\/10*10 to remove python wtf rounding system),,Yes,Yes
34089,TODO,,Yes,Yes
34092,TODO : stop loss,,Yes,Yes
34095,TODO check for each tentacle specified if update is available (with requirements),,No,Yes
34098,to implement in subclasses if config necessary,,Yes,Yes
34099,maybe later add an order remover to free up memory ?,,Yes,Yes
34103,TODO : rollback to previous version,,,Yes
34104,TODO,,Yes,Yes
34107,TODO,,Yes,Yes
34108,TODO temporary implementation waiting for more accurate fee management,,No,Yes
34109,TODO update config.json,,No,Yes
34110,TODO update config.json,,,Yes
34111,TODO generate trades with different patterns (linear; waves; random; etc),,,Yes
34114,TODO,,Yes,Yes
34117,TODO,,,Yes
34118,TODO install tentacles,,,Yes
34119,"TODO : call current binary \""-p install all\""",,,Yes
34120,TODO : temp to install corresponding tentacles,,No,Yes
34121,TODO remove this when no thread anymore,,,Yes
34122,"syntax: \""async with xxx.get_lock():\""",,No,Yes
34123,"syntax: \""async with xxx.get_lock():\""",,No,Yes
34124,TODO add confirmation,,,Yes
34125,maybe just a short downtime; retry a bit later,,Yes,Yes
34127,remove unused symbols,,,Yes
34128,"sys.argv[0] is the name of the binary when using a binary version: ends with nothing or .exe\""",,No,Yes
34129,"\""\""\"" || A ConsumerProducer collects; transform and move the data into another queue || \""\""\""",,,Yes
34130,TODO,,Yes,Yes
34131,TODO,,,Yes
34133,TODO,,Yes,Yes
34135,"\""Gemini\"": Gemini TODO Gemini requires a websocket per trading pair",,,Yes
34137,TODO will occurs in the futur evaluator_task_manager,,,Yes
34140,TODO filter creation,,,Yes
34142,TODO check if exists,,,Yes
34143,TODO TEMP,,No,Yes
34145,TODO manage wildcard,,Yes,Yes
34148,TODO,,Yes,Yes
34149,TODO : currently blocking; may implement queue if needed,,Yes,Yes
34150,TODO,,Yes,Yes
34151,TODO,,Yes,Yes
34153,TODO,,Yes,Yes
34156,@staticmethod TODO,,Yes,Yes
34157,TODO,,Yes,Yes
34160,TODO: handle proper stop,,,Yes
34161,todo remove,,,Yes
34163,move up to next evaluation,,,Yes
34164,TODO: handle multi exchange reports,,Yes,Yes
34166,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
34167,We set this variable manually because anaconda set it to a deprecated,,Yes,Yes
34172,TODO: add mixed list,,No,Yes
34175,TODO: this lock acquire is very expensive here,,No,Yes
34177,TODO: This is temporary and will be removed once Plottable will be,,No,Yes
34178,TODO: better method annotation giving the type in the tuple,,No,Yes
34180,TODO: implement _set_data and not fit,,,Yes
34182,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,,Yes
34186,TODO: implement _set_data and not fit,,Yes,Yes
34187,TODO: C++ for this,,Yes,Yes
34188,TODO: beware of zeros in z1 or z2 !,,No,Yes
34191,TODO: code the incremental strategy; where we try smaller SVDs,,Yes,Yes
34199,TODO: there's a problem if we give other coeffs with another size or,,No,Yes
34202,TODO: something better to tune the censoring level than this censoring factor,,,Yes
34203,TODO: properties for times_dist; shape; scale; censoring factor,,Yes,Yes
34204,TODO: raise a warning when the maximum label value is too large,,,Yes
34207,Fix navigation bar to top of page?,,Yes,Yes
34209,auto examples gallery to the _build folder. This works fine as is; but it would be cleaner to,,,Yes
34210,Sphinx hack: sphinx copies generated images to the build directory,,,Yes
34212,it should probably not cause a crash).  Tested successfully,,Yes,Yes
34215,TODO: fix multiprocessing,,,Yes
34216,We set T if needed,,No,Yes
34217,TODO: implement _set_data and not fit,,,Yes
34218,TODO: implement _set_data and not fit,,,Yes
34221,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34223,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34225,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34226,TODO: implement _set_data and not fit,,,Yes
34235,TODO: there's a problem if we give other coeffs with another size or,,,Yes
34236,if we change features. Maybe these should be readonly...,,Yes,Yes
34239,We set T if needed,,No,Yes
34240,TODO: this lock acquire is very expensive here,,,Yes
34241,TODO: implement _set_data and not fit,,,Yes
34242,TODO: implement _set_data and not fit,,Yes,Yes
34244,TODO: implement _set_data and not fit,,Yes,Yes
34246,TODO: implement _set_data and not fit,,Yes,Yes
34248,TODO: beware of zeros in z1 or z2 !,,No,Yes
34250,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34252,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34256,TODO: put also the OSCAR weights,,,Yes
34257,TODO: we should be able to put any weights we want...,,No,Yes
34262,TODO: implement _set_data and not fit,,Yes,Yes
34264,TODO: Use sklearn.decomposition.TruncatedSVD instead?,,Yes,Yes
34265,TODO: property for step that sets it in the C++,,,Yes
34266,TODO: this should be protected : _handle_history,,,Yes
34268,TODO: something better to tune the censoring level than this censoring factor,,Yes,Yes
34277,TODO later: put the code below somewhere else?,,No,Yes
34279,TODO: implement checker as outside function,,Yes,Yes
34284,TODO later: add self.max_n_events to allow for multiple outcomes,,,Yes
34285,TODO later: add SAGA solver,,No,Yes
34286,TODO: we might want to use SAGA also later... (might be faster here),,,Yes
34288,This is a bit of a hack as I don't see how to control the dtype of,,Yes,Yes
34289,3D representation under different rotated angles for a better visualazion,,Yes,Yes
34290,some assertions fail without this (TODO tbh),,No,Yes
34296,TODO: Don't get why int() is required here as censoring_i is uint64,,Yes,Yes
34297,some assertions fail without this (TODO tbh),,,Yes
34300,we'll need efficient access to intermediate nodes; and the tree,,,Yes
34301,contents are needed outside this function.,,Yes,Yes
34302,ugly hack because all files end with an empty column,,Yes,Yes
34303,ugly hack because all files end with an empty column,,,Yes
34305,TODO: remove the following line and rebuild index,,Yes,Yes
34306,TODO Add set call here; should compress index by 15%,,,Yes
34308,Ents are completely wrong from the web spacy model; correct them manually.,,,Yes
34309,TODO: This is possibly sub-optimal - we might,,No,Yes
34312,TODO: This is possibly sub-optimal - we might,,,Yes
34313,@TODO: Add a variable tracking the current audio send mode once that is implemented,,,Yes
34314,@TODO: Implement audio history as ringbuffer; caching only recent audio,,,Yes
34316,TODO Make the motion_profile_map into a class.,,,Yes
34317,TODO: This should be made into its own class,,No,Yes
34318,TODO alignment_type coming out ugly in the docs without real values,,Yes,Yes
34319,TODO Clamp angle to MIN_HEAD_ANGLE and MAX_HEAD_ANGLE.,,Yes,Yes
34321,TODO: Balance this more carefully once robots with proper color pipe,,No,Yes
34323,TODO Curious why events like the following aren't listed? At least some do seem to be supported in other parts of anki_vector.,,Yes,Yes
34325,TODO Update to: 'Do `pip3 install --user anki_vector[3dviewer]` from `pip3 install PyOpenGL`,,,Yes
34326,"TODO Update install line above to: ``pip3 install --user \""anki_vector[3dviewer]\""``",,,Yes
34329,Warn on old GLUT implementations that don't implement much of the interface.,,No,Yes
34330,Move up\/down,,,Yes
34334,self._audio = audio.AudioComponent(self) # TODO turn on,,No,Yes
34335,@TODO: We should decide on a resampling approach and have this function automatically rescale images,,Yes,Yes
34336,TODO Move to the robot class,,Yes,Yes
34337,@TODO Implement overlay using an ImageRect rather than a raw width & height,,No,Yes
34339,TODO: determine if this is still necessary,,Yes,Yes
34340,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
34341,TODO: clean this up,,No,Yes
34344,TODO: Update to use annotated image (add annotate module),,Yes,Yes
34346,TODO Try with num_retries of 3,,,Yes
34347,"\""\""\""This module provides 3D classes for running the OpenGL Viewer. ||  || It should be launched in a separate process to allow Vector to run freely while || the viewer is rendering. ||  || It uses PyOpenGL; a Python OpenGL 3D graphics library which is available on most || platforms. It also depends on the Pillow library for image processing. ||  || Warning: ||     This package requires Python to have the PyOpenGL package installed; along ||     with an implementation of GLUT (OpenGL Utility Toolkit). ||  ||     To install the Python packages on Mac and Linux do ``python3 -m pip install --user \""anki_vector[3dviewer]\""`` ||  ||     To install the Python packages on Windows do ``py -3 -m pip install --user \""anki_vector[3dviewer]\""`` ||  ||     On Windows and Linux you must also install freeglut (macOS \/ OSX has one ||     preinstalled). ||  ||     On Linux: ``sudo apt-get install freeglut3`` ||  ||     On Windows: Go to http:\/\/freeglut.sourceforge.net\/ to get a ``freeglut.dll`` ||     file. It's included in any of the `Windows binaries` downloads. Place the DLL ||     next to your Python script; or install it somewhere in your PATH to allow any ||     script to use it.\"" || \""\""\""",,Yes,Yes
34352,TODO move out of world.py and into lights.py?,,Yes,Yes
34354,TODO Currently cancels actions only. Add ability to cancel behaviors.,,Yes,Yes
34356,TODO restore audio feed code when ready,,No,Yes
34357,TODO make this support multiple simultaneous sound playback,,No,Yes
34358,TODO add audio feed enablement when ready,,No,Yes
34359,"\""\""\"" Reserve SDK Behavior Control ||  || While this script runs; other SDK scripts may run and Vector will not perform most || default behaviors before\/after they complete.  This will keep Vector still. ||  || High priority behaviors like returning to the charger in a low battery situation; || or retreating from a cliff will still take precedence. || \""\""\""",,Yes,Yes
34362,TODO: curses works well with Mac OS and Linux; explore msvcrt for Windows,,,Yes
34363,TODO: add return type hint,,,Yes
34364,TODO: add return type hint,,No,Yes
34366,TODO Currently cancels actions only. Add ability to cancel behaviors.,,Yes,Yes
34370,Shape info needed to build decoder model,,,Yes
34373,Shape info needed to build decoder model,,,Yes
34374,shape info needed to build decoder model,,No,Yes
34375,shape info needed to build decoder model,,No,Yes
34378,shape info needed to build decoder model,,,Yes
34379,orig paper uses SGD but RMSprop works better for DenseNet,,,Yes
34381,logp loss; the 3rd and 4th variables (entropy and beta) are needed,,Yes,Yes
34383,"\""\""\""Data generator || This is a multi-threaded; scalable; and efficient way of reading huge images || from a filesystem as dataset  || \""\""\""",,Yes,Yes
34384,needed during loss computation,,Yes,Yes
34385,"\""\""\""Data generator || This is a multi-threaded; scalable; and efficient way of reading huge images || from a filesystem as dataset  || \""\""\""",,Yes,Yes
34386,Move models to GPU,,Yes,Yes
34387,Move models to GPU,,Yes,Yes
34388,Move models to GPU,,,Yes
34389,Move models to GPU,,Yes,Yes
34390,Move models to GPU,,,Yes
34391,T.nnet.relu has some stability issues; this is better,,Yes,Yes
34392,RuntimeError: one of the variables needed for gradient computation has,,No,Yes
34393,"\""\""\"" || torchgpipe || ========== ||  || A GPipe_ implementation in PyTorch_. ||  || .. _GPipe: https:\/\/arxiv.org\/abs\/1811.06965 || .. _PyTorch: https:\/\/pytorch.org\/ ||  || .. sourcecode:: python ||  ||    from torchgpipe import GPipe ||  ||    model = nn.Sequential(a; b; c; d) ||    model = GPipe(model; balance=[1; 1; 1; 1]; chunks=8) ||  ||    for input in data_loader: ||        output = model(input) ||  || What is GPipe? || ~~~~~~~~~~~~~~ ||  || GPipe is a scalable pipeline parallelism library published by Google Brain; || which allows efficient training of large; memory-consuming models. According to || the paper; GPipe can train a 25x larger model by using 8x devices (TPU); and || train a model 3.5x faster by using 4x devices. ||  || `GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism || <https:\/\/arxiv.org\/abs\/1811.06965>`_ ||  || Google trained AmoebaNet-B with 557M parameters over GPipe. This model has || achieved 84.3% top-1 and 97.0% top-5 accuracy on ImageNet classification || benchmark (the state-of-the-art performance as of May 2019). ||  || Links || ~~~~~ ||  || - Source Code: https:\/\/github.com\/kakaobrain\/torchgpipe || - Documentation: https:\/\/torchgpipe.readthedocs.io\/ || - Original Paper: https:\/\/arxiv.org\/abs\/1811.06965 ||  || \""\""\""",,Yes,Yes
34394,Move skip to the head.,,,Yes
34395,a workaround.,,Yes,Yes
34396,TODO: change to duplicate,,,Yes
34397,TODO: why tensor should be taken?,,,Yes
34398,TODO: How PortalBlue uses it?,,,Yes
34400,TODO: stashed_tensors,,,Yes
34401,TODO: poppable_tensors,,,Yes
34402,TODO: split to subroutine,,No,Yes
34403,TODO: don't remove,,No,Yes
34408,TODO: write about None,,Yes,Yes
34409,TODO: just set if it is None.,,,Yes
34410,TODO: don't use default for explicit error,,,Yes
34411,TODO: rename to thread_local,,Yes,Yes
34412,TODO(sublee): Move to above of Skippable class for better read flow.,,Yes,Yes
34414,FIXME: leave if you want it to be celery-ready or remove,,Yes,Yes
34415,FIXME: code for uploading sources?,,No,Yes
34417,FIXME: code for uploading sources?,,,Yes
34418,(needed for the list of terms in text fields) and,,No,Yes
34422,We add full_term if needed. Note that when there's,,,Yes
34426,checks whether the information needed for local predictions is in,,,Yes
34427,TODO: modify to add boosted trees' nodes,,Yes,Yes
34428,checks whether the information needed for local predictions is in,,,Yes
34435,checks whether the information needed for local predictions is in,,,Yes
34436,We add full_term if needed. Note that when there's,,Yes,Yes
34439,Determine if 3rdparty package needed,,,Yes
34440,needed when the lib is linked with non-system-available dependencies,,Yes,Yes
34445,unused_docs = [],,Yes,Yes
34446,Hack; until I figure out how to write isgenerator() for python3!!,,No,Yes
34447,''' || (0008; 0005) Specific Character Set              CS: 'ISO_IR 100' || (0008; 0008) Image Type                          CS: ['ORIGINAL'; 'PRIMARY'; 'DIFFUSION'; 'NONE'; 'ND'; 'MOSAIC'] || (0008; 0012) Instance Creation Date              DA: '20100114' || (0008; 0013) Instance Creation Time              TM: '203419.375000' || (0008; 0016) SOP Class UID                       UI: MR Image Storage || (0008; 0018) SOP Instance UID                    UI: 1.3.12.2.1107.5.2.32.35119.201001142034191872808941 || (0008; 0020) Study Date                          DA: '20100114' || (0008; 0021) Series Date                         DA: '20100114' || (0008; 0022) Acquisition Date                    DA: '20100114' || (0008; 0023) Content Date                        DA: '20100114' || (0008; 0030) Study Time                          TM: '195840.718000' || (0008; 0031) Series Time                         TM: '203001.890000' || (0008; 0032) Acquisition Time                    TM: '203418.360000' || (0008; 0033) Content Time                        TM: '203419.375000' || (0008; 0050) Accession Number                    SH: '' || (0008; 0060) Modality                            CS: 'MR' || (0008; 0070) Manufacturer                        LO: 'SIEMENS' || (0008; 0080) Institution Name                    LO: 'MRC-CBU' || (0008; 0081) Institution Address                 ST: 'Chaucer Road  15;Cambridge;UK;GB;CB2 2EF' || (0008; 0090) Referring Physician's Name          PN: '' || (0008; 1010) Station Name                        SH: 'MRC35119' || (0008; 1030) Study Description                   LO: 'CBU^Neuroimaging' || (0008; 103e) Series Description                  LO: 'CBU_DTI_64D_1A' || (0008; 1050) Performing Physician's Name         PN: '' || (0008; 1070) Operators' Name                     PN: 'MC' || (0008; 1090) Manufacturer's Model Name           LO: 'TrioTim' || (0008; 1140)  Referenced Image Sequence   3 item(s) ----  ||    (0008; 1150) Referenced SOP Class UID            UI: MR Image Storage ||    (0008; 1155) Referenced SOP Instance UID         UI: 1.3.12.2.1107.5.2.32.35119.2010011420070434054586384 ||    --------- ||    (0008; 1150) Referenced SOP Class UID            UI: MR Image Storage ||    (0008; 1155) Referenced SOP Instance UID         UI: 1.3.12.2.1107.5.2.32.35119.2010011420070721803086388 ||    --------- ||    (0008; 1150) Referenced SOP Class UID            UI: MR Image Storage ||    (0008; 1155) Referenced SOP Instance UID         UI: 1.3.12.2.1107.5.2.32.35119.201001142007109937386392 ||    --------- || (0010; 0010) Patient's Name                      PN: '14012010' || (0010; 0020) Patient ID                          LO: 'METHODS' || (0010; 0030) Patient's Birth Date                DA: '19770222' || (0010; 0040) Patient's Sex                       CS: 'M' || (0010; 1010) Patient's Age                       AS: '032Y' || (0010; 1030) Patient's Weight                    DS: '88.000000' || (0018; 0020) Scanning Sequence                   CS: 'EP' || (0018; 0021) Sequence Variant                    CS: ['SK'; 'SP'] || (0018; 0022) Scan Options                        CS: ['PFP'; 'FS'] || (0018; 0023) MR Acquisition Type                 CS: '2D' || (0018; 0024) Sequence Name                       SH: 'ep_b1000#39' || (0018; 0025) Angio Flag                          CS: 'N' || (0018; 0050) Slice Thickness                     DS: '2.500000' || (0018; 0080) Repetition Time                     DS: '6600.000000' || (0018; 0081) Echo Time                           DS: '93.000000' || (0018; 0083) Number of Averages                  DS: '1.000000' || (0018; 0084) Imaging Frequency                   DS: '123.251815' || (0018; 0085) Imaged Nucleus                      SH: '1H' || (0018; 0086) Echo Number(s)                      IS: '1' || (0018; 0087) Magnetic Field Strength             DS: '3.000000' || (0018; 0088) Spacing Between Slices              DS: '3.000000' || (0018; 0089) Number of Phase Encoding Steps      IS: '102' || (0018; 0091) Echo Train Length                   IS: '1' || (0018; 0093) Percent Sampling                    DS: '100.000000' || (0018; 0094) Percent Phase Field of View         DS: '100.000000' || (0018; 0095) Pixel Bandwidth                     DS: '1395.000000' || (0018; 1000) Device Serial Number                LO: '35119' || (0018; 1020) Software Version(s)                 LO: 'syngo MR B17' || (0018; 1030) Protocol Name                       LO: 'CBU_DTI_64D_1A' || (0018; 1251) Transmit Coil Name                  SH: 'Body' || (0018; 1310) Acquisition Matrix                  US: [128; 0; 0; 128] || (0018; 1312) In-plane Phase Encoding Direction   CS: 'COL' || (0018; 1314) Flip Angle                          DS: '90.000000' || (0018; 1315) Variable Flip Angle Flag            CS: 'N' || (0018; 1316) SAR                                 DS: '0.421666' || (0018; 1318) dB\/dt                               DS: '0.000000' || (0018; 5100) Patient Position                    CS: 'HFS' || (0019; 0010) Private Creator                     OB: Array of 18 bytes || (0019; 1008) Private tag data                    OB: 'IMAGE NUM 4 ' || (0019; 1009) Private tag data                    OB: '1.0 ' || (0019; 100a) Private tag data                    OB: '0\\x00' || (0019; 100b) Private tag data                    OB: '40' || (0019; 100c) Private tag data                    OB: '1000' || (0019; 100d) Private tag data                    OB: 'DIRECTIONAL ' || (0019; 100e) Private tag data                    OB: Array of 24 bytes || (0019; 100f) Private tag data                    OB: 'Fast* ' || (0019; 1011) Private tag data                    OB: 'No' || (0019; 1012) Private tag data                    OB: '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\xfb\\xff\\xff' || (0019; 1013) Private tag data                    OB: '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\xfb\\xff\\xff' || (0019; 1014) Private tag data                    OB: '0\\\\0\\\\0 ' || (0019; 1015) Private tag data                    OB: Array of 24 bytes || (0019; 1016) Private tag data                    OB: '271.5475' || (0019; 1017) Private tag data                    OB: '1 ' || (0019; 1018) Private tag data                    OB: '2800' || (0019; 1027) Private tag data                    OB: Array of 48 bytes || (0019; 1028) Private tag data                    OB: '\\xaeG\\xe1z\\x14\\x0e3@' || (0019; 1029) Private tag data                    OB: Array of 384 bytes || (0020; 000d) Study Instance UID                  UI: 1.3.12.2.1107.5.2.32.35119.30000010011408520750000000022 || (0020; 000e) Series Instance UID                 UI: 1.3.12.2.1107.5.2.32.35119.2010011420292594820699190.0.0.0 || (0020; 0010) Study ID                            SH: '1' || (0020; 0011) Series Number                       IS: '12' || (0020; 0012) Acquisition Number                  IS: '40' || (0020; 0013) Instance Number                     IS: '40' || (0020; 0032) Image Position (Patient)            DS: ['-805.000000'; '-825.019119'; '-75.097641'] || (0020; 0037) Image Orientation (Patient)         DS: ['1.000000'; '0.000000'; '0.000000'; '0.000000'; '0.999986'; '-0.005236'] || (0020; 0052) Frame of Reference UID              UI: 1.3.12.2.1107.5.2.32.35119.1.20100114195840906.0.0.0 || (0020; 1040) Position Reference Indicator        LO: '' || (0020; 1041) Slice Location                      DS: '-79.416382' || (0028; 0002) Samples per Pixel                   US: 1 || (0028; 0004) Photometric Interpretation          CS: 'MONOCHROME2' || (0028; 0010) Rows                                US: 896 || (0028; 0011) Columns                             US: 896 || (0028; 0030) Pixel Spacing                       DS: ['1.796875'; '1.796875'] || (0028; 0034) Pixel Aspect Ratio                  IS: ['1'; '1'] || (0028; 0100) Bits Allocated                      US: 16 || (0028; 0101) Bits Stored                         US: 12 || (0028; 0102) High Bit                            US: 11 || (0028; 0103) Pixel Representation                US: 0 || (0028; 0106) Smallest Image Pixel Value          US or SS: '\\x00\\x00' || (0028; 0107) Largest Image Pixel Value           US or SS: '\\x08\\x03' || (0028; 1050) Window Center                       DS: '171.000000' || (0028; 1051) Window Width                        DS: '401.000000' || (0028; 1055) Window Center & Width Explanation   LO: 'Algo1' || (0029; 0010) Private Creator                     OB: Array of 18 bytes || (0029; 0011) Private Creator                     OB: Array of 22 bytes || (0029; 1008) [CSA Image Header Type]             OB: 'IMAGE NUM 4 ' || (0029; 1009) [CSA Image Header Version]          OB: '20100114' || (0029; 1010) [CSA Image Header Info]             OB: Array of 11888 bytes || (0029; 1018) [CSA Series Header Type]            OB: 'MR' || (0029; 1019) [CSA Series Header Version]         OB: '20100114' || (0029; 1020) [CSA Series Header Info]            OB: Array of 80248 bytes || (0029; 1160) [Series Workflow Status]            OB: 'com ' || (0032; 1060) Requested Procedure Description     LO: 'CBU Neuroimaging' || (0040; 0244) Performed Procedure Step Start Date DA: '20100114' || (0040; 0245) Performed Procedure Step Start Time TM: '195840.828000' || (0040; 0253) Performed Procedure Step ID         SH: 'MR20100114195840' || (0040; 0254) Performed Procedure Step Descriptio LO: 'CBU^Neuroimaging' || (0051; 0010) Private Creator                     OB: Array of 18 bytes || (0051; 1008) Private tag data                    OB: 'IMAGE NUM 4 ' || (0051; 1009) Private tag data                    OB: '1.0 ' || (0051; 100a) Private tag data                    OB: 'TA 00.04' || (0051; 100b) Private tag data                    OB: '128p*128' || (0051; 100c) Private tag data                    OB: 'FoV 1610*1610 ' || (0051; 100e) Private tag data                    OB: 'Tra>Cor(-0.3) ' || (0051; 100f) Private tag data                    OB: 'T:HEA;HEP ' || (0051; 1011) Private tag data                    OB: 'p2' || (0051; 1012) Private tag data                    OB: 'TP 0' || (0051; 1013) Private tag data                    OB: '+LPH' || (0051; 1015) Private tag data                    OB: 'R ' || (0051; 1016) Private tag data                    OB: Array of 28 bytes || (0051; 1017) Private tag data                    OB: 'SL 2.5' || (0051; 1019) Private tag data                    OB: 'A1\/PFP\/FS ' || (7fe0; 0010) Pixel Data                          OW\/OB: Array of 1605632 bytes || ''',,,Yes
34450,XXX list_files was removed in 0691d142dc33e0b1c2cfe6f4e5e915a780b428e2,,Yes,Yes
34451,fix presumed rounding errors in the B matrix by making it positive,,,Yes
34452,fix presumed rounding errors in the B matrix by making it positive,,No,Yes
34454,fix presumed rounding errors in the B matrix by making it positive,,No,Yes
34455,the columns and rows are transposed to match the way we're,,,Yes
34457,clear variables not needed to save memory,,,Yes
34458,be a useful feature to implement at some point for numeric fill_values,,Yes,Yes
34460,Perhaps later we can implement residuals,,,Yes
34461,half way round,,Yes,Yes
34463,maybe we are in a repository,,,Yes
34464,only a workaround to get things started -- not a solution,,,Yes
34465,"\""\""\"" Another way to represent tractography is as a numpy array of numpy objects. This way has an additional advantage that it can be saved very easily using the numpy. In theory in a list is faster to append an element and in an array is faster to access. In other words both representations have different + and -. Other representations are possible too e.g. graphtheoretic. || \""\""\""",,,Yes
34466,"\""\""\"" You probably have heard about the problem of crossings in diffusion MRI.  || The single tensor model cannot detect a crossing. || With Generalized Q-Sampling this is possible even up to a quadruple crossing  || or even higher as long as your datasets are able to provide that resolution. || \""\""\""",,,Yes
34467,"\""\""\"" Do you see the difference between the number of gqs tracks and ten tracks? Can you think a reason why? Correct; CROSSINGS!!! || \""\""\""",,Yes,Yes
34468,"\""\""\""  || Crossings and Generalized Q-Sampling || ------------------------------------ || You probably have heard about the problem of crossings in diffusion MRI.  || The single tensor model cannot detect a simple crossing of two fibres.  || However with *Generalized Q-Sampling (GQS)* this is possible even up to a quadruple crossing  || or higher depending on the resolution of your datasets. Resolution will  || typically depend on signal-to-noise ratio and voxel-size. || \""\""\""",,Yes,Yes
34470,to work around bug in setuptools monkeypatching of distutils,,No,Yes
34471,because pip will not allow us to workaround setuptools when it checks for,,,Yes
34472,needed in setup.py,,,Yes
34473,#TODO: this can become a nice tutorial for generating phantoms,,Yes,Yes
34474,normalize data by dividing by b0; this is needed so we can take log later,,Yes,Yes
34476,These bvecs only have two rows\/columns:,,Yes,Yes
34477,It might be good to also test the vertices somehow if we can think of a,,Yes,Yes
34478,hack for auto camera,,Yes,Yes
34480,"\""\""\"" In addition to the general idea of a model; we also define the concept of || an odf models.  An odf model is any model class that represents a continuous || function on the sphere; or an odf. An odf model should return a fit object with || an odf method. The odf method should take as it's input an instance of Sphere || (dipy.core.sphere.Sphere). ||  || Because many odf models identify fiber populations by finding peaks on the odf; || this direction finding functionality has been built into the abstract OdfModel || and OdfFit classes. In order to take advantage of this functionality; a || developer can subclass from the OdfModel and OdfFit and override the || OdfModel.fit and OdfFit.odf methods. For example: \""\""\""",,,Yes
34482,"\""\""\"" ||  || In addition to the general idea of a Model; we also define the concept of an || ODF Model.  An OdfModel is any model class that represents a continuous || function on the sphere; or an orientation distribution function (ODF). This || kind of model should implement a ``fit`` method as well; which returns an || OdfFit class instance. OdfFit classes in turn should implement an ``odf`` || method; which takes an instance of ``Sphere`` (from || ``dipy.core.sphere.Sphere``) as its input and always returns the values of the || orientation distribution function on the vertices of the provided sphere. This || implies that the OdfFit class ``odf`` method should know how to calculate the || value of the orientation distribution function at any arbitrary point on the || sphere (not only the points where measurements were obtained).    ||  || Because many ODF models identify fiber populations by finding peaks on the odf; || this direction finding functionality has been built into the abstract OdfModel || and OdfFit classes. In order to take advantage of this functionality; a || developer can subclass from the OdfModel and OdfFit and override the || OdfModel.fit and OdfFit.odf methods. ||  || Here are example implementation s of ``SillyOdfModel`` and ``SillyOdfFit`` || classes :  ||  ||  || \""\""\""",,,Yes
34489,hack for auto camera,,Yes,Yes
34490,"\""\""\""  || Crossings and Generalized Q-Sampling || ------------------------------------ || You probably have heard about the problem of crossings in diffusion MRI.  || The single tensor model cannot detect a simple crossing of two fibres.  || However with *Generalized Q-Sampling (GQS)* this is possible even up to a quadruple crossing  || or higher depending on the resolution of your datasets. Resolution will  || typically depend on signal-to-noise ratio and voxel-size. || \""\""\""",,Yes,Yes
34491,dipy uses a convention for theta and phi that is reversed with respect to,,No,Yes
34493,"\""\""\"" || .. figure:: fornix_clust.png ||    :align: center ||  ||    **Showing the different clusters with random colors**. ||  || It is also possible to save the complete QuickBundles object with pickling. || \""\""\""",,Yes,Yes
34495,This is a bit ugly; but it avoids running this again.,,,Yes
34496,The original data will be needed for final crop \/ mask,,,Yes
34497,Clip ends to align class 1 and class 2 variables:,,No,Yes
34498,standalone(Numpy and scipy are still needed though).,,No,Yes
34500,The original data will be needed for final crop \/ mask,,Yes,Yes
34501,"\""\""\"" || Saving the segmentation results is very easy using nibabel. We need the b0_mask; || and the binary mask volumes. The affine matrix which transform the image's || coordinates to the world coordinates is also needed. Here; we choose to save || both images in float32. || \""\""\""",,Yes,Yes
34502,Clip ends to align class 1 and class 2 variables:,,No,Yes
34504,bvals is a 1d vec; so there should probably be a better way to do this...,,Yes,Yes
34505,"\""\""\"" || We can now do a first segmentation of the data using the cfa. We will also get  || the rgb this way so we can further improve the masking if needed. ||  || We know that the corpus callosum should be in the middle of the brain  || and since the principal diffusion direction is the x axis;  || the red channel should be the highest in the cfa. ||  || Let's pick a threshold of 0.7 in the x axis and 0.1 in the y and z axis as a  || segmentation threshold.  ||  || We will also define a rough roi; since noisy pixels could be considered in the || maks if it's not bounded properly. Adjusting the cfa threshold and the roi  || location enables the function to segment any part of the brain based on  || an orientation and spatial location criterion. ||  || Note : Just as the threshold; roi could be supplied as a tuple; then made as a mask. || although it means you can supply premade mask made by rough drawing for example; || but we could probably try to support both if it's not too much of an hassle. || \""\""\""",,,Yes
34506,bvals is a 1d vec; so there should probably be a better way to do this...,,Yes,Yes
34508,"\""\""\"" || If needed; the fetch_stanford_hardi function will download the raw dMRI dataset || of a single subject. The size of this dataset is 87 MBytes. You only need to || fetch once.  || \""\""\""",,Yes,Yes
34510,"\""\""\"" || If needed; the fetch_stanford_hardi function will download the raw dMRI dataset || of a single subject. The size of this dataset is 87 MBytes. You only need to || fetch once.  || \""\""\""",,,Yes
34512,Use affine to move seeds int real world coordinates,,,Yes
34514,"\""\""\"" We've set `return_mapping` and `mapping_as_streamlines` to True so that || connectivity_matrix returns all the streamlines in cc_streamlines grouped by || their endpoint. ||  || We've set `symmetric` to True so that the start and end points are treated the || same and our connectivity matrix will be symmetric. ||  || Because we're typically only interested int gray-gray connections; and because || the label 0 represents background and the labels 1 and 2 represent white || matter; we then discard the first three rows and columns of the connectivity || matrix. ||  || We can now display this matrix using matplotlib; we dispaly it using a log || scale to make small values in the matrix easier to see. ||  || \""\""\""",,,Yes
34515,"Move streamlines to \""trackvis space\""",,,Yes
34516,TODO the affine returned by this function uses a different reference than,,,Yes
34518,should either fix this function in a backward compatible way or replace,,,Yes
34519,"\""\""\""Various tools related to creating and working with streamlines ||  || This module provides tools for targeting streamlines using ROIs; for making || connectivity matrices from whole brain fiber tracking and some other tools that || allow streamlines to interact with image data. ||  || Important Note: || --------------- || Some functions in this module use an affine matrix to represent the coordinate || system associated with the points of a streamline. Dipy uses a similar || convention to nifti files when interpreting this affine matrix. This convention || is that the point at the center of voxel ``[i; j; k`]` is represented by the || point ``[x; y; z]`` where ``[x; y; z; 1] = affine * [i; j; k; 1]``. || Also when the phrase \""voxel coordinates\"" is used; it is understood to be the || same as ``affine = eye(4)``. ||  || As an example; lets take a 2d image where the affine is || ``[[1.; 0.; 0.]; ||    [0.; 2.; 0.]; ||    [0.; 0.; 1.]]``: ||  || A------------ || |   |   |   | || | C |   |   | || |   |   |   | || ----B-------- || |   |   |   | || |   |   |   | || |   |   |   | || ------------- || |   |   |   | || |   |   |   | || |   |   |   | || ------------D ||  || A = [-.5; -1.] || B = [ .5;  1.] || C = [ 0.;  0.] || D = [ 2.5;  5.] || \""\""\""",,,Yes
34520,hack is from,,Yes,Yes
34521,hack is from,,,Yes
34523,"\""\""\"" || ==================================== || Symmetric Diffeomorphic Registration || ==================================== || This examples explain how to register 2D images and 3D volumes using || the Symmetric Normalization (SyN) algorithm proposed by Avants et al. || [citation needed] (also implemented in the ANTS [citation needed] software) ||  || The first example shows how to register two 2D images. We will use the classic || Circle-To-C experiment for diffeomorphic registration || \""\""\""",,,Yes
34526,Free resources no longer needed to compute the forward and backward steps,,,Yes
34528,"r\""\""\"" VerbosityLevels || This enum defines the four levels of verbosity we use in the align || module. || NONE : do not print anything || STATUS : print information about the current status of the algorithm || DIAGNOSE : print high level information of the components involved in the || \t\t   registration that can be used to detect a failing component. || DEBUG : print as much information as possible to isolate the cause of a bug. || \""\""\""",,Yes,Yes
34529,spider - diverging in the ends,,,Yes
34530,Free resources no longer needed to compute the forward and backward steps,,Yes,Yes
34531,XXX maybe check for extensions as well?,,Yes,Yes
34533,Use voxel_size to move seeds into trackvis space,,Yes,Yes
34535,the nifti-style index coordinates dipy has adopted as a convention. We,,Yes,Yes
34537,"# print(\""Apparently it's possible...\"")",,,Yes
34538,In simulation; it should work rather well (high COD):,,,Yes
34543,"r\""\""\"" VerbosityLevels || This enum defines the four levels of verbosity we use in the align || module. || NONE : do not print anything || STATUS : print information about the current status of the algorithm || DIAGNOSE : print high level information of the components involved in the || registration that can be used to detect a failing component. || DEBUG : print as much information as possible to isolate the cause of a bug. || \""\""\""",,Yes,Yes
34544,TODO: compute better voxel size,,No,Yes
34547,"\""\""\"" ||  || Probabilistic fiber tracking is a way of reconstructing white matter || connections using diffusion MR imaging. Like deterministic fiber tracking; the || probabilistic approach follows the trajectory of a possible pathway step by || step starting at a seed; however; unlike deterministic tracking; the tracking || direction at each point along the path is chosen at random from a distribution. || The distribution at each point is different and depends on the observed || diffusion data at that point. The distribution of tracking directions at each || point can be represented as a PMF (probability mass function) if the possible || tracking directions are restricted to discrete number of well distributed || points on a sphere. ||  || This example picks up where \""introduction to basic tracking\"" leaves off. || We'll begin by repeating a few steps from that example; loading the data and || fitting a CSD model. || \""\""\""",,,Yes
34548,Fix npymath libraries for Windows,,No,Yes
34549,If sigma is very small; it still needs to work:,,Yes,Yes
34550,"\""\""\"" || ==================== || Introduction to Basic Tracking || ==================== ||  || Local fiber tracking is an approach used to model white matter fibers by || creating streamlines from local directional information. The idea is as || follows: if the local directionality of a tract\/pathway segment is known; one || can integrate along those directions to build a complete representation of that || structure. Local fiber tracking is widely used in the field of diffusion MRI || because it is simple and robust. ||  || In order to perform local fiber tracking; three things are needed: 1) A method || for getting directions from a diffusion data set. 2) A method for identifying || different tissue types within the data set. 3) A set of seeds from which to || begin tracking.  This example shows how to combine the 3 parts described above || to create a tractography reconstruction from a diffusion data set. || \""\""\""",,Yes,Yes
34551,"\""\""\"" || ============================== || Introduction to Basic Tracking || ============================== ||  || Local fiber tracking is an approach used to model white matter fibers by || creating streamlines from local directional information. The idea is as || follows: if the local directionality of a tract\/pathway segment is known; one || can integrate along those directions to build a complete representation of that || structure. Local fiber tracking is widely used in the field of diffusion MRI || because it is simple and robust. ||  || In order to perform local fiber tracking; three things are needed: 1) A method || for getting directions from a diffusion data set. 2) A method for identifying || different tissue types within the data set. 3) A set of seeds from which to || begin tracking.  This example shows how to combine the 3 parts described above || to create a tractography reconstruction from a diffusion data set. || \""\""\""",,,Yes
34552,"\""\""\"" || ===================================================== || An introduction to the Probabilistic Direction Getter || ===================================================== ||  || Probabilistic fiber tracking is a way of reconstructing white matter || connections using diffusion MR imaging. Like deterministic fiber tracking; the || probabilistic approach follows the trajectory of a possible pathway step by || step starting at a seed; however; unlike deterministic tracking; the tracking || direction at each point along the path is chosen at random from a distribution. || The distribution at each point is different and depends on the observed || diffusion data at that point. The distribution of tracking directions at each || point can be represented as a probability mass function (PMF) if the possible || tracking directions are restricted to discrete number of well distributed || points on a sphere. ||  || This example picks up where \""introduction to basic tracking\"" leaves off. || We'll begin by repeating a few steps from that example; loading the data and || fitting a constrained spherical deconvolution (CSD) model. || \""\""\""",,,Yes
34555,Should work even with longer arrays:,,,Yes
34556,# XXX TODO : need to replace 'xform' with 'move_streamlines',,,Yes
34557,XXX Still need to multiply by b0 in the end to get it to the signal,,Yes,Yes
34559,Did we do better this time around?,,Yes,Yes
34566,TODO: support list of indices,,,Yes
34568,"\""\""\"" || qb has attributes like `centroids` (cluster representatives); `total_clusters` || (total number of clusters) and methods like `partitions` (complete description || of all clusters) and `label2tracksids` (provides the indices of the streamlines || which belong in a specific cluster). ||  || Lets first show the initial dataset. || \""\""\""",,Yes,Yes
34570,Generate as many random triplets as the number of seeds needed,,,Yes
34571,Use affine to move seeds int real world coordinates,,Yes,Yes
34577,TODO,,Yes,Yes
34578,hard-coded bound on the maximum residual; that's why we cannot,,,Yes
34580,All the following definitions are needed for the evaluation of the,,Yes,Yes
34584,Buffer to write the MI gradient into (if needed),,No,Yes
34587,"\""\""\"" || .. figure:: center_of_mass_feature.png ||    :align: center ||  ||    **Showing the center of mass of each streamline and colored according to ||    the QuickBundles results**. ||  || .. _clustering-examples-MidpointFeature: ||  || Midpoint Feature || ================ || **What:** Instances of `MidpointFeature` extract the middle point of a || streamline. If there is an even number of points; the feature will then || correspond to the point halfway between the two middle points. ||  || **When:** This feature can be useful when you *only* need information about the || spatial position of a streamline. This can also be an alternative to the || `CenterOfMassFeature` if the point extracted must be on the streamline. || \""\""\""",,,Yes
34589,"\""\""\"" || .. _clustering-examples-SumPointwiseEuclideanMetric: ||  || Sum of Pointwise Euclidean Metric || ================================= || TODO || \""\""\""",,Yes,Yes
34590,"\""\""\"" || ========================================================== || Enhancing QuickBundles with different metrics and features || ========================================================== ||  || QuickBundles is a flexible algorithm that requires only a distance metric and || an adjacency threshold to perform clustering. There is a wide variety of metrics || that could be uses to cluster streamlines. ||  || The purpose of this tutorial is to show how to easily create new `Feature` and || new `Metric` classes that can be used by QuickBundles. ||  ||  || Clustering framework || ==================== || Dipy provides a simple; flexible and fast framework to do clustering of || sequential data (e.g. streamlines). ||  || A *sequential datum* in Dipy is represented as a numpy array of size || :math:`(N \\times D)` where each row of the array represents a D dimensional || point of the sequence. A set of these sequences is represented as a list of || numpy arrays of size :math:`(N_i \\times D)` for :math:`i=1:M` where $M$ is the || number of sequences in the set. ||  || This clustering framework is modular and divided in three parts: || 1) feature extraction || 2) distance computation || 3) clustering algorithm ||  || The **feature extraction** part includes any preprocessing needed to be done on || the data before computing distances between them (e.g. resampling the number of || points of a streamline). To define a new way of extracting features; one has to || subclass `Feature` (see below). ||  || The **distance computation** part includes any metric capable of evaluating a || distance between two set of features previously extracted from the data. To || define a new way of extracting features; one has to subclass `Metric` (see below). ||  || The **clustering algorithm** part represents the clustering algorithm itself || (e.g. QuickBundles; K-means; Hierarchical Clustering). More precisely; it || includes any algorithms taking as input a list of sequential data and || outputting a `ClusterMap` object. ||  ||  || Extending `Feature` || =================== || This section will guide you through the creation of a new feature extraction || method that can be used in the context of this clustering framework. ||  || Assuming a set of streamlines; the type of features we want to extract is the || arc length (i.e. the sum of the length of each segment for a given streamline). ||  || Let's start by importing the necessary modules. || \""\""\""",,Yes,Yes
34592,Workaround for bug in older versions of SciPy that don't allow,,Yes,Yes
34598,Fix for python 3,,Yes,Yes
34600,Fix seed,,Yes,Yes
34602,TODO: return a list of items (i.e. each level of the assembly path).,,,Yes
34604,probably called by nose; better bail out,,Yes,Yes
34606,Clip ends to align class 1 and class 2 variables:,,,Yes
34607,Weighting seem to need a better initial guess,,No,Yes
34608,"\""\""\"" || This is the only thing needed to make your workflow available through command || line. ||  || Now just call the script you just made with -h to see the argparser help text. ||  || `python combined_workflow_creation.py --help` ||  || You should see all your parameters available along with some extra common ones || like logging file and force overwrite. Also all the documentation you wrote || about each parameter is there. Also note that every sub workflow optional || parameter is available. ||  || Now call it for real with a nifti file to see the results. Experiment || with the parameters and see the results. ||  || `python combined_workflow_creation.py volume.nii.gz` || \""\""\""",,Yes,Yes
34613,Uncompress file if needed.,,Yes,Yes
34614,TODO: we ever find them useful we could support them.,,Yes,Yes
34616,TODO ETP clean up?,,,Yes
34618,ToDo: Add other font families.,,,Yes
34622,"ToDo: down_button.add_callback(\""LeftButtonPressEvent\""; self.down_button_callback)",,Yes,Yes
34624,probably explore a more abstract way of doing this,,No,Yes
34626,This flag is needed only on 32 bits,,No,Yes
34630,fix the randominity,,,Yes
34633,no zeros in the first n-1 columns on last row,,,Yes
34637,TODO replace with Streamlines,,Yes,Yes
34639,"\""\""\"" || .. figure:: fODFs.png ||    :align: center ||  ||    **Fiber Orientation Distribution Functions; in a small ROI of the brain**. ||  || References || ---------- ||  || .. [Anderson2005] Anderson A. W.; \""Measurement of Fiber Orientation Distributions ||        Using High Angular Resolution Diffusion Imaging\""; Magnetic ||        Resonance in Medicine; 2005. ||  || .. [Kaden2016] Kaden E. et. al; \""Quantitative Mapping of the Per-Axon Diffusion ||        Coefficients in Brain White Matter\""; Magnetic Resonance in ||        Medicine; 2016. ||  || .. [Zucchelli2017] Zucchelli E. et. al; \""A generalized SMT-based framework for ||        Diffusion MRI microstructural model estimation\""; MICCAI Workshop ||        on Computational DIFFUSION MRI (CDMRI); 2017. ||  || .. include:: ..\/links_names.inc ||  || \""\""\""",,Yes,Yes
34640,Free resources no longer needed to compute the forward and backward,,Yes,Yes
34641,Unused with missing refernces to basis,,,Yes
34642,very hackish way,,No,Yes
34644,TODO: Check if coords is outside the panel.,,,Yes
34646,TODO: Should be a component like slider line.,,Yes,Yes
34647,Move slider disk.,,Yes,Yes
34648,TODO: Should be components.,,Yes,Yes
34650,Setup needed actors and sub UI components.,,Yes,Yes
34651,"\""\""\"" || .. figure:: output-1.png ||    :align: center || .. figure:: map-1.png ||    :align: center ||  ||    Registration results for a naive parameter configuration. || \""\""\""",,,Yes
34652,Temporary fix until scipy release in October 2018,,,Yes
34653,"\""\""\"" || .. figure:: viz_timer.png ||    :align: center ||  ||    **Showing 100 spheres of random radii and opacity levels**. || \""\""\""",,Yes,Yes
34654,Generate as many random triplets as the number of seeds needed,,Yes,Yes
34655,Use affine to move seeds into real world coordinates,,Yes,Yes
34657,hack_multiplier=1;,,Yes,Yes
34659,"\""\""\"" || ================================================================ || Estimating diffusion time dependent q-space indices using qt-dMRI || ================================================================ || Effective representation of the four-dimensional diffusion MRI signal --  || varying over three-dimensional q-space and diffusion time -- is a sought-after || and still unsolved challenge in diffusion MRI (dMRI). We propose a functional || basis approach that is specifically designed to represent the dMRI signal in || this qtau-space [Fick2017]_.  Following recent terminology; we refer to our || qtau-functional basis as ``q$\\tau$-dMRI''. We use GraphNet regularization -- || imposing both signal smoothness and sparsity -- to drastically reduce the || number of diffusion-weighted images (DWIs) that is needed to represent the dMRI || signal in the qtau-space. As the main contribution; q$\\tau$-dMRI provides the || framework to -- without making biophysical assumptions -- represent the || q$\\tau$-space signal and estimate time-dependent q-space indices || (q$\\tau$-indices); providing a new means for studying diffusion in nervous || tissue. qtau-dMRI is the first of its kind in being specifically designed to || provide open interpretation of the qtau-diffusion signal. ||  || q$\\tau$-dMRI can be seen as a time-dependent extension of the MAP-MRI || functional basis [Ozarslan2013]_; and all the previously proposed q-space || can be estimated for any diffusion time. These include rotationally || invariant quantities such as the Mean Squared Displacement (MSD); Q-space || Inverse Variance (QIV) and Return-To-Origin Probability (RTOP). Also || directional indices such as the Return To the Axis Probability (RTAP) and || Return To the Plane Probability (RTPP) are available; as well as the || Orientation Distribution Function (ODF). ||  || In this example we illustrate how to use the qtau-dMRI to estimate || time-dependent q-space indices from a qtau-acquisition of a mouse. ||  || First import the necessary modules: || \""\""\""",,Yes,Yes
34660,"\""\""\"" || ================================================================ || Estimating diffusion time dependent q-space indices using qt-dMRI || ================================================================ || Effective representation of the four-dimensional diffusion MRI signal -- || varying over three-dimensional q-space and diffusion time -- is a sought-after || and still unsolved challenge in diffusion MRI (dMRI). We propose a functional || basis approach that is specifically designed to represent the dMRI signal in || this qtau-space [Fick2017]_.  Following recent terminology; we refer to our || qtau-functional basis as ``q$\\tau$-dMRI''. We use GraphNet regularization -- || imposing both signal smoothness and sparsity -- to drastically reduce the || number of diffusion-weighted images (DWIs) that is needed to represent the dMRI || signal in the qtau-space. As the main contribution; q$\\tau$-dMRI provides the || framework to -- without making biophysical assumptions -- represent the || q$\\tau$-space signal and estimate time-dependent q-space indices || (q$\\tau$-indices); providing a new means for studying diffusion in nervous || tissue. qtau-dMRI is the first of its kind in being specifically designed to || provide open interpretation of the qtau-diffusion signal. ||  || q$\\tau$-dMRI can be seen as a time-dependent extension of the MAP-MRI || functional basis [Ozarslan2013]_; and all the previously proposed q-space || can be estimated for any diffusion time. These include rotationally || invariant quantities such as the Mean Squared Displacement (MSD); Q-space || Inverse Variance (QIV) and Return-To-Origin Probability (RTOP). Also || directional indices such as the Return To the Axis Probability (RTAP) and || Return To the Plane Probability (RTPP) are available; as well as the || Orientation Distribution Function (ODF). ||  || In this example we illustrate how to use the qtau-dMRI to estimate || time-dependent q-space indices from a qtau-acquisition of a mouse. ||  || First import the necessary modules: || \""\""\""",,,Yes
34662,Temporary fix until scipy release in October 2018,,,Yes
34663,workaround for the bug on cvxpy 1.0.15 when lopt = 0,,No,Yes
34665,TODO: add support for peaks,,Yes,Yes
34666,TODO use distinguished colormap,,,Yes
34668,"\""\""\"" ||  || .. _intro_basic_tracking: ||  || ============================== || Introduction to Basic Tracking || ============================== ||  || Local fiber tracking is an approach used to model white matter fibers by || creating streamlines from local directional information. The idea is as || follows: if the local directionality of a tract\/pathway segment is known; one || can integrate along those directions to build a complete representation of that || structure. Local fiber tracking is widely used in the field of diffusion MRI || because it is simple and robust. ||  || In order to perform local fiber tracking; three things are needed: 1) A method || for getting directions from a diffusion data set. 2) A method for identifying || different tissue types within the data set. 3) A set of seeds from which to || begin tracking.  This example shows how to combine the 3 parts described above || to create a tractography reconstruction from a diffusion data set. || \""\""\""",,,Yes
34669,"\""\""\"" || 3. Before we can begin tracking is to specify where to \""seed\"" (begin) the fiber || tracking. Generally; the seeds chosen will depend on the pathways one is || interested in modeling. In this example; we'll use a $2 \\times 2 \\times 2$ grid || of seeds per voxel; in a sagittal slice of the corpus callosum. Tracking from || this region will give us a model of the corpus callosum tract. This slice has || label value ``2`` in the labels image. || \""\""\""",,Yes,Yes
34670,Workaround for bug in older versions of SciPy that don't allow,,Yes,Yes
34674,"Move streamlines to \""trackvis space\""",,Yes,Yes
34677,the nifti-style index coordinates dipy has adopted as a convention. We,,,Yes
34678,should either fix this function in a backward compatible way or replace,,,Yes
34681,the nifti-style index coordinates dipy has adopted as a convention. We,,Yes,Yes
34682,should either fix this function in a backward compatible way or replace,,,Yes
34683,"\""\""\"" || ========================================================== || Denoise images using the Marcenko and Pastur PCA algorithm || ========================================================== ||  || The local PCA based denoising algorithm is an effective denoising || method because it exploits the redundancy across the diffusion-weighted images || [Manjon2013]_; [Veraart2016a]_. This algorithm has been shown to provide an || optimal compromise between noise suppression and loss of anatomical information || for different techniques such as DTI [Manjon2013]_; spherical deconvolution || [Veraart2016a] and DKI [Henri2018]_. ||  || The basic idea behind local PCA based diffusion denoising is to remove the || data's principal components mostly related to noise. The classification of || the principal components can be performed based on prior noise variance || estimates and empirical thresholds [Manjon2013]_ or based on random matrix || theory [Veraa2016a]. In addition to noise suppression; local PCA can be used || to estimate the noise variance [Veraa2016b]. ||  || In the following example; we show how to denoise diffusion MRI images and || estimate the noise variance using the local PCA algorithm. ||  || Let's load the necessary modules || \""\""\""",,Yes,Yes
34684,"\""\""\"" || .. figure:: denoised_localpca.png ||    :align: center ||  ||    Showing the middle axial slice of the local PCA denoised output. || \""\""\""",,,Yes
34686,TODO the twenty lines above are repeated in add_actor,,Yes,Yes
34687,it would be much nicer if we can refactor here.,,Yes,Yes
34688,TODO 'same' is not implemented,,Yes,Yes
34694,TODO: to be able to save bundles with header information,,,Yes
34696,TODO Need to provide header information or anatomy file,,Yes,Yes
34698,TODO use distinguished colormap,,Yes,Yes
34699,"\""\""\"" || We now define the class ``ArcLengthFeature`` that will perform the desired || feature extraction. When subclassing ``Feature``; two methods have to be || redefined: ``infer_shape`` and ``extract``. ||  || Also; an important property about feature extraction is whether or not || its process is invariant to the order of the points within a streamline. || This is needed as there is no way one can tell which extremity of a || streamline is the beginning and which one is the end. || \""\""\""",,,Yes
34700,TODO need to double check if this section is still needed,,Yes,Yes
34702,TODO use distinguished colormap,,Yes,Yes
34706,"\""\""\"" || .. figure:: symm_reconst.png ||    :align: center ||  ||    Reconstruction of a symmetric simulated signal on a high resolution sphere ||  || While a symmetric SH basis works well for reconstructing symmetric SF; it fails || to do so on asymmetric signals. We will now create such a signal by using a || different ODF for each hemisphere of our sphere. || \""\""\""",,,Yes
34707,"\""\""\"" || .. figure:: asym_signal.png ||    :align: center ||  ||    Illustration of an asymmetric simulated signal on a sphere of 64 ||    points per hemisphere ||  || Let's try to reconstruct this SF using a symmetric SH basis. || \""\""\""",,,Yes
34708,"\""\""\"" || .. figure:: asym_reconst.png ||    :align: center ||  ||    Reconstruction of an asymmetric signal using a symmetric SH basis ||  || As we can see; a symmetric basis fails to properly represent asymmetric SF. || Fortunately; DIPY_ also implements full SH bases; which can deal with symmetric || as well as asymmetric signals. For this tutorial; we will demonstrate it using || the ``descoteaux07_full`` SH basis. || \""\""\""",,Yes,Yes
34710,Todo:  Use fury.shaders API.,,,Yes
34712,"\""\""\"" || threshold indicates how strictly we want two bundles to be similar in shape. || \""\""\""",,,Yes
34715,TODO: bigger chunk_size,,No,Yes
34717,TODO: bigger chunk_size,,No,Yes
34722,TODO: dropout and batch_norm,,Yes,Yes
34724,TODO: dropout and batch_norm,,Yes,Yes
34728,each channel is a list of columns,,No,Yes
34734,TODO: remove this,,No,Yes
34735,each channel is a list of columns,,No,Yes
34736,remove any weird _l columns from merge,,,Yes
34738,TODO: maybe we can recover HADM_ID by looking at ICUSTAY_ID,,No,Yes
34739,TODO: no_icustay is calculated wrong; as we drop events with HADM_ID not listed in stays.csv,,Yes,Yes
34741,TODO,,Yes,Yes
34742,"\""\""\""Transform input data. ||  || Images are resized with Pillow which has a different coordinate convention: || https:\/\/pillow.readthedocs.io\/en\/3.3.x\/handbook\/concepts.html#coordinate-system ||  || > The Python Imaging Library uses a Cartesian pixel coordinate system; ||   with (0;0) in the upper left corner. Note that the coordinates refer to ||   the implied pixel corners; the centre of a pixel addressed as (0; 0) ||   actually lies at (0.5; 0.5). || \""\""\""",,,Yes
34744,TODO: remove hard coded class number,,Yes,Yes
34747,RandomApply(Blur(); 0.01);  # maybe irrelevant for COCO; but good for others,,Yes,Yes
34748,TODO: gives warnings,,,Yes
34749,fix valid area to be inside original image dimensions,,Yes,Yes
34750,TODO,,Yes,Yes
34752,"\""\""\""Transform input data. ||  || Images are resized with Pillow which has a different coordinate convention: || https:\/\/pillow.readthedocs.io\/en\/3.3.x\/handbook\/concepts.html#coordinate-system ||  || > The Python Imaging Library uses a Cartesian pixel coordinate system; ||   with (0;0) in the upper left corner. Note that the coordinates refer to ||   the implied pixel corners; the centre of a pixel addressed as (0; 0) ||   actually lies at (0.5; 0.5). || \""\""\""",,,Yes
34753,maybe irrelevant for COCO; but good for others,,,Yes
34754,RandomApply(Blur(); 0.01);  # maybe irrelevant for COCO; but good for others,,Yes,Yes
34756,TODO: verify the following three lines have negligible speed impact,,Yes,Yes
34759,TODO update,,,Yes
34760,mask valid TODO still necessary?,,,Yes
34762,TODO assumes one confidence,,,Yes
34766,maybe improved later,,No,Yes
34767,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
34768,maybe improved later,,,Yes
34769,unparseable. Maybe git-describe is misbehaving?,,,Yes
34770,TODO move to Cython (see grow_connection_blend),,Yes,Yes
34771,TODO: remove this reshuffling,,No,Yes
34773,cli configurable,,,Yes
34775,TODO: how to make configuration 'spawn' compatible,,No,Yes
34778,TODO: CoreMLv4 does not like strided slices.,,,Yes
34779,TODO: CoreMLv4 problem (see above).,,Yes,Yes
34780,TODO: convert into transform,,Yes,Yes
34781,TODO: by keypoint name; update skeleton indices if meta.keypoints,,Yes,Yes
34782,TODO: caf seeds,,Yes,Yes
34783,TODO: multi-scale,,Yes,Yes
34784,TODO: multi-scale,,Yes,Yes
34787,TODO assumes one confidence,,,Yes
34788,TODO implement,,Yes,Yes
34790,TODO: remove?,,No,Yes
34792,cli configurable,,,Yes
34793,cli configurable (TODO),,,Yes
34794,mask valid TODO still necessary?,,,Yes
34795,skeleton = [[dic_sk[i]; dic_sk[j]] for i; j in SKELETON]  # TODO,,Yes,Yes
34796,a timestamp index DataFrame with columns 'selected',,,Yes
34798,FIXME:remove this logic,,,Yes
34799,FIXME:we suppose history data should be there at first,,,Yes
34800,if got data;just move to another category,,Yes,Yes
34801,You can just specify package directories manually here if your project is,,Yes,Yes
34802,FIXME:handle this case gracefully,,,Yes
34806,FIXME:remove this logic,,,Yes
34807,FIXME:the > case,,No,Yes
34808,"FIXME\""refresh normal_data?",,Yes,Yes
34810,FIXME:\u5DF2\u4E0D\u53EF\u7528,,Yes,Yes
34811,FIXME:handle negative latter,,Yes,Yes
34813,if got data;just move to another entity_id,,Yes,Yes
34814,FIXME:better way for schema<->domain;now just dump to schema and use dict['field'] for operation,,Yes,Yes
34816,pd.set_option('display.max_columns'; None),,,Yes
34817,encode json columns,,Yes,Yes
34818,FIXME:\u5982\u679C\u6CA1\u5356\u5B8C\uFF0C\u91CD\u65B0\u8BA1\u7B97\u8BA1\u7B97\u5E73\u5747\u4EF7,,No,Yes
34822,"\""\""\""Does google-lint on c++ files. ||  || The goal of this script is to identify places in the code that *may* || be in non-compliance with google style.  It does not attempt to fix || up these problems -- the point is to educate.  It does also not || attempt to find all problems; or to ensure that everything it does || find is legitimately a problem. ||  || In particular; we can get very confused by \/* and \/\/ inside strings! || We do a small hack; which is to ignore \/\/'s with \""'s after them on the || same line; but it is far from perfect (in either direction). || \""\""\""",,Yes,Yes
34823,"FIXME(adonovan): \""NOLINT(\"" is misparsed as NOLINT(*).",,,Yes
34826,statements better.,,Yes,Yes
34827,To verify that the file ends in \ || ; we just have to make sure the,,,Yes
34828,Found DISALLOW* macro outside a class declaration; or perhaps it,,,Yes
34829,though; so we punt on this one for now.  TODO.,,,Yes
34830,There shouldn't be space around unary operators,,,Yes
34831,You shouldn't have spaces before your brackets; except maybe after,,,Yes
34833,Also ignores cases where the previous line ends with a backslash as can be,,No,Yes
34834,We implement a whitelist of safe macros instead of a blacklist of,,,Yes
34835,Logical and\/or operators.  This means the expression,,,Yes
34836,is more efficient when the operands are longer than a single,,Yes,Yes
34837,it provides a way to workaround this warning for people who use,,No,Yes
34839,A call-by-const-reference parameter either ends with 'const& identifier',,Yes,Yes
34840,convention of the whole function to process multiple line to handle it.,,Yes,Yes
34841,Function(int \/*unused_param*\/);,,,Yes
34843,A tiny hack: the dirname validator also returns readme YAML frontmatter.,,,Yes
34844,columns as the first row; append it to the list,,Yes,Yes
34848,ends at T' and T' is not linked,,No,Yes
34849,NB: In Python 2; longs will repr() as '2L'; which is ugly and,,Yes,Yes
34850,TODO: subgr,,No,Yes
34851,Make the seed meet C-style naming convention,,Yes,Yes
34855,We fix this problem here.,,Yes,Yes
34857,Remove unused variables,,No,Yes
34858,ends at T' and T' is not linked,,,Yes
34862,TODO: Changing input shapes of an operator is dangerous; this should be move to Topology's _fix_shapes function,,Yes,Yes
34863,TODO: Changing input shapes of an operator is dangerous; this should be move to Topology's _fix_shapes function,,Yes,Yes
34865,No concatenation is needed; we just use the first variable's name,,Yes,Yes
34866,Collect input variable names and do cast if needed,,Yes,Yes
34867,Adjust batch size if needed,,No,Yes
34868,Fix this...,,Yes,Yes
34871,TODO initial_c (optional) : T,,No,Yes
34873,TODO: figure out keras way of inital_h,,Yes,Yes
34874,Add bias vectors at different places in the original LSTM if needed,,Yes,Yes
34876,TODO: deal with input with shape [N;C;1;1],,,Yes
34877,Apply pre-processing step if needed,,,Yes
34878,workaround for resahpe in ONNX 1.2 not supporting INT64,,Yes,Yes
34879,For global pooling; a Reshape op is needed to match the actual Keras's output shape.,,Yes,Yes
34880,Check input naming convention,,Yes,Yes
34881,Check output naming convention,,Yes,Yes
34882,The other vector is (N; 2) score in two columns.,,,Yes
34884,TODO: onnxruntime can't support batch_size > 1,,No,Yes
34886,To fix that; an extra parameter must be added to,,Yes,Yes
34889,First we assume no cropping is needed at the end of those axes.,,Yes,Yes
34891,First we assume no cropping is needed at the end of those axes.,,,Yes
34892,Add the adjusted ends.,,Yes,Yes
34895,A operator has an output; so we remove the operator from the unused-operator list.,,,Yes
34900,Check input naming convention,,,Yes
34906,TODO: Add ability to set proportion of negative examples here,,Yes,Yes
34908,y; x (rows; columns),,No,Yes
34911,TODO: update notes\/cuda.rst when this class handles 8+ GPUs well,,,Yes
34912,panoptic head related param,,No,Yes
34913,TODO: make fast_rcnn irrelevant,,Yes,Yes
34917,TODO: include builtin libraries for the appropriate Python,,No,Yes
34918,TODO: include builtin libraries for the appropriate Python,,,Yes
34928,TODO: Check if Docker is up and running,,,Yes
34929,TODO: Fill in code_driver to start up Docker,,Yes,Yes
34930,TODO: Fix function to better accomodate all logs in the same way,,Yes,Yes
34939,Initialize File Manager if needed,,,Yes
34940,Initialize Environment Manager if needed,,No,Yes
34941,TODO: Convert pseudocode into real code_driver,,,Yes
34946,TODO: figure out User object and handling of owner in Project,,,Yes
34949,TODO:  add file locking,,No,Yes
34950,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
34951,TODO: handle error vs. empty response properly,,Yes,Yes
34953,TODO: Add in project template files,,Yes,Yes
34954,TODO: Add in Project template if user specifies,,Yes,Yes
34959,TODO: Add time filters,,No,Yes
34960,TODO: Save this to be reverted to,,No,Yes
34963,TODO: extract hardware information directly from the container,,Yes,Yes
34964,TODO Update after changes in snapshot and task controller,,No,Yes
34966,TODO: extract hardware information directly from the container,,Yes,Yes
34969,TODO: look into log filepath randomness; sometimes logs are not written,,,Yes
34970,TODO: implement with proper task controller function,,,Yes
34971,TODO: implement with proper task controller,,No,Yes
34973,TODO: implement in controller,,No,Yes
34974,Create new code_driver ref to revert back (if needed),,Yes,Yes
34975,TODO: Save this to be reverted to,,,Yes
34976,TODO: Use more common CLI command (e.g. curl instead of wget),,,Yes
34977,TODO: extract hardware information directly from the container,,Yes,Yes
34982,TODO: look into log filepath randomness; sometimes logs are not written,,Yes,Yes
34984,TODO: extract hardware information directly from the container,,,Yes
34985,TODO: extract hardware information directly from the container,,,Yes
34993,TODO: split out the find containers function from stop \/ remove,,Yes,Yes
34996,TODO: Check if Docker is up and running,,,Yes
34998,TODO: Add in note when environment is not setup or intialized,,Yes,Yes
35000,TODO: Fill in to start up Docker,,,Yes
35002,# TODO: handle multiple remote urls,,Yes,Yes
35004,TODO: move to list function in TaskController,,No,Yes
35005,TODO: REMOVE THIS CODE,,,Yes
35007,Step 2: Check existing paths and create files as needed to populate the,,No,Yes
35008,TODO: Fix after merging the PR for environments,,Yes,Yes
35009,TODO Use datmo environment path as a class attribute,,Yes,Yes
35012,TODO Use datmo environment path as a class attribute,,,Yes
35013,TODO: Check for it after merging changes in other PR,,,Yes
35014,TODO: extract hardware information directly from the container,,Yes,Yes
35015,TODO: Fix after merging the PR for environments,,Yes,Yes
35021,TODO: include builtin libraries for the appropriate Python,,,Yes
35023,TODO: otherwise initial commit will always fail because of no unstaged changes,,No,Yes
35024,"TODO: fix circular logic: for empty tracked filepaths; must return \""unstaged\"" until commit is created.",,,Yes
35026,TODO: remove business logic from here and create common helper,,Yes,Yes
35033,TODO: move url into configurations (to be setup `datmo configure`,,Yes,Yes
35041,TODO: generalize,,No,Yes
35043,TODO: END,,No,Yes
35044,TODO: generalize,,No,Yes
35045,TODO: Create a default location to save for the specific deployment,,Yes,Yes
35047,running daemon needed,,No,Yes
35048,TODO: abstract the datmo_directory_name,,,Yes
35050,TODO: fix stop function to handle stopping containers run from specific environment_ids,,Yes,Yes
35051,"TODO: abstract the \""datmo_directory_name\""",,No,Yes
35052,Initialize File Driver if needed,,No,Yes
35054,TODO: END,,,Yes
35055,TODO catch Ctrl-C,,Yes,Yes
35057,TODO: catch Ctrl-C,,Yes,Yes
35060,s = Solver(sp.sparse.csr_matrix(A)) ##TODO: compare to sparse,,No,Yes
35062,# FIXME - do proper split,,,Yes
35063,# TODO: compute these in C++ (CPU or GPU),,Yes,Yes
35065,# TODO: compute this in C++ (CPU or GPU),,Yes,Yes
35068,FIXME TODO: Still need (http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit_predict),,No,Yes
35070,TODO FIXME: Don't need validY if just want preds and no error; but don't return error in fit; so leave for now,,,Yes
35071,FIXME TODO: Still need (http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit_predict),,,Yes
35072,TODO: message about vector lengths?,,No,Yes
35074,TODO Add type checking,,No,Yes
35075,TODO proper type?,,,Yes
35078,TODO: add gpu_id like kmeans and ensure wraps around deviceCount,,No,Yes
35081,TODO need to figure out a proper lamba min for h2o-3,,No,Yes
35083,In general terms; leaf-wise algorithms are more efficient; they converge much faster than depth-wise. However; it may cause over-fitting when the data is small or there are too many leaves.,,,Yes
35084,The experiment shows a similar performance in XGBoost hist and LightGBM. Under the parameters we used and this big dataset; LightGBM is faster. We couldn't compute the standard version of XGBoost because we got an out of memory.,,Yes,Yes
35085,In this dataset we have a big feature size; 2048. When using the standard version of XGBoost; xgb; we get an out of memory using a NVIDIA M60 GPU; even if we reduce the max depth of the tree to 2. A solution to this issue would be to reduce the feature size. One option could be using PCA and another could be to use a different featurizer; instead of ResNet whose last hidden layer has 2048 units; we could use VGG; [also provided by Keras](https:\/\/github.com\/fchollet\/keras\/blob\/master\/keras\/applications\/vgg16.py); whose last hidden layer has 512 units.,,,Yes
35086,In our experiments with the reduced dataset of 1 million rows; the memory consumption of xgb is around 10 times higher than LightGBM and 5 times higher than XGBoost histogram (leaf-wise implementation).,,Yes,Yes
35087,Find columns containing data of bookkeeper,,Yes,Yes
35089,Rename columns with bookkeeper names,,,Yes
35090,TODO: Needs to be tuned?,,Yes,Yes
35091,"\""\""\"" || Import Data for H2O GPU Edition ||  || This function will read in data and prepare it for H2O4GPU's GLM solver ||  || Parameters || ---------- || data_path : str ||              A path to a dataset (The dataset needs to be all numeric) || use_pandas : bool ||               Indicate if Pandas should be used to parse || intercept : bool ||               Indicate if intercept term is needed || valid_fraction : float ||                   Percentage of dataset reserved for a validation set || classification : bool ||                   Classification problem? || Returns || ------- || If valid_fraction > 0 it will return the following: ||     train_x: numpy array of train input variables ||     train_y: numpy array of y variable ||     valid_x: numpy array of valid input variables ||     valid_y: numpy array of valid y variable ||     family : string that would either be \""logistic\"" if classification is set to True; otherwise \""elasticnet\"" || If valid_fraction == 0 it will return the following: ||     train_x: numpy array of train input variables ||     train_y: numpy array of y variable ||     family : string that would either be \""logistic\"" if classification is set to True; otherwise \""elasticnet\"" || \""\""\""",,Yes,Yes
35092,"\""\""\"" || Machine learning module for Python || ================================== ||  || sklearn is a Python module integrating classical machine || learning algorithms in the tightly-knit world of scientific Python || packages (numpy; scipy; matplotlib). ||  || It aims to provide simple and efficient solutions to learning problems || that are accessible to everybody and reusable in various contexts: || machine-learning as a versatile tool for science and engineering. ||  || See http:\/\/scikit-learn.org for complete documentation. || \""\""\""",,Yes,Yes
35093,avoid flakes unused variable error,,No,Yes
35094,TODO Always need to set to 0.,,No,Yes
35095,TODO raise an exception instead,,Yes,Yes
35096,TODO FIXME: Don't need valid_y if just want preds and no,,,Yes
35097,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
35100,FIXME: This function duplicates others in solvers\/utils.py as used in GLM,,Yes,Yes
35101,Not this is really munging as adds to columns and changes expected size of outputted solution,,,Yes
35104,TODO Add type checking,,,Yes
35107,TODO: FIXME,,,Yes
35108,data = data.todense() # FIXME: glm and kmeans h2o4gpu currently only supports dense matrices,,,Yes
35109,TODO don't set order if X is 'F',,Yes,Yes
35110,TODO multi GPU returns wrong results,,,Yes
35113,TODO:,,,Yes
35114,TODO,,Yes,Yes
35115,(can remove if fully implement sklearn functionality),,Yes,Yes
35116,TODO: Not set yet,,,Yes
35118,TODO: No such scheme for our class yet;,,,Yes
35119,TODO: Below fails; so our solution seems very different from what should be?,,,Yes
35121,We also want to be either better or at most 5% worse than SKLearn,,,Yes
35122,Everything else is horrible and we probably should fix something,,,Yes
35123,(can remove if fully implement sklearn functionality),,,Yes
35124,FIXME: Add init as array and kmeans++ to h2o4gpu,,Yes,Yes
35125,FIXME: Add n_init to h2o4gpu,,Yes,Yes
35128,TODO add for h2o4gpu,,Yes,Yes
35129,Can remove if fully implement sklearn functionality,,Yes,Yes
35131,Can remove if fully implement sklearn functionality,,,Yes
35136,TO-DO: change the assertion once the logic to convert probabilities to classes is implemented,,,Yes
35137,Can remove if fully implement sklearn functionality,,Yes,Yes
35143,Can remove if fully implement sklearn functionality,,,Yes
35145,reduce system memory requirements for basic tests; otherwise some tests eat too much system memory,,,Yes
35146,TODO mean_ and noise_variance_ calculation,,Yes,Yes
35147,Can remove if fully implement sklearn functionality,,,Yes
35149,To match sci-kit #TODO Port to cuda?,,,Yes
35151,To match sci-kit #TODO Port to cuda?,,Yes,Yes
35155,TODO Investigate why explained variance\/ratio are off in CUDA,,Yes,Yes
35156,TODO,,Yes,Yes
35159,TODO: grab this from BUILD_INFO.txt or __about__.py,,Yes,Yes
35160,TODO remake all settings,,Yes,Yes
35162,TODO: find out why it hangs,,Yes,Yes
35163,TODO: it's failing with lower rtol; find out why it's so inaccurate,,,Yes
35164,TODO: workaround; remove it when xgboost is fixes,,No,Yes
35165,TODO: remove when nccl works on ppc,,No,Yes
35168,TODO: https:\/\/github.com\/dmlc\/xgboost\/issues\/4518,,Yes,Yes
35169,TODO: https:\/\/github.com\/dmlc\/xgboost\/issues\/4518,,Yes,Yes
35171,TODO: CUDA-10.2 gives less accurate result,,Yes,Yes
35172,To getter a better understanding of interaction of the dimensions,,Yes,Yes
35177,Remove duplicated columns,,,Yes
35178,Function duplicate_columns,,Yes,Yes
35179,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
35183,Set output columns,,,Yes
35184,Set Leading and Lagging Columns,,,Yes
35186,Collect all columns into new frame,,Yes,Yes
35188,add intraday columns if necessary,,,Yes
35189,Make the remaining columns floating point,,,Yes
35191,TODO: These could potentially be obtained by the system,,,Yes
35194,TODO: Add more comments describing the math here.,,,Yes
35195,TODO: Use something like torch.any(dv < 0),,Yes,Yes
35196,TODO: torch.potrf sometimes says the matrix is not PSD but,,Yes,Yes
35199,TODO,,Yes,Yes
35200,TODO: Move back down,,Yes,Yes
35201,factor_kkt(S_LU; R; d) # TODO: Moved up due to numerical issues.,,Yes,Yes
35202,"print('='*70+'\ || '+\""TODO: Remove try\/except around factor_kkt!!!\""+'\ || ')",,No,Yes
35204,TODO: Move this below.,,,Yes
35205,TODO: Move factorization back here.,,,Yes
35206,1e-5) # TODO: Remove,,No,Yes
35207,TODO: I think this should be negated; but not sure.,,No,Yes
35210,TODO: Share memory between these or handle batched sparse matrices differently.,,,Yes
35211,TODO: Currently don't use pivoting because torch.btriunpack is,,Yes,Yes
35214,Calculate how many points belong to each interval.,,Yes,Yes
35217,XXX: the following line is the only line that is specific to 2D;,,Yes,Yes
35222,XXX: scale dev[jsimplex] by max(z) - min(z) and tri_radius by bounds diagonal,,,Yes
35224,XXX: maybe just set the err = 0?,,Yes,Yes
35225,XXX: What do I do here? Same as above?,,No,Yes
35226,XXX: Didn't I already calculate the center value?,,,Yes
35231,XXX: not changed yet,,,Yes
35232,XXX: this is still incorrect; it should start from the first,,Yes,Yes
35236,XXX: `self.depth == 1` might be a bad condition to determine,,Yes,Yes
35238,XXX: Need some recursion here for the parallel execution.,,,Yes
35239,XXX: is this check worth it?,,Yes,Yes
35240,Calculate how many points belong to each interval.,,Yes,Yes
35241,XXX: not sure whether this is necessary it was there,,No,Yes
35242,The while loop is needed because `stack_till` could be larger,,Yes,Yes
35246,This encodes the convention for passing extra information,,Yes,Yes
35247,XXX: learner; control and bounds are not defined,,Yes,Yes
35251,XXX: check if not sum(n for n in ex._client.ncores().values()),,Yes,Yes
35252,XXX: remove this function when we depend on ipykernel>=4.7.0,,Yes,Yes
35253,Calculate how many grid points are needed.,,,Yes
35254,XXX: what if this interval already has children?,,,Yes
35255,needed because inf\/2 == inf,,Yes,Yes
35257,TODO: change this logic when there is a git pretty-format,,Yes,Yes
35258,TODO: Choose a better estimate for the loss improvement.,,Yes,Yes
35259,XXX: This *should* pass (https:\/\/gitlab.kwant-project.org\/qt\/adaptive\/issues\/43),,No,Yes
35261,TODO: is this condition correct for arbitraty face dimension in,,,Yes
35264,TODO modify this function,,Yes,Yes
35265,TODO adapt this function,,No,Yes
35268,Calculate how many grid points are needed.,,Yes,Yes
35269,TODO adapt this function,,,Yes
35270,will return new points; later we remove these points if needed.,,Yes,Yes
35271,TODO allow cases where n > 1,,Yes,Yes
35272,Calculate how many grid points are needed.,,Yes,Yes
35273,n = int(0.658 \/ sqrt(volumes(ip).min()))  # TODO fix this calculation,,,Yes
35274,TODO: why do we even need the interpolator; just the triangulation would be sufficient,,,Yes
35275,TODO actually get losses_combined,,,Yes
35276,TODO make this a global method,,Yes,Yes
35279,TODO actually make performance better,,Yes,Yes
35282,TODO what happens if a point belongs to multiple simplices,,No,Yes
35285,TODO if s0 == -1 you may have to recompute everything :(,,,Yes
35288,or better even; do a special flip that makes the triangulation the best it can be,,Yes,Yes
35289,TODO also add this point to the neighbours of simplex,,,Yes
35291,TODO change this longest edge contribution to be scale independent,,Yes,Yes
35292,TODO also compute losses of initial simplex,,,Yes
35295,TODO in the end we want to lose this method,,,Yes
35296,TODO maybe have a method point_strictly_inside_simplex,,,Yes
35297,TODO maybe have a method point_on_face,,No,Yes
35298,XXX: Better to write a separate function for this,,,Yes
35299,No idea why this fails,,,Yes
35303,XXX: adapt this function,,,Yes
35304,XXX: allow cases where n > 1,,,Yes
35305,XXX: find a better selection algorithm,,Yes,Yes
35306,XXX: adapt this function,,,Yes
35313,XXX: the LearnerND currently fails because there is no `add_data=False` argument in ask.,,Yes,Yes
35314,XXX: The LearnerND shouldn't fail; see https:\/\/gitlab.kwant-project.org\/qt\/adaptive\/issues\/105,,Yes,Yes
35316,Calculate how many points belong to each interval.,,Yes,Yes
35318,XXX: the Learner2D fails with ~50% chance,,No,Yes
35320,Test if everything is still fine when executed in the reverse order,,,Yes
35321,XXX: take our own triangulation into account when generating the ip,,No,Yes
35322,XXX: change when https:\/\/github.com\/ioam\/holoviews\/issues\/3085,,Yes,Yes
35324,XXX: add a doc-string,,Yes,Yes
35325,Calculate how many points belong to each interval.,,Yes,Yes
35326,XXX: until https:\/\/github.com\/grantjenks\/sortedcollections\/issues\/5 is fixed,,,Yes
35329,XXX: until https:\/\/github.com\/grantjenks\/sortedcollections\/issues\/5 is fixed,,No,Yes
35330,XXX could be a property,,No,Yes
35331,XXX: used to be dm.event(),,Yes,Yes
35333,XXX: change when https:\/\/github.com\/pyviz\/holoviews\/issues\/3637,,Yes,Yes
35334,XXX: add doc-string!,,,Yes
35335,XXX: Need to add check that the loss is the most recent computed loss,,,Yes
35336,XXX: add the points outside the triangulation to this as well,,No,Yes
35337,XXX: change when https:\/\/github.com\/pyviz\/holoviews\/issues\/3637,,Yes,Yes
35338,XXX: This *should* pass (https:\/\/github.com\/python-adaptive\/adaptive\/issues\/55),,Yes,Yes
35339,XXX: change when https:\/\/github.com\/pyviz\/holoviews\/issues\/3637,,Yes,Yes
35340,Calculate how many grid points are needed.,,,Yes
35343,XXX: remove when ipyparallel 6.2.5 is released,,,Yes
35344,Use ind to index into the matrix columns,,,Yes
35346,Pete Todo: would be great to automate this later,,Yes,Yes
35348,later implement something that is different_enough for rotations?,,,Yes
35349,will happily do a more efficient way of grabbing pose,,,Yes
35350,later implement something that is different_enough for rotations?,,Yes,Yes
35353,will happily do a more efficient way of grabbing pose,,,Yes
35354,you might need to flip the image rows; vtk has a difference row ordering convention that numpy\/opencv,,No,Yes
35355,TODO:,,No,Yes
35356,there is a workaround for an issue with the ply reader.,,Yes,Yes
35357,flip the normal if needed,,Yes,Yes
35358,TODO: replace with 'all points above the table':,,Yes,Yes
35359,note this hack to orient the drill correctly:,,No,Yes
35364,later implement something that is different_enough for rotations?,,Yes,Yes
35367,convert to grayscale image if needed,,,Yes
35368,TODO: return something cleaner than no-data,,No,Yes
35369,convert to grayscale image if needed,,No,Yes
35371,maybe set this elsewhere,,Yes,Yes
35372,maybe set this elsewhere,,,Yes
35375,new metric: average l2 distance of the pixels better than ground truth,,Yes,Yes
35376,new metric: average l2 distance of the pixels better than ground truth,,Yes,Yes
35379,TODO: return something cleaner than no-data,,No,Yes
35381,new metric: average l2 distance of the pixels better than ground truth,,,Yes
35382,"\""\""\"" || This module contains functionality for determining bet sizes for investments based on machine learning predictions. || These implementations are based on bet sizing approaches described in Chapter 10. || \""\""\""",,,Yes
35384,Adding other LaTeX engine to fix build,,Yes,Yes
35386,"\""\""\"" || This class takes in a Graph object and creates interactive visualisations using Plotly's Dash. || The DualDashGraph class contains private functions used to generate the frontend components needed to create the UI. ||  || Running run_server() will produce the warning \""Warning: This is a development server. Do not use app.run_server || in production; use a production WSGI server like gunicorn instead.\"". || However; this is okay and the Dash server will run without a problem. || \""\""\""",,,Yes
35390,TODO type check arguments of input and output,,No,Yes
35391,TODO validate configuration and set defaults,,Yes,Yes
35393,WTF?,,,Yes
35396,save_max; min needed?,,,Yes
35397,TODO don't distort,,Yes,Yes
35401,TODO get image size!,,Yes,Yes
35402,TODO better resize,,No,Yes
35403,TODO make this work for @custom-AI,,Yes,Yes
35405,Plotting a ROC curve needs the model to follow the convention,,Yes,Yes
35406,TODO hide deprecation error when importing,,No,Yes
35410,TODO add plots for multi label,,,Yes
35412,TODO maybe even for all commands?,,,Yes
35413,Free form commands deal with this manually,,Yes,Yes
35414,TODO show --name only when called via the command line,,Yes,Yes
35416,REVIEW code this properly,,Yes,Yes
35418,FIXME: need to render screen,,Yes,Yes
35420,TODO,,,Yes
35421,TODO: May want to move this to seed function?,,No,Yes
35426,TODO: return the index of the action to perform,,,Yes
35427,TODO: sample a minibatch from expStore,,,Yes
35428,TODO: support for multiple subgoals,,No,Yes
35429,TODO: avoid placing objects in front of doors,,Yes,Yes
35430,FIXME,,Yes,Yes
35432,An ugly hack for my KFAC implementation.,,,Yes
35433,TODO: In order to make this code faster:,,No,Yes
35434,1) Implement _extract_patches as a single cuda kernel,,No,Yes
35436,TODO,,,Yes
35438,TODO: rotate; slice; render,,Yes,Yes
35439,TODO: encode; decode,,Yes,Yes
35440,FIXME,,Yes,Yes
35441,TODO: randomize agent position,,Yes,Yes
35445,TODO,,,Yes
35446,TODO: when we generate a mismatch; we don't,,Yes,Yes
35447,"TODO: use overloaded \""in\"" operator on grid",,No,Yes
35452,TODO: handle positions,,,Yes
35456,TODO: more commenting,,Yes,Yes
35457,TODO: if seed is -1; pick random?,,Yes,Yes
35458,TODO: if seed is -1; pick random?,,,Yes
35460,TODO: make sure the two rooms are directly connected,,No,Yes
35462,TODO: eventually; gen_surface should just use,,Yes,Yes
35463,"\""PickupAbove\"": [TODO];",,,Yes
35465,unused,,No,Yes
35466,TODO add support for recurrent policy,,No,Yes
35468,best mean return to keep track of performance on validation set,,,Yes
35469,best mean return to keep track of performance on validation set,,Yes,Yes
35470,best mean return to keep track of performance on validation set,,,Yes
35471,best mean return to keep track of performance on validation set,,Yes,Yes
35474,TODO: strict mode; picked up the wrong object,,,Yes
35477,FIXME: h4xx,,No,Yes
35478,TODO: handle unopened doors,,Yes,Yes
35481,TODO: Why fixed number? should be lower than number of demow BTW,,Yes,Yes
35483,TODO: use one logger defined outside of this; something like binary search. remove prints,,Yes,Yes
35484,TODO: define csv_writer,,,Yes
35492,"\""\""\"" || Train an agent using an intelligent expert ||  || scripts\/train_intelligent_expert.py --env BabyAI-GoToObj-v0 --demos GoToObj-bot-100k --validation-interval 5 ||  || Vanilla imitation learning: || GoToObj; 1000 demos for 100 percent success rate || GoToLocal; over 60K demos needed || \""\""\""",,Yes,Yes
35494,FIXME: sample only failing episodes here too?,,No,Yes
35502,FIXME: h4xx,,No,Yes
35504,TODO: something doesn't seem right in this else block,,,Yes
35507,TODO: make this work with done action ?,,,Yes
35508,TODO: something doesn't seem right in this else block,,Yes,Yes
35512,well then the cell is behind us; instead of choosing left or right randomly; let's do something that might be useful,,,Yes
35515,Reason why whe're going next to something,,No,Yes
35516,TODO: find a better fix,,Yes,Yes
35519,TODO rin,,Yes,Yes
35525,TODO: handle multi-speaker,,,Yes
35528,TODO: fix pypi cython installation problem.,,No,Yes
35529,Read information from the excel in the second row; for columns 2 to 10,,Yes,Yes
35531,"\""\""\"" || TODO || - Add middle click || - Add hover || \""\""\""",,,Yes
35534,TODO: Perhaps prevent eval() here?,,No,Yes
35537,TODO: This does not work on Linux?,,No,Yes
35539,TODO: not very elegant way; but this is required for Linux\/MacOSX as pythoncom obviously is not supported on those platforms,,Yes,Yes
35541,TODO: check why this code is needed,,No,Yes
35545,TODO: perhaps eval() can be eliminated,,Yes,Yes
35546,TODO: perhaps eval() can be eliminated here,,Yes,Yes
35547,TODO: This should be put elsewhere,,,Yes
35548,TODO: remove hard-coded automagica path,,,Yes
35549,TODO: remove hard-coded sizes and make relative to parent?,,Yes,Yes
35550,TODO: Button3 is not always right click on every operating system,,Yes,Yes
35551,TODO: This does not work on Linux?,,No,Yes
35552,TODO: If flow is stopped by user before this is called back; exception occurs,,Yes,Yes
35553,TODO This needs to be made cleaner,,,Yes
35554,TODO the same should happen for OSX,,,Yes
35556,TODO This needs to be made cleaner,,,Yes
35557,TODO: this needs a rewrite,,No,Yes
35558,TODO: If flow is stopped by user before this is called back; exception occurs,,,Yes
35559,TODO: why exception?!,,Yes,Yes
35560,self.app.Visible = visible TODO: gives error for some PP versions,,Yes,Yes
35562,TODO: add comment; why wildcard import? (*),,,Yes
35563,Move mouse to coordinates,,Yes,Yes
35564,Move testfolder in testfolder_2,,Yes,Yes
35565,Move mouse to coordinates,,Yes,Yes
35566,Move testfolder in testfolder_2,,Yes,Yes
35567,TODO: Truncate individual bits so we are still unique but < 63chars,,No,Yes
35570,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
35572,TODO: Figure out if we should raise an exception instead?,,,Yes
35574,FIXME: If pod goes into an unrecoverable stage; such as ImagePullBackoff or,,Yes,Yes
35578,FIXME: 400 assumes it's the user's fault (?),,,Yes
35580,FIXME: message? debug?,,No,Yes
35581,TODO: handle errors,,,Yes
35582,TODO: validate the image argument?,,No,Yes
35583,FIXME: make this configurable,,Yes,Yes
35585,FIXME: Come up with a better name for it?,,,Yes
35587,TODO assertions,,Yes,Yes
35589,we still have to modify it; because apparently Go's YAML parser can not cope with,,No,Yes
35591,we could do this better,,Yes,Yes
35592,TODO: run a watch to keep this up to date in the background,,Yes,Yes
35593,TODO: put busy users in a queue rather than fail?,,Yes,Yes
35594,we could do this better,,,Yes
35599,this is needed because tornado converts 'foo%2Fbar\/ref' to 'foo\/bar\/ref',,,Yes
35600,this is needed because tornado converts 'foo%2Fbar\/ref' to 'foo\/bar\/ref',,No,Yes
35601,this is needed because tornado converts 'foo%2Fbar\/ref' to 'foo\/bar\/ref',,,Yes
35605,FIXME: remove when instantiating a kubernetes client,,,Yes
35606,if we got here; move on to the next image,,Yes,Yes
35607,TODO: watch\/cleanup build pod existence in a dedicated thread,,Yes,Yes
35608,TODO: watch\/cleanup build pod existence in a dedicated thread,,Yes,Yes
35609,this is needed because tornado converts 'foo%2Fbar\/ref' to 'foo\/bar\/ref',,,Yes
35613,maybe improved later,,,Yes
35617,should always move to the newly added bucket,,Yes,Yes
35618,FIXME: _headers is private; but there doesn't appear to be a public way,,No,Yes
35620,FIXME: we could stop here if nsv > upper_bound,,No,Yes
35624,compute pseudo-residuals if needed,,,Yes
35625,select best basis,,,Yes
35626,compute pseudo-residuals if needed,,No,Yes
35634,4 columns of 20 doubles,,,Yes
35636,"\""\""\"" || =============================== || Dependency on the nu parameter || =============================== ||  || nu: An upper bound on the fraction of training errors and a lower ||     bound of the fraction of support vectors. Should be in the ||     interval (0; 1]. ||  || - training time increases linearly with nu || - sparsity increases linearly when nu decreases || - conclusion: one has to increase training error to increase sparsity || - caveat: increasing nu doesn't necessarily improve test accuracy ||   (overfitting!) || \""\""\""",,,Yes
35637,Author: Peter Prettenhoer <peter.prettenhofer@gmail.com>,,,Yes
35638,4 columns of 20 doubles,,,Yes
35639,Compute more columns.,,No,Yes
35640,Fix navigation bar to top of page?,,Yes,Yes
35642,Sphinx hack: sphinx copies generated images to the build directory,,No,Yes
35644,it should probably not cause a crash).  Tested successfully,,Yes,Yes
35645,copy is needed to modify y.,,,Yes
35647,fix for missing xrange in Python3,,,Yes
35648,fix for missing xrange in Python3,,,Yes
35651,fix for missing xrange in Python3,,Yes,Yes
35653,fix for missing xrange in Python3,,Yes,Yes
35654,fix for missing xrange in Python3,,,Yes
35662,Only needed to check Python version,,Yes,Yes
35663,TODO: can we avoid transferring task data twice and serializing so much?,,No,Yes
35669,"\""\""\""Tools for diffing notebooks. ||  || All diff tools here currently assumes the notebooks have already been || converted to the same format version; currently v4 at time of writing. || Up- and down-conversion is handled by nbformat. ||  || FIXME: Define and document diff format. || \""\""\""",,,Yes
35670,FIXME: Handle new and deleted cells,,Yes,Yes
35673,FIXME: Handle execution_count (always change to None?),,No,Yes
35675,TODO: Do something about that? Or use include_equals in diff_lines call?,,,Yes
35677,TODO: Figure out when to add new cell,,Yes,Yes
35679,TODO: How to handle this?,,Yes,Yes
35681,FIXME: Store single cell patch in s[2]?,,Yes,Yes
35682,FIXME: Implement this function,,,Yes
35683,"\""\""\""Utilities currently unused; written during some experimentation. Delete if they stay unused.\""\""\""",,,Yes
35684,TODO: Make this easy configurable?,,Yes,Yes
35687,TODO: I think this should work...,,,Yes
35691,TODO: To allow LCS path reconstruction; must also keep copies of V for each D and return here,,Yes,Yes
35692,If only 0 or 1 edit operation is needed;,,Yes,Yes
35694,FIXME,,Yes,Yes
35696,TODO: Configuration framework?,,,Yes
35697,FIXME: Implement merge,,No,Yes
35701,TODO: These should probably be more customizable,,Yes,Yes
35705,TODO: Configuration framework?,,,Yes
35707,FIXME: Handle new and deleted cells,,Yes,Yes
35708,FIXME: Handle cell_type,,Yes,Yes
35710,FIXME: Handle execution_count (always change to None?),,No,Yes
35713,TODO: Improve and make a more reusable utility.,,No,Yes
35717,FIXME: The diff recursion here is inconsistent; passing only a,,Yes,Yes
35718,TODO: This will be much cleaner if the diffs are single-item only.,,Yes,Yes
35719,FIXME: Format?,,No,Yes
35720,(+1 for including) # FIXME: include +1 or make it part of conflict resolution?,,,Yes
35721,FIXME: +1 here?,,,Yes
35722,FIXME: Conflicts if remote_deletes overlap,,No,Yes
35724,FIXME: Create conflict instead of inserting both,,Yes,Yes
35725,"FIXME: Inserting both won't even work for \""!\"" or \"":\""; only for \""+\""",,,Yes
35726,FIXME: Handle deletion conflicts too here,,Yes,Yes
35728,FIXME: Implement notebook aware merge,,No,Yes
35731,TODO: We want this to work; requires improvements to nested list diffing.,,Yes,Yes
35732,assert m == [[1; 2; 3]]  # TODO: This is the behaviour we want,,,Yes
35735,FIXME: Implement notebook aware merge,,,Yes
35740,TODO: Use google-diff-patch-match library,,No,Yes
35743,TODO: Investigate performance and quality of this difflib ratio approach;,,,Yes
35746,TODO: Initially try difflib ratio,,Yes,Yes
35748,"print(\""FIXME: Missing in presentation:\"")",,Yes,Yes
35750,compareit = compare.get(key; operator.__eq__)  # TODO: Do like this?,,Yes,Yes
35751,FIXME,,Yes,Yes
35756,I don't think we want to accept arbitrary filenames,,,Yes
35758,XXX,,,Yes
35759,XXX,,Yes,Yes
35760,return bool(d)  # FIXME,,No,Yes
35761,FIXME: Make sure we use linebased diff of sources,,Yes,Yes
35765,TODO: Handle output diffing with plugins? I.e. image diff; svg diff; json diff; etc.,,Yes,Yes
35767,TODO: Split lines here?,,Yes,Yes
35768,TODO: Split lines here?,,Yes,Yes
35769,TODO: Split lines here? Must be consistent with the diff for patch_notebook to work correctly!?,,Yes,Yes
35770,TODO: Reuse these add_*_args functions across the apps,,,Yes
35773,TODO: Add diff strategy options that are reusable for the merge command here,,Yes,Yes
35774,TODO: Define sensible strategy variables and implement,,Yes,Yes
35776,; path=path; differs={})  # FIXME: Needed?,,,Yes
35777,FIXME: Temporary conversion; make differs input instead of subdiffs,,Yes,Yes
35779,FIXME: Do we need this string case; and if so do we need to pass on these additional arguments?,,,Yes
35780,FIXME: Temporary conversion; make differs input instead of subdiffs,,,Yes
35781,TODO: This is now equal to diff_cells; after some refactoring steps towards generalization,,Yes,Yes
35782,Strategies for handling conflicts  TODO: Implement these and refine further!,,,Yes
35783,FIXME: Step through nbformat docs and handle case by case,,Yes,Yes
35787,FIXME: Assuming single compare in diff_sequence; streamline with multilevel algorithm,,Yes,Yes
35788,Could also this a warning; but I think it shouldn't be done,,Yes,Yes
35789,TODO: handle \/dev\/null (Windows equivalent?) for new or deleted files,,Yes,Yes
35790,If multiple compares are provided to this path; delegate to multilevel algorithm,,Yes,Yes
35791,TODO: Move some of the less official utilities in here to another submodule,,Yes,Yes
35792,"_MOVE = \""move\""",,Yes,Yes
35793,Strategies for handling conflicts  TODO: Implement these and refine further!,,No,Yes
35795,TODO configuration - Remove this section or set to False after docs are stable,,Yes,Yes
35796,FIXME: Code is perhaps too accepting; it's hard to make conflicts!,,Yes,Yes
35798,XXX,,,Yes
35801,FIXME: use format_text_merge_display for each conflicting chunk,,,Yes
35803,"with better heuristics than we have today; i.e. we can never be quite certain what the \""right choice\"" is.",,No,Yes
35804,assert m == [[1; 2; 4; 3; 4]]  # TODO: Is this the behaviour we want; merge in inner list?,,Yes,Yes
35805,TODO: Rename to DiffBuilder,,,Yes
35806,TODO: Rename to *DiffBuilder in code elsewhere and remove these,,,Yes
35808,Conflict-free behaviour that probably isn't safe to do in general:,,,Yes
35809,behaviour that makes the most sense here could very well differ from,,Yes,Yes
35810,FIXME: Figure out the best behaviour and make it happen!,,,Yes
35811,FIXME: This doesn't seem to happen?,,Yes,Yes
35812,FIXME: This may not be the exact behaviour we want:,,No,Yes
35813,(if so; fix in generic merge and chunk collection),,,Yes
35816,FIXME: Correct?,,,Yes
35820,TODO: Tool server starts on random port (in optionally specified port range),,,Yes
35821,TODO: Tool server is passed a (mandatory?) single-use access token; which is,,Yes,Yes
35826,FIXME: ignore for now,,No,Yes
35829,TODO: support git-config-specified conflict markers inside sources,,,Yes
35831,FIXME: Find a good way to handle strategies for both parent (outputs) and child (execution_count).,,,Yes
35833,new behaviour as needed!,,Yes,Yes
35836,- FIXME: Handle cell source if one cell is patched and one cell is deleted!,,Yes,Yes
35838,We can't really automate a generic merge test; at least passing through code here...,,,Yes
35841,FIXME: do the above two cases fully cover what the below one did?,,,Yes
35842,TODO: Split these into multiple decisions?,,,Yes
35843,FIXME: What has happened here? This is hard to follow; enumerate cases!,,,Yes
35847,"FIXME: Not ideal \""intuitive\"" resolution?",,Yes,Yes
35848,FIXME: Use concept of longest common subsequence; instead of fifo,,,Yes
35851,FIXME: We currently write this way as git needs \ ||  line endings;,,Yes,Yes
35853,TODO: Tool server is passed a (mandatory?) single-use access token; which is,,,Yes
35854,FIXME: ignore for now,,No,Yes
35858,TODO: Define sensible strategy variables and implement,,Yes,Yes
35859,FIXME: This uses notebook predicates and differs; which,,,Yes
35860,doesn't really belong in a generic merge algorithm...,,Yes,Yes
35861,TODO: Remove when merged notebook generation is verified to work as intended:,,,Yes
35864,TODO: This approach will show that hashes differ,,No,Yes
35866,TODO: Make this configurable,,Yes,Yes
35867,TODO: Cut strings short?,,,Yes
35870,TODO: Use this for line wrapping some places?,,No,Yes
35871,TODO: Pass path_trail here to allow formatting as listname[k]:?,,,Yes
35872,TODO: quote?,,Yes,Yes
35874,TODO: Options to show only important things: --compact; --source-only,,No,Yes
35876,TODO: Quote string if the other is a number?,,Yes,Yes
35877,args.fixme,,Yes,Yes
35882,FIXME: Move to utils,,Yes,Yes
35883,FIXME: Use diff resolution and chunking to mark only parts that conflict,,,Yes
35885,FIXME: Move to utils,,Yes,Yes
35892,FIXME: Use diff resolution and chunking to mark only parts that conflict,,Yes,Yes
35893,TODO: Compare contents of mime bundles xd; yd approximately,,,Yes
35894,FIXME: Allow some diff; e.g. on repr style text in text\/plain,,,Yes
35896,TODO: Could do some size checking?,,Yes,Yes
35898,FIXME: Allow some diff; e.g. on repr style text in text\/plain,,Yes,Yes
35900,TODO: Maybe cleaner to make the split between strict\/approximate,,,Yes
35902,TODO: Add configuration framework,,No,Yes
35904,TODO: Review whether this is wanted.,,Yes,Yes
35906,assert expected == merged  # FIXME: Enable when expected values are filled in,,Yes,Yes
35907,FIXME: Merge what can be merged here,,No,Yes
35909,XXX FIXME: pass parent strategy? push it on strategy stack?,,,Yes
35911,TODO: Should we mark addition before patch\/remove conflicted as well?,,Yes,Yes
35913,FIXME XXX,,,Yes
35914,XXX Check for ParentDeleted in _merge_list\/dict\/string!,,Yes,Yes
35915,XXX FIXME: Support two-sided removal in _merge_concurrent_inserts; see autoresolve?,,Yes,Yes
35916,FIXME,,,Yes
35917,FIXME,,Yes,Yes
35918,TODO: missing path \/metadata in diffs,,Yes,Yes
35919,FIXME XXX: Make sure resolutions are marked as conflicts,,,Yes
35920,FIXME: Implement,,Yes,Yes
35921,FIXME: Move to _merge_strings,,,Yes
35922,FIXME XXX: _split_addrange had a very specific return condition; what does it do? Probably need to match behaviour: len(subdec) > 1 or len(subdec) == 1 and subdec[0],,Yes,Yes
35926,FIXME XXX: Do we need to adjust the conflict diffs here?,,Yes,Yes
35927,FIXME: Create dummy with .transients or require strategies,,Yes,Yes
35930,FIXME: Fix record-conflict strategy then enable this line,,Yes,Yes
35931,FIXME: Move to _merge_strings,,Yes,Yes
35934,TODO: Remove execution_count from patches here?,,,Yes
35935,FIXME XXX rewrite and use for resolve_strategy_inline_attachments,,No,Yes
35936,FIXME XXX: Implement by rewriting functions above copied from autoresolve.py; search for resolve_strategy_inline_attachments above in this file,,,Yes
35937,FIXME XXX: Implement by rewriting functions above copied from autoresolve.py; search for resolve_strategy_inline_outputs above in this file,,,Yes
35938,FIXME XXX: Implement by rewriting functions above copied from autoresolve.py; search for resolve_strategy_inline_source above in this file,,,Yes
35939,TODO: Collect local diffs and remote diffs from unresolved_conflicts,,,Yes
35940,FIXME XXX: Call this here or after trying to merge,,Yes,Yes
35941,FIXME XXX: Main todos left:,,,Yes
35942,- implement resolve_* by rewriting other handlers (search for resolve_ and follow FIXME instructions; see resolve_strategy_record_conflicts for example of expected behaviour),,,Yes
35944,FIXME XXX: Implement by rewriting functions above copied from autoresolve.py; search for resolve_strategy_inline_source above in this file,,,Yes
35945,FIXME XXX: Consider if recursion is still useful to have,,Yes,Yes
35947,FIXME XXX: Implement by rewriting functions above copied from autoresolve.py; search for resolve_strategy_inline_source above in this file,,,Yes
35949,TODO: Dropping outputs changes here for now; do we want that behaviour?,,No,Yes
35951,FIXME XXX: How is this received by the caller? Chunk the non-empty diff alone?,,Yes,Yes
35954,TODO: Should this decision record conflicted diffs or all of local_diff; remote_diff?,,Yes,Yes
35955,FIXME: Handle regular resolution and conflicts for mergetool and other strategies (other text fields!),,,Yes
35956,Make sure all but the last line ends with newline,,No,Yes
35959,FIXME XXX: How is this received by the caller? Chunk the non-empty diff alone?,,Yes,Yes
35961,want parent to _not_ be deleted!  FIXME XXX not sure how to communicate this,,,Yes
35962,Note: git merge-file also takes argument -L to change label if needed,,,Yes
35964,TODO: Add this to strategies object instead,,,Yes
35965,# TODO: This means dropping metadata changes if parent cell deleted;,,Yes,Yes
35966,# TODO: Recurse to apply strategies to child nodes?,,,Yes
35967,# FIXME XXX: How is this received by the caller? Chunk the non-empty diff alone?,,Yes,Yes
35969,# TODO: This means dropping metadata changes if parent cell deleted;,,,Yes
35970,# TODO: Recurse to apply strategies to child nodes?,,Yes,Yes
35972,FIXME: This function doesn't work out so well with new conflict handling;,,,Yes
35973,perhaps change to this:,,,Yes
35975,FIXME: Right strategy?,,Yes,Yes
35976,TODO: Add option to try git merge-file or diff3 even when using mergetool,,No,Yes
35977,FIXME: Handle regular resolution and conflicts for,,No,Yes
35978,FIXME XXX This is now handled in _merge_lists;,,,Yes
35980,decisions = MergeDecisionBuilder()  # TODO: Define our own decisions collection?,,Yes,Yes
35981,FIXME: Add removals to conflicts in subdecisions?,,,Yes
35983,FIXME: Handle regular resolution and conflicts for,,No,Yes
35985,FIXME,,Yes,Yes
35986,"nbdime.log.error(\""FIXME: Update attachment conflict inlining.\"")",,No,Yes
35987,FIXME,,Yes,Yes
35990,subdecisions.has_conflicted()  # FIXME: which way?,,,Yes
35992,"nbdime.log.error(\""union strategy not implemented for source\"")  # FIXME",,,Yes
35993,TODO: Do we need global debug flags to turn,,Yes,Yes
35995,FIXME: This function doesn't work out so well with new conflict handling;,,,Yes
35996,ordering; perhaps we can add relative local\/remote indices to the decisions?,,Yes,Yes
35997,perhaps change to this:,,Yes,Yes
35999,There were strange issues with passing blob data_streams around;,,,Yes
36000,TODO: Better name; validate_diff? as_diff?,,Yes,Yes
36001,TODO: Filter base\/local: If directories; find all modified notebooks,,,Yes
36002,FIXME: Review this code.,,,Yes
36003,but flag a conflict (TODO: Or don't flag conflict?),,No,Yes
36004,TODO: Record local and remote versions of full metadata; easier to manually select one?,,,Yes
36006,TODO: Pass in language information so that an appropriate file,,Yes,Yes
36007,workaround for tornado on Windows:,,,Yes
36008,workaround for tornado on Windows:,,No,Yes
36009,FIXME: Remove asserts when sure there are no missed corner cases:,,Yes,Yes
36011,Follow stdlib\/git convention of matching all sub files\/directories:,,No,Yes
36012,added. Workaround for GitPython issue #749.,,,Yes
36013,TODO: Add deprecation warning (for git\/checkpoint only?),,,Yes
36014,This excercises current behavior; but should ideally (?) be different,,No,Yes
36015,Todo: user should be able to bring her own color palette.,,Yes,Yes
36021,#NAME?,,Yes,Yes
36022,- implement iou on a per-class basis (not mean'ed),,,Yes
36025,TODO: The calculation below does not work for multi-class.,,Yes,Yes
36027,Todo: at the moment we load all OSM shapes. It would be more efficient to tile,,Yes,Yes
36032,Todo: make input channels configurable; not hard-coded to three channels for RGB,,Yes,Yes
36035,TODO: do some evaluation.,,No,Yes
36036,10x what's needed.,,,Yes
36038,TODO: consider including stats and ranking based on quantiles;,,,Yes
36039,Pass 1: needed_images lists all images that are topk for some unit.,,No,Yes
36040,Move the most common conditions to the GPU.,,,Yes
36043,Ensure dimensions are unsqueezed as needed.,,,Yes
36045,TODO: remove the clone() if it becomes faster.,,Yes,Yes
36046,Move data down if it would leave enough empty space there,,,Yes
36048,Generate image files for just the needed images.,,,Yes
36050,Move it to CUDA if wanted.,,,Yes
36051,Instrument the model if needed,,Yes,Yes
36053,Error and ctrl-C handling: kill worker processes if the main process ends.,,,Yes
36055,TODO: replace usage of the old API calls with the safer version above.,,Yes,Yes
36060,Todo: change super_user to project_admin.,,,Yes
36061,Todo: change super_user to project_admin.,,No,Yes
36070,work-around for dj-database-url: patch ssl for mysql,,No,Yes
36071,Todo: change super_user to project_admin.,,No,Yes
36072,work-around for dj-database-url: patch ssl for mysql,,No,Yes
36075,TODO: Make user_label count chart,,,Yes
36076,Todo: I want to use bulk delete.,,No,Yes
36078,this part is ugly; because pytorch has not supported negative index,,Yes,Yes
36079,TODO enable CUDA when appropriate,,Yes,Yes
36080,TODO remove this hack when tensorflow fixes their build,,Yes,Yes
36082,TODO interesting SKLearn fitting stats,,Yes,Yes
36083,TODO interesting XGBoost fitting stats,,Yes,Yes
36084,TODO Should we unify serializers to avoid this check?,,,Yes
36085,HACK to set estimator model; and model serializer,,Yes,Yes
36087,not running in a terminal; maybe a jupiter notebook,,No,Yes
36088,HACK to set estimator model; and model serializer,,Yes,Yes
36089,TODO parrallelize with multiple processes?,,,Yes
36090,WORKAROUND HACK,,,Yes
36091,Note: This can be rewritten in a more efficient way,,No,Yes
36092,: Why would you do this\u203D Your attempt has been logged; and will be reported to the authorities.,,No,Yes
36093,TODO: Optimize; but not bottleneck obv,,Yes,Yes
36094,Parameter value corresponding to the best function value.,,,Yes
36095,# TODO: Optimize; but not bottleneck obv,,Yes,Yes
36096,TODO: Optimize; but not bottleneck obv,,Yes,Yes
36097,Hack to allow integer parameters; since the parameters,,,Yes
36098,XXX should there be an early stopping criterion?,,,Yes
36100,XXX the model predictions are flat (no gradient),,Yes,Yes
36101,XXX so right now BFGS can't do anything useful,,,Yes
36104,XXX how to detect [(1;2); (3.; 5.)] and convert it to,,,Yes
36111,XXX use linspace(*bounds; n_points) after python2 support ends,,No,Yes
36112,columns,,,Yes
36113,XXX use linspace(*bounds; n_points) after python2 support ends,,No,Yes
36114,XXX: We supply points at the edge of the search,,Yes,Yes
36115,This unfortunate kludge is the only reasonable way I could think of,,,Yes
36116,Try to do a real import first. I think it's better to prefer,,Yes,Yes
36118,Hence this hack,,No,Yes
36120,XXX: Cache np.dot(K_trans; K_inv) from above,,No,Yes
36121,Precompute arrays needed at prediction,,,Yes
36123,XXX why the need for [0] at the end?,,Yes,Yes
36124,XXX can we combine these two loops into one?,,Yes,Yes
36125,XXX scale + 1. might not actually be a float after scale if,,,Yes
36126,XXX scale is very large.,,Yes,Yes
36128,which could mess up the optimization procedure. Suggestions are welcome.,,Yes,Yes
36129,the function below is necessary as a workaround for the pool.map method requiring map function to take only a single argument,,,Yes
36130,"\""\""\"" || This code implements benchmark for the black box optimization algorithms; || applied to a task of optimizing parameters of ML algorithms for the task || of supervised learning. ||  || The code implements benchmark on 4 datasets where parameters for 6 classes || of supervised models are tuned to optimize performance on datasets. Supervised || learning models implementations are taken from sklearn. ||  || Regression learning task is solved on 2 datasets; and classification on the || rest of datasets. 3 model classes are regression models; and rest are || classification models. || \""\""\""",,,Yes
36131,which could mess up the optimization procedure. Suggestions are welcome.,,Yes,Yes
36132,the function below is necessary as a workaround for the pool.map method requiring map function to take only a single argument,,,Yes
36134,Fix deprecation warning #462,,,Yes
36137,when you for example want to fix what model is used in Pipeline.,,Yes,Yes
36138,TODO: why no check here?,,No,Yes
36141,TODO: writes a number above the plot that I don't know how to turn off.,,No,Yes
36143,columns,,No,Yes
36144,maybe improved later,,,Yes
36145,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
36147,unparseable. Maybe git-describe is misbehaving?,,,Yes
36150,"\""\""\"" || ========================================== || Scikit-learn hyperparameter search wrapper || ========================================== ||  || Iaroslav Shcherbatyi; Tim Head and Gilles Louppe. June 2017. ||  || Introduction || ============ ||  || This example assumes basic familiarity with `scikit-learn <http:\/\/scikit-learn.org\/stable\/index.html>`. ||  || Search for parameters of machine learning models that result in best cross-validation performance is necessary in almost all practical cases to get a model with best generalization estimate. A standard approach in scikit-learn is using `GridSearchCV` class; which takes a set of values for every parameter to try; and simply enumerates all combinations of parameter values. The complexity of such search grows exponentially with the addition of new parameters. A more scalable approach is using `RandomizedSearchCV`; which however does not take advantage of the structure of a search space. ||  || Scikit-optimize provides a drop-in replacement for `GridSearchCV`; which utilizes Bayesian Optimization where a predictive model referred to as \""surrogate\"" is used to model the search space and utilized to arrive at good parameter values combination as soon as possible. ||  || Note: for a manual hyperparameter optimization example; see \""Hyperparameter Optimization\"" notebook. ||  || \""\""\""",,,Yes
36152,They take care of many of the more mundane things needed to make good plots of all combinations of the dimensions.,,Yes,Yes
36153,TODO: Compare plots to known good results?,,Yes,Yes
36154,Python 2 compat: just to be able to declare that Python >=3.5 is needed.,,,Yes
36155,XXX use linspace(*bounds; n_points) after python2 support ends,,No,Yes
36156,Multiply columns of V by appropriate power of 2.,,,Yes
36158,shift down to make a better plot,,No,Yes
36159,TODO: Compare plots to known good results?,,,Yes
36162,TODO: writes a number above the plot that I don't know how to turn off.,,No,Yes
36164,So we hack it by creating a list of integers and setting the,,Yes,Yes
36166,XXX use linspace(*bounds; n_points) after python2 support ends,,No,Yes
36167,columns,,No,Yes
36170,TODO: There is a problem here if yi is very large; then matplotlib,,No,Yes
36171,TODO: writes a number above the plot that I don't know how to turn off.,,No,Yes
36173,So we hack it by creating a list of integers and setting the,,,Yes
36174,TODO replace with check_list_types(dimensions; (Integer; Real)) in PR #597,,Yes,Yes
36175,TODO: There is a problem here if yi is very large; then matplotlib,,No,Yes
36177,TODO replace with check_list_types(dimensions; (Integer; Real)) in PR #597,,Yes,Yes
36179,So we hack it by creating a list of integers and setting the,,,Yes
36180,TODO : we should probably update doc embedding here (not used currently),,No,Yes
36184,XXX: this is just quick and dirty for now. When adding a new format;,,Yes,Yes
36187,FIXME: workaround for old splitlines(),,No,Yes
36189,FIXME: remove gen.Return when we drop py2 support,,,Yes
36190,we're misconfigured (better safe than sorry!),,No,Yes
36191,TODO: 400 indicates user is unknown? what about a faked cookie?,,Yes,Yes
36192,TODO: 400 indicates user is unknown? what about a faked cookie?,,Yes,Yes
36195,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
36196,maybe improved later,,,Yes
36197,unparseable. Maybe git-describe is misbehaving?,,,Yes
36198,E.g. so subclasses can implement templates with custom logic,,,Yes
36199,This shouldn't be configurable,,Yes,Yes
36201,"\""\""\""Misc helper functions needed by autowrap.py.\""\""\""",,No,Yes
36202,Variables corresponding to structs needed by Mujoco's rendering functions.,,,Yes
36203,"\""\""\""Mujoco functions to support named indexing. ||  || The Mujoco name structure works as follows: ||  || In mjxmacro.h; each \""X\"" entry denotes a type (a); a field name (b) and a list || of dimension size metadata (c) which may contain both numbers and names; for || example ||  ||    X(int;    name_bodyadr; nbody; 1) \/\/ or ||    X(mjtNum; body_pos;     nbody; 3) ||      a       b             c -----> ||  || The second declaration states that the field `body_pos` has type `mjtNum` and || dimension sizes `(nbody; 3)`; i.e. the first axis is indexed by body number. || These and other named dimensions are sized based on the loaded model. This || information is parsed and stored in `mjbindings.sizes`. ||  || In mjmodel.h; the struct mjModel contains an array of element name addresses || for each size name. ||  ||    int* name_bodyadr; \/\/ body name pointers (nbody x 1) ||  || By iterating over each of these element name address arrays; we first obtain a || mapping from size names to a list of element names. ||  ||     {'nbody': ['cart'; 'pole']; 'njnt': ['free'; 'ball'; 'hinge']; ...} ||  || In addition to the element names that are derived from the mjModel struct at || runtime; we also assign hard-coded names to certain dimensions where there is an || established naming convention (e.g. 'x'; 'y'; 'z' for dimensions that correspond || to Cartesian positions). ||  || For some dimensions; a single element name maps to multiple indices within the || underlying field. For example; a single joint name corresponds to a variable || number of indices within `qpos` that depends on the number of degrees of freedom || associated with that joint type. These are referred to as \""ragged\"" dimensions. ||  || In such cases we determine the size of each named element by examining the || address arrays (e.g. `jnt_qposadr`); and construct a mapping from size name to || element sizes: ||  ||     {'nq': [7; 3; 1]; 'nv': [6; 3; 1]; ...} ||  || Given these two dictionaries; we then create an `Axis` instance for each size || name. These objects have a `convert_key_item` method that handles the conversion || from indexing expressions containing element names to valid numpy indices. || Different implementations of `Axis` are used to handle \""ragged\"" and \""non-ragged\"" || dimensions. ||  ||     {'nbody': RegularNamedAxis(names=['cart'; 'pole']); ||      'nq': RaggedNamedAxis(names=['free'; 'ball'; 'hinge']; sizes=[7; 4; 1])} ||  || We construct this dictionary once using `make_axis_indexers`. ||  || Finally; for each field we construct a `FieldIndexer` class. A `FieldIndexer` || instance encapsulates a field together with a list of `Axis` instances (one per || dimension); and implements the named indexing logic by calling their respective || `convert_key_item` methods. ||  || Summary of terminology: ||  || * _size name_ or _size_ A dimension size name; e.g. `nbody` or `ngeom`. || * _element name_ or _name_ A named element in a Mujoco model; e.g. 'cart' or ||   'pole'. || * _element index_ or _index_ The index of an element name; for a specific size ||   name. || \""\""\""",,,Yes
36204,Names of columns.,,,Yes
36207,Custom fixed-size columns.,,Yes,Yes
36208,Only one finalizer needed per address.,,,Yes
36210,This is needed so that the __del__ methods of MjModel and MjData can still,,,Yes
36211,This is a workaround that allows imports from `dm_control.render` to succeed,,,Yes
36213,Move plane down.,,Yes,Yes
36215,Remove unused props,,Yes,Yes
36217,Unused.,,,Yes
36220,Needed for `named_parameters` to work.,,Yes,Yes
36221,Unused.,,Yes,Yes
36223,An extension is needed because MuJoCo's compiler looks at this when,,,Yes
36224,Unused,,No,Yes
36226,Unused.,,Yes,Yes
36229,unused,,No,Yes
36230,Unused.,,Yes,Yes
36231,If it is only an index into the columns of the backing array then we,,Yes,Yes
36233,unless these quantities are needed by the simulation. We need these in,,,Yes
36235,Move reward term.,,Yes,Yes
36237,Move x to start of the next platform.,,No,Yes
36238,implemented in a consistent way.,,No,Yes
36242,Unused internal import: resources.,,Yes,Yes
36243,Move walker up out of the way before raycasting.,,No,Yes
36244,Move walker back down.,,Yes,Yes
36246,unless these quantities are needed by the simulation. We need these in,,No,Yes
36247,Horizontal speed above which Move reward is 1.,,,Yes
36249,"\""\""\""A task where the goal is to move the hand close to a target prop or site.\""\""\""",,Yes,Yes
36250,Invisible sensor sites live in group 4 by convention.,,No,Yes
36252,unused by after_step.,,No,Yes
36253,physics unused by should_terminate_episode.,,Yes,Yes
36254,unused by get_discount.,,Yes,Yes
36255,physics unused by get_veloc_control.,,Yes,Yes
36257,physics unused by get_joints_vel_control.,,,Yes
36258,physics unused by get_clip_id.,,,Yes
36260,fix the noise used in sampling,,,Yes
36261,Load VGG model if needed,,Yes,Yes
36263,Load VGG model if needed,,Yes,Yes
36264,decode again (if needed),,No,Yes
36265,add assay_id and target columns,,,Yes
36267,This multiplication kludge guarantees unique smiles.,,,Yes
36268,TODO(rbharath): This is a total kludge. Clean up later.,,,Yes
36270,a good way to pass down configuration parameters into the invocations,,Yes,Yes
36271,better to use hdf5 datasets like in MSMBuilder,,,Yes
36272,example). Fix these bugs in our processing pipeline.,,,Yes
36273,"''' || def load_pdbbind_molecules(paths; dir_name=\""fingerprints\""): ||   \""\""\""Load dataset fingerprints and return fingerprints. ||   \""\""\"" ||   # TODO(rbharath): This is a total kludge. Clean up later. ||   dir_name = \""targets\"" ||   molecules = {} ||   for dataset_path in paths: ||     pickle_dir = os.path.join(dataset_path; dir_name) ||     pickle_files = os.listdir(pickle_dir) ||     if len(pickle_files) == 0: ||       raise ValueError(\""No Pickle Files found to load molecules\"") ||     for pickle_file in pickle_files: ||       with gzip.open(os.path.join(pickle_dir; pickle_file); \""rb\"") as f: ||         contents = pickle.load(f) ||         smiles; fingerprints; scaffolds; mol_ids = ( ||             contents[\""smiles\""]; contents[\""features\""]; ||             None; None) ||         for mol in range(len(contents[\""smiles\""])): ||           molecules[smiles[mol]] = {\""fingerprint\"": fingerprints[mol]; ||                                     \""scaffold\"": None; ||                                     \""mol_id\"": None} ||   return molecules  || '''",,,Yes
36274,TODO(rbharath): The script expects that all columns in xlsx\/csv files,,,Yes
36280,regression models! Find a more general solution (perhaps by using,,Yes,Yes
36282,regression models! Find a more general solution (perhaps by using,,Yes,Yes
36285,TODO(rbharath): Explicitly passing around out_*_pkl is an encapsulation,,No,Yes
36286,TODO(rbharath\/enf): THIS IS SUPER BROKEN and probably needs complete rewrite.,,Yes,Yes
36287,it breaks. Need to fix.,,,Yes
36289,The standard columns for featurized data.,,,Yes
36293,moved into Samples to avoid bugs (ran into issues when chaning,,No,Yes
36296,The standard columns for featurized data.,,No,Yes
36297,TODO(rbharath): This is a hack. clean up.,,Yes,Yes
36298,TODO(rbharath): This feels like a total hack. Is there a structured way,,Yes,Yes
36300,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
36302,distance of 7.5 A is good cutoff. This seems really big to me;,,Yes,Yes
36303,This is perhaps controversial. I noticed that often a pi-cation,,,Yes
36304,This could be directional somehow; like a hydrogen,,,Yes
36305,this be made more efficient?,,No,Yes
36306,it might be better to just report the angle in the feature,,,Yes
36308,maybe you only have two hydrogens added; but they're sp3 hybridized.,,Yes,Yes
36309,TODO(rbharath): Ugly code right here...,,,Yes
36310,so require them to be on the same chain. needed to,,,Yes
36314,Hack to allow for easy unpickling:,,Yes,Yes
36315,TODO(rbharath): Total hack. Fix before merge!!!,,,Yes
36316,TODO(rbharath): This feels like a total hack. Is there a structured way,,,Yes
36318,TODO(rbharath): These lines are puzzling. Better way to avoid storage,,Yes,Yes
36319,TODO(rbharath): Total hack. Fix before merge!!!,,,Yes
36320,TODO(rbharath): This feels like a total hack. Is there a structured way,,Yes,Yes
36321,TODO(rbharath): Total hack. Fix before merge!!!,,Yes,Yes
36322,TODO(rbharath): This is a hack. More structured approach?,,,Yes
36325,get rid of config? Protos are much better for,,Yes,Yes
36327,TODO(rbharath): Total hack. Fix before merge!!!,,,Yes
36331,TODO(rbharath): This explicit manipulation of scopes is ugly. Is there a,,Yes,Yes
36332,What's the right fix here?,,,Yes
36333,TODO(rbharath): This is a hack. clean up.,,Yes,Yes
36334,TODO(rbharath): Total hack. Fix before merge!!!,,Yes,Yes
36335,TODO(rbharath): There's a better way to do this with numpy indexing,,,Yes
36338,Apply fit_transformers if needed,,Yes,Yes
36342,awkward. Is there a better way to handle this work.,,Yes,Yes
36343,HACK(JG): This is a hack to perform 10-fold averaging of y_pred on,,,Yes
36344,awkward. Is there a better way to handle this work.,,Yes,Yes
36345,TODO (Bowen): make this function less memory intensive,,,Yes
36346,TODO(rbharath): Is there a bug in the padding code? Why does it fail to,,Yes,Yes
36347,pretty_columns = (,,Yes,Yes
36351,Useful to avoid edge cases; but perhaps there's a better solution,,,Yes
36352,##### generator as given. Solution seems to be to to manually pull out N elements,,,Yes
36353,##### should do a better job here.,,No,Yes
36354,"\""\""\""Copy specified columns to new df with standard column names.",,Yes,Yes
36356,check to see if any columns are all zero,,Yes,Yes
36359,The convention used is that the first task is the metric.,,,Yes
36361,implementation details of fcnet. Better way to expose this information?,,,Yes
36364,Would be  nice to be able to do in memory dataset construction...,,Yes,Yes
36366,Note starts as 1\/k since fold starts at 0. Ends at 1 since fold goes up,,No,Yes
36369,TODO (rbharath): Find a more elegant solution to saving the data?,,Yes,Yes
36370,TODO (rbharath): Find a more elegant solution to saving the data?,,Yes,Yes
36371,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
36373,TODO (flee2): for transform_y; figure out weights; untransform,,Yes,Yes
36374,calculate which index this degree block ends up in the final,,,Yes
36375,Taken from Keras code [citation needed],,Yes,Yes
36378,TODO(rbharath): This really shouldn't be built up-front. Need to do this,,Yes,Yes
36380,untransformed E is needed for undo_grad_transform,,No,Yes
36384,Hack to allow for easy unpickling:,,,Yes
36385,TODO (flee2): for transform_y; figure out weights; untransform,,Yes,Yes
36386,TODO (rbharath): Find a more elegant solution to saving the data?,,Yes,Yes
36388,Hack to allow for easy unpickling:,,Yes,Yes
36389,TODO (flee2): for transform_y; figure out weights; untransform,,Yes,Yes
36391,fix the size to be [?;1],,,Yes
36393,Report every N batches. Useful for training on very large datasets;,,No,Yes
36394,TODO: Put this in once progressive multitask is supported. Or remove this,,Yes,Yes
36395,TODO (hraut->rhbarath): num_datapoints should be a vector; with ith element being,,,Yes
36397,TODO (hraut->rhbarath): num_datapoints should be a vector; with ith element being,,Yes,Yes
36399,"\""\""\"" || Processing of AACT data || @author Caleb Geniesse || \""\""\""",,,Yes
36400,columns = ['smiles'; 'CLINICAL_TRIAL_OUTCOME'; 'FDA_APPROVED_TOX'],,Yes,Yes
36401,These columns may be missing is the dataset is unlabelled.,,Yes,Yes
36402,Higher is Better,,Yes,Yes
36404,TODO (Ytz): for regression tasks we'd stop after only one cluster.,,,Yes
36407,TODO (Ytz): for regression tasks we'd stop after only one cluster.,,Yes,Yes
36408,TODO (ytz) this is a bandage solution to reorder the atoms so,,No,Yes
36418,after the '[' token which appears to be a bug. Workaround by,,Yes,Yes
36422,TODO (ytz): really; we want at least one active and inactive in both scenarios.,,Yes,Yes
36423,TODO (Ytz): for regression tasks we'd stop after only one cluster.,,Yes,Yes
36425,TODO: cache this,,No,Yes
36430,TODO (LESWING) batch norm,,,Yes
36432,TODO (LESWING) batch norm,,No,Yes
36433,TODO (LESWING) batch norm,,,Yes
36434,meaningfully; so not going to support that functionality for now.,,,Yes
36435,The player can bet on any number from 0 to 36; or walk away (which ends the,,,Yes
36437,Move X,,,Yes
36439,This probably means the variable hasn't been created yet; so try again,,Yes,Yes
36440,TODO: cache this,,No,Yes
36442,The player can bet on any number from 0 to 36; or walk away (which ends the,,,Yes
36444,After one step of optimization it should do much better,,,Yes
36445,TODO: Might want to generalize by having an explicit output argument.,,,Yes
36448,Taken from Keras code [citation needed],,Yes,Yes
36456,Consider all possible tokens we could add to this candidate sequence.,,Yes,Yes
36459,(TODO YTZ:) faster; less memory intensive way,,,Yes
36461,(TODO YTZ:) faster; less memory intensive way,,,Yes
36462,d = tf.nn.relu(d) # fix numerical instabilities about diagonal,,,Yes
36463,(ytz): this is really dirty but needed for restoring models,,,Yes
36465,(TODO YTZ:) faster; less memory intensive way,,,Yes
36466,d = tf.nn.relu(d) # fix numerical instabilities about diagonal,,Yes,Yes
36471,(TODO YTZ:) faster; less memory intensive way,,,Yes
36472,d = tf.nn.relu(d) # fix numerical instabilities about diagonal,,Yes,Yes
36476,TODO upperbound?,,,Yes
36477,Optimized model is better; return hyperparameters,,,Yes
36480,TODO upperbound?,,,Yes
36483,TODO: mol should be always sanitized when charges are calculated,,No,Yes
36484,TODO: Integrate command-line argument parser,,No,Yes
36485,TODO: Integrate command-line argument parser,,,Yes
36486,move toward it).,,,Yes
36489,TODO (hraut->rhbarath): num_datapoints should be a vector; with ith element being,,Yes,Yes
36491,For training if exact values known (unused),,No,Yes
36493,TODO What should shape[1] be?  It's not documented.,,Yes,Yes
36494,TODO What should the output shape be?  It's not documented; and there,,,Yes
36495,TODO Once we drop Python 2 support; turn outputs into a proper keyword arg,,Yes,Yes
36496,instead of using the **kwargs hack.,,,Yes
36499,This is kludgy way to add y to dataset. Can be done better?,,,Yes
36505,TODO: Check if anything needs to be added,,,Yes
36506,TODO: Add missing entry removal,,Yes,Yes
36511,TODO: Add missing entries removal,,,Yes
36512,TODO (VIGS25): Setup feed_dict and compute the Convolution and score values,,Yes,Yes
36513,TODO (VIGS25): Complete the description,,,Yes
36514,TODO (VIGS25): Setup feed_dict and compute the Convolution and score values,,Yes,Yes
36518,Taken from Keras code [citation needed],,,Yes
36520,d = tf.nn.relu(d) # fix numerical instabilities about diagonal,,Yes,Yes
36526,Try specifying particular columns.,,Yes,Yes
36528,TODO: Should we do similar dev handling?,,No,Yes
36530,TODO once improved splitting API is merged in swap out for simpler,,,Yes
36532,TODO: How to handle the failure here?,,Yes,Yes
36536,Get DeepChem data directory if needed,,,Yes
36537,TODO(rbharath): I don't like this awkward string\/class divide. Maybe clean up?,,,Yes
36540,this expected behavior? Need to think about API.,,Yes,Yes
36541,TODO (ytz) this is a bandage solution to reorder the atoms,,No,Yes
36543,TODO (VIGS25): Complete the description,,,Yes
36544,TODO: Imported metrics will be removed in a futrue version of DeepCHem,,,Yes
36545,TODO: Add a multtiask metrics example,,,Yes
36549,TODO: Fix this case with correct thresholding,,,Yes
36551,TODO: Fix this case with correct thresholding,,Yes,Yes
36552,TODO: Fix this case with correct thresholding,,,Yes
36553,TODO: replace with np.unique,,No,Yes
36556,FIXME: Incompatible types in assignment,,Yes,Yes
36559,"FIXME: Argument 1 of \""__eq__\"" is incompatible with supertype \""object\""",,Yes,Yes
36560,"FIXME: Item \""None\"" of \""Optional[List[str]]\"" has no attribute \""__iter__\"" (not iterable)",,No,Yes
36561,"FIXME: Item \""None\"" of \""Optional[List[str]]\"" has no attribute \""append\""",,Yes,Yes
36562,TODO: Change URLs,,Yes,Yes
36564,FIXME: it is better to add this json to DeepChem AWS,,,Yes
36568,Get DeepChem data directory if needed,,Yes,Yes
36570,Get DeepChem data directory if needed,,,Yes
36572,TODO: Change URLs,,Yes,Yes
36574,FIXME: The shape error happens,,No,Yes
36575,FIXME: Incompatible types in assignment,,,Yes
36576,"FIXME: Argument 1 to \""enumerate\"" has incompatible type",,,Yes
36579,"FIXME: Signature of \""_featurize_shard\"" incompatible with supertype \""DataLoader\""",,Yes,Yes
36583,FIXME: BaseEstimator doesn't guarantee the class has `predict` method.,,,Yes
36584,update model with best param,,Yes,Yes
36585,Handle empty case where no data from this shard needed,,Yes,Yes
36592,"\""\""\"" || SMILES regex pattern for tokenization. Designed by Schwaller et. al.  ||  ||  || References ||  || .. [1]  Philippe Schwaller; Teodoro Laino; Th\u00E9ophile Gaudin; Peter Bolgar; Christopher A. Hunter; Costas Bekas; and Alpha A. Lee ||         ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction ||         1572-1583 DOI: 10.1021\/acscentsci.9b00576 ||  || \""\""\""",,,Yes
36593,"\""\""\"" || SMI_REGEX_PATTERN: str ||     SMILES regex pattern for tokenization. Designed by Schwaller et. al.  ||  || References ||  || .. [1]  Philippe Schwaller; Teodoro Laino; Th\u00E9ophile Gaudin; Peter Bolgar; Christopher A. Hunter; Costas Bekas; and Alpha A. Lee ||         ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction ||         1572-1583 DOI: 10.1021\/acscentsci.9b00576 ||  || \""\""\""",,,Yes
36597,update model with best param,,,Yes
36600,Get DeepChem data directory if needed,,,Yes
36601,TODO: THIS IS FAILING!,,Yes,Yes
36602,TODO: THIS DOESN'T WORK!!,,No,Yes
36606,TODO: We need a cleaner usage example for this,,No,Yes
36607,Perhaps parallelize it?,,Yes,Yes
36609,TODO: Available pymatgne functions are very limited when DummySpecie is,,No,Yes
36610,involved. This may be perhaps fixed in the future. Until then; we,,Yes,Yes
36611,Get DeepChem data directory if needed,,,Yes
36613,TODO: This is duplicated! Clean up,,,Yes
36614,# TODO: This is failing; something about the hydrogen bond counting?,,Yes,Yes
36618,"\""\""\"" || SMI_REGEX_PATTERN: str ||     SMILES regex pattern for tokenization. Designed by Schwaller et. al. ||  || References ||  || .. [1]  Philippe Schwaller; Teodoro Laino; Th\u00E9ophile Gaudin; Peter Bolgar; Christopher A. Hunter; Costas Bekas; and Alpha A. Lee ||         ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction ||         1572-1583 DOI: 10.1021\/acscentsci.9b00576 ||  || \""\""\""",,,Yes
36619,"\""\""\"" || SMI_REGEX_PATTERN: str ||     SMILES regex pattern for tokenization. Designed by Schwaller et. al. ||  || References || ---------- || .. [1]  Philippe Schwaller; Teodoro Laino; Th\u00E9ophile Gaudin; Peter Bolgar; Christopher A. Hunter; Costas Bekas; and Alpha A. Lee ||         ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction ||         1572-1583 DOI: 10.1021\/acscentsci.9b00576 || \""\""\""",,Yes,Yes
36623,Get DeepChem data directory if needed,,,Yes
36624,TODO: This is duplicated! Clean up,,,Yes
36628,TODO Remove once verify support is merged in mxnet.gluon.utils.download,,Yes,Yes
36629,Define a temporary class to implement the normalized version,,,Yes
36630,TODO(sxjscience) Find a better solution,,No,Yes
36631,TODO(sxjscience) Move _DivSqrtDim to contrib,,Yes,Yes
36632,The wiki.simple.vec vectors don't perform too good,,No,Yes
36636,Apply the cosine to even columns and sin to odds.,,Yes,Yes
36638,Workaround for https:\/\/github.com\/apache\/incubator-mxnet\/issues\/11314,,,Yes
36639,'surrogateescape' would be better but only available in Py3,,,Yes
36640,"\""\""\"" || Large Word Language Model || =================== ||  || This example shows how to build a word-level language model on Google Billion Words dataset || with Gluon NLP Toolkit. || By using the existing data pipeline tools and building blocks; the process is greatly simplified. ||  || We implement the LSTM 2048-512 language model proposed in the following work. ||  || @article{jozefowicz2016exploring; ||  title={Exploring the Limits of Language Modeling}; ||  author={Jozefowicz; Rafal and Vinyals; Oriol and Schuster; Mike and Shazeer; Noam and Wu; Yonghui}; ||  journal={arXiv preprint arXiv:1602.02410}; ||  year={2016} || } ||  || \""\""\""",,,Yes
36641,"\""\""\""Fasttext Classification Training Model model || =========================== || This example shows how to train a FastText Classification model with the || Gluon NLP Toolkit. || The FastText Classification model was introduced by || - Joulin; Armand; et al. \""Bag of tricks for efficient text classification.\"" || ... arXiv preprint arXiv:1607.01759 (2016). || For larger datasets please refrain from using -ngrams to value > 2 || \""\""\""",,Yes,Yes
36642,Apply the cosine to even columns and sin to odds.,,,Yes
36643,TODO order may be incorrect on Python before v3.6,,Yes,Yes
36644,Fix word embedding,,Yes,Yes
36645,XXX the existing model is trained with prefix 'transformer_',,Yes,Yes
36646,XXX assume no changes in BERT configs,,No,Yes
36648,"What we really want to return is \""Steve Smith\"".",,No,Yes
36650,Figure out whether to take actual dependency on it.,,Yes,Yes
36651,"\""\""\""PyTorch BERT parameter naming to Gluon BERT parameter naming. ||  || Given a Gluon BERT model (eg. obtained with the convert_tf_gluon.py script) and || a pytorch_model.bin containing the same parameters; this script infers the || naming convention of PyTorch. ||  || \""\""\""",,No,Yes
36652,Move unknown_token to idx 0 to replicate the behavior of,,,Yes
36653,"\""\""\"" || Intent Classification and Slot Labelling with BERT ||  || ========================================================================================= ||  || This example shows how to implement finetune a model with pre-trained BERT parameters for || joint intent classification and slot labelling; with Gluon NLP Toolkit. ||  || \""\""\""",,,Yes
36654,TODO fix 'float16',,No,Yes
36655,TODO: Transformer-XL has a sample_softmax argument here,,Yes,Yes
36657,"\""\""\""Transformer-XL Language Model || ================================ ||  || This example shows how to build a Transformer-XL language model with Gluon NLP || Toolkit. ||  || @article{dai2019transformer; ||   title = {Transformer-XL: Attentive language models beyond a fixed-length context}; ||   author = {Dai; Zihang and Yang; Zhilin and Yang; Yiming and Cohen; William W ||       and Carbonell; Jaime and Le; Quoc V and Salakhutdinov; Ruslan}; ||   journal = {arXiv preprint arXiv:1901.02860}; ||   year = {2019}; || } ||  || \""\""\""",,Yes,Yes
36659,XXX Temporary hack for hybridization as hybridblock does not support None,,Yes,Yes
36660,"\""\""\"" || Transformer || ================================= ||  || This example shows how to implement the Transformer model with Gluon NLP Toolkit. ||  || @inproceedings{vaswani2017attention; ||   title={Attention is all you need}; ||   author={Vaswani; Ashish and Shazeer; Noam and Parmar; Niki and Uszkoreit; Jakob and Jones; ||           Llion and Gomez; Aidan N and Kaiser; Lukasz and Polosukhin; Illia}; ||   booktitle={Advances in Neural Information Processing Systems}; ||   pages={6000--6010}; ||   year={2017} || } || \""\""\""",,Yes,Yes
36661,TODO should be possible to change to 64 bit in MXNet 1.6 (uses int64 by default?),,,Yes
36666,We implement forward; as the number of states changes between the,,Yes,Yes
36669,TODO Replace this function with gluon.utils.split_data() once targeting MXNet 1.7,,Yes,Yes
36671,TODO remove once https:\/\/github.com\/apache\/incubator-mxnet\/issues\/17292 is fixed,,Yes,Yes
36672,this is a temporary fix to keep backward compatibility; due to an issue in MXNet:,,Yes,Yes
36673,TODO Replace this function with gluon.utils.split_data() once targeting MXNet 1.7,,Yes,Yes
36674,TODO Replace split_array() with gluon.utils.split_data() once targeting MXNet 1.7,,Yes,Yes
36677,TODO: for some tokenizers; no need to truncate words,,,Yes
36678,this is a temporary fix to keep backward compatibility; due to an issue in MXNet:,,Yes,Yes
36680,TODO,,,Yes
36681,get parameter names for tensorflow with unused parameters filtered out.,,,Yes
36686,"\""\""\"" || Transformer || ================================= ||  || This example shows how to implement the Transformer model with Gluon NLP Toolkit. ||  || @inproceedings{vaswani2017attention; ||   title={Attention is all you need}; ||   author={Vaswani; Ashish and Shazeer; Noam and Parmar; Niki and Uszkoreit; Jakob and Jones; ||           Llion and Gomez; Aidan N and Kaiser; Lukasz and Polosukhin; Illia}; ||   booktitle={Advances in Neural Information Processing Systems}; ||   pages={6000--6010}; ||   year={2017} || } || \""\""\""",,,Yes
36688,TODO Use temporary file,,,Yes
36689,TODO(sxjscience) Consider to combine the NamedTuple and batchify functionality.,,,Yes
36690,TODO investigate the impact,,,Yes
36692,TODO(sxjscience) Directly implement a kernel for masked logsoftmax,,Yes,Yes
36694,TODO(?) Add max_tokens option to BucketSampler and SortedSampler to make it similar to Fairseq: https:\/\/github.com\/pytorch\/fairseq\/blob\/master\/fairseq\/data\/data_utils_fast.pyx,,No,Yes
36696,TODO Revise examples,,Yes,Yes
36697,TODO(?) We can refactor the code using,,No,Yes
36701,TODO(sxjscience) Move do_lower to assets.,,No,Yes
36703,TODO support use_pooler,,Yes,Yes
36704,TODO(sxjscience) Think about how to improve this,,,Yes
36705,TODO(sxjscience) Better Exception Handling,,Yes,Yes
36706,TODO(sxjscience) Consider to move it into the official MXNet gluon package,,,Yes
36708,inner ffn layer denoted by xxx,,Yes,Yes
36713,TODO Investigate the precision of F.npx.leaky_relu(x; act_type='gelu'),,,Yes
36715,TODO(zheyuye); Directly implement a metric for weighted AUC,,Yes,Yes
36717,TODO; HF Tokenizer must have the unk token.,,,Yes
36718,Move the hf_${model}-merges.txt to hf_${model}.models,,Yes,Yes
36719,TODO Use temporary file,,No,Yes
36721,TODO investigate the impact,,,Yes
36723,TODO(?); When the number of samples is large. We should improve the logic here.,,,Yes
36724,TODO(sxjscience) Consider to move it into the official MXNet gluon package,,,Yes
36727,2. cross-attention; if needed,,Yes,Yes
36731,TODO; support default initializer,,,Yes
36733,TODO,,,Yes
36734,TODO Ideally; we can write a custom operator to accelerate the padding,,Yes,Yes
36735,TODO such weight sharing not supported in torchscript,,,Yes
36736,Move to the corresponding context,,,Yes
36737,Needed to write header when saving weights,,,Yes
36738,Unique anchor selection (fast but does not retain order) TODO: update to retain original order,,Yes,Yes
36740,TODO examine arbitrary 0.3 thres here,,Yes,Yes
36742,number of columns,,No,Yes
36743,Needed to write header when saving weights,,Yes,Yes
36744,TODO: auto-delete shapefile,,,Yes
36745,TODO: clamp to image border https:\/\/github.com\/ultralytics\/yolov3\/issues\/368,,,Yes
36750,no return needed,,Yes,Yes
36752,update all models (to fix SourceChangeWarning),,,Yes
36754,`kw` catches `env=None` needed for newer sphinx while maintaining,,,Yes
36755,We can also define more than two columns.,,Yes,Yes
36756,TODO: we should detect when tracing is a fallback.,,,Yes
36762,TODO: Stack arguments are currently not considered,,No,Yes
36763,TODO: Duplicate of code in reverse_ad.,,No,Yes
36766,Naming convention from 'Evaluating Derivatives'; b is rev; d is fwd,,,Yes
36771,TODO: fixes.py appears to pass None value and expect 0.0 back. Bug?,,,Yes
36772,TODO: Not sure this should normally be hit. In forward-over-reverse?,,,Yes
36777,TODO: Add version-specific checks.,,,Yes
36779,"\""\""\""Tests for Hessian-vector products on a few limited functions. ||  || HVPs are run in three configurations: ||  - Reverse-over-reverse (autograd-style) ||  - Forward-over-reverse (traditional AD style; most efficient) ||  - Reverse-over-forward || \""\""\""",,Yes,Yes
36781,TODO: Should results really be that far off?,,No,Yes
36787,TODO: blacklisted as well,,No,Yes
36792,FIXME: move out of description,,No,Yes
36795,TODO: make experiment a module,,,Yes
36796,TODO: submodules should be evaluated topologically,,,Yes
36797,TODO: check for and disallow module circles,,No,Yes
36798,TODO: Configuration of submodules should be available for module,,Yes,Yes
36800,TODO: figure out a good api for accessing submodules,,Yes,Yes
36801,TODO: figure out a good api for adding modules,,,Yes
36802,TODO: should the prefix be saved in submodule or in supermodule?,,,Yes
36803,TODO: figure out module equivalent of a Run,,Yes,Yes
36804,TODO: Is there a way of expressing the logger and the seeder as a module? Do we want that?,,,Yes
36805,"\""\""\"" || # TODO: make modules recursive || # TODO: make experiment a module || # TODO: submodules should be evaluated topologically || # TODO: check for and disallow module circles || # TODO: Configuration of submodules should be available for module || # TODO: Figure out a good api for calling module commands || # TODO: figure out a good api for accessing submodules || # TODO: figure out a good api for adding modules || # TODO: should the prefix be saved in submodule or in supermodule? || # TODO: figure out module equivalent of a Run || # TODO: Is there a way of expressing the logger and the seeder as a module? Do we want that? ||  ||  || class Module(object): ||     def __init__(self; prefix): ||         self.prefix = prefix ||         self.cfgs = [] ||         self.doc = None ||         self.observers = [] ||         self._captured_functions = [] ||         self._commands = OrderedDict() ||  ||     ############################## Decorators ################################## ||  ||     def command(self; f): ||         self._commands[f.__name__] = self.capture(f) ||         return f ||  ||     def config(self; f): ||         self.cfgs.append(ConfigScope(f)) ||         return self.cfgs[-1] ||  ||     def capture(self; f): ||         if f in self._captured_functions: ||             return f ||         captured_function = create_captured_function(f) ||         self._captured_functions.append(captured_function) ||         return captured_function ||  ||     ################### protected helpers ################################### ||     def _set_up_config(self; config_updates=None): ||         config_updates = {} if config_updates is None else config_updates ||         current_cfg = {} ||         for config in self.cfgs: ||             config(config_updates; preset=current_cfg) ||             current_cfg.update(config) ||         return current_cfg || \""\""\""",,Yes,Yes
36806,TODO: Is there a way of expressing the logger and the seeder as a module? Do we want that?,,No,Yes
36807,TODO: make experiment a module,,Yes,Yes
36808,TODO: Figure out a good api for calling module commands,,,Yes
36809,TODO: figure out a good api for accessing submodules,,Yes,Yes
36811,TODO: Is there a way of expressing the logger and the seeder as a module? Do we want that?,,No,Yes
36813,FIXME: this is a hack to access the info,,No,Yes
36814,TODO: make experiment a module,,Yes,Yes
36815,TODO: figure out a good api for accessing submodules,,Yes,Yes
36816,TODO: Is there a way of expressing the logger and the seeder as a module?,,No,Yes
36817,TODO: make the subrunner configurations read-only,,Yes,Yes
36820,TODO: Should 'main' be just a regular command?,,,Yes
36821,TODO: schould experiments be allowed a prefix? This might make them fully,,,Yes
36822,TODO: reusable as modules but might complicate things,,,Yes
36824,TODO: setting submodule properties results in false added entries,,No,Yes
36828,TODO: This might fail if we allow non-dict fixtures,,Yes,Yes
36830,TODO: allow dotted notation in config_updates,,Yes,Yes
36831,TODO: use faster heuristics first; because pkg_resources is slow,,,Yes
36832,TODO: rename,,,Yes
36833,todo: performance optimize this by only creating a PRNG if the signature,,No,Yes
36835,fill in the unused presets,,No,Yes
36836,"\""\""\"" A configurable Hello World. Yay! \""\""\""",,,Yes
36837,TODO: write documentation for this function,,,Yes
36839,"\""\""\"" || A configurable Hello World \""experiment\"". || In this example we configure the message using Sacreds special ConfigScope. ||  || As with hello_config_dict you can run it like this: ||  || >>$ .\/03_hello_config_scope.py ||   INFO - hello_config_scope - Running command 'main' ||   INFO - hello_config_scope - Started ||   Hello world! ||   INFO - hello_config_scope - Completed after 0:00:00 ||  || The message can also easily be changed using the `with` commandline argument: ||  || >>$ .\/03_hello_config_scope.py with message='Ciao world!' ||   INFO - hello_config_scope - Running command 'main' ||   INFO - hello_config_scope - Started ||   Ciao world! ||   INFO - hello_config_scope - Completed after 0:00:00 ||  ||  || But because we are using a ConfigScope that constructs the message from a || recipient we can also just modify that: ||  || >>$ .\/03_hello_config_scope.py with recipient='Bob' ||   INFO - hello_config_scope - Running command 'main' ||   INFO - hello_config_scope - Started ||   Hello Bob! ||   INFO - hello_config_scope - Completed after 0:00:00 || \""\""\""",,No,Yes
36841,TODO: How to deal with binary mode?,,No,Yes
36844,unused config updates raise,,,Yes
36845,unused but in config updates work,,No,Yes
36846,nested unused config updates raise,,No,Yes
36847,nested unused but parent used updates work,,,Yes
36849,unused but in config works,,,Yes
36853,unused but in config works,,,Yes
36855,TODO: switch type to json if possible,,No,Yes
36856,fixme: this will probably fail to detect two equivalent engines,,Yes,Yes
36860,FIXME: No idea why this fails under windows...,,Yes,Yes
36861,FIXME: No idea why this fails under windows...,,,Yes
36864,FIXME: do these work in telegram?,,No,Yes
36865,TODO: How to deal with binary mode?,,No,Yes
36866,FIXME: this line randomly doesn't show on windows (skip for now),,Yes,Yes
36867,FIXME: this line randomly doesn't show on windows (skip for now),,Yes,Yes
36868,TODO: How to deal with binary mode?,,No,Yes
36870,fixme: this will probably fail to detect two equivalent engines,,Yes,Yes
36871,TODO support ignored directories\/files,,Yes,Yes
36872,sadly many builtins are missing from the above; so we list them manually:,,,Yes
36873,ugly hack to deal with pkg-resource version bug,,Yes,Yes
36874,internal usage is a workaround because docopt cannot handle spaces,,,Yes
36875,TODO: sacred.initialize.create_run already takes care of this,,,Yes
36876,Manually convert them to avoid passing a datetime dtype handler,,No,Yes
36882,TODO: switch type to json if possible,,No,Yes
36883,Keeping the convention of referring to locations in S3 as `dir`,,No,Yes
36884,because that is a useful mental model and there isn't a better word,,,Yes
36885,old; deprecated way of creating a mongo observer,,,Yes
36887,Parse classification report: move to it's own function,,No,Yes
36890,TODO: We shouldn't return the last axis,,,Yes
36895,TODO: adjust the x and y ranges in order to compare (or use normalize),,,Yes
36897,This param causes test issues and is deprecated anyway,,Yes,Yes
36898,TODO: This block should probably be moved\/removed soon,,Yes,Yes
36899,TODO: Clean up docs so they don't reference Seaborn things we don't have,,,Yes
36903,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
36906,If X is a data frame; get the columns off it.,,Yes,Yes
36908,TODO: How to map classmap to labels?,,,Yes
36909,This param causes test issues and is deprecated anyway,,Yes,Yes
36911,TODO: Allow both colormap; listed colors; and palette definition,,,Yes
36913,TODO: Make this an independent function or property for override!,,No,Yes
36915,TODO: Make an independent function for override!,,,Yes
36916,TODO: hoist to a higher level base class,,Yes,Yes
36918,TODO: Is this the most efficient method?,,No,Yes
36926,TODO: hoist to a higher level base class,,Yes,Yes
36928,If X is a data frame; get the columns off it.,,Yes,Yes
36929,TODO: hoist,,No,Yes
36930,TODO hoist to main,,Yes,Yes
36931,TODO: hoist,,,Yes
36933,TODO: Would rather not have to set the colors with this method.,,,Yes
36934,Refactor to make better use of yb_palettes module?,,Yes,Yes
36935,TODO If score is happening inside a loop; draw would get called multiple times.,,Yes,Yes
36939,TODO: Is this the most efficient method?,,,Yes
36942,TODO: change to the self.ax method rather than plt.xticks,,,Yes
36943,TODO: Move mesh to a property so the colorbar can be finalized,,,Yes
36946,TODO: Only colors currently works to select the colors of classes.,,No,Yes
36947,TODO: Allow both colormap; listed colors; and palette definition,,Yes,Yes
36950,TODO during refactoring this can be used to generalize ClassBalance,,,Yes
36951,TODO hoist this to shared confusion matrix \/ classification report heatmap class,,Yes,Yes
36953,Needed because sklearn confusion_matrix only returns counts for selected classes,,Yes,Yes
36954,TODO also add the background color-based logic from .util as in ticket #154,,,Yes
36956,TODO also add the background color-based logic from .util as in ticket #154,,Yes,Yes
36959,TODO: Fix the color handling,,No,Yes
36960,TODO: Use resolve_colors instead of this,,,Yes
36961,If X is a data frame; get the columns off it.,,Yes,Yes
36962,TODO during refactoring this can be used to generalize ClassBalance,,No,Yes
36964,Refactor to make better use of yb_palettes module?,,Yes,Yes
36965,TODO: change to the self.ax method rather than plt.xticks,,,Yes
36966,3 columns - prec;rec;f1,,No,Yes
36967,TODO hoist this to shared confusion matrix \/ classification report heatmap class,,,Yes
36968,todo hoist,,,Yes
36969,Needed because sklearn confusion_matrix only returns counts for selected classes,,Yes,Yes
36971,handle features that are numeric columns in ndarray matrix,,No,Yes
36972,TODO: Is this the most efficient method?,,,Yes
36973,TODO: make this an independent function for override,,,Yes
36974,TODO: store these plots to add more instances to later,,,Yes
36977,TODO: impage comparison of the quick method,,No,Yes
36978,TODO: Raise an exception in this case.,,Yes,Yes
36980,TODO: store these plots to add more instances to later,,No,Yes
36982,TODO: do better than add one for really small residuals,,Yes,Yes
36986,TODO: write script to generate tsne images,,,Yes
36989,If X is a data frame; get the columns off it.,,Yes,Yes
36991,TODO: review top-level functionality,,Yes,Yes
36992,and whose columns are the predicted classes; each element,,Yes,Yes
36994,TODO: remove this in v0.9,,No,Yes
36996,If len(visualizers) isn't evenly divisibly by rows\/columns;,,Yes,Yes
37000,TODO: Make these examples part of the code base,,No,Yes
37001,TODO: Remove in v0.8,,Yes,Yes
37003,Ensure thresholds ends at 1,,No,Yes
37004,handle features that are numeric columns in ndarray matrix,,,Yes
37005,TODO: store these plots to add more instances to later,,,Yes
37010,removing columns name,,Yes,Yes
37011,uses way too much memory,,,Yes
37016,TODO: Allow both colormap; listed colors; and palette definition,,Yes,Yes
37019,TODO - as an alternative to the above flattening approach; explore an,,No,Yes
37020,and whose columns are the predicted classes; each element,,Yes,Yes
37021,TODO - as an alternative to the above flattening approach; explore an,,,Yes
37025,TODO: should the size circle's center be hard coded like this?,,Yes,Yes
37028,TODO: handle colors better with a mapping and user input,,Yes,Yes
37031,"TODO: Return y as None if there is no self.meta[\""target\""]",,Yes,Yes
37034,from ..bestfit import draw_best_fit # TODO: return in #728,,No,Yes
37035,TODO: should we reuse these colors?,,No,Yes
37037,Set and validate the columns,,,Yes
37042,TODO: still unable to make plot square using make_axes_locatable,,,Yes
37044,TODO: add support for other tagsets?,,,Yes
37045,TODO: replace with make_blobs,,,Yes
37054,TODO: refactor to make use of the new DataVisualizer functionality,,,Yes
37058,TODO: raise NotFittedError instead of returning None,,,Yes
37059,TODO: if not fitted; should raise a NotFitted error,,,Yes
37061,TODO: Switch to using target type from utils.target,,Yes,Yes
37063,TODO: use manual legend so legend works with both scatter and hexbin,,,Yes
37065,TODO: replace with resolve_colors,,,Yes
37067,TODO If score happens inside a loop; draw gets called multiple times.,,Yes,Yes
37068,Ideally we'd want the best fit line to be drawn only once,,,Yes
37070,If failing; perhaps baseline images were regenerated? See note above.,,Yes,Yes
37071,"\""\""\"" || Wrapper for third-party estimators that implement the sklearn API but do not directly || subclass the ``sklearn.base.BaseEstimator`` class. This method is a quick way to get || other estimators into Yellowbrick; while avoiding weird errors and issues. || \""\""\""",,Yes,Yes
37073,TODO: more validation,,No,Yes
37074,It's better to specify one's own model name for this scenario,,Yes,Yes
37075,well then the cell is behind us; instead of choosing left or right randomly; let's do something that might be useful,,Yes,Yes
37076,We can do better of course,,,Yes
37077,One better thing would be to go to the direction where the closest wall\/door is the furthese,,Yes,Yes
37078,TODO: make this work with done action ?,,,Yes
37079,Reason why whe're going next to something,,,Yes
37080,TODO: what if I pickup another blocker (and that's good),,No,Yes
37082,One better thing would be to go to the direction where the closest wall\/door is the furthest,,Yes,Yes
37084,TODO: find something better than random,,Yes,Yes
37086,"TODO: maybe introduce a \""closest_wall_or_door_given_dir\"" function to decide between right and left",,Yes,Yes
37088,TODO: I am not sure this is enough. Shouldn't we drop the object somewhere?,,Yes,Yes
37093,TODO: what if I pickup another blocker (and that's good),,No,Yes
37095,"TODO: maybe introduce a \""closest_wall_or_door_given_dir\"" function to decide between right and left",,,Yes
37097,TODO: or actually maybe this is wrong; maybe the drop\/pickup action is an okay thing given that GoToAdjPos might lead to a GoNextTo with blockers that need to be picked up e.g.,,,Yes
37098,FIXME: h4xx ??Salem: What's this FIXME @maxime ?,,No,Yes
37099,TODO: here; and every time we use this 999 number; find a cleaner\/better way,,,Yes
37100,TODO: I am not sure this is enough. Shouldn't we drop the object somewhere?,,Yes,Yes
37102,TODO: I don't think unseen_pos is necessarily in the same room. Do we want that though ?,,,Yes
37103,One better thing would be to go to the direction where the closest wall\/door is the furthest,,Yes,Yes
37106,TODO: or actually maybe this is wrong; maybe the drop\/pickup action is an okay thing given that GoToAdjPos might lead to a GoNextTo with blockers that need to be picked up e.g.,,No,Yes
37108,TODO: here; and every time we use this 999 number; find a cleaner\/better way,,Yes,Yes
37109,TODO: I am not sure this is enough. Shouldn't we drop the object somewhere?,,,Yes
37110,TODO: Double check that False should be returned here,,,Yes
37111,TODO: I don't think unseen_pos is necessarily in the same room. Do we want that though ?,,Yes,Yes
37115,"TODO: maybe introduce a \""closest_wall_or_door_given_dir\"" function to decide between right and left",,,Yes
37117,TODO: or actually maybe this is wrong; maybe the drop\/pickup action is an okay thing given that GoToAdjPos might lead to a GoNextTo with blockers that need to be picked up e.g.,,,Yes
37118,TODO: this as in a for loop; that seems useles; it worked... I removed it - make sure it still works ok,,,Yes
37120,maybe after dropping the object; we were supposed to go to it again; and it was referred to,,Yes,Yes
37125,FIXME: h4xx ??Salem: What's this FIXME @maxime ?,,,Yes
37126,Temporary: fix numpy version because of bug introduced in 1.16,,No,Yes
37128,"TODO: maybe introduce a \""closest_wall_or_door_given_dir\"" function to decide between right and left",,,Yes
37129,TODO: is it really necessary to do all this? It works; but it seems like it's useless code. -> Double check,,No,Yes
37130,TODO: or actually maybe this is wrong; maybe the drop\/pickup action is an okay thing given that GoToAdjPos might lead to a GoNextTo with blockers that need to be picked up e.g.,,No,Yes
37132,TODO: I want this to be,,,Yes
37133,then probably it is better to drop elsewhere.,,,Yes
37134,then probably it is better to drop elsewhere.,,,Yes
37135,How many BFS search this bot has improved,,Yes,Yes
37136,TODO: instead of updating all subgoals; just add a couple,,,Yes
37137,TODO: instead of updating all subgoals; just add a couple,,Yes,Yes
37139,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
37142,HACK,,,Yes
37143,HACK,,No,Yes
37145,FIXME Gr\u00E9gory says 'linear' instead of 'tanh',,Yes,Yes
37147,FIXME -- check value of concat_axis=1,,,Yes
37149,+3 is a hack to avoid later IndexError resulting from rounding error,,,Yes
37151,FIXME -- update ETAPE so that we can query this information directly,,Yes,Yes
37152,FIXME -- update ETAPE so that we can query this information directly,,Yes,Yes
37156,TODO dichotomic search,,,Yes
37157,FIXME -- update ETAPE so that we can query this information directly,,,Yes
37159,this is needed for self.get_shape() to work,,,Yes
37160,TODO - use zip instead of this for loop,,,Yes
37162,TODO - use zip instead of this for loop,,,Yes
37163,needed for register_custom_object to be called,,Yes,Yes
37167,HACK,,No,Yes
37174,get_prediction is probably already multithreaded; or (better) even,,,Yes
37175,TODO update this code once keras > 2.0.4 is released,,,Yes
37176,TODO update this code once keras > 2.0.4 is released,,No,Yes
37177,TODO | plot distribution of distances between centers,,,Yes
37179,hack to make things faster,,No,Yes
37181,can anyone tell me why this usually works better,,,Yes
37183,split large batch in smaller batches if needed,,Yes,Yes
37186,HACK until all packages are updated to new API,,Yes,Yes
37187,"FIXME -- make sure \""subset\"" is not empty",,Yes,Yes
37188,HACK until all packages are updated to new API,,Yes,Yes
37189,HACK until all packages are updated to the new API,,,Yes
37190,HACK until all packages are updated to use 'audio' instead of 'wav',,,Yes
37191,[0] is a hack due to a bug in docopt and,,Yes,Yes
37194,TODO this might take a very long time when hypothesis contains,,Yes,Yes
37195,get_prediction is probably already multithreaded; or (better) even,,,Yes
37196,TODO - use smarter weights (e.g. Hamming window),,No,Yes
37197,TODO add support for any internal layer,,Yes,Yes
37199,needed to register pyannote.audio's own Keras optimizers,,,Yes
37200,TODO -- check that at least one input depends on 'input_buffer',,,Yes
37202,TODO,,Yes,Yes
37204,TODO. batchify if X is too big,,No,Yes
37206,[0] is a hack due to a bug in docopt and,,,Yes
37207,the lower; the better,,,Yes
37210,TODO. rename to EER.segment (as opposed to EER.turn),,Yes,Yes
37212,compute wtf loss,,No,Yes
37213,TODO. 4. Resegmentation,,Yes,Yes
37217,number of batches needed to complete an epoch,,Yes,Yes
37221,TODO. replace argmax by Viterbi decoding,,,Yes
37222,TODO. log-sigmoid,,Yes,Yes
37223,if loss is better than previous known best,,,Yes
37227,HACK: change internal SlidingSegment's source to only extract,,,Yes
37229,FIXME. log_dir = tmp directory,,No,Yes
37230,TODO. save scheduler state as well,,,Yes
37231,TODO. load scheduler as well,,Yes,Yes
37233,from .wtf_triplet_loss import WTFTripletLoss,,,Yes
37234,TODO. make 0.1 tunable,,Yes,Yes
37239,TODO. create README file in <output_dir>,,Yes,Yes
37240,TODO. create README file in <output_dir>,,,Yes
37241,TODO. create README file in <output_dir>,,Yes,Yes
37243,TODO add option to use another sampler,,Yes,Yes
37244,convert to mono if needed,,,Yes
37246,FIXME: use fade-in between concatenated noises,,,Yes
37247,load waveform; re-sample; and convert to mono if needed,,,Yes
37248,convert to mono if needed,,No,Yes
37250,TODO. log-sigmoid,,,Yes
37252,TODO: normalize coverage with what one could achieve if,,Yes,Yes
37254,is this really needed?,,,Yes
37257,HACK remove this when Pepe's HTK files are fixed...,,,Yes
37259,is added (as it would likely degrade performance),,,Yes
37260,TODO. make all labeling apps inherit from a unique Labeling app,,,Yes
37261,TODO. add GMM-based resegmentation,,No,Yes
37262,store both epoch number and best pipeline parameter to disk,,Yes,Yes
37265,TODO. create README file in <output_dir>,,,Yes
37268,TODO. create README file in <output_dir>,,Yes,Yes
37269,number of batches needed to complete an epoch,,Yes,Yes
37271,FIXME. incorrect if embedding are not unit-normalized,,,Yes
37278,TODO. load state from dict,,Yes,Yes
37279,TODO. use moving average loss,,Yes,Yes
37280,TODO. add option to **not** use bias in classification layer,,Yes,Yes
37283,HACK. we shouldn't need to do that here...,,,Yes
37284,TODO. add support for data augmentation,,Yes,Yes
37286,HACK for JHU\/CLSP cluster,,Yes,Yes
37290,FIXME,,,Yes
37291,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
37292,"\""\""\"" || TODO || \""\""\""",,Yes,Yes
37293,TODO,,Yes,Yes
37294,"\""\""\"" || TODO || \""\""\""",,Yes,Yes
37295,TODO: move this to pyannote.database,,,Yes
37296,hack for the very last segment that might overflow by 1,,Yes,Yes
37297,"HACK to \""book\"" GPU as soon as possible",,Yes,Yes
37299,FIXME: make sure this is coherent with other changes related to,,,Yes
37301,TODO. especially useful for domain-adversarial stuff,,Yes,Yes
37302,if noise file is longer than what is needed; crop it,,,Yes
37303,TODO: use fade-in between concatenated noises,,,Yes
37307,FIXME,,Yes,Yes
37308,TODO. make this interactive:,,,Yes
37309,TODO: update version automatically,,Yes,Yes
37311,FIXME,,Yes,Yes
37313,not really needed (e.g. in pipeline training),,No,Yes
37314,HACK for when start (returned by shifted_frames.crop) is negative,,,Yes
37315,FIXME: fix support for return_intermediate,,No,Yes
37318,TODO: add progress bar (at least for demo purposes),,Yes,Yes
37319,FIXME: add half window duration to context?,,,Yes
37320,TODO. change to 'pyannote\/pyannote-audio',,Yes,Yes
37321,"\""A time delay neural network architecture for efficient modeling of long temporal contexts.\""",,Yes,Yes
37328,FIXME create a Literal type for metric,,,Yes
37332,FIXME see above,,Yes,Yes
37333,TODO. this can be done much more cleanly with,,Yes,Yes
37334,FIXME: why divive by 2?,,No,Yes
37337,FIXME maybe in pyannote.core.utils.distance,,No,Yes
37339,FIXME it has a different meaning in ArcFace; right?,,Yes,Yes
37340,FIXME create a Literal type for clamp,,,Yes
37341,FIXME create a Literal type for sampling,,,Yes
37342,FIXME see above,,Yes,Yes
37345,TODO in case success = False; one should freeze the main network for,,Yes,Yes
37347,TODO. add overlap detection,,,Yes
37348,HACK in some rare cases; .samples() yields samples,,,Yes
37352,TODO fix the problem upstream in .samples(),,,Yes
37353,FIXME: fix support for return_intermediate,,No,Yes
37354,TODO - use smarter weights (e.g. Hamming window),,,Yes
37355,FIXME: fix support for return_intermediate,,No,Yes
37356,TODO - use smarter weights (e.g. Hamming window),,No,Yes
37358,"TODO. be smart and find a way to use \""local_labels\""",,Yes,Yes
37360,IDEA stop annotating early once the current distance is much,,Yes,Yes
37361,TODO handle these corner cases better,,No,Yes
37363,TODO refactor to use sparse matrixes everywhere,,No,Yes
37367,"\""\""\"" || Machine learning module for Python || ================================== ||  || skmultilearn is a Python module integrating classical machine || learning algorithms in the tightly-knit world of scientific Python || packages (numpy; scipy; matplotlib). || It aims to provide simple and efficient solutions to learning problems || that are accessible to everybody and reusable in various contexts: || machine-learning as a versatile tool for science and engineering. || See http:\/\/scikit-learn.org for complete documentation. ||  || \""\""\""",,,Yes
37368,TODO: fix this for labelset_size > 1 per issue #42,,,Yes
37372,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
37373,"\""\""\"" || .. module:: algorithm ||    :synopsis: Wrapper around classification algorithm. ||  || \""\""\""",,No,Yes
37374,Fix unsupported image types using the Pillow.,,Yes,Yes
37376,TODO: config should only be loaded once,,,Yes
37379,TODO: a little confusingly named,,,Yes
37380,TODO: config should only be loaded once (also in database.py and enter_data.py),,No,Yes
37381,TODO: this is pretty much unnecessary,,,Yes
37382,open or create our log file. TODO: why the random number?,,No,Yes
37383,TODO: load these from db,,No,Yes
37384,TODO: a little confusingly named,,Yes,Yes
37385,TODO: config should only be loaded once (also in database.py and enter_data.py),,No,Yes
37387,TODO: load these from db,,No,Yes
37390,TODO,,Yes,Yes
37391,"\""\""\"" || .. module:: algorithm ||    :synopsis: Wrapper around classification algorithm. ||  || \""\""\""",,No,Yes
37392,TODO: this is pretty much unnecessary,,No,Yes
37393,open or create our log file. TODO: why the random number?,,No,Yes
37394,TODO: load these from db,,No,Yes
37396,TODO: config should only be loaded once (also in database.py and enter_data.py),,No,Yes
37398,TODO: load these from db,,No,Yes
37399,"\""\""\"" || .. module:: algorithm ||    :synopsis: Wrapper around classification algorithm. ||  || \""\""\""",,No,Yes
37402,fit_transform will spit out TWO columns for the binary variable (one,,Yes,Yes
37404,TODO,,,Yes
37407,TODO: why is this needed?,,No,Yes
37412,"TODO: \""Gridding Done\"" is kind of the wrong term; since it applies to",,,Yes
37415,TODO: wrap this properly in a with session_context():,,,Yes
37417,TODO this might be wrong -- maybe we shouldn't mark this done until,,Yes,Yes
37421,TODO: this doesn't belong here,,Yes,Yes
37422,TODO multicore,,,Yes
37423,k is number that xxx-k methods use. It is similar to r_min; except it is,,,Yes
37424,TODO: figure out how to handle these better,,,Yes
37426,fix a single categorical parameter; removing it from the list of free,,Yes,Yes
37427,fix a single categorical parameter; removing it from the list of free,,Yes,Yes
37428,perhaps?,,,Yes
37429,TODO: use python's logging module instead of this,,,Yes
37432,save the indices of categorical columns for one-hot encoding,,,Yes
37433,fix a single categorical parameter; removing it from the list of free,,,Yes
37434,this is needed for some of the scoring methods,,Yes,Yes
37438,save the indices of categorical columns for one-hot encoding,,,Yes
37443,these columns define the partition,,,Yes
37444,these columns point to where the output is stored,,,Yes
37448,TODO: this is hacky. See https:\/\/github.com\/HDI-Project\/ATM\/issues\/48,,Yes,Yes
37449,TODO,,,Yes
37452,TODO: use python's logging module instead of this,,No,Yes
37455,data = pd.DataFrame(columns=self.feature_columns),,Yes,Yes
37456,TODO: python 3 support,,Yes,Yes
37457,You can just specify the packages manually here if your project is,,,Yes
37461,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
37464,Needed because Python 2.7 does not support multiple star operators in a single statement.,,Yes,Yes
37465,Needed because Python 2.7 does not support multiple star operators in a single statement.,,Yes,Yes
37466,Fill in the text attribute if needed.,,No,Yes
37467,You can just specify the packages manually here if your project is,,Yes,Yes
37468,"\""\""\"" || This code implements a basic; Twitter-aware tokenizer. ||  || A tokenizer is a function that splits a string of text into words. In || Python terms; we map string and unicode objects into lists of unicode || objects. ||  || There is not a single right way to do tokenizing. The best method || depends on the application.  This tokenizer is designed to be flexible || and this easy to adapt to new domains and tasks.  The basic logic is || this: ||  || 1. The tuple regex_strings defines a list of regular expression ||    strings. ||  || 2. The regex_strings strings are put; in order; into a compiled ||    regular expression object called word_re. ||  || 3. The tokenization is done by word_re.findall(s); where s is the ||    user-supplied string; inside the tokenize() method of the class ||    Tokenizer. ||  || 4. When instantiating Tokenizer objects; there is a single option: ||    preserve_case.  By default; it is set to True. If it is set to ||    False; then the tokenizer will downcase everything except for ||    emoticons. ||  || The __main__ method illustrates by tokenizing a few examples. ||  || I've also included a Tokenizer method tokenize_random_tweet(). If the || twitter library is installed (http:\/\/code.google.com\/p\/python-twitter\/) || and Twitter is cooperating; then it should tokenize a random || English-language tweet. || \""\""\""",,Yes,Yes
37471,HACK: For some stupid reason; CoreNLPServer will timeout if we,,Yes,Yes
37472,TODO: this is not a good solution,,No,Yes
37475,"\""\""\"" || Example Data and Example Use Cases || ================================== ||  || From package Scanpy (https:\/\/github.com\/theislab\/scanpy). || Written in Python 3 (compatible with 2). || Copyright 2016-2017 F. Alexander Wolf (http:\/\/falexwolf.de). ||  || \""\""\""",,Yes,Yes
37480,"\""\""\"" || Plotting || ======== ||  || From package Scanpy (https:\/\/github.com\/theislab\/scanpy). || Written in Python 3 (compatible with 2). || Copyright 2016-2017 F. Alexander Wolf (http:\/\/falexwolf.de).    || \""\""\""",,Yes,Yes
37481,the following is a Python 2 compatibility hack,,,Yes
37484,TODO: treat negativity explicitly,,,Yes
37485,run randomized; more efficient version,,Yes,Yes
37488,the Scanpy convention of storing observations in rows and variables in,,,Yes
37495,speed no problem here; only done once,,Yes,Yes
37498,this is not actually needed,,,Yes
37502,this is not actually needed,,Yes,Yes
37506,TODO: this should all be organized more nicely,,Yes,Yes
37510,transpose if needed to match the convention that rows store samples\/cells,,Yes,Yes
37511,and columns variables\/genes,,,Yes
37512,the following is less efficient and has no support for sparse matrices,,Yes,Yes
37513,use R convention,,,Yes
37514,user R convention (unbiased estimator),,Yes,Yes
37515,not needed; just for conserving the idea,,,Yes
37516,TODO: make sure that this is really the best strategy,,Yes,Yes
37517,sett.m(1; 'TODO: get nice waitbars also in interactive mode'),,,Yes
37518,user R convention (unbiased estimator),,Yes,Yes
37520,TODO: would be nicer to make not use of __setitem__ here but instead,,Yes,Yes
37521,TODO: delete item should be aware of _keys_multicolumn and _keys,,,Yes
37524,this replaces the columns property \/ also pd.dataframes yield,,Yes,Yes
37526,TODO: change order of arguments; putting the constant self.INDEX_KEY,,,Yes
37527,TODO: check that no-one accidentally overwrites the index?,,Yes,Yes
37528,TODO the following fails,,,Yes
37529,'c' keeps the columns as should be,,,Yes
37530,TODO: need to reallocate memory,,Yes,Yes
37532,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
37533,maybe improved later,,No,Yes
37536,the following is a Python 2 compatibility hack,,,Yes
37538,print('... WARNING: did not find DISPLAY variable needed for interactive plotting\ || ',,,Yes
37539,import __main__ as main          # not needed; use matplotlib.is_interactive() function instead,,Yes,Yes
37541,TODO: this is no longer raised as we are truncating all strings at 50 bytes,,Yes,Yes
37543,TODO: this is no longer raised as we are truncating all strings at 50 bytes,,,Yes
37546,'c' keeps the columns as should be,,,Yes
37548,TODO: maybe use view on data attribute of sparse matrix,,,Yes
37552,This catches a race condition where a process ends,,,Yes
37553,TODO get rid of the following heuristics,,No,Yes
37554,TODO get rid of the following heuristics,,No,Yes
37556,TODO: this is a terrible hack; but if we use the solution above; labels,,Yes,Yes
37557,TODO: this is not a good solution,,No,Yes
37558,TODO: cleaner,,No,Yes
37559,TODO: make sure this really works as expected,,,Yes
37560,TODO,,,Yes
37561,TODO: cleaner,,No,Yes
37562,TODO: this is a terrible hack; but if we use the solution above; labels,,Yes,Yes
37563,TODO: come up with a better way of solving this; see also below,,Yes,Yes
37564,TODO: it makes not much of a difference; but we should keep this here,,,Yes
37565,this is a hack; PCA?,,Yes,Yes
37566,TODO,,,Yes
37568,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
37569,graph_tool uses the following convention;,,,Yes
37571,TODO: make these two hacks; which set the value in the _confidence fields,,,Yes
37572,require median_distances to actually provide better evidence,,Yes,Yes
37574,TODO: should not be duplicated from api.pl,,Yes,Yes
37577,TODO: Print Error Message in logging,,No,Yes
37581,Here ends the test-specific part; do logging,,,Yes
37583,TODO: Add scientific justifications,,,Yes
37584,TODO: (LATER:) Make sure that this works for sparse adata objects as well,,No,Yes
37585,TODO: (LATER:) Include when everything else works. Check how to include efficiently,,No,Yes
37589,make all string annotations categorical (not needed),,Yes,Yes
37593,TODO: At the moment; noly works for int identifiers,,,Yes
37594,TODO: Check closely what of the below actions can be skipped and whats necessary,,No,Yes
37595,TODO: Generalize. At the moment; only groups='all' works,,,Yes
37596,TODO: ALlow for comparison with rest; weighting...,,,Yes
37599,#TODO: Add functionality for group; color thresholds.,,No,Yes
37600,Here; for now we use the convention that the respective levels are true if the minimum rank is larger,,Yes,Yes
37605,We store calculated data in dict; access it via dict to dict. Check if this is the best way.,,Yes,Yes
37607,TODO: Subsample,,Yes,Yes
37609,# TODO: optimization frame,,,Yes
37610,# TODO: Pass back a truncated adata object with only those genes that fullfill thresholding criterias,,Yes,Yes
37611,TODO: also replace those for individual function pages:,,,Yes
37612,apparently we need lists to be lists; sets are not allowed in anndata indexing,,Yes,Yes
37613,"we use the scikit-learn convention of calling the seed \""random_state\""",,,Yes
37618,TODO: solve this differently!,,No,Yes
37619,TODO: this is a terrible hack; but if we use the solution above (`not,,Yes,Yes
37620,TODO: Hacked values for now,,Yes,Yes
37625,convention of standard stochastic matrices even though,,Yes,Yes
37626,loop over columns of adjacency; this is where transitions start from,,Yes,Yes
37627,loop over columns (note the transposition),,,Yes
37628,# (this is not the convention of standard stochastic matrices),,Yes,Yes
37634,enforce R convention (unbiased estimator) for variance,,,Yes
37636,The transpose is needed to get the matrix in the shape needed,,,Yes
37638,hack for excepting attribute error for empty graphs...,,,Yes
37640,to be consistent with the heatmap plot; is better to,,,Yes
37641,to be consistent with the heatmap plot; is better to,,,Yes
37643,define a layout of 1 row x 4 columns,,Yes,Yes
37644,needed such that the spacing is the same for thinner or wider images.,,,Yes
37647,don't really know why this gives a warning without passing `order`,,,Yes
37649,define a layout of 2 rows x 3 columns,,,Yes
37651,first row is for 'brackets' (if no brackets needed; the height of this row is zero),,,Yes
37653,TODO,,Yes,Yes
37654,TODO,,Yes,Yes
37655,can this be done in a different; probably faster way?,,Yes,Yes
37658,can this be done in a different; probably in a faster way?,,,Yes
37660,define a layout of 2 rows x 5 columns,,Yes,Yes
37661,define a layout of 2 rows x 3 columns,,Yes,Yes
37664,All columns should have a unique name; otherwise,,Yes,Yes
37665,pd.melt object that is passed to seaborn will merge non-unique columns.,,No,Yes
37666,Here; I simply rename the columns using a count from 1..n using the,,Yes,Yes
37667,define a layout of 2 rows x 4 columns,,Yes,Yes
37668,define a layout of 2 rows x 5 columns,,Yes,Yes
37671,todo,,,Yes
37672,Probably worth looking into a python3.5 compatable way to make this better,,No,Yes
37674,define a layout of 3 rows x 3 columns,,Yes,Yes
37675,reorder columns (usually genes) if needed. This only happens when,,No,Yes
37677,enforece R convention (unbiased estimator) for variance,,,Yes
37679,compute dendrogram if needed and reorder,,No,Yes
37680,rows and columns to match leaves order.,,,Yes
37681,TODO: also replace pale colors if necessary,,No,Yes
37682,empirically fix the prior hyperparameters,,Yes,Yes
37684,use the following hack...,,Yes,Yes
37688,remove temporary columns,,Yes,Yes
37690,layout with 2 rows and 2  columns:,,,Yes
37692,reorder matrix columns according to the dendrogram,,Yes,Yes
37693,layout with 2 rows and 2  columns:,,,Yes
37696,reorder matrix columns according to the dendrogram,,Yes,Yes
37697,layout with 2 rows and 2  columns:,,No,Yes
37700,Ensure columns sum to 1,,Yes,Yes
37701,TODO: add checks,,No,Yes
37702,-h raises it; no args doesn\u2019t. Maybe not ideal but meh.,,Yes,Yes
37705,a name to store the density values is needed. To avoid,,,Yes
37710,TODO: implement diffxpy method; make singledispatch,,Yes,Yes
37711,TODO: Throw helpful error if this doesn't work,,,Yes
37713,TODO: Check what other value could be,,No,Yes
37716,TODO: this seems to be unused,,No,Yes
37718,Nicer param docs,,,Yes
37719,enforce R convention (unbiased estimator) for variance,,,Yes
37720,TODO: is that all?,,No,Yes
37722,TODO: raises ValueError about empty distance matrix \u2013 investigate,,No,Yes
37723,TODO: Generating a dendrogram modifies the object; this should be,,,Yes
37725,0.5 needed for optimal matching with spot boundaries,,,Yes
37728,TODO: Throw helpful error if this doesn't work,,,Yes
37730,TODO: Figure out a better solution for documenting dispatched functions,,No,Yes
37732,"Build files named \""prefix_XXX.xxx\"" in a temporary directory.",,,Yes
37735,define a layout of 1 rows x 2 columns,,Yes,Yes
37738,third row is for mainplot and dendrogram (if needed),,No,Yes
37739,gridspec is the same but rows and columns are swapped,,Yes,Yes
37746,to be consistent with the heatmap plot; is better to,,,Yes
37747,All columns should have a unique name; yet; frequently,,,Yes
37749,because of the renamed matrix columns here,,,Yes
37751,the main plot is divided into three rows and two columns,,Yes,Yes
37752,second row is for brackets (if needed);,,No,Yes
37754,TODO: Let null color be handled with missing_color,,Yes,Yes
37756,TODO: na_in_legend should have some effect here,,,Yes
37757,remove temporary columns,,Yes,Yes
37759,test that columns content is correct for obs_df,,,Yes
37764,TODO: This should be made easier on the anndata side,,No,Yes
37766,Fix for anndata<0.7,,Yes,Yes
37767,ends up meaning code re-use will be limited until umap 0.4.,,No,Yes
37769,TODO: Report more context on the fields being compared on error,,No,Yes
37771,possible edge case - if an episode ends in <N steps; the computation is incorrect,,Yes,Yes
37773,TODO: Handle the different types of sensor,,No,Yes
37775,TODO: Make sure this waits for the Holodeck binary to start up...,,Yes,Yes
37777,TODO: Update self._mem_last_index,,,Yes
37778,but if needed it can be overridden,,Yes,Yes
37780,TODO(joshgreaves) : Implement this,,,Yes
37781,TODO implement sensor checking,,No,Yes
37784,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
37785,TODO: Surpress exceptions?,,,Yes
37788,TODO - I think we are leaking a file object here. Unfortunately; we,,Yes,Yes
37789,TODO implement this section for future build automation update,,Yes,Yes
37791,TODO implement this section for future build automation update,,Yes,Yes
37792,TODO move command functionality to the HolodeckClient class.,,,Yes
37793,TODO implement this section for future build automation update,,Yes,Yes
37794,TODO: More robust verison parsing,,,Yes
37797,Move forward .185 meters (to match initial release),,,Yes
37800,Ugly; disgusting hack. The foot joints behave strangely; I can't figure out why. Skip them for now,,Yes,Yes
37803,TODO: Maybe we should consider creating a config used across the board for,,No,Yes
37804,TODO(vinhowe): If someone knows of a better way to scope a fixture to a,,Yes,Yes
37805,TODO(vinhowe): If someone knows of a better way to scope a fixture to a,,Yes,Yes
37806,Initialize distributed training if needed,,No,Yes
37807,Prepare model for FP16 and distributed training if needed (order is important; distributed should be the last),,,Yes
37811,for gpt2 and maybe others,,,Yes
37812,soon! FIXME,,No,Yes
37813,soon! FIXME,,No,Yes
37814,TODO: What is there is a permanent pod; e.g.,,No,Yes
37815,FIXME: proper exception handling,,Yes,Yes
37818,FIXME: should be determined dynamically,,Yes,Yes
37820,Ugly fix to avoid numerous pods api calls,,Yes,Yes
37824,TODO: Use absolute path is recommended,,No,Yes
37825,FIXME: proper exception handling,,,Yes
37828,TODO: Jeff pls find a proper way to log the below message,,Yes,Yes
37829,TODO: exception handling,,Yes,Yes
37832,FIXME: Use GCloud API calls instead,,Yes,Yes
37833,TODO: Get rid of these default values specific to Data8,,Yes,Yes
37834,TODO: Should we even attempt to de-schedule things if our input,,,Yes
37835,TODO: Can this be nonnegative,,Yes,Yes
37837,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
37839,FIXME add `line_autoscale` when autoscale is enabled,,Yes,Yes
37842,HACK: These files are never closed; but is ok!,,,Yes
37844,FIXME: Support setting affinity directly in KubeSpawner,,No,Yes
37847,FIXME: Asking for c.user.name will invoke a request on top of requesting,,,Yes
37848,FIXME: KubeSpawner duplicate hub_connect config should be deprecated and removed,,No,Yes
37853,implement common labels,,No,Yes
37857,This workaround currently only works for single node clusters;,,Yes,Yes
37858,FIXME: use inotifiy,,No,Yes
37859,FIXME: Stop relying on chartpress to modify Chart.yaml (and values.yaml) by,,Yes,Yes
37860,creating a new feature of chartpress that allows us to directly acquire,,,Yes
37861,FIXME: We can't substitute something for an entire link; because it is,,Yes,Yes
37863,"\""\""\"" || This script is meant to assist in a manual validation that the content of || schema.yaml covers values.yaml; and vice versa. ||  || FIXME: It would be nice to run this as part of our CI pipeline to report if ||        schema.yaml and values.yaml gets out of sync; but first we need to ||        address what it means to be out of sync. ||  ||        Consider if schema.yaml describes extraLabels; and we in this helm chart ||        have an extra label set in values; how should our comparison realize that ||        its nothing to bother about? ||  ||        That kind of complexity is currently an issue for labels; resources; ||        containerSecurityContext; readiness- and livenessProbe's; and hub.config. || \""\""\""",,No,Yes
37864,"\""\""\"" || This script reads schema.yaml and generates a values.schema.json that we can || package with the Helm chart; allowing helm the CLI perform validation. ||  || While we can directly generate a values.schema.json from schema.yaml; it || contains a lot of description text we use to generate our configuration || reference that isn't helpful to ship along the validation schema. Due to that; || we trim away everything that isn't needed. || \""\""\""",,,Yes
37867,TODO: read these from a central config source instead of,,No,Yes
37870,TODO(aggftw): implement timeout,,,Yes
37871,If there are no records; show some columns at least.,,Yes,Yes
37872,If there are no records; show some columns at least.,,Yes,Yes
37873,Columns will look something like this: 'res1: Array[String] = Array(tableName; isTemporary)',,No,Yes
37875,If there are no columns,,,Yes
37878,TODO: Can I inspect the type here to pick columns?!,,Yes,Yes
37879,TODO: Handle no data,,,Yes
37881,Set up spark session to return empty JSON and then columns,,Yes,Yes
37882,Set up spark session to return empty JSON and then columns,,,Yes
37883,Set up spark session to return empty JSON and then columns,,,Yes
37884,Set up spark session to return empty JSON and then columns,,,Yes
37885,columns = result.columns.values,,Yes,Yes
37888,Hack! We do this so that we can query the .__name__ of the function,,Yes,Yes
37895,If there are no records; show some columns at least.,,,Yes
37896,If there are no records; show some columns at least.,,Yes,Yes
37898,HACK HACK HACK!,,,Yes
37899,Hack! We do this so that we can query the .__name__ of the function,,Yes,Yes
37900,This will assign the columns in the right order. If we simply did,,Yes,Yes
37901,has some columns as null; and thus would drop the columns from the df altogether.,,Yes,Yes
37902,Default is configurable retry,,Yes,Yes
37904,todo ISSUE#412 - remove comment before PR @handle_expected_exceptions,,Yes,Yes
37905,todo ISSUE#412,,Yes,Yes
37906,#todo issue#412 - add like 4 more cases,,,Yes
37907,This is ugly; but raising SparkStatementException or returning does not interrupt subsequent cells.,,Yes,Yes
37909,i == 0 never happens perhaps,,Yes,Yes
37910,Author: Peter Michael Stahl <pemistahl@gmail.com>,,Yes,Yes
37911,If the word ends with a double consonant,,,Yes
37912,TODO: delete this method when no longer needed,,No,Yes
37915,TODO: fix imports.,,Yes,Yes
37919,TODO sacar en archivo aparte,,,Yes
37921,TODO: delete this method when no longer needed,,,Yes
37923,TODO: Well; there's definitely room for improvement over here...,,,Yes
37925,TODO ver warning de conversion a unicode,,,Yes
37926,TODO ver warning de conversion a unicode,,Yes,Yes
37937,@TODO: for future needs; for now hyperdash is too...raw output,,,Yes
37938,hack with argparse in config,,Yes,Yes
37939,Hack!,,Yes,Yes
37940,@TODO: make it script,,No,Yes
37944,@TODO: for future needs; for now hyperdash is too...raw output,,Yes,Yes
37946,@TODO: better solution,,,Yes
37948,@TODO: batch metrics print?,,,Yes
37950,@TODO: need better solutions,,,Yes
37951,@TODO: need better solutions,,,Yes
37953,@TODO: refactor,,,Yes
37954,hack to prevent cycle imports,,,Yes
37955,hack to prevent cycle imports,,Yes,Yes
37957,@TODO: remove,,No,Yes
37959,@TODO: rewrite for optmizer_key,,,Yes
37960,@TODO: need better solutions,,No,Yes
37961,@TODO: need better solutions,,No,Yes
37962,@TODO: remove hack,,No,Yes
37965,@TODO: better naming,,,Yes
37966,TODO refactor,,Yes,Yes
37968,@TODO: better naming,,No,Yes
37973,hack to prevent cycle imports,,Yes,Yes
37974,cnn case: one image or several one @TODO,,,Yes
37976,@TODO: add option to collapse observations based on action,,Yes,Yes
37977,hack to prevent cycle imports,,Yes,Yes
37978,@TODO: for prioritized replay,,No,Yes
37979,hack to prevent cycle imports,,,Yes
37980,hack to prevent cycle imports,,Yes,Yes
37981,-- Options for todo extension ----------------------------------------------,,Yes,Yes
37985,# hack to prevent cycle dependencies,,,Yes
37986,hack to prevent cycle imports,,Yes,Yes
37987,@TODO: policy regularization,,No,Yes
37988,hack to prevent cycle imports,,,Yes
37989,"\""\""\""Catalyst-data scripts. ||  ||     1. **tag2label** prepares a dataset to json like {\""class_id\"":  class_column_from_dataset} ||  ||     .. code :: bash ||  ||         catalyst-data tag2label --help ||  ||     example: ||  ||     .. code:: bash ||  ||         catalyst-data tag2label \\\\ ||             --in-dir=.\/data\/ants_bees \\\\ ||             --out-dataset=.\/data\/ants_bees\/dataset.csv \\\\ ||             --out-labeling=.\/data\/ants_bees\/tag2cls.json ||  || \""\""\""",,,Yes
37990,@TODO: handle lama correctly,,No,Yes
37997,@TODO: handle lama correctly,,No,Yes
38004,hack to prevent cycle imports,,Yes,Yes
38005,@TODO: remove time usage; use it under the hood,,Yes,Yes
38006,@TODO: better PYTHONPATH handling,,,Yes
38008,@TODO: better PYTHONPATH handling,,,Yes
38009,@TODO: hardcoded,,,Yes
38010,@TODO: for prioritized replay,,No,Yes
38011,hack to prevent cycle imports,,,Yes
38013,cnn case: one image or several one @TODO,,Yes,Yes
38015,@TODO: remove this hack,,,Yes
38016,@TODO: add logic with registry and env_wrappers,,,Yes
38018,@TODO: remove this hack,,No,Yes
38019,@TODO: return warning,,No,Yes
38022,cnn case: one image or several one @TODO,,Yes,Yes
38023,@TODO: place for memory network,,,Yes
38024,@TODO: for prioritized replay,,No,Yes
38025,@TODO: actor policy specification?,,,Yes
38028,@TODO: for prioritized replay,,No,Yes
38030,@TODO: refactor,,No,Yes
38031,@TODO: any better solution?,,,Yes
38032,@TODO: make by init?,,Yes,Yes
38034,@TODO: remove this hack; simplify state,,,Yes
38035,self._factories[name] != f is a workaround for,,Yes,Yes
38037,@TODO: refactor,,No,Yes
38038,@TODO: add option to collapse observations based on action,,Yes,Yes
38040,@TODO: remove max_episode_length from initialization,,Yes,Yes
38041,@TODO: rewrite,,No,Yes
38046,@TODO: remove time usage; use it under the hood,,,Yes
38049,@TODO: add average meters,,Yes,Yes
38050,@TODO: fix,,,Yes
38054,@TODO: smarter way to do this (other than reshaping)?,,Yes,Yes
38055,@TODO smarter way to do this (other than reshaping)?,,,Yes
38056,@TODO: check,,No,Yes
38059,@TODO: any better solution?,,,Yes
38062,@TODO: fix; wandb issue,,,Yes
38063,@TODO: any better solution?,,,Yes
38067,@TODO: make more general and move to contrib,,No,Yes
38068,virtual display hack,,Yes,Yes
38070,@TODO 1: refactoring; this method is too long,,No,Yes
38071,@TODO 2: load state dicts for schedulers & criteria,,,Yes
38072,@TODO refactor with maybe_recursive_call,,,Yes
38073,jupyter source code logging hack,,No,Yes
38075,@TODO: replace this logic with global catalyst config at ~\/.catalyst,,No,Yes
38077,TODO: remove `check_trace=False`,,Yes,Yes
38078,after fixing this bug https:\/\/github.com\/pytorch\/pytorch\/issues\/23993,,Yes,Yes
38080,@TODO: fix to only KV usage,,,Yes
38082,! fix backward compatibility,,No,Yes
38085,@TODO: too complicated -> rewrite,,No,Yes
38088,jupyter source code logging hack,,No,Yes
38091,TODO Deep refactoring,,No,Yes
38093,@TODO: remove GAN hack,,No,Yes
38094,@TODO: remove this trick,,,Yes
38096,todo: should implement different policy -> action,,,Yes
38100,@TODO: add check for non distributed run for inference,,,Yes
38107,hack with argparse in config,,,Yes
38108,"\""\""\"" || Registry. || .. todo:: Representative docstring for this module || \""\""\""",,,Yes
38109,@TODO: Docs (add `Example`). Contribution is welcome.,,No,Yes
38111,@TODO: wtf?,,No,Yes
38112,repetation sampling is needed for class #3,,No,Yes
38113,TODO: EarlyStoppingCallback and TracerCallback,,Yes,Yes
38115,@TODO: wtf?,,No,Yes
38116,TODO: docs and refactor for datasets-contrib,,No,Yes
38117,TODO: update docs and shapes,,,Yes
38118,TODO: refactor and add docs; move to utils,,,Yes
38119,TODO: refactor code; examples and docs,,Yes,Yes
38121,@TODO: recheck codestyle later,,,Yes
38124,TODO: add docs and move to pure contrib,,No,Yes
38125,TODO: add docs and move to pure contrib,,No,Yes
38128,TODO: fix classes issue,,Yes,Yes
38131,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38134,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38135,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38139,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38140,@TODO: code formatting issue for 20.07 release,,,Yes
38142,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38143,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38144,@TODO: code formatting issue for 20.07 release,,,Yes
38145,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38146,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38147,@TODO: code formatting issue for 20.07 release,,,Yes
38148,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38150,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38151,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38153,@TODO: code formatting issue for 20.07 release,,,Yes
38155,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38156,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38157,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38159,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38163,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38165,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38166,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38167,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38171,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38172,@TODO: code formatting issue for 20.07 release,,,Yes
38173,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38174,@TODO: code formatting issue for 20.07 release,,,Yes
38175,@TODO: code formatting issue for 20.07 release,,,Yes
38178,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38179,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38184,@TODO: code formatting issue for 20.07 release,,,Yes
38185,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38186,@TODO: code formatting issue for 20.07 release,,,Yes
38187,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38189,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38190,@TODO: code formatting issue for 20.07 release,,,Yes
38192,@TODO: code formatting issue for 20.07 release,,,Yes
38194,@TODO: code formatting issue for 20.07 release,,,Yes
38195,@TODO: code formatting issue for 20.07 release,,,Yes
38197,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38199,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38200,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38201,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38202,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38203,@TODO: code formatting issue for 20.07 release,,,Yes
38205,@TODO: code formatting issue for 20.07 release,,Yes,Yes
38208,@TODO: code formatting issue for 20.07 release,,,Yes
38211,Fix for runtime warning:,,No,Yes
38212,convert model\/optimizer back to dict if it needed,,,Yes
38216,@TODO: why func? should be renamed,,,Yes
38221,fix for albumentations >= v0.5.0 - call `TensorToImage` directly,,Yes,Yes
38226,@TODO: chage arch to primitives-based,,No,Yes
38228,@TODO: should be mixin-based,,,Yes
38238,@TODO: move this logic to ``CheckpointCallback``,,Yes,Yes
38240,resulting matrix must be of shape (prod(n_rows); n_columns),,Yes,Yes
38242,TODO: this is a hack but it seems to do the job for now,,,Yes
38244,\\setcounter{MaxMatrixCols}{20} corrects an ugly bug if you try to have a matrix of more than 10 elements or so,,Yes,Yes
38245,Fix unsupported image types using the Pillow.,,Yes,Yes
38246,FIXME: gracefully handle errors here or in the caller?,,Yes,Yes
38247,FIXME: handle other kinds of assignments?,,,Yes
38251,Check if parenthesis are needed on the right side and then dispatch,,Yes,Yes
38253,probably called by nose; better bail out,,,Yes
38255,XXX: Whitelist of builders for which it makes sense to embed,,Yes,Yes
38257,The following is a hack that prevents this behavior by clearing the,,,Yes
38266,fail case: all matrices must have same number of columns,,Yes,Yes
38267,assert that the columns of Q are orthonormal,,,Yes
38273,Construct grids and weights if needed for parameter space,,Yes,Yes
38274,list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.,,Yes,Yes
38275,normalize columns of factor matrices,,Yes,Yes
38276,TODO: this is a hack but it seems to do the job for now,,,Yes
38277,TODO: validate method signature,,,Yes
38278,methods include the backend (`self`) as a parameter. Instead we manually,,,Yes
38280,The below is equivalent to (but more efficient than),,Yes,Yes
38282,The below is equivalent to (but more efficient than),,,Yes
38283,methods include the backend (`self`) as a parameter. Instead we manually,,,Yes
38284,copy over the needed information; and filter the signature for `self`.,,,Yes
38286,Efficient sparse-safe version,,,Yes
38287,TODO!!! Add weights in computation of mttkrp!!,,Yes,Yes
38296,However; it is needed to pop dimensions contracted over,,Yes,Yes
38298,The initial core approximation is needed here for the masking step,,No,Yes
38299,Ugly fix for stacking zero-order tensors that are of shape (1; ) in MXNet,,,Yes
38300,list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.,,,Yes
38303,Efficient sparse-safe version,,Yes,Yes
38304,TO-DO validate rank for partial tucker as well,,Yes,Yes
38305,Note how tt_matrix_to_tensor is implemented in tenalg to allow for more efficient implementations,,,Yes
38309,TODO: This doesn't always pass with these other options,,Yes,Yes
38311,Safety procedure; if columns aren't allow to be zero,,Yes,Yes
38312,PyTorch 1.8.0 has a much better NumPy interface but somoe haven't updated yet,,Yes,Yes
38313,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
38314,TODO: More field names to be added,,,Yes
38317,TODO: Add a better approach instead of adding to sys.path,,No,Yes
38318,TODO: Run the code using a function based approach,,,Yes
38319,TODO: Run the code using a function based approach,,No,Yes
38322,Fix the travis build by un-commenting this line.,,Yes,Yes
38324,TODO: Move the hardcoded cluster configuration such as the,,,Yes
38325,TODO: Replace vpc CIDR hardcoded value,,,Yes
38327,TODO: Find a better way to solve the above issue.,,Yes,Yes
38329,TODO: end,,No,Yes
38332,TODO: Implement me!,,Yes,Yes
38333,TODO,,Yes,Yes
38334,Register self as a route of the configurable-http-proxy.,,Yes,Yes
38336,include all preprocessors that have configurable options,,Yes,Yes
38338,this makes them non-configurable for the apps themselves. Then; in the init;,,,Yes
38341,Move to the next submission,,,Yes
38342,Move to the previous submission,,Yes,Yes
38344,Move to the previous submission,,,Yes
38345,# TODO: they should have a link here; even if they haven't submitted anything!,,Yes,Yes
38346,include all the apps that have configurable options,,,Yes
38347,hack to convert links to ipynb files to html,,,Yes
38348,: Whether a score needs to be assigned manually. This is automatically computed,,Yes,Yes
38350,hack to convert links to ipynb files to html,,,Yes
38351,hack to convert links to ipynb files to html,,Yes,Yes
38352,hack to convert links to ipynb files to html,,Yes,Yes
38353,Move to the next submission,,,Yes
38355,include plugins that have configurable options,,Yes,Yes
38356,XXX Move to utils.py maybe?,,No,Yes
38357,include all the apps that have configurable options,,Yes,Yes
38358,updating shouldn't work if we're validating; too,,Yes,Yes
38362,Move to the next submission,,Yes,Yes
38363,Move to the previous submission,,,Yes
38365,FIXME: Not parsing correctly a string of the format,,Yes,Yes
38366,no way to compare so fail,,Yes,Yes
38367,check that it works ok with extra and missing columns,,No,Yes
38368,check that it works ok with extra and missing columns,,,Yes
38370,This is a hack; see the comment in _set_points above.,,,Yes
38371,Normally it is a bad idea to put imports in the middle of,,,Yes
38372,Normally it is a bad idea to put imports in the middle of,,,Yes
38373,This is a bit of a hack to use .val() and .change() rather than,,No,Yes
38375,Hack: there seems to be some race condition here where sometimes the,,No,Yes
38377,--ExecutePreprocessor.timeout doesn't work.  Better solution,,Yes,Yes
38381,FIXME how do we access the logger from here?,,Yes,Yes
38382,should be moved up to Exchange? Common to this and release,,No,Yes
38383,Make sure the student is in the course; even if it's somehow,,Yes,Yes
38384,Make sure the student is in the course; even if it's somehow,,,Yes
38385,# FIXME: loop over all,,No,Yes
38386,Make sure the student is in the course; even if it's somehow,,Yes,Yes
38387,# FIXME: loop over all,,No,Yes
38390,include all the apps that have configurable options,,Yes,Yes
38391,include plugins that have configurable options,,Yes,Yes
38392,include all preprocessors that have configurable options,,Yes,Yes
38396,include all preprocessors that have configurable options,,Yes,Yes
38399,include all preprocessors that have configurable options,,Yes,Yes
38403,include plugins that have configurable options,,,Yes
38407,include all preprocessors that have configurable options,,,Yes
38408,assignment tab needs a 'value' field with the info needed to repopulate,,Yes,Yes
38409,Make sure the student is in the course; even if it's somehow,,Yes,Yes
38411,include plugins that have configurable options,,Yes,Yes
38412,include all preprocessors that have configurable options,,Yes,Yes
38413,assignment tab needs a 'value' field with the info needed to repopulate,,,Yes
38414,include all the apps that have configurable options,,,Yes
38415,include plugins that have configurable options,,Yes,Yes
38416,include all preprocessors that have configurable options,,Yes,Yes
38419,tables; columns; &c.,,Yes,Yes
38420,XXX What about other model types from the paper?,,No,Yes
38421,XXX Make our own cursors that handle BQL.,,Yes,Yes
38423,XXX Temporary location for the schema.  Move this somewhere else!,,,Yes
38424,XXX Check the engine too; and\/or add support for multiple,,,Yes
38425,XXX What if we opened some random other sqlite file which,,,Yes
38426,XXX Idiotic Python sqlite3 module has no way to execute a,,No,Yes
38427,XXX XXX XXX Temporary debugging kludge!,,,Yes
38428,XXX Use URIs; and attach read-only?,,,Yes
38429,XXX Accept parameters for guessing column types: count_cutoff &c.,,No,Yes
38430,XXX Allow ignored columns?,,Yes,Yes
38432,XXX Quote rowid?  What a pain...  (Could use any of rowid;,,,Yes
38436,XXX Is this the schema language we want?,,,Yes
38438,XXX Limit the number of rows.,,Yes,Yes
38439,XXX Ignore this column?  Treat as continuous?  Infer?,,,Yes
38440,XXX SQLite3 quirk: PRIMARY KEY does not imply NOT NULL.,,,Yes
38441,XXX This logic should not be duplicated for importing CSV tables vs,,No,Yes
38442,XXX Is str(...) necessary?  I think they should all be,,,Yes
38443,XXX Cache this?,,No,Yes
38444,XXX Silly name.,,Yes,Yes
38446,XXX For now.,,Yes,Yes
38447,XXX Ugh.  Fix crosscat so it doesn't do this.,,,Yes
38449,XXX Cargo-culted from old persistence layer's update_model.,,,Yes
38452,XXX Fix this.,,Yes,Yes
38454,XXX This doesn't really belong here; although it doesn't hurt either.,,,Yes
38456,XXX !?!??!,,,Yes
38459,XXX Why special-case empty constraints?,,Yes,Yes
38460,XXX THESE ARE REALLY BAD EXAMPLES THEY SERVE ONLY TO SEE WHETHER THE #,,Yes,Yes
38462,ESTIMATE COLUMNS FROM dha,,,Yes
38464,XXX Would be nice to avoid a named temporary file here.  Pass,,Yes,Yes
38465,XXX Avoid hard-coding this.,,Yes,Yes
38467,columns.,,,Yes
38472,old states are created; new states are added as needed until closure,,,Yes
38473,Mac slow console stderr hack,,,Yes
38474,Tie up loose ends on the propagation links,,,Yes
38475,mark (dot) showing how much of that rule has been processed so far.,,Yes,Yes
38476,'{default}' must sort last.  Apparently; this is guaranteed by,,,Yes
38481,XXX Accept rowid?,,Yes,Yes
38482,XXX Raise a principled exception here.,,,Yes
38483,XXX Accumulate errors and report principled error at end.,,No,Yes
38484,XXX None?,,,Yes
38485,XXX Wait until grammar has these tokens.,,No,Yes
38487,XXX name,,Yes,Yes
38488,XXX subquery or XXX name,,,Yes
38489,XXX name,,,Yes
38490,XXX name,,,Yes
38492,XXX Make sure floats unparse as such.,,Yes,Yes
38494,XXX subquery,,No,Yes
38495,XXX subquery,,No,Yes
38496,XXX Consider a system-independent representation of floats which,,,Yes
38497,XXX We will need some kind of type-checking to distinguish,,Yes,Yes
38498,XXX,,Yes,Yes
38499,Silly indexing convention.,,Yes,Yes
38500,XXX Don't dig out internals of scanner: fix plex to have a,,,Yes
38502,XXX codebook,,,Yes
38503,XXX model config,,Yes,Yes
38504,XXX Query parameters!,,Yes,Yes
38505,XXX Do something with the BQL compiler so we can refer to,,Yes,Yes
38506,XXX Can some other context determine the table; so that we can,,Yes,Yes
38507,XXX Use a specific parse error.,,,Yes
38510,XXX Report a clearer syntax error.,,,Yes
38511,XXX Adapt lemonade to help us identify what the allowed,,Yes,Yes
38512,XXX Record source position.,,Yes,Yes
38513,XXX subquery or XXX name,,Yes,Yes
38514,XXX name or None (don't save),,,Yes
38515,XXX Use context to determine whether to yield column names or,,,Yes
38516,XXX Use query parameters; not quotation.,,,Yes
38519,condition on the values of the row?  Maybe need another,,,Yes
38520,XXX Is this true?,,Yes,Yes
38521,XXX ESTIMATE COLUMNS FROM T1 WHERE PROBABILITY OF 1 > 0.5,,,Yes
38522,XXX Use a specific parse error.,,Yes,Yes
38523,XXX Are the models dependent on one another; or can we just,,Yes,Yes
38524,XXX name,,Yes,Yes
38526,XXX Support pandas data frames...,,Yes,Yes
38527,XXX Let the user pass in the desired encoding.,,,Yes
38528,XXX Check that rowids are contiguous.,,No,Yes
38530,XXX Revisit row numbering between SQLite3 and Crosscat.,,,Yes
38532,XXX name or None (don't save),,Yes,Yes
38533,XXX Can't do this simultaneously in multiple threads.  Need,,Yes,Yes
38535,XXX name or None (don't save),,Yes,Yes
38536,Ignore extraneous parameters.  XXX Bad idea?,,Yes,Yes
38541,XXX Neither Python's sqlite3 module nor apsw supports,,,Yes
38545,what we get out of this will be a list of columns in the,,,Yes
38547,XXX Allow the user to pass in the desired encoding (and CSV dialect;,,,Yes
38548,XXX Support pandas data frames...,,Yes,Yes
38550,XXX Can we get the CSV reader to decode and strip for us?,,No,Yes
38551,XXX Is this the schema language we want?,,Yes,Yes
38553,XXX Limit the number of rows.,,,Yes
38557,XXX Pass count_cutoff\/ratio_cutoff through from above.,,Yes,Yes
38558,XXX Is unicode(...) necessary?  I think they should all be,,No,Yes
38560,XXX This module would be called `import'; but Python won't let me,,Yes,Yes
38561,XXX The schema language here; such as it is; is pretty limited.,,Yes,Yes
38562,Perhaps generating the SQL schema is the wrong approach here.  When,,,Yes
38565,XXX SQLite3 quirk: PRIMARY KEY does not imply NOT NULL.,,,Yes
38566,XXX This logic should not be duplicated for importing external data,,,Yes
38568,XXX Is unicode(...) necessary?  I think they should all be,,,Yes
38569,XXX Whattakludge.,,Yes,Yes
38570,XXX Make our own cursors that handle BQL.,,,Yes
38571,XXX Parse and compile query first.  Would be nice if we,,Yes,Yes
38572,XXX Temporary location for the schema.  Move this somewhere else!,,,Yes
38575,XXX What if we opened some random other sqlite file which,,Yes,Yes
38576,XXX Idiotic Python sqlite3 module has no way to execute a,,,Yes
38578,XXX This doesn't really belong here; although it doesn't hurt either.,,,Yes
38580,XXX Not really right; but it'll do for now.,,,Yes
38581,Find the columns as SQLite knows about them.,,,Yes
38582,Rip out the key column and the ignored columns.,,Yes,Yes
38583,Determine the non-ignored columns.,,Yes,Yes
38585,foo will be a key column; hence no columns to model.,,,Yes
38587,XXX Support even older models formats; from before the schema,,Yes,Yes
38588,XXX Check whether the schema resembles a sane btable schema.,,,Yes
38589,XXX Check whether models is a dict mapping integers to thetas.,,,Yes
38591,XXX Name this operation: DROP BTABLE ...,,Yes,Yes
38592,XXX Urk.  Need a serious story about engine identifiers.,,Yes,Yes
38594,XXX Check whether the metamodel makes sense of it!,,,Yes
38598,much longer to complete (about 30s). This is going to be annoying for pre-,,Yes,Yes
38599,XXX Require the models share a common kernel_list.,,,Yes
38601,XXX Using time.time() is wrong too -- we ought to use a,,No,Yes
38602,XXX Cargo-culted from old persistence layer's update_model.,,,Yes
38606,XXX Raise a principled exception here.,,Yes,Yes
38607,XXX This got broken a while ago: parenthesization in PROBABILITY,,,Yes
38608,XXX What is this idiocy?  End-of-input is reported the same,,,Yes
38610,XXX Database name; &c.,,,Yes
38611,XXX Database name; &c.,,Yes,Yes
38614,XXX Does not disable the `quit' command and whatever other,,Yes,Yes
38615,XXX Not sure this is the right API.  What if overwrite is a,,Yes,Yes
38616,XXX Create a virtual table that automatically does this on insert?,,,Yes
38617,Find the indices of the modelled columns.,,,Yes
38618,XXX Arbitrary input in error message...,,Yes,Yes
38620,XXX More specific exception.,,Yes,Yes
38622,XXX Move this to core.py?,,Yes,Yes
38623,XXX More specific exception.,,Yes,Yes
38624,XXX Database name; &c.,,Yes,Yes
38627,XXX Move this somewhere appropriate.,,No,Yes
38630,XXX Can't do this simultaneously in multiple threads.  Need,,Yes,Yes
38634,XXX Would be nice not to duplicate these column lists.,,No,Yes
38635,XXX Temporary kludge until we get BQL cursors proper; with; e.g.;,,,Yes
38636,XXX Can't do this simultaneously in multiple threads.  Need,,Yes,Yes
38638,We'll implement that later.,,Yes,Yes
38639,XXX XXX XXX Temporary debugging kludge!,,Yes,Yes
38641,XXX For now.,,Yes,Yes
38645,XXX Using time.time() is wrong too -- we ought to use a,,No,Yes
38646,XXX Require the models share a common kernel_list.,,No,Yes
38647,XXX Cargo-culted from old persistence layer's update_model.,,,Yes
38648,XXX For some reason; crosscat fails this assertion.,,Yes,Yes
38650,XXX Ugh!  What to do?  If we allow importing any SQL table,,,Yes
38651,Row function:  SIMILARITY TO <target_row> [WITH RESPECT TO <columns>],,,Yes
38652,XXX Create a virtual table that simulates results?,,Yes,Yes
38655,Find the indices of the modelled columns.,,Yes,Yes
38656,XXX Move to compiler.py.,,Yes,Yes
38657,XXX Do something with the BQL compiler so we can refer to,,Yes,Yes
38659,XXX Use query parameters; not quotation.,,Yes,Yes
38660,XXX UH OH!  This will have the effect of shadowing names.  We,,,Yes
38662,XXX Report source location.,,,Yes
38663,XXX Can some other context determine the table; so that we can,,Yes,Yes
38666,condition on the values of the row?  Maybe need another,,Yes,Yes
38667,XXX Is this true?,,Yes,Yes
38668,XXX We need some kind of type checking to guarantee that,,Yes,Yes
38669,what we get out of this will be a list of columns in the,,,Yes
38671,Silly indexing convention.,,,Yes
38672,XXX Make sure floats unparse as such.,,,Yes
38673,XXX Qualified table names.,,Yes,Yes
38675,XXX Database name; &c.,,Yes,Yes
38676,XXX The metamodel should have responsibility for supplying,,,Yes
38678,Make sure the bayesdb_column table knows all the columns.,,,Yes
38682,XXX What about `RENAME X TO X'?,,Yes,Yes
38684,XXX Put these warning somewhere more appropriate.,,,Yes
38685,XXX WHATTAKLUDGE!,,,Yes
38686,XXX,,,Yes
38688,XXX What about a schema change or insert in the middle of,,,Yes
38691,XXX Why special-case empty constraints?,,Yes,Yes
38693,XXX Simplify this -- we have the correspondence between,,,Yes
38694,XXX Fix this.,,Yes,Yes
38695,XXX !?!??!,,Yes,Yes
38697,XXX Whattakludge.,,,Yes
38698,XXX Idiotic Python sqlite3 module has no way to execute a,,No,Yes
38699,XXX Maybe push the foreign keys pragma to caller.,,No,Yes
38700,XXX Consider running PRAGMA integrity_check; foreign_key_check;,,Yes,Yes
38701,XXX Should be SELECT; not ESTIMATE; here?,,,Yes
38703,XXX Syntax currently doesn't support both nsteps and,,,Yes
38704,XXX Would be nice if we could prepare this statement before,,,Yes
38705,nonnull columns with no default value.  However; the only,,,Yes
38707,XXX Automatically delete the generators?  Generators,,,Yes
38708,ESTIMATE COLUMNS:,,No,Yes
38709,XXX Should explicate that only crosscat models are supported; since,,Yes,Yes
38710,XXX Populate bayesdb_crosscat_metadata;,,,Yes
38711,Cache the metadata json blob -- we'll probably use it,,Yes,Yes
38712,#NAME?,,Yes,Yes
38713,XXX Whattakludge!,,Yes,Yes
38714,XXX Not clear changing the schema is really appropriate.,,Yes,Yes
38719,XXX Compatibility with existing queries.,,Yes,Yes
38720,XXX Database name; &c.,,Yes,Yes
38721,XXX Need to deal with this in the compiler.,,,Yes
38722,to columns by (tabname; colno) pairs rather than,,No,Yes
38723,Rename the table's columns; not the generator's columns.,,Yes,Yes
38725,XXX,,,Yes
38726,XXX One of these days; we'll have to consider making the,,Yes,Yes
38727,XXX Distinguish the two generators somehow.,,,Yes
38728,XXX Combining characters?,,Yes,Yes
38729,XXX Preserve the expression as a column name...?,,Yes,Yes
38730,XXX Support more than just stattype: allow arbitrary column,,,Yes
38731,Too many columns in data.,,,Yes
38736,XXX Also check key columns.,,Yes,Yes
38737,XXX WHATTAKLUDGE!,,Yes,Yes
38738,XXX name,,Yes,Yes
38739,XXX subquery,,,Yes
38740,XXX We need some kind of type checking to guarantee that,,,Yes
38741,what we get out of this will be a list of columns in the,,,Yes
38742,XXX: Is there any reason to use exec and give the users a limited,,Yes,Yes
38743,XXX Kludge to strip control characters introduced by the pty,,,Yes
38744,XXX Kludge to strip control characters introduced by the pty,,Yes,Yes
38745,XXX Kludge to skip pty-introduced control characters on line,,Yes,Yes
38747,"\""\""\""Miscellaneous utilities for managing BayesDB entities. ||  || Tables; generators; and columns are named with strs.  Only US-ASCII is || allowed; no Unicode. ||  || Each table has a nonempty sequence of named columns.  As in sqlite3; || tables may be renamed and do not necessarily have numeric ids; so || there is no way to have a handle on a table that is persistent outside || a savepoint. ||  || Each table may optionally be modelled by any number of generators; || representing a parametrized generative model for the table's data; || according to a named metamodel.  For each table; at most one generator || may be designated as the default generator for the table. ||  || Each generator models a subset of the columns in its table; which are || called the modelled columns of that generator.  Each column in a || generator has an associated statistical type.  Like tables; generators || may be renamed.  Unlike tables; each generator has a numeric id; which || is never reused and therefore persistent across savepoints. ||  || Each generator may have any number of different models; each || representing a particular choice of parameters for the parametrized || generative model.  Models are numbered consecutively for the || generator; and may be identified uniquely by (generator_id; modelno) || or (generator_name; modelno). ||  || Tables and generators may not share names.  In most contexts; where a || generator's name is needed; the name of a table with a default || generator may be substituted. ||  || \""\""\""",,,Yes
38748,XXX Don't hard-code this.,,Yes,Yes
38750,XXX CreateTabSim is not necessary.  Eliminate it.,,Yes,Yes
38751,XXX Reduce copypasta with case for CreateTabSim in bql.py.,,,Yes
38752,XXX Move to compiler.py.,,Yes,Yes
38753,XXX Copypasta of this in compile_simulate!,,,Yes
38754,XXX Should allow parameters for iterations and ckpt\/iter.,,No,Yes
38755,XXX It would be nice to take advantage of Crosscat's,,,Yes
38757,XXX Whattakludge.  Invent a better parsing scheme for,,Yes,Yes
38761,XXX Should be NotImplementedError; but sqlite3 doesn't,,,Yes
38762,XXX Mega-kludge.  See below about grammars for details.,,Yes,Yes
38766,XXX HACK Ensure dependent columns.,,No,Yes
38767,XXX fails on filenames with spaces.,,Yes,Yes
38768,TODO: It would be nice to be async about this. Set 1 second timeout.,,,Yes
38770,XXX Is that really what -q should mean? I would take away the short name.,,,Yes
38772,XXX name,,Yes,Yes
38778,TODO: find better way to get lists of lists into bayesdb than this hack.,,,Yes
38781,XXX Currently CrossCat throws a RuntimeError; we should fix,,Yes,Yes
38783,XXX Why is this independent of the row?  Can't we,,,Yes
38784,condition on the values of the row?  Maybe need another,,Yes,Yes
38785,Make sure the bayesdb_column table knows all the columns.,,No,Yes
38789,"\""\""\""A model that posts that all columns are independently Gaussian with || unknown parameters. ||  || The parameters are taken from the normal and inverse-gamma conjuate || prior. ||  || This module implements the :class:`bayeslite.IBayesDBMetamodel` || interface for the NIG-Normal model. || \""\""\""",,,Yes
38790,XXX WHATTAKLUDGE!,,Yes,Yes
38792,TODO Do this computation inside the database?,,,Yes
38793,"TODO This code is identical with \""initialize\"" except for the",,,Yes
38794,This assumes that models x columns forms a dense,,Yes,Yes
38795,TODO Filter in the database?,,No,Yes
38796,Note: The constraints are irrelevant because columns are,,No,Yes
38797,TODO Filter in the database?,,No,Yes
38801,High mean; tiny variance would lead to catastrophic cancellation,,Yes,Yes
38807,TODO: A way to be pleasant when the person wants to use the old version.,,,Yes
38808,TODO: It would be nice to be async about this. Set 1 second timeout.,,,Yes
38809,TODO: Should we be throwing instead?,,No,Yes
38811,XXX Colno?  Generator id?  ...?,,,Yes
38812,XXX fails on filenames with spaces.,,,Yes
38813,TODO: It would be nice to be async about this. Set 1 second timeout.,,Yes,Yes
38816,[(Exp*; XXX name)],,,Yes
38818,XXX Whattakludge!  Should we not also include colno;,,Yes,Yes
38819,XXX Colno?  Generator id?  ...?,,,Yes
38820,XXX This is a cop-out -- we should validate,,,Yes
38821,Ensure dependent columns if necessary.,,No,Yes
38822,XXX Hope no ' in temp.name...,,,Yes
38825,ESTIMATE * FROM COLUMNS OF:,,,Yes
38827,XXX This is necessary. sklearn cannot deal with missing values and,,Yes,Yes
38828,Not in this release; perhaps later.,,Yes,Yes
38829,XXX For whatever reason; a Python sqlite3 cursor for an empty query,,Yes,Yes
38836,XXX Let the user pass in a seed.,,,Yes
38838,client had released their null result cursor.  Why,,Yes,Yes
38839,TODO: currently appears unreliable; error is being used instead,,No,Yes
38843,XXX This kludgerosity (together with the tuple size dispatch,,,Yes
38845,XXX Make sure the whole cursor API works.,,Yes,Yes
38846,XXX These should be attributes of `setup'; but helpful distutils,,,Yes
38849,XXX Get the description first because apsw cursors; for,,Yes,Yes
38850,XXX apsw bug: There is no way to discover the description of a,,Yes,Yes
38851,is to assume that such a cursor has no columns either.  This is,,,Yes
38852,to fix that; change the sense of this conditional (and eliminate,,,Yes
38853,guess is bool. subsample is False or an int. columns is a list of pairs,,No,Yes
38854,XXX This is silly.  We should return log densities; not densities.,,Yes,Yes
38856,XXX This should be stored in the database by adding a column to the,,,Yes
38857,XXX Consider requiring setuptools,,Yes,Yes
38861,"to a BQLParseError.  Unsure what the \""ESTIMATE * FROM COLUMNS OF subquery\""",,Yes,Yes
38863,Sanity-check the result.  XXX Consider checking the full PEP 386,,Yes,Yes
38864,XXX Pass a 32-byte seed from weakprng once Crosscat supports,,Yes,Yes
38868,[DONE] Fix necessary XXX: fill bayesdb_cgpm_variable.,,Yes,Yes
38869,- Kludge up Kepler's laws in Python.,,Yes,Yes
38870,XXX Future TODO:,,Yes,Yes
38871,- Implement model tagging:,,No,Yes
38872,XXX Whattakludge!,,Yes,Yes
38875,XXX Is this integral correct?  Should it be weighted?,,,Yes
38877,XXX Subsampling?,,Yes,Yes
38878,XXX WHATTAKLUDGE for json,,,Yes
38879,XXX Parallelize me!  Push me into the engine!,,Yes,Yes
38880,XXX subsampling,,,Yes
38881,XXX error message if not modelled,,No,Yes
38887,XXX check schema,,Yes,Yes
38890,XXX check schema,,Yes,Yes
38894,XXX check change counts,,Yes,Yes
38895,XXX if (not) exists,,No,Yes
38896,XXX omit needless bayesdb_generator_column table,,,Yes
38898,XXX ifnotexists,,Yes,Yes
38902,Get only the columns that the feralcat models.,,Yes,Yes
38904,If there remain any variables that we needed to model; because,,,Yes
38905,XXX check for alphanumeric\/_,,,Yes
38906,XXX incremental model initialization,,,Yes
38907,XXX GUESS(*),,,Yes
38908,specify a prior weight (XXX and update some kind of posterior,,Yes,Yes
38909,XXX,,,Yes
38910,XXX Get some venturescript integration going.,,,Yes
38911,XXX subsampling,,No,Yes
38912,XXX Kepler source code.,,Yes,Yes
38917,XXX check agreement with statistical type,,,Yes
38918,XXX Why would you be here; anyway?,,Yes,Yes
38922,XXX check agreement with statistical type,,,Yes
38923,XXX WHATTA LUDICROUS LINE,,Yes,Yes
38924,XXX check agreement with statistical type,,Yes,Yes
38926,XXX Right way to find the stattype?,,Yes,Yes
38927,XXX WHATTA LUDICROUS LINE,,,Yes
38929,XXX check agreement with statistical type,,Yes,Yes
38930,XXX Punt confidence for now,,Yes,Yes
38932,XXX Why would you be here; anyway?,,,Yes
38933,XXX Punt confidence for now,,Yes,Yes
38934,XXX Right way to find the stattype?,,,Yes
38937,XXX check agreement with statistical type,,,Yes
38938,XXX check agreement with statistical type,,,Yes
38942,XXX Punt confidence for now,,Yes,Yes
38944,XXX WHATTA LUDICROUS LINE,,,Yes
38945,XXX Why would you be here; anyway?,,,Yes
38947,XXX Schema of [[]] instead of [] is kinda wacky.  Fix?  (But,,,Yes
38949,XXX check for alphanumeric\/_,,Yes,Yes
38950,XXX Show the constraints with symbolic names.,,,Yes
38951,XXX,,,Yes
38956,XXX TODO:,,No,Yes
38957,[DONE] Kludge up Kepler's laws in Python.,,Yes,Yes
38959,XXX Move these utilities elsewhere.,,Yes,Yes
38963,XXX FILL ME XXX,,,Yes
38964,XXX Catch a more specific exception.,,Yes,Yes
38965,be in needed.,,Yes,Yes
38967,XXX WHATT HACK. For CGPMs that support EXPOSING; the last L,,Yes,Yes
38971,XXX Cannot specify statargs for a latent variable. Trying to using,,,Yes
38973,XXX Convert all EXPOSED claues to latent clauses.,,,Yes
38974,XXX name,,Yes,Yes
38977,XXX change to lognormal.,,,Yes
38978,Extract the population columns and stattypes as pairs.,,No,Yes
38980,Extract the ignored columns.,,Yes,Yes
38981,Extract the guessed columns.,,,Yes
38982,XXX name,,Yes,Yes
38983,XXX Database name; &c.,,Yes,Yes
38986,XXX name,,Yes,Yes
38987,XXX helpful error checking if generators still exist,,,Yes
38988,XXX check change counts,,Yes,Yes
38992,XXX FIXME: Why is this code in a try-except block?,,,Yes
38993,TODO Perform error checking if the OPTIMIZED clause is used.,,Yes,Yes
38995,XXX Insert synthetic data generator here.,,Yes,Yes
38997,XXX Duplicated definitions for `nominal` and `categorical`.,,Yes,Yes
39001,XXX name,,Yes,Yes
39002,XXX This integral of the CMI returned by each model of all generators in,,Yes,Yes
39003,XXX Move to compiler.py.,,Yes,Yes
39004,XXX Copypasta of this in compile_simulate!,,No,Yes
39005,XXX Manual implementation of IF NOT EXISTS; skips computing query.,,,Yes
39007,XXX CreateTabSim is not necessary.  Eliminate it.,,,Yes
39009,XXX Disable SimulateModels without CreateTab,,Yes,Yes
39010,TODO Perform error checking if the OPTIMIZED clause is used.,,,Yes
39013,XXX This query returns an AssertionError because the LinearRegression,,No,Yes
39016,XXX Omit needless bayesdb_generator_column table,,Yes,Yes
39017,Ensure columns of unique floats are only taken to be keys when they are,,Yes,Yes
39018,Columns with unique ints and non-integer-valued floats cannot be keys.,,Yes,Yes
39019,XXX 1 Persist nan tokens into bdb; like oid tokens?,,Yes,Yes
39021,bql_row_similarity find the columns.,,Yes,Yes
39023,XXX Raise error about ignored constraints.,,Yes,Yes
39024,XXX Give meaningful names.,,No,Yes
39025,XXX Kinda silly way to store this in intermediate memory.,,Yes,Yes
39042,[XXX name],,,Yes
39045,XXX This is wrong -- it returns independent samples from,,No,Yes
39047,XXX Allow nontrivial accuracy?,,,Yes
39048,First expand any subquery columns.,,Yes,Yes
39049,XXX Unify determination of column names.,,No,Yes
39053,XXX Change [colno] to colno by updating IBayesDBMetamodel.,,,Yes
39054,XXX FIXME Github issue: https:\/\/github.com\/probcomp\/bayeslite\/issues\/484,,No,Yes
39057,XXX Report clearer error message with names.,,Yes,Yes
39059,XXX Kludge!,,Yes,Yes
39061,XXX FIXME Github issue: https:\/\/github.com\/probcomp\/bayeslite\/issues\/484,,No,Yes
39062,XXX Unify determination of column names.,,No,Yes
39065,XXX TODO: Move any items of cgpm_query_rowid which are not yet,,Yes,Yes
39067,XXX For now; each of these will be independent estimates.,,Yes,Yes
39069,XXX Two spaces after SELECT; due to compiler.compile_select_columns.,,,Yes
39070,bql_row_similarity find the columns.,,Yes,Yes
39071,XXX This mixes up target and reference variables; which is OK;,,No,Yes
39072,XXX Two spaces after SELECT; due to compiler.compile_select_columns.,,Yes,Yes
39074,Similarity with respect to multiple columns.,,,Yes
39077,XXX,,,Yes
39078,XXX FIXME Github issue: https:\/\/github.com\/probcomp\/bayeslite\/issues\/484,,No,Yes
39079,XXX Don't hard-code this.,,,Yes
39080,XXX TODO: Move any items of cgpm_query_rowid which are not yet,,Yes,Yes
39083,XXX This mixes up target and reference variables; which is OK;,,,Yes
39086,XXX fsaad@20170624: Setting modelnos = None arbitrarily; figure out,,Yes,Yes
39088,XXX fsaad@20170625: Setting modelnos = None arbitrarily; figure,,No,Yes
39091,TODO store the string-int transformations - use in logpdf,,Yes,Yes
39093,"TODO transform the data types (\""string to int reprisentation\"") and do ordering",,,Yes
39095,TODO optimize bdb calls,,Yes,Yes
39096,TODO don't ignore the context,,Yes,Yes
39097,TODO: cache server,,Yes,Yes
39099,Store ordering of columns,,Yes,Yes
39103,TODO race condition if bayesdb is case sensitive,,Yes,Yes
39104,TODO helper function,,No,Yes
39105,XXX Omit needless bayesdb_generator_column table --,,Yes,Yes
39106,TODO do we need schema?,,Yes,Yes
39109,XXX No column hyper transitions in lovecat.,,No,Yes
39110,XXX name,,Yes,Yes
39114,XXX No abstraction.,,,Yes
39115,Get the columns to migrate. Reject anything other than *.,,,Yes
39116,Get the columns to migrate.,,Yes,Yes
39118,Move period to a singleton in model 3.,,No,Yes
39119,TODO expose name overriding in iventure,,Yes,Yes
39121,TODO fix bug - colnos are not dense,,,Yes
39125,XXX Remove these imports.,,,Yes
39127,XXX This procedure appears to be computing the wrong thing.,,,Yes
39128,XXX Return a singleton list; since self._crosscat.similarity,,,Yes
39131,XXX Hackery for baselines.,,,Yes
39132,XXX name,,Yes,Yes
39133,XXX Why are the constraints being ignored? If Loom does not support,,Yes,Yes
39134,conditioning; then implement constraints using the simple Monte Carlo,,,Yes
39136,XXX This is going to cause a counts of 2.4 to evaluate to 2.,,No,Yes
39137,Better than having a StopIteration error coming from Loom.,,Yes,Yes
39138,XXX: what is the best way to set the seed here?,,,Yes
39139,XXX we may want to downscale this eventually.,,,Yes
39141,XXX: again; copy-pasta. Isn't this just csv_headers?,,Yes,Yes
39142,Otherwise; no marginalization is needed.,,,Yes
39143,XXX: wrong but quick;,,Yes,Yes
39144,XXX Insert synthetic data generator here.,,Yes,Yes
39145,conditioning; then implement constraints using the simple Monte Carlo,,,Yes
39147,Otherwise; no marginalization is needed.,,,Yes
39149,Release tags start with v* (XXX what about other tags starting with v?),,Yes,Yes
39150,that can be enabled manually when needed,,,Yes
39152,FIXME: last eojeol gets truncated (hotfixed),,,Yes
39153,TODO: do not replace unless explicitly noticed + add 'only hangul' option,,No,Yes
39154,FIXME: last eojeol gets truncated (hotfixed),,,Yes
39156,TODO: do not replace unless explicitly noticed,,,Yes
39157,TODO: do not replace unless explicitly noticed + add 'only hangul' option,,,Yes
39158,TODO: document replacements,,Yes,Yes
39159,TODO: check whether flattened results equal non-flattened,,No,Yes
39160,TODO: consider Python version,,,Yes
39162,TODO: progress bar,,,Yes
39163,TODO: Check if file has been properly installed,,,Yes
39165,Site's anti-bot policy may block crawling & you can consider gentle crawling,,,Yes
39170,THE MAIN RUNTIME FUNCTION ENDS,,No,Yes
39172,TODO: validation accuracy may not be the best metric to use,,,Yes
39173,add option to implement other metrics,,,Yes
39174,TODO: implement the alternative printing method,,Yes,Yes
39176,TODO describe what all this does,,,Yes
39177,runtime ends,,No,Yes
39179,input parameters section ends,,Yes,Yes
39181,TODO: the case where reduction_method,,No,Yes
39184,than the total number of bins (k*m)^N - which is why LHS is needed in the first place.,,Yes,Yes
39192,remove redundant columns,,No,Yes
39193,clear tensorflow sessions (maybe),,No,Yes
39194,TODO fix shuffle; figure out how it is supposed to work,,Yes,Yes
39196,initialize with random shuffle if needed,,No,Yes
39198,MOVE TO command specific tests,,Yes,Yes
39199,capture the parameter names for columns later,,,Yes
39200,continuous maybe; or too many classes,,No,Yes
39202,drop all other metric columns except reduction_metric,,,Yes
39203,convert all hyperparameter columns to multi label columns,,,Yes
39204,You can just specify the packages manually here if your project is,,Yes,Yes
39207,Provides and API-like functionality to search and access Wikipedia data,,,Yes
39210,TODO: Extend the context of this function,,,Yes
39211,"TODO: change this question to \""Who invented General Relativity\""",,Yes,Yes
39212,of data with the efficient Fast Fourier Transform (FFT) algorithm,,Yes,Yes
39213,TODO: audio has a wrong data type,,No,Yes
39214,"fix for situations like \""I 'AM\""; \""YOU 'LL\""",,Yes,Yes
39216,TODO: Replace all sess by self.sess (not necessary a good idea) ?,,Yes,Yes
39218,TODO: Natural sorting,,No,Yes
39219,TODO: Also show the top 10 most likely predictions for each predicted output (when verbose mode),,,Yes
39221,TODO: Summarize the output too (histogram; ...),,Yes,Yes
39226,Hack this to filter on subset of Opensubtitles,,Yes,Yes
39227,initializer=tf.truncated_normal_initializer()  # TODO: Tune value (fct of input size: 1\/sqrt(input_dim)),,,Yes
39230,Parameters of sampled softmax (needed for attention mechanism and a large vocabulary size),,No,Yes
39231,TODO: Should use a placeholder instead,,Yes,Yes
39232,better word representation,,Yes,Yes
39233,TODO: When the LSTM hidden size is too big; we should project the LSTM output into a smaller space (4086 => 2046): Should speed up,,,Yes
39234,TODO: Attach a summary to visualize the output,,No,Yes
39239,TODO: Should replace that by generator (better: by tf.queue),,No,Yes
39241,2nd step: filter the unused words and replace them by the unknown token,,No,Yes
39243,Map the full words ids to the new one (TODO: Should be a list),,,Yes
39247,Directly on server-side Q&A related API endpoints START,,,Yes
39248,A production-quality pure-Python WSGI server with very acceptable performance,,,Yes
39250,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
39252,A production-quality pure-Python WSGI server with very acceptable performance,,Yes,Yes
39253,Needed for raw and evoked-response data,,Yes,Yes
39254,XXX : todo,,,Yes
39255,XXX : fix? pb when tag.next < 0,,Yes,Yes
39256,Do the columns first,,,Yes
39258,XXX : fix,,Yes,Yes
39259,XXX: from,,,Yes
39260,XXX : see if better name,,Yes,Yes
39261,XXX : potential bug,,Yes,Yes
39263,XXX : fix,,Yes,Yes
39268,XXX : can do better,,,Yes
39270,Needed modules,,No,Yes
39271,XXX : should be improved later,,,Yes
39273,XXX : can be improved,,,Yes
39275,XXX : double because of mayavi bug,,Yes,Yes
39277,#    Select the columns of interest (convert to integers),,,Yes
39278,XXX really necessary?,,Yes,Yes
39279,XXX,,Yes,Yes
39280,better than nested.,,,Yes
39281,XXX : kind of ugly,,Yes,Yes
39282,XXX : check,,No,Yes
39283,XXX : check,,No,Yes
39284,XXX : check,,,Yes
39287,XXX,,,Yes
39290,"\""\""\"" XXX : bug !!! 2 make_compensator functions",,Yes,Yes
39292,"\""\""\""Do projection and compensation as needed",,,Yes
39293,print 'No forward operator compensator needed.',,,Yes
39295,% Move to another coordinate system in MEG channel channel info,,,Yes
39296,% Move to another coordinate system in EEG channel channel info,,Yes,Yes
39297,Rey's approach. MNE has been changed to implement this.,,,Yes
39298,XXX : check,,,Yes
39299,gain; Q_Cortex = bst_xyz2lf(gain; normals) # XXX,,Yes,Yes
39300,XXX : check,,,Yes
39302,XXX : check for artefacts,,No,Yes
39303,XXX : check artefacts,,No,Yes
39304,XXX : check,,No,Yes
39309,XXX can do better,,Yes,Yes
39311,"\""\""\"" || =================================================== || Compute induced power in the source space with dSPM || =================================================== ||  || XXX ||  || \""\""\""",,Yes,Yes
39313,XXX : can do better when no preload,,Yes,Yes
39314,XXX,,,Yes
39315,Move onto the valley,,Yes,Yes
39317,XXX,,Yes,Yes
39318,XXX : should use deepcopy but breaks ...,,Yes,Yes
39319,FIXME: abs?,,,Yes
39320,FIXME: abs?,,,Yes
39322,TODO: how to decide which filter to use,,Yes,Yes
39323,XXX: without float() endianness is wrong; not sure why,,,Yes
39325,The following is a hack that prevents this behavior by clearing the,,Yes,Yes
39326,it should probably not cause a crash).  Tested successfully,,,Yes
39327,XXX : how to handle depth_prior with fixed orientation?,,Yes,Yes
39331,XXX : don't import pylab here or you will break the doc,,,Yes
39334,XXX : recent pylab feature,,,Yes
39336,XXX : Back ported from statsmodels,,Yes,Yes
39338,XXX there is a bug here; the ordering of the stc_data is assumed,,,Yes
39339,HACK,,No,Yes
39342,By convention (Percival and Walden; 1993 pg 379),,,Yes
39343,A better approach is to iterate separately for each freq; but,,Yes,Yes
39344,XXX : we have a problem when proj are changed and preload is True,,,Yes
39346,Move points to origin,,Yes,Yes
39349,XXX : not exposed to the user,,,Yes
39352,a little bit faster. Unfortunately there's no way to tell numpy,,,Yes
39354,XXX These files should eventually be moved to the sample dataset and,,Yes,Yes
39355,TODO example broke somehow...,,,Yes
39357,"\""\""\"" || ========================================= || Visualize channel over epochs as an image || ========================================= ||  || This will produce what is sometimes called an event related || potential \/ field (ERP\/ERF) image. ||  || It is also demonstrated how to reorder the epochs using a 1d spectral || embedding as described in: ||  || Graph-based variability estimation in single-trial event-related neural || responses A. Gramfort; R. Keriven; M. Clerc; 2010; || Biomedical Engineering; IEEE Trans. on; vol. 57 (5); 1051-1061 || http:\/\/hal.inria.fr\/inria-00497023 || \""\""\""",,Yes,Yes
39358,However; rejection pefromance may significantly improve when using,,,Yes
39359,However; rejection pefromance may significantly improve when using,,,Yes
39360,"\""\""\"" || ============================================================ || Visualize channel over epochs as images in sensor topography || ============================================================ ||  || This will produce what is sometimes called an event related || potential \/ field (ERP\/ERF) image. ||  || One sensor topograpgy plot is produced the evoked field images from || selected channes. ||  || It is also demonstrated how to reorder the epochs using a 1d spectral || embedding as described in: ||  || Graph-based variability estimation in single-trial event-related neural || responses A. Gramfort; R. Keriven; M. Clerc; 2010; || Biomedical Engineering; IEEE Trans. on; vol. 57 (5); 1051-1061 || http:\/\/hal.inria.fr\/inria-00497023 || \""\""\""",,,Yes
39363,have to import verbose first since it's needed by many things,,Yes,Yes
39366,Equalize trial counts to eliminate bias (which would otherwise be,,Yes,Yes
39367,We only really care about t > 0; so crop to reduce multiple comparisons,,Yes,Yes
39368,XXX FOR NOW; JUST USE FIRST N,,,Yes
39369,"\""\""\""Compatibility fixes for older version of python; numpy and scipy ||  || If you add content to this file; please give the version of the package || at which the fixe is no longer needed. ||  || # XXX : copied from scikt-learn ||  || \""\""\""",,Yes,Yes
39371,XXX. The None cases helped revealing bugs but are time consuming.,,,Yes
39372,a little bit faster. Unfortunately there's no way to tell numpy,,Yes,Yes
39374,TODO:,,No,Yes
39375,XXX: this is the same as in fieldtrip; but it is it actually,,Yes,Yes
39377,todo cwt,,Yes,Yes
39378,todo cwt,,Yes,Yes
39380,hack to inlcude channel name; so we can show it in callback,,Yes,Yes
39381,friendly. The info columns 'epoch' and 'time' will be used as hierarchical,,Yes,Yes
39382,and the second the columns; that is; channels.,,,Yes
39386,XXX this should be fixed by a future PR...,,,Yes
39387,so we set it here. This is a hack as it can break other things,,Yes,Yes
39389,XXX use an intelligent guess,,,Yes
39390,XXX Need to actually check this on Windows at some point...,,Yes,Yes
39391,XXX reminder to remove this once upstream pysurfer is changed,,Yes,Yes
39392,This is strange on Windows XXX,,Yes,Yes
39394,XXX This is too low; need to figure it out...,,Yes,Yes
39395,Use presumably less efficient concatenating method,,No,Yes
39398,let's use an ugly; prime Fs for fun,,,Yes
39399,XXX it would be good to implement the moving window version for long,,,Yes
39401,XXX : should be fixed and not skipped,,,Yes
39402,"XXX Currently the fwd solns never have \""patch_areas\"" defined",,Yes,Yes
39405,compatible; but leaving them in breaks beamforming XXX,,Yes,Yes
39406,Move ahead the pointer if necessary,,Yes,Yes
39409,XXX WHY WAS THIS SET?,,No,Yes
39410,TODO,,,Yes
39414,XXX These lines should be commented out once forward reading bug,,,Yes
39416,XXX These lines should be commented out once forward reading bug,,,Yes
39418,XXX do something nicer!,,Yes,Yes
39421,needed.,,Yes,Yes
39425,Equalize trial counts to eliminate bias (which would otherwise be,,,Yes
39426,_; pvals = f_twoway_rm(data; [2; 3]; correction=True)  # XXX fix this,,Yes,Yes
39427,XXX fix this,,Yes,Yes
39428,XXX fix this,,Yes,Yes
39430,XXX : should find a wat to avoid the change to raw...,,Yes,Yes
39432,TODO: What about the case when a label is given to choose vertices? Does,,No,Yes
39433,TODO: The eigenvector associated with the smallest eigenvalue,,Yes,Yes
39435,XXX. at the moment we are committed to 1- \/ 2-sensor-types layouts,,,Yes
39436,# TODO: plot csp patterns!\uFFFF,,,Yes
39439,XXX improve later,,Yes,Yes
39440,3*4 --> case 2D matrix; ToDo calculate el_size through,,Yes,Yes
39441,ToDo consider 3D case --> do that by using tag->size,,,Yes
39442,ToDo Time Out,,Yes,Yes
39445,variables needed for receiving raw buffers,,Yes,Yes
39446,2 seconds XXX fix me,,Yes,Yes
39447,XXX fix this later. Bug in sklearn; see PR #2273,,,Yes
39449,TODO: I don't know what to do about SSPs and whitening; SSP should probably,,Yes,Yes
39452,should probably be used when using combined EEG and MEG data,,,Yes
39455,TODO: This should be reimplemented,,Yes,Yes
39457,TODO: DICS; in the original 2001 paper; used a free orientation beamformer;,,Yes,Yes
39459,TODO: The eigenvector associated with the smallest eigenvalue,,Yes,Yes
39461,TODO: Vectorize outside of the loop?,,No,Yes
39463,TODO: Time and frequency windows should be selected on the basis of e.g. a,,,Yes
39466,XXX : STC cannot contain (yet?) complex values,,Yes,Yes
39469,XXX for some reason --check does not work here.,,,Yes
39470,TODO: For multiple frequencies this should be set correctly,,Yes,Yes
39474,provisional. Maybe they could be more directly compared to dics()?,,Yes,Yes
39477,hide unused axes,,,Yes
39478,hide unused axes,,,Yes
39486,make sure evoked contains all the channels needed,,,Yes
39487,move by center,,,Yes
39488,Omit unused vertices from the neighborhoods,,No,Yes
39489,Set up the volume data (needed for creating the interpolation matrix),,,Yes
39490,(even though they aren't really head coords; won't matter),,Yes,Yes
39495,TODO: Is this check too restrictive? I.e. thick check won't fail only,,No,Yes
39497,TODO: Should be frequencies; but stcs for time windows are returned now,,,Yes
39499,TODO: Check win_lengths and freq_bins match in length,,No,Yes
39501,TODO: Use \/\/ and 1e3,,,Yes
39503,better than by multiplying by 1e3?!?,,Yes,Yes
39504,TODO: Allow selection of multitaper bandwidth for each window,,No,Yes
39506,TODO: Unnecessary; the case below solves this already!,,,Yes
39508,TODO: Do not manually set control\/baseline window!,,,Yes
39509,TODO: Check that there's enough data for baseline,,No,Yes
39510,TODO: Use all events,,,Yes
39512,TODO: Using 300 as last value leads to error; that's probably to be expected,,,Yes
39513,due to sampling frequency being roughly 600; but maybe should be investigated,,No,Yes
39516,TODO: Check that no time window is longer than tstep,,No,Yes
39517,TODO: Note that 0.3 \/ 0.05 produces 5.999! So n_overlap will be 5,,,Yes
39518,better than by multiplying by 1e3?!?,,Yes,Yes
39519,TODO: Results of tf_dics are really weird; this function's results should,,No,Yes
39521,TODO: Results of tf_dics are really weird; this function's results should,,No,Yes
39525,TODO: Note that 0.3 \/ 0.05 produces 5.999! So n_overlap will be 5,,Yes,Yes
39527,events = mne.read_events(event_fname)[:3]  # TODO: Use all events,,,Yes
39528,TODO: Use all events,,Yes,Yes
39531,TODO: This should be done using empty room noise,,,Yes
39532,TODO: Try a direct comparison to results of lcmv,,No,Yes
39533,XXX : why this?,,Yes,Yes
39535,XXX: there is a bug somewhere that causes a difference at 2 vertices..,,No,Yes
39536,cut below 7Hz to improve plot,,Yes,Yes
39537,otherwise we get an ugly nan,,,Yes
39538,XXX THIS IS WRONG; MUST BE EXPANDED TO BE ~160000 SQUARE AND SPARSE,,Yes,Yes
39540,Workspace needed?,,,Yes
39541,XXX Make subfunctions take vectors and vertno,,Yes,Yes
39543,ACTUALLY NEED THIS XXX,,,Yes
39544,Compensation channel information may be needed,,,Yes
39545,Compensation needed?,,Yes,Yes
39546,to the forward solution that we'll need to refactor XXX,,,Yes
39548,XXX dbg,,,Yes
39550,Do not know how we could get this XXX,,,Yes
39551,move hsp by translation parameters,,,Yes
39553,and apparently this does not happen by default:,,Yes,Yes
39554,get the version (don't import mne here; so dependencies are not needed),,,Yes
39555,XXX : deprecate CTF compensator,,,Yes
39556,XXX: there is a bug somewhere that causes a difference at 2 vertices..,,,Yes
39559,XXX don't ask me why,,Yes,Yes
39560,preallocation needed for min \/ max scaling,,,Yes
39562,XXX reminder to remove this once upstream pysurfer is changed,,,Yes
39564,mock new convention,,,Yes
39566,easy way,,,Yes
39569,easy way,,No,Yes
39570,this is needed in old versions of Python,,Yes,Yes
39571,This is a bit ugly; but it avoids running this again.,,Yes,Yes
39572,compute eplained variance manually; cf. sklearn bug fixed in #2664,,Yes,Yes
39573,fix start,,,Yes
39576,XXX Add SSP?,,Yes,Yes
39577,SVD is numerically better than the eigenvalue composition even if,,Yes,Yes
39578,XXX should be made much more efficient here,,,Yes
39579,XXX should be made more efficient here,,No,Yes
39580,XXX Wrap this to scipy.polynomial.legendre,,,Yes
39585,XXX for string types the data size is used as,,Yes,Yes
39588,(fix make_surface_mapping),,Yes,Yes
39589,XXX how much of the above keys do we need and shall return in,,Yes,Yes
39591,XXX : why not get_head_surf to be consistent with get_meg_helmet_surf ?,,,Yes
39592,SVD is numerically better than the eigenvalue composition even if,,,Yes
39594,fix onsets before buffer start,,Yes,Yes
39595,fix onsets before buffer start,,,Yes
39598,XXX : len(data_b) - len(train) is negative ??? is that expected?,,No,Yes
39599,XXX : will this work well with mixed channels type?,,Yes,Yes
39602,really clean warning stack,,No,Yes
39603,find an unused color (try shades of gray first),,Yes,Yes
39605,XXX unrelated bug? this crashes,,,Yes
39606,XXX unrelated bug? this crashes,,,Yes
39607,XXX unrelated bug? this crashes,,,Yes
39608,XXX should be deleted for 0.9 release,,No,Yes
39609,unused bytes are filled with 0. remove them,,Yes,Yes
39610,TODO: use a smaller data set,,,Yes
39612,TODO: zero-padding is not correct either.,,Yes,Yes
39613,TODO: put events from the annotation channel into,,Yes,Yes
39614,TODO: automatic detection of the tal_channel?,,No,Yes
39616,XXX : to be deprecated in 0.9,,No,Yes
39617,Hack: fake filter information so raw.filter won't throw an exception at us.,,,Yes
39618,XXX fix copy==True later. Bug in sklearn; see PR #2273,,Yes,Yes
39619,compute eplained variance manually; cf. sklearn bug,,No,Yes
39620,implement later,,,Yes
39621,XXX : next line is a hack don't ask why,,Yes,Yes
39622,XXX : make glob cleaner,,Yes,Yes
39627,convert sub-leadfield matrix to evoked data type (a bit of a hack),,,Yes
39628,TODO,,,Yes
39630,convert sub-leadfield matrix to evoked data type (a bit of a hack),,,Yes
39632,XXX debug,,,Yes
39633,XXX debug,,Yes,Yes
39634,XXX debug,,Yes,Yes
39635,XXX compare \/ debug,,Yes,Yes
39636,Calculate the number of kernels needed for each dimension,,Yes,Yes
39638,XXX : todo IO of TFRs,,,Yes
39639,XXX : next line is a hack don't ask why,,Yes,Yes
39645,move back surface to MRI coordinate system,,Yes,Yes
39646,XXX : don't import pyplot here or you will break the doc,,No,Yes
39648,hide unused axes,,,Yes
39649,Calculate the number of kernels needed for each dimension,,,Yes
39651,XXX TODO: This and the __repr__ in SourceSpaces should call a,,Yes,Yes
39653,Set up the volume data (needed for creating the interpolation matrix),,No,Yes
39654,XXX,,Yes,Yes
39656,XXX: save_bmp \/ save_png \/ ...,,,Yes
39659,XXX : find a better way to get max range of slices,,,Yes
39660,XXX : include mpld3 js libraries in html folder,,No,Yes
39661,XXX: save_bmp \/ save_png \/ ...,,,Yes
39665,hack due to MNE-C bug in IO of CTF,,,Yes
39666,Test creating grid layout with specified number of columns,,,Yes
39667,XXX: Fix these...,,Yes,Yes
39673,XXX: save_bmp \/ save_png \/ ...,,,Yes
39674,overwrite = options.overwrite  # XXX Not actually used anywhere,,Yes,Yes
39678,needed to inherit doc string,,Yes,Yes
39680,XXX pick 2 has epochs of zeros.,,,Yes
39681,XXX explore cuda optimazation at some point.,,,Yes
39683,action is needed to handle bad results.,,Yes,Yes
39684,XXX expose later,,,Yes
39685,if needed.,,Yes,Yes
39686,small hack; unscale; remean ...,,Yes,Yes
39687,XXX : here epochs.proj is true so it means the projs=True or False below,,Yes,Yes
39689,XXX : colors are not all visible on white background,,Yes,Yes
39693,Only needed to check Python version,,Yes,Yes
39694,TODO: handle arg tuples,,,Yes
39695,auto examples gallery to the build folder. This works fine as is; but it would be cleaner to,,Yes,Yes
39700,XXX,,,Yes
39701,TODO: deprecate keyword argument for TAL?,,No,Yes
39704,XXX Cross validation should be transformed into a make_cv; and,,,Yes
39705,XXX Good name?,,Yes,Yes
39706,XXX good name?,,Yes,Yes
39707,XXX I didn't manage to initalize correctly this array; as,,Yes,Yes
39708,XXX Problem here with scorer when proba=True but y !=  (0 | 1).,,No,Yes
39709,XXX Here I did not manage to find an efficient and generic way to guess,,Yes,Yes
39714,XXX but something seems buggy here anyways.,,,Yes
39716,XXX EHN: This loop should be parallelized in a similar way to fit(),,,Yes
39719,XXX JRK: Is there something to be done here?,,,Yes
39720,XXX JRK: Shall we print the repr from the DecodingTime() obj,,Yes,Yes
39722,XXX Sklearn doesn't like non-binary inputs. We could binarize the data;,,,Yes
39723,XXX potential Python incompatibility: no func_name attribute.,,Yes,Yes
39727,XXX @verbose,,Yes,Yes
39728,are what is needed:,,,Yes
39730,Export epochs data in tabular structure with MEG channels as columns,,,Yes
39731,and three additional info columns 'epoch'; 'condition'; and 'time'.,,Yes,Yes
39732,columns will be included in the table as categorial data.,,,Yes
39733,check that all needed points are present,,,Yes
39735,XXX Need API to identify propper scorer from the clf,,Yes,Yes
39736,XXX need API to identify how multiple predictions can be combined?,,Yes,Yes
39737,XXX,,Yes,Yes
39738,XXX,,Yes,Yes
39739,First make G fortran for faster access to blocks of columns,,No,Yes
39744,The code below is a more efficient version (~30x) of this:,,,Yes
39745,XXX: remove redundant read_evokeds,,,Yes
39746,XXX: this means (None; None) cannot be specified through command line,,Yes,Yes
39748,check that all needed points are present,,,Yes
39749,It is more memory efficient to load data in a separate,,,Yes
39750,TODO: write in equation numbers from Samu's paper,,,Yes
39751,TODO: Should factorial function use floating or long precision?,,Yes,Yes
39752,TODO fix look up of Legendre value,,,Yes
39753,TODO: Check how fast taking the real part of scipy's sph harmonic function is,,,Yes
39757,XXX This should be refactored to actually save memory!,,,Yes
39758,XXX what?,,Yes,Yes
39760,TODO: speed up by computing sph_harmonic only once and passing twice,,No,Yes
39761,XXX Check that this sum is correct,,No,Yes
39762,TODO; inds might be off by 1,,,Yes
39764,XXX Check that this sum is correct with Jussi's code,,Yes,Yes
39767,TODO: confirm that this equation follows the correct convention,,No,Yes
39770,TODO: Compute spherical harmonics,,No,Yes
39774,TODO: Check that [-m to m] convention is correct for all equations,,No,Yes
39775,TODO: Eventually; reuse code in field_interpolation,,Yes,Yes
39777,XXX Eventually this function could be refactored to save a lot of,,,Yes
39779,"XXX \""cals\"" here does not function the same way as in RawFIF;",,Yes,Yes
39780,XXX This is a hack to make sure this figure gets drawn last,,No,Yes
39782,preallocation needed for min \/ max scaling,,,Yes
39785,XXX This is a hack to make sure this figure gets drawn last,,No,Yes
39786,this we are going to use the following hack:,,No,Yes
39791,TODO: Eventually; reuse code in field_interpolation,,,Yes
39792,TODO: Find cleaner way to get channel info than reusing forward soln code,,Yes,Yes
39793,XXX : projs does not seem to be allowed to be a bool !!!,,,Yes
39795,ugly hack for making space for the title,,Yes,Yes
39797,TODO: needs vectorization; currently matching Jussi's code for debugging,,Yes,Yes
39798,XXX this could be made to work on non-preloaded data...,,No,Yes
39799,XXX this could operate on non-preloaded data; too,,Yes,Yes
39800,XXX this could be made to work on non-preloaded data...,,No,Yes
39801,XXX this could operate on non-preloaded data; too,,Yes,Yes
39802,silly fix for old numpy index error,,Yes,Yes
39803,XXX this could be made to work on non-preloaded data...,,No,Yes
39804,XXX this could operate on non-preloaded data; too,,,Yes
39805,XXX these do not work quite yet; indicative of a logic problem...,,Yes,Yes
39808,XXX this could operate on non-preloaded data; too,,Yes,Yes
39810,XXX this could be made to work on non-preloaded data...,,No,Yes
39813,XXX this could be made to work on non-preloaded data...,,,Yes
39815,TODO: determine appropriate pinv tolerance,,Yes,Yes
39817,First make G fortran for faster access to blocks of columns,,No,Yes
39820,TODO: Eventually refactor this in forward computation code,,Yes,Yes
39821,TODO: In fwd solution code; reformulate check that forces head,,,Yes
39822,coords and remove this hack. (Or use only head coords),,,Yes
39824,TODO: Improve logging process to better match Elekta's version,,,Yes
39825,Check that we have all coils needed,,,Yes
39826,TODO: Flesh out\/fix bookkeeping info,,Yes,Yes
39831,XXX refactor with _get_solids?,,,Yes
39835,XXX refactor with _get_solids?,,Yes,Yes
39836,TODO -> ica.exclude,,No,Yes
39839,reference needed for clicks,,,Yes
39840,XXX This is a hack to make sure this figure gets drawn last,,,Yes
39842,Furthermore; assigning to a preallocated array would be faster.,,Yes,Yes
39845,event types). Columns correspond to predictors; predictors correspond to,,Yes,Yes
39847,TODO Add checks for source space,,,Yes
39848,XXX should be deprecated after fixing simulate_sparse_stc,,,Yes
39849,XXX,,,Yes
39850,TODO: Get events object,,,Yes
39854,Get distances between vertices needed,,No,Yes
39855,TODO: Is this function general enough to go somewhere else?,,No,Yes
39857,When functionality is complete; expand raw object with this channel,,,Yes
39858,Could be *slightly* more efficient not to do this N times;,,Yes,Yes
39860,raw._data[event_ch; ].fill(0) XXX,,,Yes
39863,TODO: Add more localization accuracy functions. For example; distance between,,Yes,Yes
39866,XXX What should we check? that the data is having the same size?,,,Yes
39868,XXX should be deprecated after fixing simulate_sparse_stc,,,Yes
39869,TODO: Get events object,,Yes,Yes
39871,TODO: Figure out why timing gets slightly off,,Yes,Yes
39873,Get distances between vertices needed,,No,Yes
39874,TODO: Is this function general enough to go somewhere else?,,No,Yes
39875,TODO: Check below; what exactly does this do?,,,Yes
39882,XXX,,,Yes
39884,XXX do it in a function like simulate_data,,No,Yes
39887,FIXME use MNE cov estimator,,Yes,Yes
39888,FIXME use mne covariance estimator,,Yes,Yes
39889,XXX: This is going to fail if the init is a staticmethod; but,,Yes,Yes
39896,TODO: Add back in,,No,Yes
39902,XXX ?,,Yes,Yes
39904,TODO: JRK: Chunking times points needs to be simplified,,,Yes
39908,TODO: To further functionality; eventually expand raw object with,,Yes,Yes
39909,XXX make more robust,,No,Yes
39911,Figure out why tmax=0.5 doesn't work,,Yes,Yes
39913,this shouldn't happen; eventually we could add the transforms,,Yes,Yes
39914,ends up with t>t_end,,No,Yes
39917,XXX eventually we could speed this up by allowing the forward,,Yes,Yes
39919,there is probably a better algorithm for finding the bad ones...,,Yes,Yes
39921,XXX eventually calculate and add this; too,,Yes,Yes
39922,XXX eventually calculate this; too,,Yes,Yes
39923,XXX eventually calculate this,,,Yes
39925,TODO: Get comments on naming conventions from @staulu,,,Yes
39930,XXX For some reason on 14 Oct 2015 Travis started timing out on this,,Yes,Yes
39932,"\""\""\"" || ========================================================== || Identify similar ICs across multiple datasets via CORRMAP || ========================================================== ||  || After fitting ICA to multiple data sets; CORRMAP [1]_ || automatically identifies similar ICs in all sets based || on a manually selected template. These ICs can then be || removed; or further investigated. ||  || References || ---------- || .. [1] Viola FC; et al. Semi-automatic identification of independent components ||        representing EEG artifact. Clin Neurophysiol 2009; May; 120(5): 868-77. || \""\""\""",,Yes,Yes
39934,temp hack,,No,Yes
39935,TODO: Exclude 'bads' in multipolar moment calc; add back during,,Yes,Yes
39937,XXX for some reason this list has a bunch of junk in the last entry:,,,Yes
39940,XXX we should just be able to do S_tot \/= coil_scale here; but,,,Yes
39941,error; so we leave it split here (perf hit is hopefully minimal),,,Yes
39942,"This is the \""seismology\"" convention on Wikipedia; w\/o Condon-Shortley",,,Yes
39943,Now normalize our columns,,Yes,Yes
39944,XXX These should really be better...,,Yes,Yes
39946,XXX should go before,,,Yes
39949,XXX for some reason this list can have a bunch of junk,,,Yes
39958,We could convert to real at the end; but it's more efficient,,Yes,Yes
39959,Eventually we could probably refactor this for 2x mem (and maybe CPU),,,Yes
39960,effectively what would happen by earlier multiply,,No,Yes
39961,XXX Some strange MPL\/3.5 error...,,Yes,Yes
39962,We use the same convention for ex as for Neuromag planar,,Yes,Yes
39965,Now normalize our columns,,,Yes
39968,XXX Eventually we could do cross-talk and fine-cal here,,,Yes
39969,"XXX eventually we could add \""auto\"" mode here",,,Yes
39971,1. Implement minimum-norm version,,Yes,Yes
39972,XXX Eventually we could do cross-talk and fine-cal here,,,Yes
39976,XXX this KIT origin fit is terrible! Need to fix it before release :(,,No,Yes
39978,XXX JRK: Still 12 % of cpu time.,,,Yes
39982,XXX we should improve this,,Yes,Yes
39983,XXX : check,,No,Yes
39986,Alternatively; you may also create PSDs from Raw objects with psd_XXX,,Yes,Yes
39988,work around for mpl bug,,Yes,Yes
39989,XXX hpicons?,,Yes,Yes
39990,XXX use distances from digitization; not initial fit?,,Yes,Yes
39991,XXX eventually high-pass filtering to get rid of interference?,,Yes,Yes
39992,XXX eventually high-pass filtering to get rid of interference?,,Yes,Yes
39994,XXX support sklearn < 0.18,,Yes,Yes
39995,XXX broken ...,,Yes,Yes
39996,XXX support sklearn < 0.18,,,Yes
39997,XXX we cannot pass any other parameters than X and y to cv.split,,Yes,Yes
39999,TODO: np.array scores from initialization JRK,,Yes,Yes
40001,HACK development version...,,Yes,Yes
40002,HACK replace mag data with grad_norm!,,Yes,Yes
40004,XXX Need to add interactivity to the patches so click-to-show,,,Yes
40005,XXX These calls could probably be made faster by using collections,,,Yes
40007,XXX see below...,,Yes,Yes
40009,FIXME the last dipole happens to have max gof; but plot_topomap fails!,,,Yes
40010,FIXME why doesn't 'diff = evoked - pred_evoked' work?!? (just returns evoked),,Yes,Yes
40011,FIXME the last dipole happens to have max gof; but plot_topomap fails!,,Yes,Yes
40014,XXX,,Yes,Yes
40015,XXX,,,Yes
40016,XXX: Buffer size different to c version,,Yes,Yes
40018,XXX JRK: full wavelet decomposition needs to be implemented,,Yes,Yes
40020,bit of a hack to avoid projection warnings,,,Yes
40021,"If doing \""inplace\"" mode; \""fix\"" the projectors to only operate",,Yes,Yes
40022,bit of a hack to avoid projection warnings,,Yes,Yes
40023,"\""Fix\"" projectors after subselection",,Yes,Yes
40024,potentially *much* more memory efficient to do it the iterative way,,,Yes
40025,The pure-string uses the more efficient numpy-based method; the,,Yes,Yes
40027,XXX: Bug in matplotlib won't allow setting the position of existing,,No,Yes
40028,This shouldn't happen; but if it does; we can probably come,,Yes,Yes
40029,TODO:,,,Yes
40031,- 20 unused channels,,Yes,Yes
40032,The head tracking channels and the unused channels are marked as misc,,Yes,Yes
40033,from sample numbers to seconds is needed:,,No,Yes
40034,visible around 170 ms in both conditions but much stronger in the standard,,,Yes
40035,efficient IO which loads the data on demand. However; filtering and some,,Yes,Yes
40036,The event list contains three columns. The first column corresponds to,,,Yes
40037,"\""\""\"" || Artifact Correction with ICA and SSP || ==================================== ||  || ICA finds directions in the feature space || corresponding to projections with high non-Gaussianity. We thus obtain || a decomposition into independent components; and the artifact\u2019s contribution is || localized in only a small number of components. || These components have to be correctly identified and removed. ||  || If EOG or ECG recordings are available; they can be used in ICA to automatically || select the corresponding artifact components from the decomposition. To do so; || you have to first build an Epoch object around blink or heartbeat event:: ||  || \""\""\""",,,Yes
40038,"\""\""\"" || .. _tut_erp: ||  || EEG processing and Event Related Potentials (ERPs) || ================================================== ||  || XXX : montage; referencing; rois (help help jona !) ||  || \""\""\""",,,Yes
40039,analysis pipeline. That's why it's recommended to set bad channels,,Yes,Yes
40040,XXX : TODO after brainstorm PR is merged,,,Yes
40041,and look into the cause of the rejections. Maybe it's just a matter,,Yes,Yes
40042,"\""\""\"" || .. _tut_artifacts_intro: ||  || Introduction: dealing with artifacts || ==================================== ||  || Since MNE supports the data of many different acquisition systems; the || particular artifacts in your data might behave very differently from the || artifacts you can observe in our tutorials and examples. ||  || Therefore you should be aware of the different approaches and of || the variability of artifact rejection (automatic\/manual) procedures described || onwards. At the end consider always to visually inspect your data || after artifact rejection or correction. ||  || Background: what is an artifact? || -------------------------------- ||  || Artifacts are signal interference that can be || endogenous (biological) and exogenous (environmental). || Typical biological artifacts are head movements; eye blinks || or eye movements; heart beats. The most common environmental || artifact is due to the power line; the so-called *line noise*. ||  || How to handle artifacts? || ------------------------ ||  || MNE deals with artifacts by first identifying them; and subsequently removing || them. Detection of artifacts can be done visually; or using automatic routines || (or a combination of both). After you know what the artifacts are; you need || remove them. This can be done by: ||  ||     - *ignoring* the piece of corrupted data ||     - *fixing* the corrupted data ||  || For the artifact detection the functions MNE provides depend on whether || your data is continuous (Raw) or epoch-based (Epochs) and depending on || whether your data is stored on disk or already in memory. ||  || Detecting the artifacts without reading the complete data into memory allows || you to work with datasets that are too large to fit in memory all at once. || Detecting the artifacts in continuous data allows you to apply filters || (e.g. a band-pass filter to zoom in on the muscle artifacts on the temporal || channels) without having to worry about edge effects due to the filter || (i.e. filter ringing). Having the data in memory after segmenting\/epoching is || however a very efficient way of browsing through the data which helps || in visualizing. So to conclude; there is not a single most optimal manner || to detect the artifacts: it just depends on the data properties and your || own preferences. ||  ||  || For how to detect artifacts visually or automatically || see ref:`tut_artifacts_detect`. ||  || For how to correct artifacts by rejection see ref:`tut_artifacts_reject`. || To discover how to correct certain artifacts by filtering see || ref:`tut_artifacts_filtering` and to learn how to correct artifacts || with subspace methods like SSP and ICA see ref:`tut_artifacts_ica_ssp` || \""\""\""",,Yes,Yes
40043,"\""\""\"" || .. _tut_erp: ||  || EEG processing and Event Related Potentials (ERPs) || ================================================== ||  || For a generic introduction to the computation of ERP and ERF || see :ref:`tut_epoching_and_averaging`. Here we cover the specifics || of EEG; namely:: ||  ||     - setting the reference ||     - using standard montages :func:`mne.channels.Montage` ||  || XXX : ROI plots? ||  || \""\""\""",,Yes,Yes
40044,pandas data frames the columns stand for channels and rows for times. Notice,,Yes,Yes
40045,"\""\""\"" ||  || .. _tut_artifacts_correct_ica_ssp: ||  || Artifact Correction with ICA and SSP || ==================================== ||  || ICA finds directions in the feature space || corresponding to projections with high non-Gaussianity. We thus obtain || a decomposition into independent components; and the artifact\u2019s contribution is || localized in only a small number of components. || These components have to be correctly identified and removed. ||  || If EOG or ECG recordings are available; they can be used in ICA to || automatically select the corresponding artifact components from the || decomposition. To do so; you have to first build an Epoch object around || blink or heartbeat event. || \""\""\""",,,Yes
40047,red -> before; black -> after. Yes! We remove quite a lot!,,Yes,Yes
40048,In MNE-Python option 2 is easily achievable and it might be better;,,,Yes
40050,It is a FIF file that ends with -trans.fif. It can be obtained with,,No,Yes
40051,#NAME?,,Yes,Yes
40054,XXX Eventually de-duplicate with _kind_dict of mne\/io\/meas_info.py,,Yes,Yes
40055,XXX cmoutard: does it make any sense to average single_power across,,,Yes
40060,XXX: New version of matplotlib has this implemented for radio buttons;,,Yes,Yes
40061,XXX Need to extend this to more than 1000 samples for long IIR filters!,,No,Yes
40062,time domain (i.e.; infinite order) to be realized. Another way to think of,,Yes,Yes
40064,entire second. So this na\u00EFve method is probably not a good way to build,,,Yes
40066,MNE-Python also offers IIR filtering functionality that is based on the,,,Yes
40070,Ideally we would have the fine calibration and cross-talk information,,Yes,Yes
40074,no longer needed,,Yes,Yes
40076,XXX support sklearn.cross_validation cv,,No,Yes
40077,XXX the z-scoring is applied outside the CV; which is not standard.,,,Yes
40080,1) it's numpy computation so it's already efficient;,,,Yes
40081,Seems to be a good way to exclude single clicks.,,Yes,Yes
40083,XXX: Use _check_estimator #3381,,No,Yes
40085,XXX update this after deprecation of ba,,Yes,Yes
40088,pass-band; but also within the transition and stop-bands -- perhaps,,Yes,Yes
40090,FIXME: not sure how to design,,,Yes
40094,No phase in multitaper XXX Check ?,,,Yes
40095,FIXME: to avoid overheads we should use np.array_split(),,,Yes
40096,Inter-trial phase locking is apparently computed per taper...,,Yes,Yes
40097,XXX : should be refactored with combined_evoked function,,Yes,Yes
40098,allow us to do this in a nice way. Instead; we increase our filter,,Yes,Yes
40100,XXX Fix when Python 2.6 support is dropped!,,,Yes
40101,XXX Fix when Scipy 0.12 support is dropped!,,Yes,Yes
40102,XXX: could possibly be refactored; plot_joint is doing a similar thing,,,Yes
40104,because we move out of the MNE stack; so warnings won't properly,,,Yes
40105,XXX datasets match only when baseline is applied to both;,,Yes,Yes
40107,new convention,,No,Yes
40108,XXX should de-duplicate with make_ad_hoc_cov,,Yes,Yes
40111,XXX This one fails due to grads being combined but this proj having,,,Yes
40114,Pull the first two columns since they're meaningful for 2d plotting,,No,Yes
40116,FIXME: to avoid overheads we should use np.array_split(),,No,Yes
40117,Inter-trial phase locking is apparently computed per taper...,,,Yes
40118,XXX : should be refactored with combined_evoked function,,Yes,Yes
40120,check that all needed points are present,,Yes,Yes
40121,check that all needed points are present,,Yes,Yes
40122,naming convention 'Artemis_Data_YYYY-MM-DD-HHh-MMm_[chosen by user].bin',,,Yes
40124,Scipy spectrogram (for mne.time_frequency.psd_welch) needed for scipy < 0.16,,Yes,Yes
40126,XXX: deprecation,,,Yes
40129,But to speed it up; we really need to read multiple blocks at once;,,Yes,Yes
40133,XXX we should fix this:,,No,Yes
40134,XXX: _fake_click raises an error on Agg backend,,,Yes
40135,XXX: In mpl 1.5 you can do: fig.radio.value_selected,,,Yes
40137,dialogs which interrupt the tests. This workaround triggers,,No,Yes
40138,XXX this should be refactored with mne.surface.get_head_surf ...,,,Yes
40140,XXX this could be refactored more with e.g.; plot_evoked,,No,Yes
40144,"\""\""\"" || =============================== || Visualize subject head movement || =============================== ||  || Show how subjects move as a function of time. || \""\""\""",,,Yes
40145,XXX: _fake_click raises an error on Agg backend,,Yes,Yes
40147,Events objects are essentially numpy arrays with three columns:,,,Yes
40148,Finally; we can write events to disk. Remember to use the naming convention,,Yes,Yes
40149,"\""\""\"" || =========================================================== || Explore event-related dynamics for specific frequency bands || =========================================================== ||  || The objective is to show you how to explore spectrally localized || effects. For this purpose we adapt the method described in [1]_ and use it on || the somato dataset. The idea is to track the band-limited temporal evolution || of spatial patterns by using the Global Field Power (GFP). ||  || We first bandpass filter the signals and then apply a Hilbert transform. To || reveal oscillatory activity the evoked response is then subtracted from every || single trial. Finally; we rectify the signals prior to averaging across trials || by taking the magniude of the Hilbert. || Then the GFP is computed as described in [2]_; using the sum of the squares || but without normalization by the rank. || Baselining is subsequently applied to make the GFPs comparable between || frequencies. || The procedure is then repeated for each frequency band of interest and || all GFPs are visualized. To estimate uncertainty; non-parametric confidence || intervals are computed as described in [3]_ across channels. ||  || The advantage of this method over summarizing the Space x Time x Frequency || output of a Morlet Wavelet in frequency bands is relative speed and; more || importantly; the clear-cut comparability of the spectral decomposition (the || same type of filter is used across all bands). ||  || References || ---------- ||  || .. [1] Hari R. and Salmelin R. Human cortical oscillations: a neuromagnetic ||        view through the skull (1997). Trends in Neuroscience 20 (1); ||        pp. 44-49. || .. [2] Engemann D. and Gramfort A. (2015) Automated model selection in ||        covariance estimation and spatial whitening of MEG and EEG signals; ||        vol. 108; 328-342; NeuroImage. || .. [3] Efron B. and Hastie T. Computer Age Statistical Inference (2016). ||        Cambrdige University Press; Chapter 11.2. || \""\""\""",,Yes,Yes
40150,Digitized HPI points are needed.,,Yes,Yes
40151,move into MNE head coords,,No,Yes
40152,This is a little hack (aliasing while decimating) to make it much faster,,No,Yes
40154,version (unused here),,No,Yes
40155,remove border around figure,,,Yes
40156,XXX Eventually this should be de-duplicated with the MNE-MATLAB stuff...,,Yes,Yes
40158,hack due to MNE-C bug in IO of CTF,,No,Yes
40162,XXX do projections here if necessary,,,Yes
40163,hack for coverage,,Yes,Yes
40166,XXX Fix when Scipy 0.12 support is dropped!,,Yes,Yes
40168,computationally more efficient to manually accumulate and,,,Yes
40169,should really be int-like anyway,,,Yes
40170,- ias : For Internal Active Shielding data (maybe on Triux only).,,Yes,Yes
40171,Adjust DC and maybe Nyquist; depending on one-sided transform,,Yes,Yes
40172,XXX It would be nice to support non oct source spaces too...,,,Yes
40175,filename of the resulting downloaded archive (only needed if the URL,,Yes,Yes
40176,original folder names that get extracted (only needed if the,,Yes,Yes
40177,finally; where we want them to extract to (only needed if the folder name,,,Yes
40178,XXX put back,,,Yes
40179,This should really only happen when a hash is wrong,,,Yes
40180,XXX eventually this should probably live in montage.py,,No,Yes
40181,XXX eventually this could just call convert_forward_solution,,,Yes
40183,add meg picks if needed.,,Yes,Yes
40184,morph map maybe missing,,,Yes
40185,"\""\""\"" || ================================== || Querying epochs with rich metadata || ================================== ||  || Selecting a subset of epochs based on rich metadata. ||  || MNE allows you to include metadata along with your :class:`mne.Epochs` objects. || This is in the form of a :class:`pandas.DataFrame` that has one row for each || event; and an arbitrary number of columns corresponding to different || features that were collected. Columns may be of type int; float; or str. ||  || If an :class:`mne.Epochs` object has a metadata attribute; you can select || subsets of epochs by using pandas query syntax directly. Here we'll show || a few examples of how this looks. || \""\""\""",,Yes,Yes
40186,"\""\""\"" || ================================================ || Pandas querying and metadata with Epochs objects || ================================================ ||  || Demonstrating pandas-style string querying with Epochs metadata. || For related uses of :class:`mne.Epochs`; see the starting tutorial || :ref:`sphx_glr_auto_tutorials_plot_object_epochs.py`. ||  || Sometimes you've got a more complex trials structure that cannot be easily || summarized as a set of unique integers. In this case; it may be useful to use || the ``metadata`` attribute of :class:`mne.Epochs` objects. This must be a || :class:`pandas.DataFrame` where each row corresponds to an epoch; and each || column corresponds to a metadata attribute of each epoch. Columns must || contain either strings; ints; or floats. ||  || In this dataset; subjects were presented with individual words || on a screen; and the EEG activity in response to each word was recorded. || We know which word was displayed in each epoch; as well as || extra information about the word (e.g.; word frequency). ||  || Loading the data || ---------------- || First we'll load the data. If metadata exists for an :class:`mne.Epochs` || fif file; it will automatically be loaded in the ``metadata`` attribute. || \""\""\""",,Yes,Yes
40187,hack fix for windows to avoid bincount problems,,,Yes
40189,the better the approximation; but the longer it takes).,,,Yes
40190,The first three columns show the parametric and non-parametric statistics,,Yes,Yes
40191,The next three columns show multiple comparison corrections of the,,Yes,Yes
40193,XXX should put a good list of default colors into defaults.py,,,Yes
40197,so that _orth_svdvals thresholding should work properly with,,Yes,Yes
40201,XXX conditional necessary because of annoying behavior of,,Yes,Yes
40204,"XXX eventually we should update the normals whenever \""points\"" is changed",,Yes,Yes
40205,XXX eventually this should be refactored with the cHPI fitting code;,,Yes,Yes
40206,"XXX eventually we should update the normals whenever \""points\"" is changed",,,Yes
40207,KDTree is really only faster for huge (~100k) sets;,,,Yes
40209,XXX there might be a cleaner way to do this someday,,,Yes
40210,move to head coords,,No,Yes
40211,XXX This should be de-duplicated with LCMV,,,Yes
40213,FIXME: not make this hardcoded,,Yes,Yes
40215,sample dataset; scaled to implement the desired SNR.,,Yes,Yes
40218,Not sure if there is a better way to normalize.,,,Yes
40219,Hack to fix nibabel problems; see,,Yes,Yes
40220,XXX: change to default=True in 0.17,,,Yes
40221,XXX: change to default=True in 0.17,,,Yes
40223,XXX cov objects don't include compensation_grade,,,Yes
40225,Set coil_type (does FT supply this information somehow?),,Yes,Yes
40226,TODO This next call in principle should fail.,,Yes,Yes
40227,This is needed for python 2 and 3 compatibility,,,Yes
40230,XXX this code does not do any checking for compensation channels;,,,Yes
40231,FIXME: ideally; we would not use the middle column of the events,,Yes,Yes
40232,array to store the duration. A better solution would be using,,,Yes
40233,multiplexed; channels in columns,,,Yes
40234,XXX we should pass src to _make_stc,,,Yes
40238,XXX eventually this should not be in meas; but a property of BaseRaw,,No,Yes
40240,XXX : ugly hack to avoid picking subset of info with applied comps,,,Yes
40241,XXX do we need this?,,,Yes
40242,XXX we should pass src to _make_stc,,Yes,Yes
40243,XXX : ugly hack to avoid picking subset of info with applied comps,,,Yes
40245,XXX when it's refactored; Report._render_raw will need to be updated,,,Yes
40247,matrix; where to each vertex (rows) at multiple time points (columns) a value,,,Yes
40253,XXX; TODO: this should be a function; method or something.,,Yes,Yes
40255,XXX this function should be expanded to handle other divergent colormaps,,Yes,Yes
40256,XXX: check lines below,,,Yes
40257,XXX We should fix this; but it's hard to get nilearn to,,Yes,Yes
40260,"\""\""\"" || Optically pumped magnetometer (OPM) data || ======================================== ||  || In this dataset; electrical median nerve stimulation was delivered to the || left wrist of the subject. Somatosensory evoked fields were measured using || nine QuSpin SERF OPMs placed over the right-hand side somatomotor area. || Here we demonstrate how to localize these custom OPM data in MNE. || \""\""\""",,,Yes
40261,3D convex hull (will fail for 2D geometry; can extend later if needed),,Yes,Yes
40262,XXX : why not passing ch_type???,,Yes,Yes
40263,XXX : anonymize should rather subtract a random date,,,Yes
40266,we should fix at some point (if possible -- could be HDF5 limitation),,,Yes
40267,XXX see discussion gh-5574; this is necessary due to the fact,,Yes,Yes
40268,XXX this is broken; dm.point_names is used. Sometimes we say this should,,Yes,Yes
40269,If using modern VTK\/Mayavi; improve rendering with FXAA,,Yes,Yes
40270,This ensures that rendering with front-\/back-face culling works properly,,Yes,Yes
40272,read_raw_xxx -> EOF -> verbose() -> BaseRaw.__init__ -> get_argvalues,,Yes,Yes
40274,XXX we can use rank='' to deprecate to get to None eventually:,,No,Yes
40275,XXX this could maybe use pca=True to avoid needing to use,,Yes,Yes
40276,XXX 'hf_sef' and 'misc' do not conform to these standards,,,Yes
40277,XXX eventually should be refactored with data_path,,Yes,Yes
40279,XXX Eventually this could be made to deal with rank deficiency properly,,No,Yes
40282,needed until SciPy 1.2.0 is released,,,Yes
40283,it is often more intuitive to think about how :math:`x(t)` is composed of,,No,Yes
40286,"but in general \""shrunk\"" is usually better",,,Yes
40288,SciPy writing bug that pops up sometimes:,,Yes,Yes
40292,FIXME: we should probably reset __new__ for full generality,,Yes,Yes
40293,10 really should be sufficient...,,Yes,Yes
40295,because we move out of the MNE stack; so warnings won't properly,,Yes,Yes
40297,XXX : this should use the to appear compute_rank function,,Yes,Yes
40299,XXX: `tal_ch_names` to pass to `_check_stim_channel` should be computed,,,Yes
40300,XXX see discussion gh-5574; this is necessary due to the fact,,,Yes
40303,move back,,No,Yes
40304,Hack the first channel data to store the desired selection in epoch data,,No,Yes
40306,Pull the first two columns since they're meaningful for 2d plotting,,No,Yes
40308,subjects_url = BASE_URL + 'SC-subjects.xls'  # XXX not used,,,Yes
40309,XXX this BASE_URL does not match the one in _utils.py,,,Yes
40311,XXX This is inside the loop; guaranteeing a single iter!,,,Yes
40312,XXX eventually this could just call convert_forward_solution,,Yes,Yes
40313,XXX this should be float32 probably due to how we save and,,Yes,Yes
40315,XXX eventually we should unify how channel types are handled,,,Yes
40317,XXX for now it just uses the total count,,,Yes
40318,"XXX this should be \""rank\"" not \""rank_orig\""; see gh-5146",,,Yes
40320,this problem goes away; but the test is much slower.,,,Yes
40321,temporary option until we can fix things,,Yes,Yes
40322,XXX default scalings mis-estimate sometimes :(,,Yes,Yes
40323,XXX we can use rank='' to deprecate to get to None eventually:,,,Yes
40325,XXX This is inside the loop; guaranteeing a single iter!,,Yes,Yes
40326,needed for backward compat: EVENT type 3 has the same structure as type 2,,Yes,Yes
40327,XXX stim_channel_toggle is used because stim_channel was in use already,,,Yes
40328,XXX long NumEvents is available; why are not we using it?,,Yes,Yes
40329,"XXX: the data has \""05\/10\/200 17:35:31\"" so it is set to None",,Yes,Yes
40330,columns of u; rows of v,,Yes,Yes
40334,XX eventually we should probably get this lower,,,Yes
40336,this is a hack to avoid using a deleled ren_win,,,Yes
40339,XXX eventually we could speed this up by allowing the forward,,Yes,Yes
40343,"Note that some of the columns are transformed to \""category\"" data types.",,Yes,Yes
40345,Restrict the new label to the vertices of the input label if needed.,,Yes,Yes
40346,ctf_head_t should not be needed,,,Yes
40350,"assert the new interpol correlates at least .05 \""better\""",,,Yes
40353,loaded into memory (by default it's only read from disk as-needed); so we'll,,,Yes
40354,needed to create an :class:`~mne.Epochs` object; which we create with the,,No,Yes
40355,(they're accessed from disk only when needed); but here we'll force loading,,Yes,Yes
40356,XXX recent MPL throws an error for 3D axis aspect setting; not much,,,Yes
40357,XXX Eventually we should figure out where the resulting point is;,,Yes,Yes
40366,extension you provide. By convention; MNE-Python expects events files to,,,Yes
40368,.. TODO replace above sentence when the relevant tut is ready:,,,Yes
40370,XXX: all points are supposed to be in FIFFV_COORD_HEAD,,,Yes
40371,move into MNE head coords,,,Yes
40372,ctf_head_t should not be needed,,Yes,Yes
40375,XXX: most probably the functions needing this; should go somewhere else,,No,Yes
40377,location is also configurable; see the documentation of any of the,,Yes,Yes
40378,".. TODO change \""in a later tutorial\"" to crossref when the projectors tutorial",,Yes,Yes
40380,the `10-20 <ten_twenty>`_ or `10-05 <ten_oh_five>`_ systems; or perhaps it,,Yes,Yes
40381,XXX we should really support this at some point,,No,Yes
40382,XXX this should be supported someday,,Yes,Yes
40383,.. TODO: discuss annotation snapping in the below bullets,,,Yes
40384,.. TODO: When projectors tutorials are done; add this:,,Yes,Yes
40386,is a temporary workaround of:,,,Yes
40393,.. TODO: add EOG\/ECG examples to,,Yes,Yes
40395,XXX: This is kept for back compatibility; we should check the logic,,,Yes
40396,XXX: to be removed when deprecating montage,,Yes,Yes
40398,XXX this could be refactored more with e.g.; plot_evoked,,No,Yes
40399,XXX when it's refactored; Report._render_raw will need to be updated,,Yes,Yes
40400,Needed because the data do not match the info anymore.,,,Yes
40401,XXX we should really support this at some point,,No,Yes
40403,check for compatible `fig` \/ `axes`; instantiate figs if needed; add,,,Yes
40405,around 20 seconds; so in this case a cutoff of 0.1 Hz would probably suppress,,,Yes
40406,.. TODO: An example of slow-drift removal is shown in {crossref to filter,,Yes,Yes
40407,computes online averages; these can be a good way to spot bad channels as,,No,Yes
40408,but that can lead to a dramatic drop in data rank (and ends up discarding a,,No,Yes
40409,XXX This fails until PR #6439 is merged.,,No,Yes
40410,"\""\""\""Utility functions to speed up linear algebraic operations. ||  || In general; things like np.dot and linalg.svd should be used directly || because they are smart about checking for bad values. However; in cases where || things are done repeatedly (e.g.; thousands of times on tiny matrices); the || overhead can become problematic from a performance standpoint. Examples: ||  || - Optimization routines: ||   - Dipole fitting ||   - Sparse solving ||   - cHPI fitting || - Inverse computation ||   - Beamformers (LCMV\/DICS) ||   - eLORETA minimum norm ||  || Significant performance gains can be achieved by ensuring that inputs || are Fortran contiguous because that's what LAPACK requires. Without this; || inputs will be memcopied. || \""\""\""",,,Yes
40411,XXX: the following line fixes curious SEGFAULT when,,Yes,Yes
40412,just a consumer to move around conveniently,,Yes,Yes
40413,XXX: there should be a nicer way to do that,,,Yes
40414,we only need 3 values from res4. Maybe we can read them directly instead,,Yes,Yes
40415,manually by setting the ``ica.exclude`` attribute. Similar to marking bad,,Yes,Yes
40418,resolves out a little better:,,,Yes
40419,Much better! Now we've captured both ICs that are reflecting the heartbeat,,No,Yes
40420,- In general; larger values of ``st_duration`` are better (provided that your,,,Yes
40421,Eventually this could perhaps live in SG.,,,Yes
40422,XXX eventually this should be stored in ch['loc'][3:6],,Yes,Yes
40424,check that all needed points are present,,Yes,Yes
40425,XXX: why this is returned as empty list instead of None?,,Yes,Yes
40427,XXX: point_names.append('HPI%03d' % d['ident']),,,Yes
40432,XXX: shall we make it a Transform? rather than np.array,,Yes,Yes
40434,XXX: This scaling business seems really dangerous to me.,,Yes,Yes
40435,XXX: this should change,,Yes,Yes
40436,XXX: hack this should go!!,,Yes,Yes
40437,dig_montage.transform_to_head()  # XXX: this call had no effect!!,,Yes,Yes
40438,XXX this function should be moved out of coreg as used elsewhere,,,Yes
40439,XXX: to remove in 0.20,,Yes,Yes
40442,XXX : should desappear in 0.20,,Yes,Yes
40444,XXX: this does not check ch_names + it cannot work because of write_dig,,,Yes
40446,might appear as a completely flat channel; or the software might subtract out,,Yes,Yes
40448,.. TODO what are the cases where you might need to customize the ECG filter?,,No,Yes
40449,.. TODO should advice for filtering here be the same as advice for filtering,,Yes,Yes
40452,to edit a report once it's no longer in-memory in an active Python session;,,No,Yes
40453,XXX: This should be dead code; but is deeply buried in,,,Yes
40458,XXX: dig_ch_pos['EEG%03d' % d['ident']] = d['r'],,Yes,Yes
40459,XXX: to split as _parse like bvct,,Yes,Yes
40460,Fix pos to match Montage code,,Yes,Yes
40461,XXX: This code was duplicated !!,,Yes,Yes
40462,XXX: to unify with digitization,,Yes,Yes
40464,XXX eventually this should go away,,Yes,Yes
40465,"\""\""\"" || .. _ica: ||  || ================================================== || Background on Independent Component Analysis (ICA) || ================================================== ||  || .. contents:: Contents ||    :local: ||    :depth: 2 ||  || Many M\/EEG signals including biological artifacts reflect non-Gaussian || processes. Therefore PCA-based artifact rejection will likely perform worse at || separating the signal from noise sources. || MNE-Python supports identifying artifacts and latent components using temporal ICA. || MNE-Python implements the :class:`mne.preprocessing.ICA` class that facilitates applying ICA || to MEG and EEG data. Here we discuss some || basics of ICA. ||  || Concepts || ======== ||  || ICA finds directions in the feature space corresponding to projections with high non-Gaussianity. ||  || - not necessarily orthogonal in the original feature space; but orthogonal in the whitened feature space. || - In contrast; PCA finds orthogonal directions in the raw feature ||   space that correspond to directions accounting for maximum variance. || - or differently; if data only reflect Gaussian processes ICA and PCA are equivalent. ||  ||  || **Example**: Imagine 3 instruments playing simultaneously and 3 microphones || recording mixed signals. ICA can be used to recover the sources ie. what is played by each instrument. ||  || ICA employs a very simple model: :math:`X = AS` where :math:`X` is our observations; :math:`A` is the mixing matrix and :math:`S` is the vector of independent (latent) sources. ||  || The challenge is to recover :math:`A` and :math:`S` from :math:`X`. ||  ||  || First generate simulated data || ----------------------------- || \""\""\""",,,Yes
40466,XXX: the rest of the message is deprecated. to remove in 0.20,,,Yes
40467,XXX: deprecated. to remove in 0.20 (raise_if_subset; too),,No,Yes
40470,XXX: This require loading loc.,,Yes,Yes
40471,XXX: write forces head,,No,Yes
40473,XXX: missing reader,,,Yes
40474,XXX: This is a workaround to get the previous behavior.,,Yes,Yes
40475,XXX: who grants 'head'?? this is BACKCOMPAT but seems a BUG,,,Yes
40480,XXX: this should actually race an error 346 != 4,,,Yes
40490,often recorded with sampling rates around 1000 Hz or higher. This is good,,,Yes
40491,are not of interest and precise timing is not needed (e.g.; computing EOG or,,Yes,Yes
40492,"hack the src_to \""zooms\"" to make it seem like a pos=20. source space",,Yes,Yes
40494,in everything below indices refer to columns,,No,Yes
40495,columns for bad channels will be zero,,Yes,Yes
40496,remove columns for bad channels,,,Yes
40500,Add transparency if needed,,No,Yes
40502,XXX but these we should fix eventually:,,Yes,Yes
40503,XXX should also verify that | is used rather than ; to separate params,,No,Yes
40504,XXX should maybe also restore the parameter-desc-length < 800 char check,,Yes,Yes
40508,peak ampl. per location across columns,,,Yes
40509,to inf -- then the 1. \/ s below will turn this to zero; as needed.,,Yes,Yes
40514,needed to create an :class:`~mne.Epochs` object; which we create with the,,No,Yes
40515,The MNE-Python naming convention for epochs files is that the file basename,,,Yes
40516,provide does not adhere to that convention.,,Yes,Yes
40518,A convenient way to visualize many epochs simultaneously is to plot them as,,Yes,Yes
40525,XXX: most probably the functions needing this; should go somewhere else,,No,Yes
40529,XXX ideally functions using layout + head would be refactored not to,,,Yes
40530,to skip the loading step by passing the filename string directly to the,,Yes,Yes
40531,similar functionality to,,Yes,Yes
40532,"\""\""\"" || .. _tut-epochs-metadata: ||  || Working with Epoch metadata || =========================== ||  || This tutorial shows how to add metadata to :class:`~mne.Epochs` objects; and || how to use :ref:`Pandas query strings <pandas:indexing.query>` to select and || plot epochs based on metadata properties. ||  || .. contents:: Page contents ||    :local: ||    :depth: 2 ||  || For this tutorial we'll use a different dataset than usual: the || :ref:`kiloword-dataset`; which contains EEG data averaged across 75 subjects || who were performing a lexical decision (word\/non-word) task. The data is in || :class:`~mne.Epochs` format; with each epoch representing the response to a || different stimulus (word). As usual we'll start by importing the modules we || need and loading the data: || \""\""\""",,Yes,Yes
40533,:class:`pandas.DataFrame` containing one row for each epoch. The columns of,,No,Yes
40534,Like any :class:`pandas.DataFrame`; you can modify the data or add columns as,,Yes,Yes
40539,prepare extra columns \/ multiindex,,,Yes
40541,prepare extra columns \/ multiindex,,Yes,Yes
40544,TODO: this might be a bad idea as sometimes random noise might correlate,,,Yes
40545,XXX just the sensor; where is ref (next 3)?,,Yes,Yes
40546,XXX need to check\/ensure this,,Yes,Yes
40548,there is probably a better algorithm for finding the bad ones...,,,Yes
40553,prepare extra columns \/ multiindex,,Yes,Yes
40554,prepare extra columns \/ multiindex,,Yes,Yes
40555,:class:`~pandas.DataFrame`; alongside three additional columns of event name;,,Yes,Yes
40556,columns:,,,Yes
40557,It is also possible to move one or more of the indicator columns (event name;,,,Yes
40558,XXX someday we could choose to weight these points by their goodness,,Yes,Yes
40559,of fit somehow.,,,Yes
40560,XXX this angtol is not great but there is a hard to,,Yes,Yes
40562,2 cm\/s is not great but probably fine,,,Yes
40565,XXX eventually this should be called in the window resize callback,,Yes,Yes
40566,XXX in theory we should set inv['source_cov'] properly.,,Yes,Yes
40569,move gif to fname,,Yes,Yes
40570,just for our hack,,,Yes
40573,control this by passing an empty :class:`list` to the ``exclude`` parameter,,Yes,Yes
40574,XXX this should be refactored with set_time_point so that interp1d,,Yes,Yes
40575,XXX this should be refactored with set_time_point so that interp1d,,,Yes
40577,TODO: @classmethod: write() on GUI?,,,Yes
40580,in manual mode: if n < total; things probably got wrong,,Yes,Yes
40581,py2: maybe magically removed already,,Yes,Yes
40582,TODO: check this doesn't overwrite another fixed bar,,,Yes
40587,XXX temporary hidden workaround for memory problems on CircleCI,,No,Yes
40588,someone passing True\/False is much more likely to be an error than,,,Yes
40589,XXX temporary hidden workaround for memory problems on CircleCI,,No,Yes
40590,XXX for some reason doing this on Azure causes access violations:,,,Yes
40591,fix position,,,Yes
40592,XXX someday we should refactor this so that you don't have to pass,,Yes,Yes
40593,method -- maybe `prepare_inverse_operator` should add a `method`,,Yes,Yes
40594,XXX vector someday?,,No,Yes
40596,XXX this is a bug; it should be populated...,,No,Yes
40597,XXX eventually we could speed this up by allowing the forward,,Yes,Yes
40598,these formats better.,,Yes,Yes
40599,XXX this rtol should be better...?,,,Yes
40603,XXX once volumes are supported; this should move to BaseSourceEstimate,,Yes,Yes
40604,XXX we don't check pca_flip; probably should someday...,,Yes,Yes
40607,XXX: remove with 0.22 once captrCK is deprecated,,Yes,Yes
40610,TODO: iterating over each tube rather than plotting in,,,Yes
40611,XXX old defs here apparently (maybe not realistic)?,,Yes,Yes
40612,so it shouldn't really add appreciable overhead,,Yes,Yes
40613,XXX this should probably be deprecated because it returns surface Labels;,,,Yes
40614,XXX this also assumes that the first two source spaces are surf without,,,Yes
40616,XXX : line above should work but does not as only last step is,,,Yes
40617,XXX adding this step breaks,,Yes,Yes
40619,XXX needs to support vector; too,,,Yes
40621,"\""\""\""Generic wrapper function read_raw for specific read_raw_xxx readers.\""\""\""",,,Yes
40625,check setting number of columns,,,Yes
40627,just a consumer to move around conveniently,,,Yes
40628,hack these; others (kind; type) should be correct,,,Yes
40630,XXX CSD is wrong...,,,Yes
40632,above. But we can also see another channel exceeding the limits; apparently,,,Yes
40633,XXX: remove with 0.22,,,Yes
40634,XXX: remove with 0.22 once captrCK is deprecated,,,Yes
40635,XXX old defs here apparently (maybe not realistic)?,,Yes,Yes
40639,XXX undo once size is fixed,,Yes,Yes
40640,this will not be I\/O efficient; but will be mem efficient,,,Yes
40641,FreeSurfer convention; we look at :file:`T1.mgz`; which gets created from the,,Yes,Yes
40643,TODO: Restore this?,,No,Yes
40644,TODO: Still not stable,,No,Yes
40645,singular values are unsigned; move the sign into v,,,Yes
40648,XXX someday we should probably expose the origin,,Yes,Yes
40649,"XXX should probably support the \""origin\"" argument",,Yes,Yes
40652,better than ECD + sphere,,,Yes
40653,which rows and columns each type of visual needs to be added to,,No,Yes
40655,views are columns,,,Yes
40656,XXX for sided data; we probably actually need two,,,Yes
40659,normals and pickable are unused,,Yes,Yes
40660,eliminate invalid tris and zero out unused rrs,,,Yes
40661,"\""\""\"" || .. _tut-artifact-regression: ||  || Repairing artifacts with regression || =================================== ||  || This tutorial covers removal of artifacts using regression as in Gratton et al. || (1983) :footcite:`GrattonEtAl1983`. ||  || .. contents:: Page contents ||    :local: ||    :depth: 2 ||  || Generally speaking; artifacts that result in time waveforms on the sensors || that are accurately reflected by some reference signal can be removed by || regression. Blink artifacts captured by bipolar EOG channels serve as a good || example of this; so we will demonstrate this here. ||  || Although ECG signals are well captured by bipolar ECG electrodes; || regression-based removal of ECG artifacts usually does not work very well. || This is likely because the heart acts like a rotating dipole; and || therefore the ECG channel time waveform recorded from the ECG electrode sites || does not reflect the same temporal dynamics that manifest at each MEG channel || (obtained by sampling some component of the related magnetic vector field). || Other approaches like :ref:`ICA <tut-artifact-ica>` or || :ref:`SSP <tut-artifact-ssp>` will likely work better for ECG. ||  || Prepare the data || ^^^^^^^^^^^^^^^^ ||  || We begin as always by importing the necessary Python modules and loading some || data. In this case we use data from :ref:`Brainstorm <tut-brainstorm-auditory>` || because it has some clear; large blink artifacts. We then crop it to 60 || seconds; set some channel information; then process the auditory evoked data. ||  || Note that there are other corrections that are useful for this dataset that we || will not apply here (see :ref:`tut-brainstorm-auditory` for more information). || \""\""\""",,Yes,Yes
40663,I have no idea why; but MF transposes this for storage..,,Yes,Yes
40665,left click (and maybe drag) in progress in axes,,,Yes
40666,unused headlight,,,Yes
40668,XXX BDF data for these is around 0.01 when it should be in the uV range;,,,Yes
40670,XXX this should be True,,Yes,Yes
40672,sections and subsections currently unused,,Yes,Yes
40675,TODO: utilize state and var_type in code.,,,Yes
40678,move back surface to MRI coordinate system,,,Yes
40679,TODO: Support more than one controlblock and more than one datablock,,Yes,Yes
40684,XXX this fails: or n_pca_components == 8:,,,Yes
40685,XXX this case should warn?,,,Yes
40687,very useful for debugging; might as well leave it in,,Yes,Yes
40691,HELP BUTTON: ...move it down by changing its locator,,,Yes
40694,"below; value \"" \"" is a hack to make \""\ || \"".split(value) have length 1",,,Yes
40695,TODO: rclick_name,,,Yes
40697,TODO: we would like useblit=True here; but MPL #9660 prevents it,,Yes,Yes
40698,XXX older MPL doesn't have circle.set_center,,,Yes
40700,XXX when matplotlib 3.3 is min version; replace this with,,,Yes
40701,XXX gs = fig.add_gridspec(15; 1),,No,Yes
40704,add more traces if needed,,,Yes
40706,draw scalebars maybe,,No,Yes
40709,turn off draggable mode; then move a bit,,,Yes
40710,XXX workaround: plt.close() doesn't spawn close_event on Agg backend,,,Yes
40711,XXX this fails with minimal deps,,,Yes
40712,XXX currently no-op,,,Yes
40717,XXX end PyVista,,,Yes
40718,XXX old mpl,,,Yes
40719,downloads if needed,,,Yes
40720,:meth:`apply <mne.SourceMorph.apply>`. This approach is more efficient,,Yes,Yes
40722,XXX we need to require these except when doing simplify_info,,,Yes
40723,We finally found exactly what we needed. Sometimes this can take a bit of,,,Yes
40724,XXX,,Yes,Yes
40725,XXX even just a pure scaling does not work very well; bug...,,,Yes
40728,XXX uncomment these lines for debugging help with volume morph,,Yes,Yes
40729,XXX,,Yes,Yes
40730,FIX: https:\/\/github.com\/pyvista\/pyvistaqt\/pull\/68,,Yes,Yes
40731,XXX workaround: plt.close() doesn't spawn close_event on Agg backend,,No,Yes
40734,normalise to maximum norm across columns,,No,Yes
40736,XXX possibly some error in dipy or nibabel (\/SciPy); or some boundary,,No,Yes
40737,This is the same as the following; but more efficient:,,,Yes
40738,XXX: remove with 0.22 once captrCK is deprecated,,Yes,Yes
40739,chpi not needed; and unhashable (a list),,No,Yes
40740,Data ends just before this.,,,Yes
40742,source\/detector combinations are represented as columns.,,No,Yes
40743,Detectors are represented as columns.,,,Yes
40745,XXX should eventually round-trip,,No,Yes
40747,TODO: defaults to 'auto' in v0.22,,Yes,Yes
40749,XXX: Weird that real_filter happens *before* whitening; which could,,,Yes
40750,"XXX it's a bug that our rank functions don't treat \""meg\""",,Yes,Yes
40754,needed for vertex tc,,Yes,Yes
40756,Could eventually be added but probably not worth the effort unless someone,,No,Yes
40757,XXX remove first two rows. It is unknown currently if there is a way to,,Yes,Yes
40758,XXX This hack defines what extra methods numpydoc will document,,,Yes
40759,hack to initialize the Mayavi Engine,,Yes,Yes
40760,XXX currently (0.3.dev0) messes with style,,,Yes
40761,Eventually this could perhaps live in SG.,,Yes,Yes
40762,themselves; which is hopefully safe enough.,,Yes,Yes
40764,Fix columns,,Yes,Yes
40766,But seriously: this was a nice idea; but we've reached the limit of,,Yes,Yes
40767,Check we have columns all events,,,Yes
40768,The names of the remaining columns correspond to the event names specified in,,,Yes
40769,the ``all_event_id`` dictionary. These columns contain floats; the values,,,Yes
40773,Adding new columns to describe stimulation side and response correctness,,,Yes
40775,Exactly like in the previous example; create new columns ``stimulus_side``,,Yes,Yes
40776,XXX for some reason doing this on Azure causes access violations:,,No,Yes
40777,left click (and maybe drag) in progress in axes,,Yes,Yes
40779,needed for vertex tc,,Yes,Yes
40780,XXX disable for sprint because it's too unreliable,,No,Yes
40781,artifacts and achieve better frequency resolution when filtering must,,No,Yes
40782,Reordering should fix,,No,Yes
40783,Fix resize grip size,,No,Yes
40784,XXX power normally not used as csd cannot get_data(),,No,Yes
40785,XXX This hack defines what extra methods numpydoc will document,,,Yes
40786,hack to initialize the Mayavi Engine,,Yes,Yes
40787,XXX currently (0.3.dev0) messes with style,,No,Yes
40789,Convert any MLlib Vector columns to scipy.sparse.csr_matrix,,Yes,Yes
40791,TODO once pyspark\/ml\/common.py is present in the snapshot; get rid of this painful hack.,,Yes,Yes
40792,checking itself would require some serious mocking),,,Yes
40794,TODO use this instead of pickle? from pyspark.serializers import CloudPickleSerializer,,,Yes
40795,TODO org imports,,Yes,Yes
40796,estimator at most once. This becomes a bit difficult because then extraneous non-input,,Yes,Yes
40798,User keys are just [0; NUSERS); repeated for each key if there are multiple columns.,,,Yes
40799,Sorts rows in dataframes by sortby. If sortby is None then all columns are used.,,,Yes
40802,Must have key columns,,Yes,Yes
40805,TODO,,Yes,Yes
40806,TODO: implement maze add,,,Yes
40807,TODO: implement maze add,,Yes,Yes
40808,TODO: implement maze add,,Yes,Yes
40810,Read it manually instead of with gensim so we can stream large models,,,Yes
40811,HACK I disabled this check.,,Yes,Yes
40812,used for python.  XXX What about mingw; borland; and so on?,,,Yes
40814,no parameters; parameters are needed,,Yes,Yes
40820,Calculates the number of dimensions needed to prevent hashing from,,Yes,Yes
40822,Calculates the number of dimensions needed to prevent hashing from,,,Yes
40823,Calculates the number of dimensions needed to prevent hashing from,,,Yes
40824,Calculates the number of dimensions needed to prevent hashing from,,,Yes
40825,Calculates the number of dimensions needed to prevent hashing from,,Yes,Yes
40827,Calculates the number of dimensions needed to prevent hashing from,,Yes,Yes
40828,Calculates the number of dimensions needed to prevent hashing from,,,Yes
40829,Calculates the number of dimensions needed to prevent hashing from,,Yes,Yes
40831,limitations may prevent large .magnitude files with many columns,,No,Yes
40832,limitations may prevent large .magnitude files with many columns,,No,Yes
40834,Import any additional modules needed (to register custom classes).,,,Yes
40835,"u\""\""\"" || The ``make-vocab`` subcommand allows you to create a vocabulary from || your dataset[s]; which you can then reuse without recomputing it || each training run. ||  || .. code-block:: bash ||  ||    $ allennlp make-vocab --help ||  ||     usage: allennlp make-vocab [-h] [-o OVERRIDES] [--include-package INCLUDE_PACKAGE] param_path ||  ||     Create a vocabulary from the specified dataset. ||  ||     positional arguments: ||     param_path            path to parameter file describing the model and its ||                           inputs ||  ||     optional arguments: ||     -h; --help            show this help message and exit ||    -s SERIALIZATION_DIR; --serialization-dir SERIALIZATION_DIR ||                            directory in which to save the vocabulary directory ||     -o OVERRIDES; --overrides OVERRIDES ||                           a JSON structure used to override the experiment ||                           configuration ||     --include-package INCLUDE_PACKAGE ||                             additional packages to include || \""\""\""",,,Yes
40836,Hack because e.g. typing.Union isn't a type.,,,Yes
40838,Hack for RNNs,,Yes,Yes
40839,Hack in our Optimizer class to the trainer,,Yes,Yes
40841,Anything with a from_params method is itself configurable.,,,Yes
40842,"\""non_padded_namespaces\""; \""min_count\"" etc. can be set if needed.",,,Yes
40844,TODO(Mark): Remove this once tqdm cleans up after itself properly.,,,Yes
40847,NLTK is so performance orientated (ha ha) that they have lazy imports. Why? Who knows.,,Yes,Yes
40848,This is un-needed and clutters the label space.,,Yes,Yes
40850,above; some of these functions have unused arguments.,,,Yes
40852,should find a better way to loosen those bounds; or let people extend them.  E.g.; we could have,,,Yes
40855,of instances each epoch; and we didn't specify how to many instances to load,,,Yes
40856,There's enough logic here to require a custom from_params.,,Yes,Yes
40858,the multiple calls to util.batched_index_select below more efficient.,,Yes,Yes
40859,we're using attention with ``DotProductSimilarity``; this is needed.,,,Yes
40862,NOTE(markn): This is a hack because 0-dim pytorch tensors are not iterable.,,,Yes
40864,TODO (pradeep): Assuming all worlds give the same set of valid actions.,,Yes,Yes
40865,sequence currently. Maybe define top-k metrics?,,,Yes
40866,TODO (pradeep): The denotation based cost below is strict. May be define a cost based on,,,Yes
40867,TODO (pradeep): Make this cleaner.,,Yes,Yes
40870,TODO (pradeep): Assuming all worlds give the same set of valid actions.,,Yes,Yes
40871,TODO (pradeep): Use an unindexed field for labels?,,,Yes
40872,TODO(pradeep): Can move most of this block to super class.,,Yes,Yes
40873,TODO(pradeep): Most of the functionality in this black can be moved to the super,,,Yes
40875,TODO(mattg): this could probably be moved into a FullSequenceMatch metric; or something.,,Yes,Yes
40876,Is (sequence_length; batch_size); but all the columns are the same; so take the first.,,Yes,Yes
40877,reshape the input if needed,,,Yes
40880,Masks for the unused states of shape (1; new_batch_size; 1),,,Yes
40882,"u\""\""\"" || An implementation of the OpenAI Transformer Language Model. ||  || Mostly just a slightly modified version of || https:\/\/github.com\/huggingface\/pytorch-openai-transformer-lm || so thanks to them! ||  || Some of these modules duplicate code elsewhere in AllenNLP; || but the serialized weights depend on the exact parameter setup || here; so it's easiest to just reimplement them. || \""\""\""",,Yes,Yes
40883,numpy can't read from a tarfile directly; so we need a workaround,,,Yes
40884,We want `exclusive` span ends for the backward direction,,,Yes
40886,As we added 1 to the span_ends to make them exclusive; which might have caused indices,,Yes,Yes
40888,These span widths are off by 1; because the span ends are `inclusive`.,,Yes,Yes
40889,We're using <= here (and for the mask below) because the span ends are,,Yes,Yes
40890,There are no classes to decorate; so we hack these into Registrable._registry,,,Yes
40891,lists of a `DecoderState` subclass and output structures with the subclass.  Really ugly that we,,,Yes
40892,TODO(pradeep): Move this method to nn.decoding.util,,Yes,Yes
40893,"Looking for lambda productions; but not for cells or columns with the word \""lambda\"" in",,Yes,Yes
40894,There are no classes to decorate; so we hack these into Registrable._registry,,,Yes
40897,TODO(mattg): We should merge how this works with how the `WikiTablesAccuracy` metric works; maybe,,Yes,Yes
40901,Following Sempre's convention for naming cells.,,Yes,Yes
40903,linking score won't have any way to differentiate them...  We should figure,,Yes,Yes
40904,out a better way to handle this.,,Yes,Yes
40905,appear in the logical forms; we have a way of specifying ``constant_type_prefixes`` and passing,,Yes,Yes
40906,"u\""\""\"" || This module defines some classes that are generally useful for defining a type system for a new || domain. We inherit the type logic in ``nltk.sem.logic`` and add some functionality on top of it || here. There are two main improvements: || 1) Firstly; we allow defining multiple basic types with their own names (see ``NamedBasicType``). || 2) Secondly; we allow defining function types that have placeholders in them (see || ``PlaceholderType``). || We also extend NLTK's ``LogicParser`` to define a ``DynamicTypeLogicParser`` that knows how to deal || with the two improvements above. || \""\""\""",,Yes,Yes
40908,"TODO(pradeep): Assuming the mapping of \""var\"" function is \""V\"". Do something better.",,,Yes
40909,this; it's just something that works for now; that we can fix later if \/ when it's needed.,,,Yes
40911,TODO (pradeep): This is messy. Fix the type declaration so that we don't have to deal,,,Yes
40912,cells and columns and a few simple numbers; so we can get them as valid actions in the,,Yes,Yes
40913,NLTK has a naming convention for variable types. If the world has predicate or entity names beyond,,,Yes
40914,"u\""\""\"" || This is a tiny webapp for generating configuration stubs for your models. || It's very hacky and very experimental; so don't rely on it for anything important. ||  || ``` || python -m allennlp.service.config_explorer || ``` ||  || will launch the app on `localhost:8123` (you can specify a different port if you like). ||  || It can also incorporate your own classes if you use the `include_package` flag: ||  || ``` || python -m allennlp.service.config_explorer \\ ||     --include-package my_library || ``` || \""\""\""",,No,Yes
40917,With 100 instances; shuffling better change the order.,,,Yes
40919,Some recent efficiency changes (using bmm for `weighted_sum`; the more efficient,,Yes,Yes
40924,Best path would normally be [3; 2; 3] but we add a,,Yes,Yes
40926,Most of these are instance-specific production rules.  These are the columns in the,,Yes,Yes
40927,"We add columns to the name mapping in sorted order; so \""league\"" and \""year\"" end up as C2",,,Yes
40928,check for unused regex,,,Yes
40929,Only the 'loss' is needed.,,Yes,Yes
40930,Save model if needed.,,,Yes
40931,TODO: if elmo pass entire 2d thing to vectors_for_keys and,,,Yes
40932,unused_docs = [],,,Yes
40933,This includes the functionality marked as experimental in SQLite 3.,,,Yes
40934,A hack we dont't document,,No,Yes
40935,Another hack.  Visual Studio 2008 & 2010 ship with 64,,No,Yes
40936,scripts I have ever seen.  This hack just sets some environment,,,Yes
40937,Work around SQLite 3.7.13 bug where a symbol was,,No,Yes
40938,ends up as part of the source distribution.,,,Yes
40939,the better,,,Yes
40940,check same number and names and order for columns,,Yes,Yes
40943,should be way quicker.,,Yes,Yes
40944,::TODO:: check collations,,No,Yes
40945,error cases ok; return real values and move on to cursor methods,,Yes,Yes
40948,implemented unicode properly.,,Yes,Yes
40950,Straight forward backup.  The gc.collect() is needed because,,No,Yes
40951,wrong number of columns,,,Yes
40952,we run all the tests multiple times which has better coverage,,Yes,Yes
40954,"\""\""\""This file runs the test suite against several versions of SQLite || and Python to make sure everything is ok in the various combinations. || It only runs on a UNIX like environment. ||  || All the work is done in parallel rather than serially.  This allows || for it to finish a lot sooner. ||  || \""\""\""",,,Yes
40956,py2&3 compatible way of doing this,,Yes,Yes
40957,portable workaround with a decorated list instead,,Yes,Yes
40958,work around textwrap bug,,,Yes
40968,evaluate hash in all columns,,,Yes
40969,# TODO: might be buggy,,,Yes
40970,# TODO: maybe no need,,,Yes
40972,TODO: more assertion here,,No,Yes
40973,TODO: try sampled teacher forcing,,,Yes
40974,TODO: more assertion here,,No,Yes
40975,TODO: more assertion here,,,Yes
40986,FIXME: move args definition\/parsing inside of main?,,,Yes
40990,most stupid code ever -- Fix it !,,Yes,Yes
40991,most stupid code ever -- Fix it !,,,Yes
1306,TODO: revise this method!,,,Yes
1496,TODO: This position is right?,,Yes,Yes
1962,TODO: those numbers are some kind of meaningless; since we just,,Yes,Yes
2633,TODO: add boundary stuff?,,,Yes
2845,TODO target max size,,Yes,Yes
3086,"\""\""\"" || Qi et al. || An efficient sparse metric learning in high-dimensional space via L1-penalized log-determinant regularization || ICML 2009 ||  || Adapted from https:\/\/gist.github.com\/kcarnold\/5439945 || Paper: http:\/\/lms.comp.nus.edu.sg\/sites\/default\/files\/publication-attachments\/icml09-guojun.pdf || \""\""\""",,Yes,Yes
3529,Map from restricted to full vocab ids if needed,,,Yes
3915,TODO: remaining types,,,Yes
4072,TODO: Remove the shuffling above and use,,,Yes
4304,"\""\""\"" || Functions related to logging in SKLL. ||  || :author: Nitin Madnani (nmadnani@ets.org) || \""\""\""",,Yes,Yes
4711,"\""\""\"" || Synopsis: TV-l1 regression. Handles squared loss and logistic too. || Author: DOHMATOB Elvis Dopgima <gmdopp@gmail.com> <elvis.dohmatob@inria.fr> ||  || \""\""\""",,No,Yes
4915,"\""\""\"" || This module implements plotting functions useful to report analysis results. ||  || Author: Martin Perez-Guevara; Elvis Dohmatob; 2017 || \""\""\""",,,Yes
5005,setting report size for better visual experience in Jupyter Notebooks.,,,Yes
5006,"\""\""\"" || This module presents an interface to use the glm implemented in || nistats.regression. ||  || It provides facilities to realize a second level analysis on lists of || first level contrasts or directly on fitted first level models ||  || Author: Martin Perez-Guevara; 2016 || \""\""\""",,Yes,Yes
5007,assert_almost_equal(con1.variance * 2; con2.variance) FIXME,,,Yes
5009,formula should work (passing varible name directly),,Yes,Yes
5010,formula should work (passing variable name directly),,Yes,Yes
5011,formula should work passing variable name directly,,Yes,Yes
5012,XXX: the following line fixes curious SEGFAULT when,,,Yes
5014,"\""\""\"" || This module is for contrast computation and operation on contrast to || obtain fixed effect results. ||  || Author: Bertrand Thirion; Martin Perez-Guevara; 2016 || \""\""\""",,Yes,Yes
5017,"\""\""\"" || This module implement classes to handle statistical tests on likelihood models ||  || Author: Bertrand Thirion; 2011--2015 || \""\""\""",,Yes,Yes
5021,"\""\""\"" || This module implements plotting functions useful to report analysis results. ||  || Author: Martin Perez-Guevara; Elvis Dohmatob; 2017 || \""\""\""",,No,Yes
5022,Subpeak naming convention is cluster num+letter: 1a; 1b; etc,,No,Yes
5024,"\""\""\"" || This file contains a bunch of functions run via __main__(). || The functions represent feature comprehensive examples || to visualize; inspect; and test the functionality || of nistats.reporting.make_glm_reports(). ||  || Disable any of the function calls in the __main__() || to run a specific script and save time. || \""\""\""",,Yes,Yes
5027,formula should work (passing varible name directly),,,Yes
5029,formula should work passing variable name directly,,Yes,Yes
5030,XXX: the following line fixes curious SEGFAULT when,,Yes,Yes
5031,1\/64 Hz ~ 0.016 Hz. Note that the design matrix has more columns to model drifts in the data.,,,Yes
5032,"\""\""\"" || This module implements plotting functions useful to report analysis results. ||  || Author: Martin Perez-Guevara; Elvis Dohmatob; 2017 || \""\""\""",,,Yes
5033,from the url list we infer all available subjects like 'sub-xxx\/',,No,Yes
5035,($\\ell_1$ and $\\ell_2$). The sparse penalty works better because we are in,,No,Yes
5036,do ANOVA with SVR instead of manually defining the whole pipeline.,,Yes,Yes
5038,of our model on examples it hasn't seen to examine how well the model perform,,Yes,Yes
5040,from the url list we infer all available subjects like 'sub-xxx\/',,No,Yes
5041,from the url list we infer all available subjects like 'sub-xxx\/',,No,Yes
5042,from the url list we infer all available subjects like 'sub-xxx\/',,No,Yes
5043,"\""\""\"" || This module implements plotting functions useful to report analysis results. ||  || Author: Martin Perez-Guevara; Elvis Dohmatob; 2017 || \""\""\""",,No,Yes
5044,"\""\""\"" || fREM on Jimura et al \""mixed gambles\"" dataset. || ================================================== ||  || In this example; we use fast ensembling of regularized models (fREM) to || solve a regression problem; predicting the gain level corresponding to each || beta maps regressed from mixed gambles experiment. fREM uses an implicit || spatial regularization through fast clustering and aggregates a high number || of  estimators trained on various splits of the training set; thus returning || a very robust decoder at a lower computational cost than other spatially || regularized methods. ||  || To have more details; see: :ref:`frem`. || \""\""\""",,Yes,Yes
5045,clustering to reduce the number of feature by agglomerating similar ones,,Yes,Yes
5048,"\""\""\"" || Decoding of a dataset after GLM fit for signal extraction || ========================================================= ||  || Full step-by-step example of fitting a GLM to perform a decoding experiment. || We use the data from one subject of the Haxby dataset. ||  || More specifically: ||  || 1. Download the Haxby dataset. || 2. Extract the information to generate a glm representing the blocks of stimuli. || 3. Analyze the decoding performance using a classifier. ||  || To run this example; you must launch IPython via ``ipython || --matplotlib`` in a terminal; or use the Jupyter notebook. ||  || .. contents:: **Contents** ||     :local: ||     :depth: 1 || \""\""\""",,Yes,Yes
5049,* although it usually helps to decode better; z-maps time series don't,,,Yes
5051,We can also implement feature selection before decoding as a scikit-learn,,No,Yes
5052,modified; therefore copy is needed,,,Yes
5053,Fix: Matplotlib version 3.3.2 to 3.3.3,,Yes,Yes
5057,Now; another way of limiting the number of slices along rows and columns,,Yes,Yes
5058,Hack to avoid empty arrows to crash with,,Yes,Yes
5059,leave out the last 3 columns with a mean of zero to test user warning,,Yes,Yes
5061,this actually point to the headwords they belong to; I think; these needs to be parsed and looped,,Yes,Yes
5066,TODO,,Yes,Yes
5067,TODO: make sure this is with the right,,Yes,Yes
5070,TODO: fix `tglu` calls,,,Yes
5073,TODO,,,Yes
5074,TODO: fix paths,,No,Yes
5077,fix beta code transliteration problems,,,Yes
5078,fix tlg markup,,Yes,Yes
5079,TODO mk singuler,,,Yes
5082,"''' ||  || def build_phi5_index(index_path_rel = '~\/cltk_data\/originals\/phi5\/AUTHTAB.DIR'): ||     \""\""\""Return dict of 362 files in format of {file: author_name}. This has ||     been pre-generated and saved at ``~\/cltk\/corpus\/latin\/phi5_index.py``. ||     TODO: Update this to account for works within each author's file. ||     \""\""\"" ||     index_path = os.path.expanduser(index_path_rel) ||     if not os.path.isfile(index_path): ||         logger.info(\""Failed to locate original PHI5 index at '%s'. Please import PHI5 first.\"" % index_path) ||         sys.exit(1) ||     with open(index_path; 'rb') as f: ||         r = f.read() ||         index_all = r.decode('latin-1').split('\\xff')[1:-21] ||         index = [x for x in index_all if x] ||         file_author = {} ||         for x in index: ||             # file name ||             pattern_file = re.compile('LAT[\\d].{4}') ||             m = pattern_file.match(x) ||             file_name = m.group()[:-1] + '.TXT' ||  ||             # author name ||             author_name = pattern_file.split(x)[-1] ||             pattern_author = re.compile('&1|&\u0083l|l$|&|1$|\\x83') ||             author_name = pattern_author.sub(''; author_name) ||             pattern_comma = re.compile('\\x80') ||             author_name = pattern_comma.sub('; '; author_name) ||             file_author[file_name] = author_name ||  ||     return file_author ||  ||  || def build_tlg_index(index_path_rel='~\/cltk_data\/originals\/tlg\/AUTHTAB.DIR'): ||     \""\""\""Return dict of 362 files in format of {file: author_name}. This has ||     been pre-generated and saved at ``~\/cltk\/corpus\/latin\/phi5_index.py``. ||     TODO: Update this to account for works within each author's file. ||     TODO: merge with phi5 build index || \""\""\"" ||     index_path = os.path.expanduser(index_path_rel) ||     if not os.path.isfile(index_path): ||         logger.info(\""Failed to locate original TLG index at '%s'. Please import TLG first.\"" % index_path) ||         sys.exit(1) ||     with open(index_path; 'rb') as f: ||         r = f.read() ||         index_all = r.decode('latin-1').split('\\xff')[1:-6]  # diff from phi5 ||         index = [x for x in index_all if x] ||         file_author = {} ||         for x in index: ||             # file name ||             pattern_file = re.compile('TLG[\\d].{4}') ||             m = pattern_file.match(x) ||             file_name = m.group()[:-1] + '.TXT' ||  ||             # author name ||             author_name = pattern_file.split(x)[-1] ||             pattern_author = re.compile('&1|&\u0083l|l$|&|1$|\\x83|\\[2|\\]2')  # diff from phi5 ||             author_name = pattern_author.sub(''; author_name) ||             pattern_comma = re.compile('\\x80') ||             author_name = pattern_comma.sub('; '; author_name) ||             file_author[file_name] = author_name ||  ||     return file_author || '''",,Yes,Yes
5084,super ugly. replace name if 1 of 3 which has Greek in name,,Yes,Yes
5085,same as above. damn ugly. replace name w\/ dict value if name is one we,,Yes,Yes
5086,! this is super ugly and contains redundancies,,No,Yes
5087,"\""\""\""Indices for the TLG. ||  || Note: # ``TLG_MASTER_INDEX`` is the result of failed IDT parsing. ||  || TODO: Add work names to ``TLG_WORKS_INDEX`` || TODO: Add all TLG index data. || \""\""\""",,,Yes
5089,TODO: print git output to screen,,Yes,Yes
5090,t.concordance('ut')  # this has better formatting than c.print_concordance('ut'),,No,Yes
5091,Syllable ends with a diphthong,,Yes,Yes
5096,maybe not worth the effort,,No,Yes
5097,"\""\""\""Functions for retrieving data from text corpora. ||  || TODO: Add CLTK logging. || TODO: Make different functions for regex versus plaintext query. || TODO: Make public function for searching string. || TODO: Make public function for searching specific texts (passing list of eg; author names; ids; and\/or filepaths.) || TODO: Add option of outputting to plaintext file. || TODO: For whatever output; generate statistics on # of matches found; # docs searched. || \""\""\""",,Yes,Yes
5098,TODO: Add '\\u'; '\\U'; '\\x' to this list,,,Yes
5102,TODO: add sibilants\/sonorants,,,Yes
5108,"\""\""\""Language-specific word tokenizers. Primary purpose is to handle enclitics. ||  || Re: latin || Starter lists have been included to handle the Latin enclitics || (-que; -ne; -ue\/-ve; -cum). These lists are based on high-frequency vocabulary ||  and have been supplemented on a as-needed basis; i.e. they are not ||  comprehensive. Additions to the exceptions list are welcome. PJB || \""\""\""",,,Yes
5111,TODO Determine how to disambiguate tags (see logger),,Yes,Yes
5112,TODO: make `cltk_data` dir is not present,,,Yes
5114,Need to check that tokens exist before handling them; needed to make stream.readlines work in PlaintextCorpusReader,,No,Yes
5116,"\""\""\"" || Split Akkadian words into a list of syllables.  Logic is based on || A Grammar of Akkadian; Huehnergard 3rd. ed. ||  || TODO: Check this logic with von Soden's Grundriss der akkadischen Grammatik. || TODO: Deal with j\/y issue. || \""\""\""",,,Yes
5117,frequencies.counter_from_corpus('xxx'),,,Yes
5118,"\""\""\""Test making dict for author contrib file.\""\""\""",,No,Yes
5120,TODO: Improve stop list word,,Yes,Yes
5121,TODO: Add translate comments for each stop word.,,,Yes
5122,"\""arabtex\"": ARABTEX_TO_UNICODE; todo: not ready",,,Yes
5123,"\""iso8859-6\"": ISO88596_TO_UNICODE; todo: not ready",,Yes,Yes
5125,@todo: arabtex and iso8859-6 need individual handling because in some cases using one-two mapping,,Yes,Yes
5126,Unused for now,,Yes,Yes
5127,## Todo: Refactor to be more compact,,No,Yes
5128,"\""\""\"" || Get the stem of a word; given a declined form and its gender. ||  || TODO: Check this logic with von Soden's Grundriss der akkadischen Grammatik. || TODO: Deal with j\/y issue. || \""\""\""",,,Yes
5136,TODO: fails on: ['hammurabi'; 'u'; 'i\u0161me\u0101nim'],,No,Yes
5138,"\""\""\"" || The biggest challenge when it comes to noun and adjective stemming is that -similarly to MG- MHG suffixes are based on gender; || which is difficult to determine without either a hard-coded dictionary or an efficient tagger. Statistical analysis could  || theoretically yield more  accurate results; but a lack of online resources make this approach somewhat unreliable. ||  || Another core problem is the fact that unlike English; changes of the stem often occur in the middle of the word rather than the || end (bruoder -> br\u00FCeder). ||  || The following algorithm is inspired by Modern German stemmers (namely Snowball); modified to better fit MHG morphological  || structure. ||  || http:\/\/snowball.tartarus.org\/algorithms\/german\/stemmer.html || http:\/\/www.inf.fu-berlin.de\/lehre\/WS98\/digBib\/projekt\/_stemming.html || \""\""\""",,,Yes
5139,Here's how to debug every split decision,,No,Yes
5144,To-do: Add different dialects and\/or notations,,No,Yes
5145,To-do: Add different dialects and\/or notations,,,Yes
5146,TODO add your corpus here:,,,Yes
5147,: Generic file ending; override below in your own CorpusReader implementation,,Yes,Yes
5151,the principal part number needed to lookup the correct stem.,,Yes,Yes
5153,Handle better?,,Yes,Yes
5154,Perhaps should be an assertion about raising an exception,,Yes,Yes
5157,Need to think about the best way to evaluate sentence tokenizers,,,Yes
5159,Part of Latin workaround,,Yes,Yes
5160,Move to latin_models_cltk,,Yes,Yes
5162,"TODO  +\""vi\""",,No,Yes
5163,"TODO +\""vum\""",,Yes,Yes
5164,"TODO + \""va\""",,,Yes
5168,"\""\""\""Module for mapping Glottolog codes to standard family names. ||  || Glottolog is a project run by the Max Planck Institute for the || Science of Human History. The website contains codes for languages || as well as the reconstructed of language families: <http:\/\/glottolog.org\/>. ||  || TODO: Consider whether this kind of module is necessary. || TODO: Consider the other codes that users might want (ISO 639-1 639-2; ISO 639-3) || \""\""\""",,,Yes
5169,# TODO dealing with merges between verbs and sik -> st : middle voice,,,Yes
5170,previous word ends in consonant and current word begins with consonant,,Yes,Yes
5172,needed to make stream.readlines work in PlaintextCorpusReader,,No,Yes
5173,TODO: Decide which of these are necessary,,Yes,Yes
5174,TODO: Improve stop list word,,Yes,Yes
5175,TODO: Add translate comments for each stop word.,,,Yes
5176,TODO: Figure out right way to do these init imports and in submodules,,Yes,Yes
5177,TODO: Fill out more attributes to this,,No,Yes
5178,TODO: create and return list of tokens using Word,,Yes,Yes
5182,"\""\""\""Custom data types for the CLTK. ||  || TODO: Fill out more attributes to these || \""\""\""",,,Yes
5187,"TODO: Re-enable \""sphinx_autodoc_typehints\""; which fails on RTD builds",,Yes,Yes
5188,TODO: Figure out if I can avoid having to call the dataclass Pipeline,,No,Yes
5190,"\""\""\""Module for tokenizers. ||  || TODO: Think about adding check somewhere if a contrib (not user) chooses an unavailable item || \""\""\""",,No,Yes
5191,"\""\""\""Default processing pipelines for languages. The purpose of || these dataclasses is to represent: ||  || 1. the types of NLP processs that the CLTK can do || 2. the order in which processs are to be executed || 3. specifying what downstream features a particular implemented process requires || \""\""\""",,No,Yes
5200,TODO: Log INFO level,,Yes,Yes
5203,TODO: Give instructions how to install,,,Yes
5205,">>> is_vector_for_lang(iso_code=\""lat\""; training_set=\""xxx\"")",,,Yes
5208,# TODO: Log INFO level,,,Yes
5212,# TODO: Log INFO level,,Yes,Yes
5213,"TODO: Look at \""Download Large Files with Tqdm Progress Bar\"" here: https:\/\/medium.com\/better-programming\/python-progress-bars-with-tqdm-by-example-ce98dbbc9697",,Yes,Yes
5214,TODO: Confirm everything saves right,,,Yes
5215,">>> is_fasttext_lang_available(iso_code=\""xxx\"")",,,Yes
5219,cltkv1.core.exceptions.CLTKException: Invalid ``training_set`` 'xxx'. Available: 'wiki'; 'common_crawl'.,,No,Yes
5220,TODO: Do better than check for just name. Try trimming up to user home dir.,,Yes,Yes
5221,TODO: Add exceptions for loading problems due to FT not being installed,,,Yes
5223,# TODO: Give instructions how to install,,No,Yes
5225,"embeddings_obj = Embeddings(iso_code=\""lat\""; training_set=\""xxx\"")",,Yes,Yes
5229,TODO: Add 10 sec wait to this; to give user time to cancel dl,,,Yes
5230,TODO: mk this recursive fn,,Yes,Yes
5231,TODO: Figure out how to pass var of Class + method,,No,Yes
5234,TODO: Fix MULTILINGUAL_WORD_TOK; this might not work,,Yes,Yes
5242,better handle final sigmas,,No,Yes
5245,"\""\""\""Import CLTK corpora. || TODO: Fix so ``import_corpora()`` can take relative path. || TODO: Add https:\/\/github.com\/cltk\/pos_latin || \""\""\""",,Yes,Yes
5254,"TODO: Add Hindi (\""hin \"")",,Yes,Yes
5255,"TODO: Add Old Marathi (\""omr\"")",,,Yes
5256,"TODO: Add Panjali (\""pan\"")",,Yes,Yes
5257,"TODO: Add Hindi (\""hin \"")",,Yes,Yes
5261,Workaround for Latin\u2014use old API syntax to load new sent tokenizer,,Yes,Yes
5266,# TODO dealing with merges between verbs and sik -> st : middle voice,,No,Yes
5267,"\""\""\"" Tokenization utilities ||  || TODO: KJ consider moving to ``scripts`` dir. || \""\""\""",,,Yes
5269,xxx,,,Yes
5271,TODO: mk this recursive fn,,Yes,Yes
5272,TODO: Log INFO level; it's OK if dir already exists,,,Yes
5273,TODO: Add 10 sec wait to this; to give user time to cancel dl,,Yes,Yes
5275,"\""\""\""The Imperial Aramaic alphabet; plus simple script to transform || a Hebrew transcription of an Imperial Aramaic text to its own Unicode block. ||  || TODO: Add Hebrew-to-Aramaic converter || \""\""\""",,No,Yes
5276,TODO: fails on: ['hammurabi'; 'u'; 'i\u0161me\u0101nim'],,No,Yes
5278,"\""iso8859-6\"": ISO88596_TO_UNICODE; todo: not ready",,Yes,Yes
5281,Check whether ultima ends in e,,No,Yes
5283,Syllable ends with a diphthong,,,Yes
5284,Syllable ends with a vowel,,Yes,Yes
5285,TODO Determine how to disambiguate tags (see logger),,Yes,Yes
5286,previous word ends in consonant and current word begins with,,Yes,Yes
5287,previous word ends in vowel and current word begins in,,,Yes
5288,maybe not worth the effort,,No,Yes
5290,"\""\""\"" || Split Akkadian words into a list of syllables.  Logic is based on || A Grammar of Akkadian; Huehnergard 3rd. ed. ||  || TODO: Check this logic with von Soden's Grundriss der akkadischen Grammatik. || TODO: Deal with j\/y issue. || \""\""\""",,,Yes
5291,Deprecated; remove from future release?,,Yes,Yes
5295,TODO: Re-enable,,No,Yes
5305,TODO: Mv this a self. var or maybe even global,,,Yes
5306,# TODO: Fix this; I forget what we were tracking in this,,Yes,Yes
5312,Workaround for regex tokenizer,,Yes,Yes
5313,TODO add your corpus here:,,,Yes
5314,: Generic file ending; override below in your own CorpusReader implementation,,Yes,Yes
5318,TODO: Re-enable coptic,,Yes,Yes
5319,TODO: get stanza code,,,Yes
5321,"\""\""\"" || Starter lists have been included to handle the Latin enclitics || (-que; -ne; -ue\/-ve; -cum). These lists are based on high-frequency vocabulary ||  and have been supplemented on a as-needed basis; i.e. they are not ||  comprehensive. Additions to the exceptions list are welcome. PJB || \""\""\""",,Yes,Yes
5322,# TODO dealing with merges between verbs and sik -> st : middle voice,,No,Yes
5323,TODO add message; must specify sent_end_chars; or warn and use defaults,,Yes,Yes
5324,Workaround for Latin\u2014use old API syntax to load new sent tokenizer,,Yes,Yes
5325,Workaround for regex tokenizer,,Yes,Yes
5330,Move to latin_models_cltk,,Yes,Yes
5331,"\""\""\""Init module for importing the CLTK class. ||  || TODO: Add ``__version__`` here with ``curr_version = pkg_resources.get_distribution(\""cltk\"")  # type: pkg_resources.EggInfoDistribution`` and ``release = curr_version.version  # type: str`` || \""\""\""",,,Yes
5332,TODO: Re-enable this. Something breaking on build server but works for KJ locally,,Yes,Yes
5335,Check whether ultima ends in e,,,Yes
5337,TODO: This is broken!,,No,Yes
5341,TODO: generate size; alloc calls,,Yes,Yes
5342,TODO: handle X.T properly,,Yes,Yes
5343,TODO: self._analyze_call(lhs; rhs.func.name; rhs.args),,Yes,Yes
5344,TODO: check for index dependency,,Yes,Yes
5345,TODO: handle multi-dimensional arrays properly,,,Yes
5346,second dimension not needed,,Yes,Yes
5347,output df1 has same columns as df; create new vars,,No,Yes
5348,needs df columns for type inference stage,,Yes,Yes
5349,input columns have same distribution,,Yes,Yes
5350,output columns have same distribution,,,Yes
5351,TODO: rebalance if output distributions are 1D instead of 1D_Var,,,Yes
5352,TODO: generate parfor,,,Yes
5353,TODO: replace defaults (add to args),,,Yes
5355,TODO: compute inplace if input array is dead,,,Yes
5356,TODO: check for index dependency,,,Yes
5357,needs df columns for type inference stage,,,Yes
5360,TODO: rebalance if output distributions are 1D instead of 1D_Var,,Yes,Yes
5364,TODO: fix copies of global,,,Yes
5365,TODO: fix copies of global,,Yes,Yes
5367,TODO: replace array shape if array is small,,No,Yes
5369,TODO: ignore NA,,Yes,Yes
5371,TODO: use ptr instead of allocating and copying; use NRT_MemInfo_new,,Yes,Yes
5373,TODO: handle reference counting,,Yes,Yes
5374,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
5375,FIXME: need to renew definitions before PIO?,,No,Yes
5378,columns names as string constants,,,Yes
5379,TODO: add f's signature to locals,,Yes,Yes
5380,TODO: find prange actually coming from user,,Yes,Yes
5382,XXX: hack to get lengths assuming they are constant,,,Yes
5385,since columns should have the same size; output is filled with NaNs,,,Yes
5386,float columns can have regular np.nan,,Yes,Yes
5389,TODO: argmin\/argmax,,No,Yes
5390,TODO: support multi-dim slice setitem like X[a:b; c:d],,,Yes
5396,bool array and input columns are used,,,Yes
5397,output columns are defined,,,Yes
5399,XXX: use startswith since hpat output can have extra characters,,Yes,Yes
5402,TODO: or self._is_1D_Var_arr(rhs.value.name)),,No,Yes
5405,input columns have same distribution,,Yes,Yes
5406,output columns have same distribution,,,Yes
5407,TODO: rebalance if output distributions are 1D instead of 1D_Var,,,Yes
5409,bool array and input columns are used,,Yes,Yes
5410,output columns are defined,,,Yes
5412,add columns from left to output,,Yes,Yes
5417,TODO: rebalance if output distributions are 1D instead of 1D_Var,,Yes,Yes
5419,TODO: consider keys with same name; cols with suffix,,Yes,Yes
5420,if an output column is dead; the related input column is not needed,,,Yes
5425,TODO: rebalance if output distributions are 1D instead of 1D_Var,,,Yes
5427,XXX: assuming key arr is 1D,,,Yes
5428,TODO: extend to other key types,,Yes,Yes
5430,XXX: assuming key arr is 1D,,No,Yes
5431,add keys first (TODO: remove dead keys),,,Yes
5433,TODO: delete buffers,,,Yes
5434,TODO: fix type,,No,Yes
5435,XXX: get sizes in lower dimensions,,Yes,Yes
5436,TODO: support string type,,Yes,Yes
5438,FIXME how to check that the returned size is > 0?,,No,Yes
5441,XXX: fix overload for getitem and use it,,Yes,Yes
5443,FIXME: import here since hio has hdf5 which might not be available,,,Yes
5444,# FIXME: import here since hio has hdf5 which might not be available,,No,Yes
5446,FIXME: we use rebalance array to handle the output array,,,Yes
5448,TODO: avoid alloc and copy if no communication necessary,,Yes,Yes
5452,TODO: handle non numpy alloc types,,Yes,Yes
5457,TODO: refactor to avoid reduction,,,Yes
5458,XXX: get sizes in lower dimensions,,,Yes
5462,FIXME: import here since hio has hdf5 which might not be available,,,Yes
5463,TODO: refactor,,No,Yes
5466,FIXME: fix bool_,,Yes,Yes
5468,XXX: refcount?,,Yes,Yes
5470,TODO: error handling like Numba callwrappers.py,,,Yes
5471,TODO: check types,,No,Yes
5472,XXX: code for timestamp series getitem in regular Numba,,,Yes
5473,TODO: check types,,No,Yes
5474,TODO: add boxing,,No,Yes
5475,TODO: support distributed input,,No,Yes
5477,FIXME: this is possibly fragile; maybe replace all series getitems,,,Yes
5478,FIXME: this is fragile,,,Yes
5480,XXX assuming the whole column is strings if 1st val is string,,Yes,Yes
5481,FIXME dtype for dt64,,No,Yes
5482,FIXME dtype for str,,Yes,Yes
5485,find columns that are actually used if possible,,,Yes
5487,XXX placeholder for df variable renaming,,Yes,Yes
5488,TODO: generalize to more cases,,,Yes
5489,TODO: rename the dataframe variable to keep schema static,,Yes,Yes
5491,TODO: implement in regular python,,Yes,Yes
5492,TODO: init only once,,Yes,Yes
5495,TODO: support non-constant address\/dset_name,,No,Yes
5496,fix list(multi-dim arrays) (packing images),,Yes,Yes
5498,FIXME: np.array() for everything else?,,No,Yes
5499,TODO: need different flag for 1D_Var return (distributed_var)?,,,Yes
5500,TODO: implement this,,Yes,Yes
5503,"TODO: fix \""numba.extending\"" in function def",,No,Yes
5504,TODO: check types,,No,Yes
5505,XXX: does control flow affect type inference in Numba?,,,Yes
5507,TODO: handle datetime.date() series,,No,Yes
5509,TODO: box set(string),,,Yes
5510,TODO: expand to other set types,,No,Yes
5511,TODO: implement iterator,,,Yes
5512,TODO: other types like datetime?,,,Yes
5513,TODO: handle int64 counts,,,Yes
5514,XXX offset type is uint32,,No,Yes
5515,TODO: refactor with join,,No,Yes
5516,TODO: delete string,,,Yes
5518,XXX convert build_list to build_tuple since Numba doesn't handle list of,,No,Yes
5519,TODO: handle non-numerical (e.g. string; datetime) columns,,,Yes
5520,TODO: enable when namedtuple analysis patch is merged (#2984),,,Yes
5522,TODO: use get_cstr_and_len instead of getitem,,,Yes
5524,FIXME: it could potentially avoid remove dead for the column if,,Yes,Yes
5526,TODO: fix numba.extending,,Yes,Yes
5529,TODO: refactor,,No,Yes
5533,TODO: support aggregation functions sum; count; etc.,,,Yes
5534,find selected output columns,,Yes,Yes
5537,key array and input columns are used,,Yes,Yes
5538,output columns are defined,,Yes,Yes
5540,TODO: are there other non-numpy array types?,,Yes,Yes
5541,input columns have same distribution,,Yes,Yes
5542,output columns have same distribution,,,Yes
5544,"\""Only int64 and float64 columns are currently supported in aggregate\"")",,Yes,Yes
5545,TODO: rebalance if output distributions are 1D instead of 1D_Var,,Yes,Yes
5546,TODO: handle key column being part of output,,Yes,Yes
5548,TODO: handle string,,Yes,Yes
5550,TODO: non-int dict,,No,Yes
5552,XXX can modify since iterator is terminated,,,Yes
5553,XXX can modify since iterator is terminated,,,Yes
5554,no output columns in parallel-local computation (reduce arrs returned),,,Yes
5556,XXX can modify since iterator is terminated,,Yes,Yes
5557,XXX input column type can be different than reduction variable type,,No,Yes
5560,XXX can modify since iterator is terminated,,,Yes
5561,TODO: replace with functions,,No,Yes
5562,XXX can modify since iterator is terminated,,Yes,Yes
5565,shuffle other columns,,No,Yes
5567,TODO: handle numerics to string casting case,,Yes,Yes
5568,TODO: allocate string array of NAs,,Yes,Yes
5572,XXX assuming shape\/size nodes are right after arg,,Yes,Yes
5574,in parfor.py:3039; TODO: make this detection more robust,,No,Yes
5575,TODO: add outside globals,,No,Yes
5576,TODO: simplify f_ir,,Yes,Yes
5579,TODO: support multi block eval funcs,,Yes,Yes
5580,TODO: support other selection formats,,,Yes
5582,XXX array_types[0] is implicit index,,,Yes
5583,TODO: support string arrays,,,Yes
5584,XXX implicit int index,,Yes,Yes
5586,TODO: more efficient implementation (e.g. C++ string buffer),,No,Yes
5587,XXX arrow converts int96 timestamp to int64,,,Yes
5588,TODO: proper Series\/Timeseries type to avoid this,,No,Yes
5590,both timeseries; not needed,,Yes,Yes
5592,TODO: examine all possible ops,,No,Yes
5595,TODO: refcounted str,,,Yes
5598,pivotStore = key_arr[start]  # TODO: copy data to pivot,,,Yes
5599,The number of elements to move,,No,Yes
5600,TODO: optimize for n==1 and n==2,,Yes,Yes
5602,FIXME: is slicing ok?,,,Yes
5604,swap; TODO: copy data,,Yes,Yes
5605,XXX refactored nested loop break,,No,Yes
5607,TODO: support inplace=False,,,Yes
5612,TODO: other types like boolean,,,Yes
5617,TODO: big alltoallv,,,Yes
5618,TODO: use k-way merge instead of sort,,No,Yes
5619,TODO: string key,,,Yes
5620,input columns have same distribution,,,Yes
5621,key array and input columns are used,,Yes,Yes
5622,TODO: use *args,,Yes,Yes
5623,TODO: handle data,,Yes,Yes
5624,TODO: use k-way merge instead of sort,,,Yes
5626,FIXME: this needs to become more generic; we need to find the actual so in the python root,,Yes,Yes
5627,short-cut for Array type. FIXME: we currently only support 2d-double arrays,,No,Yes
5630,FIXME ILP,,,Yes
5635,FIXME: check types,,,Yes
5638,We provide a factory whcih creates all numba\/HPAT code needed to compile\/distribute daal4py code.,,Yes,Yes
5639,FIXME:,,No,Yes
5643,FIXME: check args,,No,Yes
5645,TODO: use get_cstr_and_len instead of getitem,,,Yes
5646,XXX offset type is uint32,,No,Yes
5647,XXX offset type is uint32,,,Yes
5650,TODO: fix np.full and refactor,,No,Yes
5651,XXX assuming str list is not used anymore,,,Yes
5652,TODO: increate refcount?,,No,Yes
5654,XXX: make sure function is not using old SortState,,Yes,Yes
5655,TODO: customize through @hpat.jit,,No,Yes
5656,TODO: refactor to use only tmp_offset,,,Yes
5663,XXX alloc empty arrays for dtor to safely delete?,,,Yes
5664,TODO: init; update all redvars,,Yes,Yes
5665,# TODO: replace with functions,,No,Yes
5668,# TODO: non-int dict,,No,Yes
5669,hack to return set with specified type,,Yes,Yes
5670,TODO check for numeric value,,Yes,Yes
5673,put pivots in locals TODO: generalize numba.jit options,,Yes,Yes
5674,XXX: unify Series\/Array as Array,,,Yes
5675,TODO: types other than Array and StringArray?,,No,Yes
5676,TODO: other types?,,No,Yes
5677,TODO: remove timestamp_series_type,,No,Yes
5678,TODO: check to make sure it is series type,,No,Yes
5679,FIXME: last arg should be types.DType?,,No,Yes
5680,TODO: error handling like Numba callwrappers.py,,,Yes
5683,TODO: replace timestamp type,,,Yes
5684,TODO: implement type inference instead of subtyping array since Pandas as of,,,Yes
5685,TODO: use infer_global to avoid lowering multiple versions?,,No,Yes
5686,XXX: side effect: force update of call signatures,,Yes,Yes
5689,XXX: use infer_global instead of overload; since overload fails if the same,,Yes,Yes
5690,TODO: add other types,,No,Yes
5691,TODO: replace Any with types,,Yes,Yes
5692,TODO: add other types,,,Yes
5696,same as types.Array; TODO: add Series?,,Yes,Yes
5698,TODO: add itemsize; strides; etc. when removed from Pandas,,Yes,Yes
5699,TODO: handle string arrays; etc.,,,Yes
5700,TODO: string array; dt_index,,Yes,Yes
5701,TODO: strings; dt_index,,Yes,Yes
5702,TODO: remove return after aliasing fix,,Yes,Yes
5703,XXX: Boxed series variable types shouldn't be replaced in hiframes_typed,,Yes,Yes
5704,TODO: change class name to Series in install_operations,,,Yes
5705,XXX: new_call_typ could be None for things like np.int32(),,,Yes
5706,fix types with undefined dtypes in empty_inferred; etc.,,Yes,Yes
5707,TODO: fix List; Set,,,Yes
5711,TODO: move to utils or Numba,,,Yes
5712,TODO: datetime.date; DatetimeIndex?,,Yes,Yes
5713,TODO: add definitions?,,No,Yes
5715,XXX: using .values to check date type since DatetimeIndex returns,,,Yes
5716,TODO: handle skipna; min_count arguments,,Yes,Yes
5720,time (TODO: time32; time64; ...),,,Yes
5722,TODO: fix string formatting to match python\/pandas,,Yes,Yes
5724,TODO: handle string; etc.,,Yes,Yes
5729,TODO: handle case where type has to be converted due to int64 NaNs,,,Yes
5734,TODO: refactor to a new func,,No,Yes
5736,TODO: check lens,,No,Yes
5738,TODO: complex numbers return complex,,,Yes
5740,TODO: check aligned nans; (S1.notna() != S2.notna()).any(),,Yes,Yes
5742,TODO: np.true_divide?,,,Yes
5745,FIXME: handle Distribution.Thread and Disribution.REP as equivalent,,Yes,Yes
5746,The following information is needed:,,Yes,Yes
5748,TODO: ignore_index,,No,Yes
5750,XXX: returns a dummy type that should be fixed in hiframes_typed,,Yes,Yes
5751,TODO: handle NA as 1st value,,Yes,Yes
5752,i\/8; XXX: lshr since always positive,,,Yes
5754,TODO: set null_bitmap,,No,Yes
5762,TODO: handle string array reflection,,,Yes
5763,TODO,,Yes,Yes
5766,XXX: assuming last offset is already set by allocate_string_array,,No,Yes
5767,integer case; TODO: bool; date etc.,,Yes,Yes
5768,TODO,,Yes,Yes
5769,TODO: handle values and aggfunc options,,,Yes
5770,TODO: make out_key_var an index column,,Yes,Yes
5771,XXX assuming shape\/size nodes are right after arg,,Yes,Yes
5772,TODO: handle pivot_table\/crosstab with return key,,Yes,Yes
5773,TODO: crosstab with values arg,,Yes,Yes
5774,TODO: handle other types like datetime etc.,,,Yes
5775,TODO: handle NAs,,No,Yes
5777,TODO: support cases where k is not too small,,No,Yes
5779,TODO: handle len(res) < k case,,No,Yes
5780,TODO: check return types; e.g. float32 -> float32,,,Yes
5781,TODO: handle NAs in argmin\/argmax,,,Yes
5782,TODO: kws,,Yes,Yes
5784,TODO: extend to other types like datetime?,,,Yes
5786,TODO: index arg?,,Yes,Yes
5788,make sure it's slice; TODO: support non-slice like integer,,Yes,Yes
5789,TODO: handle control flow,,,Yes
5791,TODO: close groups automatically,,,Yes
5793,TODO: remove this,,No,Yes
5794,XXX: used in agg func output to avoid mutating filter; agg; join; etc.,,Yes,Yes
5798,TODO: make sure assert_equiv is not generated unnecessarily,,,Yes
5799,TODO: fix assert_equiv for np.stack from df.value,,No,Yes
5800,TODO: support kws,,Yes,Yes
5803,TODO: support aggregation functions sum; count; etc.,,Yes,Yes
5804,find selected output columns,,Yes,Yes
5805,TODO: remove index col for offset case,,,Yes
5807,TODO: fix center,,,Yes
5808,TODO: support minp arg end_range etc.,,,Yes
5809,TODO: center,,No,Yes
5811,TODO: handle 1D_Var or other cases where data is actually large but,,,Yes
5817,TODO: refactor small data functions,,No,Yes
5819,TODO: make argument,,,Yes
5820,TODO: support dynamic conversion,,,Yes
5822,TODO: support minp arg end_range etc.,,No,Yes
5825,TODO: is incref required?,,Yes,Yes
5826,TODO,,Yes,Yes
5830,Pandas is right closed by default; TODO: extend to support arg,,,Yes
5831,TODO,,,Yes
5836,XXX: Pandas returns time = [np.nan] for size==1 for some reason,,Yes,Yes
5839,TODO: linear support,,No,Yes
5841,TODO: variable window,,,Yes
5843,TODO: support variable window rolling cov\/corr which is only,,Yes,Yes
5844,df on df cov\/corr returns common columns only (without,,,Yes
5845,TODO: support pairwise arg,,No,Yes
5848,line: res_columns = arg1.columns.union(arg2.columns),,,Yes
5849,TODO: is topo_order necessary?,,,Yes
5850,TODO: rename variables; fix scope\/loc,,,Yes
5852,TODO: handle skipna; min_count arguments,,Yes,Yes
5853,XXX update tp_vars in copy propagate etc.?,,,Yes
5854,TODO: handle skipna; min_count arguments,,Yes,Yes
5855,TODO: this has to be more generic to support all combinations.,,No,Yes
5857,XXX: only var supported for now,,Yes,Yes
5860,TODO: Pandas formula is better or Welford?,,,Yes
5861,TODO: setitem,,,Yes
5862,XXX assuming the order of the dictionary is the same as Pandas,,Yes,Yes
5863,TODO: check dictionary order,,Yes,Yes
5865,TODO: support their differences,,Yes,Yes
5866,TODO: check index for non-integer,,No,Yes
5867,TODO: support constant integer (return namedtuple),,No,Yes
5870,TODO: support strings and other types,,No,Yes
5871,TODO: handle passed in dict case (pass colname to func?),,No,Yes
5872,TODO: check for series\/dict\/list input,,Yes,Yes
5873,TODO: enforce ignore_index=True?,,Yes,Yes
5874,TODO: verify how Pandas sorts column names,,,Yes
5876,get input columns,,No,Yes
5878,TODO: this crashes on Travis (3 process config) with size 1,,No,Yes
5879,TODO: support other reductions,,Yes,Yes
5880,asof key is already sorted; TODO: add error checking,,Yes,Yes
5882,TODO: set NaN,,No,Yes
5884,TODO: see if next processor provides the value,,Yes,Yes
5885,TODO: support string,,Yes,Yes
5886,TODO: use binary search,,,Yes
5888,XXX: set NA values in bool arrays to False,,,Yes
5890,TODO: move to Numba,,Yes,Yes
5892,TODO: handle boolean scalars properly,,,Yes
5893,XXX df isin is different than Series.isin; df.isin considers,,No,Yes
5894,TODO: support strings and other types,,,Yes
5895,TODO: move to Numba,,Yes,Yes
5897,TODO: use prefix-sum and all-to-all,,No,Yes
5900,blocks of data are passed in; TODO: document,,,Yes
5901,output columns are defined,,,Yes
5902,csv doesn't generate copies; it just kills the output columns,,,Yes
5906,FIXME: fix after Numba #3372 is resolved,,,Yes
5907,XXX: temporary fix pending Numba's #3378,,Yes,Yes
5909,TODO: fix globals after Numba's #3355 is resolved,,,Yes
5910,TODO: check file name arg,,No,Yes
5914,TODO: handle rebalance,,,Yes
5916,TODO: handle 1D balance for inplace case,,Yes,Yes
5918,XXX arange() on float32 has overflow issues on large n,,,Yes
5919,find key columns,,Yes,Yes
5922,TODO: can we do this without reverse_copies?,,,Yes
5926,TODO: hanlde multiple keys (index args),,No,Yes
5929,TODO: arr refcount if arr is not stored somewhere?,,,Yes
5930,TODO: fix multi-key alloc when return_key==True,,Yes,Yes
5931,TODO: fix return key case,,,Yes
5932,TODO: support string in tuple set,,,Yes
5939,TODO: support other args like usecols,,,Yes
5941,TODO: rename df name,,,Yes
5943,TODO: set actual nan for str,,,Yes
5949,TODO: replace with np.isnat,,,Yes
5954,TODO: other attrs,,No,Yes
5955,TODO: move to Numba,,Yes,Yes
5957,TODO: resolve import conflict,,Yes,Yes
5958,XXX trying both since init_prange doesn't work for min,,,Yes
5959,TODO: support other reductions,,Yes,Yes
5960,c.pyapi.decref(arr)  # TODO needed?,,,Yes
5965,TODO: handle categorical,,No,Yes
5966,maybe improved later,,,Yes
5967,unparseable. Maybe git-describe is misbehaving?,,,Yes
5969,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
5972,"TODO: constant hash like hash(\""ss\"";) fails",,Yes,Yes
5977,TODO: fix handling of df setitem to force match of array dists,,,Yes
5980,TODO: refactor to avoid reduction,,,Yes
5981,XXX: get sizes in lower dimensions,,Yes,Yes
5982,TODO: move other funcs to old API?,,,Yes
5984,TODO: refactor to avoid reduction,,,Yes
5986,TODO: support multiple input flags,,,Yes
5987,XXX disable for now to enable dist series,,No,Yes
5989,TODO: refactor,,,Yes
5991,TODO: remove since probably unused,,Yes,Yes
5992,XXX just checking isna() since Pandas uses None in this case,,No,Yes
5995,XXX hack for array container case; TODO: handle properly,,,Yes
5996,XXX: njit doesn't work when hpat.jit() is used for agg_func in hiframes,,,Yes
5998,XXX replace hpat.hiframes_api.isna(A; i) for now,,,Yes
5999,TODO: handle actual NA,,,Yes
6000,TODO: reverse=None,,Yes,Yes
6001,TODO: handle reverse,,Yes,Yes
6002,TODO: overload of constructor doesn't work,,,Yes
6003,# TODO: use vector to avoid two passes?,,,Yes
6004,TODO: use vector to avoid two passes?,,,Yes
6005,XXX enabling this turns on old std::string implementation,,,Yes
6006,TODO: put offset\/data in main structure since immutable,,No,Yes
6007,TODO: use overload,,,Yes
6010,TODO: fix Numba to convert literal,,Yes,Yes
6012,XXX using std_str.split() until Numba can support split(),,No,Yes
6013,XXX handle unicode until Numba supports int(str),,Yes,Yes
6014,XXX handle unicode until Numba supports float(str),,Yes,Yes
6016,XXX fails due in overload,,,Yes
6020,XXX for pre_alloc_string_array(n; nc); we assume nc is local,,,Yes
6022,XXX using list of list string instead of array of list string since Numba's,,Yes,Yes
6023,XXX only supports get for list(list(str)) input,,,Yes
6025,XXX only list(list(str)) supported,,No,Yes
6026,TODO: support NAN,,No,Yes
6027,TODO required?,,,Yes
6029,TODO handle list_string_array_type in other nodes,,,Yes
6031,TODO: use Parfor loop blocks when replacing funcs in,,,Yes
6034,FIXME: list(str) code,,,Yes
6035,XXX we don't call native cleanup for each,,Yes,Yes
6036,TODO: support more types. what types can be in recarrays?,,,Yes
6040,XXX: refcount?,,Yes,Yes
6041,XXX assuming the whole column is strings if 1st val is string,,,Yes
6043,TODO: datetime.date; DatetimeIndex?,,,Yes
6045,TODO: is incref required?,,Yes,Yes
6047,FIXME dtype for str,,Yes,Yes
6048,FIXME dtype for list(str),,,Yes
6049,TODO: refcounts?,,Yes,Yes
6051,FIXME: list(str) code,,No,Yes
6052,FIXME: dt64 code,,,Yes
6054,XXX we don't call native cleanup for each,,,Yes
6055,XXX using replace() since it copies; otherwise cached overload,,Yes,Yes
6056,XXX: inine_closure_call() can't handle defaults properly,,,Yes
6058,TODO: support more types. what types can be in recarrays?,,No,Yes
6059,TODO: other types?,,,Yes
6060,XXX: Boxed series variable types shouldn't be replaced in hiframes_typed,,Yes,Yes
6061,TODO: copy other types like list(str),,,Yes
6064,TODO: dtype,,No,Yes
6065,XXX using replace() since it copies; otherwise cached overload,,,Yes
6066,XXX: side effect: force update of call signatures,,Yes,Yes
6067,XXX: new_sig could be None for things like np.int32(),,No,Yes
6068,fix types with undefined dtypes in empty_inferred; etc.,,Yes,Yes
6069,TODO: handle index and name,,Yes,Yes
6070,TODO: support alignment; dt; etc.,,,Yes
6072,TODO handle inplace alignment similar to,,,Yes
6073,TODO: inplace of str array?,,,Yes
6074,XXX assuming init_series is the only call to create a series,,No,Yes
6076,XXX use get_series_data() for getting data instead of S._data,,Yes,Yes
6078,TODO: support Series type similar to Array,,No,Yes
6079,XXX sometimes new_sig is None for some reason,,Yes,Yes
6084,fix definitions,,,Yes
6087,TODO: support other properties like freq\/tz\/dtype\/yearfirst?,,,Yes
6088,XXX is copy necessary?,,Yes,Yes
6089,TODO: fix timestamp,,Yes,Yes
6090,TODO: check\/handle other input,,Yes,Yes
6095,TODO: support other properties like unit\/freq?,,,Yes
6097,TODO: fix timedelta,,Yes,Yes
6100,TODO: handle all timedelta args,,,Yes
6105,TODO: comprehensive support for Series vars,,,Yes
6108,TODO: handle index,,Yes,Yes
6114,XXX assuming init_series is the only call to create a series,,No,Yes
6115,XXX use get_series_index() for getting data instead of S._index,,,Yes
6117,### passed to jitclass TODO: update,,,Yes
6119,TODO: arr refcount if arr is not stored somewhere?,,No,Yes
6120,TODO: increate refcount?,,No,Yes
6121,TODO refactor to use overload_method,,Yes,Yes
6122,TODO: check error,,,Yes
6125,TODO: use a seperate implementation?,,,Yes
6126,TODO: make sure hash(str) is not already instantiated in overloads,,No,Yes
6127,float columns can have regular np.nan,,,Yes
6129,TODO: other types,,,Yes
6130,TODO: fix for dt64,,,Yes
6133,TODO: handle string; etc.,,Yes,Yes
6134,TODO: use online algorithm; e.g. StatFunctions.scala,,Yes,Yes
6135,TODO: np.clip,,,Yes
6136,TODO: np.true_divide?,,No,Yes
6137,TODO: refactor regex and noregex,,Yes,Yes
6138,TODO: timedelta,,,Yes
6139,TODO: handle NAs in argmin\/argmax,,,Yes
6140,TODO: dataframe pass needed?,,No,Yes
6144,# TODO: support alignment; dt; etc.,,,Yes
6145,XXX assuming init_dataframe is the only call to create a dataframe,,,Yes
6146,XXX: inine_closure_call() can't handle defaults properly,,Yes,Yes
6152,XXX is copy necessary?,,,Yes
6153,needed?,,Yes,Yes
6156,TODO: support unboxing index,,,Yes
6157,TODO: other objects?,,,Yes
6158,TODO: refcounts?,,Yes,Yes
6162,list of flags noting which columns and index are unboxed,,,Yes
6163,TODO: make df refcounted to avoid repeated unboxing,,,Yes
6169,FIXME: it could potentially avoid remove dead for the column if,,Yes,Yes
6176,and other.columns == self.columns):,,Yes,Yes
6177,handling df.loc similar to df.iloc as temporary hack,,No,Yes
6178,TODO: handle proper labeled indexes,,No,Yes
6181,TODO: handle df.at[],,,Yes
6183,TODO: init_dataframe,,No,Yes
6184,TODO: handle df.at[],,Yes,Yes
6185,HACK: delete pd.DataFrame({}) nodes to avoid typing errors,,,Yes
6186,TODO: remove when dictionaries are implemented and typing works,,,Yes
6190,TODO: add this check back in,,,Yes
6191,"raise ValueError(\""setting dataframe columns inside conditionals and\""",,Yes,Yes
6192,TODO: generalize to more cases,,No,Yes
6193,columns,,No,Yes
6194,TODO: refcount of parent?,,No,Yes
6196,HACK: dummy overload for CategoricalDtype to avoid type inference errors,,No,Yes
6197,TODO: implement dtype properly,,Yes,Yes
6199,FIXME: fix after Numba #3372 is resolved,,,Yes
6200,TODO: no_cpython_wrapper=True crashes for some reason,,Yes,Yes
6201,HACK: delete pyarrow.parquet.read_table() to avoid typing errors,,No,Yes
6202,TODO: add proper metadata to Numba types,,Yes,Yes
6203,XXX: when constants are used; all the uses of the list object,,Yes,Yes
6205,TODO: add this to dead_branch_prune pass,,,Yes
6207,TODO: IterableType over groups,,Yes,Yes
6208,XXX is copy necessary?,,,Yes
6209,TODO: add df object to allow control flow?,,,Yes
6210,TODO: multi key,,No,Yes
6213,XXX output becomes series if single output and explicitly selected,,,Yes
6214,add key columns of not as_index,,,Yes
6215,XXX output becomes series if single output and explicitly selected,,,Yes
6218,TODO: make out_key_var an index column,,,Yes
6219,TODO: check Series vs. array for index\/columns,,,Yes
6220,XXX the order of output variables passed should match out_typ.columns,,Yes,Yes
6221,TODO: hanlde multiple keys (index args),,,Yes
6222,TODO: handle values and aggfunc options,,,Yes
6223,TODO: support agg func other than frequency,,No,Yes
6224,XXX this is needed for _TypeMetaclass._intern to return the proper,,Yes,Yes
6226,TODO: key attribute?,,,Yes
6227,TODO: add df object and win\/center vals to allow control flow?,,Yes,Yes
6229,TODO: handle Series case (explicit select),,No,Yes
6230,TODO: check 'on' arg,,,Yes
6232,XXX output becomes series if single output and explicitly selected,,,Yes
6234,TODO: support dynamic conversion,,No,Yes
6235,TODO: support other offsets types (time delta; etc.),,,Yes
6237,TODO: Series as other,,No,Yes
6239,XXX pandas only accepts variable window cov\/corr,,,Yes
6240,TODO: support variable window rolling cov\/corr which is only,,Yes,Yes
6242,TODO: support pairwise arg,,No,Yes
6243,TODO: implement to_numeric in typed pass?,,Yes,Yes
6244,TODO: handle non-numerical (e.g. string; datetime) columns,,Yes,Yes
6246,get input columns,,No,Yes
6247,XXX convert build_list to build_tuple since Numba doesn't handle list of,,No,Yes
6248,TODO: handle options,,Yes,Yes
6249,TODO: verify how Pandas sorts column names,,Yes,Yes
6250,XXX we add arrays of float64 NaNs if a column is missing,,Yes,Yes
6251,TODO: fix NA column additions for other types,,,Yes
6252,TODO remove this cast?,,Yes,Yes
6253,TODO: handle other iterables like arrays; lists; ...,,Yes,Yes
6254,TODO: get globals directly from passed lambda if possible?,,,Yes
6258,using NamedTuple instead of Series; TODO: pass Series,,,Yes
6264,TODO: refcounted df data object is needed for proper inplace,,Yes,Yes
6265,HACK assign output df back to input df variables,,,Yes
6268,XXX inplace type is just bool when value not passed. Therefore;,,Yes,Yes
6271,XXX sometimes init_dataframe() can't be resolved in dataframe_pass,,,Yes
6272,TODO: remove when overload_method can avoid lowering or avoid cpython,,Yes,Yes
6275,copy type to sethas_parent False; TODO: data always copied?,,Yes,Yes
6277,TODO: refcounted df data object is needed for proper inplace,,,Yes
6278,HACK assign output df back to input df variables,,Yes,Yes
6279,TODO CFG backbone?,,Yes,Yes
6282,TODO: inplace of df with parent that has a string column (reflection),,Yes,Yes
6284,TODO: more robust fix or just check,,,Yes
6285,copy type to sethas_parent False; TODO: data always copied?,,Yes,Yes
6286,TODO: reflection; drop=False semantics,,,Yes
6287,TODO: drop actual index; fix inplace,,Yes,Yes
6289,XXX inplace type is just bool when value not passed. Therefore;,,Yes,Yes
6290,TODO: more robust fix or just check,,,Yes
6291,TODO: inplace of df with parent (reflection),,,Yes
6292,XXX inplace type is just bool when value not passed. Therefore;,,,Yes
6293,TODO: more robust fix or just check,,No,Yes
6294,TODO: fix error when no df is returned,,,Yes
6295,TODO: support recovery when object is not df,,Yes,Yes
6296,TODO: make sure call post dominates df_var definition or df_var,,Yes,Yes
6297,TODO: inplace of df with parent (reflection),,,Yes
6298,XXX inplace type is just bool when value not passed. Therefore;,,,Yes
6300,TODO: reflection for drop inplace,,Yes,Yes
6301,TODO: reflection,,No,Yes
6305,TODO: tuple case,,,Yes
6307,TODO: name; index,,,Yes
6310,TODO: inline freevar,,Yes,Yes
6312,TODO: other types,,No,Yes
6314,TODO: cat as keys,,,Yes
6315,TODO: refcount issues?,,No,Yes
6318,TODO: check results,,No,Yes
6323,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6325,TODO: support ddof,,,Yes
6326,TODO: ignore non-numerics,,Yes,Yes
6327,TODO: non-numeric columns should be ignored automatically,,,Yes
6336,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6337,TODO: support ddof,,,Yes
6338,TODO: kwargs,,No,Yes
6339,TODO: ignore non-numerics,,Yes,Yes
6340,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6341,TODO: kwargs,,No,Yes
6343,unify types for output series; TODO: check Pandas unify rules,,No,Yes
6344,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6345,TODO: kwargs,,No,Yes
6346,TODO: ignore non-numerics,,,Yes
6348,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6349,TODO: non-numeric columns should be ignored automatically,,,Yes
6350,try single type for all columns case,,Yes,Yes
6351,TODO: fix aliasing,,No,Yes
6352,HACK support A.reshape(n; 1) for 1D_Var,,No,Yes
6353,HACK support A.reshape(n; 1) for 1D_Var,,No,Yes
6354,TODO: fix lazy IO load,,No,Yes
6356,TODO: refcount,,No,Yes
6358,HACK use the string in a dummy function to avoid refcount issues,,,Yes
6359,TODO: fix string data reference count,,Yes,Yes
6360,TODO: fix in Numba,,,Yes
6361,TODO: rebalance if set,,No,Yes
6363,TODO: string_array; categorical; etc.,,No,Yes
6364,HACK replace build_map to avoid inference errors,,,Yes
6365,TODO: support other args,,,Yes
6366,HACK replace dict.keys getattr to avoid typing errors,,Yes,Yes
6367,TODO: is in fact a list of tables!,,,Yes
6369,TODO: table can have different types,,No,Yes
6370,TODO: fix find_const(),,No,Yes
6371,TODO: optimized list type,,Yes,Yes
6376,TODO support dropna() for split view,,No,Yes
6378,TODO: refactor and enable distributed,,,Yes
6379,TODO: fix distributed,,No,Yes
6384,TODO: enable type checking when emty list item in,,,Yes
6386,TODO: check num strings and support NAN,,No,Yes
6388,XXX hack in hiframes_typed to make globals available,,,Yes
6389,TODO: use code.co_names to find globals actually used?,,,Yes
6390,TODO: implement extendable version in ir_utils,,Yes,Yes
6392,XXX sometimes copy propagation doesn't work for parfor indices,,Yes,Yes
6393,TODO: support index rename; kws,,Yes,Yes
6394,TODO: handle all possible cases,,,Yes
6400,TODO: get rid of static_getitem,,,Yes
6409,TODO: fix cache issue,,,Yes
6410,TODO: use ascii from unicode type when available,,Yes,Yes
6417,TODO: generalize,,,Yes
6420,TODO: ignore non-numerics,,Yes,Yes
6421,TODO: kwargs,,No,Yes
6422,TODO: non-numeric columns should be ignored automatically,,Yes,Yes
6424,Always add new name at the ends. Do not change the order,,No,Yes
6434,TODO type_min\/type_max,,,Yes
6435,TODO: remove these helper functions when Numba provide appropriate way to manipulate passes,,,Yes
6437,TODO: StringArrayType cannot resize inplace; and assigning a copy back to self._data is not possible now,,Yes,Yes
6439,TODO: this heavily relies on B being a homogeneous tuple\/list - find a better way,,No,Yes
6440,TODO: refactor to use numpy.concatenate when Numba supports building a tuple at runtime,,,Yes
6444,TODO: use list comprehension instead or self.unique(),,No,Yes
6445,TODO: consider order of values with the same frequency,,Yes,Yes
6446,TODO: unique() can not handle numpy.nan because numpy.nan == numpy.nan is False,,,Yes
6447,TODO: not optimal,,Yes,Yes
6451,TODO: Change hpat to sdc,,Yes,Yes
6453,TODO: Rename hpat module name to sdc,,Yes,Yes
6454,-- Todo extension configuration  ----------------------------------------------,,Yes,Yes
6456,TODO: Try to help pyarrow infer date type - set DateType.,,,Yes
6457,TODO: support non-numpy types like strings,,Yes,Yes
6458,TODO: fix globals after Numba's #3355 is resolved,,Yes,Yes
6460,workaround expected behavior from unittests,,,Yes
6461,XXX remove slice() of h5 read due to Numba's #3380 bug,,,Yes
6464,cfg needed for set df column,,Yes,Yes
6466,TODO: inst other than Assign?,,,Yes
6467,TODO: insert new blocks in current spot of work_list,,Yes,Yes
6477,TODO: support strings and other types,,,Yes
6478,TODO: check for series\/dict\/list input,,Yes,Yes
6479,TODO: enforce ignore_index=True?,,Yes,Yes
6484,TODO: support index var,,Yes,Yes
6487,TODO: verify how Pandas sorts column names,,,Yes
6489,get input columns,,No,Yes
6490,fix list(multi-dim arrays) (packing images),,,Yes
6491,FIXME: does this break for list(other things)?,,Yes,Yes
6494,TODO: remove index col for offset case,,Yes,Yes
6496,TODO: support variable window rolling cov\/corr which is only,,Yes,Yes
6498,TODO: support pairwise arg,,,Yes
6500,TODO: add datetime index for offset case,,No,Yes
6502,line: res_columns = arg1.columns.union(arg2.columns),,,Yes
6503,XXX placeholder for df variable renaming,,Yes,Yes
6504,TODO: replace with generic function to generate random sequence of floats,,,Yes
6505,XXX hack in hiframes_typed to make globals available,,Yes,Yes
6507,TODO: fix issue occurred if name is not assigned,,,Yes
6508,XXX hack in hiframes_typed to make globals available,,Yes,Yes
6509,TODO: use code.co_names to find globals actually used?,,Yes,Yes
6510,TODO: fix issue occurred if name is not assigned,,,Yes
6512,Fix bullet list indentation issues,,Yes,Yes
6513,Fix unresolved references after removal of References sections,,,Yes
6514,Check if only short description is needed,,,Yes
6515,workaround expected behavior from unittests,,,Yes
6517,TODO: eliminate code duplication by merging implementations for numeric and StringArray,,,Yes
6520,TODO: replace with StringArrays comparison,,,Yes
6522,XXX hack in hiframes_typed to make globals available,,Yes,Yes
6523,TODO: use code.co_names to find globals actually used?,,Yes,Yes
6525,XXX hack in hiframes_typed to make globals available,,,Yes
6526,TODO: use code.co_names to find globals actually used?,,Yes,Yes
6530,TODO: replace below with core join(how='outer'; return_indexers=True) when implemented,,,Yes
6531,TODO: fix the issue when window = 0,,,Yes
6532,TODO: fix the issue when window = 0,,,Yes
6533,TODO: fix the issue when window = 0,,,Yes
6536,TODO: check `other` is Series after a circular import of SeriesType fixed,,,Yes
6537,TODO: tune this,,Yes,Yes
6541,TODO: support joining indexes with common dtype=object - requires Numba,,Yes,Yes
6544,TODO: replace below with core join(how='outer'; return_indexers=True) when implemented,,,Yes
6546,TODO: IterableType over column names,,Yes,Yes
6552,XXX is copy necessary?,,Yes,Yes
6553,needed?,,Yes,Yes
6554,XXX: unify Series\/Array as Array,,,Yes
6556,TODO: fix timestamp,,,Yes
6562,TODO: provide specialization for (types.NPDatetime; types.NPTimedelta),,Yes,Yes
6563,TODO: improve check,,,Yes
6564,Keep columns that are StringArrayType,,,Yes
6566,TODO: support other array-like types,,,Yes
6567,TODO: support index in series from df-columns,,Yes,Yes
6570,kind is not known at compile time; so get this function here and use in impl if needed,,Yes,Yes
6571,TODO: use overload for all getitem cases (currently implemented via lower_builtin),,Yes,Yes
6572,FIXME: old-style getitem implementations copy strings but not null bits,,,Yes
6574,more than 19 columns raise SystemError: CPUDispatcher() returned a result with an error set,,,Yes
6576,columns order matters,,Yes,Yes
6580,TODO: refactor this when str_arr setitem is fully supported,,,Yes
6582,more than 19 columns raise SystemError: CPUDispatcher() returned a result with an error set,,,Yes
6583,TODO: Handle StringArrayType,,,Yes
6585,TODO: extend with other types,,No,Yes
6586,TODO: check if elementwise copy is needed at all,,Yes,Yes
6589,TODO: fix this during optimizing of covariance,,No,Yes
6590,TODO: remove conversion from Numba typed.List to reflected one while creating group_arr_{i},,Yes,Yes
6592,TODO: Rewrite when DF constructor will be fixed with index=None,,Yes,Yes
6594,TODO: Data generator for DataFrames,,,Yes
6595,this unboxes all DF columns so that no column unboxing occurs later,,Yes,Yes
6596,TODO: tune this,,,Yes
6597,TODO: string_array; categorical; etc.,,No,Yes
6599,remove_unused_recursively should see all del statements of variables,,,Yes
6600,Keep columns that are StringArrayType,,,Yes
6602,TODO: replace below with core join(how='outer'; return_indexers=True) when implemented,,,Yes
6604,TODO: support range unboxing with reference to parent in Numba?,,Yes,Yes
6605,TO-DO: extend getitem to support other indexers (Arrays; Lists; etc),,,Yes
6607,TODO: move to tools,,No,Yes
6610,# TODO: can not recall similar function,,No,Yes
6611,TODO: consider renaming to CategoricalDtype b\/c Categorical - not CategoricalType,,No,Yes
6612,TODO: take dtype from categories array,,Yes,Yes
6613,TODO: make ArrayCompatible. It will make reuse Array boxing; unboxing.,,Yes,Yes
6614,TODO: index and name,,,Yes
6615,TODO: pass codes array if exists,,No,Yes
6618,to deref the void * passed. TODO: nrt awareness,,No,Yes
6619,TO-DO: not supported; since no generic setitem for StringArray,,,Yes
6621,FIXME: TypingError in parfor step (wrong promotion to float64?) if prange is used,,,Yes
6622,TO-DO: replace sdc_reindex_series with reindex methods and move this logic to impl,,,Yes
6627,FIXME_Numba#5157: change to simple A == B when issue is resolved,,,Yes
6628,TODO: naive implementation; data from set can probably,,,Yes
6630,TO-DO: replace types.none index with separate type; e.g. DefaultIndex,,No,Yes
6631,TO-DO: should we check that all elements are strings?,,,Yes
6633,TODO: replace below with core join(how='outer'; return_indexers=True) when implemented,,Yes,Yes
6634,TO-DO: this actually includes calling 'index' attribute overload; should really be S._index;,,Yes,Yes
6636,below line is only needed since Literal[bool] var cannot be converted to bool,,,Yes
6637,TO-DO: not supported; since no generic setitem for StringArray,,Yes,Yes
6642,Read only these columns,,,Yes
6643,TODO: add support of int32 type,,,Yes
6644,FIXME: CategoricalType has wrong dtype attribute value (i.e. dtype of codes),,Yes,Yes
6645,FIXME_Numba#3372: add into numba.types to allow returning from objmode,,,Yes
6647,of columns dtypes is captured at compile time; because some dtypes (like datetime),,,Yes
6648,FIXME_Numba#3372: add into numba.types to allow returning from objmode,,Yes,Yes
6649,FIXME_Numba#3372: add into numba.types to allow returning from objmode,,,Yes
6650,if no transformation is needed just use outer param name (since APIs match),,,Yes
6651,of columns dtypes is captured at compile time; because some dtypes (like datetime),,,Yes
6652,FIXME_Numba#3372: add into numba.types to allow returning from objmode,,Yes,Yes
6654,making a new tuple of lists reorder as needed,,,Yes
6657,TO-DO: need DefaultIndex to handle self.index[idx] construct inside func,,Yes,Yes
6659,TO-DO: add operator.contains support for arrays in Numba,,Yes,Yes
6661,TO-DO: this and many other impls are generic and should be moved to indexes_generic.py,,No,Yes
6662,FIXME_Numba#5157: result must be np.array; remove list when Numba is fixed,,Yes,Yes
6663,FIXME_Numba#5157: remove np.asarray and return as list,,,Yes
6664,FIXME_Numba#5801: Numba type unification rules make this float,,,Yes
6670,FIXME_Numba#5801: Numba type unification rules make this float,,No,Yes
6671,TO-DO: add\/change adaptor to handle case of ascending=False,,,Yes
6673,TO-DO: remove when it's added,,No,Yes
6676,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,Yes,Yes
6677,TODO: Check NFC Normalize,,,Yes
6678,TODO: Validate tokenize,,No,Yes
6679,each non-empty line must contain >= 3 columns,,Yes,Yes
6680,extract tags from last 2 columns,,,Yes
6685,load_big_file is a workaround by https:\/\/github.com\/highway11git to load models on some Mac\/Windows setups,,Yes,Yes
6686,add start and end columns,,Yes,Yes
6687,zero-pad right columns,,Yes,Yes
6690,LSTM outputs a tuple of (hidden; cell); this is a common hack \uD83D\uDE01,,Yes,Yes
6691,LSTM outputs a tuple of (hidden; cell); this is a common hack \uD83D\uDE01,,Yes,Yes
6693,TODO: remove,,No,Yes
6696,TODO: required arguments,,Yes,Yes
6697,TODO,,,Yes
6698,TODO: need to return buckets,,No,Yes
6699,Move centroids step,,,Yes
6700,TODO \u5F53\u524D\u628Aloss\u5199\u6B7B\u4E86,,,Yes
6701,TODO \u9700\u8981\u8C28\u614E\u8003\u8651\u5982\u4F55\u5904\u7406\u7A7A\u683C\u7684\u95EE\u9898,,Yes,Yes
6703,TODO: \u8F6C\u6210\u6700\u7EC8\u8F93\u51FA,,No,Yes
6709,TODO,,,Yes
6710,TODO,,,Yes
6711,TODO \u5F53\u8FD9\u4E2AfieldArray\u662Fseq_length\u8FD9\u79CD\u53EA\u6709\u4E00\u4F4D\u7684\u5185\u5BB9\u65F6\uFF0C\u4E0D\u9700\u8981padding\uFF0C\u9700\u8981\u518D\u8BA8\u8BBA\u4E00\u4E0B,,No,Yes
6712,4. TODO \u8FD9\u91CC\u5E94\u8BE5\u8981\u4EA4\u7ED9\u4E00\u4E2Aiterator\u4E00\u6837\u7684\u4E1C\u897F\u9884\u6D4B\u8FD9\u4E2A\u7ED3\u679C,,,Yes
6713,5. TODO \u5F97\u5230\u7ED3\u679C\uFF0C\u9700\u8981\u8003\u8651\u662F\u5426\u9700\u8981\u53CD\u8F6C\u56DE\u53BB; \u53CApost_process\u7684\u64CD\u4F5C,,,Yes
6715,TODO \u8FD8\u9700\u8981\u8003\u8651\u5982\u4F55\u66FF\u6362\u56DE\u539F\u6587\u7684\u95EE\u9898\uFF1F,,No,Yes
6718,TODO: refactor self.get_loss,,No,Yes
6719,TODO seq_lens\u7684key\u8FD9\u6837\u505A\u4E0D\u5408\u7406,,,Yes
6720,TODO \u5E94\u8BE5\u53EF\u4EE5\u5B9A\u5236,,,Yes
6722,TODO:,,,Yes
6724,TODO \u8FD9\u91CC\u53EF\u80FD\u9700\u8981\u81EA\u5B9A\u4E49\u4E00\u4E9BError\u7C7B\u578B,,Yes,Yes
6725,TODO change error type,,No,Yes
6727,TODO: auto detect dtype,,Yes,Yes
6729,TODO change error type,,No,Yes
6730,TODO: \u8FD4\u56DE\u884C\u4E3A\u4E0D\u4E00\u81F4\uFF0C\u6709\u9690\u60A3,,No,Yes
6731,TODO check loss\u4E0Emetrics\u7684\u7C7B\u578B,,No,Yes
6732,TODO self._best_accuracy\u4E0D\u80FD\u8868\u73B0\u51FA\u5F53\u524D\u7684metric\u591A\u79CD\u7684\u60C5\u51B5,,No,Yes
6735,TODO \u8FD9\u91CC\u9700\u8981\u6839\u636E\u65B0\u7248\u7684metrics\u505A\u4FEE\u6539\uFF0C\u53E6\u5916\u8FD9\u91CC\u9700\u8981\u6355\u83B7\u6765\u81EAmetric\u7684\u62A5\u9519\uFF0C\u56E0\u4E3A\u9700\u8981\u6307\u5BFC\u7528\u6237debug,,,Yes
6737,move data to model's device,,,Yes
6738,check duplicated; unused; missing,,,Yes
6740,TODO: add UNUSED warning.,,No,Yes
6741,increase_better is True. It means the exp result gets better if the indicator increases.,,Yes,Yes
6742,TODO self._best_accuracy\u4E0D\u80FD\u8868\u73B0\u51FA\u5F53\u524D\u7684metric\u591A\u79CD\u7684\u60C5\u51B5,,No,Yes
6744,TODO self._best_accuracy\u4E0D\u80FD\u8868\u73B0\u51FA\u5F53\u524D\u7684metric\u591A\u79CD\u7684\u60C5\u51B5,,No,Yes
6745,TODO \u8FD9\u91CC\u9700\u8981\u68C0\u67E5\u662F\u5426\u8FD4\u56DE\u6765\u7684\u503C\u662F\u5426\u662F\u5408\u7406\u7684,,,Yes
6747,TODO \u8FD9\u91CC\u62A5\u9519\u7684\u903B\u8F91\u5E94\u8BE5\u662F\u600E\u6837\u7684\uFF1F,,Yes,Yes
6749,# (9) check map; include unused,,Yes,Yes
6750,"pred_dict = {\""prediction\"": torch.zeros(4; 3; 2); 'unused':1}",,,Yes
6751,(9) check map; include unused,,,Yes
6752,TODO: np.cov\u5728linux\u4E0Asegment fault;\u539F\u56E0\u672A\u77E5,,No,Yes
6753,if they are like 'SomeParam(assign to xxx)',,No,Yes
6755,(9) check map; include unused,,Yes,Yes
6757,TODO need to make sure they all have same batch_size,,No,Yes
6758,if _unused_field:,,,Yes
6759,if check_res.unused:,,No,Yes
6761,TODO \u9700\u8981\u505A\u4E00\u4E9B\u68C0\u67E5\uFF0CF.cross_entropy\u5728\u8BA1\u7B97\u65F6\uFF0C\u5982\u679Cpred\u662F(16; 10 ;4); target\u7684\u5F62\u72B6\u6309\u9053\u7406\u5E94\u8BE5\u662F(16; 10); \u4F46\u5B9E\u9645\u5374\u9700\u8981,,,Yes
6762,TODO  \uFF0816\uFF0C 4\uFF09,,Yes,Yes
6763,TODO: another error raised if CheckError caught,,No,Yes
6764,TODO: remove it. It is strange.,,Yes,Yes
6765,TODO; remove it.,,Yes,Yes
6768,TODO \u5982\u4F55\u5C06\u5EFA\u7ACBvocab\u548Cindex\u8FD9\u4E24\u6B65\u7EDF\u4E00\u4E86\uFF1F,,,Yes
6770,TODO: add limited pickling support for sharing an iterator,,,Yes
6772,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
6774,forward pass. This could probably be fixed in a more elegant way; but,,Yes,Yes
6780,forward pass. This could probably be fixed in a more elegant way; but,,Yes,Yes
6782,Instead of averaging loose ends; perhaps there should,,Yes,Yes
6783,average all the loose ends,,No,Yes
6789,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
6790,if check_res.unused:,,,Yes
6791,TODO \u8FD9\u4E2A\u7C7B\u4F7F\u7528\u5728\u4F55\u5904\uFF1F,,Yes,Yes
6794,TODO,,Yes,Yes
6795,"\""\""\"" ||     ..todo:: ||         \u68C0\u67E5\u8FD9\u4E2A\u7C7B\u662F\u5426\u9700\u8981 || \""\""\""",,Yes,Yes
6798,TODO: still in progress,,Yes,Yes
6801,TODO \u4FEE\u6539,,,Yes
6805,TODO,,,Yes
6806,TODO \u8003\u8651\u4E0D\u540C\u7684dataset\u7C7B\u578B\u600E\u4E48check,,Yes,Yes
6808,TODO \u4FEE\u6539,,No,Yes
6810,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
6812,TODO \u628Abaidu\u4E91\u4E0A\u7684\u52A0\u4E0A\u53BB,,Yes,Yes
6813,TODO \u8FD9\u6837\u611F\u89C9\u4E0D\u89C4\u8303\u5450,,Yes,Yes
6815,todo \u8FD9\u91CC\u52A0\u5165fastnlp\u7684\u8BB0\u5F55,,No,Yes
6816,TODO \u6539\u540D\u4E3Aevaluate\uFF0C\u8F93\u5165\u4E5F,,No,Yes
6817,TODO \u539F\u672C\u7684getprf,,,Yes
6818,TODO \u540E\u9762\u53EF\u80FD\u8981\u6539,,,Yes
6819,TODO \u4E0D\u4EA4\u53C9\u6CA1\u505A\u5904\u7406,,,Yes
6820,TODO \u8FD9\u91CC\u53EA\u8003\u8651\u4E86start\u6CA1\u6709\u8003\u8651end,,Yes,Yes
6821,TODO: torch.max(value; dim=None) threw an error at time of writing,,Yes,Yes
6823,TODO flatte lstm,,,Yes
6825,TODO \u6CA1\u6709\u6D4B\u8BD5,,,Yes
6828,TODO \u622A\u6389\u957F\u5EA6\u8D85\u8FC7\u7684\u90E8\u5206\u3002,,No,Yes
6829,"We \""pool\"" the model by simply taking the hidden state corresponding",,Yes,Yes
6830,TODO add compare & save best,,Yes,Yes
6832,TODO \u66FF\u6362,,Yes,Yes
6833,increase_better is True. It means the exp result gets better if the indicator increases.,,Yes,Yes
6834,TODO \u622A\u6389\u957F\u5EA6\u8D85\u8FC7\u7684\u90E8\u5206\u3002,,,Yes
6837,\tIf ends with Chinese character; will be processed,,,Yes
6839,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6840,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6842,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6843,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6845,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6846,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6847,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6850,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6853,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6854,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6855,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6856,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6857,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6858,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,,Yes
6859,"\""\""\"" || .. todo:: ||     doc || \""\""\""",,Yes,Yes
6860,TODO check 1,,No,Yes
6866,todo: \u7531\u4E8E\u6BCF\u4E2A\u6A21\u578B\u90FD\u6709embedding\u7684\u7ED1\u5B9A\u6216\u5176\u4ED6\u64CD\u4F5C\uFF0C\u5EFA\u8BAE\u632A\u5230\u5916\u90E8\u51FD\u6570\u4EE5\u51CF\u5C11\u5197\u4F59\uFF0C\u53EF\u53C2\u8003fairseq,,No,Yes
6868,TODO \u9700\u8981\u67E5\u770B\u5982\u679Ctokens\u957F\u5EA6\u4E0D\u662F1\uFF0Cdecode\u7684\u65F6\u5019\u662F\u5426\u8FD8\u80FD\u591F\u76F4\u63A5decode\uFF1F,,Yes,Yes
6870,Set max length if needed,,,Yes
6871,Convert old format to new format if needed from a PyTorch state_dict,,No,Yes
6872,Set max length if needed,,Yes,Yes
6875,Update config with kwargs if needed,,,Yes
6876,Prune heads if needed,,No,Yes
6877,Tie weights if needed,,,Yes
6878,Convert old format to new format if needed from a PyTorch state_dict,,No,Yes
6879,make sure word embedding weights are still tied if needed,,,Yes
6882,Set max length if needed,,Yes,Yes
6883,\u5982\u679Ctoken\u6CA1\u6709\u627E\u5230\uFF0C\u4F1A\u88AB\u62C6\u5206\u6210\u5B57\u6BCD\u8FD4\u56DE  TODO need comment,,,Yes
6884,Set max length if needed,,Yes,Yes
6887,todo: \u7531\u4E8E\u6BCF\u4E2A\u6A21\u578B\u90FD\u6709embedding\u7684\u7ED1\u5B9A\u6216\u5176\u4ED6\u64CD\u4F5C\uFF0C\u5EFA\u8BAE\u632A\u5230\u5916\u90E8\u51FD\u6570\u4EE5\u51CF\u5C11\u5197\u4F59\uFF0C\u53EF\u53C2\u8003fairseq,,No,Yes
6888,todo \u652F\u6301\u4E0D\u505Aattention,,No,Yes
6891,todo \u8FD9\u4E2A\u8981\u653E\u54EA\u91CC\uFF1F,,No,Yes
6892,TODO \u9700\u8981\u91CD\u65B0\u4FEE\u6539\uFF0C\u4F7F\u5F97encoder\u53EF\u4EE5\u76F4\u63A5\u8BFB\u53D6embedding\u7684\u6743\u91CD,,Yes,Yes
6893,TODO: add assert with proper check,,,Yes
6894,TODO: fixme,,No,Yes
6895,TODO: add below funtionalities,,,Yes
6898,TODO: change to [:2] at v1.0,,Yes,Yes
6899,TODO: verify this works as expected,,Yes,Yes
6900,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
6902,TODO: add documentation,,Yes,Yes
6903,move points to origin,,,Yes
6904,move points to origin,,Yes,Yes
6905,TODO: investage why precision is that low,,No,Yes
6907,TODO: embedd to a class,,,Yes
6908,TODO: implement me,,Yes,Yes
6909,TODO: implement me,,Yes,Yes
6910,TODO: implement me,,,Yes
6911,TODO: implement me,,Yes,Yes
6912,TODO: add more documentation,,Yes,Yes
6914,NOTE: torch.bincount does not implement batched version,,Yes,Yes
6916,hack for bitcounting 2 arrays together,,,Yes
6917,TODO: Filter2D convolves an image with the kernel. A wrapper fucntion for conv2d something similar to the one,,Yes,Yes
6918,TODO: explore solution when using jit.trace since it raises a warning,,No,Yes
6919,TODO: add broadcasting to get_rotation_matrix2d for center,,No,Yes
6920,TODO: add broadcasting to get_rotation_matrix2d for center,,No,Yes
6921,TODO: move to utils or conversions,,Yes,Yes
6922,reject even rows and columns.,,Yes,Yes
6924,TODO: implement support for kernel different than three,,Yes,Yes
6927,TODO:,,No,Yes
6928,follow the convention of opencv: https:\/\/github.com\/opencv\/opencv\/pull\/14411\/files,,,Yes
6930,TODO: point [0; 0; 0] crashes,,Yes,Yes
6931,norm; then renorm is needed for allowing detection on one resulution,,,Yes
6932,hack to match sizes,,,Yes
6933,ToDo: replace with 3d input; when grid_sample will start to support it,,Yes,Yes
6934,TODO: add this to the main module,,No,Yes
6936,move tensors to GPU,,,Yes
6938,TODO: implement apply_perspective,,Yes,Yes
6940,TODO: find an automatic way to do this,,Yes,Yes
6943,TODO: This part should be inferred from rotate directly,,No,Yes
6945,TODO: remove this since it does not help readability,,Yes,Yes
6946,TODO: Enable batch mode,,,Yes
6948,TODO: In terms of functional API; there should not be any initialization of an nn.Module.,,Yes,Yes
6949,TODO: In terms of functional API; there should not be any initialization of an nn.Module.,,,Yes
6950,TODO: In terms of functional API; there should not be any initialization of an nn.Module.,,Yes,Yes
6951,TODO: In terms of functional API; there should not be any initialization of an nn.Module.,,,Yes
6954,TODO: Make a differentiable version,,Yes,Yes
6955,The following is needed to avoid singular cases,,,Yes
6956,3 extra levels are needed for DoG nms.,,Yes,Yes
6958,Hack; because PyTorch does not allow to pad more than original size.,,,Yes
6964,TODO: move to utils or conversions,,,Yes
6965,TODO: translation math,,No,Yes
6966,TODO: scale is not implemented here,,No,Yes
6967,TODO: move to utils or conversions,,,Yes
6968,TODO: translation to rotation center,,,Yes
6971,TODO: scale is not implemented here,,No,Yes
6972,TODO: translation math,,,Yes
6973,TODO: scale is not implemented here,,,Yes
6974,TODO: translation math,,,Yes
6975,TODO: move to utils or conversions,,Yes,Yes
6980,We expand trans_01 to match the dimensions needed for bmm,,Yes,Yes
6981,TODO: This line somehow breaks the gradcheck,,Yes,Yes
6983,TODO: Looking for a vectorized way,,Yes,Yes
6984,TODO: Isn't this function duplicated with eye_like?,,,Yes
6987,TODO: get_perspective_transform3d seems to be correct since it would result in the,,Yes,Yes
6988,TODO: remove xfail once we have enough gpu bandwith in the CI,,,Yes
6990,TODO: update this when having torch.get_default_device(),,No,Yes
6995,TODO: add better cases,,,Yes
6996,TODO(jian): add better cases,,,Yes
6998,TODO Implement,,Yes,Yes
7000,TODO Implement,,,Yes
7001,in order to zero-out the fully filled rows or columns,,Yes,Yes
7003,This stupid thing needed for jitting...,,Yes,Yes
7004,"Fix mypy complains: error: Incompatible return value type (got \""Tuple[int; ...]\""; expected \""Size\"")",,,Yes
7006,TODO: unify the two lines below when pytorch 1.6 support is dropped,,No,Yes
7008,TODO: add type and value checkings,,No,Yes
7009,TODO: improve this since might slow down the function,,,Yes
7010,clip limit (TODO: optimice the code),,No,Yes
7012,should be similar to enhance.equalize but slower. Similar because the lut is computed in a different way.,,Yes,Yes
7013,TODO: Move to proper place,,,Yes
7016,This line makes execution much faster; I don't know why,,Yes,Yes
7017,This line makes execution much faster; I don't know why,,Yes,Yes
7018,TODO Too many return values; must re-consider interfaces,,Yes,Yes
7020,Q is not needed here; but log it just for information,,Yes,Yes
7021,Q is not needed here; but log it just for information,,,Yes
7022,Needed to run without X-server,,Yes,Yes
7024,TODO support recurrent Q-function,,,Yes
7025,Move data to CPU because we use Brent's algorithm in scipy,,Yes,Yes
7027,anneal beta in 200;000 steps [citation needed],,,Yes
7029,"\""\""\""Columns that describe information about an experiment. ||  || steps: number of time steps taken (= number of actions taken) || episodes: number of episodes finished || elapsed: time elapsed so far (seconds) || mean: mean of returns of evaluation runs || median: median of returns of evaluation runs || stdev: stdev of returns of evaluation runs || max: maximum value of returns of evaluation runs || min: minimum value of returns of evaluation runs || \""\""\""",,No,Yes
7030,TODO:,,No,Yes
7031,grads of unused variables must be zero,,Yes,Yes
7032,FIXME: The code works with EpisodicReplayBuffer,,No,Yes
7033,TODO,,Yes,Yes
7034,Q is not needed here; but log it just for information,,Yes,Yes
7035,Q is not needed here; but log it just for information,,Yes,Yes
7041,episode ends,,No,Yes
7042,episode ends; so we should add n-1 transitions,,Yes,Yes
7043,TODO Change eval episode time to cap at 5 mins!,,Yes,Yes
7045,TODO Change eval episode time to cap at 5 mins!,,Yes,Yes
7046,Start new episodes if needed,,No,Yes
7047,Start new episodes if needed,,,Yes
7048,Start new episodes if needed,,,Yes
7049,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
7050,FIXME: This probably can be avoided by improving the merging of the,,,Yes
7051,TODO: required?,,Yes,Yes
7052,each sublist (sl) contains rows with a subset of columns. Each,,,Yes
7053,stacked among themselves forming the final columns.,,,Yes
7055,TODO: documentation ain't true,,,Yes
7058,iterate through columns,,No,Yes
7061,efficient than parsing the lines manually,,Yes,Yes
7062,TODO gives problems with empty blocks,,Yes,Yes
7063,average_ratings = dataset.mean(axis='columns').collect(),,,Yes
7064,iterate through columns,,No,Yes
7067,all rows; single-block columns,,,Yes
7068,(3; 5; None; None);  # single-block rows; all columns,,,Yes
7070,all rows (slice : for rows) and list of indices for columns,,,Yes
7074,single-block rows; all columns,,Yes,Yes
7075,efficient than parsing the lines manually,,Yes,Yes
7077,efficient than parsing the lines manually,,Yes,Yes
7078,needed because subtract with scipy.sparse does not support,,Yes,Yes
7081,apply dropout to the input if needed.,,Yes,Yes
7084,apply dropout to the input if needed.,,Yes,Yes
7085,The next two lines are just a hack to initialize the SRNN cell from,,,Yes
7087,The next two lines are just a hack to initialize the SRNN cell from,,Yes,Yes
7088,todo (?) add available files and folders as select options,,No,Yes
7090,todo,,No,Yes
7091,Status: TODO make a proper diff implementing Hunt\u2013McIlroy algorithm,,Yes,Yes
7092,todo: different output options,,No,Yes
7093,TODO: proper documenting of different modes,,,Yes
7097,TODO: further augment formatter to give cleaner output,,,Yes
7098,''' || Introduction: || PaperRanker is a class which is used to predict how much possibility there is that a publication is belong to a professor. || Usage: || >>> ret; res = pr.label(a; b; threshold=0.5) || ''',,Yes,Yes
7099,The transaction is not needed here; but upload_index() will raise otherwise,,,Yes
7103,"\""\""\""Columns present in a labels dataframe. || \""\""\""",,Yes,Yes
7105,"\""\""\""Module responsible for definition of whole application ||  || It is also a great entry point for running this app. To do so; you can use: ||  ||     $ python data_labeling\/api\/app.py ||      * Running on http:\/\/localhost:51000\/ (Press CTRL+C to quit) ||      * Restarting with stat ||      * Debugger is active! ||      * Debugger PIN: XXX-XXX-XXX || \""\""\""",,,Yes
7106,Todo: handle duplicate username,,,Yes
7108,UGLY WORKAROUND - Start,,,Yes
7109,UGLY WORKAROUND - Stop,,Yes,Yes
7110,UGLY WORKAROUND FOR COMPRESSED DICOMs - Start,,,Yes
7112,Create needed directory,,Yes,Yes
7113,Add new columns with statuses,,,Yes
7115,Revert all previous columns,,Yes,Yes
7116,Remove newly added columns with statuses,,Yes,Yes
7119,Droping LabelSelections foreign key (instead of LabelElements) due to naming bug,,Yes,Yes
7121,NOTE: Find better parameters automatically,,,Yes
7122,Previous component was better; so let's use it,,Yes,Yes
7124,TODO what if the original text needs to be later transformed; e.g.,,Yes,Yes
7125,TODO text in this case means AnnoText; elswhere; it's raw text,,Yes,Yes
7129,"TODO -- should this work with self.doc.text = \""Deaths : 2\"" ?",,No,Yes
7132,TODO -- this example removed because it is long than the 2 intervening,,Yes,Yes
7133,and efficient way to match this example later.,,,Yes
7136,"\""\""\""An annie loader creates an AnnoDoc from a source such as a file or database. || The loader should perform as much annotation as is necessary to preserve parts || of document structure that would otherwise be lost. For example; if there is a || document header; it might be parsed and metadata stored in the AnnoDoc.properties. || If HTML tags are removed; certain tags might be transferred to an AnnoTier. || \""\""\""",,Yes,Yes
7138,This should probably be folded into the other match somehow,,Yes,Yes
7139,TODO: This needs to be delt with in the next stage.,,Yes,Yes
7140,TODO: This needs to be delt with in the next stage.,,,Yes
7142,TODO: This needs to be delt with in the next stage.,,,Yes
7144,Distinctness is probably more effective when combined,,Yes,Yes
7145,TODO? Check admin codes for containment,,,Yes
7147,TODO: Recompute scores since they could have been,,No,Yes
7148,TODO: We might be able to remove some of these names in a more general way,,Yes,Yes
7149,TODO: This needs to be delt with in the next stage.,,Yes,Yes
7152,TODO: We might be able to remove some of these names in a more general way,,,Yes
7153,TODO: This needs to be delt with in the next stage.,,,Yes
7154,Distinctness is probably more effective when combined,,,Yes
7155,that the match ends.,,No,Yes
7157,that the match ends.,,,Yes
7160,Pattern probably shouldn't be creating zero length words.,,Yes,Yes
7161,that the match ends.,,No,Yes
7168,TODO: It would be better to make,,,Yes
7169,TODO: Different parents could be used. Remove this property?,,Yes,Yes
7172,TODO: Serialize as JSON or something else.,,,Yes
7175,TODO: Parse the token which is a cardinal and\/or quantity,,Yes,Yes
7177,"TODO: Handle verbs for things like \""additional\""; \""incremental\"".",,Yes,Yes
7182,TODO: This should check that nc is actually a noun chunk. It should also,,,Yes
7183,TODO: Consider iterating through until a triggering word is,,No,Yes
7184,FIXME: This is a little kludgy. But maybe it's as good as it can be.,,,Yes
7185,Perhaps it's better to use a proper logging framework?,,Yes,Yes
7187,TODO: Consider iterating through until a triggering word is,,,Yes
7188,FIXME: It's probably silly to do this differently for counts; but I think,,Yes,Yes
7189,TODO: Handle this!,,,Yes
7190,I could be convinced that either way is better on this.,,Yes,Yes
7193,TODO: Consider iterating through until a triggering word is,,,Yes
7194,Remove rows without the right number of columns,,Yes,Yes
7197,TODO: Support the 'suspected' attribute. Look through additional attributes.,,Yes,Yes
7199,"FIXME: This should operate on \""groups\""",,Yes,Yes
7201,"# TODO: Find a way to reach \""30\""",,,Yes
7202,FIXME: This should work better. Right now it removes possessives by checking,,Yes,Yes
7203,It'd be nice to have a consistently applicable approach; where; say; you,,,Yes
7204,TODO: We don't look for this formulation.,,,Yes
7206,TODO: Investigate this.,,,Yes
7208,TODO: We don't look for this formulation.,,,Yes
7209,"TODO: Find a way to reach \""30\""",,No,Yes
7211,TODO: Support the 'suspected' attribute. Look through additional attributes.,,Yes,Yes
7213,TODO: PUT IN INFECTION ANNOTATOR,,No,Yes
7215,Skip tables with differing numbers of columns in each row,,Yes,Yes
7219,TODO: Quriat is missing,,No,Yes
7221,better default plotting style,,Yes,Yes
7226,would be more efficient),,Yes,Yes
7227,XXX,,,Yes
7228,XXX could be better,,Yes,Yes
7229,XXX FIXME,,,Yes
7231,TODO: encapsulate this in _get_factory,,,Yes
7233,TODO: pass from function,,No,Yes
7234,TODO: needs to be adapted in the sparse case,,,Yes
7236,# TODO: make it robust to this case,,,Yes
7237,TODO: encapsulate this in _get_factory,,,Yes
7238,TODO: needs to be adapted in the sparse case,,Yes,Yes
7245,.. recompute Ax TODO: do only in async ..,,No,Yes
7246,XXX TODO: implement specific step-size,,,Yes
7247,.. TODO: allow to be set also from environment variable ..,,Yes,Yes
7248,XXX,,,Yes
7252,Better alternatives exist for high-dimensional sparse vectors (cf. [1]),,No,Yes
7253,[1] Efficient Projections onto the .1-Ball for Learning in High Dimensions,,Yes,Yes
7255,"\""\""\"" || Total variation regularization || ============================== ||  || Comparison of solvers with total variation regularization. ||  || TODO: split computational and plotting code || \""\""\""",,,Yes
7256,TODO: avoid definition of d_t,,Yes,Yes
7257,XXX no sense for zero weight,,,Yes
7259,f_t; grad = f_grad(x_t)  # XXX,,Yes,Yes
7263,.. XXX TODO description ..,,,Yes
7265,implement also a version for dense data (numpy arrays) to better exploit data locality,,Yes,Yes
7267,TODO: could compute loss and grad in the same function call,,,Yes
7268,FIXME: just a workaround for now,,No,Yes
7270,XXX how to compute the number of blocks??,,No,Yes
7272,L-BFGS-B method seems to be working much better at finding the optimal,,Yes,Yes
7273,"\""\""\""TODO || \""\""\""",,Yes,Yes
7276,define a function with unused arguments for the API,,Yes,Yes
7277,best projection: itself!,,Yes,Yes
7292,TODO upload a fix to sklearn of wherever the bug is!,,,Yes
7302,TODO un-hard-code the 10 as number of classes,,,Yes
7303,TODO load the validation set (if any),,Yes,Yes
7312,TODO dataset and dataset-folder should never exist together,,Yes,Yes
7314,TODO change as soon as svhn has a val set :),,,Yes
7319,TODO dataset and dataset-folder should never exist together,,,Yes
7320,TODO dataset and dataset-folder should never exist together,,Yes,Yes
7321,TODO choose which of the 2 following lines :),,Yes,Yes
7324,TODO dataset and dataset-folder should never exist together,,Yes,Yes
7325,TODO dataset and dataset-folder should never exist together,,Yes,Yes
7326,TODO un-hard-code the 10 as number of classes,,Yes,Yes
7331,TODO fix this such that only B and W are return values; prolly bring in the assign logic here and leave only the real assign outside,,Yes,Yes
7332,TODO un-hard-code the 10 as number of classes,,,Yes
7337,Keep only necessary dimensions when num_columns > num_desired_dimensions,,Yes,Yes
7338,The T belongs to the reshape operation! It is NOT transposing the input! It is necessary to select columns,,No,Yes
7340,order to prevent any memory allocation on unused GPUs,,Yes,Yes
7341,hack to speed up process,,,Yes
7343,TODO check is this is done anyway by default?,,,Yes
7346,TODO: make data balancing agnostic to type of dataset,,No,Yes
7350,TODO: DOES NOT PLAY WELL WITH SEEDS. Figure out why!,,No,Yes
7351,TODO: Check if this really necessary?,,No,Yes
7353,Fix for TB writer. Its an ugly workaround to have it printed nicely in the TEXT section of TB.,,Yes,Yes
7354,Fix for TB writer. Its an ugly workaround to have it printed nicely in the TEXT section of TB.,,,Yes
7355,TODO: make it save a zipfile instead of a tarfile.,,,Yes
7356,In order to make this parallel (if ever needed) one should create a Process class which swallows,,,Yes
7363,Fix for TB writer. Its an ugly workaround to have it printed nicely in the TEXT section of TB.,,,Yes
7364,TODO All parts computing the accuracy are commented out. See the TODO in evaluate.py,,Yes,Yes
7365,TODO: store something cleaner,,,Yes
7374,TODO: only use for DivaHisDB,,,Yes
7375,4. TODO: only for DIVAHisDB,,Yes,Yes
7377,TODO: add weights to kwargs,,,Yes
7378,TODO: from __future__ import print_function,,Yes,Yes
7379,TODO: refactor into the image_folder_segmentation.py,,No,Yes
7380,fix naming issue,,Yes,Yes
7381,TODO: fix input and output dims (see one_hot_to_output),,,Yes
7385,TODO: add weights to kwargs,,,Yes
7387,TODO documentation format,,Yes,Yes
7390,TODO: investigate which axes are correct.,,,Yes
7391,TODO: confirm that filters=16 and dilation_rate=(2; 2; 2) gives a,,No,Yes
7392,TODO: confirm that filters=16 and dilation_rate=(4; 4; 4) gives a,,,Yes
7396,probabilities = tf.nn.softmax(logits; -1)  # unused at the moment.,,No,Yes
7397,TODO: sometimes NaN is returned for Dice of class 1 (brainmask). This,,No,Yes
7398,TODO: generalize this.,,,Yes
7399,TODO: generalize this.,,No,Yes
7401,TODO:,,No,Yes
7404,TODO (kaczmarj): do not get mean of NaN.,,Yes,Yes
7405,fix,,Yes,Yes
7406,fix,,,Yes
7407,maybe improved later,,No,Yes
7408,unparseable. Maybe git-describe is misbehaving?,,,Yes
7409,TODO: improve docs.,,Yes,Yes
7410,TODO: validation dataset,,No,Yes
7411,TODO: For debugging only.,,No,Yes
7412,improve read performance?,,No,Yes
7414,TODO: we might have to reshape the outputs before bias_add.,,Yes,Yes
7415,TODO (kaczmarj): add is_mc and a_initializer.,,,Yes
7420,TODO.,,,Yes
7423,Below this line; we implement methods similar to those above but using Numpy.,,,Yes
7424,TODO: add more cases.,,,Yes
7428,TODO: where should this go? Or should it be removed?,,,Yes
7429,TODO: add WeightNorm wrapper from tensorflow-probability once next,,,Yes
7431,TODO: implement is_mc behavior.,,No,Yes
7432,TODO: add entropy,,No,Yes
7435,TODO: need to implement this soon.,,,Yes
7436,underlings will be called up; and maybe they'll do better.,,,Yes
7437,this is still needed to make sure that the parameter NAMES are known.,,Yes,Yes
7439,Doesn't really matter what it returns for this test; so just making sure it catches all of them,,,Yes
7441,underlings will be called up; and maybe they'll do better.,,No,Yes
7443,function with httpretty.enable() and ends it with httpretty.disable().  However; when combined,,,Yes
7444,this is still needed to make sure that the parameter NAMES are known.,,Yes,Yes
7445,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
7446,TODO: Need to change later,,No,Yes
7447,TODO: why?,,,Yes
7453,#TODO: Not a correct version. Need to work on it,,No,Yes
7454,TODO: Add custom phase names,,Yes,Yes
7455,-- Options for todo extension ----------------------------------------------,,Yes,Yes
7456,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
7457,print(columns),,,Yes
7458,TODO,,,Yes
7460,pad them if needed; reverse encoder inputs and add GO to decoder.,,Yes,Yes
7462,probabilities; which would require the accumulated alpha values at every,,Yes,Yes
7463,"TODO change this to use the Python \""hdfs\"" class",,Yes,Yes
7464,TODO: does this work?,,No,Yes
7466,TODO check if this is sufficient!,,Yes,Yes
7467,convert columns,,No,Yes
7468,get H2OSparkling context (#TODO: if context doesn't exist yet; raise error! Should not be created here),,,Yes
7469,convert factor columns,,,Yes
7471,TODO possibly split into two modules: data_set readers and data_bunch readers,,No,Yes
7473,TODO possibly split into two modules: data_set readers and data_bunch readers,,No,Yes
7475,TODO must filter on threshold_metric_names,,,Yes
7476,TODO this should return an H2OSparklingDataWrapper in the input type is H2OSparklingDataWrapper,,Yes,Yes
7477,"TODO possibly change this to create spark session outside and pass \""spark\"" as variable",,No,Yes
7482,TODO existing metrics should be updated; not overwritten!,,Yes,Yes
7483,We can also add DataWrappers afterwards; for example; the following will add a wrapper that consists of the full data set with all columns,,,Yes
7486,"Then we use the \""tasks\"" API to store the model in each of the provided formats; as well as copying the model to a \""remote\"" location (in this example we simply copy to another local folder; but this would normally be used in combination with S3; GCS; HDFS etc)",,,Yes
7487,todo,,,Yes
7488,The convention in BERT is:,,No,Yes
7489,Needed so that we dont add the processors mutiple times,,Yes,Yes
7491,"We \""pool\"" the model by simply taking the hidden state corresponding",,,Yes
7493,FIXME rewrite,,Yes,Yes
7494,FIXME is there a better way to fix for noise?,,No,Yes
7496,fix this,,Yes,Yes
7497,TODO: this should be self.ppf,,Yes,Yes
7498,loops through columns and applies transformation,,,Yes
7501,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
7504,loops through columns and applies transformation,,,Yes
7505,fix style issues,,,Yes
7506,TODO: Discuss if this loss of precision is acceptable,,Yes,Yes
7508,TODO: Alternatively; remove it.,,Yes,Yes
7511,TODO solve this...,,No,Yes
7519,TODO log a warning here; no exception.,,,Yes
7520,FIXME: Path to template path. This might be temporary.,,,Yes
7521,TODO: Put all comicsite related stuff in comicsite.urls,,,Yes
7522,this one is needed to be able make {% url work}  TODO: having two identical regexes here seems stinky.. can this be different?,,,Yes
7523,TODO check whether short name is really clean and short!,,No,Yes
7524,todo: is this double save really needed?,,,Yes
7525,This is needed to use the @register.tag decorator,,,Yes
7527,FIXME: is this double save really needed?,,No,Yes
7528,TODO check whether short name is really clean and short!,,,Yes
7530,This is needed to use the @register.tag decorator,,,Yes
7531,TODO log a warning here; no exception.,,,Yes
7535,TODO: print {% tag %} values in this,,Yes,Yes
7536,FIXME: I want to make the comicsite field uneditable; but setting,,Yes,Yes
7537,FIXME : Sjoerd: comicmodels and filetransfers are being merged here. How to keep original Filetransfers seperate from this?,,,Yes
7538,TODO check whether short name is really clean and short!,,No,Yes
7540,TODO: check whether user is allowed to register; maybe wait for verification;,,,Yes
7541,common save functionality for all models,,No,Yes
7542,code below was completely pasted from django.contrib.admin.options I needed to make changes to the,,Yes,Yes
7544,TODO: could a decorator be better then all these ..IfAllowed pages?,,,Yes
7545,TODO: move HtmlLinkReplacer to better location..,,Yes,Yes
7548,FIXME: How to populate comicSiteAdminForm.admins with some data? The line below,,No,Yes
7550,throws an error?. Workaround is to add 'remove' as path and chop this off the returned link,,Yes,Yes
7551,FIXME: I think this class should be refactored into something which is listed,,Yes,Yes
7552,FIXME style: is this too much in one line?,,Yes,Yes
7553,TODO: put this in template tags,,,Yes
7555,"TODO: does accessing a file \""..\\..\\..\\..\\allyoursecrets.txt\"" work?",,Yes,Yes
7557,FIXME:  throw 403 or proper permission denied here,,,Yes
7558,TODO: send email!,,Yes,Yes
7560,FIXME: move this code to seperate location. Spike solution right now,,Yes,Yes
7561,TODO check content safety,,No,Yes
7565,FIXME: quick-n-dirty implementation to make things work for social-auth login redirect handling.,,Yes,Yes
7566,FIXME: create a temporary solution to including javascript and css with template tags,,Yes,Yes
7568,Second call has no 'usagestr' defined workaround now is to check for existing key and not,,Yes,Yes
7569,Needed this code to do reliable loading of initial data using fixtures in,,Yes,Yes
7571,TODO: If you upload you result to the site; someone else cannot guess the,,Yes,Yes
7572,TODO: verify that files uploaded in editor can be served directly.,,Yes,Yes
7574,TODO: How to refer to method in this file nicely? This seems a bit cumbersome,,Yes,Yes
7575,TODO: How to refer to method in this file nicely? This seems a bit cumbersome,,,Yes
7576,FIXME: I think this class should be refactored into something which is listed,,,Yes
7579,TODO: is there no less repetitive way of wrapping?,,No,Yes
7582,TODO: THis has code smell. If page has to be checked like this; is it,,No,Yes
7583,TODO: here confused coding comes to light: I need to have the page,,,Yes
7584,As a workaround; just checking for both conditions.,,Yes,Yes
7585,and the security risk is not too great. TODO (is it not?),,Yes,Yes
7589,seems quite weird. But how to do it better?,,,Yes
7590,tell nice bots what to do. TODO: using 'robots.txt' as a template name will,,Yes,Yes
7591,tell nice bots what to do. TODO: using 'robots.txt' as a template name will,,Yes,Yes
7592,TODO: recursive call upon error. Is this horrible coding?,,,Yes
7594,TODO: How to do this gracefully?,,No,Yes
7595,todo: is this ugly? At least there is explicit assignment of vars.,,,Yes
7596,How to do this better?,,,Yes
7597,TODO: move HtmlLinkReplacer to better location..,,Yes,Yes
7598,throws an error?. Workaround is to add 'remove' as path and chop this off the returned link.,,Yes,Yes
7599,so confusing. Think about class responsibilities and fix this.,,,Yes
7606,TODO: This way of filtering should be used for all comicobjects; this,,,Yes
7608,TODO: The final clasuse in the if statement is a total hack. May posterity,,,Yes
7611,Hack because registrationrequest does not have a 'comicsite' param;,,,Yes
7614,Assumptions of urls being fixed a bit; but it is the only way to reuse much,,Yes,Yes
7616,TODO check content safety,,No,Yes
7617,TODO: here confused coding comes to light: I need to have the page,,No,Yes
7619,throws an error?. Workaround is to add 'remove' as path and chop this off the returned link.,,,Yes
7621,TODO: here confused coding comes to light: I need to have the page,,,Yes
7622,As a workaround; just checking for both conditions.,,,Yes
7624,TODO check content safety,,,Yes
7626,As a workaround; just checking for both conditions.,,Yes,Yes
7627,FIXME: create a temporary solution to including javascript and css with template tags,,,Yes
7628,TODO: The permissions are not correct; https:\/\/github.com\/comic\/comic-django\/issues\/306,,Yes,Yes
7633,TODO: Check that the user is a participant of that challenge,,No,Yes
7636,TODO - Implement the validation,,Yes,Yes
7638,TODO - check that we're being run as part of a context manager,,Yes,Yes
7639,The alpine image is needed for the reader and writer containers,,,Yes
7641,TODO: Add a validator to make sure the form is sha256:{64},,,Yes
7644,TODO: Error handling,,No,Yes
7645,TODO: Error handling; update the job status,,No,Yes
7646,TODO: Add a validator to make sure the form is sha256:{64},,,Yes
7650,implemented if we want to pre-populate upload forms,,Yes,Yes
7652,TODO: Challenge Participant Only,,,Yes
7654,When a full configurable permissions system is in place; see ticket #244,,Yes,Yes
7655,The url for a project in comic is \/site\/<projectname>. This is quite ugly. It,,Yes,Yes
7656,FIXME: Path to template path. This might be temporary.,,No,Yes
7658,TODO: JM add class=active to the active link,,Yes,Yes
7659,These are needed for subdomain redirects,,No,Yes
7660,TODO: JM - Add the profile filling as a partial,,Yes,Yes
7662,TODO: Challenge Admin Only,,,Yes
7667,What is needed is a clear and unanbiguous way to deal with subdomain as project name,,Yes,Yes
7671,TODO: a method is needed,,No,Yes
7673,Do not raise EOFError on read; follow convention of BytesIO,,No,Yes
7674,Do not raise EOFError on read; follow convention of BytesIO,,,Yes
7678,TODO: Team Update and Team Member delete permissions,,,Yes
7679,I'm not sure that sending signals is the best way to do this.,,No,Yes
7680,TODO: THis has code smell. If page has to be checked like this; is it,,,Yes
7681,and the security risk is not too great. TODO (is it not?),,Yes,Yes
7683,TODO: Remove the sortables on edit etc.,,Yes,Yes
7684,TODO: check whether user is allowed to register; maybe wait for verification;,,,Yes
7685,TODO : check this once at server start but not every time this method is,,Yes,Yes
7686,I'm not sure that sending signals is the best way to do this.,,,Yes
7688,TODO: adapt this for ckeditor,,No,Yes
7689,TODO: remove; unneeded once moved to ckeditor,,Yes,Yes
7693,TODO : do checking for scripts and hacks here?,,,Yes
7696,TODO: make a mixin for DockerImage; generalize docker_image_path to work with instance,,,Yes
7697,TODO: Permissions,,,Yes
7701,TODO: should the ipynb be downloadable?,,Yes,Yes
7702,TODO: put the generated html into a frame?,,,Yes
7704,TODO: Unhardcode,,,Yes
7707,TODO: save results to database,,No,Yes
7708,Maybe add .mhd and .mha files here?,,No,Yes
7709,TODO,,Yes,Yes
7712,TODO: This thing should not interact with the database,,No,Yes
7713,TODO: Create a StagedFile and StagedAjaxFile from this,,Yes,Yes
7718,TODO: load images too,,No,Yes
7719,TODO: This thing should not interact with the database,,,Yes
7721,TODO: Change to subdomain urls,,Yes,Yes
7722,TODO: add support for PROJECTNAME_IS_SUBDOMAIN?,,No,Yes
7723,TODO: Change to subdomain urls,,,Yes
7724,TODO: Change to subdomain urls,,,Yes
7730,TODO: Change to subdomain urls,,,Yes
7732,TODO combine with viewset,,,Yes
7734,TODO: permission for creation... anyone can create a polygon_set and set user_id to what he wants...,,No,Yes
7737,TODO: This thing should not interact with the database,,No,Yes
7738,TODO: This thing should not interact with the database,,,Yes
7744,TODO: ensure that this is a full url,,Yes,Yes
7748,Fix for a long standing bug in django flatpages,,,Yes
7749,Fix for a long standing bug in django flatpages,,Yes,Yes
7751,TODO: Provide a queryset,,,Yes
7753,TODO: add the readers group and make the correct permissions,,,Yes
7754,TODO: validate the answer type,,,Yes
7755,TODO: Should it be UserIsChallengeAdminMixin?,,Yes,Yes
7756,TODO: add the readers group and make the correct permissions,,,Yes
7758,Workaround to ensure DjangoModelPermissions are not applied,,Yes,Yes
7759,Workaround to ensure DjangoModelPermissions are not applied,,Yes,Yes
7760,TODO: add terms_of_service and contact,,No,Yes
7761,TODO: add validators=[JSONSchemaValidator(schema=ANSWER_TYPE_SCHEMA)];,,,Yes
7764,TODO: this view also contains the ground truth answer values.,,Yes,Yes
7766,TODO: Handle public permissions,,No,Yes
7768,Just return the internal request if needed,,,Yes
7770,TODO - add region,,,Yes
7771,TODO Email admins,,Yes,Yes
7772,in db so needed...,,,Yes
7773,TODO Email admins,,Yes,Yes
7775,TODO Fix image set dependency,,Yes,Yes
7777,TODO: allow setting of archives for phases,,No,Yes
7779,copyright notice and this permission notice appear in all copies.,,,Yes
7780,Fix issue in upstream where description can be null,,Yes,Yes
7781,TODO For challenges; hidden needs to be refactored to public,,Yes,Yes
7782,TODO JM These functions rely on docker specific code (reader),,,Yes
7783,TODO JM @action(detail=True),,,Yes
7785,TODO reduce number of queries,,,Yes
7786,TODO remove legacy result_dict,,No,Yes
7787,TODO: fix the warnings from types that could not be inferred,,Yes,Yes
7788,Maybe solved in https:\/\/github.com\/tfranzel\/drf-spectacular\/issues\/264,,,Yes
7789,TODO (jmsmkn): Create the tiff files in the correct location,,Yes,Yes
7790,Todo: move this check to execute() code when using inputs is done,,No,Yes
7791,TODO: celery errorhandling with the .on_error seems to not work when,,,Yes
7793,Workaround for,,Yes,Yes
7794,Todo - should be easy to come up with a decent heuristic,,No,Yes
7795,need to swap rows and cols here apparently! confusing!,,,Yes
7796,# DEBUG: draw a border to see where the image ends up,,,Yes
7797,Todo remove code duplication with BalancingDAIterator (call method),,No,Yes
7800,TODO need refinements,,No,Yes
7801,TODO Mainly useful for ImageNet Dataset,,,Yes
7803,"\""\""\""Multi-threaded word2vec mini-batched skip-gram model. ||  || Trains the model described in: || (Mikolov; et. al.) Efficient Estimation of Word Representations in Vector Space || ICLR 2013. || http:\/\/arxiv.org\/abs\/1301.3781 || This model does traditional minibatching. ||  || The key ops used are: || * placeholder for feeding in tensors for each example. || * embedding_lookup for fetching rows from the embedding matrix. || * sigmoid_cross_entropy_with_logits to calculate the loss. || * GradientDescentptimizer for optimizing the loss. || * skipgram custom op that does input processing. || \""\""\""",,,Yes
7804,Unused by updated loading code.,,Yes,Yes
7806,This is needed because the pre-activation variant does not have batch,,Yes,Yes
7807,This is needed because the pre-activation variant does not have batch,,Yes,Yes
7808,TODO think about phase again,,,Yes
7812,unused by sample_fn,,,Yes
7816,TODO: remove this when Dataset API improves.,,No,Yes
7817,needed for the gather,,Yes,Yes
7818,An extension maybe only correct the sparse blob.,,Yes,Yes
7819,Unused for now.,,,Yes
7820,sufficient statistics. As a workaround we simply perform the operations,,No,Yes
7822,TODO(n3011): implement variable stripping.,,Yes,Yes
7823,TODO(n3011): Once we strip unused variables; remove references to,,,Yes
7824,TODO(n3011): Revisit this once the problem is addressed. Currently,,Yes,Yes
7825,"\""\""\""Memory efficient gradient computations || credit: https:\/\/github.com\/openai\/gradient-checkpointing\/blob\/master\/memory_saving_gradients.py || \""\""\""",,,Yes
7826,better error handling of special cases,,No,Yes
7828,TODO: Place the hing\/xent loss in a for loop.,,Yes,Yes
7829,Is this a problem with our unit tests or a real bug?,,Yes,Yes
7831,Check how many levels of recursion we should be going.,,,Yes
7834,This is currently undocumented until we have explored better options,,Yes,Yes
7837,This is currently undocumented until we have explored better options,,Yes,Yes
7840,For some reason this is needed to make unit `x + x` pass on TF 1.14,,,Yes
7844,#more engineered but efficient in code: only add template chunk to memory; not full large template batch,,,Yes
7845,#slow; pooling better,,,Yes
7847,#TODO freeze gradient of decode?,,,Yes
7851,Adding controllers displayed as columns,,,Yes
7854,TODO: warn,,,Yes
7855,TODO: reduce properly,,,Yes
7856,TODO: Issue #19,,No,Yes
7857,TODO: find better solution,,,Yes
7858,TODO,,,Yes
7861,Adding controllers displayed as columns,,No,Yes
7863,TODO: How to obtain cdf that is consistent with the estimated PDF?,,,Yes
7865,TODO: integrate cdf stepfunction,,Yes,Yes
7866,TODO: posterior sampling,,No,Yes
7867,TODO more validations,,,Yes
7869,TODO need more validation in nlp,,,Yes
7871,tensorflow2paddle fix problem temporary,,Yes,Yes
7872,TODO,,,Yes
7874,construct arguments needed by custom layer function from node's parameters,,Yes,Yes
7875,"\""\""\"" a custom layer for 'argmax'; maybe we should implement this in standard way. ||     more info can be found here: http:\/\/caffe.berkeleyvision.org\/tutorial\/layers\/argmax.html || \""\""\""",,,Yes
7877,"\""\""\"" a custom layer for 'flatten'; maybe we should implement this in standard way. ||     more info can be found here: http:\/\/caffe.berkeleyvision.org\/tutorial\/layers\/flatten.html || \""\""\""",,No,Yes
7880,"\""\""\"" a custom layer for 'reshape'; maybe we should implement this in standard way. ||     more info can be found here: http:\/\/caffe.berkeleyvision.org\/tutorial\/layers\/reshape.html || \""\""\""",,Yes,Yes
7888,TODO: Find a better solution for this.,,No,Yes
7889,WORKAROUND: RuntimeError: No Adapter For OP,,No,Yes
7894,attrs bypassed; FIXME: emit squeeze2,,Yes,Yes
7895,FIXME: emit transpose2,,,Yes
7896,attrs bypassed; FIXME: emit unsqueeze2,,,Yes
7897,FIXME: axis=-1 in Paddle is broken; refer it in specialization,,,Yes
7898,TODO: pow for scalar exponent,,No,Yes
7899,additional; maybe var_name,,Yes,Yes
7903,TODO:,,,Yes
7904,attrs bypassed; FIXME: emit flatten2,,,Yes
7905,FIXME: out is int64 vs int32,,,Yes
7906,attrs bypassed; FIXME: emit squeeze2,,,Yes
7907,FIXME: emit transpose2,,No,Yes
7909,TODO: pow for scalar exponent,,No,Yes
7910,additional; maybe var_name,,,Yes
7911,FIXME: Paddle 1.3 Doc: '\u5BF9\u4E8E\u672A\u77E5\u5927\u5C0F\u7EF4\u5EA6\u7684\u672B\u5C3E\u8FDB\u884C\u5207\u7247\uFF0C\u5219\u5EFA\u8BAE\u4F20\u5165 INT_MAX' not works ?,,No,Yes
7913,FIXME: default axis = -1; reshape required before and after,,No,Yes
7914,WORKAROUND: shape of scalars is [],,Yes,Yes
7915,WORKAROUND: bad scalar support,,No,Yes
7916,FIXME: Paddle 1.3 Doc: '\u5BF9\u4E8E\u672A\u77E5\u5927\u5C0F\u7EF4\u5EA6\u7684\u672B\u5C3E\u8FDB\u884C\u5207\u7247\uFF0C\u5219\u5EFA\u8BAE\u4F20\u5165 INT_MAX' not works ?,,,Yes
7917,would be a nice idea if the upsampling could be learned too;,,Yes,Yes
7919,TODO: symbolic file routing by domain,,No,Yes
7921,TODO: fix reduce_all ?,,No,Yes
7922,TODO,,Yes,Yes
7923,TODO useless node remove,,Yes,Yes
7924,TODO identity node remove,,Yes,Yes
7926,TODO compute optimize,,No,Yes
7929,custom layer import ends,,Yes,Yes
7930,TODO bn merge,,Yes,Yes
7932,TODO biasadd merge,,,Yes
7933,TODO,,Yes,Yes
7935,TODO,,,Yes
7936,TODO,,,Yes
7938,TODO useless node remove,,,Yes
7941,custom layer import ends,,Yes,Yes
7942,fix paddle shape infer problem,,Yes,Yes
7943,TODO codes without validation,,No,Yes
7944,TODO: this doesn't work with RNN ops,,Yes,Yes
7946,implement; mark as broken in _broken_operators,,Yes,Yes
7947,TODO: make this more efficient,,Yes,Yes
7948,TODO: This method needs a refactor for clarity,,No,Yes
7949,so we don't need this hack anymore,,,Yes
7951,TODO: pow for scalar exponent,,No,Yes
7952,#TODO add node shape inference,,No,Yes
7955,unknown op to ONNX; maybe from higher opset or other domain,,Yes,Yes
7957,#TODO add node shape inference,,,Yes
7958,#TODO add node shape inference,,,Yes
7961,custom layer import ends,,Yes,Yes
7962,TODO support pads is Variable,,Yes,Yes
7963,TODO support pads is Variable,,Yes,Yes
7964,TODO support pads is Variable,,,Yes
7966,TODO support pads is Variable,,Yes,Yes
7968,#TODO add node shape inference,,,Yes
7970,handle sympy_data if needed; for slice in shape computation,,,Yes
7971,unknown op to ONNX; maybe from higher opset or other domain,,Yes,Yes
7973,custom layer import ends,,,Yes
7976,fix paddle shape infer problem,,,Yes
7979,TODO useless node remove,,Yes,Yes
7980,TODO useless node remove,,Yes,Yes
7983,ends_value[idx] = 2**31 - 1,,Yes,Yes
7984,fix paddle shape infer problem,,,Yes
7990,TODO codes without validation,,No,Yes
7991,for idx in range(len(ends_value)):,,No,Yes
7994,Should instead probably remove all parens in outermost parens; while still removing words in,,,Yes
7995,You can just specify the packages manually here if your project is,,Yes,Yes
7997,This passes; when it shouldn't. not sure if there's any way around it,,Yes,Yes
7998,not really efficient to re-run the counter. I think saving counters,,Yes,Yes
7999,seems extremely problematic way to do a loop,,Yes,Yes
8000,"doc = \""How is the treat-ment.5 going. Pretty well\""",,Yes,Yes
8002,better way to do this?,,Yes,Yes
8004,Fix the version of mysqlclient due to windows problems,,,Yes
8005,Fix the minor version so model doesn't change,,Yes,Yes
8009,todo,,,Yes
8011,TODO: Figure out if we are going to blindly pass metrics through; or if we use a strict mapping,,Yes,Yes
8017,TODO: Figure out if we are going to blindly pass metrics through; or if we use a strict mapping,,Yes,Yes
8019,todo; rely on default openml setup; apikey is private...,,Yes,Yes
8023,todo: score predictions and print results,,,Yes
8025,todo: should we use one_hot_encoder here instead?,,,Yes
8027,reorder columns alphabetically: necessary to match label encoding,,,Yes
8029,todo: add mode? local; docker; aws,,Yes,Yes
8030,todo: sort the columns to have index columns; followed by result; metrics and finally version and time,,,Yes
8031,todo: append,,,Yes
8032,TODO:,,No,Yes
8033,apparently no need to load bucket,,Yes,Yes
8035,TODO: reconsider organisation of output files:,,Yes,Yes
8036,todo: sort the columns to have index columns; followed by result; metrics and finally version and utc time,,Yes,Yes
8037,reorder columns alphabetically: necessary to match label encoding,,,Yes
8039,todo: sort the columns to have index columns; followed by result; metrics and finally version and time,,Yes,Yes
8040,todo: append,,No,Yes
8042,todo: switch to subprocess module (Popen) instead of os? would allow to use timeouts and kill signal,,,Yes
8044,todo: pass path to downloaded benchmark def file,,,Yes
8045,todo: error handling,,No,Yes
8046,todo: ideally; would be nice to monitor instance individually and asynchronously; cf. asyncio,,,Yes
8047,todo error handling,,,Yes
8050,todo: timeout,,No,Yes
8051,todo: detect format change; i.e. data_frame columns are different or different order from existing file,,Yes,Yes
8054,TODO: idea is to handle results progressively on the remote side and push results as soon as they're generated,,Yes,Yes
8055,todo: pass path to downloaded benchmark def file,,,Yes
8056,todo: ideally; would be nice to monitor instance individually and asynchronously; cf. asyncio,,Yes,Yes
8057,todo handle mask,,Yes,Yes
8063,"\""\""\"" || **aws** module is built on top of **benchmark** to provide the platform-specific logic || necessary to run a benchmark on EC2 instances: ||  || - create a S3 bucket (if it doesn't already exist). || - upload some resources on S3. || - configures an AWS IAM profile to provide read\/write access to the S3 bucket from the future EC2 instances. || - create jobs and start an EC2 instance for each job: ||     - the EC2 instance download some resources from S3. ||     - the EC2 instance runs the task locally or using docker. ||     - on task completion; the EC2 instance uploads the results and logs to S3 and stops. || - monitors each job and downloads results and logs from s3 when the job is completed. || - merge downloaded results with existing\/local results. || - properly cleans up AWS resources (S3; EC2). || \""\""\""",,Yes,Yes
8064,"\""\""\"" || the **frameworks** package contains all the automl framework subpackages: || each of those framework package can expose the following functions: ||  || - ``run(*args; **kvargs)``: this function is mandatory for each package and is called by each job; ||     providing a ``Dataset`` and a ``TaskConfig`` instance to the framework. ||  ||     The framework should run its automl implementation against the provided dataset; ||     and should try to honour the constraints provided by the task_config. ||  ||     This function is usually implemented by importing the ``exec`` module dynamically ||     and forwarding the parameters to its own ``run`` function:: ||         def run(*args; **kwargs): ||             from .exec import run ||             run(*args; **kwargs) ||  ||     this provides the possibility; if necessary \u2013 for example if the framework depends on libraries incompatible with the app \u2013; ||     to delegates the execution to a different process after serializing the parameters (using json or pickle for example). ||  || - ``setup(*args)``: this function is optional and is called to let the framework install its required dependencies. || - ``docker_commands()``: this function is optional and should return a string with docker commands ||     necessary to install the framework dependencies when building the docker image. ||  ||  || important ||     Ideally; frameworks entry packages should not import any automl module outside **utils** for the reason explained above. ||  || \""\""\""",,Yes,Yes
8066,todo: we can probably remove this command line argument: by default; we're using the user default region as defined in ~\/aws\/config,,,Yes
8067,todo: impute only if np.isnan(X_fit).any() ?,,,Yes
8068,todo: we can probably remove this command line argument: by default; we're using the user default region as defined in ~\/aws\/config,,No,Yes
8069,no reordering needed; not data to load; returning original path,,,Yes
8071,no reordering needed; returning loaded data or original path,,No,Yes
8072,todo: provide the possibility to return data even if save is set to false;,,Yes,Yes
8074,todo: do we still want to delete resources if concern in _upload_resources is fixed?,,,Yes
8075,allows to import modules outside project: should work on AWS as well;,,,Yes
8076,fixme: doesn't allow to build docker images for custom versions of h2o,,Yes,Yes
8077,todo: should we be able to pass as seed for reproducibility (or to see improvements\/degradation across versions),,Yes,Yes
8078,TODO: error handling,,,Yes
8082,TODO: use rpy2 instead? not necessary here though as the call is very simple,,,Yes
8083,TODO: could support unlimited args by making a tuple out of *args + **kwargs: not needed for now,,,Yes
8086,TODO: would be nice to reload generated scores and return them,,Yes,Yes
8088,cast columns to have float types,,,Yes
8092,for categories represented as numerical values; h2o prefixes the probabilities columns with p,,Yes,Yes
8096,TODO: support non-merged classes,,No,Yes
8097,"TODO: change this to a dependency on the \""transformer\""",,Yes,Yes
8099,"\""\""\"" || From: https:\/\/www.figure-eight.com\/data-for-everyone\/ ||  || Customer review task from SentEval.  Note that performance on this dataset is not comparable to official SentEval scores because of differences in data splitting. || \""\""\""",,No,Yes
8102,"\""\""\"" || From: https:\/\/www.figure-eight.com\/data-for-everyone\/ ||  || Stanford Sentiment Treebank binary task from SentEval.  Note that performance on this dataset is not comparable to official SentEval scores because of differences in data splitting. || \""\""\""",,,Yes
8104,TODO Data is hard coded although seems configurable from config.,,,Yes
8106,TODO: make weights as variables,,,Yes
8107,TODO: binary search,,Yes,Yes
8114,TODO: binary search,,,Yes
8117,Our scenario is easy we exactly know what value we want,,No,Yes
8118,todo,,No,Yes
8119,todo node.stdev?,,,Yes
8120,TODO: That threshold needs some evidence or theoretical grounding,,No,Yes
8122,import all needed data and modules,,No,Yes
8123,todo double check here,,No,Yes
8124,todo should node.scope be adjusted?,,,Yes
8125,todo check again node.scope and par scope,,Yes,Yes
8129,todo,,,Yes
8130,output_mask = np.zeros(data.shape; dtype=bool)   # todo check scope and node.scope again,,,Yes
8132,TODO: Build Context wrapper according to README.md; this should work pretty well,,Yes,Yes
8133,TODO: Remove?,,No,Yes
8143,TODO handle zeros for efficiency; darwiche 2003,,Yes,Yes
8144,-- Options for todo extension ----------------------------------------------,,,Yes
8147,Implement product as convolution,,,Yes
8148,Create index map from flattened to coordinates (only needed in sampling),,Yes,Yes
8149,TODO: maybe check padding?,,No,Yes
8151,TODO: Implement more torch distributions,,,Yes
8152,-- Options for todo extension ----------------------------------------------,,Yes,Yes
8155,Since we have 3 variables; we want to create a 2D numpy array of 3 columns,,Yes,Yes
8157,TODO iterate through all files,,Yes,Yes
8159,TODO indicatives long list,,,Yes
8160,TODO connecting long list,,,Yes
8163,is_annotation(words from start to start+length) { # TODO precise pseudocode,,Yes,Yes
8164,TODO mode select inclusive\/exclusive,,,Yes
8167,TODO annotation options (map information to stuff),,Yes,Yes
8170,TODO incomplete connecting list,,Yes,Yes
8172,TODO annotation options (map information to stuff),,Yes,Yes
8173,TODO regex tree? search to increase performance if needed (profiling),,Yes,Yes
8175,FIXME check for whole document,,Yes,Yes
8176,TODO just abstracts or whole documents?,,Yes,Yes
8179,TODO (1) offset check,,,Yes
8180,TODO docs with at least one nl mention vs total number (3),,,Yes
8181,TODO convention filtering,,Yes,Yes
8183,TODO complete conventions according to HGVS and set of regexs by tmVar (3),,,Yes
8184,TODO Abstract vs Full document ratio (2),,Yes,Yes
8186,FIXME so inclsuive and exclsuiev can be achieved here (5),,,Yes
8188,TODO Abstract vs Full document ratio (2),,Yes,Yes
8189,TODO Export into other file. (20),,,Yes
8190,TODO do inclusive run (1),,,Yes
8191,TODO do inclusive run export (2),,Yes,Yes
8192,TODO do exclusive run (4),,,Yes
8194,FIXME Add __main__ function so this can be imported as module,,,Yes
8197,TODO do inclusive run (1),,No,Yes
8198,TODO do inclusive run export (2),,Yes,Yes
8202,TODO Export into other file. (20),,,Yes
8203,TODO incomplete connecting list (30),,,Yes
8208,is_annotation(words from start to start+length) { # TODO precise pseudocode (15),,,Yes
8209,TODO (3) get top 5 words,,No,Yes
8210,OPTIONAL regex tree? search to increase performance if needed @profiling,,,Yes
8213,FIXME replace to other folder,,,Yes
8217,TODO (6) add hgvs package,,Yes,Yes
8218,FIXME return object as dictionary,,Yes,Yes
8229,TODO full nl nr \/ full tot token nr,,,Yes
8232,TODO save that in config file,,,Yes
8234,TODO 0;1;2;3;4+ instead of len = nr,,,Yes
8235,TODO check if ok the implementation (edge cases e.g. numeric means 123.232? or 123 and 232?),,No,Yes
8236,"TODO last token include: \""&& $last_token[...]\""",,Yes,Yes
8239,TODO suffix patterns,,,Yes
8240,"TODO last token include: \""&& $last_token[...]\""",,,Yes
8243,TODO last token,,Yes,Yes
8244,TODO add introductory explanation,,,Yes
8245,TODO 0;1;2;3;4+ instead of len = nr,,Yes,Yes
8246,TODO change to sensefull way,,,Yes
8247,TODO last token,,Yes,Yes
8251,TODO add introductory explanation,,Yes,Yes
8252,TODO change to sensefull way,,Yes,Yes
8256,TODO shift position to get correct labeling on bars,,Yes,Yes
8258,TODO fix docstring,,No,Yes
8259,TODO docsting,,,Yes
8260,TODO figure out how to best set class_id independent from Labeler used,,Yes,Yes
8261,TODO figure out how to best set class_id independent since we don't know it,,,Yes
8263,fix boundary #17000021\t251\t258\t1858C>T --> +1858C>T,,No,Yes
8265,fix boundary add missing ),,Yes,Yes
8270,TODO Rename implementation class to include Impl in the name,,Yes,Yes
8277,meta3 = ET.SubElement(head; 'meta'; { 'name': 'dcterms.source'; 'content' : 'http:\/\/www.ncbi.nlm.nih.gov\/pubmed\/' + pubmedid } )  # deprecated maybe different sources,,,Yes
8278,"TODO \""s#p# naming convention\"" for id",,,Yes
8279,TODO: Remove this when done implementing issue #65,,No,Yes
8282,TODO if possible; change parts & sentences & tokens from List to Tuple,,Yes,Yes
8284,TODO,,,Yes
8285,TODO,,,Yes
8286,FIXME is that ok? --> self in outer class method,,No,Yes
8287,TODO,,Yes,Yes
8291,print(confidence; confidence_values)  TODO print debug,,,Yes
8292,TODO lowercase,,No,Yes
8295,TODO document this better and move it to a more appropriate place,,Yes,Yes
8296,TODO export annotations as well,,,Yes
8297,TODO consolidate with bootstrapping section,,Yes,Yes
8298,TODO fix bug in equality_operator calculations @aleksandar (have to speak about that on skype; etc.),,,Yes
8299,FIXME should be x1.offset < (y.offset + len(y.text)) or x1.offset <= (y.offset + len(y.text) - 1) same for the other condition,,No,Yes
8302,"ANN2 = \""     XXX \""",,Yes,Yes
8305,TODO nltk include for each sentence,,Yes,Yes
8306,todo docset,,,Yes
8307,todo check whether right offsets (especially the last one),,Yes,Yes
8308,FIXME huge bug.... -.- regex on sentence lvl but overlap search on document lvl,,,Yes
8309,TODO nltk include for each sentence,,Yes,Yes
8310,todo textfile tagger @major,,Yes,Yes
8311,todo provide method to create new pattern on an automated base,,,Yes
8312,TODO change if idp4 then those results otherwise use tmvartagger and caching,,No,Yes
8314,todo save performances to file,,Yes,Yes
8315,todo learning,,,Yes
8316,todo check for ability to use crfsuite command instead of abspath,,,Yes
8317,"fixme path to read is only \""\/reviewed\/\""",,Yes,Yes
8319,todo discussion on config file in bootstrapping root or iteration_n check for n,,Yes,Yes
8321,todo learning,,No,Yes
8323,todo this method get previous ids,,Yes,Yes
8324,todo divide into 2 parts with 1st being learning; docselection; tagging and the 2nd being manual import and evaluation,,,Yes
8325,todo check for evaluation done (writing in csv file),,No,Yes
8327,todo create pattern performance eval for descending amount of recognized patterns,,No,Yes
8328,TODO when creating new prediction which confidence should we add,,Yes,Yes
8330,todo finish docset of Iteration Class,,,Yes
8331,fixme pmids not only in form asdjkasdjlja-pmid.plain.html or dasdas-pmid.ann.json but also in pmid.html or pmid.ann.json,,,Yes
8332,fixme print verbose not executed.... why? just highrecallregex filter.... no idea,,Yes,Yes
8333,todo clean print statement,,,Yes
8337,todo question is that the proper way? with predicts_classes,,Yes,Yes
8340,todo ist noch falsch...,,,Yes
8343,todo major refactor to learning\/taggers class,,,Yes
8347,"\""confidence\"": 1  # todo discussion confidence from GNormPlus is not provided so just putting in here 1",,Yes,Yes
8348,"\""confidence\"": 1  # todo discussion confidence from GNormPlus is not provided so just putting in here 1",,Yes,Yes
8349,"\""confidence\"": 1  # todo discussion confidence from GNormPlus is not provided so just putting in here 1",,Yes,Yes
8356,TODO Design decision; whether to retain sentence or retain part and sentence id,,,Yes
8357,TODO review this method,,Yes,Yes
8359,TODO Design decision; whether to retain sentence or retain part and sentence id,,,Yes
8361,todo debug purpose; has to be deleted,,Yes,Yes
8364,TODO plus minus,,,Yes
8365,TODO this should not be part of nalaf,,Yes,Yes
8366,TODO this should not be part of nalaf,,Yes,Yes
8368,todo question is that the proper way? with predicts_classes,,Yes,Yes
8369,TODO SpaCy will soon have it's own constituency parser; integrate that,,No,Yes
8370,TODO rest is potential material to delete; almost exact copy in relna's sentence.py,,Yes,Yes
8371,TODO populate with something minimally meaningful,,No,Yes
8372,TODO rest is potential material to delete; almost exact copy in relna's sentence.py,,,Yes
8374,TODO Juanmi: I do not understand why the extra inner loop here (not in original LocText),,,Yes
8375,TODO all following readers are deprecated and should be moved to nala,,Yes,Yes
8377,TODO should we rewrite the edges?,,,Yes
8380,TODO or -1 and +1 ? or negative or positive?,,,Yes
8383,TODO we likely need a pair of sentence ids for non same-sentence relationships,,No,Yes
8385,TODO we may need the following,,,Yes
8389,TODO,,,Yes
8390,Note: would be nice to implement the word filter too here -- see below,,No,Yes
8392,The best best solution would be to be able to retrieve the part and sentence_id from the entities directly,,,Yes
8394,TODO we should much more carefully take care of its type; and whether it could even contain other values,,,Yes
8395,TODO delete this old code:,,,Yes
8396,TODO,,Yes,Yes
8397,TODO,,Yes,Yes
8398,TODO this may be too relna-specific,,,Yes
8399,The following code can be made more efficient by iterating only once over the tokens lists,,No,Yes
8402,TODO we could set it as real value - \u26A0\uFE0F that's what `entityhead::named_entity_count` did,,,Yes
8405,TODO #28,,No,Yes
8406,"\""\""\"" || Combined dependency-based features implementation as succintly described in Shrikant's Master's Thesis (Section 4.5): || https:\/\/github.com\/juanmirocks\/LocText-old-ShrikantThesis\/files\/474428\/MasterThesis.pdf ||  || The implementation consider 4 types of dependency types: ||  || * OW (1 and 2): Outer Window == tokens at the outer side of an entity (1 or 2) || * IW (1 and 2): Inner Window == tokens at the inner side of an entity (1 or 2) || * LD: Linear Dependency == tokens within the two entities || * PD: Parsing Dependency == real dependency parsing obtained from spaCy's library ||  || \""\""\""",,Yes,Yes
8408,MAYBE Dikjstra algorithm is way more efficient for this case,,Yes,Yes
8409,MAYBE As of now; matrises are written fully. An obvious performance improvement is to write them sparsely.,,,Yes
8414,TODO,,,Yes
8415,todo,,,Yes
8417,but that would require either converting feature values here or enforcing type in EdgeFeatureGenerator,,,Yes
8420,"PAR1 = \""XXX      \""",,No,Yes
8421,TODO make it efficient with direct dictionary indexing or perhaps using a dok_matrix,,Yes,Yes
8424,TODO use_pred ?,,,Yes
8432,TODO,,,Yes
8433,In 1.0.0 they move .vocab: https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/master\/CHANGELOG.md#100-2017-02-24,,Yes,Yes
8438,TODO Inferred concepts have an id; but can we treat them exactly the same as non-inferred; or must we keep the,,Yes,Yes
8439,TODO See above; omitting due to bug,,Yes,Yes
8441,# data_type = 0 for non-attributes; TODO or use None\/NaN and then zero-index instead?,,,Yes
8442,TODO pass this in or make into class variable?,,,Yes
8444,TODO Only required while we have a bug on roles as variables in Graql,,Yes,Yes
8448,TODO should this be a constant tensor?,,No,Yes
8449,TODO Hacky; don't like it,,Yes,Yes
8450,TODO Changing queries due to bug,,,Yes
8451,TODO Needs renaming from concept to avoid confusion,,Yes,Yes
8453,TODO Add actual string encoder,,,Yes
8454,TODO Needs renaming from concept to avoid confusion,,Yes,Yes
8456,TODO Changing queries due to bug,,Yes,Yes
8458,TODO Pass this to traversal\/executor,,No,Yes
8460,TODO Update and move now this isn't used here,,Yes,Yes
8461,Any steps needed to get arrays ready for the rest of the pipeline,,,Yes
8462,TODO remove,,,Yes
8463,TODO The following didn't work; but performing from the console did,,,Yes
8469,TODO Get rid of pointless lambdas,,,Yes
8472,TODO Deal with where to build arrays,,Yes,Yes
8476,this flush method is needed for python 3 compatibility.,,Yes,Yes
8477,TODO (7; 2; 2) Throws an error without rules,,,Yes
8481,TODO Should this be an array not a list?,,,Yes
8482,TODO (7; 2; 2) Throws an error without rules,,,Yes
8483,TODO Should this be an array not a list?,,,Yes
8484,this flush method is needed for python 3 compatibility.,,,Yes
8490,TODO Remove formatters,,Yes,Yes
8493,TODO Remove; but useful for debugging,,,Yes
8494,Could be renamed to a frame\/situation\/region\/ROI(Region of Interest)\/locale\/zone,,Yes,Yes
8496,TODO do we want to see @has-attribute here?,,Yes,Yes
8497,TODO This should be called in a loop when using more than one batch,,Yes,Yes
8499,TODO Presently unused; should be removed if unnecessary,,Yes,Yes
8500,TODO Presently unused,,Yes,Yes
8501,tf.summary.histogram('classification\/dense\/kernel'; classification_layer.kernel)  # TODO figure out why,,No,Yes
8507,print(pmf.to_dataframe()) # TODO Remove pandas if this is not needed now,,,Yes
8511,TODO: the NN strategy is not actually used by this class,,Yes,Yes
8512,TODO (wardlt): Consider breaking this off into its own class method,,Yes,Yes
8513,TODO (wardlt): Misses atoms in two rings of the same size,,No,Yes
8516,TODO (wardlt): These libraries are required. Should we remove try\/catch,,Yes,Yes
8517,If needed; add the targets,,,Yes
8518,Compile the inputs in needed order,,Yes,Yes
8520,serialize is needed here,,Yes,Yes
8521,complement stain matrix if needed,,No,Yes
8522,"extract solutions and make columns of \""W\"" unit-norm",,Yes,Yes
8523,complement stain matrix if needed,,,Yes
8525,complement stain matrix if needed,,No,Yes
8528,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
8529,TODO: put package requirements here,,,Yes
8530,TODO: Ensure these are actually provided,,Yes,Yes
8531,TODO: Ensure these are actually provided,,,Yes
8534,TODO: Ensure these are actually provided,,Yes,Yes
8535,TODO: This function fails the style checker's maximum complexity requirement,,Yes,Yes
8536,complement stain matrix if needed,,,Yes
8538,process columns,,,Yes
8539,fix boundary conditions,,No,Yes
8542,do stuff needed to create REST endpoint for cLI,,,Yes
8544,convert intensity image type to float if needed,,,Yes
8547,do stuff needed to create REST endpoint for cLI,,Yes,Yes
8550,TODO: Ensure these are actually provided,,Yes,Yes
8552,TODO: Ensure these are actually provided,,Yes,Yes
8554,TODO: Ensure these are actually provided,,Yes,Yes
8556,pick the best scoring candidates and cut if needed,,No,Yes
8557,no cut made; move to next object,,Yes,Yes
8558,iterate through objects; replicating where needed,,No,Yes
8559,check addtional points if needed,,No,Yes
8560,iterate through objects; calculating distances where needed,,Yes,Yes
8561,add columns to dataframe,,No,Yes
8562,clip to ends,,,Yes
8567,iterate through objects; calculating distances where needed,,,Yes
8568,fix boundary conditions,,,Yes
8571,process columns,,Yes,Yes
8572,TODO check if a newer version should be pulled,,,Yes
8573,TODO remove bad image names,,Yes,Yes
8575,TODO apply try catch blocks individually and catch specific exceptions,,Yes,Yes
8576,TODO pull non existent image names,,Yes,Yes
8580,TODO use image id to confirm equivalence need v2 manifest schema on cloud,,,Yes
8581,TODO how to handle duplicate clis,,,Yes
8583,some validation of folder here would be a good idea,,Yes,Yes
8584,Could maybe be expanded to handle all regular expressions?,,Yes,Yes
8588,clip to ends,,,Yes
8591,TODO validate with xml schema,,,Yes
8593,TODO check\/validate schema of dict,,Yes,Yes
8601,boiler plate to start and stop the server if needed,,,Yes
8605,calculate directed cross-product of first two columns,,,Yes
8606,boiler plate to start and stop the server if needed,,Yes,Yes
8610,TODO: Should we list Girder here?,,,Yes
8611,TODO it's not clear what 'chord length' refers to in the paper,,Yes,Yes
8612,TODO chords,,No,Yes
8614,boiler plate to start and stop the server if needed,,,Yes
8615,save a copy of ROI-only mask to crop to it later if needed,,,Yes
8616,Now crop polygons to roi if needed (prevent 'overflow' beyond roi edge),,No,Yes
8617,save a copy of ROI-only mask to crop to it later if needed,,Yes,Yes
8619,to keep track of things better relative to contour_group; now it is:,,No,Yes
8621,colnames = edge_contours[list(edge_contours.keys())[0]].columns,,,Yes
8622,Less obviously: using object graph directly leads to really long GC,,No,Yes
8626,"\""\""\"" || Created on Thu Sep 19 02:25:34 2019. ||  || @author: mtageld || \""\""\""",,,Yes
8627,#NAME?,,,Yes
8629,"\""\""\"" || Created on Tue Sep 24 00:43:04 2019. ||  || @author: mtageld || \""\""\""",,,Yes
8631,color variations and sometimes gives better results,,,Yes
8633,"\""\""\"" || Created on Mon Sep 30 22:09:40 2019 ||  || @author: mtageld || \""\""\""",,,Yes
8635,and using reordered such that columns are the order:,,Yes,Yes
8637,TODO -- incorporate masking and macenko!!,,,Yes
8639,TODO -- fix me,,Yes,Yes
8640,TODO -- fix me!!!!,,Yes,Yes
8641,TODO -- instead; smoother visualization bounds (at MAG),,,Yes
8642,and using reordered such that columns are the order:,,Yes,Yes
8643,TODO -- fix me,,Yes,Yes
8644,TODO -- fix me!!!!,,,Yes
8649,TODO -- This is likely a bug (?); fix me!!!,,Yes,Yes
8650,"\""\""\"" || Created on Mon Sep 30 18:12:48 2019. ||  || @author: mtageld || \""\""\""",,,Yes
8652,go through annotation elements and add as needed,,No,Yes
8653,crop using shapely to desired bounds if needed,,Yes,Yes
8655,and using reordered such that columns are the order:,,Yes,Yes
8656,"\""\""\"" || Created on Wed Sep 18 00:06:28 2019. ||  || @author: mtageld || \""\""\""",,Yes,Yes
8657,A bug in scikit-image could produce a (very slightly),,No,Yes
8660,Add the adjusted ends.,,Yes,Yes
8661,TODO; we need verify this after onnx opset 10 release,,No,Yes
8662,Make the seed meet C-style naming convention,,Yes,Yes
8663,A operator has an input; so we remove the operator from the unused-operator list.,,,Yes
8664,A operator has an output; so we remove the operator from the unused-operator list.,,Yes,Yes
8665,Scan through all operators and adjust their variables' shapes if needed,,,Yes
8666,We fix this problem here.,,Yes,Yes
8667,Remove unused operators,,,Yes
8669,Check input naming convention,,,Yes
8670,Check output naming convention,,,Yes
8671,We implement Upsample through Resize instead,,No,Yes
8672,TODO: implement postprocessing of inference results,,No,Yes
8673,OPTIONAL TODO: implement preprocessing of PIL image objects,,No,Yes
8674,OPTIONAL TODO: implement preprocessing of SimpleITK image objects,,Yes,Yes
8675,TODO: implement preprocessing of image after it was converted to a numpy array,,Yes,Yes
8676,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
8677,Todo:,,No,Yes
8680,TODO,,Yes,Yes
8684,TODO handle case where no permission to create folder,,Yes,Yes
8686,tree_array = columns_to_tree(columnsfile),,,Yes
8691,Add filename to SUBJ_ID; this is a work around for unique path constraint.,,Yes,Yes
8694,column number columns. If no df parameter is not set; build index,,,Yes
8695,# df.set_index(list(df.columns[[0; 1]]); drop=False; inplace=True),,Yes,Yes
8697,Put back the right order of columns after concatenating the two dataframes,,Yes,Yes
8698,Put back the right order of columns after concatenating the two dataframes,,Yes,Yes
8701,TODO: add reference columns to blueprint mapping,,No,Yes
8702,TODO: find name of variable column,,Yes,Yes
8703,TODO: add reference columns to blueprint mapping,,,Yes
8705,TODO: Check if file is Excel,,,Yes
8707,check if 'metadata tag' and 'metadata value' columns have a corresponding 'Level' column:,,No,Yes
8709,check values in columns,,Yes,Yes
8710,Fill level columns of metadata-only rows with values from the previous row,,,Yes
8711,TODO these lines should be removed as they are now part of the template validation,,Yes,Yes
8712,Make the array of booleans equal length to the number of columns in the full df,,Yes,Yes
8713,code below uses private APIs; it will probably break (and doesn't work) -- hopefully coreml ships official support soon,,Yes,Yes
8714,needed for Resnet152 support,,No,Yes
8715,no idea why the Python 2 CI won't run these models (they run out of memory),,,Yes
8716,no idea why the Python 3.6 CI won't run these models (they run out of memory),,Yes,Yes
8718,FIXME: Open a file and dump stats to it later,,,Yes
8721,FIXME: Only 4 types are supported now. Support more types later.,,No,Yes
8723,FIXME: Need to check if mod is the equivalent of floorMod in NumPy,,Yes,Yes
8725,FIXME: This only works if we call np.mean on b[0]. Need to figure out why.,,Yes,Yes
8726,FIXME: Make this work with any type; not just float32,,Yes,Yes
8727,FIXME: This seems to work; but not sure if it always does,,No,Yes
8728,FIXME: Can't inject faults into unpack as it's not a tensor or scalar,,Yes,Yes
8729,FIXME: This throws an exception; so we dummied it out,,,Yes
8730,FIXME: According to tf doc; this should only take 2 arguments,,,Yes
8731,\tbut somehow it is complaining that it requires 3 arguments,,Yes,Yes
8732,FIXME: Actually implement the Switch operation,,Yes,Yes
8733,FIXME: According to the TF docs; this operation doesn't exist !,,,Yes
8734,### If you implement any of them; please move them above the line              ####,,Yes,Yes
8735,FIXME: Should we NOT actually do the operation as well ??,,Yes,Yes
8737,\tAlso; maybe these should be sorted alphabetically - this is getting quite big,,Yes,Yes
8739,FIXME: Not sure if Min is a synonymn of Minimum or a new operation,,Yes,Yes
8741,FIXME: We should provide some degree of roll-back and retry here,,,Yes
8742,If it's the last process; only launch as many injections as needed,,,Yes
8745,activations such that no rescaling is needed at evaluation time.,,,Yes
8747,Hack to build the indexing and retrieve the right output.,,Yes,Yes
8748,"\""\""\"" K-Means. ||  || Implement K-Means algorithm with TensorFlow; and apply it to classify || handwritten digit images. This example is using the MNIST database of || handwritten digits as training samples (http:\/\/yann.lecun.com\/exdb\/mnist\/). ||  || Note: This example requires TensorFlow v1.1.0 or over. ||  || Author: Aymeric Damien || Project: https:\/\/github.com\/aymericdamien\/TensorFlow-Examples\/ || \""\""\""",,Yes,Yes
8750,FIXME: Need to debug why this doesn't work,,,Yes
8753,Get the next batch of MNIST data (only images are needed; not labels),,,Yes
8754,Get the next batch of MNIST data (only images are needed; not labels),,Yes,Yes
8755,''' || A linear regression learning algorithm example using TensorFlow library. ||  || Author: Aymeric Damien || Project: https:\/\/github.com\/aymericdamien\/TensorFlow-Examples\/ || ''',,Yes,Yes
8756,''' || A linear regression learning algorithm example using TensorFlow library. ||  || Author: Aymeric Damien || Project: https:\/\/github.com\/aymericdamien\/TensorFlow-Examples\/ || ''',,Yes,Yes
8758,data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes),,No,Yes
8759,Only convert object type of columns,,No,Yes
8760,You can manually specify the instance here rather than using the random instances,,,Yes
8763,Note that we could use better randomization across epochs.,,Yes,Yes
8766,FIXME: According to tf doc; this should only take 2 arguments,,,Yes
8767,\tbut somehow it is complaining that it requires 3 arguments,,,Yes
8768,"\""Cast\"": inputgen_Cast; # this raises an exception; apparently cannot pass the dtype parameter to create_op(); must figure out a way around this",,Yes,Yes
8769,Get the next batch of MNIST data (only images are needed; not labels),,Yes,Yes
8771,random index of the bit to flip (switch to low=0 if you don't want to inject fault to sign bit),,,Yes
8772,FIXME: this should be avoided,,No,Yes
8776,Reverse may be more efficient,,,Yes
8778,"df.columns = [\""dataset\""; \""id\""; \""num_proteins\""; \""num_species\"";",,,Yes
8779,FIXME: 10 repeats might not be enough,,,Yes
8781,-- Options for todo extension ----------------------------------------------,,Yes,Yes
8782,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
8785,FIXME: following is duplicated from Evaluation\/utils.py,,No,Yes
8786,Note: here query_cl maybe a higher level cl,,No,Yes
8787,TODO: We can do some sort of interpolation here to further improve,,No,Yes
8790,TODO!!!,,Yes,Yes
8792,TODO implement send_hardware_metrics,,No,Yes
8793,TODO implement run_monitoring_thread,,Yes,Yes
8794,TODO implement handle_uncaught_exceptions,,,Yes
8795,FIXME delete all of these transitions,,Yes,Yes
8796,FIXME,,Yes,Yes
8797,In this case; this thread is not needed anymore.,,,Yes
8799,TODO implement handle_uncaught_exceptions,,,Yes
8800,FIXME delete all of these transitions,,Yes,Yes
8801,FIXME,,Yes,Yes
8802,TODO: change error type and info,,No,Yes
8804,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
8806,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
8807,TODO: remove this pylint exception once we stop supporting Python 2,,,Yes
8808,TODO add custom types,,Yes,Yes
8809,TODO In the specification; a Variable does not hold data directly;,,Yes,Yes
8810,fewer delegated method calls; but perhaps there are other requirements,,,Yes
8812,TODO need to determine the type while creating the Variable?,,Yes,Yes
8813,TODO check that the type is supported by the Series structure,,No,Yes
8815,FIXME We provide a global list of conversions in the prototype.,,Yes,Yes
8817,Also; lookup should be made efficient.,,Yes,Yes
8822,TODO path validation; empty path,,,Yes
8823,TODO: implement batch update methods: assign; log; add,,Yes,Yes
8826,TODO message,,No,Yes
8830,TODO validate and normalize to \/path\/to\/variable,,,Yes
8831,TODO check that the type is supported by the Series structure,,No,Yes
8833,TODO mark interface methods with decorators?,,Yes,Yes
8834,TODO validate and normalize to \/path\/to\/variable,,Yes,Yes
8836,TODO atomicity?,,,Yes
8839,TODO support all methods on structures,,No,Yes
8841,TODO allow for changing type?,,,Yes
8842,TODO handle custom step and timestamp,,,Yes
8845,# TODO handle steps and timestamps,,Yes,Yes
8849,TODO: Support steps and timestamps,,No,Yes
8850,TODO: self.assertEqual(exp['some\/num\/val'].get_values(); 5),,,Yes
8851,"TODO: self.assertEqual(exp['some\/str\/val'].get_values(); \""some text\"")",,Yes,Yes
8853,TODO: Support steps and timestamps,,,Yes
8854,TODO: Should be None or exception?,,Yes,Yes
8855,TODO: Do not use NeptuneAuthenticator from old_neptune. Move it to new package.,,Yes,Yes
8856,TODO: Consider renaming 'api_address' (breaking backward compatibility),,,Yes
8858,TODO: Avoid loop,,No,Yes
8859,TODO: Avoid loop,,,Yes
8862,TODO: Support Image value,,No,Yes
8863,TODO: Do not use NeptuneAuthenticator from old_neptune. Move it to new package.,,Yes,Yes
8864,TODO: Use new upload endpoint,,,Yes
8865,FIXME,,,Yes
8866,TODO: Return errors to OperationProcessor,,No,Yes
8868,TODO: Handle errors,,Yes,Yes
8872,TODO once the new client is released; this file should be registered as a command line entry point,,,Yes
8873,TODO Implement me,,,Yes
8874,TODO print in color once colored exceptions are added,,Yes,Yes
8875,TODO print in color once colored exceptions are added,,,Yes
8876,TODO Temporary hardcoded version to make work installing from github,,Yes,Yes
8877,# TODO handle the error,,,Yes
8879,TODO: Improvement. How to determine which backend class should be used?,,,Yes
8880,TODO: handle other data types,,,Yes
8881,TODO: what is step?,,No,Yes
8882,TODO: handle `FileChunkStream` or update `neptune.experiments.Experiment._start`,,Yes,Yes
8883,TODO: handle soft errors,,,Yes
8886,TODO,,Yes,Yes
8887,TODO: NPT-9216,,,Yes
8888,TODO: NPT-9216,,,Yes
8889,TODO: what about img: `name` and `description` fields?,,,Yes
8892,self.exp[f'{PROPERTIES_ATTRIBUTE_SPACE}prop_list'] = [1; 2; 3]  # TODO: merge changes from alpha,,,Yes
8893,neptune.set_property('prop_list'; [1; 2; 3])  # TODO: merge changes from alpha,,Yes,Yes
8894,del self.exp[SYSTEM_TAGS_ATTRIBUTE_PATH]  # TODO: NPT-9222,,,Yes
8896,neptune.remove_tag('tag2_to_remove')  # TODO: NPT-9222,,No,Yes
8898,'init_list': [1; 2; 3];  # TODO: Error 500 in old client,,Yes,Yes
8902,TODO: what about those missing attributes,,Yes,Yes
8905,maybe improved later,,,Yes
8906,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
8909,maybe improved later,,,Yes
8910,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
8911,maybe improved later,,No,Yes
8912,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
8917,"\""\""\""\\ || This package contains several learning algorithms to be used in conjunction with || Pyconstruct domains. All the learners in Pyconstruct are agnostic to the type of || structured objects the data contains; thanks to the fact that the domain takes || care of both making inference and computing feature vectors. ||  || Learners in Pyconstruct follow the same interface as Scikit-learn estimators. || Each learner needs first to be instanciated; passing a domain as argument to the || constructor. For instance:: ||  ||     from pyconstruct import SSG; Domain ||  ||     ocr = Domain('ocr') ||     ssg = SSG(domain=ocr) ||  || The constructor usually accepts other hyper-parameters of the algorithm too. || After being instantiated; the learner needs to be trained with data that is || compatible with the domain passed to the learner instance. In this case; for || instance; we can make use of data provided by Pyconstruct:: ||  ||     from pyconstruct.datasets import load_ocr ||     data = load_ocr() ||  || Most of the learners in Pyconstruct are online learners; i.e. they can partially || fit a model a mini-batch of examples at the time. This provides high flexibility || to the way models can be trained; and is indeed useful given that training a || very big model on structured data may require a lot of time and computational || resources. As in Scikit-learn; online learners implement the `partial_fit` || method; which takes a mini-batch of examples and uses it to update the model. || Pyconstruct has a convenient utility to separate data into mini-batches; which || in turn can then be used to train the model:: ||  ||     from pyconstruct.utils import batches ||  ||     for X_b; Y_b in batches(ocr.data; ocr.target; size=50): ||         ssg.partial_fit(X_b; Y_b) ||  || This method of training is very flexible because it allows to; for instance; || validate the model while training:: ||  ||     from pyconstruct.metrics import hamming ||  ||     for X_b; Y_b in batches(ocr.data; ocr.target; size=50): ||  ||         # Validate ||         Y_pred = ssg.predict(X_b) ||         loss = hamming(Y_pred; Y_b; key='sequence').mean() ||         print('Training loss: {}'.format(loss)) ||  ||         # Update ||         ssg.partial_fit(X_b; Y_b) ||  || Here the `hamming` function takes a parameter `key='sequence'` because that is || the name of the attribute in the OCR data that need to be compared. ||  || As said; most learners in Pyconstruct are meant to be used in this way; so in || most cases they do not implement a `fit` method over the full dataset; instead || often `fit` is an alias for `partial_fit`. Check the documentation of each || learner for more details. DO NOT try to `fit` the full dataset; it would simply || perform a gradient step using the full dataset. || \""\""\""",,,Yes
8919,TODO: use `state_` here as well,,,Yes
8921,TODO: Fix documentation.,,Yes,Yes
8922,Convert DMRSs to SortDictDmrs with span_pred_key node if needed.,,,Yes
8926,!!! TODO: Optimize this,,,Yes
8928,!!! TODO: Optimize this,,,Yes
8932,TODO: Docstrings,,No,Yes
8933,TODO: Docstrings,,No,Yes
8934,TODO #DOCSTRING,,No,Yes
8936,TODO: This is very ugly and complicated and should probably be refactored,,Yes,Yes
8937,TODO: This is very ugly and complicated and should probably be refactored,,Yes,Yes
8939,``shared_y`` we will have to cast it to int. This little hack,,No,Yes
8943,TODO: Maype print some individuals here?,,,Yes
8944,TODO: Give some *meaningful* name here,,Yes,Yes
8945,TODO: Change the `root_dir_path` here,,,Yes
8946,TODO: Change the optimizee to the appropriate Optimizee class,,Yes,Yes
8947,TODO: Change the optimizer to the appropriate Optimizer class,,No,Yes
8948,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
8951,TODO: Change the optimizer to the appropriate Optimizer class,,,Yes
8952,TODO best individual should be tracked somehow?(not needed for recorder),,Yes,Yes
8953,TODO best individual should be tracked somehow?(not needed for recorder),,,Yes
8954,TODO: Change the optimizer to the appropriate Optimizer class,,,Yes
8956,TODO: Change the optimizer to the appropriate Optimizer class,,No,Yes
8957,decay parameter for each schedule. If needed can be different for each,,Yes,Yes
8959,"\""\""\"" || Multiplicative Monotonic Cooling || This schedule type multiplies the starting temperature by a factor that  || decreases over time (number k of the performed iteration steps). It requires a  || decay parameter (alpha) but not an ending temperature; as the prgression of the  || temperature is well definded by the decay parameter only. The Multiplicative  || Monotonic Cooling schedules are: Exponential multiplicative cooling;  || Logarithmical multiplicative cooling; Linear multiplicative cooling and  || Quadratic multiplicative cooling. || Source: Kirkpatrick; Gelatt and Vecchi (1983) ||  || - Exponential multiplicative cooling || Default cooling schedule for typical applications of simulated annealing. Each  || step; the temperature T_k is multiplied by the factor alpha (which has to be  || between 0 and 1) or in other words it is the starting temperature T_0  || multiplied by the factor alpha by the power of k: T_k = T_0 * alpha^k ||  || - Logarithmical multiplicative cooling || The factor by which the temperature decreases; is indirectly proportional to  || the log of k.  Therefore it slows down the cooling; the further progressed  || the schedule is. Alpha has to be largert than one.  || T_k = T_0 \/ ( 1 + alpha* log (1 + k) ) ||  || - Linear multiplicative cooling || Behaves similar to Logarithmical multiplicative cooling in that the decrease  || gets lower over time; but not as pronounced. The decrease is indirectly  || proportional to alpha times k and alpha has to be larger than zero: || T_k = T_0 \/ ( 1 + alpha*k) ||  || - Quadratic multiplicative cooling  || This schedule stays at high temperatures longer; than the other schedules and  || has a steeper cooling later in the process. Alpha has to be larger than zero. || T_k = T_0 \/ ( 1 + alpha*k^2) ||  || Additive Monotonic Cooling || The differences to Multiplicative Monotonic Cooling are; that the final  || temperature T_n and the number of iterations n are needed also. So this  || cannot be used as intended; if the stop criterion is something different;  || than a certain number of iteration steps. A decay parameter is not needed.  || Each temperature is computed; by adding a term to the final temperature. The  || Additive Monotonic Cooling schedules are: Linear additive cooling; Quadratic  || additive cooling; Exponential additive cooling and Trigonometric additive  || cooling. || Source. Additive monotonic cooling B. T. Luke (2005)  ||  || - Linear additive cooling  || This schedule adds a term to the final temperature; which decreases linearily  || with the progression of the schedule. || T_k = T_n + (T_0 -T_n)*((n-k)\/n) ||  || - Quadratic additive cooling  || This schedule adds a term to the final temperature; which decreases q || uadratically with the progression of the schedule. || T_k = T_n + (T_0 -T_n)*((n-k)\/n)^2 ||  || - Exponential additive || Uses a complicated formula; to come up with a schedule; that has a slow start;  || a steep decrease in temperature in the middle and a slow decrease at the end  || of the process. || T_k = T_n + (T_0 - T_n) * (1\/(1+exp( 2*ln(T_0 - T_n)\/n * (k- n\/2) ) ) ) ||  || - Trigonometric additive cooling || This schedule has a similar behavior as Exponential additive; but less pronounced.  || T_k = T_n + (T_0 - T_n)\/2 * (1+cos(k*pi\/n)) ||  || \""\""\""",,Yes,Yes
8960,Neither the name of the author nor the names of other contributors,,,Yes
8962,TODO Support multi-dimensional,,Yes,Yes
8963,-- Options for todo extension ----------------------------------------------,,,Yes
8965,"r\""\""\"" || Todo: ||     Write docs. || \""\""\""",,,Yes
8966,"r\""\""\"" || Todo: ||     Write docs. || \""\""\""",,Yes,Yes
8967,TODO Implement.,,Yes,Yes
8968,TODO Implement.,,Yes,Yes
8969,"r\""\""\""``hypothesis.simulation`` is a package consisting of the base simulator || architecture and utilities to perform efficient simulations. Every forward || model needs to be wrapped in a class which inherits from || ``hypothesis.simulation.Simulator``. || \""\""\""",,Yes,Yes
8970,Maybe you want to do something special here.,,,Yes
8972,second dimension indexes grid columns,,,Yes
8974,Clone to fix strange behaviour in Jupyter.,,No,Yes
8975,TODO Implement,,,Yes
8976,TODO vectorize,,,Yes
8980,Check if columns are present in data file,,Yes,Yes
8981,TODO: Add ability to run the experiment,,,Yes
8985,TODO: so; obviously; this needs to be changed,,,Yes
8986,"\""\""\"" || What does a criterion do? Well; it describes the performance || \""\""\""",,,Yes
8987,TODO: I think this should subclass the torch dataset??,,No,Yes
8989,"\""\""\"" || normally just use the pytorch ones... which are returned appropriately in factory. || you could store your options in a list somewhere just like the bootstrap package? ||  || perhaps call the directory custom_optimizers? || \""\""\""",,Yes,Yes
8990,"\""\""\"" || What does a criterion do? Well; it describes the performance || \""\""\""",,,Yes
8991,TODO: something to do with keeping track of the best checkpoint - create an object? forget the name of the design pattern; but there's a relevant one.,,Yes,Yes
8993,TODO: so; obviously; this needs to be changed,,,Yes
8996,TODO: I don't think this should actually be here,,,Yes
8999,TODO: come up with an alternate way to validate config,,,Yes
9000,TODO: deal with stopping rules,,,Yes
9002,TODO: change and check type here?,,No,Yes
9004,TODO: some optmizers have different behaviour; although this is unlikely to apply,,,Yes
9007,TODO: fix the fact that you copy pasted this,,,Yes
9008,TODO: deal with the fact that you copied this,,,Yes
9009,TODO: this should be a nn.sequential??,,No,Yes
9010,TODO: blarg,,,Yes
9011,TODO: define setters for everything and call those... although I really don't care about making things private?,,,Yes
9012,TODO: figure out if you really need this?,,,Yes
9015,TODO: do some sort of data validation here,,No,Yes
9018,TODO: want to call it activation but namespace; so what to do best?,,Yes,Yes
9022,TODO: deal with stopping rules,,Yes,Yes
9023,TODO: do you have to call any nn.module methods?? do you even actually want to subclass at this point if you have layers that subclass nn.module??,,,Yes
9027,TODO: check type?,,No,Yes
9028,TODO: figure out how this works in conjunction with optimizer,,,Yes
9034,TODO: do you really want this here....?,,No,Yes
9036,TODO: use setters to enforce types\/formats\/values!,,No,Yes
9037,TODO: I don't know why pycharm keeps rejecting this?,,No,Yes
9039,TODO: this won't work for all of them...,,,Yes
9040,TODO: use_gpu should probably go somewhere else in the future...,,No,Yes
9046,#TODO: figure out how this works in conjunction with optimizer,,,Yes
9048,#TODO: deal with the fact that you copied this,,Yes,Yes
9050,TODO: this won't work for all of them...,,Yes,Yes
9051,TODO: use_gpu should probably go somewhere else in the future...,,,Yes
9052,TODO: priya why isn't this being used??,,,Yes
9054,TODO: this is copy pasted,,,Yes
9057,TODO: need to convert to correct datatype,,No,Yes
9058,TODO: instance method?,,No,Yes
9059,TODO: include a list of csv files and then you can merge them based on a certain column.... certain criteria must be assumed in advance,,Yes,Yes
9061,TODO: check types; possibly wrong,,,Yes
9063,TODO: verify that labels has the same length as data,,,Yes
9064,TODO: this operates on categorical; as necessary. need to figure out where in the pipeline this happens...,,Yes,Yes
9065,TODO: this was taken from pytorch code.... but needs to be adapted to work with pytorch data,,Yes,Yes
9068,TODO: this is copy pasted - edit as appropriate,,Yes,Yes
9069,TODO: perform typechecking,,,Yes
9070,TODO: all methods need to be updated to work with new dataset,,Yes,Yes
9073,TODO: this is copy pasted - edit as appropriate,,,Yes
9074,TODO: perform typechecking,,,Yes
9075,TODO: Add ClassificationUnit?,,No,Yes
9081,TODO: variance thresholding,,No,Yes
9083,TODO: backport,,No,Yes
9084,TODO: implement variance thresholding,,No,Yes
9085,TODO: update to work with pytorch,,No,Yes
9086,TODO: switch this to joining multiple datasets??,,Yes,Yes
9087,TODO: check cause this may cause problems with vars originally containing underscores,,,Yes
9088,Find dummy columns and build pairs (category; category_value),,,Yes
9090,Select columns for each category,,Yes,Yes
9091,Find max value among columns,,Yes,Yes
9094,TODO: Why don't we also have instance norm here too? I think this is something we can bring up to the base class,,,Yes
9096,TODO: Modify to use val loader,,Yes,Yes
9098,TODO: Instead of self.cpu(); use is_cuda to know if you can use gpu,,,Yes
9099,TODO: Automatically calculate padding to be the same as input shape.,,Yes,Yes
9100,TODO: Should call this BaseUnit or call the others DenseLayer; etc.,,Yes,Yes
9102,TODO: all methods need to be updated to work with new dataset,,,Yes
9103,TODO: update to work with pytorch,,No,Yes
9106,TODO: Automatically calculate padding to be the same as input shape.,,,Yes
9107,TODO: Should call this BaseUnit or call the others DenseLayer; etc.,,Yes,Yes
9108,TODO: class # should correspond with self.num_class,,,Yes
9110,TODO: turn this into a percentage too? currently it's not,,Yes,Yes
9116,#TODO: figure out how this works in conjunction with optimizer,,Yes,Yes
9117,TODO: Instead of self.cpu(); use is_cuda to know if you can use gpu,,Yes,Yes
9118,TODO: reorganize these.,,No,Yes
9119,TODO: add more logging statements as appropriate,,,Yes
9120,TODO: probably bad to use this?,,No,Yes
9121,TODO: not great to use mutables as arguments.,,Yes,Yes
9122,TODO: reorganize these.,,,Yes
9123,TODO: add on additional if you want to be able to re-create a network?,,Yes,Yes
9125,TODO: where to do typechecking... just let everything fail?,,No,Yes
9127,TODO: Priya add data types,,No,Yes
9128,TODO: not great to use mutables as arguments.,,,Yes
9130,TODO: where to do typechecking... just let everything fail?,,No,Yes
9132,TODO: reorganize these.,,,Yes
9135,TODO: Priya I don't know what this is,,,Yes
9136,TODO: I hope that's ok,,No,Yes
9138,TODO: priya define.,,Yes,Yes
9143,TODO: Priya add data types,,No,Yes
9146,self._itr = 0 #TODO: ?,,,Yes
9148,TODO: https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/utils\/data\/dataset.html#Dataset,,No,Yes
9149,self._itr = 0 #TODO: ?,,Yes,Yes
9151,TODO: check what this does for the last split..,,No,Yes
9156,TODO: I don't think this is necessary,,,Yes
9158,TODO: is it dumb to have a constant name?,,Yes,Yes
9159,TODO: implement; add in classification and input layers??,,,Yes
9160,TODO: caitrin save the optimizers state dict? even though this is included with our instance?,,Yes,Yes
9161,TODO: implement; add in classification and input layers?,,Yes,Yes
9162,TODO: Modify for multi-input NNs,,,Yes
9164,TODO: Think about moving dimension to config file,,,Yes
9169,TODO: Revisit dim disorder and check isinstance for classes.,,No,Yes
9171,TODO: should rewrite the save_path structure,,No,Yes
9173,TODO: ignore for now,,,Yes
9175,TODO: should rewrite the save_path structure,,No,Yes
9177,TODO: why is this .cpu?,,,Yes
9180,TODO: should rewrite the save_path structure,,No,Yes
9183,TODO: Use tablemodules NEW: https:\/\/github.com\/torch\/nn\/blob\/master\/doc\/table.md,,,Yes
9185,TODO: should rewrite the save_path structure,,No,Yes
9190,TODO: why is this .cpu?,,No,Yes
9193,TODO: where to do typechecking... just let everything fail?,,,Yes
9194,TODO: why is this .cpu?,,,Yes
9195,TODO: should rewrite the save_path structure,,,Yes
9198,TODO: Use get_class,,,Yes
9203,TODO: convert to list,,,Yes
9205,TODO: Ensure to make this work without specifying the input size,,,Yes
9208,TODO: Remove temp,,,Yes
9210,TODO: Use logger to describe if the optimizer is changed.,,,Yes
9213,TODO: Remove temp,,No,Yes
9216,TODO: Should this be called self.network for continuity?,,,Yes
9217,TODO: change the bits of this you don't understand,,Yes,Yes
9219,TODO: why is this .cpu?,,,Yes
9221,TODO: See if using nn.ModuleDict is faster,,Yes,Yes
9223,TODO: Ensure to make this work without specifying the input size,,Yes,Yes
9224,TODO: See if using nn.ModuleDict is faster,,Yes,Yes
9225,TODO: Remove temp,,No,Yes
9227,TODO: convert to list,,,Yes
9232,TODO: Remove temp,,No,Yes
9234,TODO: Ensure to make this work without specifying the input size,,Yes,Yes
9235,TODO: Sort by number of dimensions and then by number of elements,,,Yes
9240,TODO:  rework on this elif to ensure to support Conv1D type tensor,,,Yes
9242,MOF (merge on columns),,No,Yes
9243,TODO: convert to list,,,Yes
9244,TODO: See if using nn.ModuleDict is faster,,,Yes
9245,TODO: Remove temp,,No,Yes
9246,TODO: should rewrite the save_path structure,,,Yes
9248,TODO: Fix Linear in_dim,,,Yes
9251,TODO: check what this does for the last split..,,No,Yes
9255,TODO: Fix Linear in_dim,,,Yes
9256,TODO: convert to list,,No,Yes
9259,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,No,Yes
9260,TODO: Remove temp,,No,Yes
9261,TODO: should rewrite the save_path structure,,,Yes
9263,TODO: check what this does for the last split..,,,Yes
9264,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,No,Yes
9266,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,,Yes
9267,TODO: not great to use mutables as arguments.,,Yes,Yes
9269,TODO: where to do typechecking... just let everything fail?,,No,Yes
9271,TODO: Use logger to describe if the optimizer is changed.,,No,Yes
9272,TODO: should rewrite the save_path structure,,,Yes
9273,TODO: ignore for now,,No,Yes
9275,TODO: Ensure to make this work without specifying the input size,,Yes,Yes
9279,TODO: See if using nn.ModuleDict is faster,,Yes,Yes
9280,TODO: Remove temp,,No,Yes
9283,TODO: Use tensor.expand_as?,,Yes,Yes
9284,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,No,Yes
9285,TODO: What if we get None? meaning; if there is no intersection,,,Yes
9286,TODO:  rework on this elif to ensure to support Conv1D type tensor,,No,Yes
9287,TODO: convert to list,,No,Yes
9292,TODO: See if using nn.ModuleDict is faster,,,Yes
9294,TODO: reorganize these.,,,Yes
9296,TODO: why is this .cpu?,,,Yes
9301,TODO: we could show something better here like calculate all the results so far,,Yes,Yes
9302,TODO: See if using nn.ModuleDict is faster,,Yes,Yes
9303,TODO: Remove temp,,,Yes
9304,TODO: reorganize these.,,No,Yes
9305,TODO: where to do typechecking... just let everything fail?,,,Yes
9306,TODO: why is this .cpu?,,,Yes
9308,TODO: why does use_unlabeled exist?,,Yes,Yes
9309,TODO: this doesn't seem correct,,,Yes
9312,TODO: would be better to make these namedtuples...,,Yes,Yes
9314,TODO: not great to use mutables as arguments.,,,Yes
9316,self._itr = 0 #TODO: ?,,Yes,Yes
9317,TODO: where to do typechecking... just let everything fail?,,No,Yes
9318,TODO: Should this be called self.network for continuity?,,No,Yes
9319,TODO: Modify to use val loader,,,Yes
9323,TODO: add in non_numeric,,No,Yes
9325,TODO: replace with Joseph's version,,,Yes
9328,TODO: why does use_unlabeled exist?,,,Yes
9329,TODO: this doesn't seem correct,,,Yes
9334,TODO: Modify to use val loader,,,Yes
9335,TODO: Modify for multi-input NNs,,No,Yes
9337,TODO: Remove temp,,,Yes
9338,TODO: Use torch.nn.ConstantPadding?,,No,Yes
9339,TODO: convert to list,,No,Yes
9340,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,No,Yes
9342,technically would re-write if they had 2 targets...,,Yes,Yes
9343,TODO: add more logging statements as appropriate,,Yes,Yes
9344,TODO: insert logging statements,,,Yes
9345,TODO: check cause this may cause problems with vars originally containing underscores,,,Yes
9348,TODO: turn this into a percentage too? currently it's not,,Yes,Yes
9351,TODO: not great to use mutables as arguments.,,,Yes
9352,TODO: reorganize these.,,,Yes
9353,self._itr = 0 #TODO: ?,,,Yes
9355,TODO: Revisit dim disorder and check isinstance for classes.,,No,Yes
9356,TODO: Modify for multi-input NNs,,No,Yes
9358,TODO: not great to use mutables as arguments.,,,Yes
9360,TODO: convert to list,,,Yes
9361,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,,Yes
9363,TODO: Use torch.nn.ConstantPadding?,,No,Yes
9364,TODO: Modify for multi-input NNs,,,Yes
9366,TODO: convert to list,,No,Yes
9367,TODO: convert to list,,No,Yes
9368,TODO: Instead of self.cpu(); use is_cuda to know if you can use gpu,,,Yes
9371,TODO: should we use .data? https:\/\/discuss.pytorch.org\/t\/cpu-detach-numpy-vs-data-cpu-numpy\/20036,,Yes,Yes
9373,TODO: Instead of self.cpu(); use is_cuda to know if you can use gpu,,Yes,Yes
9374,TODO: store in tensor for continuity?,,No,Yes
9375,TODO: should we use .data? https:\/\/discuss.pytorch.org\/t\/cpu-detach-numpy-vs-data-cpu-numpy\/20036,,Yes,Yes
9376,TODO: datetime categorical?,,No,Yes
9377,TODO: this is really slow make it faster,,,Yes
9379,TODO: DO we need to return a numpy object?,,Yes,Yes
9380,TODO: make label column the index??,,Yes,Yes
9382,TODO: implement,,Yes,Yes
9383,TODO: datetime categorical?,,No,Yes
9388,TODO: you made them backwards,,,Yes
9399,TODO: make label column the index??,,Yes,Yes
9400,TODO: rewrite to work with new stitch datasets function,,Yes,Yes
9403,TODO: re-write documentation,,Yes,Yes
9408,TODO: should we use .data? https:\/\/discuss.pytorch.org\/t\/cpu-detach-numpy-vs-data-cpu-numpy\/20036,,,Yes
9409,TODO: class # should correspond with self.num_class,,,Yes
9410,Assert_frame_equal checks order of columns; therefore; sort_index by columns when checking. If dataframes are,,Yes,Yes
9411,anyone got something better?,,Yes,Yes
9412,TODO: check index list doesn't fail if set twice...,,Yes,Yes
9414,TODO: store in tensor for continuity?,,,Yes
9416,TODO: why does use_unlabeled exist?,,Yes,Yes
9417,TODO: Use get_class,,No,Yes
9418,TODO: this doesn't seem correct,,Yes,Yes
9419,TODO: class # should correspond with self.num_class,,,Yes
9420,Assert_frame_equal checks order of columns; therefore; sort_index by columns when checking. If dataframes are,,,Yes
9422,TODO: use kwargs,,No,Yes
9423,future improvements could come from,,Yes,Yes
9425,TODO: Throws RuntimeError: sizes must be non-negative,,No,Yes
9426,Find dummy columns and build pairs (category; category_value),,Yes,Yes
9427,TODO: I think we need to re-create\/re-initalize the basenetwork when calling this function since,,No,Yes
9429,TODO: add more logging statements as appropriate,,Yes,Yes
9431,Select columns for each category,,Yes,Yes
9432,TODO: insert other logging statements,,Yes,Yes
9435,TODO: turn this into a percentage too? currently it's not,,,Yes
9438,TODO: Change to logger,,Yes,Yes
9439,TODO: check index list doesn't fail if set twice...,,Yes,Yes
9443,TODO: add more logging statements as appropriate,,Yes,Yes
9445,TODO: insert other logging statements,,,Yes
9447,TODO: check this doesn't operate in place... damn,,Yes,Yes
9448,TODO: turn this into a percentage too? currently it's not,,,Yes
9452,TODO failing here: RuntimeError: Jacobian mismatch for output 0 with respect to input 0;,,,Yes
9453,TODO failing here too assuming if Pool passes: RuntimeError: Jacobian mismatch for output 0 with respect to input 0;,,Yes,Yes
9455,TODO: make more elegant,,No,Yes
9457,TODO: what type are the raw predicted values that come out??,,No,Yes
9458,TODO: check that this won't mess with replicability,,Yes,Yes
9459,TODO: consider making class_converted default True,,Yes,Yes
9461,TODO: do we want to do anything with this name?,,Yes,Yes
9462,TODO: check index list doesn't fail if set twice...,,Yes,Yes
9463,TODO: update to use kwargs.,,No,Yes
9464,TODO: use kwargs,,No,Yes
9466,Find dummy columns and build pairs (category; category_value),,Yes,Yes
9467,Find max value among columns,,,Yes
9469,future improvements could come from,,Yes,Yes
9470,TODO: implement,,,Yes
9471,Drop rows where there are duplicates for the merged_on_columns.,,,Yes
9472,TODO: Use logger to describe if the optimizer is changed.,,No,Yes
9475,TODO: does this break windows?? no idea.,,,Yes
9476,TODO: use setters to enforce types\/formats\/values!,,No,Yes
9477,TODO: make this a base class?,,,Yes
9479,TODO: https:\/\/github.com\/pytorch\/pytorch\/issues\/9410,,No,Yes
9480,TODO: Think about moving dimension to config file,,Yes,Yes
9483,TODO: Will work on these classes below later during Vulcan2 deployment,,No,Yes
9484,TODO: consider making class_converted default True,,Yes,Yes
9486,TODO: store in tensor for continuity?,,No,Yes
9487,TODO: include support,,,Yes
9494,TODO: Use torch.nn.ConstantPadding?,,No,Yes
9496,"\""\""\""Specify dummy networks to test vulcan functionality.\""\""\""",,,Yes
9497,TODO: make more elegant,,No,Yes
9500,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
9501,TODO: maybe numpydoc?,,No,Yes
9502,TODO: check this,,,Yes
9506,TODO: could integrate map location in the future if needed,,Yes,Yes
9507,TODO: this may not work with current TabularDataset,,Yes,Yes
9510,TODO: this may not work with current TabularDataset,,Yes,Yes
9514,TODO: could integrate map location in the future if needed,,Yes,Yes
9516,recoding binary valued columns as ones and zeros,,Yes,Yes
9517,TODO: Evaluate these as static methods...,,,Yes
9518,TODO: Evaluate these as static methods...,,,Yes
9519,TODO: Evaluate these as static methods...,,Yes,Yes
9520,TODO: split function,,No,Yes
9521,TODO: use kwargs,,,Yes
9524,Copy non-dummy columns over.,,,Yes
9526,recoding binary valued columns as ones and zeros,,,Yes
9537,TODO: ensure dummy_na =False is what you want,,,Yes
9538,TODO: refactor,,No,Yes
9539,MOC (merge on columns),,No,Yes
9540,Drop rows where there are duplicates for the merged_on_columns.,,,Yes
9542,TODO: update this list to match your application: https:\/\/pypi.org\/pypi?%3Aaction=list_classifiers,,,Yes
9543,TODO: Add your library's requirements here,,,Yes
9545,TODO in the article it is 0.31 - why?,,,Yes
9546,TODO how import files from a package,,Yes,Yes
9550,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
9551,TODO: add the SVD method from section 6 step 1,,,Yes
9552,TODO: what is PairBais?,,No,Yes
9560,TODO not all full_specific_words are lower case - why? maybe just names?,,No,Yes
9562,TODO: refactor for speed and clarity,,No,Yes
9563,TODO: is it correct for inhertence of class method?,,No,Yes
9566,TODO: refactor - check before if one group is without words,,,Yes
9567,"\""\""\"" || Collection of common benchmark datasets from fairness research. ||  || Each dataset object contains a `pandas.DataFrame` as `df` attribute || that holds the actual data. || The dataset object will take care of loading; preprocessing || and validating the data. || The preprocessing is done by standard practices that are associated with || this data set: from its manual (e.g.; README) || or as other did in the literature. ||  || See :class:`ethically.dataset.Dataset` || for additional attribute and complete documentation. ||  || Currently these are the available datasets: ||     - ProPublica recidivism\/COMPAS dataset; ||       see: :class:`~ethically.dataset.COMPASDataset` ||  ||     - Adult dataset; see: :class:`~ethically.dataset.AdultDataset` ||  ||     - German credit dataset; see: :class:`~ethically.dataset.GermanDataset` ||  || Usage || ----- || .. code:: python ||  ||     >>> from ethically.dataset import COMPASDataset ||     >>> compas_ds = COMPASDataset() ||     >>> print(compas_ds) ||     <ProPublica Recidivism\/COMPAS Dataset. 6172 rows; 56 columns in ||     which {race; sex} are sensitive attributes> ||     >>> type(compas_ds.df) ||     <class 'pandas.core.frame.DataFrame'> ||     >>> compas_ds.df['race'].value_counts() ||     African-American    3175 ||     Caucasian           2103 ||     Hispanic             509 ||     Other                343 ||     Asian                 31 ||     Native American       11 ||     Name: race; dtype: int64 || \""\""\""",,Yes,Yes
9568,"\""\""\"" || Demographic Classification Fairness Criteria. ||  || The objectives of the demographic classification fairness criteria || is to measure unfairness towards sensitive attribute valuse. ||  ||  || One should keep in mind that the criteria are intended || to *measure unfairness; rather than to prove fairness*; as it stated in || the paper `Equality of opportunity in supervised learning <https:\/\/arxiv.org\/abs\/1610.02413>`_ || by Hardt et al. (2016): ||  ||     ... satisfying [the demographic criteria] should not be ||     considered a conclusive proof of fairness. ||     Similarly; violations of our condition are not meant ||     to be a proof of unfairness. ||     Rather we envision our framework as providing a reasonable way ||     of discovering and measuring potential concerns that require ||     further scrutiny. We believe that resolving fairness concerns is ||     ultimately impossible without substantial domain-specific ||     investigation. ||  ||  || The output of binary classifiers can come in two forms; either giving || a binary outcome prediction for input or producing || a real number score; which the common one is the probability || for the positive or negative label || (such as the method ``proba`` of an ``Estimator`` in ``sklearn``). || Therefore; the criteria come in two flavors; one for **binary** output; || and the second for **score** output. ||  || The fundamental concept for defining the fairness criteria || is `conditional independence <https:\/\/en.wikipedia.org\/wiki\/Conditional_independence>`_. || Using *Machine Learning and Fairness* book's notions: ||  || - ``A`` - Sensitive attribute || - ``Y`` - Binary ground truth (correct) target || - ``R`` - Estimated binary targets or score as returned by a classifier ||  || There are three demographic fairness criteria for classification: ||  || 1. Independence - R\u22A5A ||  || 2. Separation - R\u22A5A\u2223Y ||  || 3. Sufficiency - Y\u22A5A\u2223R ||  || \""\""\""",,,Yes
9569,hack to keep the same strutcure of code,,,Yes
9571,probably should be a better design,,,Yes
9573,TODO: add the SVD method from section 6 step 1,,Yes,Yes
9575,TODO: refactor for speed and clarity,,,Yes
9579,TODO: add the SVD method from section 6 step 1,,Yes,Yes
9580,TODO: maybe using cosine_similarities on all the vectors?,,No,Yes
9581,TODO: refactor for speed and clarity,,,Yes
9582,TODO: refactor,,No,Yes
9583,TODO: refactor,,No,Yes
9584,TODO: only check that there is no exception;,,,Yes
9585,should b change to a better test cas,,Yes,Yes
9586,"\""\""\"" || Collection of common benchmark datasets from fairness research. ||  || Each dataset object contains a :class:`pandas.DataFrame` as `df` attribute || that holds the actual data. || The dataset object will take care of loading; preprocessing || and validating the data. || The preprocessing is done by standard practices that are associated with || this data set: from its manual (e.g.; README) || or as other did in the literature. ||  || See :class:`responsibly.dataset.Dataset` || for additional attribute and complete documentation. ||  || Currently these are the available datasets: ||  ||     - ProPublica recidivism\/COMPAS dataset; ||       see: :class:`~responsibly.dataset.COMPASDataset` ||  ||     - Adult dataset; ||       see: :class:`~responsibly.dataset.AdultDataset` ||  ||     - German credit dataset; ||       see: :class:`~responsibly.dataset.GermanDataset` ||  ||     - FICO credit score dataset; ||       see :func:`~responsibly.dataset.build_FICO_dataset` ||  || Usage || ----- || .. code:: python ||  ||     >>> from responsibly.dataset import COMPASDataset ||     >>> compas_ds = COMPASDataset() ||     >>> print(compas_ds) ||     <ProPublica Recidivism\/COMPAS Dataset. 6172 rows; 56 columns in ||     which {race; sex} are sensitive attributes> ||     >>> type(compas_ds.df) ||     <class 'pandas.core.frame.DataFrame'> ||     >>> compas_ds.df['race'].value_counts() ||     African-American    3175 ||     Caucasian           2103 ||     Hispanic             509 ||     Other                343 ||     Asian                 31 ||     Native American       11 ||     Name: race; dtype: int64 || \""\""\""",,Yes,Yes
9588,"\""\""\"" || Collection of common benchmark datasets from fairness research. ||  || Each dataset object contains a :class:`pandas.DataFrame` as `df` attribute || that holds the actual data. || The dataset object will take care of loading; preprocessing || and validating the data. || The preprocessing is done by standard practices that are associated with || this data set: from its manual (e.g.; README) || or as other did in the literature. ||  || See :class:`ethically.dataset.Dataset` || for additional attribute and complete documentation. ||  || Currently these are the available datasets: ||  ||     - ProPublica recidivism\/COMPAS dataset; ||       see: :class:`~ethically.dataset.COMPASDataset` ||  ||     - Adult dataset; ||       see: :class:`~ethically.dataset.AdultDataset` ||  ||     - German credit dataset; ||       see: :class:`~ethically.dataset.GermanDataset` ||  ||     - FICO credit score dataset; ||       see :func:`~ethically.dataset.build_FICO_dataset` ||  || Usage || ----- || .. code:: python ||  ||     >>> from ethically.dataset import COMPASDataset ||     >>> compas_ds = COMPASDataset() ||     >>> print(compas_ds) ||     <ProPublica Recidivism\/COMPAS Dataset. 6172 rows; 56 columns in ||     which {race; sex} are sensitive attributes> ||     >>> type(compas_ds.df) ||     <class 'pandas.core.frame.DataFrame'> ||     >>> compas_ds.df['race'].value_counts() ||     African-American    3175 ||     Caucasian           2103 ||     Hispanic             509 ||     Other                343 ||     Asian                 31 ||     Native American       11 ||     Name: race; dtype: int64 || \""\""\""",,,Yes
9591,TODO: refactor!,,Yes,Yes
9592,TODO: only check that there is no exception;,,Yes,Yes
9595,TODO: Remove me in the future future,,,Yes
9596,Travis Hack (becaouse of botocore),,No,Yes
9597,TODO: Remove me in the future future,,Yes,Yes
9601,it is even step so maybe converged but it depends on example unable to test,,Yes,Yes
9602,TODO: description,,No,Yes
9603,TODO: set false when end of development,,,Yes
9606,data with two columns,,Yes,Yes
9609,TODO: set false when end of development,,,Yes
9610,hack to destroy the legend for coloraxis,,,Yes
9611,TODO: modify for more thetas,,,Yes
9612,check if really minimal; function is monotonic so everywhere around,,,Yes
9613,hack to destroy the legend for coloraxis,,,Yes
9614,TODO: modify for more thetas,,,Yes
9616,check if really minimal; function is monotonic so everywhere around,,Yes,Yes
9618,todo: remove if\/when domain[idx] is fixed,,Yes,Yes
9621,TODO: Fix fallback for lenient parsing,,,Yes
9622,TODO: Fix fallback for lenient parsing,,Yes,Yes
9623,TODO: Error checking,,No,Yes
9627,conversion needed to use np.inf after,,No,Yes
9628,This is ugly; but,,Yes,Yes
9631,efficient than parsing the lines manually,,Yes,Yes
9633,This currently uses a very crisp boolean mask; looks better when edges are,,Yes,Yes
9634,grow GPU memory as needed,,,Yes
9637,FIXME Inspect messes with garbage collection,,No,Yes
9638,The code looks cleaner; but might cause problems when you want to refactor,,Yes,Yes
9639,The code looks cleaner; but might cause problems when you want to refactor,,Yes,Yes
9640,TODO: Need to handle Queue's and mean scalars of histograms,,Yes,Yes
9641,The code looks cleaner; but might cause problems when you want to refactor,,,Yes
9643,TODO: use log(),,No,Yes
9644,TODO: Will have to fix this when there are other statuses than 'done',,Yes,Yes
9646,!!! TODO skrifa yfir smi\u00F0inn fyrir TOK \u00FAr tokenizer.py \u00ED Tokenizer-pakka,,Yes,Yes
9647,Best candidate is very unlikely: return the original word,,,Yes
9648,!!! TODO skrifa yfir smi\u00F0inn fyrir TOK \u00FAr tokenizer.py \u00ED Tokenizer-pakka,,,Yes
9651,!!! TODO: There should also be a mechanism for,,,Yes
9653,S003: Erroneously formed word forms picked up by ErrorForms. Should be corrected. TODO split up by nature.,,,Yes
9656,!!! TODO: Consider whether to overwrite previous error;,,Yes,Yes
9658,!!! TODO: case (for instance; '\u00E1' as a nominative of '\u00E6r').,,Yes,Yes
9659,!!! TODO: We are not handling those here.,,No,Yes
9660,!!! TODO: This could be made more efficient if all,,No,Yes
9661,!!! TODO: taboo word forms could be generated ahead of time,,,Yes
9662,!!! TODO: and checked via a set lookup,,,Yes
9665,Fix single-word errors,,,Yes
9666,!!! TODO: We temporarily allow U001 as an error code for,,,Yes
9667,Fix compound words,,,Yes
9669,P_xxx: Phrase error codes,,,Yes
9670,!!! TODO: depending on which rule we're talking about,,,Yes
9671,!!! TODO: This could be made more efficient if all,,,Yes
9672,!!! TODO: taboo word forms could be generated ahead of time,,,Yes
9673,!!! TODO: and checked via a set lookup,,Yes,Yes
9676,!!! TODO: here; i.e. one with full or partial backoff to,,Yes,Yes
9678,!!! TODO: here; such as Kneser-Ney or Katz,,,Yes
9679,!!! TODO: Optimize the following,,Yes,Yes
9680,!!! TODO: here; i.e. one with full or partial backoff to,,,Yes
9681,!!! TODO: bigram and unigram frequencies,,Yes,Yes
9682,"assert \""kynfer\u00F0isofbeldinu\"" in s  # !!! TODO: This becomes 'kynfer\u00F0iofbeldinu'",,,Yes
9683,"assert \""\u00F6rf\u00E1\"" in s  # !!! TODO: This becomes '\u00F6rva'",,Yes,Yes
9685,!!! TODO: particular stem in B\u00CDN - this is presently not possible,,Yes,Yes
9686,"assert g[4].error_code == \""W001\""    # TODO \u00FAtf\u00E6ra",,Yes,Yes
9688,TODO \u00FEetta \u00E1 l\u00EDklega frekar heima \u00ED checker.py; ath. hvort \u00FEetta er b\u00E6\u00F0i s\u00E9rnafn og samnafn og \u00FEannig.,,,Yes
9691,TODO villan kemur \u00ED fyrsta or\u00F0i\u00F0 \u00ED fasta frasanum en \u00E6tti a\u00F0 f\u00E1 \u00E1 villuor\u00F0i\u00F0 sj\u00E1lft.,,No,Yes
9693,"assert \""lei\u00F0inlegt\"" in s   # TODO er \u00FEetta ekki \u00ED \u00FEekktu villunum sem \u00E1 eftir a\u00F0 koma inn?",,,Yes
9695,"assert \""t\u00EDmanlega\"" in s     # TODO sama",,,Yes
9696,assert g[3].error_code == S003  # TODO eftir; g\u00E6ti veri\u00F0 S005,,Yes,Yes
9697,assert g[5].error_code == S003  # TODO eftir; g\u00E6ti veri\u00F0 S005,,,Yes
9698,assert g[8].error_code == S003  # TODO eftir; g\u00E6ti veri\u00F0 S005,,,Yes
9699,TODO vil f\u00E1 A001,,Yes,Yes
9700,"assert \""\u00FE. \u00E1 m.\"" in s  # TODO ekki gert r\u00E9tt eins og er; \u00FEarf a\u00F0 b\u00E6ta vi\u00F0 \u00FEekktar villur. Get b\u00FAi\u00F0 til s\u00E9rfall \u00ED errtokenizer.py; veri\u00F0 me\u00F0 l\u00EDti\u00F0 safn \u00ED ReynirCorrect.conf.",,Yes,Yes
9701,"assert \""a.m.k.\"" in s    # TODO b\u00FDr \u00FEetta til og S001; en setur aukapunkt og b\u00FDr til n\u00FDja setningu eftir \u00FEetta!",,Yes,Yes
9703,"assert g[7].error_code == \""A001\""      # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9705,"assert \""o.fl.\"" in s       # TODO b\u00FDr \u00FEetta til en setur aukapunkt aftan vi\u00F0!",,,Yes
9706,"assert \""ar\u00EDi\"" in s        # TODO virkar ekki",,,Yes
9707,"assert \""Sj\u00E1lfst\u00E6\u00F0isma\u00F0ur\"" in s    # TODO lei\u00F0r\u00E9ttist ekki",,Yes,Yes
9708,"assert \""Sj\u00EDti\"" in s       # TODO lei\u00F0r\u00E9ttist \u00ED sj\u00EDta. \u00DEarf a\u00F0 l\u00E1ta einr\u00E6\u00F0anlegar villur gera \u00FEetta og svo ekkert stoppa \u00FEa\u00F0",,,Yes
9710,"assert g[12].error_code == \""Z002\""   # M\u00FAsl\u00EDmi; TODO lei\u00F0r\u00E9ttist ekki",,Yes,Yes
9712,"assert g[1].error_code == \""B001\""    # tr\u00E9\u00F0; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9713,"assert g[4].error_code == \""B001\""    # rekstrar; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9716,"assert g[2].error_code == \""B001\""    # fyndist; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9717,"assert g[3].error_code == \""B001\""    # v\u00ED\u00F0fe\u00F0mt; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9718,"assert g[5].error_code == \""B001\""    # \u00E1rvekni; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9719,"assert \""k\u00FDrin\"" in s        # TODO eftir a\u00F0 setja inn",,,Yes
9720,"assert \""eldingarinnar\"" in s    # TODO eftir a\u00F0 setja inn",,Yes,Yes
9721,"assert g[2].error_code == \""B001\""    # k\u00FDrin; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9724,"assert g[4].error_code == \""B001\""    # \u00E1ratugarins; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9727,"assert g[5].error_code == \""B001\""    # fj\u00F3rum; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9728,"assert g[2].error_code == \""B001\""    # \u00F3lst; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9729,"assert g[8].error_code == \""B001\""    # f\u00F6\u00F0ur; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9731,"assert \""Fri\u00F0s\u00E6lli\"" in s        # TODO eftir a\u00F0 setja inn",,Yes,Yes
9732,"assert \""k\u00EDl\u00F3metra\"" in s    # TODO eftir a\u00F0 setja inn",,Yes,Yes
9733,"assert g[1].error_code == \""B001\""      # fri\u00F0s\u00E6lli; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9734,"assert g[6].error_code == \""B001\""      # hundru\u00F0; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9736,"assert g[11].error_code == \""B001\""     # k\u00EDl\u00F3metra; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9737,"assert g[13].error_code == \""B001\""     # f\u00E9nu; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9738,"assert g[15].error_code == \""B001\""     # \u00E1standsins; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9739,"assert g[5].error_code == \""B001\""        # Selfoss; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9740,"assert g[6].error_code == \""B001\""        # tuttugasta; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9742,"assert \""\u00F3tal margra\"" in s      # TODO eftir a\u00F0 h\u00F6ndla",,Yes,Yes
9743,"assert \""feykna skemmtilegir\"" in s    # TODO eftir a\u00F0 h\u00F6ndla",,,Yes
9745,"assert g[2].error_code == \""M004\""    # \u00F3tal margra; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9746,"assert g[3].error_code == \""M004\""    # fj\u00F6lnota hesta; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9747,"assert g[5].error_code == \""M001\""    # feiknaskemmtilegir; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9748,"assert \""Loftlagsm\u00E1l\"" in s  # TODO eftir a\u00F0 h\u00F6ndla",,,Yes
9750,"assert g[3].error_code == \""M004\""  # alhli\u00F0a vandam\u00E1l; TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9754,"assert \""arfberunum\"" in s          # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9758,"assert \""Vefurinn b\u00ED\u00F0ur\"" not in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,No,Yes
9759,"assert \""fr\u00E9ttir mi\u00F0lanna\"" in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9762,"assert g[7].error_code == \""S005\""  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9763,"assert \""hv\u00EDsl\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9765,"assert g[4].error_code == \""S005\""  # TODO eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,Yes,Yes
9766,"assert \""Kyrtillinn\"" in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9767,"assert \""Kirtillinn\"" not in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9769,"assert \""l\u00FDkur\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9772,"assert \""kvatt\"" not in s   # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9774,"assert \""r\u00FDmum\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9775,"assert \""leyfa\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9776,"assert \""kvelja\"" in s   # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9777,"assert \""setji\u00F0 \"" in s      # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9778,"assert \""setji\u00F0 \u00FEi\u00F0\"" in s   # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9779,"assert g[6].error_code == \""Q001\""   # TODO eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,Yes,Yes
9780,"assert \""n\u00E1i\u00F0 \u00FEi\u00F0\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra; spelling.py vir\u00F0ist taka \u00E1 \u00FEessu",,Yes,Yes
9781,"assert \""n\u00E1i\u00F0i\"" not in s     # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9782,"assert g[7].error_code == \""Q001\""    # TODO eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,,Yes
9783,"assert g[3].error_code == \""T001\""    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9784,"assert g[6].error_code == \""T001\""    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9787,"assert \""ti la\u00F0\"" not in s  # TODO eftir a\u00F0 b\u00E6ta vi\u00F0",,Yes,Yes
9788,"assert g[1].error_code == \""S001\""   # TODO virkar ekki",,,Yes
9789,"assert \""r\u00EDkisstj\u00F3rn\"" in s     # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9791,"assert g[7].error_code == \""S001\""      # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9792,TODO \u00FEarf l\u00EDklega a\u00F0 breyta til. Eftir a\u00F0 \u00FAtf\u00E6ra?,,,Yes
9793,"check_sentence(s; [3; 5; \""P_NT_X\""])        # TODO F\u00E6 ekki \u00FE\u00E1ttun \u00E1 setninguna",,Yes,Yes
9794,TODO taka \u00FAt \u00FEegar b\u00FAin a\u00F0 afl\u00FAsa pr\u00F3fanirnar,,No,Yes
9797,TODO  FsMeFallstj\u00F3rn greinir villu; en n\u00E6r ekki yfir Eflingu; eitthva\u00F0 skr\u00FDti\u00F0 \u00E1 fer\u00F0inni! Vil f\u00E1 reglu sem heitir FallInnanNafnli\u00F0ar og \u00E1 a\u00F0 n\u00E1 yfir 5; 8.,,Yes,Yes
9799,"check_sentence(s; [(2; 2; \""P_NT_Einhver\"")])     # TODO villan greinist sem S001; viljum vi\u00F0 h\u00F6ndla \u00FEetta sem beygingarsamr\u00E6misvillu frekar? \u00DEetta er \u00F3samhengish\u00E1\u00F0.",,Yes,Yes
9803,TODO villan greinist en \u00E6tti a\u00F0 vera sta\u00F0sett \u00E1 s\u00F6gninni svo h\u00E6gt s\u00E9 a\u00F0 lei\u00F0r\u00E9tta hana. Sko\u00F0a hvernig\/hvort villan er lei\u00F0r\u00E9tt.,,Yes,Yes
9805,TODO virkar; en athuga lengdina; og hvernig \u00FEetta er lei\u00F0r\u00E9tt \u00ED vi\u00F0m\u00F3ti. Er s\u00F6gninni l\u00EDka breytt?,,,Yes
9806,"check_sentence(s; [(2; 2; \""P_WRONG_PARTICLE_uppi\"")])    # TODO greinist ekki; \u00FEetta \u00E1 algerlega eftir a\u00F0 \u00FAtf\u00E6ra betur \u00FEegar \u00FEetta er komi\u00F0 inn \u00ED Verbs.conf. \u00DEetta er l\u00EDklega ekki r\u00E9ttur villuk\u00F3\u00F0i.",,,Yes
9808,"check_sentence(s; [(3; 4; \""P_WRONG_PP_af\"")])      # TODO villan greinist ekki. Komi\u00F0 \u00ED Verbs.conf? L\u00EDklega ekki r\u00E9ttur villuk\u00F3\u00F0i.",,Yes,Yes
9810,"check_sentence(s; [(2; 4; \""P_WRONG_PP_\u00ED_skyn\"")])      # TODO villan greinist ekki. Komi\u00F0 \u00ED Verbs.conf? L\u00EDklega ekki r\u00E9ttur villuk\u00F3\u00F0i.",,Yes,Yes
9812,TODO \u00FEetta virkar; en sko\u00F0a lengdina.,,Yes,Yes
9815,"check_sentence(s; [(3; 4; \""P_A\u00F0\"")])        # TODO villan greinist ekki; eftir a\u00F0 \u00FAtf\u00E6ra. \u00C6tti a\u00F0 vera \u00ED Verbs.conf",,Yes,Yes
9818,"check_sentence(s; [(1; 3; \""P_Nafnor\u00F0ast\u00EDll\"")])        # TODO greinist ekki; eftir a\u00F0 \u00FAtf\u00E6ra -- \u00FEetta g\u00E6ti virka\u00F0 vel \u00ED Verbs.conf!",,,Yes
9819,"check_sentence(s; [(0; 33; \""E004\"")])      # TODO \u00FEetta vir\u00F0ist ekki virka; strandar \u00E1 \u00FEv\u00ED a\u00F0 setningin greinist ekki!",,,Yes
9820,"check_sentence(s; [(0; 0; \""P_SUBJ_CASE_nf_\u00FEf\"")])            # TODO setningin f\u00E6r ekki \u00FE\u00E1ttun. \u00DEetta er inni \u00ED Verbs.conf; af hverju er \u00FEetta ekki h\u00F6ndla\u00F0?",,,Yes
9822,"assert g[1].error_code == \""S001\""   # TODO virkar ekki; endar sem S004",,,Yes
9823,"assert \""r\u00EDkisstj\u00F3rn\"" in s     # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9824,"assert \""r\u00EDkistj\u00F3rn\"" in s      # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9825,"assert \""sat Gunna og\"" in s              # TODO Virkar ekki eins og er \u00FAt af h\u00E1staf \u00ED unique_errors",,Yes,Yes
9826,"assert \""sat Gunan og\"" not in s          # TODO Virkar ekki eins og er \u00FAt af h\u00E1staf \u00ED unique_errors",,Yes,Yes
9827,TODO \u00DEetta virkar \u00ED vi\u00F0m\u00F3ti en allt \u00ED einu ekki h\u00E9r.,,,Yes
9828,"assert g[3].error_code == \""S001\""  # TODO virkar ekki \u00FAt af h\u00E1staf \u00ED unique_errors; setja inn \u00FEegar \u00FEa\u00F0 er laga\u00F0",,,Yes
9831,TODO getur lei\u00F0r\u00E9tt g\u00E6rk\u00F6ld\u2192g\u00E6rkv\u00F6ld; en g\u00E6rkv\u00F6ldi vir\u00F0ist ekki vera \u00ED safninu.,,,Yes
9832,"assert g[2].error_code == \""S002\""  # TODO endar sem S004; \""Checking rare word 'fyldist'\""",,,Yes
9833,"assert g[4].error_code == \""S002\""  # TODO endar sem S004",,Yes,Yes
9834,"assert g[6].error_code == \""S002\""  # TODO endar sem S004",,,Yes
9837,"assert \""reglulega \u00ED\"" in s     # TODO lei\u00F0r\u00E9ttist ekki; kemur me\u00F0 upp\u00E1stungu",,Yes,Yes
9838,"assert \""\u00ED l\u00EDkamsr\u00E6kt\"" in s    # TODO lei\u00F0r\u00E9ttist ekki; of fl\u00F3kin villa.",,,Yes
9839,"assert g[5].error_code == \""S002\""      # TODO endar sem S004",,,Yes
9841,"assert g[9].error_code == \""S002\""      # TODO endar sem S004",,Yes,Yes
9842,"assert g[10].error_code == \""S002\""     # TODO endar sem S003! Endar sem bara upp\u00E1stunga",,Yes,Yes
9843,"assert \""hv\u00EDsl\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9845,"assert g[4].error_code == \""S006\""  # TODO eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,Yes,Yes
9846,"assert \""Kyrtillinn\"" in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9847,"assert \""Kirtillinn\"" not in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9849,"assert \""l\u00FDkur\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9851,"assert \""hvatt\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9853,"assert \""hvika\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9854,"assert \""r\u00FDmum\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,,Yes
9855,"assert \""leyfa\"" in s    # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9856,"assert \""kvelja\"" in s   # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9857,"assert \""fj\u00F6gurleyti\u00F0\"" in s    # TODO sama",,,Yes
9858,assert g[8].error_code == S007  # TODO greinist ekki; eftir a\u00F0 setja inn,,Yes,Yes
9859,"assert \""annarra\"" in s          # TODO lei\u00F0r\u00E9ttist ekki; er \u00ED ErrorForms en er samhengish\u00E1\u00F0 villa",,Yes,Yes
9860,"assert \""einskis\"" in s         # TODO lei\u00F0r\u00E9ttist ekki.",,Yes,Yes
9861,for ix; t in enumerate(g):                 # TODO virkar ekki; eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0ann og skipta villunum upp eftir e\u00F0li,,Yes,Yes
9866,"assert g[3].error_code == \""S004\""  # TODO virkar ekki; f\u00E6 W001 vir\u00F0ist vera.",,,Yes
9870,"assert g[3].error_code == \""S004\""  # TODO Vir\u00F0ist ekki virka!",,,Yes
9871,"assert g[4].error_code == \""S004\""  # TODO Vir\u00F0ist ekki virka! Finn S001",,Yes,Yes
9872,"assert g[6].error_code == \""S004\""  # TODO Vir\u00F0ist ekki virka! Finn S001",,Yes,Yes
9873,"assert \""ar\u00EDi\"" in s        # TODO lei\u00F0r\u00E9ttist ekki \u00FEv\u00ED a\u00F0 Ar\u00EDi var til sta\u00F0ar. B\u00FAin a\u00F0 laga \u00ED BinErrata.conf; svo ver\u00F0ur ekki vandam\u00E1l \u00FEegar n\u00E6sta \u00FAtg\u00E1fa ord.compressed kemur.",,Yes,Yes
9874,"assert g[2].error_code == \""Z001\""  # ar\u00EDi; TODO lei\u00F0r\u00E9ttist ekki eins og er; gerist me\u00F0 n\u00FDrri \u00FAtg\u00E1fu ord.compressed.",,Yes,Yes
9876,"assert g[6].error_code == \""M001\""    # TODO f\u00E6 C002",,Yes,Yes
9878,"assert \""h\u00E1lfber\"" in s             # TODO virkar ekki",,,Yes
9880,"assert g[10].error_code == \""M002\"" # TODO eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,,Yes
9882,"assert \""afar kosti\"" in s          # TODO virkar ekki",,,Yes
9883,"assert \""forvinnunni\"" in s         # TODO virkar ekki",,,Yes
9884,"assert \""for vinnunni\"" not in s    # TODO virkar ekki",,Yes,Yes
9886,"assert g[6].error_code == \""M002\""  # TODO Eftir a\u00F0 \u00FAtf\u00E6ra",,Yes,Yes
9887,"assert \""barnd\u00F3m\"" in s                 # TODO Eftir a\u00F0 \u00FAtf\u00E6ra",,No,Yes
9889,"assert g[4].error_code == \""M003\""      # TODO Eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,Yes,Yes
9890,"assert g[16].error_code == \""M003\""     # TODO Eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,Yes,Yes
9891,"assert g[1].error_code == \""M004\""      # TODO Eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a; f\u00E6 C002",,,Yes
9892,"assert g[4].error_code == \""M004\""      # TODO Eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a; f\u00E6 C002",,,Yes
9894,"assert g[1].error_code == \""T001\""    # TODO Eftir a\u00F0 \u00FAtf\u00E6ra. Tab\u00FAor\u00F0 \u00E6tti a\u00F0 merkja sem sl\u00EDk.",,Yes,Yes
9895,"assert g[4].error_code == \""M004\""    # TODO Eftir a\u00F0 \u00FAtf\u00E6ra; f\u00E6 U001. En beygingarvillur?",,Yes,Yes
9897,"assert \""afar lei\u00F0inlegir\"" in s    # TODO virkar ekki",,Yes,Yes
9901,"assert \""ofur svalur\"" in s       # TODO Reglurnar segja til um a\u00F0 \u00FEetta s\u00E9 r\u00E9ttara en \u00E9g er bara ekki samm\u00E1la!",,,Yes
9902,"assert g[8].error_code == \""M005\""  # TODO Eftir a\u00F0 \u00FAtf\u00E6ra villuk\u00F3\u00F0a",,,Yes
9905,TODO breyta pr\u00F3funinni svo falli a\u00F0 mynsturgreininum.,,,Yes
9907,"assert \""Vefurinn b\u00ED\u00F0ur\"" not in s  # TODO eftir a\u00F0 \u00FAtf\u00E6ra",,No,Yes
9908,"assert g[2].error_code == \""V001\""  # TODO eftir a\u00F0 \u00E1kve\u00F0a villuk\u00F3\u00F0a",,Yes,Yes
9909,TODO Verbs.conf \u00E6tti a\u00F0 dekka \u00FEetta -- \u00FAtf\u00E6ra goggunarr\u00F6\u00F0?,,,Yes
9910,TODO greinist; en sko\u00F0a lengdina.,,Yes,Yes
9911,TODO pr\u00F3fa h\u00E9r.,,Yes,Yes
9912,Should be corrected. !!! TODO split up by nature.,,,Yes
9914,Fix the capitalization,,No,Yes
9915,!!! TODO: Probably missing yield token; token = get() here,,No,Yes
9916,TODO isn't this if-clause unnecessary?,,Yes,Yes
9918,"assert \""eyrnal\u00E6kninum\"" in s       # TODO \u00C6tti a\u00F0 virka \u00FEegar geri n\u00FD or\u00F0anet",,,Yes
9919,"assert g[5].error_code == \""C004\""  # TODO virkar ekki",,Yes,Yes
9920,"assert \""\u00D6ldungadeildar\u00FEingma\u00F0urinn\"" in s      # TODO \u00C6tti a\u00F0 virka \u00FEegar n\u00FD or\u00F0anet",,,Yes
9921,"assert \""d\u00EDsilb\u00EDl\"" in s                        # TODO \u00C6tti a\u00F0 virka \u00FEegar n\u00FD or\u00F0anet",,No,Yes
9922,"assert \""\u00F3tal margir\"" in s         # TODO virkar ekki \u00FEv\u00ED \""\u00F3talmargur\"" er \u00ED B\u00CDN!",,Yes,Yes
9923,"assert \""\u00F3talmargir\"" not in s      # TODO \u00C6tla a\u00F0 merkja sl\u00EDkar f\u00E6rslur sem villur \u00ED CID\/CD_error_forms",,Yes,Yes
9925,TODO Eftir a\u00F0 \u00FAtf\u00E6ra; f\u00E6 C002,,Yes,Yes
9926,"assert g[8].error_code == \""C002\""  # TODO Virkar ekki",,Yes,Yes
9927,"assert g[6].error_code == \""C002\""  # TODO",,Yes,Yes
9929,"assert g[6].error_code == \""C002\""  # TODO \u00C6tti a\u00F0 virka...",,,Yes
9930,"assert \""vel s\u00E6tur\"" in s           # TODO virkar ekki",,,Yes
9931,"assert \""vels\u00E6tur\"" not in s            # TODO virkar ekki",,Yes,Yes
9932,TODO STILLING - h\u00E9r er bara upp\u00E1stunga; skiptir ekki m\u00E1li fyrir \u00F3sh. m\u00E1lr\u00FDni,,,Yes
9935,TODO STILLING - setja svo if-lykkju h\u00E9r til a\u00F0 lei\u00F0r\u00E9tta bara \u00F3sh. ef \u00FEa\u00F0 er vali\u00F0.,,,Yes
9936,TODO STILLING - ath. \u00FE\u00F3 a\u00F0 e-\u00F0 af or\u00F0hlutunum \u00ED Morphemes.BOUND_DICT geta ekki sta\u00F0i\u00F0 sj\u00E1lfst\u00E6\u00F0,,No,Yes
9937,TODO STILLING - \u00FE\u00E1 \u00FEarf a\u00F0 merkja \u00FE\u00E1 or\u00F0hluta sem villu ef \u00F3sh. lei\u00F0r\u00E9tting er valin.,,Yes,Yes
9938,TODO STILLING - H\u00E9r er bara upp\u00E1stunga; skiptir ekki m\u00E1li f. \u00F3sh. m\u00E1lr\u00FDni,,Yes,Yes
9939,TODO STILLING - h\u00E9r er bara upp\u00E1stunga.,,,Yes
9941,"TODO STILLING - viljum ekki endilega lei\u00F0r\u00E9tta \""byggingaregla\""; \u00FE\u00F3 a\u00F0 venjan leyfi hitt frekar.",,,Yes
9943,TODO STILLING - ALWAYS_WRONG_FORMERS og MOSTLY_WRONG_FORMERS e\u00F0a eitthva\u00F0 \u00FEannig?,,No,Yes
9944,TODO STILLING - fyrra alltaf lei\u00F0r\u00E9tt; en seinna bara \u00E1bending?,,Yes,Yes
9945,TODO B\u00E6ta inn lei\u00F0r\u00E9ttingu \u00FAt fr\u00E1 seinni or\u00F0hlutum?,,,Yes
9946,TODO STILLING - \u00FEetta er \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting!,,Yes,Yes
9948,TODO STILLING - og l\u00EDka \u00FEv\u00ED sko\u00F0um l\u00EDka sjaldg\u00E6f or\u00F0.,,Yes,Yes
9949,TODO STILLING - er samt versti hlutur \u00ED heimi a\u00F0 hafa \u00F3\u00FEekktu leitina hluta af \u00F3sh. m\u00E1lr\u00FDninni?,,,Yes
9950,TODO STILLING - \u00FEetta er bara upp\u00E1stunga,,Yes,Yes
9951,TODO STILLING - h\u00E9r er blanda. Or\u00F0 sem eiga alltaf a\u00F0 vera h\u00E1stafa en birtast l\u00E1gstafa eru \u00F3sh.;,,Yes,Yes
9952,TODO STILLING - or\u00F0 sem eiga alltaf a\u00F0 vera l\u00E1gstafa nema \u00ED byrjun setningar eru sh. lei\u00F0r\u00E9tting.,,Yes,Yes
9955,TODO STILLING - h\u00E9r er bara samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting,,Yes,Yes
9956,TODO STILLING - h\u00E9r er \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting!,,Yes,Yes
9957,TODO STILLING - Athuga hvort h\u00E9r \u00E6tti a\u00F0 hafa \u00F3l\u00EDk villuskilabo\u00F0 fyrir WRONG_FORMERS og WRONG_FORMERS_CI?,,No,Yes
9958,TODO STILLING Tilb\u00FAi\u00F0 til a\u00F0 vera \u00ED sta\u00F0inn sent inn \u00ED CorrectionPipeline.,,,Yes
9960,TODO STILLING - h\u00E9r er b\u00E6\u00F0i samhengish\u00E1\u00F0 og \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting,,,Yes
9962,TODO STILLING - setja svo if-lykkju h\u00E9r til a\u00F0 lei\u00F0r\u00E9tta bara \u00F3sh. ef \u00FEa\u00F0 er vali\u00F0.,,Yes,Yes
9963,TODO STILLING - er samt versti hlutur \u00ED heimi a\u00F0 hafa \u00F3\u00FEekktu leitina hluta af \u00F3sh. m\u00E1lr\u00FDninni?,,Yes,Yes
9964,TODO STILLING - h\u00E9r er bara upp\u00E1stunga; skiptir ekki m\u00E1li fyrir \u00F3sh. m\u00E1lr\u00FDni,,Yes,Yes
9968,TODO STILLING - h\u00E9r er bara upp\u00E1stunga.,,Yes,Yes
9969,TODO STILLING - h\u00E9r er \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting; en \u00FEa\u00F0 er spurning hvort allt h\u00E9r teljist endilega villa.,,,Yes
9971,TODO STILLING - \u00DEarf a\u00F0 fara \u00ED gegnum WRONG_FORMERS; m\u00E6tti skipta upp \u00ED,,Yes,Yes
9972,TODO STILLING - ALWAYS_WRONG_FORMERS og MOSTLY_WRONG_FORMERS e\u00F0a eitthva\u00F0 \u00FEannig?,,,Yes
9974,TODO STILLING - Athuga hvort h\u00E9r \u00E6tti a\u00F0 hafa \u00F3l\u00EDk villuskilabo\u00F0 fyrir WRONG_FORMERS og WRONG_FORMERS_CI?,,,Yes
9976,TODO STILLING - \u00FEetta er \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting!,,Yes,Yes
9977,TODO STILLING - h\u00E9r er samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting af \u00FEv\u00ED a\u00F0 vi\u00F0 notum \u00FErenndir!,,,Yes
9978,TODO STILLING - og l\u00EDka \u00FEv\u00ED sko\u00F0um l\u00EDka sjaldg\u00E6f or\u00F0.,,Yes,Yes
9979,TODO STILLING - \u00FEetta er bara upp\u00E1stunga,,,Yes
9981,TODO STILLING - or\u00F0 sem eiga alltaf a\u00F0 vera l\u00E1gstafa nema \u00ED byrjun setningar eru sh. lei\u00F0r\u00E9tting.,,Yes,Yes
9982,TODO STILLING - h\u00E9r er \u00F3samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting EN er bara upp\u00E1stunga.,,Yes,Yes
9984,TODO STILLING Tilb\u00FAi\u00F0 til a\u00F0 vera \u00ED sta\u00F0inn sent inn \u00ED CorrectionPipeline.,,,Yes
9985,TODO STILLING - h\u00E9r er bara samhengish\u00E1\u00F0 lei\u00F0r\u00E9tting,,Yes,Yes
9987,TODO Consider limiting to words under 15 characters,,No,Yes
9989,!!! TODO: Move this to a config file,,No,Yes
9991,!!! TODO: Better annotation here; with the corrected subject,,,Yes
9992,TODO villan greinist ekki! Ath. l\u00EDka lengdina.,,Yes,Yes
9993,"If the code ends with \""\/w\""; it is a warning",,,Yes
10000,!!! TODO: More intelligent substitution to create a suggestion,,No,Yes
10001,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
10002,Python hack to create a fresh; empty instance of the,,Yes,Yes
10004,"assert \""Fj\u00F6gur hundru\u00F0 manns\"" in s  # !!! Needs B\u00CDN fix; upcoming",,Yes,Yes
10008,"assert \""fj\u00F6gur hundru\u00F0 manns\"" in s  # !!! Needs B\u00CDN fix; upcoming",,Yes,Yes
10009,!!! BUG: The code currently allows nonterminal nodes to match,,Yes,Yes
10010,!!! BUG: The code currently allows nonterminal nodes to match,,Yes,Yes
10012,TODO Setja \u00FAtreikning \u00E1 P; R og F \u00ED s\u00E9rfall;,,,Yes
10013,!!! TODO: this actually fixes spacing errors; causing them,,Yes,Yes
10014,!!! TODO might be the cause of quotation marks being affixed to the next word,,,Yes
10018,TODO B\u00E6ta vi\u00F0 stats sem skila,,Yes,Yes
10021,TODO: The following actually reduces GreynirCorrect's score on the,,,Yes
10022,Something like 'b-deildin' or 'a-flokki' which should probably,,,Yes
10024,sb -> b (should probably be sbr.),,Yes,Yes
10028,TODO Setja \u00FAtreikning \u00E1 P; R og F \u00ED s\u00E9rfall;,,Yes,Yes
10029,TODO T\u00E9kka h\u00E9r hvort er bara vi\u00F0v\u00F6run; x.is_warning(),,,Yes
10032,TODO B\u00E6ta vi\u00F0 stats sem skila,,Yes,Yes
10034,TODO safna villunum \u00ED generatora og taka eitt stak \u00ED einu og bera saman?,,,Yes
10035,TODO T\u00E9kka h\u00E9r hvort er bara vi\u00F0v\u00F6run; x.is_warning(),,,Yes
10036,TODO vinna \u00FAr rest af listum ef eitthva\u00F0 er eftir. Get t\u00E9kka\u00F0 \u00E1 lengdinni \u00ED upphafi?,,,Yes
10037,TODO Finna f\u00E1ga\u00F0ri lausn; sem tekur tillit til villuspana.,,,Yes
10039,or does it perhaps not exist? Check how BEA 2019 does this.,,No,Yes
10041,TODO put undir Typo?,,,Yes
10042,TODO put under Typo?,,Yes,Yes
10044,TODO taka saman corr_rec og span_rec; sko\u00F0a hvernig f\u00E6 F-skor; svipa\u00F0 og fyrir hitt; \u00FEegar er ekki me\u00F0 TN inni,,Yes,Yes
10045,!!! TODO: Maybe the following should be just token.txt.capitalize(),,,Yes
10046,TODO: This code is provisional; intended as a placeholder for similar cases,,,Yes
10047,!!! TODO: This is a provisional placeholder for similar cases,,Yes,Yes
10048,!!! TODO: Amalgamate more than one potential correction,,,Yes
10049,TODO taka saman corr_rec og span_rec; sko\u00F0a hvernig f\u00E6 F-skor; svipa\u00F0 og fyrir hitt; \u00FEegar er ekki me\u00F0 TN inni,,Yes,Yes
10050,TODO Consider limiting to words under 15 characters,,No,Yes
10051,!!! TODO: Add correctly inflected suggestion here,,,Yes
10052,TODO sama,,No,Yes
10054,TODO villurnar greinast ekki; vantar l\u00EDklega reglur.,,Yes,Yes
10059,TODO f\u00E6 enga villu; eftir a\u00F0 \u00FAtf\u00E6ra.,,Yes,Yes
10060,TODO villan greinist ekki. Komi\u00F0 \u00ED Verbs.conf? L\u00EDklega ekki r\u00E9ttur villuk\u00F3\u00F0i.,,,Yes
10061,"\""E003\"" : [\""XXX\""];",,Yes,Yes
10062,"\""P_WRONG_OP_FORM\"" : [\""XXX\""];",,Yes,Yes
10064,"\""E003\"" : [\""XXX\""];",,Yes,Yes
10068,"\""P_WRONG_OP_FORM\"" : [\""XXX\""];",,Yes,Yes
10069,TODO change?,,Yes,Yes
10073,TODO not ytok.text,,Yes,Yes
10076,TODO or suggest,,No,Yes
10077,TODO: Shouldn't this be 1?,,Yes,Yes
10078,TODO: Should this be 1?,,No,Yes
10079,FIXME:,,No,Yes
10080,FIXME:,,,Yes
10081,TODO sko\u00F0a,,,Yes
10082,TODO sko\u00F0a,,No,Yes
10084,!!! TODO: More intelligent substitution to create a suggestion,,,Yes
10086,# !!! TODO: More intelligent substitution to create a suggestion,,,Yes
10088,TODO: This code is provisional; intended as a placeholder for similar cases,,Yes,Yes
10089,The better (preferred) stem should still be there somewhere,,,Yes
10090,assert any(mm.stofn in better for mm in m),,,Yes
10093,Match: move to the next index position,,Yes,Yes
10094,(this is less efficient for small trees but much more efficient,,,Yes
10095,A complete 't\u00F6l' or 'no' is better (has more info) than a rough 'tala',,No,Yes
10096,!!! NOTE: It is probably not enough to just duplicate,,,Yes
10097,Eliminate all families except the best scoring one,,Yes,Yes
10098,Dictionary keyed by word containing a list of tuples (worse; better),,Yes,Yes
10104,!!! TODO: Limit the cache size; for example by LRU or a periodic purge,,,Yes
10105,First parts must match (i.e.; no_xxx != so_xxx),,Yes,Yes
10107,"nominal form (unless it already ends with \""st\"").",,,Yes
10109,Hack to make 'stt' terminals match with the B\u00CDN 'st' category,,Yes,Yes
10111,Hack to allow cases to be specified on fs literal terminals,,No,Yes
10112,Note that the Earley algorithm is more efficient on left recursion,,,Yes
10116,!!! TODO: Handle currency names and measurement units,,Yes,Yes
10117,Otherwise; they probably belong to a previous verb and we,,,Yes
10120,TODO skrifa yfir smi\u00F0inn fyrir TOK \u00FAr tokenizer.py \u00ED Tokenizer-pakka,,Yes,Yes
10121,The first line is the root (by convention nodeid 0),,,Yes
10123,TODO: Use .bin-files instead,,,Yes
10126,TODO: Use .bin-files instead,,Yes,Yes
10127,Match: move to the next index position,,,Yes
10128,TODO: Change if necessary.,,,Yes
10132,"print(\""{}-{}\"".format(w; m)) # TODO b\u00E6ta h\u00E9r vi\u00F0 sko\u00F0un \u00E1 'beri'; 'gjafi'; ... L\u00EDka annars sta\u00F0ar? Hj\u00E1 b\u00E1\u00F0um return-skipununum?",,No,Yes
10134,This is not needed for command-line invocation of bincompress.py;,,,Yes
10135,"print(\""{}-{}\"".format(w; m)) # TODO b\u00E6ta h\u00E9r vi\u00F0 sko\u00F0un \u00E1 'beri'; 'gjafi'; ... L\u00EDka annars sta\u00F0ar? Hj\u00E1 b\u00E1\u00F0um return-skipununum?",,No,Yes
10136,!!! TODO: Parse the corr string,,Yes,Yes
10138,!!! TODO: replacement of the entire construct),,,Yes
10139,TODO: Make sure node names are translated in treegrid,,,Yes
10141,(needed since None is a valid utg value),,,Yes
10145,TODO: Make sure node names are translated in treegrid,,,Yes
10146,!!! TODO: Handle currency names and measurement units,,,Yes
10149,If so; we eliminate one level and move the children of the child,,Yes,Yes
10151,No information needed after this,,Yes,Yes
10152,TODO change to another tagger; IceStagger or ABLtagger,,Yes,Yes
10153,!!! NOTE: This set should probably include all abbreviations that,,No,Yes
10156,Unknown words by convention get a category of 'entity',,,Yes
10161,!!! TODO: We might be pruning the parse forest too,,Yes,Yes
10162,!!! TODO: Parse the corr string,,,Yes
10163,!!! TODO: Implement this (store specification of a,,Yes,Yes
10165,The following declaration is a deliberate mypy hack,,,Yes
10169,!!! TODO: self._cat may be None; for instance for TOK.AMOUNT tokens,,No,Yes
10170,!!! TODO: There should be an escape character,,Yes,Yes
10173,we resort to a hack here by using type:ignore to silence mypy's,,No,Yes
10175,"Hack: Allow specifying the forward slash as \""\/\"" or '\/'",,No,Yes
10176,You can just specify the packages manually here if your project is,,Yes,Yes
10177,TODO: remove by dependencies,,No,Yes
10178,TODO: excecution_order by dependencies,,,Yes
10181,TODO: use time instead of mjd,,,Yes
10182,TODO: use mag instead of data,,,Yes
10187,remove all the not needed features and extractors,,Yes,Yes
10188,FIX the random state,,,Yes
10189,ok not to implement!,,,Yes
10193,isn't really intended to be played with.  It should be possible;,,Yes,Yes
10194,#NAME?,,,Yes
10195,Things to happen to your dictionary (apparently before Python,,Yes,Yes
10197,- I think parsers should probably return TreeTokens; not Trees.,,,Yes
10198,[edloper 8\/14\/01] Tokens really shouldn't contain mutable types,,,Yes
10202,rule initializer should compile the final regexp for efficient runtime execution,,Yes,Yes
10209,Create an empty array of (way x way) entries.,,,Yes
10214,This may not be the most efficient method if we're not using,,,Yes
10215,"\""\""\"" ||  || Basic data classes for building feature-based classifiers. || X{features} provide a standard way of encoding the information used to || make classification decisions.  This standard encoding allows the same || classifier to be used to solve many different problems. ||  || Features || ======== || Each feature specifies some aspect of a C{LabeledText} that is || relevant to deciding how likely that C{LabeledText} is to occur. || These features can then be used to examine how likely different labels || are for a given text.  A typical example of a feature is: ||  ||     - Whether a C{LabeledText} contains the word C{\\\""ball\\\""} and has ||       the label C{\\\""sports\\\""}. ||  || Abstractly; features can be thought of as functions mapping from || C{LabeledText}s to values.  For example; the feature function || corresponding to the typical feature given above is:: ||  ||     f(ltext)  =  1  if ((\\\""ball\\\"" in ltext.text) and ||                         (ltext.label == \\\""sports\\\"")) ||                         ||               =  0  otherwise ||  || Note that features depend on both the text and the label.  This allows || us to specify which aspects of a text are relevant for making || decisions about which labels.  Feature functions usually have the || form:: ||  ||     f(ltext)  =  g(ltext.text)   if ltext.label == L ||                       0          if ltext.label != L ||  || for some function C{g} and label C{L}.  {g} is sometimes called the || X{context function}. (?) ||  || Abstractly; each feature consists of: ||  ||    - A unique X{feature id}; which is used to distinguish the ||      feature.  Feature ids are bounded non-negative integers. ||       ||    - A X{feature detector}; which encapsulates the feature's ||      function.  Feature detectors are implemented using the ||      C{FeatureDetectorI} interface. ||       ||    - A set of possible X{feature value}s that can be produced by the ||      feature detector.  In principle; feature detectors can generate ||      any immutable value; however; many classifiers require that their ||      features have a specific type of value.  The most common sets of ||      feature values are: ||  ||          - booleans (C{0} and C{1}) ||          - integers ||          - non-negative integers ||          - real numbers ||  || Features are not explicitly represented by any object; instead; they || are indirectly represented using feature detectors. ||  || FeatureDetectorLists || ==================== || X{Feature detector lists} provide a way of grouping feature detectors || together.  Abstractly; a feature detector list can be thought of as a || C{list} of feature detectors.  The M{i}th element of this list is the || feature detector for the feature with id M{i}.   ||  || When a feature detector list is applied to a C{LabeledText}; it || returns a X{feature value list}.  Abstractly; a feature value list can || be thought of as a C{list} of feature values.  The M{i}th element of || this list is the feature value for the feature with id M{i}. ||  || Feature detector lists don't just serve to group feature detectors || together; they are also an important tool for efficient feature || detection.  Often; the features used for classification are closely || related to each other.  For example; a document classifier might use || features that examine whether a given word is in a document.  If we || applied each feature detector separately; we would have to scan || through the document once for each word we are interested in. || Instead; we can build a feature detector list that will check for all || relevant words at the same time. ||  || Similarly; feature value lists serve to make feature detection more || efficient.  For many classification tasks; feature value lists are || very sparse; in other words; most of the feature values have some || X{default value} (usually; zero).  Feature value lists provide a || method that can be used to retrieve all of the non-default feature || value assignments.  This can decrease the time that it takes to || process the feature value list considerably. ||  || Labeled Feature Value Lists || =========================== || Often; it is useful to associate a label with a feature value list. || The C{LabeledFeatureValueList} class can be used for this purpose. || Typically; each C{LabeledFeatureValueList} corresponds to a text; || where the labels are identical; and the feature value list is obtained || by applying some feature detector list to the text. || \""\""\""",,Yes,Yes
10217,"\""\""\"" || A text classifier model based on maximum entropy modeling framework. || This framework considers all of the probability distributions that are || emperically consistant with the training data; and chooses the || distribution with the highest entropy.  A probability distribution is || X{emperically consistant} with a set of training data if its estimate || for the frequency of each feature is equal to that frequency of the || feature in the training data.  In other words:: ||  ||   SUM[lt] (fd[i](lt) * P(lt)) = SUM[lt] (fd[i](lt) * freq(lt)) ||    || For all i; where: ||   - M{lt} is a labeled text. ||   - M{fd[i]} is the feature detector for the M{i}th feature. ||   - M{freq(lt)} is the frequency of M{lt} in the training corpus. ||   - M{P(lt)} is the estimated probability of M{lt}. ||  || It can be shown that the emperically consistant distribution that || maximizes entropy must have the form:: ||  ||   P(l|t) = 1\/Z(t) * exp(w[0]*fd[0](LabeledText(t;l)) + ||                         w[1]*fd[1](LabeledText(t;l)) + ||                         ... + ||                         w[n]*fd[n](LabeledText(t;l))) ||  || Where: ||   - M{t} is a text. ||   - M{l} is a label. ||   - M{fd[i]} is the feature detector for the M{i}th feature. ||   - M{w[i]} is the weight associated with the M{i}th feature. ||   - M{Z(t)} is a normalization factor; computed by summing ||     M{P(l|t)} over labels:: ||  ||         Z(t) = SUM[l] P(l|t) ||  || This form is known as a \""conditional exponential model.\""  The || C{ConditionalExponentialClassier} class implements this model. ||  || C{GISMaxentClassifierTrainer} and C{IISMaxentClassifierTrainer} || implement two different algorithms for training || C{ConditionalExponentialClassifiers}.  Both trainers find the || emperically consistant model which maximizes entropy. || C{GISMaxentClassifierTrainer} uses Generalized Iterative Scaling; and || C{IISMaxentClassifierTrainer} uses Improved Iterative Scaling. || \""\""\""",,,Yes
10222,CONSIDER CHANGING DATA STRUCTURE SO THAT THIS IS EFFICIENT,,Yes,Yes
10223,TODO - code up minimization algorithm from ASU,,,Yes
10224,How much extra space should we add around the FSA; to make it,,,Yes
10225,How much extra scroll-space should we provide; to let the user move,,Yes,Yes
10226,isn't terribly efficient; but we dont' expect to be,,Yes,Yes
10228,"\""\""\"" ||  || This is a version of chartparser that uses a single ChartRule interface; || which can be C{apply}ed to a chart... ||  || The chartparser module defines the C{ChartParser} class; and two supporting || classes; C{Edge} and C{Chart}. ||  || 'chart rule' is really not a very good name..  What might be a better || name?  We could use 'strategy.'  Hmm..  Of course; right now; a || strategy is a collection of chart rules..  Which is nice; for talking || about; e.g.; BU strategy.  Hrm..   ||  ||  || \""\""\""",,,Yes
10229,"\""\""\"" || Parsers for probabilistic context free grammars (C{PCFGs}). || C{nltk.pcfgparser} currently defines two basic types of || C{ProbabilisticParser}: C{ViterbiPCFGParser} and || C{BottomUpPCFGChartParser}. ||  || C{ViterbiPCFGParser} is a C{PCFG} parser based on a Viterbi-sytle || algorithm.  It uses dynamic programming to efficiently find the single || most likely parse for a given text. ||  || C{BottomUpPCFGChartParser} is an abstract class that implements a || bottom-up chart parser for C{PCFG}s.  It maintains a queue of edges; || and adds them to the chart one at a time.  The ordering of this queue || is based on the probabilities associated with the edges; allowing the || parser to expand more likely edges before less likely ones.  Each || subclass implements a different queue ordering; producing different || search strategies.  Currently the following subclasses are defined: ||  ||   - C{InsidePCFGParser} searches edges edges in decreasing order of ||     their trees' inside probabilities. ||   - C{RandomPCFGParser} searches edges in random order. ||   - C{LongestPCFGParser} searches edges in decreasing order of their ||     location's length. ||    || The following subclasses will be added in the near future: ||  ||   - C{OutsidePCFGParser} searches edges using best-first search. ||   - C{InsideOutsidePCFGParser} searches edges using A* search. || \""\""\""",,Yes,Yes
10232,Move it back; if we were dragging.,,No,Yes
10233,Move to (x;y),,,Yes
10234,"\""\""\"" || A graphical tool for exploring the shift\/reduce parser. ||  || This tool allows you to explore algorithm used by the shift\/reduce || parser.  The shift\/reduce parser maintains a stack; which records the || structure of the portion of the text that has been parsed.  The stack || is initially empty.  Its contents are shown on the left side of the || demo window. ||  || On the right side of the demo window is the remaining text.  This is || the portion of the text which has not yet been considered by the parser. ||  || The parser builds up a tree structure for the text using two || operations:  ||  ||   - \""shift\"" moves the first token from the remaining text to the top ||     of the stack.  In the demo; the top of the stack is its right-hand ||     side. ||   - \""reduce\"" uses a grammar production to combine the rightmost stack ||     elements into a single tree token. ||  || You can control the parser's operation by using the \""shift\"" and || \""reduce\"" button; or you can use the \""step\"" button to let the parser || automatically decide which operation to apply.  The shift reduce || parser uses the following rules to decide which operation to use: ||  ||   - Only shift if no reductions are available. ||   - If multiple reductions are available; then apply the reduction ||     whose CFG production is listed earliest in the grammar. ||  || Currently; there is no way to choose which production to apply; || however; this functionality should be added in the near future. ||  || KEYBOARD SHORTCUTS: ||     [space]    Perform the next shift or reduce operation ||     [s]        Perform a shift operation ||     [r]        Perform a reduction operation ||     [delete]   Reset the parser ||     [g]        Show\/hide grammar ||     [ctrl-a]   Toggle animations ||     [h]        Help ||     [p]        Print ||     [q]        Quit || \""\""\""",,No,Yes
10235,Move the remaining text to the correct location (keep it,,No,Yes
10236,"\""\""\"" || Possible future improvements: ||   - undo (shortcut=backspace).  Simplest implentation: keep a list of ||     the stack\/remaining text after each operation; and roll-back by ||     setting to the old one.  This should probably be implemented in ||     the stepping parser; not in thte demo.  (i.e.; stepping srparser ||     would have an undo() method). ||   - button\/window to change and\/or select text.  Just pop up a window ||     with an entry; and let them modify the text; and then retokenize ||     it?  Maybe give a warning if it contains tokens whose types are ||     not in the grammar. ||   - button\/window to change and\/or select grammar.  Select from ||     several alternative grammars?  Or actually change the grammar?  If ||     the later; then I'd want to define nltk.draw.cfg; which would be ||     responsible for that. || \""\""\""",,,Yes
10237,This isn't the best way to implement the productions,,Yes,Yes
10240,# efficient for sparse feature value lists...,,,Yes
10241,value lists are sparse; we can improve performance by finding,,Yes,Yes
10242,This import is needed to prevent an error if we create,,,Yes
10243,This reload is needed to prevent an error if we create,,No,Yes
10244,"BUG: 1001 gives \""one thousand one\""; and similar",,Yes,Yes
10252,"\""\""\"" || Classes and interfaces for dividing a string into a list of its || constituent tokens.  This task; which is known as X{tokenizing}; is || defined by the L{TokenizerI} interface. ||  || This module defines several implementations of the tokenizer || interface; such as L{WSTokenizer}; which splits texts based on || whitespace; and L{RETokenizer}; which uses a regular expression to || divide a string into tokens.  Several other modules also define || specialized tokenizers; such as L{nltk.tree.TreebankTokenizer} and || L{nltk.tagger.TaggedTokenizer}.  For a complete list of available || tokenizers; see the reference documentation for L{TokenizerI}. ||  || @group Interfaces: TokenizerI || @group Tokenizers: WSTokenizer; RETokenizer; CharTokenizer; ||     LineTokenizer; _XTokenTuple || @sort: Location; Token; TokenizerI; WSTokenizer; RETokenizer; CharTokenizer; ||     LineTokenizer; _XTokenTuple || \""\""\""",,Yes,Yes
10254,fix lone &,,Yes,Yes
10256,"fix \""\""\""",,Yes,Yes
10257,"fix <s snum=dd> => <s snum=\""dd\""\/>",,Yes,Yes
10261,[XX] END HACK,,Yes,Yes
10262,hack..,,,Yes
10264,isn't terribly efficient; but we dont' expect to be,,Yes,Yes
10265,<- is this better??,,,Yes
10267,[XX] This might not be implemented quite right -- it would be better,,Yes,Yes
10268,a terrible hack with nasty; hard-to-fathom side effects that should,,Yes,Yes
10269,"\""\""\"" || Classes and interfaces for dividing a token into its constituent || pieces.  This task; which is known as X{tokenizing}; is defined by the || L{TokenizerI} interface. ||  || This module defines several implementations of the tokenizer || interface; such as L{WSTokenizer}; which splits texts based on || whitespace; and L{RegexpTokenizer}; which uses a regular expression to || divide a token into pieces.  Several other modules also define || specialized tokenizers; such as L{nltk.tree.TreebankTokenizer} and || L{nltk.tagger.TaggedTokenizer}.  For a complete list of available || tokenizers; see the reference documentation for L{TokenizerI}. ||  || @group Interfaces: TokenizerI || @group Tokenizers: WSTokenizer; RegexpTokenizer; LineTokenizer; ||                    AbstractTokenizer || \""\""\""",,Yes,Yes
10270,"\""\""\"" || Classes for representing hierarchical language structures over tokens; || such as syntax trees and morphological trees.  A single tree is || represented by a nested structure of X{tree tokens}; where each tree || token encodes a single hierarchical grouping.  Tree tokens are || specialized tokens that associate additional meaning with specific || properties.  Different tree token implementations associate different || meanings to these properties.  Three tree token implementations are || currently available: ||  ||   - L{TreeToken}s use the C{CHILDREN} property to record the ||     hierarchical content of a tree. ||  ||   - L{ParentedTreeToken}s use the C{CHILDREN} property to record ||     the hierarchical content of a tree; and the C{PARENT} property ||     to record the tree's unique parent. ||  ||   - L{MultiParentedTreeToken}s use the C{CHILDREN} property to ||     record the hierarchical content of a tree; and the C{PARENTS} ||     property to record a list of the tree's parents. ||  || For most purposes; the C{TreeToken} implementation is sufficient.  But || in cases where parent pointers are needed; the C{ParentedTreeToken} or || C{MultiParentedTreeToken} implementations can be used.  The || C{ParentedTreeToken} implementation is appropriate when each subtree || has a unique parent; and the C{MultiParentedTreeToken} implementation || is appropriate when a single subtree can be shared by multiple || parents. || \""\""\""",,,Yes
10272,Right-hand operations.  These are needed to make sure that,,,Yes
10275,"\""\""\"" || This module contains a number of basic clustering algorithms. Clustering || describes the task of discovering groups of similar items with a large || collection. It is also describe as unsupervised machine learning; as the data || from which it learns is unannotated with class information; as is the case for || supervised learning.  Annotated data is difficult and expensive to obtain in || the quantities required for the majority of supervised learning algorithms. || This problem; the knowledge acquisition bottleneck; is common to most natural || language processing tasks; thus fueling the need for quality unsupervised || approaches. ||  || This module contains a k-means clusterer; E-M clusterer and a group average || agglomerative clusterer (GAAC). All these clusterers involve finding good || cluster groupings for a set of vectors in multi-dimensional space. ||  || The K-means clusterer starts with k arbitrary chosen means then allocates each || vector to the cluster with the closest mean. It then recalculates the means of || each cluster as the centroid of the vectors in the cluster. This process || repeats until the cluster memberships stabilise. This is a hill-climbing || algorithm which may converge to a local maximum. Hence the clustering is || often repeated with random initial means and the most commonly occuring || output means are chosen. ||  || The GAAC clusterer starts with each of the M{N} vectors as singleton clusters. || It then iteratively merges pairs of clusters which have the closest centroids. || This continues until there is only one cluster. The order of merges gives rise || to a dendogram - a tree with the earlier merges lower than later merges. The || membership of a given number of clusters M{c}; M{1 <= c <= N}; can be found by || cutting the dendogram at depth M{c}. ||  || The Gaussian EM clusterer models the vectors as being produced by a mixture || of k Gaussian sources. The parameters of these sources (prior probability; || mean and covariance matrix) are then found to maximise the likelihood of the || given data. This is done with the expectation maximisation algorithm. It || starts with k arbitrarily chosen means; priors and covariance matrices. It || then calculates the membership probabilities for each vector in each of the || clusters - this is the 'E' step. The cluster parameters are then updated in || the 'M' step using the maximum likelihood estimate from the cluster membership || probabilities. This process continues until the likelihood of the data does || not significantly increase. ||  || They all extend the ClustererI interface which defines common operations || available with each clusterer. These operations include. ||    - cluster: clusters a sequence of tokens ||    - classify: assign a token to a cluster ||    - classification_probdist: give the probability distribution over cluster memberships ||  || The current existing classifiers also extend VectorSpaceClusterer; an || abstract class which allows for singular value decomposition (SVD) and vector || normalisation. SVD is used to reduce the dimensionality of the vector space in || such a manner as to preserve as much of the variation as possible; by || reparametising the axes in order of variability and discarding all bar the || first d dimensions. Normalisation ensures that vectors fall in the unit || hypersphere. ||  || Usage example (see also demo()):: ||     tokens = [Token(FEATURES=Numeric.array([3; 3])); ||               Token(FEATURES=Numeric.array([1; 2])); ||               Token(FEATURES=Numeric.array([4; 2])); ||               Token(FEATURES=Numeric.array([4; 0]))] ||      ||     # initialise the clusterer (will also assign the tokens to clusters) ||     clusterer = KMeansClusterer(2; euclidean_distance) ||     clusterer.cluster(tokens; True) ||  ||     # classify a new token ||     token = Token(FEATURES=Numeric.array([3; 3])) ||     clusterer.classify(token) ||     print token ||  || Note that the tokens must have FEATURE attributes with Numeric array-like || objects. nltk_contrib.unimelb.tacohn.SparseArrays may be used for efficiency || when required. || \""\""\""",,,Yes
10276,if the matrix is tiny (i.e. only one point)... better to,,,Yes
10278,calculate likelihood - FIXME: may be broken,,No,Yes
10280,that this isn't the best rule; so move on:,,Yes,Yes
10281,If the actual score is better than the best score; then,,Yes,Yes
10284,"\""\""\"" || Classes and interfaces for dividing a token into its constituent || pieces.  This task; which is known as X{tokenizing}; is defined by the || L{TokenizerI} interface. ||  || This module defines several implementations of the tokenizer || interface; such as L{WhitespaceTokenizer}; which splits texts based on || whitespace; and L{RegexpTokenizer}; which uses a regular expression to || divide a token into pieces.  Several other modules also define || specialized tokenizers; such as L{nltk.tree.TreebankTokenizer} and || L{nltk.tagger.TaggedTokenizer}.  For a complete list of available || tokenizers; see the reference documentation for L{TokenizerI}. ||  || @group Interfaces: TokenizerI || @group Tokenizers: WhitespaceTokenizer; RegexpTokenizer; LineTokenizer; ||                    AbstractTokenizer || \""\""\""",,,Yes
10285,SUBPATTERN item and repair the sub item if needed,,,Yes
10286,[XX] TEMPORARY HACK WARNING!  This should be replaced with,,Yes,Yes
10287,So this is a somewhat hackish work-around; which converts a,,Yes,Yes
10290,believe him. FIXME,,No,Yes
10292,"fix \""\""\""",,Yes,Yes
10294,fix <{word}>,,Yes,Yes
10295,"fix 'abc <p=\""foo\""\/>' style tags - now <wf pos=\""foo\"">abc<\/wf>",,Yes,Yes
10296,SUBPATTERN item and repair the sub item if needed,,No,Yes
10297,A nicer way would be welcome.,,Yes,Yes
10298,that this isn't the best rule; so move on:,,,Yes
10300,"\""\""\"" || Classes and interfaces for producing tree structures that represent || the internal organization of a text.  This task is known as X{parsing} || the text; and the resulting tree structures are called the text's || X{parses}.  Typically; the text is a single sentence; and the tree || structure represents the syntactic structure of the sentence. || However; parsers can also be used in other domains.  For example; || parsers can be used to derive the morphological structure of the || morphemes that make up a word; or to derive the discourse structure || for a set of utterances. ||  || Sometimes; a single piece of text can be represented by more than one || tree structure.  Texts represented by more than one tree structure are || called X{ambiguous} texts.  Note that there are actually two ways in || which a text can be ambiguous: ||  ||     - The text has multiple correct parses. ||     - There is not enough information to decide which of several ||       candidate parses is correct. ||  || However; the parser module does I{not} distinguish these two types of || ambiguity. ||  || The parser module defines C{ParserI}; a standard interface for parsing || texts; and two simple implementations of that interface; || C{ShiftReduceParser} and C{RecursiveDescentParser}.  It also contains || three sub-modules for specialized kinds of parsing: ||  ||   - C{nltk.parser.chart} defines chart parsing; which uses dynamic ||     programming to efficiently parse texts. ||   - C{nltk.parser.chunk} defines chunk parsing; which identifies ||     non-overlapping linguistic groups in a text. ||   - C{nltk.parser.probabilistic} defines probabilistic parsing; which ||     associates a probability with each parse. ||  || @group Interfaces: ParserI || @group Parsers: ShiftReduceParser; SteppingShiftReduceParser; ||        RecursiveDescentParser; SteppingRecursiveDescentParser || @sort: ParserI; ShiftReduceParser; SteppingShiftReduceParser; ||        RecursiveDescentParser; SteppingRecursiveDescentParser;  ||        demo; chart; chunk; probabilistic || @see: C{nltk.cfg} || \""\""\""",,,Yes
10301,[XX] TEMPORARY HACK WARNING!  This should be replaced with,,,Yes
10302,i == 0 never happens perhaps,,,Yes
10303,"if self.ends(\""abli\""):      self.r(\""able\"")",,Yes,Yes
10305,"\""\""\"" || Classes and interfaces for producing tree structures that represent || the internal organization of a text.  This task is known as X{parsing} || the text; and the resulting tree structures are called the text's || X{parses}.  Typically; the text is a single sentence; and the tree || structure represents the syntactic structure of the sentence. || However; parsers can also be used in other domains.  For example; || parsers can be used to derive the morphological structure of the || morphemes that make up a word; or to derive the discourse structure || for a set of utterances. ||  || Sometimes; a single piece of text can be represented by more than one || tree structure.  Texts represented by more than one tree structure are || called X{ambiguous} texts.  Note that there are actually two ways in || which a text can be ambiguous: ||  ||     - The text has multiple correct parses. ||     - There is not enough information to decide which of several ||       candidate parses is correct. ||  || However; the parser module does I{not} distinguish these two types of || ambiguity. ||  || The parser module defines C{ParserI}; a standard interface for parsing || texts; and two simple implementations of that interface; || C{ShiftReduceParser} and C{RecursiveDescentParser}.  It also contains || three sub-modules for specialized kinds of parsing: ||  ||   - C{nltk.parser.chart} defines chart parsing; which uses dynamic ||     programming to efficiently parse texts. ||   - C{nltk.parser.chunk} defines chunk parsing; which identifies ||     non-overlapping linguistic groups in a text. ||   - C{nltk.parser.probabilistic} defines probabilistic parsing; which ||     associates a probability with each parse. ||  || @group Interfaces: ParserI || @group Parsers: ShiftReduceParser; SteppingShiftReduceParser; ||        RecursiveDescentParser; SteppingRecursiveDescentParser || @sort: ParserI; ShiftReduceParser; SteppingShiftReduceParser; ||        RecursiveDescentParser; SteppingRecursiveDescentParser;  ||        demo; chart; chunk; probabilistic || @see: C{nltk.cfg} || \""\""\""",,,Yes
10307,A nicer way would be welcome.,,Yes,Yes
10312,SUBPATTERN item and repair the sub item if needed,,No,Yes
10313,Move it back; if we were dragging.,,No,Yes
10315,This reload is needed to prevent an error if we create,,No,Yes
10316,Boy; too bad tkinter doesn't implement Listbox.itemconfig;,,Yes,Yes
10317,Move the text string down; if necessary.,,Yes,Yes
10319,hack..,,,Yes
10320,"\""\""\"" || Classes and interfaces for producing tree structures that represent || the internal organization of a text.  This task is known as X{parsing} || the text; and the resulting tree structures are called the text's || X{parses}.  Typically; the text is a single sentence; and the tree || structure represents the syntactic structure of the sentence. || However; parsers can also be used in other domains.  For example; || parsers can be used to derive the morphological structure of the || morphemes that make up a word; or to derive the discourse structure || for a set of utterances. ||  || Sometimes; a single piece of text can be represented by more than one || tree structure.  Texts represented by more than one tree structure are || called X{ambiguous} texts.  Note that there are actually two ways in || which a text can be ambiguous: ||  ||     - The text has multiple correct parses. ||     - There is not enough information to decide which of several ||       candidate parses is correct. ||  || However; the parser module does I{not} distinguish these two types of || ambiguity. ||  || The parser module defines C{ParseI}; a standard interface for parsing || texts; and two simple implementations of that interface; || C{ShiftReduce} and C{RecursiveDescent}.  It also contains || three sub-modules for specialized kinds of parsing: ||  ||   - C{nltk.parser.chart} defines chart parsing; which uses dynamic ||     programming to efficiently parse texts. ||   - C{nltk.parser.chunk} defines chunk parsing; which identifies ||     non-overlapping linguistic groups in a text. ||   - C{nltk.parser.probabilistic} defines probabilistic parsing; which ||     associates a probability with each parse. || \""\""\""",,,Yes
10322,believe him. FIXME,,No,Yes
10329,"\""why..I\"" \te.g. \""why am I here?\"" \""Why do I like cake?\""",,,Yes
10331,Author: Peter Spiller <pspiller@csse.unimelb.edu.au>,,,Yes
10332,[XX] This might not be implemented quite right -- it would be better,,,Yes
10334,A semi-hack to have elegant looking code below.  As a result;,,Yes,Yes
10335,Author: Peter Spiller,,Yes,Yes
10336,calculate amount of left padding needed,,,Yes
10338,TODO - check that parse was complete; and report error otherwise,,,Yes
10340,delete inaccessible nodes and unused transitions,,Yes,Yes
10342,TODO: remove Unix dependencies,,Yes,Yes
10343,cheap hack now that graphviz is not working right...,,Yes,Yes
10346,\t                   (5; True; [ 1;   1;   1;  0;  1;  2;  0;  1 ]);    # V Cpal e +:0... [english.rul needed fixing],,Yes,Yes
10347,\t                   (8; True; [ 1;   1;   1;  0;  1;  0;  0;  1 ]) ]); # V C e +:0... [english.rul needed fixing],,Yes,Yes
10348,this should really be done in dotstring,,Yes,Yes
10349,recognition causes a problem; here's why.  this routine encounters @ before +:i,,No,Yes
10351,that this isn't the best rule; so move on:,,Yes,Yes
10353,TODO: move into __init__() when all marshalling classes will be moved into,,,Yes
10357,"\""\""\"" || Zen Chatbot talks in gems of Zen wisdom. ||  || This is a sample conversation with Zen Chatbot: || ZC:    Welcome; my child. || me:    Good afternoon. || ZC:    Ask the question you have come to ask. || me:    How can I achieve enlightenment? || ZC:    How do you suppose? || me:    Through meditation. || ZC:    Form is emptiness; and emptiness form. || me:    How can I empty my mind of worldly troubles? || ZC:    Will an answer to that really help in your search for enlightenment? || me:    Yes. || ZC:    It is better to be right than to be certain. || me:    I seek truth and wisdom. || ZC:    The search for truth is a long journey. || me:    Are you sure? || ZC:    Maybe sure; maybe not sure. ||  ||  || The chatbot structure is based on that of chat.eliza. Thus; it uses || a translation table to convert from question to response || i.e. \""I am\"" --> \""you are\"" ||  || Of course; since Zen Chatbot does not understand the meaning of any words; || responses are very limited. Zen Chatbot will usually answer very vaguely; or || respond to a question by asking a different question; in much the same way || as Eliza. || \""\""\""",,,Yes
10359,why questions are separated into three types:,,,Yes
10360,"\""why..I\""     e.g. \""why am I here?\"" \""Why do I like cake?\""",,,Yes
10361,"\""why...\""    e.g. \""Why is the sky blue?\""",,,Yes
10363,calculate likelihood - FIXME: may be broken,,,Yes
10364,work-around while marshal is not moved into standard tree,,Yes,Yes
10365,Author: Peter Spiller,,,Yes
10366,calculate amount of left padding needed,,No,Yes
10368,TODO - check that parse was complete; and report error otherwise,,,Yes
10370,delete inaccessible nodes and unused transitions,,Yes,Yes
10372,TODO: remove Unix dependencies,,Yes,Yes
10375,\t                 '             Cpal C    e:0 e:@ +:0 Vbk V   @'; # english.rul needed pairs re-ordered,,,Yes
10376,\t                   (5; True; [ 1;   1;   1;  0;  1;  2;  0;  1 ]);    # V Cpal e +:0... [english.rul needed fixing],,Yes,Yes
10377,\t                   (8; True; [ 1;   1;   1;  0;  1;  0;  0;  1 ]) ]); # V C e +:0... [english.rul needed fixing],,Yes,Yes
10378,this should really be done in dotstring,,Yes,Yes
10382,A nicer way would be welcome.,,,Yes
10383,that this isn't the best rule; so move on:,,Yes,Yes
10384,If the actual score is better than the best score; then,,Yes,Yes
10385,Move it back; if we were dragging.,,No,Yes
10387,This reload is needed to prevent an error if we create,,No,Yes
10388,Boy; too bad tkinter doesn't implement Listbox.itemconfig;,,,Yes
10389,Move the text string down; if necessary.,,,Yes
10391,hack..,,,Yes
10393,Kludge to ensure child_choices is a doubly-nested list,,Yes,Yes
10395,[XX] This might not be implemented quite right -- it would be better,,,Yes
10397,A semi-hack to have elegant looking code below.  As a result;,,Yes,Yes
10399,A nicer way would be welcome.,,,Yes
10400,that this isn't the best rule; so move on:,,Yes,Yes
10401,If the actual score is better than the best score; then,,,Yes
10402,believe him. FIXME,,No,Yes
10404,"if self.ends(\""abli\""):      self.r(\""able\"")",,,Yes
10405,SUBPATTERN item and repair the sub item if needed,,,Yes
10407,"if self.ends(\""abli\""):      self.r(\""able\"")",,Yes,Yes
10408,"\""\""\"" || Functionality for parsing and manipulating the contents of a Shoebox || lexicon without reference to its metadata. For more sophisticated || functionality that handles metadata; use the module I{metadata}. || \""\""\""",,No,Yes
10409,"\""\""\"" || This module provides functionality for handling the metadata associated || with Shoebox lexicons and texts. || \""\""\""",,,Yes
10412,TODO: Deal with Font Information,,,Yes
10414,"\""\""\"" || TODO || \""\""\""",,,Yes
10415,"\""\""\"" || Functionality for parsing and manipulating the contents of a Shoebox || lexicon without reference to its metadata. For more sophisticated || functionality that handles metadata; use the module I{metadata}. || \""\""\""",,,Yes
10416,"\""\""\"" || This module provides functionality for handling the metadata associated || with Shoebox lexicons and texts. || \""\""\""",,Yes,Yes
10418,TODO,,,Yes
10420,TODO: Modify to take into account changes to Field object,,,Yes
10424,Hack the summary output to look nicer.,,,Yes
10426,Write BOM if needed.,,,Yes
10428,Yeah; it's ugly and slow.,,,Yes
10429,TODO: support for BOM within a stream.,,Yes,Yes
10430,Reset everything (not really needed).,,No,Yes
10431,TODO: We need to make tab handling rules more sane. A good rule is,,Yes,Yes
10433,A depth-first search would work as well since the trees must,,,Yes
10436,TODO: Add field to header,,,Yes
10437,TODO: Raise NonUniqueEntryKeyError,,No,Yes
10438,expr wasn't a constant; maybe a variable that g knows about?,,Yes,Yes
10439,isn't terribly efficient; but we dont' expect to be,,Yes,Yes
10441,hack..,,Yes,Yes
10443,"\""\""\"" || This module provides functionality for reading Shoebox settings files; || which provide metadata for Shoebox lexicons and texts. || \""\""\""",,,Yes
10446,work around a Windows Python bug,,Yes,Yes
10447,Ideally; we'd use a weak dict; but there aren't any.  A strong dict,,,Yes
10448,you; if needed.,,Yes,Yes
10449,2003-11-15 fl   fixed nested namespace bug,,Yes,Yes
10450,FIXME: issue warning in this case?,,No,Yes
10454,FIXME: overkill,,Yes,Yes
10455,@param data A string.  This should be either an 8-bit string,,Yes,Yes
10460,inflected\/uninflected constituents would probably be needed (compounds,,No,Yes
10462,Chat-80 relation metadata bundles needed to build the valuation,,,Yes
10464,Work around a Windows Python bug,,Yes,Yes
10465,Write BOM if needed.,,Yes,Yes
10466,TODO: support for BOM within a stream.,,,Yes
10467,Yeah; it's ugly and slow.,,Yes,Yes
10468,TODO: support for BOM within a stream.,,Yes,Yes
10469,Reset everything (not really needed).,,No,Yes
10470,TODO: We need to make tab handling rules more sane. A good rule is,,Yes,Yes
10471,The specification is really confusing about tabs in plain scalars.,,Yes,Yes
10472,TODO: This next code is dense and confusing. Clean up at some point.,,Yes,Yes
10477,[XXX] We can't do this without poking around in other,,Yes,Yes
10478,depends on the class used to implement elements; so we replace,,,Yes
10480,"\""\""\"" || Register YAML tags in the NLTK namespace with the YAML loader; by telling it || what module and class to look for. ||  || NLTK uses simple '!' tags to mark the types of objects; but the fully-qualified || \""tag:nltk.sourceforge.net;2007:\"" prefix is also accepted in case anyone ends up || using it. || \""\""\""",,,Yes
10481,# expr wasn't a constant; maybe a variable that g knows about?,,,Yes
10482,# expr wasn't a constant; maybe a variable that g knows about?,,,Yes
10483,"\""\""\"" || Ewan Klein; March 2007 ||  || Experimental module to provide support for implementing English morphology by || feature unification. ||  || Main challenge is to find way of encoding morphosyntactic rules. Current idea is to let a concatenated form such as 'walk + s' be encoded as a dictionary C{'stem': 'walk'; 'affix': 's'}. This allows the morpho-phonological representation to undergo unification in the normal way. || \""\""\""",,Yes,Yes
10484,"\""\""\"" || Classes and interfaces for producing tree structures that represent || the internal organization of a text.  This task is known as X{parsing} || the text; and the resulting tree structures are called the text's || X{parses}.  Typically; the text is a single sentence; and the tree || structure represents the syntactic structure of the sentence. || However; parsers can also be used in other domains.  For example; || parsers can be used to derive the morphological structure of the || morphemes that make up a word; or to derive the discourse structure || for a set of utterances. ||  || Sometimes; a single piece of text can be represented by more than one || tree structure.  Texts represented by more than one tree structure are || called X{ambiguous} texts.  Note that there are actually two ways in || which a text can be ambiguous: ||  ||     - The text has multiple correct parses. ||     - There is not enough information to decide which of several ||       candidate parses is correct. ||  || However; the parser module does I{not} distinguish these two types of || ambiguity. ||  || The parser module defines C{ParseI}; a standard interface for parsing || texts; and two simple implementations of that interface; || C{ShiftReduce} and C{RecursiveDescent}.  It also contains || three sub-modules for specialized kinds of parsing: ||  ||   - C{nltk.parser.chart} defines chart parsing; which uses dynamic ||     programming to efficiently parse texts. ||   - C{nltk.parser.probabilistic} defines probabilistic parsing; which ||     associates a probability with each parse. || \""\""\""",,,Yes
10487,Kludge to ensure child_choices is a doubly-nested list,,,Yes
10490,[XX] This might not be implemented quite right -- it would be better,,Yes,Yes
10491,[XX] TEMPORARY HACK WARNING!  This should be replaced with,,,Yes
10492,A semi-hack to have elegant looking code below.  As a result;,,Yes,Yes
10494,Author: Contributed by Rob Speer (NLTK version),,,Yes
10498,TODO refactor to use nltk_lite.probability.FreqDist for self.counts,,Yes,Yes
10499,TODO,,,Yes
10500,todo,,No,Yes
10501,TODO: Add in the option to manually add a new root node; this will be,,Yes,Yes
10503,Work around a Windows Python bug,,,Yes
10504,Work around a Windows Python bug,,Yes,Yes
10505,workaround for lack of nested closures in Python < 2.1,,Yes,Yes
10506,"No action taken if word ends with \""-ply\""",,Yes,Yes
10509,"\""\""\"" || Below are data structures that are needed to store the information of the corpus || \""\""\""",,Yes,Yes
10511,ugh!! ugly!!!.. need to find a better way.. there are way too many params here! till then.. this stays,,,Yes
10512,skip comments at the ends of lines,,No,Yes
10514,workaround for lack of nested closures in Python < 2.1,,,Yes
10515,Chat-80 relation metadata bundles needed to build the valuation,,,Yes
10517,workaround for lack of nested closures in Python < 2.1,,Yes,Yes
10523,Find a list of bigram collocations whose first word ends in,,No,Yes
10524,Get the types of both tokens.  If typ1 ends in a period;,,No,Yes
10528,[XX] This is less evil; but not too efficient!,,No,Yes
10529,fix lone &,,,Yes
10531,"fix <s snum=dd> => <s snum=\""dd\""\/>",,,Yes
10532,fix <{word}>,,Yes,Yes
10535,Yes; it's bad programming practice; but this is a little hack,,Yes,Yes
10539,If we're stripping comments; then make sure our block ends,,Yes,Yes
10540,[xx] if the file ends with a non-parenthasized sexpr,,Yes,Yes
10541,[xx] if the file ends with a non-parenthasized sexpr,,,Yes
10543,the word ends in 's'? apply rule for plural reduction,,,Yes
10545,TODO: figure out while empty documents are being returned,,Yes,Yes
10550,Better shell support on Windows; thanks Noel O'Boyle.,,,Yes
10551,2007-07-29 NMB Better packaging.,,Yes,Yes
10554,todo: get a more general solution to canonicalized symbols for clauses -- maybe use xmlcharrefs?,,,Yes
10556,(list-of-lists) performs better than csr and csc formats.,,No,Yes
10558,needed after freq_threshold,,,Yes
10559,this load function would be more efficient if the data was pickled,,Yes,Yes
10560,add new columns to the output probability table without,,No,Yes
10562,[xx] hack check:,,No,Yes
10563,Efficiency hack -- if the grammar is empty; then don't,,,Yes
10565,hack:,,,Yes
10566,Ensure that the filename ends with '.zip',,,Yes
10568,TODO deal with case where s contains an int,,,Yes
10569,TODO: throughout this package variable names and docstrings need,,No,Yes
10570,TODO Handle files here.,,,Yes
10571,TODO: The following issues exist with this module; and should,,Yes,Yes
10572,This looks up multiple words at once.  This is probably not,,Yes,Yes
10573,TODO.  Part of this page should be dynamic so it is updated with the wordnet database.,,Yes,Yes
10574,marked with 'XXX',,Yes,Yes
10575,XXX: write these global constants in shouting case.,,Yes,Yes
10576,XXX: This fallback may have problems on windows.,,Yes,Yes
10577,## XXX: MUST find a standard location for the stats HTML page;,,,Yes
10578,XXX: MAY simplfy the if predicate. *\/,,Yes,Yes
10579,XXX: MAY remove three statments with no effect. *\/,,Yes,Yes
10581,TODO: Should give instructions for using dbinfo_html.py,,,Yes
10582,Try to catch the screen dimensions like this because no better,,,Yes
10584,#NAME?,,Yes,Yes
10585,Subclasses shuld define more efficient implementations of this;,,,Yes
10586,[xx] nb: this is not too efficient,,,Yes
10587,columns to expect for SRL data.,,,Yes
10588,todo: implement Katz backoff,,,Yes
10590,optional tree columns,,Yes,Yes
10591,Remaining columns: self,,,Yes
10592,hack,,,Yes
10593,TODO lf = lf.normalize('[xyz]\\d*'; 'z%d'),,Yes,Yes
10594,needs to implement simplified tags,,,Yes
10596,Hide\/Show Columns,,,Yes
10597,Columns,,No,Yes
10599,too small which leads to poor performance loading large gzipped,,,Yes
10600,Columns can be resized by dragging them:,,,Yes
10601,Columns can be resized by dragging them.  (This binding is,,No,Yes
10602,used if they click on the grid between columns:),,,Yes
10604,So this is really what we should do.  That way the threaded,,Yes,Yes
10605,the wrong thing to do.  Maybe the _interactive_download,,Yes,Yes
10606,Create a menu to control which columns of the table are,,,Yes
10607,shown.  n.b.: we never hide the first two columns (mark and,,Yes,Yes
10608,Author:     Peter Wang,,,Yes
10609,A depth-first search would work as well since the trees must,,Yes,Yes
10611,should probably be done lazily:,,,Yes
10614,TODO: Add in the option to manually add a new root node; this will be,,Yes,Yes
10615,this load function would be more efficient if the data was pickled,,,Yes
10616,Move it back; if we were dragging.,,,Yes
10619,TODO Handle files here.,,,Yes
10620,TODO: The following issues exist with this module; and should,,Yes,Yes
10621,XXX: I don't know the format of this datastrcutre so I wont try to,,,Yes
10624,marked with 'XXX',,Yes,Yes
10629,XXX: MAY remove three statments with no effect. *\/,,,Yes
10633,XXX: What is prev_synset_key?,,,Yes
10634,This looks up multiple words at once.  This is probably not,,,Yes
10635,XXX: What is prev_synset_key?,,No,Yes
10636,TODO add a variation of this that takes a non ecoded word or MWE.,,,Yes
10640,TODO: Frequent sentence starters optionally exclude always-capitalised words,,No,Yes
10641,skip comments at the ends of lines,,No,Yes
10643,"\""\""\"" || Implementations of inter-annotator agreement coefficients surveyed by Artstein || and Poesio (2007); Inter-Coder Agreement for Computational Linguistics. ||  || An agreement coefficient calculates the amount that annotators agreed on label  || assignments beyond what is expected by chance. ||  || In defining the AnnotationTask class; we use naming conventions similar to the  || paper's terminology.  There are three types of objects in an annotation task:  ||  ||     the coders (variables \""c\"" and \""C\"") ||     the items to be annotated (variables \""i\"" and \""I\"") ||     the potential categories to be assigned (variables \""k\"" and \""K\"") ||  || Additionally; it is often the case that we don't want to treat two different  || labels as complete disagreement; and so the AnnotationTask constructor can also || take a distance metric as a final argument.  Distance metrics are simply  || functions that take two arguments; and return a value between 0.0 and 1.0  || indicating the distance between them.  If not supplied; the default is binary  || comparison between the arguments. ||  || The simplest way to initialize an AnnotationTask is with a list of equal-length  || lists; each containing a coder's assignments for all objects in the task: ||  ||     task = AnnotationTask([];[];[]) ||  || Alpha (Krippendorff 1980) || Kappa (Cohen 1960) || S (Bennet; Albert and Goldstein 1954) || Pi (Scott 1955) ||  ||  || TODO: Describe handling of multiple coders and missing data ||  || Expected results from the Artstein and Poesio survey paper: ||  || >>> t = AnnotationTask(data=[x.split() for x in open(\""%sartstein_poesio_example.txt\"" % (__file__.replace(\""__init__.py\""; \""\"")))]) || >>> t.avg_Ao() || 0.88 || >>> t.pi() || 0.7995322418977614 || >>> t.S() || 0.81999999999999984 || \""\""\""",,Yes,Yes
10644,TODO: VERY slow; speed this up!,,,Yes
10645,I don't understand why this negation is needed,,No,Yes
10648,Trying to fetch a HTML file TODO:,,Yes,Yes
10649,TODO add a variation of this that takes a non ecoded word or MWE.,,No,Yes
10651,Total hack warning:,,No,Yes
10653,FIXME Should this raise some kind of error instead?,,,Yes
10655,Author: Peter Ljungl\u00F6f <peter.ljunglof@heatherleaf.se>,,Yes,Yes
10656,TODO: Clean this mess up,,Yes,Yes
10658,TODO: change this to conform more with the standard ChartParser,,Yes,Yes
10663,Author: Peter Ljungl\u00F6f <peter.ljunglof@heatherleaf.se>,,,Yes
10665,[xx] There's no reason in principle why this can't preserve,,,Yes
10666,hack,,,Yes
10667,"\""\""\"" || An interface to Boxer. ||  || Usage: ||   Set the environment variable CANDCHOME to the bin directory of your CandC installation. ||   The models directory should be in the CandC root directory. ||   For example: ||      \/path\/to\/candc\/ ||         bin\/ ||             candc ||             boxer ||         models\/ ||             boxer\/ || \""\""\""",,No,Yes
10674,"Hack to keep NLTK's \""tokenize\"" module from colliding with the \""tokenize\"" in",,Yes,Yes
10675,TODO: Add support for jar names specified as regular expressions,,Yes,Yes
10676,!!!!!!!!!!!!!TODO LATE; USE nltk.data TO FETCH PATHS!!!!!!!!!,,,Yes
10678,"\""\""\"" || A classifier based on a support vector machine. This code uses Thorsten Joachims' || SVM^light implementation (http:\/\/svmlight.joachims.org\/); wrapped using || PySVMLight (https:\/\/bitbucket.org\/wcauchois\/pysvmlight). The default settings are to  || train a linear classification kernel; though through minor modification; full SVMlight || capabilities should be accessible if needed. Only binary classification is possible at present. || \""\""\""",,,Yes
10680,"\""\""\"" || NLTK Parsers ||  || Classes and interfaces for producing tree structures that represent || the internal organization of a text.  This task is known as X{parsing} || the text; and the resulting tree structures are called the text's || X{parses}.  Typically; the text is a single sentence; and the tree || structure represents the syntactic structure of the sentence. || However; parsers can also be used in other domains.  For example; || parsers can be used to derive the morphological structure of the || morphemes that make up a word; or to derive the discourse structure || for a set of utterances. ||  || Sometimes; a single piece of text can be represented by more than one || tree structure.  Texts represented by more than one tree structure are || called X{ambiguous} texts.  Note that there are actually two ways in || which a text can be ambiguous: ||  ||     - The text has multiple correct parses. ||     - There is not enough information to decide which of several ||       candidate parses is correct. ||  || However; the parser module does I{not} distinguish these two types of || ambiguity. ||  || The parser module defines C{ParserI}; a standard interface for parsing || texts; and two simple implementations of that interface; || C{ShiftReduceParser} and C{RecursiveDescentParser}.  It also contains || three sub-modules for specialized kinds of parsing: ||  ||   - C{nltk.parser.chart} defines chart parsing; which uses dynamic ||     programming to efficiently parse texts. ||   - C{nltk.parser.probabilistic} defines probabilistic parsing; which ||     associates a probability with each parse. || \""\""\""",,Yes,Yes
10681,Todo: Add a way to select the development set from the menubar.  This,,,Yes
10683,XXX Transforming to lil_matrix is wasteful; since scikit-learn,,Yes,Yes
10684,"\""\""\"" || An interface to Boxer. ||  || Usage: ||   Set the environment variable CANDCHOME to the bin directory of your CandC installation. ||   The models directory should be in the CandC root directory. ||   For example: ||      \/path\/to\/candc\/ ||         bin\/ ||             candc ||             boxer ||         models\/ ||             boxer\/ || \""\""\""",,,Yes
10685,"\""\""\"" || Register YAML tags in the NLTK namespace with the YAML loader; by telling it || what module and class to look for. ||  || NLTK uses simple '!' tags to mark the types of objects; but the fully-qualified || \""tag:nltk.org;2011:\"" prefix is also accepted in case anyone ends up || using it. || \""\""\""",,Yes,Yes
10687,We need to implement __getslice__ and friends; even though,,Yes,Yes
10691,TODO: We need to add some kind of smoothing here; instead of,,Yes,Yes
10695,XXX: self.__class__ vs Nonterminal?,,,Yes
10698,workaround for py25 which doesn't support followlinks,,,Yes
10699,XXX: self.__class__ vs Nonterminal?,,Yes,Yes
10701,FIXME: this won't work under python 3,,Yes,Yes
10702,XXX: it is stated in module docs that there is no function versions,,,Yes
10705,XXX: imports can't be moved to the top of the file,,,Yes
10706,Fix for inspect.isclass under Python 2.6,,Yes,Yes
10708,Kneser and Hermann Ney. It was meant to improve the accuracy of language,,No,Yes
10709,In order for the implementation of Kneser-Ney to be more efficient; some,,Yes,Yes
10710,TODO: load() should be able to read zipfiles too,,Yes,Yes
10715,"if self.ends(\""abli\""):      self.r(\""able\"")",,Yes,Yes
10716,why is this needed?,,,Yes
10720,Kneser and Hermann Ney. It was meant to improve the accuracy of language,,No,Yes
10721,In order for the implementation of Kneser-Ney to be more efficient; some,,Yes,Yes
10722,"if self.ends(\""abli\""):      self.r(\""able\"")",,,Yes
10723,XXX what should we do in Python 3?,,Yes,Yes
10726,FIXME,,Yes,Yes
10728,kludge - already decoded in PY3?,,Yes,Yes
10729,that this isn't the best rule; so move on:,,Yes,Yes
10730,If the actual score is better than the best score; then,,Yes,Yes
10735,from nltk.align.XXX              import YYY,,,Yes
10737,n_ooo = n_xxx - n_iii - n_oii - n_ioi - n_iio - n_ooi - n_oio - n_ioo,,Yes,Yes
10738,TODO: count_w == candidate_ngrams.count(c_words[-1]) + 1,,No,Yes
10740,Fix HTML character entities:,,No,Yes
10744,remove unused columns; right to left,,,Yes
10745,remove unused rows; reverse,,Yes,Yes
10750,Todo : because of probability = True => very slow due to cross-validation,,,Yes
10752,Long Duong : Fix bug #543 (looking for Senna executable),,No,Yes
10754,ToDo: Update with http:\/\/en.wikipedia.org\/wiki\/List_of_emoticons ?,,,Yes
10757,TODO: implement node label semantics,,Yes,Yes
10758,TODO implement,,,Yes
10759,''' || Created on July 04; 2013 || @author: C.J. Hutto ||  || Citation Information ||  || If you use any of the VADER sentiment analysis tools  || (VADER sentiment lexicon or Python code for rule-based sentiment  || analysis engine) in your work or research; please cite the paper.  || For example: ||  ||   Hutto; C.J. & Gilbert; E.E. (2014). VADER: A Parsimonious Rule-based Model for  ||   Sentiment Analysis of Social Media Text. Eighth International Conference on  ||   Weblogs and Social Media (ICWSM-14). Ann Arbor; MI; June 2014. || ''',,Yes,Yes
10761,"\""\""\"" || NLTK Twitter client ||  || This module offers methods for collecting and processing tweets. Most of the || functionality depends on access to the Twitter APIs; and this is handled via || the third party Twython library. ||  || If one of the methods below returns an integer; it is probably a `Twitter || error code <https:\/\/dev.twitter.com\/overview\/api\/response-codes>`_. For || example; the response of '420' means that you have reached the limit of the || requests you can currently make to the Twitter API. Currently; `rate limits || for the search API <https:\/\/dev.twitter.com\/rest\/public\/rate-limiting>`_ are || divided into 15 minute windows. || \""\""\""",,Yes,Yes
10763,Test if magic find_binary still works but maybe it should be deprecated.,,Yes,Yes
10764,TODO: any UNANN exemplars?,,Yes,Yes
10766,XXX (ncoghlan): The following code attempts to make,,,Yes
10767,TODO: not strictly the case that every LU sentence has 1 annotation set:,,,Yes
10768,The emoticon string gets its own regex so that we can preserve case for them as needed:,,Yes,Yes
10771,''' || Created on July 04; 2013 || @author: C.J. Hutto ||  || Citation Information ||  || If you use any of the VADER sentiment analysis tools  || (VADER sentiment lexicon or Python code for rule-based sentiment  || analysis engine) in your work or research; please cite the paper.  || For example: ||  ||   Hutto; C.J. & Gilbert; E.E. (2014). VADER: A Parsimonious Rule-based Model for  ||   Sentiment Analysis of Social Media Text. Eighth International Conference on  ||   Weblogs and Social Media (ICWSM-14). Ann Arbor; MI; June 2014. || ''',,,Yes
10773,To improve flexibility we could later abstract from tweets to generic documents,,,Yes
10774,This method is probably poorly implemented. We need to store word_features,,No,Yes
10775,This list of negation is taken from vader.py. We'd better import it instead.,,No,Yes
10776,Issue a ResourceWarning if implicit cleanup needed,,No,Yes
10778,"\""\""\"" || NLTK Twitter client ||  || This module offers methods for collecting and processing Tweets. Most of the || functionality depends on access to the Twitter APIs; and this is handled via || the third party Twython library. ||  || If one of the methods below returns an integer; it is probably a `Twitter || error code <https:\/\/dev.twitter.com\/overview\/api\/response-codes>`_. For || example; the response of '420' means that you have reached the limit of the || requests you can currently make to the Twitter API. Currently; `rate limits || for the search API <https:\/\/dev.twitter.com\/rest\/public\/rate-limiting>`_ are || divided into 15 minute windows. || \""\""\""",,Yes,Yes
10781,"\""\""\"" || CorpusReader for the Customer Review corpus. ||  || - Customer Review Corpus information - || Annotated by: Minqing Hu and Bing Liu; 2004. ||     Department of Computer Sicence ||     University of Illinois at Chicago ||  || Contact: Bing Liu; liub@cs.uic.edu ||         http:\/\/www.cs.uic.edu\/~liub ||  || Distributed with permission. ||  || The dataset contains annotated customer reviews of 5 products from amazon.com. ||  ||     1. digital camera: Canon G3 ||     2. digital camera: Nikon coolpix 4300 ||     3. celluar phone:  Nokia 6610 ||     4. mp3 player:     Creative Labs Nomad Jukebox Zen Xtra 40GB ||     5. dvd player:     Apex AD2600 Progressive-scan DVD player ||  || Related papers: || - Minqing Hu and Bing Liu. \""Mining and summarizing customer reviews\"". ||     Proceedings of the ACM SIGKDD International Conference on Knowledge ||     Discovery & Data Mining (KDD-04); 2004. ||  || - Minqing Hu and Bing Liu. \""Mining Opinion Features in Customer Reviews.\"" ||     Proceedings of Nineteeth National Conference on Artificial Intelligence ||     (AAAI-2004); 2004. ||  || Symbols used in the annotated reviews: ||  ||     [t] : the title of the review: Each [t] tag starts a review. ||     xxxx[+|-n]: xxxx is a product feature. ||     [+n]: Positive opinion; n is the opinion strength: 3 strongest; and 1 weakest. ||           Note that the strength is quite subjective. ||           You may want ignore it; but only considering + and - ||     [-n]: Negative opinion ||     ##  : start of each sentence. Each line is a sentence. ||     [u] : feature not appeared in the sentence. ||     [p] : feature not appeared in the sentence. Pronoun resolution is needed. ||     [s] : suggestion or recommendation. ||     [cc]: comparison with a competing product from a different brand. ||     [cs]: comparison with a competing product from the same brand. || \""\""\""",,Yes,Yes
10782,"\""\""\"" || The IBM models are a series of generative models that learn lexical || translation probabilities; p(target language word|source language word); || given a sentence-aligned parallel corpus. ||  || The models increase in sophistication from model 1 to 5. Typically; the || output of lower models is used to seed the higher models. All models || use the Expectation-Maximization (EM) algorithm to learn various || probability tables. ||  || Words in a sentence are one-indexed. The first word of a sentence has || position 1; not 0. Index 0 is reserved in the source sentence for the || NULL token. The concept of position does not apply to NULL; but it is || indexed at 0 by convention. ||  || Each target word is aligned to exactly one source word or the NULL || token. ||  || Notations || i: Position in the source sentence ||     Valid values are 0 (for NULL); 1; 2; ...; length of source sentence || j: Position in the target sentence ||     Valid values are 1; 2; ...; length of target sentence || s: A word in the source language || t: A word in the target language ||  ||  || In IBM Model 1; word order is ignored for simplicity. Thus; the || following two alignments are equally likely. ||  || Source: je mange du jambon || Target: i eat some ham || Alignment: (1;1) (2;2) (3;3) (4;4) ||  || Source: je mange du jambon || Target: some ham eat i || Alignment: (1;4) (2;3) (3;2) (4;1) ||  || The EM algorithm used in Model 1 is: || E step - In the training data; count how many times a source language ||          word is translated into a target language word; weighted by ||          the prior probability of the translation. ||  || M step - Estimate the new probability of translation based on the ||          counts from the Expectation step. ||  ||  || References: || Philipp Koehn. 2010. Statistical Machine Translation. || Cambridge University Press; New York. ||  || Peter E Brown; Stephen A. Della Pietra; Vincent J. Della Pietra; and || Robert L. Mercer. 1993. The Mathematics of Statistical Machine || Translation: Parameter Estimation. Computational Linguistics; 19 (2); || 263-311. || \""\""\""",,Yes,Yes
10783,"\""\""\"" || The IBM models are a series of generative models that learn lexical || translation probabilities; p(target language word|source language word); || given a sentence-aligned parallel corpus. ||  || The models increase in sophistication from model 1 to 5. Typically; the || output of lower models is used to seed the higher models. All models || use the Expectation-Maximization (EM) algorithm to learn various || probability tables. ||  || Words in a sentence are one-indexed. The first word of a sentence has || position 1; not 0. Index 0 is reserved in the source sentence for the || NULL token. The concept of position does not apply to NULL; but it is || indexed at 0 by convention. ||  || Each target word is aligned to exactly one source word or the NULL || token. ||  || Notations || i: Position in the source sentence ||     Valid values are 0 (for NULL); 1; 2; ...; length of source sentence || j: Position in the target sentence ||     Valid values are 1; 2; ...; length of target sentence || l: Number of words in the source sentence || m: Number of words in the target sentence || s: A word in the source language || t: A word in the target language ||  ||  || IBM Model 2 improves on Model 1 by accounting for word order. || An alignment probability is introduced; a(i | j;l;m); which predicts || a source word position; given its aligned target word's position. ||  || The EM algorithm used in Model 2 is: || E step - In the training data; collect counts; weighted by prior ||          probabilities. ||          (a) count how many times a source language word is translated ||              into a target language word ||          (b) count how many times a particular position in the source ||              sentence is aligned to a particular position in the target ||              sentence ||  || M step - Estimate new probabilities based on the counts from the E step ||  ||  || References: || Philipp Koehn. 2010. Statistical Machine Translation. || Cambridge University Press; New York. ||  || Peter E Brown; Stephen A. Della Pietra; Vincent J. Della Pietra; and || Robert L. Mercer. 1993. The Mathematics of Statistical Machine || Translation: Parameter Estimation. Computational Linguistics; 19 (2); || 263-311. || \""\""\""",,Yes,Yes
10784,"\""\""\"" || The IBM models are a series of generative models that learn lexical || translation probabilities; p(target language word|source language word); || given a sentence-aligned parallel corpus. ||  || The models increase in sophistication from model 1 to 5. Typically; the || output of lower models is used to seed the higher models. All models || use the Expectation-Maximization (EM) algorithm to learn various || probability tables. ||  || Words in a sentence are one-indexed. The first word of a sentence has || position 1; not 0. Index 0 is reserved in the source sentence for the || NULL token. The concept of position does not apply to NULL; but it is || indexed at 0 by convention. ||  || Each target word is aligned to exactly one source word or the NULL || token. ||  || Notations || i: Position in the source sentence ||     Valid values are 0 (for NULL); 1; 2; ...; length of source sentence || j: Position in the target sentence ||     Valid values are 1; 2; ...; length of target sentence || l: Number of words in the source sentence || m: Number of words in the target sentence || s: A word in the source language || t: A word in the target language || phi: Fertility; the number of target words produced by a source word || p1: Probability that a target word produced by a source word is ||     accompanied by another target word that is aligned to NULL || p0: 1 - p1 ||  || IBM Model 3 improves on Model 2 by directly modeling the phenomenon || where a word in one language may be translated into zero or more words || in another. This is expressed by the fertility probability; || n(phi | source word). ||  || If a source word translates into more than one word; it is possible to || generate sentences that have the same alignment in multiple ways. This || is modeled by a distortion step. The distortion probability; d(j|i;l;m); || predicts a target word position; given its aligned source word's || position. The distortion probability replaces the alignment probability || of Model 2. ||  || The fertility probability is not applicable for NULL. Target words that || align to NULL are assumed to be distributed uniformly in the target || sentence. The existence of these words is modeled by p1; the probability || that a target word produced by a real source word requires another || target word that is produced by NULL. ||  || The EM algorithm used in Model 3 is: || E step - In the training data; collect counts; weighted by prior ||          probabilities. ||          (a) count how many times a source language word is translated ||              into a target language word ||          (b) count how many times a particular position in the target ||              sentence is aligned to a particular position in the source ||              sentence ||          (c) count how many times a source word is aligned to phi number ||              of target words ||          (d) count how many times NULL is aligned to a target word ||  || M step - Estimate new probabilities based on the counts from the E step ||  || Because there are too many possible alignments; only the most probable || ones are considered. First; the best alignment is determined using prior || probabilities. Then; a hill climbing approach is used to find other good || candidates. ||  ||  || References: || Philipp Koehn. 2010. Statistical Machine Translation. || Cambridge University Press; New York. ||  || Peter E Brown; Stephen A. Della Pietra; Vincent J. Della Pietra; and || Robert L. Mercer. 1993. The Mathematics of Statistical Machine || Translation: Parameter Estimation. Computational Linguistics; 19 (2); || 263-311. || \""\""\""",,,Yes
10786,"\""\""\"" || Common methods and classes for all IBM models. See ``IBMModel1``; || ``IBMModel2``; and ``IBMModel3`` for specific implementations. ||  || The IBM models are a series of generative models that learn lexical || translation probabilities; p(target language word|source language word); || given a sentence-aligned parallel corpus. ||  || The models increase in sophistication from model 1 to 5. Typically; the || output of lower models is used to seed the higher models. All models || use the Expectation-Maximization (EM) algorithm to learn various || probability tables. ||  || Words in a sentence are one-indexed. The first word of a sentence has || position 1; not 0. Index 0 is reserved in the source sentence for the || NULL token. The concept of position does not apply to NULL; but it is || indexed at 0 by convention. ||  || Each target word is aligned to exactly one source word or the NULL || token. ||  || References: || Philipp Koehn. 2010. Statistical Machine Translation. || Cambridge University Press; New York. ||  || Peter E Brown; Stephen A. Della Pietra; Vincent J. Della Pietra; and || Robert L. Mercer. 1993. The Mathematics of Statistical Machine || Translation: Parameter Estimation. Computational Linguistics; 19 (2); || 263-311. || \""\""\""",,,Yes
10789,TODO implement me,,Yes,Yes
10791,FIXME magic number that will be removed in next commit; which drops the use of max_fertiliy,,,Yes
10792,TODO Consider top n translations,,,Yes
10793,Instead of returning empty output; perhaps a partial,,Yes,Yes
10795,check if a better score can be obtained by combining,,,Yes
10796,This is a bit ugly; but it avoids running this again by,,Yes,Yes
10797,Workaround for standalone backslash,,,Yes
10798,TODO: Does it work?,,,Yes
10799,TODO: Originally; we can return several parsers for a sentence.,,Yes,Yes
10801,TODO: Originally; we can return several parsers for a sentence.,,Yes,Yes
10802,TODO: take a free random port.,,,Yes
10803,Don't tokenize period unless it ends the line and that it isn't,,No,Yes
10805,Checks if token ends with a fullstop.,,No,Yes
10810,TODO: any UNANN exemplars?,,Yes,Yes
10812,TODO: is there a better way of checking whether a server is ready to,,,Yes
10814,workaround for bug in Tk font handling,,Yes,Yes
10815,Hack to help people like the readers of,,,Yes
10817,Hack to help people like the readers of,,No,Yes
10818,It'll be better to unescape after STRIP_EOL_HYPHEN,,Yes,Yes
10819,or next ? todo : how to deal with or next,,,Yes
10822,copy needed to prevent state sharing,,,Yes
10823,FIXME: Is this necessary at all?,,No,Yes
10824,FIXME: Why is it inheritting from SyntaxCorpusReader but initializing,,,Yes
10825,FIXME: Why is it inheritting from SyntaxCorpusReader but initializing,,,Yes
10827,FIXME:  override any imported demo from various corpora; see https:\/\/github.com\/nltk\/nltk\/issues\/2116,,Yes,Yes
10829,or next TODO: How to deal with or next instruction,,,Yes
10830,put skipped and unused terms back into play for later unification.,,,Yes
10833,move in direction of minimum cost,,,Yes
10834,move in direction of minimum cost,,,Yes
10835,import statment fix,,Yes,Yes
10836,Add more above if needed.,,,Yes
10837,TODO(lukaszkaiser): remove hack below; needed for greedy decoding for now.,,,Yes
10844,TODO(lukaszkaiser): why is this hack needed for variables init? Repair.,,No,Yes
10852,"NOTE: This algorithm is greedy; it won't necessarily produce the \""best\""",,Yes,Yes
10853,Not needed if self.is_character_level.,,Yes,Yes
10855,Not needed if self.is_character_level.,,Yes,Yes
10856,mode-specific.  A better fix would be to stop abusing the,,,Yes
10862,TODO(lukaszkaiser): why is this hack needed for variables init? Repair.,,,Yes
10873,These are not images; axis=2;3 are not needed.,,No,Yes
10874,sequences.  Due to some (hopefully) temporary hacks in the,,Yes,Yes
10876,TODO(rsepassi): Remove once we move to core Estimator.,,,Yes
10877,Hack to make each expert have a unique id,,Yes,Yes
10879,TODO(rsepassi): Rm hasattr call once new dynamic window size functionality,,Yes,Yes
10880,"According to noam; (\""n\""; \""da\"") seems better for harder-to-learn models",,Yes,Yes
10882,mode-specific.  A better fix would be to stop abusing the,,,Yes
10883,"\""\""\""Single stack of transformations with no masking. ||  || Produces output aligned with inputs. ||  || Configurable using hyperparameters to use some combination of convolutions; || attention; mixtures of experts; etc. ||  || A good problem for this model is languagemodel_wiki_scramble1k50 . || \""\""\""",,Yes,Yes
10884,TODO(llion): Explain! Is this even needed?,,Yes,Yes
10885,they only implement the hparams.,,Yes,Yes
10886,TODO(seabass): Implement the fix so that we can remove this assertion.,,Yes,Yes
10887,Python 2 hack for keyword only args,,Yes,Yes
10888,Generic way to extend multihead_attention,,,Yes
10890,Hack: Forward the loss by by-passing multihead_attention,,No,Yes
10891,out why.,,Yes,Yes
10894,CzEng contains 100 gz files with tab-separated columns; so let's expect,,,Yes
10895,TODO(epot): Implement more generic version of the mask computation to,,Yes,Yes
10896,A hack could be to add at least one sequence of each batch on each group so,,,Yes
10897,TODO(epot): Implement more generic version of the mask computation to,,Yes,Yes
10898,targets; which can improve the models inference results later. The,,Yes,Yes
10899,CzEng contains 100 gz files with tab-separated columns; so let's expect,,Yes,Yes
10902,TODO: ensure the output format (chars split by spaces) was as intended,,No,Yes
10904,perhaps there were no inputs; and this is a new variable.,,Yes,Yes
10907,you need to register to get UN data and CWT data. Also; by convention;,,,Yes
10911,Needed info is constant; so we construct in numpy,,Yes,Yes
10912,Used only when a vocab file or such like is needed.,,,Yes
10915,The convention is that the models are flattened along the spatial;,,Yes,Yes
10917,Not needed if self.is_character_level.,,,Yes
10918,TODO(lukaszkaiser): find a better way than printing this.,,,Yes
10919,>1 shards helps with faster parameter distribution on multi-GPU machines,,,Yes
10922,HACK: Make lr and global_step dependent on grad.,,No,Yes
10923,END HACK,,Yes,Yes
10924,Better shuffling is important for distributed training.,,No,Yes
10927,that rows is a multiple of query_shape and columns is a multiple of,,Yes,Yes
10928,times number of channels. This is  needed for positional encodings and,,Yes,Yes
10930,Only needed in eval runs.,,Yes,Yes
10932,Only needed in eval runs.,,,Yes
10933,HACK: Make things dependent on grad.,,No,Yes
10934,END HACK,,Yes,Yes
10935,Below we have a hacky solution which is a workaround to be used together,,,Yes
10936,a class of the interface bach env (todo: pm; fill me),,,Yes
10941,TODO: pm -> B\u0142a\u017Cej. I'm to tired to fix it now.,,No,Yes
10942,TODO: pm->\u0141ukasz eval is not working (to be precise it behaves stochastically.,,Yes,Yes
10947,#TODO: pm->\u0141ukasz. What should be the starting conditions,,Yes,Yes
10948,TODO: pm-> B\u0142a\u017Cej. Check if TimeLimitWrapper does what it is supposed to do,,No,Yes
10950,TODO: pm remove tf.identity below,,,Yes
10952,TODO: looks as if it is broken,,,Yes
10953,TODO: remove PongT2TGeneratorHackWrapper by writing a modality,,No,Yes
10954,TODO: possibly make embeding of inputs_0 and inputs_1,,,Yes
10957,TODO: Check if TimeLimitWrapper does what it is supposed to do,,,Yes
10958,TODO: pm->pm: add done,,Yes,Yes
10959,TODO: pull it outside,,,Yes
10963,Inputs and features preparation needed to handle edge cases.,,,Yes
10964,columns to match for every resolution.,,,Yes
10965,This if statement is needed to guard the cast; because batch norm,,,Yes
10967,columns to match for every resolution.,,Yes,Yes
10968,TODO(rsepassi): Fix decode length. Broken by cl\/190537320.,,,Yes
10969,Below we have a hacky solution which is a workaround to be used together,,,Yes
10970,TODO: remove PongT2TGeneratorHackWrapper by writing a modality,,No,Yes
10971,TODO: pull it outside,,,Yes
10973,TODO: possibly make embeding of inputs_0 and inputs_1,,,Yes
10982,To fix the issue #706,,,Yes
10986,TODO: Check if TimeLimitWrapper does what it is supposed to do,,,Yes
10989,To fix issue:#706,,Yes,Yes
10990,To fix the issue #706,,No,Yes
10992,Inputs and features preparation needed to handle edge cases.,,,Yes
10993,TODO: remove 8,,,Yes
10994,"\""\""\""Transformers with depthwise recurrency (go\/r-transformer). ||  ||  || A high-level explanation on the idea and the architecture: ||  || The vanilla Transformer model has no recurrence and struggles with some tasks || that a fully recurrent model can easily solve. Instead of incorporating || recurrence in time (which has a dependency on sequence length T); || we apply recurrence in depth (which we can set to some fixed length D << T); || and apply self-attention instead of sequential processing to enable the model || to incorporate long-range dependencies. ||  || Structure of the code is explained in r_transformer_util.py || \""\""\""",,Yes,Yes
10996,TODO(noam): remove this hack once XLA does the right thing.,,,Yes
10997,Move frames next to batch.,,,Yes
11000,TODO(piotrm): This should be probably removed.,,,Yes
11006,Hack: If training on autoencoded frames; autoencoder_path needs to be,,Yes,Yes
11007,hack: ignoring true targets and putting dist_targets in targets,,Yes,Yes
11008,Can be unstable; maybe try Adam.,,Yes,Yes
11011,TODO(fstahlberg): Implement a sparse version,,Yes,Yes
11015,Unused,,,Yes
11016,Hack: foldl complains when the output shape is less specified than the,,No,Yes
11017,TODO(piotrmilos). This should be probably done in collect,,Yes,Yes
11018,TODO (piotrmilos). it is possible to set more,,,Yes
11020,TODO(avaswani): Better way to do this.,,No,Yes
11022,Unused,,,Yes
11023,TODO(llion): Explain! Is this even needed?,,Yes,Yes
11025,TODO(piotrm): This should be probably removed.,,Yes,Yes
11026,Inputs and features preparation needed to handle edge cases.,,,Yes
11029,Generic way to extend multihead_attention,,,Yes
11030,"r\""\""\""View the problem. ||  || This binary saves the videos in the problem(dataset) into gifs. ||  || The imagemagick package should be installed for conversion to gifs. ||  || Example usage to view dataset: ||  ||   video2gif \\ ||       --data_dir ~\/data \\ ||       --problem=gym_water_world_random5k \\ ||       --hparams_set=next_frame_stochastic \\ ||       --output_dir \/usr\/local\/google\/home\/mbz\/t2t_train\/ww\/ \\ ||       --data_dir \/usr\/local\/google\/home\/mbz\/temp\/ \\ ||       --num_samples 10 || \""\""\""",,,Yes
11032,This is hackish way of introducing resets every,,No,Yes
11035,"add \""_rev\"" as a hack to avoid image standardization",,,Yes
11036,Concat columns of pad to shift from relative to absolute indexing.,,Yes,Yes
11039,TODO(piotrmilos): move restoring networks to SimulatedBatchEnv.initialize,,,Yes
11040,Hack: If training on autoencoded frames; autoencoder_path needs to be,,,Yes
11042,TODO(ylc): fix this once TPU estimator changes are checked in.,,,Yes
11043,Hack: if you report a loss of NaN; TensorBoard will plot a point at,,,Yes
11045,Generic way to extend multihead_attention,,,Yes
11046,TODO(trandustin): Fix this in a better manner.,,No,Yes
11048,HACK: Do first step outside to initialize all the variables,,No,Yes
11049,HACK: Do first step outside to initialize all the variables,,No,Yes
11051,When choosing shuffle buffer sizes; larger sizes result in better,,Yes,Yes
11053,num_items; unused,,Yes,Yes
11056,"approximately as much as \""going back 1 epoch\"" would be in default schedule.",,Yes,Yes
11058,HACK. just return something.,,Yes,Yes
11059,TODO(avaswani): Maybe scale the embeddings flowing out of the experts.,,,Yes
11061,TODO(avaswani): Figure out why tf.get_variable doesn't work with assign,,,Yes
11062,TODO(avaswani): Maybe scale the embeddings flowing out of the experts.,,,Yes
11063,Should be implemented if ever two StackWrappers are to be used together.,,,Yes
11065,The convention is that the models are flattened along the spatial;,,Yes,Yes
11068,TODO(piotrmilos): move restoring networks to SimulatedBatchEnv.initialize,,Yes,Yes
11070,"is approximately as much as \""going back 1 epoch\"" would be.",,Yes,Yes
11071,Reward prediction if needed.,,No,Yes
11072,dirty hack to enable the latent tower,,Yes,Yes
11073,TODO(nikip): Maybe add residual with a projection?,,,Yes
11074,more hack to enable latent_tower,,Yes,Yes
11075,TODO(ylc): Better estimation of replica cache size?,,Yes,Yes
11076,Inputs and features preparation needed to handle edge cases.,,Yes,Yes
11078,"is approximately as much as \""going back 1 epoch\"" would be.",,,Yes
11081,This hack is here because SimulatedBatchEnv needs to get,,,Yes
11082,TODO: do we need option not to gather_ppo_real_env_data?,,No,Yes
11084,Inputs and features preparation needed to handle edge cases.,,,Yes
11086,How many data points to suffle. Ideally should be part of problem not model!,,,Yes
11087,Currently not needed. Keeping it just in case.,,,Yes
11088,HACK: bypassing decoding issues.,,No,Yes
11090,is needed; please file an issue under:,,Yes,Yes
11091,should simply provide a good starting point to an interested party.,,Yes,Yes
11092,necessarily when it begins to apply gradients; rather; it should be placed at,,Yes,Yes
11094,TODO(trandustin): Fix this to work with Eager.,,Yes,Yes
11099,TODO(konradczechowski): move 'simulated' to  batch_env,,Yes,Yes
11101,the following ends up being `mean + unconstrained_stddev * noise`.,,,Yes
11102,is needed for model based rollouts).,,,Yes
11105,Unused; number of PPO epochs is calculated from the real frame limit.,,Yes,Yes
11106,If this will be a problem for maintenance; we could probably override,,Yes,Yes
11107,TODO(noam): implement different types of transformers.,,,Yes
11108,unused,,,Yes
11109,Hack: if you report a loss of NaN; TensorBoard will plot a point at,,Yes,Yes
11110,To avoid OOM. Probably way to small.,,Yes,Yes
11111,If needed for using a pre-trained model's vocabulary where extra indices,,Yes,Yes
11112,"tf.global_variables(\""clean_scope.*\"")  # Needed for sharing params.",,Yes,Yes
11115,TODO(konradczechowski): remove when not longer needed.,,Yes,Yes
11116,TODO(konradczechowski): remove when this will be not needed.,,Yes,Yes
11123,TODO(afrozm): This should eventually subclass Problem.,,Yes,Yes
11124,Unused.,,,Yes
11126,Play a move,,Yes,Yes
11127,all the envs take one (extra) step; but would be a clean way to do it.,,Yes,Yes
11132,places in ppo_learner.py -- re-evaluate if needed.,,,Yes
11133,locations. Although this is not the most disk efficient strategy; it,,Yes,Yes
11135,unused arg,,No,Yes
11136,TODO(lukaszkaiser): remove this function when not needed any more.,,,Yes
11137,TODO(lukaszkaiser): remove this function when not needed any more.,,No,Yes
11138,TODO(lukaszkaiser): remove this function when not needed any more.,,,Yes
11139,faster and better packing but requires custom-built binary.,,Yes,Yes
11140,prepare the left-most and right-most partial blocks if needed,,Yes,Yes
11142,__init__ args are unused in any methods. They're maintained for,,Yes,Yes
11143,Import for gin configurable models,,Yes,Yes
11144,unused,,No,Yes
11145,If needed; create log_dir directory as well as missing parent directories.,,,Yes
11148,unused,,No,Yes
11149,unused arg,,No,Yes
11153,* Make eval metrics configurable,,Yes,Yes
11155,* Make learning rate configurable; possibly combine with optimizer,,,Yes
11156,TODO(b\/37527917): Total hack below. Implement more principled formatting.,,Yes,Yes
11157,* Move metrics to metrics.py,,Yes,Yes
11158,unused arg,,No,Yes
11159,unused,,No,Yes
11162,improvement_margin: how much we need to improve to consider the metric,,Yes,Yes
11165,Test a few other cases; unused variables; non-input-tree use of,,,Yes
11167,Move frames next to batch.,,,Yes
11168,We need a model_predict that fills in the random generator if needed.,,Yes,Yes
11170,>1 shards helps with faster parameter distribution on multi-GPU machines,,,Yes
11174,move it to dopamine_connector.py (rename it?),,,Yes
11177,TODO(konradczechowski): move 'simulated' to  batch_env,,,Yes
11180,real env); move it to dopamine_connector.py (rename it?),,Yes,Yes
11185,unused arg,,,Yes
11188,Unused,,,Yes
11192,"\""\""\""Trax backend: all the primitive functions needed.\""\""\""",,Yes,Yes
11193,ignore unused arguments,,Yes,Yes
11194,unused,,No,Yes
11195,Unused.,,Yes,Yes
11197,Chunked case: apply to all chunks selecting as much as needed.,,Yes,Yes
11198,Maybe num_blocks can be automatically calculated?,,Yes,Yes
11199,the last time-step and adding more padding if needed.,,No,Yes
11203,TODO(afrozm): Maybe clip gradients?,,,Yes
11204,"Lightweight convolution naming convention uses \""R_X\"" where X is the variable",,No,Yes
11205,All unused outputs combined_together.,,,Yes
11206,Add the resizing layer if needed.,,Yes,Yes
11208,Chunked case: apply to all chunks selecting as much as needed.,,Yes,Yes
11211,TODO(jonni): Implement for dict if dicts remain important.,,Yes,Yes
11213,move heads to batch dimension. This is needed to reduce number of,,Yes,Yes
11214,In fast decoding; output only contains one element; this is not needed.,,Yes,Yes
11223,TODO(kitaev): workaround for https:\/\/github.com\/google\/jax\/issues\/850,,Yes,Yes
11225,TODO: Vanilla DQN and Rainbow have a lot of common code. Most likely we want,,,Yes
11226,If this will be a problem for maintenance; we could probably override,,,Yes
11227,TODO(karishmamalkan): Fix documentation and refactor name,,Yes,Yes
11228,"Workaround for \""ValueError: prediction values must be from the default",,Yes,Yes
11233,unused arg,,,Yes
11234,The individual dictionaries maybe empty.,,No,Yes
11236,No resizing needed; so let's be on the normal EnvProblem.,,,Yes
11237,Anything more efficient?,,Yes,Yes
11239,Dynamically configurable parameters will be passed to the update function.,,,Yes
11240,TODO(afrozm): Find a better way to do these configurations.,,,Yes
11241,TODO(kitaev): implement attention dropout,,Yes,Yes
11242,second dimension. Do it more efficiently if needed.,,No,Yes
11243,LayerNorm; and whether dropout broadcasting is needed here.,,Yes,Yes
11245,TODO(pkozakowski): Fix.,,Yes,Yes
11248,attention softmax; but normalizing keys is needed so that similarity for,,Yes,Yes
11250,Transpose and reshape back q if needed.,,,Yes
11254,attention softmax; but normalizing keys is needed so that similarity for,,Yes,Yes
11258,TODO(pkozakowski): Find a better way to determine this.,,,Yes
11261,"Workaround for \""ValueError: prediction values must be from the default",,Yes,Yes
11262,It's only needed for a specific purpose in the short term; will go.,,Yes,Yes
11263,attention softmax; but normalizing keys is needed so that similarity for,,Yes,Yes
11264,XXX(kitaev):,,,Yes
11265,indexing; [0] here. But we should make it more explicit in a better API.,,Yes,Yes
11266,TODO(lukaszkaiser): clean this up once layer API stabilizes.,,,Yes
11268,Workaround for: tf.one_hot(,,No,Yes
11269,Unused,,No,Yes
11270,>1 shards helps with faster parameter distribution on multi-GPU machines,,Yes,Yes
11271,unused arg,,No,Yes
11272,these as needed.,,Yes,Yes
11275,"\""\""\""Data generators for English-Czech backtranslation NMT data-sets. ||  || To use this problem you need to provide backtranslated (synthetic) data to || tmp_dir (cs_mono_{en;cs}.txt{0;1;2} - each file of a similar size to the || authentic training data). || You can either translate the monolingual data yourself or you can download || \""csmono\"" data from CzEng2.0 (http:\/\/ufal.mff.cuni.cz\/czeng; registration needed) || which comes with synthetic translations into English using a || backtranslation-trained model; thus the final model will be using || \""iterated\"" backtranslation. ||  || To get the best results out of the Block-Backtranslation || (where blocks of synthetic and authentic training data are concatenated || without shuffling); you should use checkpoint averaging (see t2t-avg-all). || \""\""\""",,Yes,Yes
11276,"\""\""\""Data generators for English-Czech backtranslation NMT data-sets. ||  || To use this problem you need to provide backtranslated (synthetic) data to the tmp_dir || (cs_mono_{en;cs}.txt{0;1;2} - each file of a similar size to the authentic training data). || You can either translate the monolingual data yourself || or you can download \""csmono\"" data from CzEng2.0 (http:\/\/ufal.mff.cuni.cz\/czeng; registration needed); || which comes with synthetic translations into English using a backtranslation-trained model; || thus the final model will be using \""iterated\"" backtranslation. ||  || To get the best results out of the Block-Backtranslation || (where blocks of synthetic and authentic training data are concatenated without shuffling); || you should use checkpoint averaging (see t2t-avg-all). || \""\""\""",,Yes,Yes
11277,consistentIds(art1.id_int; art2.id_int) and  \\ # FIXME don't check internal id consistency for now,,,Yes
11280,# FIXME: !!doesn't update tokens and tokenPositions!!,,Yes,Yes
11281,FIXME not sparse atm; scipy.sparse is crap,,,Yes
11282,HACK: don't scale zero vectors (INF bad?),,,Yes
11283,TODO add,,,Yes
11284,FIXME quadratic better? (% of length of S as a vector),,,Yes
11285,OPT better than direct distMatrix(points; euclid)?,,,Yes
11288,"raise Exception(\""unspecified language (perhaps french?)\"")",,Yes,Yes
11289,"raise Exception(\""unspecified language (perhaps english?)\"")",,Yes,Yes
11290,TODO add,,Yes,Yes
11291,#        TODO: nejaky tokenizer; ktery nahrazuje cislovky atd vyssi sem. kategorii (nejaky dummy token NUM nebo tak),,,Yes
11292,#        TODO: kolik domenove znalosti? pro kazdy jazyk zvlast? promenne -> dummy symbol; cisla -> dummy symbol atd,,Yes,Yes
11294,FIXME k cemu byl vubec zamyslen tag 'suffix' v similar.xml?,,Yes,Yes
11295,FIXME here; at least three copies of the original sparseMat exist in memory!!,,,Yes
11298,FIXME what is this for?,,No,Yes
11302,alter array shape from (n;) to (n; 1); needed for correct broadcasting on the following line,,Yes,Yes
11303,were in the input (bar duplicates); which looks better.,,Yes,Yes
11305,needed for Latent Semantic Indexing,,Yes,Yes
11306,needed for Latent Dirichlet Allocation,,No,Yes
11308,FIXME this assumes WI_WORDS==5; make more flexible,,Yes,Yes
11312,TODO maybe parse out some meta; but currently not needed for anything...,,Yes,Yes
11316,convert to Compressed Sparse Row for efficient row slicing and multiplications,,,Yes
11317,relative difference between document inference iterations needed to stop sooner than VAR_MAX_ITER,,No,Yes
11318,set up temporary vars needed for EM,,,Yes
11321,FIXME TODO,,Yes,Yes
11322,now set the shape properly; using no. columns = highest term index in the corpus + 1,,No,Yes
11323,FIXME  remove,,Yes,Yes
11326,TODO:,,No,Yes
11328,not needed; free up mem,,Yes,Yes
11329,"raise Exception(\""unspecified language (perhaps french?)\"")",,Yes,Yes
11330,"raise Exception(\""unspecified language (perhaps english?)\"")",,,Yes
11334,were in the input (bar duplicates); which looks better.,,Yes,Yes
11336,FIXME TODO,,Yes,Yes
11338,XXX could we install in a subprocess here?,,,Yes
11341,needed because sample data files are located in the same folder,,Yes,Yes
11343,now set the shape properly; using no. columns = highest term index in the corpus + 1,,,Yes
11344,convert to Compressed Sparse Row for efficient row slicing and multiplications,,Yes,Yes
11345,FIXME temporary array unnecessarily big (int32 -> int8),,Yes,Yes
11349,HACK using leftover from enumerate(corpus) above,,No,Yes
11353,not needed; but why not...,,Yes,Yes
11355,FIXME,,Yes,Yes
11356,TODO may this rotation could be done on the sending end; not receiving?,,Yes,Yes
11357,pro: faster (only done once; in one worker; instead of N times in each worker),,,Yes
11361,now `a` is a matrix that contains the new documents as columns,,,Yes
11363,TODO Maybe keep the bases in their natural form (rotations); without,,Yes,Yes
11365,TODO temporarily creates an extra (m;k) dense array! find a way to avoid this!,,,Yes
11367,remove table markup; TODO this is ugly...,,,Yes
11369,expensive; only here for historical reasons; maybe deprecate?,,,Yes
11370,TODO speed up by block svd (process multiple words at once),,No,Yes
11371,broadcasting will promote this to eye(n2) where needed,,No,Yes
11372,TODO should really be 'syr'.. but no wrapper for DSYR in scipy :(,,,Yes
11374,documents = columns of sparse CSC,,Yes,Yes
11376,most common case; quick hack,,Yes,Yes
11378,"\""\""\"" || USAGE: %(program)s ||  ||     Worker (\""slave\"") process used in computing distributed LDA. Run this script \\ || on every node in your cluster. If you wish; you may even run it multiple times \\ || on a single machine; to make better use of multiple cores (just beware that \\ || memory footprint increases accordingly). ||  || Example: python lda_worker.py || \""\""\""",,,Yes
11380,FIXME,,Yes,Yes
11381,"maybe select only a subset of corpus here (to simulate their \""stochastic\"" approach)",,Yes,Yes
11382,documents = columns of sparse CSC,,Yes,Yes
11383,make sure shape[1]=number of docs (needed in len()),,No,Yes
11387,as well as sufficient statistics needed to update lambda.,,,Yes
11388,TODO: what it LoL?,,No,Yes
11390,TODO: do we need this?,,,Yes
11391,TODO: unused,,,Yes
11393,"if self.ends(\""abli\""):      self.r(\""able\"")",,Yes,Yes
11395,the following is needed to make the tokenizer see '[[socialist]]s' as a single word 'socialists',,,Yes
11396,TODO is this really desirable?,,,Yes
11397,TODO maybe ignore tokens with non-latin characters? (no chinese; arabic; russian etc.),,Yes,Yes
11401,print raw_input('holding here to see memory usage ') # todo measure time and memory,,Yes,Yes
11404,"if self.ends(\""abli\""):      self.r(\""able\"")",,,Yes
11406,analysis that is very difficult to do (maybe cannot be done) straight from the dump.,,No,Yes
11407,# todo add the preprocessing module to gensim,,,Yes
11415,FIXME,,Yes,Yes
11421,todo check: the bow query must use the same dictionary,,,Yes
11422,time? TODO compute them on the fly instead?,,,Yes
11423,and pop already-ready chunks from it as needed.,,,Yes
11424,add `+ iteration` to ensure convergence (fake convergence; really! won't work on non-stationary input streams),,,Yes
11426,TODO this should be moved to some library (textcorpus?),,No,Yes
11428,and pop already-ready chunks from it as needed.,,Yes,Yes
11429,'b' for binary; needed on Windows,,,Yes
11430,'b' for binary; needed on Windows,,Yes,Yes
11431,todo check: the bow query must use the same dictionary,,,Yes
11432,better random initialization,,,Yes
11433,FIXME replace with unicode compatible regexp; without the assumption,,Yes,Yes
11434,TODO: if version_info < 2.7?,,,Yes
11435,HACK assume feature ids fit in 32bit integer,,,Yes
11436,FIXME self.numworkers,,Yes,Yes
11437,FIXME self.numworkers,,,Yes
11438,TODO: load back with mmap immediately?,,No,Yes
11440,FIXME yuck; optimize,,Yes,Yes
11442,"TODO mention in docs that the pattern of \""add 1 doc\/query\/add 1 doc\/query\/..\""",,,Yes
11443,FIXME when query a chunk,,,Yes
11445,TODO: load back with mmap immediately?,,No,Yes
11446,FIXME yuck; optimize,,Yes,Yes
11447,XXX the above `dot` is very inefficient if num_topics not full and `u` not in fortran order!!,,Yes,Yes
11449,hack SparseMatrixSim indexes so they're easy to compare,,Yes,Yes
11451,"TODO or maybe clip? are opposite vectors \""similar\"" or \""dissimilar\""?!",,No,Yes
11454,needed because sample data files are located in the same folder,,Yes,Yes
11456,commit ends the session,,No,Yes
11457,TODO: spawn a proper daemon ala http:\/\/code.activestate.com\/recipes\/278731\/ ?,,No,Yes
11458,TODO HACK: exit on first doc without a payload (=assume all docs have payload; or none does),,No,Yes
11459,HACK using leftover from enumerate(corpus) above,,No,Yes
11460,the user better know what he's doing (no normalization; must,,Yes,Yes
11461,"\""\""\"" || This module encapsulates functionality for the online Hierarchical Dirichlet Process algorithm. ||  || It allows both model estimation from a training corpus and inference of topic || distribution on new; unseen documents. ||  || The core estimation code is directly adapted from the `onlinelhdp.py` script || by C. Wang see || **Wang; Paisley; Blei: Online Variational Inference for the Hierarchical Dirichlet || Process; JMLR (2011).** ||  || http:\/\/jmlr.csail.mit.edu\/proceedings\/papers\/v15\/wang11a\/wang11a.pdf ||  || The algorithm: ||  ||   * is **streamed**: training documents come in sequentially; no random access; ||   * runs in **constant memory** w.r.t. the number of documents: size of the ||     training corpus does not affect memory footprint ||  || \""\""\""",,,Yes
11462,...and do the lazy updates on the necessary columns of lambda,,No,Yes
11464,collapse the output at the end. TODO this is accomplished by modifying,,Yes,Yes
11472,TODO load back incl. distributed state? will require re-initialization of worker state,,No,Yes
11473,"\""\""\"" || Module for deep learning. ||  || TODO pick word that doesn't belong: https:\/\/github.com\/dhammack\/Word2VecExample\/blob\/master\/main.py ||  || \""\""\""",,Yes,Yes
11474,FIXME remove debug to save memory,,Yes,Yes
11475,TODO negative sampling here,,Yes,Yes
11479,"\""\""\"" || Corpus in CSV format. TODO: still serializes to SVMLight format; feel free to change this. || \""\""\""",,,Yes
11480,add a little random jitter; to randomize results around the same alpha,,,Yes
11484,randomize weights vector by vector; rather than materializing a huge random matrix in RAM at once,,,Yes
11485,This is a bit ugly; but it avoids running this again.,,,Yes
11488,XXX Do we want list results from the dict members in Py3 too?,,Yes,Yes
11489,work on the entire tree at once; to push as much work into numpy's C routines as possible (performance),,Yes,Yes
11490,needed for python3,,No,Yes
11491,"\""\""\"" || Deep learning via doc2vec's \""skip-gram and CBOW models\""; using either || hierarchical softmax or negative sampling [1]_ [2]_. ||  || The training algorithms were originally ported from the C package https:\/\/code.google.com\/p\/doc2vec\/ || and extended with additional functionality. ||  || **Install Cython with `pip install cython` to use optimized doc2vec training** (70x speedup [3]_). ||  || Initialize a model with e.g.:: ||  || >>> model = Doc2Vec(sentences; size=100; window=5; min_count=5; workers=4) ||  || Persist a model to disk with:: ||  || >>> model.save(fname) || >>> model = Doc2Vec.load(fname)  # you can continue training with the loaded model! ||  || The model can also be instantiated from an existing file on disk in the doc2vec C format:: ||  ||   >>> model = Doc2Vec.load_doc2vec_format('\/tmp\/vectors.txt'; binary=False)  # C text format ||   >>> model = Doc2Vec.load_doc2vec_format('\/tmp\/vectors.bin'; binary=True)  # C binary format ||  || You can perform various syntactic\/semantic NLP word tasks with the model. Some of them || are already built-in:: ||  ||   >>> model.most_similar(positive=['woman'; 'king']; negative=['man']) ||   [('queen'; 0.50882536); ...] ||  ||   >>> model.doesnt_match(\""breakfast cereal dinner lunch\"".split()) ||   'cereal' ||  ||   >>> model.similarity('woman'; 'man') ||   0.73723527 ||  ||   >>> model['computer']  # raw numpy vector of a word ||   array([-0.00449447; -0.00310097;  0.02421786; ...]; dtype=float32) ||  || and so on. ||  || If you're finished training a model (=no more updates; only querying); you can do ||  ||   >>> model.init_sims(replace=True) ||  || to trim unneeded model memory = use (much) less RAM. ||  || .. [1] Tomas Mikolov; Kai Chen; Greg Corrado; and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR; 2013. || .. [2] Tomas Mikolov; Ilya Sutskever; Kai Chen; Greg Corrado; and Jeffrey Dean. Distributed Representations of Words and Phrases and their Compositionality. ||        In Proceedings of NIPS; 2013. || .. [3] Optimizing doc2vec in gensim; http:\/\/radimrehurek.com\/2013\/09\/doc2vec-in-python-part-two-optimizing\/ || \""\""\""",,Yes,Yes
11492,TODO: do we want to add labels as elements to be predicted here? Might be fun to try...,,Yes,Yes
11493,randomize weights vector by vector; rather than materializing a huge random matrix in RAM at once,,Yes,Yes
11494,TODO: use level3 BLAS (=evaluate multiple questions at once); for speed,,Yes,Yes
11495,TODO assumes vocabulary preprocessing uses lowercase; too...,,,Yes
11496,"\""\""\"" || Deep learning via the distributed memory and distributed bag of words models from || [1]_; using either hierarchical softmax or negative sampling [2]_ [3]_. ||  || **Install Cython with `pip install cython` to use optimized doc2vec training** (70x speedup [4]_). ||  || Initialize a model with e.g.:: ||  || >>> model = Doc2Vec(sentences; size=100; window=8; min_count=5; workers=4) ||  || Persist a model to disk with:: ||  || >>> model.save(fname) || >>> model = Doc2Vec.load(fname)  # you can continue training with the loaded model! ||  || The model can also be instantiated from an existing file on disk in the doc2vec C format:: ||  ||   >>> model = Doc2Vec.load_doc2vec_format('\/tmp\/vectors.txt'; binary=False)  # C text format ||   >>> model = Doc2Vec.load_doc2vec_format('\/tmp\/vectors.bin'; binary=True)  # C binary format ||  || You can perform various syntactic\/semantic NLP word tasks with the model. Some of them || are already built-in:: ||  ||   >>> model.most_similar(positive=['woman'; 'king']; negative=['man']) ||   [('queen'; 0.50882536); ...] ||  ||   >>> model.doesnt_match(\""breakfast cereal dinner lunch\"".split()) ||   'cereal' ||  ||   >>> model.similarity('woman'; 'man') ||   0.73723527 ||  ||   >>> model['computer']  # raw numpy vector of a word ||   array([-0.00449447; -0.00310097;  0.02421786; ...]; dtype=float32) ||  || and so on. ||  || If you're finished training a model (=no more updates; only querying); you can do ||  ||   >>> model.init_sims(replace=True) ||  || to trim unneeded model memory = use (much) less RAM. ||  || .. [1] Quoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents. http:\/\/arxiv.org\/pdf\/1405.4053v2.pdf || .. [2] Tomas Mikolov; Kai Chen; Greg Corrado; and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR; 2013. || .. [3] Tomas Mikolov; Ilya Sutskever; Kai Chen; Greg Corrado; and Jeffrey Dean. Distributed Representations of Words and Phrases and their Compositionality. ||        In Proceedings of NIPS; 2013. || .. [4] Optimizing word2vec in gensim; http:\/\/radimrehurek.com\/2013\/09\/word2vec-in-python-part-two-optimizing\/ ||  || \""\""\""",,Yes,Yes
11497,TODO figure out the apropriate size,,,Yes
11502,u'Radim \u0158eh\u016F\u0159ek'; # <- should really be this...;,,Yes,Yes
11503,TODO optimization do not create zero matrix,,Yes,Yes
11504,TODO optimization do not create zero matrix,,,Yes
11508,TODO optimization do not create zero matrix,,,Yes
11510,TODO: auto-tune alpha?,,Yes,Yes
11515,FIXME: doesn't work well,,,Yes
11516,check cached length; calculate if needed,,Yes,Yes
11518,needed because sample data files are located in the same folder,,Yes,Yes
11519,needed because sample data files are located in the same folder,,,Yes
11523,possibly not needed; but harmless,,,Yes
11524,TODO: auto-tune alpha?,,Yes,Yes
11525,TODO: This is redundant,,,Yes
11529,TODO raise ValueError()?,,No,Yes
11531,## TODO: save doclbl fields,,,Yes
11532,needed because sample data files are located in the same folder,,Yes,Yes
11533,TODO: adapt for word_vectors\/word_locks,,,Yes
11538,## FIXME,,No,Yes
11539,loop ended by job count; really done,,Yes,Yes
11542,loop ended by job count; really done,,,Yes
11544,loop ended by job count; really done,,Yes,Yes
11545,could move this import up to where train_* is imported;,,Yes,Yes
11547,If no sentence could be identified; the function ends.,,No,Yes
11548,workaround for python 2.6,,,Yes
11550,better than 'isinstance(val; SaveLoad)' if IPython reloading,,Yes,Yes
11551,loop ended by job count; really done,,,Yes
11553,TODO: this is wasteful (only compute the principal component).,,,Yes
11554,needed because sample data files are located in the same folder,,Yes,Yes
11555,needed because sample data files are located in the same folder,,,Yes
11556,needed because sample data files are located in the same folder,,Yes,Yes
11557,better random initialization,,,Yes
11559,needed because sample data files are located in the same folder,,,Yes
11560,needed because sample data files are located in the same folder,,Yes,Yes
11562,needed because sample data files are located in the same folder,,Yes,Yes
11563,TODO optimize this.,,Yes,Yes
11564,vocab file given; but word is missing -- set count to None (TODO: or raise?),,Yes,Yes
11566,vocab file given; but word is missing -- set count to None (TODO: or raise?),,Yes,Yes
11571,"TODO: remove \""batch\"" input variable when done working on batching.",,,Yes
11572,TODO: remove when not needed anymore.,,,Yes
11573,FIXME: last sentence is ignored.,,,Yes
11574,TODO: consider proper value for this constant.,,No,Yes
11575,TODO: remove when not needed anymore.,,Yes,Yes
11576,vocab file given; but word is missing -- set count to None (TODO: or raise?),,Yes,Yes
11578,TODO: do for cbow also.,,Yes,Yes
11580,TODO: make this code more elegant; it is very messy now.,,Yes,Yes
11583,"TODO: remove \""batch\"" input variable when done working on batching.",,Yes,Yes
11584,TODO: do for cbow also.,,Yes,Yes
11587,TODO: use for instead.,,No,Yes
11588,TODO: use for instead.,,,Yes
11591,loop ended by job count; really done,,,Yes
11592,"FIXME: remove \""batch\"" input variable when done working on batching.",,Yes,Yes
11593,loop ended by job count; really done,,,Yes
11594,could move this import up to where train_* is imported;,,,Yes
11595,"FIXME: remove \""batch\"" and \""const_alpha\"" input variable when done working on batching.",,,Yes
11596,TODO: remove; just for debugging.,,,Yes
11598,loop ended by job count; really done,,,Yes
11599,could move this import up to where train_* is imported;,,,Yes
11600,could move this import up to where train_* is imported;,,,Yes
11601,"skip \""doc\"" and \""source\"" columns",,No,Yes
11602,needed because sample data files are located in the same folder,,,Yes
11603,could move this import up to where train_* is imported;,,Yes,Yes
11604,"FIXME: remove \""batch\"" and \""const_alpha\"" input variable when done working on batching.",,,Yes
11606,loop ended by job count; really done,,,Yes
11607,"skip \""doc\"" and \""source\"" columns",,,Yes
11609,needed because sample data files are located in the same folder,,Yes,Yes
11610,needed because sample data files are located in the same folder,,,Yes
11611,NOTE: this could be implemented for other similarities as well (i.e.,,No,Yes
11612,FIXME: Fails on osx and win,,No,Yes
11615,FIXME : Change window size to 110 finally.,,,Yes
11617,needed because sample data files are located in the same folder,,Yes,Yes
11619,TODO: bound is initialized to 0,,Yes,Yes
11621,TODO: apply lambda function,,Yes,Yes
11622,TODO: check why there's an IF,,,Yes
11623,needed because sample data files are located in the same folder,,Yes,Yes
11624,Cannot calculate eigenvectors if number of unique words in text < 3. Warns user to add more text. The function ends.,,,Yes
11626,TODO: check whether the Fortran-order shenanigans still make sense. In the original,,,Yes
11627,code (~2010); this made a BIG difference for numpy BLAS implementations; perhaps now the wrappers,,,Yes
11628,are smarter and this is no longer needed?,,Yes,Yes
11629,This is a hack to work around a bug in numpy; where a FORTRAN-order array,,,Yes
11630,#TODO: sporadic failure to be investigated,,,Yes
11632,needed because sample data files are located in the same folder,,Yes,Yes
11640,TODO: it is not possible to add new authors to an existing document (all input documents are treated,,,Yes
11642,"rho is the \""speed\"" of updating; TODO try other fncs",,Yes,Yes
11644,TODO: treat this in a more general way; similar to how it is done with word_score.,,Yes,Yes
11646,TODO:,,,Yes
11650,"\""\""\"" || Python wrapper around word representation learning from FastText; a library for efficient learning || of word representations and sentence classification [1]. ||  || This module allows training a word embedding from a training corpus with the additional ability || to obtain word vectors for out-of-vocabulary words; using the fastText C implementation. ||  || The wrapped model can NOT be updated with new documents for online training -- use gensim's || `Word2Vec` for that. ||  || Example: ||  || >>> from gensim.models.wrappers import FastText || >>> model = fasttext.FastText.train('\/Users\/kofola\/fastText\/fasttext'; corpus_file='text8') || >>> print model['forests']  # prints vector for given out-of-vocabulary word ||  || .. [1] https:\/\/github.com\/facebookresearch\/fastText#enriching-word-vectors-with-subword-information ||  || \""\""\""",,Yes,Yes
11653,better approximation,,No,Yes
11657,better approximation,,No,Yes
11658,needed because sample data files are located in the same folder,,Yes,Yes
11659,needed because sample data files are located in the same folder,,Yes,Yes
11662,Warns user to add more text. The function ends.,,No,Yes
11663,If couldn't get important docs; the algorithm ends.,,Yes,Yes
11664,needed because sample data files are located in the same folder,,,Yes
11665,needed because sample data files are located in the same folder,,,Yes
11668,TODO: cleanup to reduce repeated code in this class;,,Yes,Yes
11676,"\""\""\"" || Warnings || -------- || .. deprecated:: 3.3.0 ||    Use :mod:`gensim.models.doc2vec` instead. ||  ||  ||  || Deep learning via the distributed memory and distributed bag of words models from || [1]_; using either hierarchical softmax or negative sampling [2]_ [3]_. See [#tutorial]_ ||  || **Make sure you have a C compiler before installing gensim; to use optimized (compiled) || doc2vec training** (70x speedup [blog]_). ||  || Initialize a model with e.g.:: ||  || >>> model = Doc2Vec(documents; size=100; window=8; min_count=5; workers=4) ||  || Persist a model to disk with:: ||  || >>> model.save(fname) || >>> model = Doc2Vec.load(fname)  # you can continue training with the loaded model! ||  || If you're finished training a model (=no more updates; only querying); you can do ||  ||   >>> model.delete_temporary_training_data(keep_doctags_vectors=True; keep_inference=True): ||  || to trim unneeded model memory = use (much) less RAM. ||  ||  ||  || .. [1] Quoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents. ||        http:\/\/arxiv.org\/pdf\/1405.4053v2.pdf || .. [2] Tomas Mikolov; Kai Chen; Greg Corrado; and Jeffrey Dean. ||        Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR; 2013. || .. [3] Tomas Mikolov; Ilya Sutskever; Kai Chen; Greg Corrado; and Jeffrey Dean. ||        Distributed Representations of Words and Phrases and their Compositionality. In Proceedings of NIPS; 2013. || .. [blog] Optimizing word2vec in gensim; http:\/\/radimrehurek.com\/2013\/09\/word2vec-in-python-part-two-optimizing\/ ||  || .. [#tutorial] Doc2vec in gensim tutorial; ||                https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/docs\/notebooks\/doc2vec-lee.ipynb ||  ||  ||  || \""\""\""",,,Yes
11679,vocab file given; but word is missing -- set count to None (TODO: or raise?),,Yes,Yes
11680,TODO: use level3 BLAS (=evaluate multiple questions at once); for speed,,,Yes
11681,better than 'isinstance(val; SaveLoad)' if IPython reloading,,Yes,Yes
11682,'b' for binary; needed on Windows,,Yes,Yes
11686,TOCONSIDER: maybe mismatched vectors still useful enough to merge (truncating\/padding)?,,,Yes
11689,"\""\""\"" || Warnings || -------- || .. deprecated:: 3.2.0 ||    Use :mod:`gensim.models.fasttext` instead. ||  ||  ||  || Python wrapper around word representation learning from FastText; a library for efficient learning || of word representations and sentence classification [1]. ||  || This module allows training a word embedding from a training corpus with the additional ability || to obtain word vectors for out-of-vocabulary words; using the fastText C implementation. ||  || The wrapped model can NOT be updated with new documents for online training -- use gensim's || `Word2Vec` for that. ||  || Example: ||  || >>> from gensim.models.wrappers import FastText || >>> model = FastText.train('\/Users\/kofola\/fastText\/fasttext'; corpus_file='text8') || >>> print model['forests']  # prints vector for given out-of-vocabulary word ||  || .. [1] https:\/\/github.com\/facebookresearch\/fastText#enriching-word-vectors-with-subword-information ||  ||  ||  || \""\""\""",,No,Yes
11691,Traverse all columns.,,,Yes
11694,TODO: implement 3CosMul and set-based methods for solving analogies,,No,Yes
11695,load really old model,,,Yes
11697,"\""\""\""This module implements functionality related to the `Term Frequency - Inverse Document Frequency || <https:\/\/en.wikipedia.org\/wiki\/Tf%E2%80%93idf>` vector space bag-of-words models. ||  || For a more in-depth exposition of TF-IDF and its various SMART variants (normalization; weighting schemes); || see the blog post at https:\/\/rare-technologies.com\/pivoted-document-length-normalisation\/ ||  || \""\""\""",,No,Yes
11698,## TODO use smart_open again when https:\/\/github.com\/RaRe-Technologies\/smart_open\/issues\/207 will be fixed,,Yes,Yes
11699,TODO use smart_open again when https:\/\/github.com\/RaRe-Technologies\/smart_open\/issues\/207 will be fixed,,,Yes
11701,wait for visdom server startup (any better way?),,Yes,Yes
11703,variable; so we reinitialize it here; if needed.,,Yes,Yes
11704,This is a workaround for a problem with temporary files on AppVeyor:,,No,Yes
11706,how many columns are processed between progress messages,,Yes,Yes
11707,"\""\""\""Holds data loaded from the Facebook binary. ||  || Fields || ------ || dim : int ||     The dimensionality of the vectors. || ws : int ||     The window size. || epoch : int ||     The number of training epochs. || neg : int ||     If non-zero; indicates that the model uses negative sampling. || loss : int ||     If equal to 1; indicates that the model uses hierarchical sampling. || model : int ||     If equal to 2; indicates that the model uses skip-grams. || bucket : int ||     The number of buckets. || min_count : int ||     The threshold below which the model ignores terms. || t : float ||     The sample threshold. || minn : int ||     The minimum ngram length. || maxn : int ||     The maximum ngram length. || raw_vocab : collections.OrderedDict ||     A map from words (str) to their frequency (int).  The order in the dict ||     corresponds to the order of the words in the Facebook binary. || nwords : int ||     The number of words. || vocab_size : int ||     The size of the vocabulary. || vectors_ngrams : numpy.array ||     This is a matrix that contains vectors learned by the model. ||     Each row corresponds to a vector. ||     The number of vectors is equal to the number of words plus the number of buckets. ||     The number of columns is equal to the vector dimensionality. || hidden_output : numpy.array ||     This is a matrix that contains the shallow neural network output. ||     This array has the same dimensions as vectors_ngrams. ||     May be None - in that case; it is impossible to continue training the model. || \""\""\""",,,Yes
11712,workaround when it's necessary; because np.fromfile is heavily optimized,,Yes,Yes
11713,and very efficient (when it works).,,No,Yes
11714,"\""\""\"" || Intro || ----- ||  || This module contains integration Nmslib with :class:`~gensim.models.word2vec.Word2Vec`; || :class:`~gensim.models.doc2vec.Doc2Vec`; :class:`~gensim.models.fasttext.FastText` and || :class:`~gensim.models.keyedvectors.KeyedVectors`. || To use nmslib; instantiate a :class:`~gensim.similarities.nmslib.NmslibIndexer` class || and pass the instance as the indexer parameter to your model's most_similar method || (e.g. :py:func:`~gensim.models.doc2vec.most_similar`). ||  || Example usage || ------------- ||  || .. sourcecode:: pycon ||  ||     >>> from gensim.similarities.nmslib import NmslibIndexer ||     >>> from gensim.models import Word2Vec ||     >>> ||     >>> sentences = [['cute'; 'cat'; 'say'; 'meow']; ['cute'; 'dog'; 'say'; 'woof']] ||     >>> model = Word2Vec(sentences; min_count=1; seed=1) ||     >>> ||     >>> indexer = NmslibIndexer(model) ||     >>> model.most_similar(\""cat\""; topn=2; indexer=indexer) ||     [('cat'; 1.0); ('meow'; 0.5595494508743286)] ||  || Load and save example || --------------------- ||  || .. sourcecode:: pycon ||  ||     >>> from gensim.similarities.nmslib import NmslibIndexer ||     >>> from gensim.models import Word2Vec ||     >>> from tempfile import mkstemp ||     >>> ||     >>> sentences = [['cute'; 'cat'; 'say'; 'meow']; ['cute'; 'dog'; 'say'; 'woof']] ||     >>> model = Word2Vec(sentences; min_count=1; seed=1; iter=10) ||     >>> ||     >>> indexer = NmslibIndexer(model) ||     >>> _; temp_fn = mkstemp() ||     >>> indexer.save(temp_fn) ||     >>> ||     >>> new_indexer = NmslibIndexer.load(temp_fn) ||     >>> model.most_similar(\""cat\""; topn=2; indexer=new_indexer) ||     [('cat'; 1.0); ('meow'; 0.5595494508743286)] ||  || What is Nmslib || ------------- ||  || Non-Metric Space Library (NMSLIB) is an efficient cross-platform similarity search library and a toolkit || for evaluation of similarity search methods. The core-library does not have any third-party dependencies. || More information about Nmslib: `github repository <https:\/\/github.com\/nmslib\/nmslib>`_. ||  || Why use Nmslib? || ------------- ||  || The current implementation for finding k nearest neighbors in a vector space in gensim has linear complexity || via brute force in the number of indexed documents; although with extremely low constant factors. || The retrieved results are exact; which is an overkill in many applications: || approximate results retrieved in sub-linear time may be enough. || Nmslib can find approximate nearest neighbors much faster. || Compared to annoy; nmslib has more parameters to control the build and query time and accuracy. || Nmslib can achieve faster and more accurate nearest neighbors search than annoy. || \""\""\""",,,Yes
11716,In practice; corpora may be very large; so loading them into memory may be impossible.,,Yes,Yes
11717,Your way of processing the documents will likely vary; here; I only split on whitespace,,Yes,Yes
11718,another way of doing it: print one document at a time; making use of the streaming interface,,Yes,Yes
11719,Gensim also contains `efficient utility functions <http:\/\/radimrehurek.com\/gensim\/matutils.html>`_,,,Yes
11722,which corresponds better to our intuition of,,,Yes
11723,(hopefully) more semantic way.,,Yes,Yes
11726,"r\""\""\"" || How to Compare LDA Models || ========================= ||  || Demonstrates how you can compare a topic model with itself or other models. ||  || \""\""\""",,,Yes
11728,If you compare a model with itself; you want to see as many red elements as possible (except diagonal). With this picture; you can look at the not very red elements and understand which topics in the model are very similar and why (you can read annotation if you move your pointer to cell).,,Yes,Yes
11729,"r\""\""\"" || How to Author Gensim Documentation || ================================== ||  || Some tips of how to author documentation for ``gensim``. || \""\""\""",,,Yes
11730,Unfortunately; not all of this functionality is documented **well**; and some of it is not documented at all.,,,Yes
11734,This will reduce the risk of your documentation becoming obsolete because required data is no longer available.,,Yes,Yes
11736,*fname.d*. Both files are needed to correctly restore all attributes. Before,,Yes,Yes
11739,For a nice review of the mathematical differences between Hellinger and KL;,,Yes,Yes
11747,really no easy answer for this; it will depend on both your data and your,,,Yes
11749,short documents with length of around 500 had very good score hence the bias,,Yes,Yes
11750,larger ones; and then we will review the performance of the summarizer in,,Yes,Yes
11751,This algorithm was later improved upon by `Barrios et al.,,,Yes
11752,"between documents; in other words the most efficient way to \""move\"" the",,Yes,Yes
11755,.. Note:: Feel free to skip these review sections if you're already familiar with the models.,,,Yes
11756,This corpus is small enough to fit entirely in memory; but we'll implement a,,No,Yes
11757,Bigger size values require more training data; but can lead to better (more,,,Yes
11758,There\u2019s a little extra memory needed for storing the vocabulary tree (100;000 words would take a few megabytes); but unless your words are extremely loooong strings; memory footprint will be dominated by the three matrices above.,,Yes,Yes
11759,``Word2Vec`` training is an unsupervised task; there\u2019s no good way to,,,Yes
11760,In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.,,,Yes
11761,work well in your application; or vice versa. It\u2019s always best to evaluate,,,Yes
11762,"r\""\""\"" || Core Concepts || ============= ||  || This tutorial introduces Documents; Corpora; Vectors and Models: the basic concepts and terms needed to understand and use gensim. || \""\""\""",,Yes,Yes
11765,another way of doing it: print one document at a time; making use of the streaming interface,,,Yes
11766,Gensim also contains `efficient utility functions <http:\/\/radimrehurek.com\/gensim\/matutils.html>`_,,,Yes
11767,we covered what it means to create a corpus in the Vector Space Model and how,,No,Yes
11768,them received quite high similarity scores (no. 2 is actually the most similar!);,,,Yes
11769,which corresponds better to our intuition of,,,Yes
11770,(hopefully) more semantic way.,,,Yes
11771,`gensim` uses a novel online incremental streamed distributed training algorithm (quite a mouthful!);,,,Yes
11772,reduce vector space dimensionality. This is a very efficient (both memory- and,,Yes,Yes
11774,If you're running via a Jupyter notebook; then you'll get a nice interactive Plotly heatmap.,,Yes,Yes
11775,If you compare a model with itself; you want to see as many red elements as possible (except diagonal). With this picture; you can look at the not very red elements and understand which topics in the model are very similar and why (you can read annotation if you move your pointer to cell).,,,Yes
11776,"r\""\""\"" || How to Author Gensim Documentation || ================================== ||  || Some tips of how to author documentation for ``gensim``. || \""\""\""",,,Yes
11777,Unfortunately; not all of this functionality is documented **well**; and some of it is not documented at all.,,Yes,Yes
11779,When you make a PR with new functionality; please consider authoring each kind of documentation.,,Yes,Yes
11780,Once your script.py works; put it in a suitable subdirectory.,,Yes,Yes
11781,This will reduce the risk of your documentation becoming obsolete because required data is no longer available.,,Yes,Yes
11783,*fname.d*. Both files are needed to correctly restore all attributes. Before,,,Yes
11784,terms - but as bank in this context is likely to belong to the finance topic;,,Yes,Yes
11785,and is probably the most 'famous' distance measure in fields like Information,,Yes,Yes
11786,For a nice review of the mathematical differences between Hellinger and KL;,,Yes,Yes
11790,According to a detailed comparison of Word2Vec and FastText in `this notebook <https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/docs\/notebooks\/Word2Vec_FastText_Comparison.ipynb>`__; fastText does significantly better on syntactic tasks as compared to the original Word2Vec; especially when the size of the training corpus is small. Word2Vec slightly outperforms FastText on semantic tasks though. The differences grow smaller as the size of training corpus increases.,,Yes,Yes
11791,Syntactically similar words generally have high similarity in fastText models; since a large number of the component char-ngrams will be the same. As a result; fastText generally does better at syntactic tasks than Word2Vec. A detailed comparison is provided `here <Word2Vec_FastText_Comparison.ipynb>`_.,,No,Yes
11797,larger ones; and then we will review the performance of the summarizer in,,Yes,Yes
11800,If you use Gensim's WMD functionality; please consider citing [1]; [2] and [3].,,Yes,Yes
11801,4. Thomas Mikolov et al. *Efficient Estimation of Word Representations in Vector Space*\\ ; 2013.,,Yes,Yes
11802,.. Note:: Feel free to skip these review sections if you're already familiar with the models.,,,Yes
11803,This corpus is small enough to fit entirely in memory; but we'll implement a,,No,Yes
11804,Bigger size values require more training data; but can lead to better (more,,,Yes
11805,There\u2019s a little extra memory needed for storing the vocabulary tree (100;000 words would take a few megabytes); but unless your words are extremely loooong strings; memory footprint will be dominated by the three matrices above.,,Yes,Yes
11807,In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.,,,Yes
11808,work well in your application; or vice versa. It\u2019s always best to evaluate,,,Yes
11811,fasttext tool creates both *vec and *bin files; so we have to remove both; even thought *vec is unused,,Yes,Yes
11812,the following is needed to be able to add numpy's include dirs... without,,Yes,Yes
11813,TODO: Remove the pin once we drop py2.7 from gensim too.,,,Yes
11814,the following is needed to be able to add numpy's include dirs... without,,,Yes
11815,TODO: Remove the pin once we drop py2.7 from gensim too.,,,Yes
11816,HACK: Installing tensorflow causes a segfault in Travis on py3.6. Other Pythons work \u2013 a mystery.,,,Yes
11818,FIXME: evaluate if precaching even necessary; compared to recalculating as needed,,,Yes
11819,TODO? warn if not matching extras already present?,,,Yes
11821,TOCONSIDER: maybe mismatched vectors still useful enough to merge (truncating\/padding)?,,,Yes
11822,no longer needed,,Yes,Yes
11823,FIXME(someday): make this faking optional; include more realistic (Zipf-based) fake numbers,,Yes,Yes
11827,HACK: Installing tensorflow causes a segfault in Travis on py3.6. Other Pythons work \u2013 a mystery.,,Yes,Yes
11828,dtype; which uses too much memory!,,Yes,Yes
11829,similar and why (you can read annotation if you move your pointer to cell).,,Yes,Yes
11831,FIXME docvecs now = ? What's the replacement for docvecs.count; index_to_doctag; etc?,,,Yes
11834,"Choose a distance function that matches your upstream task better: what kind of \""similarity\"" is",,,Yes
11838,XXX: Why do we care about *all* phrase tokens? Why not just score the start+end bigram?,,Yes,Yes
11839,XXX: get rid of this: not used much; too complex and brittle.,,,Yes
11840,Unfortunately; the GitHub API doesn't link PRs to issues that they fix;,,,Yes
11841,If you use Gensim's SCM functionality; please consider citing [1]; [2] and [3].,,Yes,Yes
11843,If you use Gensim's SCM functionality; please consider citing [1]; [2] and [3].,,Yes,Yes
11844,4. Tom\u00E1\u0161 Mikolov et al. Efficient Estimation of Word Representations in Vector Space; 2013.,,Yes,Yes
11846,TODO: Fix this hack!,,,Yes
11847,"\""\""\""Sphinx doctest is just too hard. Manually paste doctest examples here\""\""\""",,Yes,Yes
11849,TODO: Clean this up,,,Yes
11851,TODO: This is currently difficult --- infix interferes here.,,Yes,Yes
11852,Arbitrary attributes. Currently unused.,,Yes,Yes
11854,TODO: ImportError: No module named _doc_examples,,Yes,Yes
11858,ugly hack to find out whether something other,,,Yes
11861,FIXME supply spacy with an old-style data dir,,Yes,Yes
11862,TODO: retrieve version,,,Yes
11863,"\""\""\"" cythonize ||  || Cythonize pyx files into C files as needed. ||  || Usage: cythonize [root_dir] ||  || Default [root_dir] is 'spacy'. ||  || Checks pyx files to see if they have been changed relative to their || corresponding C files.  If they have; then runs cython on these files to || recreate the C files. ||  || The script thinks that the pyx files have changed relative to the C files || by comparing hashes stored in a database file. ||  || Simple script to invoke Cython (and Tempita) on all .pyx (.pyx.in) || files; while waiting for a proper build system. Uses file hashes to || figure out if rebuild is needed. ||  || For now; this script should be run by developers when changing Cython files || only; and the resulting C files checked in; so that end-users (and Python-only || developers) do not get the Cython\/Tempita dependencies. ||  || Originally written by Dag Sverre Seljebotn; and copied here from: ||  || https:\/\/raw.github.com\/dagss\/private-scipy-refactor\/cythonize\/cythonize.py ||  || Note: this script does not check any of the dependent C libraries; it only || operates on the Cython .pyx files. || \""\""\""",,,Yes
11865,FIXME supply spacy with an old-style data dir,,Yes,Yes
11866,It'd probably be better for `word.subtree` to return a `Span` object instead,,Yes,Yes
11868,the head relation upwards always ends at the root node,,No,Yes
11869,TODO: This points to a deeper issue with the tokenizer: it doesn't re-enter,,Yes,Yes
11871,values = numpy.ndarray(shape=(len(doc);len(columns)); dtype='int32'),,No,Yes
11876,- dependency labels shouldn't be empty,,,Yes
11878,TODO: Is this correct? See discussion in Issue #435.,,,Yes
11879,TODO -- fix this,,,Yes
11880,'''Test the possibly temporary workaround of flushing the stringstore of OOV words.''',,No,Yes
11882,TODO Make tokenizer excpetions for Dutch,,,Yes
11884,This is very messy; but it's the minimal working fix to Issue #639.,,,Yes
11885,TODO insert TAG_MAP for Dutch,,No,Yes
11886,Make a special-case hack for loading the GloVe vectors; to support,,Yes,Yes
11888,This is very messy; but it's the minimal working fix to Issue #639.,,,Yes
11890,TODO: Better error,,,Yes
11891,"\""\""\""Test the possibly temporary workaround of flushing the stringstore of OOV words.\""\""\""",,,Yes
11892,TODO: brackets; is_ascii; is_upper; is_lower; is_title,,Yes,Yes
11893,"Note: \""chromosomes\"" worked previous the bug fix",,,Yes
11894,Add workaround for Python 2 on Windows (see issue #909),,No,Yes
11895,TODO: Word vectors?,,,Yes
11903,so we can save the factor k. This also gives a nice CPU\/GPU division:,,Yes,Yes
11909,TODO: Fix when saving\/loading is fixed.,,Yes,Yes
11913,Workaround: these aren't actually context managers atm.,,,Yes
11914,TODO: This isn't complete yet -- need to map from IOB to,,Yes,Yes
11916,TODO: Fix!,,Yes,Yes
11917,if tagging was done properly; pos tags shouldn't be empty,,Yes,Yes
11919,if ner was done properly; ent_iob shouldn't be empty,,Yes,Yes
11922,if ner was done properly; ent_iob shouldn't be empty,,Yes,Yes
11923,TODO: This is missing a lot of modules. Does it matter?,,,Yes
11925,TODO: if the text has been tokenized; this info is already available,,,Yes
11926,XXX ADJ if alone; AUX otherwise,,Yes,Yes
11929,XXX VERB if alone; AUX otherwise,,,Yes
11934,TODO Make concatenate support lists,,No,Yes
11937,TODO -- fix this,,Yes,Yes
11938,so even if the list of companies is long; it's very efficient,,,Yes
11943,TODO -- fix this,,Yes,Yes
11944,It'd probably be better for `word.subtree` to return a `Span` object,,,Yes
11945,for no relation; we simply chose an arbitrary dependency label; e.g. '-',,,Yes
11946,TODO -- fix this,,Yes,Yes
11947,TODO -- fix this,,,Yes
11951,This seems to be a dict ordering bug somewhere. Only failing on some platforms,,Yes,Yes
11953,TODO: This needs to be zero-width :(.,,Yes,Yes
11955,TODO: Proper ERROR.,,,Yes
11956,TODO: maybe refactor this,,,Yes
11962,Todo: A better name for this class,,No,Yes
11964,Todo: A better name for this class,,No,Yes
11965,Todo: A better name for this class,,,Yes
11967,Todo: add fit generator function,,,Yes
11968,build model structure in sequent way,,Yes,Yes
11969,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
11974,build model structure in sequent way,,,Yes
11977,fix random seed for reproducibility,,No,Yes
11981,TODO: Check register_forward_hook,,,Yes
11983,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
11985,TODO support cpu backend,,Yes,Yes
11989,TODO add plot curve,,,Yes
11990,FIXME this is a bug somewhere not in the code,,No,Yes
11991,TODO norm layer; instance norm?,,Yes,Yes
11992,TODO: change to [:2] at v1.0,,Yes,Yes
11993,TODO: verify this works as expected,,Yes,Yes
11994,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
11995,`kw` catches `env=None` needed for newer sphinx while maintaining,,Yes,Yes
11996,TODO; figure out why nccl all_reduce doesn't work for gradcheck,,Yes,Yes
11997,TODO check faster?,,,Yes
11998,"\""\""\"" || class SegmentationLosses(Module): ||     def __init__(self; aux; aux_weight=0.2; weight=None; size_average=True; ignore_index=-1): ||         super(SegmentationLosses; self).__init__() ||         self.aux = aux ||         self.aux_weight = aux_weight ||         # Somehow the size averge is not handled correctly on multi-gpu; so we average by ourself. ||         self.nll_loss = NLLLoss(weight; ignore_index=ignore_index; reduce=True) ||  ||     def _forward_each(self; inputs; targets): ||         return self.nll_loss(F.log_softmax(inputs; dim=1); targets) ||  ||     def forward(self; *inputs): ||         if not self.aux: ||             return self._forward_each(*inputs) ||         pred1; pred2; target = tuple(inputs) ||         loss1 = self._forward_each(pred1; target) ||         loss2 = self._forward_each(pred2; target) ||         return loss1 + self.aux_weight * loss2 || \""\""\""",,,Yes
11999,TODO currently torch.eq is not working as expected; change back when it's fixed,,,Yes
12000,move images to proper subfolders,,,Yes
12001,manually reflect the tform to undo the reflection done on xyR,,Yes,Yes
12002,Figure out if trans1 or trans2 is better,,Yes,Yes
12003,adjust LR for each training stage; you can also choose to adjust LR manually (with slight modification) once plaueau observed,,,Yes
12004,todo: complete this out (I bit off a bit more than I could chew with this function. Will probably take a bunch of basian stuff,,,Yes
12006,logging ends,,No,Yes
12007,logging ends,,No,Yes
12010,TODO: Checkpoint save should be arbitrary and checkpoint predict can be broken up into utility functions?,,No,Yes
12011,TODO: Consider saving as well a predict lambda,,,Yes
12017,TODO: Just use Pandas#DataFrame,,No,Yes
12019,TODO: Investigate data. Look into preprocessing.,,,Yes
12020,"\""\""\"" || We implement additional hyperparameter optimization methods not present in || https:\/\/scikit-optimize.github.io\/. ||  || Gist: https:\/\/gist.github.com\/Deepblue129\/2c5fae9daf0529ed589018c6353c9f7b || \""\""\""",,No,Yes
12021,TODO: Compute the tqdm total,,No,Yes
12023,TODO: Use `sklearn.metrics` for a `confusion_matrix` implemented with ignore_index,,Yes,Yes
12024,TODO: Use `sklearn.metrics` for a `recall` implemented with ignore_index,,,Yes
12026,TODO: Use `sklearn.metrics` for a `f1` implemented with ignore_index,,,Yes
12027,TODO: Implement Accuracy Top N for classification,,,Yes
12028,TODO: Implement perplexity,,Yes,Yes
12029,TODO: Why require decoding? The original source can just be sent? Maybe overall the thing is incorreect.,,,Yes
12030,TODO: Include mask on padding_indx?,,Yes,Yes
12031,TODO: https:\/\/arxiv.org\/pdf\/1707.06799v1.pdf,,Yes,Yes
12033,TODO: Add a vocabulary filter depending on the current output,,Yes,Yes
12035,TODO: Think about should the encoder during decoding include <eos> or not?,,Yes,Yes
12036,TODO: Add reserved tokens to SubwordTextTokenizer like Google did to ensure correct tokenization,,,Yes
12037,"NOTE: This algorithm is greedy; it won't necessarily produce the \""best\""",,,Yes
12038,TODO: If the folder is empty then delete it after the execution finishes,,Yes,Yes
12039,TODO: Consider having a random loss function,,Yes,Yes
12041,TODO: Add corpus to random args,,,Yes
12042,TODO: implement abs on CharTensor,,,Yes
12043,TODO: Support context manager interface,,Yes,Yes
12044,If you need it; manually apply your callable in a lambda instead.,,,Yes
12046,TODO: Add corpus to random args,,No,Yes
12050,-- Options for todo extension ----------------------------------------------,,Yes,Yes
12051,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
12052,TODO: MOCK urlretrieve and just ping the server...,,Yes,Yes
12053,TODO: Write or have a file in dest to be used,,Yes,Yes
12054,TODO: Remove experiment directory created...,,,Yes
12056,TODO: Remove Optimizer as it is not NLP do a PytorchUtils library,,No,Yes
12058,TODO: Credit IBM for this snipit,,,Yes
12059,TODO: Credit torchtext for this snippet,,,Yes
12060,`kw` catches `env=None` needed for newer sphinx while maintaining,,,Yes
12061,TODO: Already tokenized text should work...,,Yes,Yes
12062,TODO: Fix failure case if internet does not work,,Yes,Yes
12064,TODO: Add back padding,,No,Yes
12066,TODO: Fix failure case if internet does not work,,,Yes
12068,TODO: Implement rogue metric,,Yes,Yes
12069,Our chunks are similar to the columns in this PyTorch example:,,No,Yes
12070,TODO: Fix failure case if internet does not work,,,Yes
12071,"\""Using the Output Embedding to Improve Language Models\"" (Press & Wolf 2016)",,No,Yes
12072,TODO: Use SRU \/ CNN Encoder \/ Embeddings etc...,,,Yes
12074,TODO: Figure out a good abstraction for evaluation.,,,Yes
12080,TODO: design the structure of the output,,Yes,Yes
12093,TODO: design the structure of the output,,Yes,Yes
12096,TODO: check number of estimatoes and scores match,,No,Yes
12098,TODO: fix output differences,,,Yes
12105,TODO: verify the values,,Yes,Yes
12106,XXX: not handling dictionaries,,Yes,Yes
12109,TODO: implement a faster solution,,,Yes
12112,TODO: place holder only,,,Yes
12114,TODO: placeholder; do not use,,Yes,Yes
12115,TODO: turn off performance check before a better data generation,,Yes,Yes
12116,"\""\""\""Local Outlier Factor (LOF). Implemented on scikit-learn library. || \""\""\""",,Yes,Yes
12120,TODO: sklearn examples are too small to form valid,,No,Yes
12121,TODO: turn off estimator check due to output warnings.,,Yes,Yes
12122,Standardize data for better performance,,Yes,Yes
12124,TODO: add version information here,,Yes,Yes
12125,TODO: add neural networks and update output precision (=4),,,Yes
12131,TODO: sklearn check does not support Numba optimization,,Yes,Yes
12136,TODO: add neural networks; LOCI; SOS,,Yes,Yes
12141,TODO: GAN may yield unstable results; turning performance off check,,No,Yes
12143,TODO: detector score combination through BFS should be implemented,,,Yes
12144,''' || TO-DO by Yue Zhao || ''',,No,Yes
12145,TODO: check performance is turned off due to poor performance.,,Yes,Yes
12148,TO-DO: 'mad': Median Absolute Deviation to be added,,Yes,Yes
12150,TODO: look into how to speed up the algorithm with numba,,,Yes
12151,TODO: look into how to speed up the algorithm with numba,,Yes,Yes
12156,TODO: code cleanup,,No,Yes
12161,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
12163,TODO comments,,,Yes
12164,todo,,No,Yes
12166,top left -- no changes needed; just use jitter,,Yes,Yes
12170,TODO: Adding 3D landmark support,,No,Yes
12171,TODO: ugly,,,Yes
12172,batch size; needed for reshaping later,,,Yes
12173,minimum is set to 12; as at least 3 color channels are needed for correct upsampling,,Yes,Yes
12174,TODO: support batch size > 1.,,No,Yes
12175,Move the origin of transformation.,,,Yes
12177,Move the origin of transformation.,,Yes,Yes
12179,TODO: use persistent CD-k,,,Yes
12181,impurity gain is difference in loss before vs. after split,,,Yes
12182,TODO: revise this,,Yes,Yes
12184,TODO: this assumes all actions are available in every state,,Yes,Yes
12187,TODO: this assumes all actions are available in every state,,Yes,Yes
12188,TODO: what's a good threshold here?,,No,Yes
12189,0 = move left; 1 = move right,,Yes,Yes
12191,XXX: instead of calculating the tf NCE on the entire batch; we,,Yes,Yes
12192,calculate it per-example and then sum. this is really lame and should,,Yes,Yes
12195,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
12196,TODO: should be i+j?,,Yes,Yes
12198,As a workaround; we set d to 1 and add one to n.,,,Yes
12201,TODO: change to DL,,Yes,Yes
12203,TODO: Write a version of this that returns a dict,,No,Yes
12206,TODO: add attachment type by extension,,No,Yes
12207,TODO stickers not yet supported by Messenger :(,,,Yes
12208,TODO: add attachment type by extension,,No,Yes
12209,TODO telegram attachments,,Yes,Yes
12211,FIXME send without dummy message,,Yes,Yes
12212,TODO support telegram location; keyboard <> inline keyboard,,,Yes
12213,TODO stickers not yet supported by Messenger :(,,No,Yes
12215,todo parse stuff,,,Yes
12217,todo quick replies,,Yes,Yes
12218,FIXME ensure uid doesn't exist or is expired,,Yes,Yes
12220,TODO other buttons,,Yes,Yes
12224,avoid importing tf and spacy when not needed,,No,Yes
12225,FIXME allow longer messages,,,Yes
12226,FIXME ADD METADATA !!!,,,Yes
12227,## FIXME VALIDATE SLOVAK CHARACTERS !!! ###,,No,Yes
12228,TODO remove character accents,,No,Yes
12229,TODO https:\/\/stackoverflow.com\/questions\/10572603\/specifying-optional-dependencies-in-pypi-python-setup-py,,Yes,Yes
12230,TODO shuffle data,,,Yes
12231,TODO support sending location,,Yes,Yes
12233,FIXME <-- don't crash on invalid return value (not iterable),,No,Yes
12238,word = '########'  # FIXME use <unk>; which I don't have in the embedding right now,,,Yes
12239,FIXME more than 25 chars,,Yes,Yes
12240,FIXME,,,Yes
12241,FIXME max_length,,Yes,Yes
12242,TODO something more clever,,No,Yes
12244,Don't tokenize period unless it ends the line and that it isn't,,,Yes
12245,Don't tokenize period unless it ends the line eg.,,,Yes
12246,A multidimensional array of 0s with len(s) rows and len(t) columns.,,No,Yes
12248,FIXME not here,,Yes,Yes
12250,FIXME,,Yes,Yes
12254,TODO revise this,,Yes,Yes
12256,TODO custom nlp might receive them preprocessed (or not),,,Yes
12259,FIXME use a factory to build the correct subclass with right arguments,,,Yes
12265,TODO,,Yes,Yes
12267,FIXME nop or what,,,Yes
12268,FIXME,,Yes,Yes
12271,TODO what to say and do on invalid requires -> input?,,,Yes
12272,TODO somebody might want _message_text and intent locked for freetext\/human,,No,Yes
12273,TODO i would go with always as the user's code might depend on the entities being non-null,,,Yes
12276,TODO 'type(response).__name__ if response else 'TextMessage';,,,Yes
12277,TODO json.loads(json.dumps(response; default=lambda obj: obj.__dict__ if hasattr(obj;'__dict__') else str(obj))),,,Yes
12278,TODO this has to be called async,,,Yes
12280,TODO unidecode?,,,Yes
12281,TODO filter by roles,,No,Yes
12284,negative samples (this is a hack),,No,Yes
12285,FIXME,,,Yes
12287,TODO 'type(response).__name__ if response else 'TextMessage';,,,Yes
12289,TODO (1) try embeddings,,No,Yes
12292,TODO is this correct?,,No,Yes
12295,TODO webview,,Yes,Yes
12296,TODO avoid repeating,,,Yes
12297,TODO maybe confidence can be something different,,,Yes
12298,TODO don't increment when @ requires -> input and it's valid,,Yes,Yes
12299,TODO what to say and do on invalid requires -> input?,,Yes,Yes
12301,TODO should they be checked when moving or always?,,,Yes
12302,TODO i would go with always as the user's code might depend on the entities being non-null,,Yes,Yes
12304,TODO catch and log errors,,Yes,Yes
12307,TODO support relative paths; discovery or what,,,Yes
12316,TODO what to say and do on invalid requires -> input?,,Yes,Yes
12317,TODO somebody might want _message_text and intent locked for freetext\/human,,,Yes
12318,FIXME this won't work,,Yes,Yes
12319,execute default action TODO stay here; like fake root,,Yes,Yes
12323,TODO support relative imports in YAML,,,Yes
12326,"TODO should \""unsupported\"" be states or just actions?",,,Yes
12329,Even better: move to special (configurable) unsupported state that will be temporary too,,No,Yes
12330,TODO just run action without moving if the state is temporary,,Yes,Yes
12331,FIXME this won't work,,,Yes
12332,TODO add local entities,,No,Yes
12333,TODO run 'unsupported' action but stay here,,Yes,Yes
12336,TODO might use a state that accepts it instead?,,Yes,Yes
12337,FIXME somehow it also uses older entities,,,Yes
12339,flip the orientation as needed to make all the cameras align,,Yes,Yes
12340,flip the orientation as needed,,Yes,Yes
12343,TODO: make this board configurable,,,Yes
12347,# TODO: release the session here; free the neural net memory,,,Yes
12351,TODO: fill this is in using process_all,,Yes,Yes
12352,# TODO: refactor this file so we can easily check probs as part of the pipeline,,,Yes
12353,TODO: make triangulation type configurable,,No,Yes
12355,# TODO: figure out why this doesn't properly center the data in some cases (???),,,Yes
12356,# TODO: configure aruco board,,Yes,Yes
12357,TODO: this should change with calibration board config,,No,Yes
12358,TODO: this should change with calibration board config,,No,Yes
12362,# TODO: make this ratio and trimming configurable,,Yes,Yes
12363,# TODO build up camera matrices based on pairs,,No,Yes
12367,TODO: make ransac a configurable option,,,Yes
12369,FIXME: hack for plotting,,,Yes
12371,ang_names = [col for col in angles.columns if col not in bad_cols],,Yes,Yes
12372,TODO: get rid of skvideo dependency,,,Yes
12374,# TODO: handle missing cameras,,Yes,Yes
12376,# TODO: remove this function and import from project_2d.py,,Yes,Yes
12377,Return DataFrame with interventions of all users (columns) for all dates (rows),,No,Yes
12378,Put dates into nice visual format,,,Yes
12379,Return DataFrame with interventions of all users (columns) for all hour times (rows),,No,Yes
12380,Put dates into nice visual format,,,Yes
12381,Return DataFrame with interventions of all users (columns) for all days (rows),,,Yes
12383,Return DataFrame with interventions of all users (columns) for all hour times (rows),,No,Yes
12384,TODO Change reading mode for an argv mode,,,Yes
12385,Put dates into nice visual format,,Yes,Yes
12388,df = pd.DataFrame.from_dict(dictionary; orient='columns'),,Yes,Yes
12389,"\""\""\""Return DataFrame with interventions of all users (columns) for all hour times (rows) ||  ||     Parameters ||     ---------- ||     users: list ||         List with the usernames of the chat. ||     hours: list ||         Hours the chat has been active. ||     data: list ||         Legible data. ||  ||     Returns ||     ---------- ||     df: Dataframe ||         Table containing #interventions per user per each hour of the day ||     \""\""\""",,No,Yes
12390,TODO: document,,,Yes
12392,TODO: use accents!,,No,Yes
12393,FIXME Is this version 0.x or 1.x?,,Yes,Yes
12395,FIXME Are going to officially support Python 2.x?,,Yes,Yes
12397,"'''def get_intervention_table_hoursday(users; hours; data): ||     \""\""\"" || \""\""\""Return DataFrame with interventions of all users (columns) for all hour times (rows) ||  ||     Parameters ||     ---------- ||     users: list ||         List with the usernames of the chat. ||     hours: list ||         Hours the chat has been active. ||     data: list ||         Legible data. ||  ||     Returns ||     ---------- ||     df: Dataframe ||         Table containing #interventions per user per each hour of the day ||     \""\""\"" || \""\""\"" ||     interventions_per_hour = np.zeros(len(hours)) ||  ||     # Loop for all users ||     df = pd.DataFrame() ||     for user in users: ||         interventions = get_interventions_user(user; data) ||         # Obtain number of interventions per each day contained in hours ||         for i in range(len(hours)): ||             interventions_per_hour[i] = get_number_interventions_per_hour(hours[i]; ||                                                                           interventions) ||         inter = pd.Series(interventions_per_hour; index=hours) ||         df.insert(0; user; inter) ||  ||     return df ||  ||  || def get_list_interventions_user(username; data): ||     \""\""\"" ||     Obtains a list with all interventions of username_ ||  ||     Parameters ||     ---------- ||     username_: list ||         Days the chat has been active. ||     data_: list ||         Legible data. ||  ||     Returns ||     ---------- ||     list ||         List of dates (nicely written) the chat has been active ||     \""\""\"" ||     return [d for d in data if d[1] == username] ||  ||  || def get_number_interventions_per_day(day_; interv_): ||     \""\""\"" ||     Obtains the number of interventions in the day 'day_' ||  ||     Parameters ||     ---------- ||     day_: list ||         Day we are examining. ||     interv_: list ||         List containing all considered interventions. ||  ||     Returns ||     ---------- ||     list ||         List containing two parameters. The first one quantifies the number ||         of interventions in day 'day_'. The second one is just the index of ||         the last intervention in 'day_' to make the overall search more ||         efficient ||     \""\""\"" ||  ||     s = [1 if i[0][:3] == day_ else 0 for i in interv_] ||     if s[-1] == 0: ||         i = s.index(0) ||     else: ||         i = -1 ||     return [sum(s); i] ||  ||  ||  || def get_number_interventions_per_hour(hour_; interv_): ||     \""\""\"" ||     Obtains the number of interventions during the hour 'hour_' ||  ||     Parameters ||     ---------- ||     hour_: list ||         Hour we are examining. ||     interv_: list ||         List containing all considered interventions. ||  ||     Returns ||     ---------- ||     int ||         quantifies the number of interventions during 'hour_'. ||     \""\""\"" ||     s = [1 if i[0][3] == hour_ else 0 for i in interv_] ||     return sum(s) || '''",,Yes,Yes
12398,TODO: document,,,Yes
12400,Probably this could be better done with Pandas,,No,Yes
12402,Probably this could be better done with Pandas,,No,Yes
12403,"'''def get_intervention_table_hoursday(users; hours; data): ||     \""\""\"" || \""\""\""Return DataFrame with interventions of all users (columns) for all hour times (rows) ||  ||     Parameters ||     ---------- ||     users: list ||         List with the usernames of the chat. ||     hours: list ||         Hours the chat has been active. ||     data: list ||         Legible data. ||  ||     Returns ||     ---------- ||     df: Dataframe ||         Table containing #interventions per user per each hour of the day ||     \""\""\"" || \""\""\"" ||     interventions_per_hour = np.zeros(len(hours)) ||  ||     # Loop for all users ||     df = pd.DataFrame() ||     for user in users: ||         interventions = get_interventions_user(user; data) ||         # Obtain number of interventions per each day contained in hours ||         for i in range(len(hours)): ||             interventions_per_hour[i] = get_number_interventions_per_hour(hours[i]; ||                                                                           interventions) ||         inter = pd.Series(interventions_per_hour; index=hours) ||         df.insert(0; user; inter) ||  ||     return df ||  ||  || def get_list_interventions_user(username; data): ||     \""\""\"" ||     Obtains a list with all interventions of username_ ||  ||     Parameters ||     ---------- ||     username_: list ||         Days the chat has been active. ||     data_: list ||         Legible data. ||  ||     Returns ||     ---------- ||     list ||         List of dates (nicely written) the chat has been active ||     \""\""\"" ||     return [d for d in data if d[1] == username] ||  ||  || def get_number_interventions_per_day(day_; interv_): ||     \""\""\"" ||     Obtains the number of interventions in the day 'day_' ||  ||     Parameters ||     ---------- ||     day_: list ||         Day we are examining. ||     interv_: list ||         List containing all considered interventions. ||  ||     Returns ||     ---------- ||     list ||         List containing two parameters. The first one quantifies the number ||         of interventions in day 'day_'. The second one is just the index of ||         the last intervention in 'day_' to make the overall search more ||         efficient ||     \""\""\"" ||  ||     s = [1 if i[0][:3] == day_ else 0 for i in interv_] ||     if s[-1] == 0: ||         i = s.index(0) ||     else: ||         i = -1 ||     return [sum(s); i] ||  ||  ||  || def get_number_interventions_per_hour(hour_; interv_): ||     \""\""\"" ||     Obtains the number of interventions during the hour 'hour_' ||  ||     Parameters ||     ---------- ||     hour_: list ||         Hour we are examining. ||     interv_: list ||         List containing all considered interventions. ||  ||     Returns ||     ---------- ||     int ||         quantifies the number of interventions during 'hour_'. ||     \""\""\"" ||     s = [1 if i[0][3] == hour_ else 0 for i in interv_] ||     return sum(s) || '''",,Yes,Yes
12405,TODO: RETHING LOOP AS IN THE ONE ABOVE,,Yes,Yes
12408,TODO: Assert number of columns equals number of users,,No,Yes
12409,"By convention this will be \""index\""",,No,Yes
12410,"By convention this will be \""index\""",,,Yes
12411,TODO: Assumes there are always two elements in list chats!,,,Yes
12413,fix W's and U's references,,Yes,Yes
12414,fix W's and U's references,,Yes,Yes
12415,fix W's and U's references,,Yes,Yes
12417,TODO: compare gufunc with njit when support for gufunc in njit is added (issue 2089),,,Yes
12418,TODO: update doctring,,No,Yes
12419,TODO: update doctring,,,Yes
12420,TODO: memory optimizations,,Yes,Yes
12421,TODO: compare gufunc with njit when support for gufunc in njit is added (issue 2089),,,Yes
12425,TODO: normalize error handling for invalid inputs,,No,Yes
12428,passing integers directly,,No,Yes
12429,TODO: normalize error handling for invalid inputs,,,Yes
12431,m[i;j]: min number of scalar multiplications needed to compute A_{i..j},,No,Yes
12432,maybe improved later,,No,Yes
12433,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
12435,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
12437,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
12438,m[i;j]: min number of scalar multiplications needed to compute A_{i..j},,,Yes
12440,TODO: migrate to factory wrappers once mutually-broadcastable strat is available,,,Yes
12442,Hack to deal with summing over an empty tensor.,,Yes,Yes
12443,unused indices form a continuous stretch of dimensions,,,Yes
12448,TODO: optimize this,,Yes,Yes
12449,TODO: ensure ints are promoted to floats,,,Yes
12450,TODO: copy-data doesnt work here!!,,Yes,Yes
12451,TODO: remove this,,,Yes
12452,TODO: This is inefficient!,,,Yes
12455,faster than passing the tensor directly,,No,Yes
12457,TODO: Implement grad-view semantics,,Yes,Yes
12458,hack to make broadcastable shapes work for inplace op:,,Yes,Yes
12461,TODO: handle tuple `out` correctly,,Yes,Yes
12462,TODO: handle tuple `out` correctly,,Yes,Yes
12465,ends up roughly between -1 and 1,,No,Yes
12467,Apparently; the exact duration may vary slightly based on which decoder is used,,Yes,Yes
12469,TODO: When librosa has closed the following issue; we can remove our workaround:,,Yes,Yes
12470,Here we use a workaround that simply loops over the channels. It's not perfect.,,,Yes
12471,TODO: When librosa natively supports multichannel audio; remove our workaround,,,Yes
12473,TODO: Add support for 24-bit and 32-bit loading in scipy>=1.6.0,,,Yes
12474,You can just specify the packages manually here if your project is,,Yes,Yes
12475,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
12476,TODO - input size needs to be 299 for inception_v3,,,Yes
12478,TODO: docs,,No,Yes
12479,"\""\""\"" || @author: XuMing <shibing624@126.com> || @description:evaluator of classification algorithm || \""\""\""",,Yes,Yes
12480,TODO: clean this up,,,Yes
12483,TODO: clean this up,,No,Yes
12485,##it seems Adam is better than SGD here...,,Yes,Yes
12489,TODO tabulating misclassifications,,Yes,Yes
12491,TODO generate a CSV of different metrics for each dataset; as well as a reloadable,,No,Yes
12493,perhaps by controlling the class order in input,,Yes,Yes
12494,LATER choose a more universal serialization method (that could be loaded from a web app) TODO,,,Yes
12495,TODO need to standardize what needs to saved\/read back,,Yes,Yes
12497,TODO need to include subcortical volumes,,,Yes
12505,sort them if need be (not needed if MLDatasets),,No,Yes
12508,TODO generate a CSV of different metrics for each dataset; as well as a reloadable,,,Yes
12511,TODO for binary experiments; compute AUC; sensitivity; specificity (optional precision; recall),,Yes,Yes
12512,TODO implement,,Yes,Yes
12514,TODO this can fail if missing values were encouteterd. Change to genfromtxt later,,Yes,Yes
12516,TODO FIX auc calculation flipped,,Yes,Yes
12517,sel_names not returned to follow return-a-single-vector convention,,Yes,Yes
12518,TODO this can fail if missing values were encouteterd. Change to genfromtxt later,,,Yes
12519,adding an index for an even better contrast,,Yes,Yes
12521,TODO later when are the uses of precision and recall appropriate?,,,Yes
12524,TODO accuracy and AUC on random binary datasets must be chance!,,Yes,Yes
12528,TODO should I export subject-wise misclassification rate as well?,,,Yes
12530,TODO turn the following into a metho of the form,,,Yes
12534,TODO design an API interface for advanced access as an importable package,,Yes,Yes
12538,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
12539,for which len() is not defined (which is needed for pyradigm to find dimensionality,,Yes,Yes
12541,TODO there must be a more elegant way to write dict to CSV,,,Yes
12544,TODO show no more than 4 subplots per figure.,,,Yes
12546,perhaps by controlling the class order in input,,Yes,Yes
12547,NOT EASY TODO enable users choose selector and classifier,,,Yes
12549,TODO save results for each rep independently - in a way that I can re-assemble in case grid search job crashes,,,Yes
12551,TODO save results for each rep independently - in a way that I can re-assemble in case grid search job crashes,,,Yes
12555,maybe improved later,,No,Yes
12557,maybe improved later,,No,Yes
12559,TODO look for ways to avoid building this every iter and every dataset.,,Yes,Yes
12560,TODO expose these options to user at cli,,,Yes
12567,for which len() is not defined (which is needed for pyradigm to find dimensionality,,Yes,Yes
12568,TODO think about how to export predictive probability per class per CV rep,,,Yes
12572,TODO try pruning values based on their processing time\/redundancy,,Yes,Yes
12573,TODO consult literature for better selection of ranges,,,Yes
12574,TODO generate the entire class at once!,,No,Yes
12575,TODO option to print saved options (from previous runs): simple and verbose,,,Yes
12576,TODO this check for exact match is too conservative: allow for extra subjects\/classes to exist,,,Yes
12578,TODO perhaps k-fold is a better inner CV;,,Yes,Yes
12580,TODO perhaps k-fold is a better inner CV;,,,Yes
12582,find out why prefix neg_ is needed,,,Yes
12586,TODO need some simple validation to ensure loaded results are usable,,Yes,Yes
12588,column_stack ensures output is a 2D array; needed for sklearn transformers,,Yes,Yes
12592,TODO implement outlier detection,,Yes,Yes
12595,# TODO likely buggy; double check,,,Yes
12597,TODO should we ensure dataset_id exists already in self._dataset_ids?,,,Yes
12599,TODO find ways to refactor; to reduce reuse of above common code,,Yes,Yes
12604,(columns are the number of examples),,No,Yes
12605,Write columns,,Yes,Yes
12607,"\""\""\"" || package: Images2Dataset || class: stats || Author: Rodrigo Loza || Description: Utils methods  || \""\""\""",,Yes,Yes
12608,"\""\""\"" || package: Images2Dataset || class: utils || Author: Rodrigo Loza || Description: Utils methods  || \""\""\""",,Yes,Yes
12613,"\""\""\""  || Author: Rodrigo Loza  || Company: pfm Medical Bolivia  || Description: Loads a tensorflow self.graph model || \""\""\""",,,Yes
12614,"\""\""\"" || package: Images2Dataset || class: DataAugmentation || Author: Rodrigo Loza || Description: Common data augmentation operations  || for an image. || \""\""\""",,No,Yes
12615,"\""\""\"" || package: Images2Dataset || class: DataAugmentationMethods || Author: Rodrigo Loza || Description: Common data augmentation operations  || for an image. || \""\""\""",,,Yes
12616,"\""\""\"" || package: Images2Dataset || class: ImagePreprocessing || Author: Rodrigo Loza || Description: Common pre-processing operations  || for an image. || \""\""\""",,No,Yes
12617,Fix the excess in slide_window,,Yes,Yes
12618,"\""\""\"" || package: impy || class: Images2Dataset || Author: Rodrigo Loza || Description: Class that loads an image dataset. || We recommend giving some structure to your dataset before || using this class. || * The folder's structure should be like this: || \t\t\t\t\t\t- Data set\/ || \t\t\t\t\t\t\t\t- Folder class 0\/ || \t\t\t\t\t\t\t\t\t- Image 1 || \t\t\t\t\t\t\t\t\t- Image 2  || \t\t\t\t\t\t\t\t\t- ... || \t\t\t\t\t\t\t\t- Folder class 1\/ || \t\t\t\t\t\t\t\t\t- Image 1 || \t\t\t\t\t\t\t\t\t- Image 2  || \t\t\t\t\t\t\t\t\t- ... || \t\t\t\t\t\t\t\t- ... || - You should provide the path to the Data set folder. || - We recommend giving the data set folder a descriptive name. || - The nested folders should contain the name of the class. || - The file names of the images inside the folders don't matter. If you || \twould like to give them proper names; then use the formatDataset method. || \""\""\""",,Yes,Yes
12619,"\""\""\"" || package: Images2Dataset || class: DataAugmentation || Author: Rodrigo Loza || Description: Common data augmentation operations  || for an image. || Log: || \tNovemeber; 2017 -> Re-estructured class. || \tDecember; 2017 -> Researched most used data augmentation techniques. || \tMarch; 2018 -> Coded methods. || \""\""\""",,No,Yes
12621,#################################TO FIX#############################################,,,Yes
12622,(columns are the number of examples),,No,Yes
12626,Fix bounding boxes,,No,Yes
12627,"\""\""\"" || package: Images2Dataset || class: ImageAugmenters || Author: Rodrigo Loza || Description: Common data augmentation methods for images. || \""\""\""",,Yes,Yes
12629,"\""\""\"" || package: Images2Dataset || class: DataAugmentation || Email: lozuwaucb@gmail.com || Author: Rodrigo Loza || Description: Common data augmentation operations  || for an image. || Log: || \tNovemeber; 2017 -> Re-estructured class. || \tDecember; 2017 -> Researched most used data augmentation techniques. || \tMarch; 2018 -> Coded methods. || \tApril; 2018 -> Redesigned the methods to support multiple bounding || \t\t\t\t\t\t\t\t boxes (traditional data augmentation tools.) || \tApril; 2018 -> Redefined list of augmenters: || \tApril; 2018 -> Separated generic image augmenters into color and space augmenters. ||  || \t--------------- || \tColor dimension || \t--------------- || \t1. Invert color || \t\tInvert the color space of the image. || \t2. Histogram equalization || \t\tEqualize the contrast of an image. || \t3. Change brightness || \t\tChange the brightness of an image. || \t4. Random sharpening || \t\tRandomly add sharpening to an image. || \t5. Add gaussian noise || \t\tAdd normal noise to an image. || \t6. Gaussian blur  || \t\tConvolves the image with a Gaussian filter. || \t7. Shift colors || \t\tSwap the color spaces of an image. || \t8. Fancy PCA || \t\tAdd a color perturbation based on the computation || \t\tof color's space PCA. || \""\""\""",,Yes,Yes
12630,"\""\""\"" || package: Images2Dataset || class: ImageAugmenters || Author: Rodrigo Loza || Description: Common data augmentation methods for images. || \""\""\""",,Yes,Yes
12634,Make sure the columns are organized in xyz order,,Yes,Yes
12636,TODO: JointsSelector (x),,No,Yes
12640,TODO: DataFrameNumpier (x),,,Yes
12642,TODO,,Yes,Yes
12644,==========My implement according to paper==========,,Yes,Yes
12646,a new fixed params needed for pytorch port of RMC,,,Yes
12647,just using one big param is more efficient; rather than this line,,Yes,Yes
12648,needed for truncated BPTT; called at every batch forward pass,,Yes,Yes
12649,TODO: check this input flattening is correct,,,Yes
12651,TODO: NVIL loss,,,Yes
12653,TODO: for each parent,,,Yes
12654,TODO: rsgan loss at each category,,Yes,Yes
12655,TODO: rsgan loss at each category,,Yes,Yes
12659,TODO: check this input flattening is correct,,,Yes
12660,TODO: for each parent,,Yes,Yes
12669,TODO: bug: have to reset,,No,Yes
12673,TODO: need to delete,,No,Yes
12676,for temp evolutionary # TODO: need to change to bleu3,,Yes,Yes
12677,TODO: need to delete,,,Yes
12678,TODO: change to python,,Yes,Yes
12679,TODO: change to False,,No,Yes
12682,we want to plot only two columns,,No,Yes
12684,In this particular case; the best performance is obtained by seeking,,,Yes
12685,Increasing the number of line points helps in finding a better optimal,,,Yes
12687,"\""\""\""ResNet\/RevNet implementation used for The Reversible Residual Network || Implemented in PyTorch instead of TensorFlow. ||  || @inproceedings{gomez17revnet; ||   author    = {Aidan N. Gomez and Mengye Ren and Raquel Urtasun and Roger B. Grosse}; ||   title     = {The Reversible Residual Network: Backpropagation without Storing Activations} ||   booktitle = {NIPS}; ||   year      = {2017}; || } ||  || Github: https:\/\/github.com\/renmengye\/revnet-public ||  || Author: Sil van de Leemput ||  || \""\""\""",,Yes,Yes
12694,TODO attempt to use requires_grad to avoid grad injection,,,Yes
12695,TODO add fixed random_seed,,,Yes
12697,To consider:  maybe get_device_states and set_device_states should reside in torch\/random.py?,,Yes,Yes
12698,TODO: not sure why this needs these specific dimensions,,Yes,Yes
12699,z = tf.to_float(tf.argmax(y_pred; axis=4)); # argmax seems to cause some massive error in keras\/tf :S. Not sure why.,,Yes,Yes
12700,figure out the number of rows and columns,,No,Yes
12702,''' || We'd like the following callback actions for neuron: ||  || - print metrics on the test and validation; especially surface-specific dice || --- Perhaps doable with CSVLogger? || - output graph up to current iteration for each metric || --- Perhaps call CSVLogger or some metric computing callback? || - save dice plots on validation || --- again; expand CSVLogger or similar || - save screenshots of a single test subject [Perhaps just do this as a separate callback?] || --- new callback; PlotSlices ||  || ''',,Yes,Yes
12708,TODO: fix in one line,,Yes,Yes
12712,TODO: add Cropping3D or Cropping2D if 'valid' padding,,,Yes
12713,TODO: add Cropping3D or Cropping2D if 'valid' padding,,,Yes
12716,TODO: This needs fixing for when a layer has >1 input;,,Yes,Yes
12718,TODO: This needs fixing for when a layer has >1 input;,,Yes,Yes
12719,Potential Fix: via the recursion; there could be some 'fake' input layers,,Yes,Yes
12720,TO MOVE,,Yes,Yes
12721,TODO: can force a fit through a bunch of volume inputs!,,,Yes
12722,TODO: could output more than a single timepoint!,,Yes,Yes
12724,TODO(nolivia): improve performance with a broadcast,,Yes,Yes
12725,Prepare reshape by inserting dimensions with size 1 where needed,,Yes,Yes
12726,TODO(nolivia): improve performance with a broadcast,,Yes,Yes
12727,figure out the number of rows and columns,,No,Yes
12731,TODO: add Cropping3D or Cropping2D if 'valid' padding,,No,Yes
12734,ends of linear corrective function,,,Yes
12735,TODO: show_example_prediction_result is actually in neuron_sandbox for now,,Yes,Yes
12737,TODO,,,Yes
12739,TODO load from pickle,,,Yes
12741,TODO change to custom config details,,,Yes
12742,TODO change to custom config details,,Yes,Yes
12743,TODO fix it,,Yes,Yes
12746,TODO: are there sparse,,,Yes
12749,TODO: stop sorting when we have top num_results; instead of truncating,,Yes,Yes
12750,TODO: sparse? this appears to be on the hashes which are small,,Yes,Yes
12751,TODO: dot to sparse dot; diff.dot(diff),,,Yes
12752,TODO: sparse sparse.csr_matrix.mean,,,Yes
12753,TODO: sparse; diff.dot(diff),,,Yes
12755,TODO: sparse,,,Yes
12756,TODO: save\/reconstruct data;indices;indptr arrays w\/ ujson,,No,Yes
12758,TODO: remove once we're all sparse lists,,,Yes
12762,TODO: dot to sparse dot; diff.dot(diff),,Yes,Yes
12767,"\""\""\"" || Polymr is a light-weight MapReduce library for single machine computation.  It supports a number of  || useful features such as map and reduce side joins; associative reduces;  || aggregations; multiprocessing; and more. ||  || While the underlying engine uses MapReduce; Polymr is best utilized via it's DSL which provides || higher level functionality for complex workflows. || \""\""\""",,Yes,Yes
12768,"\""\""\"" || Polymr is a light-weight MapReduce library for single machine computation.  It supports a number of  || useful features such as map and reduce side joins; associative reduces;  || aggregations; multiprocessing; and more. ||  || While the underlying engine uses MapReduce; Polymr is best utilized via it's DSL which provides || higher level functionality for complex workflows. ||  || \""\""\""",,Yes,Yes
12769,To improve pickling speed to disk; dampr batches tuples to disk.  Increase or decrease,,Yes,Yes
12772,This hackaround is ugly,,,Yes
12773,OK; like; WTF???,,Yes,Yes
12775,record various intermediates (needed later for backprop),,,Yes
12776,Pong has either +1 or -1 reward exactly when game ends.,,Yes,Yes
12779,TODO: discard this ugly hack!,,No,Yes
12782,Returns: a sample from the policy distribution. The distribution is: move,,No,Yes
12783,'''Core functionality for muda''',,No,Yes
12784,XXX:    2015-03-25 22:37:15 by Brian McFee <brian.mcfee@nyu.edu>,,,Yes
12787,To-Do: Add tiny YOLO for real time object detection,,Yes,Yes
12788,Use your better judgment for the insertion of spaces around arithmetic,,Yes,Yes
12789,needed for nauty graph initialise a small lambda,,No,Yes
12790,move from index labels to dictionary key labels,,Yes,Yes
12791,needed for nauty graph initialise a small lambda,,,Yes
12792,needed for nauty graph initialise a small lambda,,,Yes
12795,TODO support list of tuples,,Yes,Yes
12797,TODO: support nystrom approximation,,,Yes
12798,"\""\""\"" The propagation kernel as defined in [1]: || ' Neumann M.; Garnett R.; P.A..: Propagation kernels: efficient graph kernels from propagated information. In: Springer. Mach Learn (2016) p.209\u2013245' || \""\""\""",,,Yes
12799,calculate the Propagation matrix if needed,,,Yes
12803,this is needed for some reason...,,Yes,Yes
12804,Define the graph format that this kernel needs (if needed),,,Yes
12805,Define the graph format that this kernel needs (if needed),,No,Yes
12808,kernel as subkernel with a custom propagation matrix. This is a workaround!,,,Yes
12809,Define the graph format that this kernel needs (if needed),,,Yes
12810,Define the graph format that this kernel needs (if needed),,No,Yes
12811,Description : Implement the Echo State Network neural network with feed backs.,,No,Yes
12813,Description : Implement the Echo State Network neural network.,,No,Yes
12815,Init seed if needed,,,Yes
12817,Init seed if needed,,Yes,Yes
12818,Linear layer if needed,,,Yes
12819,Init seed if needed,,Yes,Yes
12820,Create directory if needed,,,Yes
12822,Rows; columns and values,,,Yes
12823,Fix covariance matrix,,,Yes
12824,Fix the average,,Yes,Yes
12827,Fix the average,,Yes,Yes
12828,Init seed if needed,,Yes,Yes
12831,TODO: Check how aperture behave under C addition,,,Yes
12832,TODO: Check how aperture behave under C substraction,,Yes,Yes
12835,Rows and columns,,No,Yes
12836,Rows and columns,,No,Yes
12838,Rows and columns,,No,Yes
12840,TODO: Problem with aperture of a AND of two different conceptors,,,Yes
12841,end _find_columns_indices,,Yes,Yes
12842,Description : Implement the RC-SFA module.,,No,Yes
12844,Keep only the needed components,,Yes,Yes
12847,end columns,,Yes,Yes
12848,Columns properties,,,Yes
12849,end columns_properties,,,Yes
12850,Selected columns,,Yes,Yes
12851,Create the tensor for segments (if needed),,No,Yes
12852,Create the tensor for events (jumps) (if needed),,Yes,Yes
12853,[todo] variable inputs,,,Yes
12854,[todo] variable outputs,,,Yes
12856,"''' || 1. @register ||    class XXX || 2. @register(\""OP\"") ||    class XXX || 3. @register(a = 3) ||    class XXX || '''",,Yes,Yes
12857,[TODO] Check Types,,,Yes
12859,[TODO] template,,Yes,Yes
12860,ctype.__name__ = 'c_xxx',,,Yes
12863,TODO: packed variable length sequence,,No,Yes
12867,TODO: packed variable length sequence,,,Yes
12868,Needed if we want to do something like:,,Yes,Yes
12869,install_requires=[];              # Required packages; pulls from pip if needed; do not use for Conda deployment,,,Yes
12870,maybe improved later,,No,Yes
12872,TODO: remove diagonal elements from adjacency matrix,,,Yes
12873,TODO: remove constant 1008 from here,,Yes,Yes
12874,TODO: is copy needed here?,,No,Yes
12879,TODO: check if .eval() creates any problems with batchnorm; dropout; etc.,,Yes,Yes
12882,TODO: load from original checkpoint if previous line fails,,Yes,Yes
12883,TODO: use small embedding layer here for edge class,,No,Yes
12884,TODO: remove diagonal elements from adjacency matrix,,,Yes
12887,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12888,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12889,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12891,Maybe return without targets,,,Yes
12892,recompute\/expand embeddings if needed,,,Yes
12894,Maybe return without target,,No,Yes
12895,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12897,Sending q will cause the process to quit -- manually override,,Yes,Yes
12898,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12899,Tokenize the inputs; perhaps multi-processed.,,Yes,Yes
12902,"print(\""Transformation update : \"" ; df1.columns);",,Yes,Yes
12904,"print(\""Cycle update : \"" ; df1.columns);",,Yes,Yes
12906,TODO : this one is not very easy ... too many values.,,Yes,Yes
12907,Better handle time delta in months,,Yes,Yes
12908,smallest cycles are better,,,Yes
12909,print(table.columns);,,Yes,Yes
12910,"print(\""setParams ; columns\""; iInputDS.columns);",,Yes,Yes
12911,"print(\""preProcessExogenousVariables ; columns\""; iInputDS.columns);",,Yes,Yes
12912,"print(\""preProcessExogenousVariables ; dummy columns\""; lExogenousDummiesDS.columns);",,Yes,Yes
12913,"print(\""preProcessExogenousVariables ; columns\""; lInputDS.columns);",,,Yes
12914,"print(\""mAREstimFrame columns :\"" ; self.mAREstimFrame.columns);",,,Yes
12916,"print(\""preProcessExogenousVariables ; columns\""; self.mExogenousVariables);",,Yes,Yes
12918,"print(\""EXOG_COLUMNS\""; self.mExogenousDummiesDataFrame.columns);",,Yes,Yes
12919,"print(\""BEFORE_EXOG_TRANSFORM_DATASET\"" ; df.shape; df.columns);",,Yes,Yes
12920,"print(\""AFTER_EXOG_TRANSFORM_DATASET\"" ; df.shape; df.columns);",,,Yes
12922,print(df.columns);,,No,Yes
12923,"print(self.mFormula; \""\ || \""; lag_df.columns);",,,Yes
12924,print(list(self.mARFrame.columns));,,,Yes
12926,rename the first two columns (as date and signal),,No,Yes
12927,"print(\""TimeInfo update : \"" ; df1.columns);",,Yes,Yes
12928,"print(\""Transformation update : \"" ; df1.columns);",,Yes,Yes
12929,"print(\""Trend update : \"" ; df1.columns);",,Yes,Yes
12931,"print(\""AR update : \"" ; df1.columns);",,Yes,Yes
12936,level 0 is the original\/physical columns,,Yes,Yes
12938,print(df.columns);,,No,Yes
12939,"print(self.mFormula; \""\ || \""; lag_df.columns);",,Yes,Yes
12942,"print(self.mFormula; \""\ || \""; lag_df.columns);",,Yes,Yes
12944,print(sel2.columns);,,,Yes
12945,"print(\""HORIZON_UNION\"" ; h ; lUnion.columns);",,Yes,Yes
12946,"print(\""HORIZON_UNION_TYPES\"" ; h ; [col.type for col in lUnion.columns]);",,Yes,Yes
12950,"print(\""HORIZON_UNION_TYPES\"" ; h ; [col.type for col in lUnion.columns]);",,,Yes
12951,print(lForecast_DF.columns);,,No,Yes
12952,time in exogenous data should be the strictly same type as time in training dataset (join needed),,No,Yes
12955,Not all columns are mandatory.,,Yes,Yes
12956,print(df.columns),,,Yes
12957,list the columns of the forecast dataset,,Yes,Yes
12958,print(lLastRow.columns ;  df.columns),,Yes,Yes
12960,list the columns of the forecast dataset,,Yes,Yes
12962,keep only the first two columns (as date and signal),,No,Yes
12964,list the columns of the forecast dataset,,,Yes
12968,list the columns of the forecast dataset,,,Yes
12972,print(sel2.columns);,,Yes,Yes
12973,"print(\""HORIZON_UNION\"" ; h ; lUnion.columns);",,Yes,Yes
12976,"print(\""preProcessExogenousVariables ; dummy columns\""; self.mEncodedExogenous);",,Yes,Yes
12977,"print(\""EXOG_COLUMNS\""; self.mEncodedExogenousDataFrame.columns);",,Yes,Yes
12978,print(df2.columns);,,No,Yes
12979,"print(\""BEFORE_EXOG_TRANSFORM_DATASET\"" ; df.shape; df.columns);",,,Yes
12980,"print(\""AFTER_EXOG_TRANSFORM_DATASET\"" ; df.shape; df.columns);",,Yes,Yes
12981,"print(\""mAREstimFrame columns :\"" ; self.mAREstimFrame.columns);",,No,Yes
12982,print(df.columns);,,,Yes
12984,"print(\""mAREstimFrame columns :\"" ; self.mAREstimFrame.columns);",,No,Yes
12985,print(df.columns);,,No,Yes
12986,"print(self.mFormula; \""\ || \""; lag_df.columns);",,Yes,Yes
12987,"print(\""setParams ; columns\""; iInputDS.columns);",,,Yes
12988,time in exogenous data should be the strictly same type as time in training dataset (join needed),,No,Yes
12989,smallest cycles are better,,Yes,Yes
12990,"print(\""Forecast Columns \"" ; dfapp_out.columns);",,Yes,Yes
12992,TODO : use linalg.solve here,,No,Yes
12993,Not all columns are mandatory.,,,Yes
12994,print(lLastRow.columns ;  df.columns),,Yes,Yes
12995,print(self.mModelFrame.columns);,,No,Yes
12996,"print(\""Transformation update : \"" ; df1.columns);",,,Yes
12997,"print(\""TimeInfo update : \"" ; df1.columns);",,Yes,Yes
12999,"print(\""Cycle update : \"" ; df1.columns);",,Yes,Yes
13000,"print(\""AR update : \"" ; df1.columns);",,Yes,Yes
13001,not needed. exogfenous data are missing when not available.,,Yes,Yes
13002,not needed. exogfenous data are missing when not available.,,,Yes
13003,not needed. exogenous data are missing when not available.,,Yes,Yes
13004,not needed. exogenous data are missing when not available.,,Yes,Yes
13009,less MAPE is better; less categories is better; the last is the name of the seasonal to have a total order.,,,Yes
13010,print((lSignal; lTime; lForecastFrame_i.columns)),,Yes,Yes
13011,print(iInputDS.shape; iInputDS.columns; self.mSignals; self.mDateColumns; self.mHorizons),,Yes,Yes
13012,Todo: if batch_size=1; eval does not work.,,,Yes
13013,"\""\""\"" || Author: Philipp Gross; https:\/\/github.com\/phipleg\/keras\/blob\/crf\/keras\/layers\/crf.py || \""\""\""",,Yes,Yes
13014,todo delimiter changeable,,,Yes
13016,todo: check that this is correct,,,Yes
13017,classes = df.columns[2:],,Yes,Yes
13018,TBD: use better initializers (uniform; etc.),,Yes,Yes
13021,TBD: use better initializers (uniform; etc.),,Yes,Yes
13023,finally project down if needed,,Yes,Yes
13024,finally project down to projection dim if needed,,Yes,Yes
13026,some punctuation are prefixed by \/ (e.g. \/. or \/? for dialogue turn apparently),,Yes,Yes
13028,(2) Blank lines between documents. Document boundaries are needed so,,,Yes
13029,The convention in BERT is:,,No,Yes
13031,The convention in BERT is:,,No,Yes
13033,"What we really want to return is \""Steve Smith\"".",,,Yes
13035,Filter out the columns that are not fitting,,No,Yes
13036,print(columns_index),,No,Yes
13037,Filter out the columns that are not fitting,,,Yes
13040,by bert convention; PAD is zero,,Yes,Yes
13041,adding other default bert convention labels,,Yes,Yes
13043,below a quick fix:,,Yes,Yes
13046,if 'reuse' in df.columns:,,,Yes
13047,"\""\""\"" ||     This binary classifier is used in combination with a software mention recognition model; for characterizing ||     the nature of the citation of software in scientific and technical literature.  ||     This classifier predicts if the software introduced by a software mention in a sentence is used ||     or not by the described work.  ||  ||     For the software mention recognizer; see https:\/\/github.com\/ourresearch\/software-mentions ||     and grobidTagger.py in the present project DeLFT. ||  ||     Best architecture\/model is fine-tuned SciBERT.  || \""\""\""",,No,Yes
13050,TODO: maybe we need to be careful abount edges? (t=0; t=T-1),,No,Yes
13051,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
13052,TODO: this is passing locally; but fails on wercker,,Yes,Yes
13053,TODO,,,Yes
13054,TODO: should define data structure that represents full-context labels?,,,Yes
13055,TODO: is this really required?,,,Yes
13056,TODO: does the magic number really make sense?,,,Yes
13057,handle HTK wildcards (and lack of them) at ends of label:,,No,Yes
13058,TODO: this is really ugly,,Yes,Yes
13061,TODO: consider two label alignmetn format,,,Yes
13062,TODO: consider comments?,,,Yes
13063,TODO,,Yes,Yes
13064,TODO: does the magic number really make sense?,,No,Yes
13065,Is this really true? probably no,,,Yes
13068,TODO,,Yes,Yes
13071,Since torch's Dataset (and Chainer; and maybe others) assumes dataset has,,,Yes
13079,Workaround for python 3.7 and bandmat,,,Yes
13080,TODO: currently there are many problem in falset; so we do not support falset,,,Yes
13081,TODO: check lab file,,No,Yes
13082,WARNING - Not sure I'll even implement this at this time,,Yes,Yes
13087,TODO config xml; yaml and json do not handle missing values; need a better option for default values and mandatory values,,Yes,Yes
13088,TODO better handling of <html> type tags,,,Yes
13089,"TODO wrap every resolve method in try\/catch and return \""\"" if error",,Yes,Yes
13092,"TODO <that><topic> can take single \""1\"" and double \""1;2\"" indexes",,Yes,Yes
13093,"TODO <that><topic> can take single \""1\"" and double \""1;2\"" indexes",,,Yes
13094,"TODO <that><topic> can take single \""1\"" and double \""1;2\"" indexes",,Yes,Yes
13095,"TODO <that><topic> can take single \""1\"" and double \""1;2\"" indexes",,Yes,Yes
13097,TODO Sort out space in questions,,Yes,Yes
13102,TODO Add priority words first,,,Yes
13103,TODO Add priority words first,,Yes,Yes
13104,"TODO wrap every resolve method in try\/catch and return \""\"" if error",,Yes,Yes
13105,TODO This overwrites the self._template with an evaluated one,,Yes,Yes
13111,Fix provided by @newdev7 28\/03\/2017,,Yes,Yes
13114,TODO Multiple request calls with AGAIN causes stack fault,,,Yes
13115,TODO If the index exceeds the number of stars then an exception is thrown; it should write an error and return None,,Yes,Yes
13116,TODO This seems to be an issue,,,Yes
13121,"self.assertEqual(response; \""RED IS A NICE COLOR.\"")",,,Yes
13122,TODO Handle case when its not a category,,Yes,Yes
13123,TODO We could have nodes here; make sure they are resolved,,,Yes
13126,TODO Add config option to all POST or throw exception,,Yes,Yes
13127,TODO Add config option to all GET or throw exception,,Yes,Yes
13128,TODO Add POST Option,,Yes,Yes
13131,TODO Set this to be configurable,,,Yes
13133,TODO Check for duplicates rdfs,,,Yes
13134,TODO Move this to Spelling bass class,,No,Yes
13135,TODO move this to Conversations base class,,Yes,Yes
13136,TODO Move this to spelliing base class,,No,Yes
13137,TODO Move this to spelling base class,,No,Yes
13139,TODO Issue here when the response is more than just a simple sentence,,,Yes
13140,TODO Added this to catch a failed sentence,,,Yes
13142,TODO Move sentence_split_charts into a property of tokenizer and move functionality into that class,,No,Yes
13144,TODO Either move config into brain or move functionaity into bot,,Yes,Yes
13147,TODO Added this to catch a failed sentence,,,Yes
13149,TODO; modify this to return mocked json payload,,Yes,Yes
13152,TODO clientid could be replaced with context,,,Yes
13153,TODO Replace bot with client_context,,,Yes
13154,TODO Same method in every class; move to base class,,,Yes
13157,TODO Create Sentence Processor,,Yes,Yes
13158,TODO move into tokenizer code base,,Yes,Yes
13159,TODO MOve into BrainTreeManager,,Yes,Yes
13160,TODO MOve into Security Manager,,,Yes
13161,TODO move all client descriptions into config,,,Yes
13162,TODO fix this,,Yes,Yes
13164,TODO; deal with the spacing between the quotes,,Yes,Yes
13166,TODO Add checks to ensure learnf data is created in storage,,Yes,Yes
13168,TODO; need a load conversation when running in multi client mode using Redis,,Yes,Yes
13169,TODO This fails when subdirs = False and\/or when extension is none,,Yes,Yes
13170,TODO Check for duplicates and remove,,Yes,Yes
13171,TODO Check for duplicates and remove,,,Yes
13172,If it ends with a terminator; keep the terminator; otherwise add a full stop,,Yes,Yes
13174,TODO this writes to local storage rather than \/tmp,,Yes,Yes
13175,TODO Add better parsing protextion to the splits,,Yes,Yes
13177,KS Added this to fix empty string UDC,,Yes,Yes
13180,Move to GPU if available,,Yes,Yes
13182,Move to GPU if available,,Yes,Yes
13183,FIX BUGS WITH RANDOM STATE,,Yes,Yes
13184,"r\""\""\""Abstract base Model for training; evaluating and performing inference || All custom models should subclass this and implement train; evaluate and predict functions ||  ||     Args: ||         use_cuda_if_available (boolean): If set to true; training would be done on a gpu if any is available ||      ||     \""\""\""",,Yes,Yes
13188,init_state_dict sets up an alternative way to cast per-param state tensors.,,,Yes
13189,alternative way to cast per-param state tensors:,,Yes,Yes
13190,discarding the iteration;  but probably wouldn't improve overall efficiency.,,Yes,Yes
13193,init_state_dict sets up an alternative way to cast per-param state tensors.,,Yes,Yes
13194,alternative way to cast per-param state tensors:,,,Yes
13195,discarding the iteration;  but probably wouldn't improve overall efficiency.,,Yes,Yes
13196,More efficient version that can be used if .sum() returns a Python scalar,,,Yes
13197,not cloning the dictionary at this point... maybe it should be?,,Yes,Yes
13198,input_sample = self.transform(image=input_sample)     # needed for albumentations to work (but currently albumentations dies with multiple workers),,Yes,Yes
13199,color space is unused here,,Yes,Yes
13200,Workaround: can't sort Variable bug,,,Yes
13202,hack for bincounting 2 arrays together,,,Yes
13203,self.act;      #TODO orig code uses ReLU here,,,Yes
13204,nn.BatchNorm2d(out_channels); #TODO: orig code uses BN here,,No,Yes
13207,TODO: ugly,,Yes,Yes
13211,compatibility hack,,No,Yes
13212,TODO check https:\/\/github.com\/pytorch\/pytorch\/issues\/5332,,,Yes
13213,# TODO Problem here:,,No,Yes
13214,turn on the cudnn autotuner that selects efficient algorithms,,No,Yes
13217,By convention; model names starting with lowercase are pretrained on imagenet while uppercase are not,,Yes,Yes
13219,"\""\""\"" || Below you will find all the latest image classification models. || By convention; model names starting with lowercase are pretrained on imagenet while uppercase are not (vanilla). To load one of the pretrained || models with your own number of classes use the ``models.model_utils.get_model(...)`` function and specify the name of the model || exactly like the pretrained model method name (e.g. if the method name reads ``pywick.models.classification.dpn.dualpath.dpn68`` then use || `dpn68` as the model name for ``models.model_utils.get_model(...)``. || \""\""\""",,,Yes
13221,seriously... why?  I'm looking at you OCNet,,,Yes
13222,TODO : Make beautiful,,,Yes
13228,put on gpu if needed,,No,Yes
13229,TODO: remove,,No,Yes
13235,hack to get nccl to stop throwing error... seems to be an nccl race condition,,Yes,Yes
13240,move optimizer to GPU 1 weight at a time,,,Yes
13243,TODO: fix hack (maybe not a hack),,No,Yes
13244,fixes weird bug where copies are out of sync,,Yes,Yes
13246,TODO: in dp; the state gets wiped... need to figure out how to fix,,No,Yes
13247,needed to prevent ImportError and duplicated logs.,,,Yes
13248,for iterable train loader; the progress bar never ends,,Yes,Yes
13249,needed to prevent ImportError and duplicated logs.,,Yes,Yes
13251,done in hook so user can overwrite if needed,,No,Yes
13252,TODO: fix for anything with multiprocess DP; DDP; DDP2,,,Yes
13254,for iterable train loader; the progress bar never ends,,,Yes
13256,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
13257,TODO: better parse from package since the import name and package name may differ,,,Yes
13260,do something when the epoch ends,,,Yes
13267,TODO: some alternative should be added,,,Yes
13269,args needed to reload correct experiment,,Yes,Yes
13270,TODO: some alternative should be added,,,Yes
13272,needed to prevent ImportError and duplicated logs.,,Yes,Yes
13274,backward compatible; todo: remove in v0.8.0,,Yes,Yes
13277,when ddp ends; we save the model,,,Yes
13279,TODO: remove after getting own MNIST,,,Yes
13283,TODO: remove in 1.0.0,,,Yes
13284,"TODO: get \""help\"" from docstring :)",,No,Yes
13285,backward compatible; todo: remove in v0.9.0,,Yes,Yes
13286,Backward compatibility; TODO: remove in v0.9.0,,No,Yes
13287,"\""\""\""Diagnose your system and show basic information ||  || This server mainly to get detail info for better bug reporting. ||  || \""\""\""",,Yes,Yes
13288,backward compatible; todo: remove in v0.9.0,,Yes,Yes
13291,so; we hack it by using the string representation,,Yes,Yes
13292,so; we hack it by using the string representation,,Yes,Yes
13293,TODO: remove in v1.0.0,,No,Yes
13294,args needed to reload correct experiment,,Yes,Yes
13295,backward compatible; todo: remove in v0.9.0,,Yes,Yes
13296,Backward compatibility; TODO: remove in v0.9.0,,No,Yes
13297,backward compatible; todo: remove in v0.8.0,,,Yes
13299,TODO: log lr.results to self.logger,,,Yes
13300,TODO: remove in v0.9.0,,No,Yes
13301,TODO: consolidate all actions that need to take place only after,,Yes,Yes
13304,TODO: remove in v 0.8.0,,Yes,Yes
13305,Backward compatibility; TODO: remove in v0.9.0,,No,Yes
13308,hack forward to do autocast for the user,,,Yes
13309,TODO: remove in v0.8.0,,,Yes
13310,backward compatible; todo: remove in v0.8.0,,Yes,Yes
13314,backward compatible; todo: remove in v0.9.0,,,Yes
13315,when training ends on these platforms dump weights to get out of the main process,,,Yes
13318,backward compatible; todo: remove in v0.9.0,,Yes,Yes
13319,"\""\""\"" || Metrics || ======= ||  || Metrics are generally used to monitor model performance. ||  || The following package aims to provide the most convenient ones as well || as a structure to implement your custom metrics for all the fancy research || you want to do. ||  || For native PyTorch implementations of metrics; it is recommended to use || the :class:`TensorMetric` which handles automated DDP syncing and conversions || to tensors for all inputs and outputs. ||  || If your metrics implementation works on numpy; just use the || :class:`NumpyMetric`; which handles the automated conversion of || inputs to and outputs from numpy as well as automated ddp syncing. ||  || .. warning:: Employing numpy in your metric calculation might slow ||     down your training substantially; since every metric computation ||     requires a GPU sync to convert tensors to numpy. ||  ||  || \""\""\""",,Yes,Yes
13320,"\""\""\"" || This file provides functions and decorators for automated input and output || conversion to\/from :class:`numpy.ndarray` and :class:`torch.Tensor` as well as utilities to || sync tensors between different processes in a DDP scenario; when needed. || \""\""\""",,Yes,Yes
13321,TODO: to be fixed in #1773,,,Yes
13323,user could press ctrl+c many times... only shutdown once,,Yes,Yes
13327,todo add some back compatibility,,,Yes
13331,todo,,,Yes
13332,# no matter how you do it; it should be assigned,,Yes,Yes
13333,all of this needs to go into the early stopping to clean up better,,Yes,Yes
13334,so we have to hack it like this,,Yes,Yes
13340,TODO: verify it is still needed and deprecate it..,,Yes,Yes
13341,TODO: remove in 0.10.0,,Yes,Yes
13345,Backward compatibility; TODO: remove in v0.9.0,,No,Yes
13351,TODO: modify when using result obj,,,Yes
13352,# TODO: why `dataloder` is required if it is not used,,,Yes
13354,redefine the type for ArgParser needed,,Yes,Yes
13356,TODO: add matching messages,,,Yes
13358,when training ends on these platforms dump weights to get out of the main process,,,Yes
13363,todo; pass complete checkpoint as state dictionary,,,Yes
13365,TODO: remove with dropping NVIDIA AMP support,,,Yes
13366,TODO: need to split using random_split once updated to torch >= 1.6,,,Yes
13367,TODO: deprecate 1.0,,,Yes
13369,TODO: remove when dict results are deprecated,,No,Yes
13371,hack for types in (int; float),,,Yes
13372,hack for track_grad_norm,,No,Yes
13374,TODO: collapse if statement into backends (next),,,Yes
13375,TODO: deprecate,,Yes,Yes
13376,TODO: deprecate,,Yes,Yes
13377,TODO: deprecate,,Yes,Yes
13380,set up the passed in dataloaders (if needed),,,Yes
13381,so; we hack it by using the string representation,,Yes,Yes
13386,modify dataloader if needed (ddp; etc...),,,Yes
13393,reload data when needed,,,Yes
13396,VALIDATE IF NEEDED + CHECKPOINT CALLBACK,,,Yes
13397,TODO: merge both functions?,,No,Yes
13400,hack for types in (int; float),,,Yes
13401,hack for track_grad_norm,,No,Yes
13402,TODO: log lr.results to self.logger,,No,Yes
13404,These are the only lines needed after v0.8.0,,Yes,Yes
13407,todo; pass complete checkpoint as state dictionary,,Yes,Yes
13409,TODO: fix for anything with multiprocess DP; DDP; DDP2,,,Yes
13410,TODO: this should be taken out of here... but depends too much on DDP,,Yes,Yes
13412,todo; pass also best score,,Yes,Yes
13414,TODO: 1.0.0 remove,,,Yes
13415,TODO: remove checks in 1.0.0,,No,Yes
13416,TODO: add outputs to batches,,No,Yes
13417,TODO: deprecate at 1.0,,,Yes
13418,TODO: is this needed?,,No,Yes
13419,todo; pass also best score,,Yes,Yes
13421,TODO: deprecate 1.0,,Yes,Yes
13422,TODO: if logged twice fail with crash,,,Yes
13429,TODO: Deprecated in v0.10.0. Remove early stopping default configuration in v1.0,,,Yes
13431,todo: remove in v1.0.0,,No,Yes
13432,NeptuneLogger;  # TODO: fix: https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/pull\/3256,,Yes,Yes
13433,TODO: recursive reduce:,,,Yes
13438,todo: remove this old warning,,,Yes
13441,Todo: allow user to pass in tensor with weights,,,Yes
13442,todo: maybe add a warning that some init args were overwritten by Env arguments,,No,Yes
13443,so; we hack it by using the string representation,,,Yes
13444,TODO: pass the closure to the step ASAP,,,Yes
13446,TODO: max_steps seems to fail together with accumulation,,No,Yes
13447,TODO: unify metrics between class and functional; add below,,,Yes
13448,Todo: allow user to pass in tensor with weights,,No,Yes
13469,todo: lower this thr,,,Yes
13471,TODO: pass the closure to the step ASAP,,Yes,Yes
13472,TODO: remove this method in v1.3.0.,,No,Yes
13473,TODO: Update with MisconfigurationException when auto mode is removed in v1.3,,Yes,Yes
13478,todo: understand why synchronization breaks there.,,Yes,Yes
13480,todo: find a better way than try \/ except,,,Yes
13481,todo add logic that it cannot be set if GPU is missing,,Yes,Yes
13487,TODO: deprecated in favor of general ROC in pytorch_lightning\/metrics\/functional\/roc.py,,,Yes
13488,todo: remove in v1.2,,,Yes
13490,Todo: required argument `process_idx` is not used,,Yes,Yes
13492,Todo: required argument `process_idx` is not used,,Yes,Yes
13494,Todo: required argument `process_idx` is not used,,,Yes
13496,Todo: required argument `process_idx` is not used,,,Yes
13497,Todo: required argument `is_master` is not used,,Yes,Yes
13498,Todo: required argument `tpu_core_idx` is not used,,Yes,Yes
13500,Todo: required argument `optimizer_idx` is not used,,,Yes
13501,Todo: required argument `is_slurm_managing_tasks` is not used,,Yes,Yes
13503,Todo: required argument `frame` is not used,,Yes,Yes
13504,hack for types in (int; float),,Yes,Yes
13505,hack for track_grad_norm,,No,Yes
13508,todo: later add also checking deprecated warnings,,Yes,Yes
13509,todo: find a better way than try \/ except,,Yes,Yes
13511,Todo: required argument `process_idx` is not used,,,Yes
13512,Todo: required argument `optimizer_idx` is not used,,Yes,Yes
13514,todo: specify the expected Exceptions to come,,Yes,Yes
13516,todo: specify the possible exception,,Yes,Yes
13517,todo: specify the possible exception,,,Yes
13518,todo: specify the possible exception,,,Yes
13519,todo: specify the possible exception,,,Yes
13520,todo: specify the possible exception,,Yes,Yes
13521,todo: specify the possible exception,,,Yes
13524,todo: specify the possible exception,,Yes,Yes
13527,could be multiple datasets; but use self.dataset to follow the name convention in DataLoader,,Yes,Yes
13529,Todo: required argument `process_idx` is not used,,,Yes
13530,Todo: required argument `optimizer_idx` is not used,,,Yes
13532,"todo: kind=\""Vanilla PT\"" -> use_lightning=False",,No,Yes
13533,todo: wrap content as commented description,,,Yes
13534,Todo: required argument `optimizer_idx` is not used,,Yes,Yes
13538,todo: specify the possible exception,,Yes,Yes
13539,todo: specify the possible exception,,Yes,Yes
13540,todo: specify the possible exception,,Yes,Yes
13541,Todo: required argument `optimizer_idx` is not used,,,Yes
13543,todo: specify the possible exception,,Yes,Yes
13544,Todo: required argument `process_idx` is not used,,,Yes
13547,Todo: required argument `tpu_core_idx` is not used,,,Yes
13551,Todo: required argument `optimizer_idx` is not used,,Yes,Yes
13552,todo: specify the possible exception,,,Yes
13556,todo: specify the possible exception,,Yes,Yes
13557,todo: specify the possible exception,,,Yes
13561,if unset; default `find_unused_parameters` `True`,,,Yes
13562,todo: specify the possible exception,,Yes,Yes
13564,todo: specify the possible exception,,Yes,Yes
13568,TODO: unify metrics between class and functional; add below,,No,Yes
13569,todo: specify the possible exception,,Yes,Yes
13572,todo: add more legacy checkpoints :],,,Yes
13574,running .fit() would require us to implement custom data loaders; we mock the model reference instead,,Yes,Yes
13576,todo: specify the possible exception,,Yes,Yes
13578,Todo: required argument `process_idx` is not used,,,Yes
13579,TODO: this should be taken out of here... but depends too much on DDP,,Yes,Yes
13580,TODO: clean-up this branching as most just select class and uses the very same arguments,,No,Yes
13582,Todo: required argument `is_slurm_managing_tasks` is not used,,,Yes
13583,todo: remove in v1.3,,Yes,Yes
13586,Todo: add support for custom pruning_fn function.,,Yes,Yes
13588,todo: address this in another PR,,,Yes
13589,: PrecisionPlugin  # fixme,,,Yes
13590,TODO: this is a hack; find a better solution for this (hook?),,,Yes
13591,: PrecisionPlugin # fixme,,,Yes
13594,unused parameters. Only if `find_unused_parameters` is set.,,,Yes
13595,fixme: uncomment when this class will actually be used,,No,Yes
13596,fixme: uncomment when this class will actually be used,,,Yes
13597,fixme,,Yes,Yes
13599,if unset; default `find_unused_parameters` `True`,,Yes,Yes
13601,if unset; default `find_unused_parameters` `True`,,Yes,Yes
13604,todo: specify the possible exception,,,Yes
13606,todo: the same function as slurm_environment.py `_resolve_root_node_address`,,Yes,Yes
13607,todo: this is the same func as slurm_environment.py `master_port`,,Yes,Yes
13608,todo: specify the possible exception,,Yes,Yes
13609,todo: clean up this routing mess.,,Yes,Yes
13610,TODO: probably not needed anymore after refactor,,Yes,Yes
13612,todo: specify the possible exception,,,Yes
13614,TODO: Checks with filepath. To be removed in v1.2,,No,Yes
13619,TODO: Fatal Python error: Bus error,,No,Yes
13625,todo: clean up this routing mess.,,Yes,Yes
13629,TODO: log lr.results to self.logger,,,Yes
13630,TODO: Move this logic to logger_connector. This also needs to be fixed for any,,,Yes
13631,TODO: improve these docs,,Yes,Yes
13635,TODO: decouple DDP from TE,,,Yes
13636,TODO: maybe introduce a DefaultEnvironment?,,No,Yes
13637,next line is a workaround for a pytorch issue (fixed on master; still present,,,Yes
13638,todo,,,Yes
13640,Todo: required argument `pl_module` is not used,,Yes,Yes
13641,TODO: remove this method in v1.3.0.,,No,Yes
13642,TODO(carmocca): when we implement flushing the logger connector metrics after,,,Yes
13645,instead of us having to do it here manually,,,Yes
13647,if unset; default `find_unused_parameters` `True`,,,Yes
13649,if unset; default `find_unused_parameters` `True`,,Yes,Yes
13652,TODO: add predict,,No,Yes
13654,todo,,No,Yes
13656,TODO: Add support to allow batch transfer to device in Lightning for DP mode.,,,Yes
13658,todo: Find why coverage breaks CI.,,Yes,Yes
13659,Check with (tgaddair) on Horovod issues if this feature is needed,,,Yes
13663,todo: PyTorch 1.7.0 DDP introduces ``self.reducer._rebuild_buckets()`` breaking manual_optimization,,Yes,Yes
13664,todo (tchaton) All ranks should call describe.,,Yes,Yes
13665,todo (tchaton) add support for all ranks,,,Yes
13666,Todo (tchaton) Better fix,,No,Yes
13667,TODO: this is duplicated in MetricsHolder. should be unified,,,Yes
13668,TODO: decrease speed diff since only 2 GPUs sharding 2 optimizers,,Yes,Yes
13673,todo: this is required for DeepSpeed throughput timers; or throughput timers will be incorrect,,No,Yes
13674,todo (tchaton) Add support for accumulate_grad_batches being a dictionary.,,,Yes
13676,hook: give user access to checkpoint if needed.,,,Yes
13678,todo: move this logic internally within the barrier.,,Yes,Yes
13680,TODO(carmocca): when we implement flushing the logger connector metrics after,,,Yes
13681,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
13683,Keep the number of columns in the original dataset,,Yes,Yes
13684,The categorical columns are the ones whose values are not numerical,,Yes,Yes
13685,Extract the supplementary columns,,,Yes
13686,Extract the categorical columns,,Yes,Yes
13687,Remove the categorical and the supplementary columns from the main dataframe,,Yes,Yes
13690,Todo,,Yes,Yes
13691,Extract the categorical columns,,,Yes
13694,Determine the numerical columns,,,Yes
13695,Determine the number of columns in the initial matrix,,Yes,Yes
13696,Determine the number of columns in the indicator matrix,,Yes,Yes
13697,Separate the categorical columns from the numerical ones,,Yes,Yes
13699,Separate numerical columns from categorical columns,,Yes,Yes
13700,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
13701,for ci is no comparison space or vectors needed,,Yes,Yes
13702,\t\tfor col in self.comparison_space.columns.tolist():,,Yes,Yes
13705,all letters both for rows and columns (based on ideas implemented by,,,Yes
13707,unparseable. Maybe git-describe is misbehaving?,,Yes,Yes
13709,unparseable. Maybe git-describe is misbehaving?,,,Yes
13712,No labels passed; maybe series or dataframe passed? Let's try...,,Yes,Yes
13713,The actual classifier. Maybe this is slightly strange because of inheritance.,,No,Yes
13715,This is a bit ugly; but it avoids running this again by,,,Yes
13716,Workaround for standalone backslash,,Yes,Yes
13717,index only columns needed,,Yes,Yes
13718,Index all columns,,,Yes
13719,reconsider this decision once this numpy bug is fixed:,,Yes,Yes
13722,drop missing values and columns without relevant information,,,Yes
13723,make an empty dataframe with the columns of self.a and self.b,,Yes,Yes
13727,Check if all columns are there,,Yes,Yes
13728,The columns with data,,Yes,Yes
13729,possible to pickle instancemethods. A workaround can be found at,,Yes,Yes
13732,Metadata columns,,Yes,Yes
13734,replace missing columns names by numbers,,,Yes
13735,The actual classifier. Maybe this is slightly strange because of,,Yes,Yes
13736,XXX The following is a stopgap measure; we need to set the dimensions,,,Yes
13738,TODO: ensure classes are [0; 1] (not [1; 0]),,,Yes
13739,TODO: check with bin.y_type_,,No,Yes
13741,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
13742,TODO: documentation: for CSV\/Excel,,,Yes
13743,They are needed by _ProtocolMeta,,,Yes
13747,TODO: Completely redesign,,,Yes
13749,Bug work-around,,Yes,Yes
13751,Bug work-around,,Yes,Yes
13752,TODO: can we do this with xpath instead?,,No,Yes
13754,TODO: can't we do this inline in a list comprehension?,,Yes,Yes
13755,TODO: verify and catch stdout; stderr,,Yes,Yes
13756,TODO: return standard output,,No,Yes
13757,TODO: return error output,,No,Yes
13759,TODO,,Yes,Yes
13760,TODO: write index,,Yes,Yes
13761,TODO: pron; grad,,Yes,Yes
13763,unused_docs = [],,Yes,Yes
13764,Configuration is specific to ILK servers (TODO: make external configuration file),,,Yes
13767,The library currently has only a minimal set of functionality compared,,,Yes
13768,ORIGINAL AND AS-OF-YET UNUSED CODE (included for later porting),,No,Yes
13774,TODO: ADD IMDI,,,Yes
13776,TODO,,Yes,Yes
13777,TODO,,,Yes
13778,TODO: Parse CMDI,,,Yes
13781,TODO: IMPLEMENT,,Yes,Yes
13783,TODO: replace other child within the same set,,Yes,Yes
13784,TODO: implement,,Yes,Yes
13785,TODO: ID trouble?,,No,Yes
13789,TODO: make obsolete,,Yes,Yes
13790,MAYBE TODO: corrected attribute?,,Yes,Yes
13791,TODO: Implement,,,Yes
13794,TODO: Refactor,,No,Yes
13796,TODO: relaxNG,,,Yes
13798,TODO: format string,,Yes,Yes
13799,ugly patch to get rid of namespace prefix,,Yes,Yes
13800,TODO,,Yes,Yes
13801,TODO,,,Yes
13802,TODO!,,Yes,Yes
13803,TODO: relaxNG,,No,Yes
13805,TODO: implement,,Yes,Yes
13808,TODO: Implement,,Yes,Yes
13811,XML Tree is now obsolete (only needed when partially loaded for xpath queries),,,Yes
13812,TODO: Parse xlink:href,,Yes,Yes
13813,TODO: Parse xlink:href,,,Yes
13815,TODO: add phoneme when it becomes available,,Yes,Yes
13816,XML Tree is now obsolete (only needed when partially loaded for xpath queries); free memory,,,Yes
13818,ignorelist = [ globals()[c] if not inspect.isclass(c) else c for c in ignorelist ]  #TODO: make more efficient; resolving the same default ignorelist every time is slow; isclass is costly,,,Yes
13819,There is a leak in lxml :( ; specialise file handler to replace xml:id to id; ugly hack (especially for Python2),,Yes,Yes
13822,TODO: won't work in text <x\/> text scenarios,,No,Yes
13823,TODO: Implement,,Yes,Yes
13825,will hold all subdocs (sourcestring => document) ; needed so the index can resolve IDs in subdocs,,Yes,Yes
13828,TODO: check validity of elements under subdoc\/text with respect to self.parent,,Yes,Yes
13831,ugly patch to get rid of namespace prefix,,Yes,Yes
13832,self.form = #TODO,,,Yes
13833,TODO,,,Yes
13834,TODO,,Yes,Yes
13836,TODO: process modifier,,No,Yes
13837,TODO: efficiency,,,Yes
13840,TODO: implement,,,Yes
13841,if a sentence ends in a linebreak; we don't want any delimiter,,No,Yes
13844,OPTIONAL_ATTRIBS = (Attrib.ID; Attrib.SETONLY;) #TODO: handle SETONLY in new scheme,,,Yes
13846,(twice; better safe than sorry),,No,Yes
13847,nasty backward-compatibility hack to allow deprecated listitem element (actually called item),,,Yes
13848,definitions needed for ForeignData (allow any content) - see http:\/\/www.microhowto.info\/howto\/match_arbitrary_content_using_relax_ng.html,,Yes,Yes
13851,TODO: serialise to json,,No,Yes
13857,needed for Windows,,Yes,Yes
13858,- Secondly; we fix a bunch of command line arguments.,,,Yes
13861,"\""\""\"" || ========================================== || 2D Optimal transport for different metrics || ========================================== ||  || Stole the figure idea from Fig. 1 and 2 in  || https:\/\/arxiv.org\/pdf\/1706.07650.pdf ||  ||  || @author: rflamary || \""\""\""",,Yes,Yes
13863,TODO: check whether Xs is new or not,,,Yes
13866,FIXME: we should probably reset __new__ for full generality,,Yes,Yes
13867,FIXME: we should probably reset __new__ for full generality,,Yes,Yes
13870,TODO: check whether Xs is new or not,,,Yes
13872,and labeled target samples occupy the first columns,,No,Yes
13873,columns constraints,,,Yes
13875,XXX use random state,,,Yes
13879,Compute worst violation per line and columns,,,Yes
13881,trick to fasten the computation: select only the subset of columns\/lines,,,Yes
13883,Update personal bests if the current position is better,,,Yes
13888,Update personal bests if the current position is better,,Yes,Yes
13890,TODO: Implement Beale's Function,,Yes,Yes
13891,TODO: Implement Bukin Function no. 6,,,Yes
13896,"r\""\""\"" || Base class for single-objective discrete Particle Swarm Optimization  || implementations. ||  || All methods here are abstract and raises a :code:`NotImplementedError`  || when not used. When defining your own swarm implementation; || create another class; ||  ||     >>> class MySwarm(DiscreteSwarmBase): ||     >>>     def __init__(self): ||     >>>        super(MySwarm; self).__init__() ||  || and define all the necessary methods needed. ||  || As a guide; check the discrete PSO implementations in this package. ||  || .. note:: Regarding :code:`**kwargs`; it is highly recommended to ||     include parameters used in position and velocity updates as ||     keyword arguments. For parameters that affect the topology of ||     the swarm; it may be much better to have them as positional ||     arguments. ||  || See Also || -------- || :mod:`pyswarms.discrete.bn`: binary PSO implementation ||  || \""\""\""",,Yes,Yes
13897,Update personal bests if the current position is better,,Yes,Yes
13900,"r\""\""\"" || Base class for multi-objective Particle Swarm Optimization || implementations. ||  || All methods here are abstract and raises a :code:`NotImplementedError` || when not used. When defining your own swarm implementation; || create another class; ||  ||     >>> class MySwarm(MultiObjectiveSwarmBase): ||     >>>     def __init__(self): ||     >>>         super(MySwarm; self).__init__() ||  || and define all the necessary methods needed. ||  || .. note:: Regarding :code:`options`; it is highly recommended to ||     include parameters used in position and velocity updates as ||     keyword arguments. For parameters that affect the topology of ||     the swarm; it may be much better to have them as positional ||     arguments. ||  || \""\""\""",,Yes,Yes
13901,The minimum index is itself; no mapping needed.,,Yes,Yes
13902,The minimum index is itself; no mapping needed.,,Yes,Yes
13906,kick out dummy entries for true negative patients. not needed on roi-level.,,,Yes
13907,implement extra anchor-scales according to retina-net publication.,,Yes,Yes
13909,improve performance by trimming to top anchors by score,,No,Yes
13911,TODO return for instance segmentation:,,,Yes
13912,For positive anchors; compute shift and scale needed to transform them to match the corresponding GT boxes.,,No,Yes
13913,p1_out = self.P1_conv2(p1_pre_out) # usually not needed.,,No,Yes
13915,needed if doing instance segmentation. evaluation not yet implemented.,,,Yes
13918,# 3. Detailed illustraction of how differet split,,No,Yes
13923,TODO: generation function in numpy; random sampling,,,Yes
13927,TODO: fix it later,,,Yes
13929,TODO: Use the axis index for factoring this loop,,,Yes
13930,re-initialize move,,,Yes
13931,horrible hack,,No,Yes
13932,re-initialize move,,,Yes
13933,re-initialize move,,,Yes
13934,horrible hack,,,Yes
13935,horrible hack,,No,Yes
13936,choose next move,,Yes,Yes
13938,"\""\""\"" || author: Sebastian Flennerhag || date: 10\/01\/2017 || Support functions for naming estimators to enable ensemble parameter mapping || \""\""\""",,No,Yes
13939,"\""\""\"" || author: Sebastian Flennerhag || date: 11\/01\/2017 || Stacked ensemble class for full control over the entire model's parameters. || Scikit-learn API allows full integration; including grid search and pipelining. || \""\""\""",,Yes,Yes
13940,"\""\""\"" || author: Sebastian Flennerhag || data: 10\/01\/2017 || Base functions for any parallel processing || \""\""\""",,,Yes
13948,Fill list of parameter settings by param,,,Yes
13949,This is a bit ugly; but it avoids running this again by,,Yes,Yes
13950,Workaround for standalone backslash,,,Yes
13952,TODO: make the preprocessing of folds optional as it can take a lot of memory,,Yes,Yes
13953,XXX After removing the deprecated scorers (v0.20) remove the,,No,Yes
13959,"\""\""\"" ||  || :author: Sebastian Flennerhag || :copyright: 2017 || :licence: MIT ||  || Stacked ensemble class for full control over the entire model's parameters. || Scikit-learn API allows full integration; including grid search and pipelining. || \""\""\""",,,Yes
13962,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
13963,"\""\""\""ML-Ensemble ||  || :author: Sebastian Flennerhag || :copyright: 2017 || :licence: MIT ||  || Parallel processing core backend. || \""\""\""",,,Yes
13964,"\""\""\""ML-ENSEMBLE ||  || Benchmark of ML-Ensemble against Scikit-learn estimators using Scikit-learn's || friedman1 dataset. ||  || All estimators are instantiated with default settings; and all estimators in || the ensemble are part of the benchmark. ||  || The default ensemble configuration achieves a 25% score improvement as compared || to the best benchmark estimator (GradientBoostingRegressor). ||  || Ensemble training time depends on the number of available cores. ||  || Example output || -------------- ||  || Benchmark of ML-ENSEMBLE against Scikit-learn estimators on the friedman1 || dataset. ||  || Scoring metric: Root Mean Squared Error. ||  || Available CPUs: 4 ||  || Ensemble architecture || Num layers: 1 || Meta estimator: GradientBoostingRegressor || layer-1 | Min Max Scaling - Estimators: ['svr']. || layer-1 | Standard Scaling - Estimators: ['elasticnet'; 'lasso'; ||                                           'kneighborsregressor']. || layer-1 | No Preprocessing - Estimators: ['randomforestregressor'; ||                                           'gradientboostingregressor']. ||  || Benchmark estimators: GBM KNN Kernel Ridge Lasso Random Forest SVR Elastic-Net ||  || Data || Features: 10 || Training set sizes: from 2000 to 20000 with step size 2000. ||  || SCORES ||   size | Ensemble |      GBM |      KNN | Kern Rid |    Lasso | Random F | ... ||   2000 |     0.83 |     0.92 |     2.26 |     2.42 |     3.13 |     1.61 | ... ||   4000 |     0.75 |     0.91 |     2.11 |     2.49 |     3.13 |     1.39 | ... ||   6000 |     0.66 |     0.83 |     2.02 |     2.43 |     3.21 |     1.29 | ... ||   8000 |     0.66 |     0.84 |     1.95 |     2.43 |     3.19 |     1.24 | ... ||  10000 |     0.62 |     0.79 |     1.90 |     2.46 |     3.17 |     1.16 | ... ||  12000 |     0.68 |     0.86 |     1.84 |     2.46 |     3.16 |     1.10 | ... ||  14000 |     0.59 |     0.75 |     1.78 |     2.45 |     3.15 |     1.05 | ... ||  16000 |     0.62 |     0.80 |     1.76 |     2.45 |     3.15 |     1.02 | ... ||  18000 |     0.59 |     0.79 |     1.73 |     2.43 |     3.12 |     1.01 | ... ||  20000 |     0.56 |     0.73 |     1.70 |     2.42 |     4.87 |     0.99 | ... ||  ||   size |      SVR |    elNet | ||   2000 |     2.32 |     3.18 | ||   4000 |     2.31 |     3.16 | ||   6000 |     2.18 |     3.25 | ||   8000 |     2.09 |     3.24 | ||  10000 |     2.03 |     3.21 | ||  12000 |     1.97 |     3.21 | ||  16000 |     1.92 |     3.20 | ||  16000 |     1.87 |     3.19 | ||  18000 |     1.83 |     3.17 | ||  20000 |     1.81 |     4.75 | ||  || FIT TIMES ||   size | Ensemble |      GBM |      KNN | Kern Rid |    Lasso | Random F | ||   2000 |     0:01 |     0:00 |     0:00 |     0:00 |     0:00 |     0:00 | ||   4000 |     0:02 |     0:00 |     0:00 |     0:00 |     0:00 |     0:00 | ||   6000 |     0:04 |     0:00 |     0:00 |     0:01 |     0:00 |     0:00 | ||   8000 |     0:06 |     0:00 |     0:00 |     0:04 |     0:00 |     0:00 | ||  10000 |     0:08 |     0:01 |     0:00 |     0:08 |     0:00 |     0:00 | ||  12000 |     0:09 |     0:01 |     0:00 |     0:12 |     0:00 |     0:00 | ||  14000 |     0:12 |     0:01 |     0:00 |     0:20 |     0:00 |     0:00 | ||  16000 |     0:16 |     0:02 |     0:00 |     0:34 |     0:00 |     0:00 | ||  18000 |     0:20 |     0:02 |     0:00 |     0:47 |     0:00 |     0:00 | ||  20000 |     0:25 |     0:02 |     0:00 |     1:20 |     0:00 |     0:00 | ||  ||   size |      SVR |    elNet | ||   2000 |     0:00 |     0:00 | ||   4000 |     0:00 |     0:00 | ||   6000 |     0:01 |     0:00 | ||   8000 |     0:02 |     0:00 | ||  10000 |     0:03 |     0:00 | ||  12000 |     0:04 |     0:00 | ||  16000 |     0:06 |     0:00 | ||  16000 |     0:08 |     0:00 | ||  18000 |     0:10 |     0:00 | ||  20000 |     0:13 |     0:00 | ||  || \""\""\""",,,Yes
13965,Set up main columns mapping,,Yes,Yes
13966,TODO:        self.scores_ = set_scores(self),,,Yes
13968,Set up main columns mapping,,Yes,Yes
13969,TODO:        self.scores_ = set_scores(self),,Yes,Yes
13970,Probably not the best way to do this but it does the trick,,No,Yes
13972,XXX: not handling dictionaries,,Yes,Yes
13974,FIXME: Needs a quality check!,,Yes,Yes
13975,Set up main columns mapping,,Yes,Yes
13976,Number of prediction columns depends on:,,No,Yes
13977,Finally; we sort summary in order of best performance,,Yes,Yes
13980,will change with every new kernel instance. This hack,,No,Yes
13981,Hack to detect functions not defined at the module-level,,,Yes
13982,TODO: Maybe add a warning here?,,,Yes
13983,XXX: Maybe I need an inspect.isbuiltin to detect C-level methods; such,,,Yes
13984,XXX: Return a sorted list of pairs?,,No,Yes
13986,XXX: Not using logging framework,,,Yes
13988,workaround is to view the array as bytes before,,Yes,Yes
13989,XXX: This conflicts with the debug flag used in children class,,Yes,Yes
13992,TODO: The following object should have a data store object as a sub,,No,Yes
13994,TODO: Same remark for the logger; and probably use the Python logging,,,Yes
13997,objects; as it ends up being too fragile,,No,Yes
13998,XXX: Should be using warnings; and giving stacklevel,,,Yes
14001,XXX: Bad explanation of the None value of cachedir,,,Yes
14002,_mk_exception. Note: in Python 2; if you implement __init__,,,Yes
14003,The next line set the .args correctly. This is needed to,,,Yes
14006,learn to use logger better.,,,Yes
14013,workaround is to view the array as bytes before,,Yes,Yes
14016,XXX: We should have a logging mechanism,,Yes,Yes
14017,batches. Better reduce the batch size a bit to limit the,,No,Yes
14018,workaround is to view the array as bytes before,,,Yes
14019,"Workaround  occasional \""[Error 5] Access is denied\"" issue",,,Yes
14024,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14026,In particular; the learner will populate the columns given in the,,Yes,Yes
14030,it can load when needed. To facilitate preprocessing across several learners;,,,Yes
14031,The output_columns can contain several entries if your indexer creates,,No,Yes
14032,In particular; the learner will populate the columns given in the,,Yes,Yes
14034,The output_columns can contain several entries if your indexer creates,,,Yes
14035,In particular; the learner will populate the columns given in the,,,Yes
14039,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14048,TODO: Fix table printing,,,Yes
14050,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
14051,The output_columns can contain several entries if your indexer creates,,,Yes
14052,In particular; the learner will populate the columns given in the,,Yes,Yes
14055,In particular; the learner will populate the columns given in the,,,Yes
14056,it can load when needed. To facilitate preprocessing across several learners;,,,Yes
14059,it can load when needed. To facilitate preprocessing across several learners;,,,Yes
14060,The output_columns can contain several entries if your indexer creates,,No,Yes
14061,In particular; the learner will populate the columns given in the,,Yes,Yes
14062,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14063,The output_columns can contain several entries if your indexer creates,,No,Yes
14064,In particular; the learner will populate the columns given in the,,,Yes
14065,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14066,The output_columns can contain several entries if your indexer creates,,No,Yes
14067,In particular; the learner will populate the columns given in the,,Yes,Yes
14068,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14070,In particular; the learner will populate the columns given in the,,Yes,Yes
14073,In particular; the learner will populate the columns given in the,,Yes,Yes
14074,it can load when needed. To facilitate preprocessing across several learners;,,Yes,Yes
14075,By passing a class labels; the plot shows how well separated different classes,,,Yes
14076,By passing a class labels; the plot shows how well separated different classes,,,Yes
14077,TODO: Refactor the formatting into a single function,,No,Yes
14080,TODO: refactor this using the '{}'.format() API,,No,Yes
14081,"\""\""\"" || .. _ensemble-tutorial: ||  || Advanced High-level API Tutorials || ================================= ||  || The following tutorials highlight advanced functionality and provide in-depth || material on ensemble APIs. ||  || ===============================  ============================================== || Tutorial                         Content || ===============================  ============================================== || :ref:`propa-tutorial`            Propagate feature input features through layers || \\                                to allow several layers to see the same input. || :ref:`proba-tutorial`            Build layers that output class probabilities from each base || \\                                learner so that the next layer or meta estimator learns || \\                                from probability distributions. || :ref:`subsemble-tutorial`        Learn homogenous partitions of feature space || \\                                that maximize base learner's performance on each partition. || :ref:`sequential-tutorial`       How to build ensembles with different layer classes || :ref:`memory-tutorial`           Avoid loading data into the parent process by specifying a || \\                                file path to a memmaped array or a csv file. || :ref:`model-selection-tutorial`  Build transformers that replicate layers in ensembles for || \\                                model selection of higher-order layers and \/ or meta learners. || ===============================  ============================================== ||  || We use the same preliminary settings as in the || :ref:`getting started <getting-started>` section. || \""\""\""",,Yes,Yes
14083,library of base learners gives a dramatic increase in performance on the test,,Yes,Yes
14084,better representation of the distribution and greatly facilitates the learning,,Yes,Yes
14086,By creating partitions; subsembles :ref:`scale significantly better <bench>`,,Yes,Yes
14087,only by luck that we happen to create such partitions. A better way is to,,,Yes
14089,number of partitions. Here's minimalist way of wrapping a Scikit-learn,,No,Yes
14091,index columns and footers.,,,Yes
14092,input is a mapping between partitions and output columns in the,,No,Yes
14093,efficient operation that introduce only a minor overhead on computation time.,,No,Yes
14094,for the learner to load when needed. To construct a learner with,,Yes,Yes
14095,dat_key is the estimators. Number of columns is not fixed so need,,,Yes
14096,Check which row name columns we can drop (ex partition number),,,Yes
14097,Check if there are empty columns,,Yes,Yes
14099,"\""\""\""ML-Ensemble ||  || :author: Sebastian Flennerhag || :copyright: 2017 || :licence: MIT ||  || Parallel processing job managers. || \""\""\""",,No,Yes
14102,TODO: should pop names when instance is destroyed and check if name taken,,No,Yes
14104,TODO: remove,,,Yes
14105,TODO: investigation of root cause is required.,,Yes,Yes
14106,TODO: Set should be used in line with specification (article); but list is not hashable object therefore it's impossible to use list in this fucking set!,,Yes,Yes
14107,Fix has been implemented in core.dbscan.,,,Yes
14112,TODO: This method is not ready yet,,,Yes
14115,TODO: Fix this fucking bug! It isn't displayed anymore!,,Yes,Yes
14116,TODO set random direction to agent,,Yes,Yes
14118,TODO: Check that it's right way for comparison,,No,Yes
14120,TODO: Rellocation is less complexity than sorting,,No,Yes
14121,"'''\r || \r || Cluster analysis algorithm: CURE\r || \r || Based on article description:\r ||  - S.Guha; R.Rastogi; K.Shim. \""CURE: An Efficient Clustering Algorithm for Large Databases\""; 1998\r || \r || Implementation: Andrei Novikov (spb.andr@yandex.ru)\r || \r || '''",,,Yes
14123,TODO: LEGION allocation of clusters should be reused for avoiding duplicated code.,,No,Yes
14124,TODO: LEGION allocation of clusters should be reused for avoiding duplicated code.,,,Yes
14125,'''\r || \r || Cluster analysis algorithm: BIRCH\r || \r || Based on article description:\r ||  - T.Zhang; R.Ramakrishnan; M.Livny. BIRCH: An Efficient Data Clustering Method for Very Large Databases. 1996.\r || \r || Implementation: Andrei Novikov (spb.andr@yandex.ru)\r || \r || ''',,No,Yes
14127,Fix unsupported image types using the PIL.,,Yes,Yes
14129,pass way too much stuff to a helper object to be reasonable.,,,Yes
14130,Create it ahead of time as it is cheap and it is ugly to declare it for both exception,,,Yes
14132,TODO: This methods should be scrapped as they are only called in one place. We should just,,Yes,Yes
14133,Probably need a better way to do this as currently we're only doing,,No,Yes
14135,Horrible hack to silence errors on filtering unicode objects,,No,Yes
14137,out when it is needed. This approach reflects the old code that was here but it wasn't,,,Yes
14138,commented (my fault.) I wonder if maybe the public and private declarations themselves can,,No,Yes
14139,out in a helper function. This feels fairly ugly due to the number of arguments. A forced,,,Yes
14140,Horrible hack to silence errors on filtering unicode objects,,No,Yes
14141,TODO: We should really return a docutils warning node here,,,Yes
14142,if needed,,,Yes
14143,"\""\""\""Does google-lint on c++ files. ||  || The goal of this script is to identify places in the code that *may* || be in non-compliance with google style.  It does not attempt to fix || up these problems -- the point is to educate.  It does also not || attempt to find all problems; or to ensure that everything it does || find is legitimately a problem. ||  || In particular; we can get very confused by \/* and \/\/ inside strings! || We do a small hack; which is to ignore \/\/'s with \""'s after them on the || same line; but it is far from perfect (in either direction). || \""\""\""",,,Yes
14145,In what way are we counting errors?,,Yes,Yes
14146,statements better.,,Yes,Yes
14151,though; so we punt on this one for now.  TODO.,,,Yes
14153,private; but needed to be public for implementation reasons.,,,Yes
14156,Logical and\/or operators.  This means the expression,,Yes,Yes
14158,it provides a way to workaround this warning for people who use,,No,Yes
14159,naming convention but not the include convention.,,Yes,Yes
14160,A call-by-reference parameter ends with '& identifier'.,,,Yes
14161,A call-by-const-reference parameter either ends with 'const& identifier',,,Yes
14162,convention of the whole function to process multiple line to handle it.,,Yes,Yes
14163,Function(int \/*unused_param*\/);,,,Yes
14164,the declarator ends and where the virt-specifier starts to avoid,,,Yes
14165,"Support the UNIX convention of using \""-\"" for stdin.  Note that",,,Yes
14166,We can't depend on os.linesep to determine what the desired,,Yes,Yes
14167,Add path to pyclustering package (much better to set PYTHONPATH).,,Yes,Yes
14169,very poor; therefore square root is used to improved.,,,Yes
14172,TODO: draw ellipes for each cluster using covariance matrix,,,Yes
14175,TODO: is_neighbor should consider density!,,Yes,Yes
14176,# TODO: do not use data,,No,Yes
14178,TODO: calculate it on C++ side as well,,No,Yes
14181,''' || Data visualization library || TODO pie; swarm; box plots || TODO for stacked area; just use df cumsum || ''',,,Yes
14183,TODO logger; with dedent,,Yes,Yes
14185,TODO auto file writer; resolve to sensible format,,Yes,Yes
14186,TODO refer to old exp util,,,Yes
14188,TODO new exp id needs to reflect DAG structure: its ancestors; use neo4j to store,,,Yes
14193,TODO switch to abs path of file,,,Yes
14194,TODO move interface logic from openai lab,,,Yes
14195,Move head pointer. Wrap around if necessary,,,Yes
14199,TODO need proper space resolution for multi-env,,,Yes
14200,TODO also spec needs to specify AEB space and bodies,,,Yes
14201,TODO do body num here,,,Yes
14202,analogously; do other dim counts as needed from env,,Yes,Yes
14203,TODO delegate a copy of variable like action_dim to agent too,,,Yes
14204,TODO save or smth,,No,Yes
14205,TODO should really move into somewhere in experiment module; cuz agent and environment modules really should be atomic and not worry much about multiplicities,,No,Yes
14206,TODO or just set properties for all these; no method,,,Yes
14207,TODO perhaps do extension like above again,,,Yes
14208,TODO expose brain methods properly to env,,,Yes
14212,TODO hook monitor to agent; env; then per update; auto fetches all that is in background,,Yes,Yes
14213,TODO call update in session; trial; experiment loops to collect data visible there too; for unit_data,,Yes,Yes
14216,TODO link in AEB space properly,,Yes,Yes
14221,TODO compose episode data from monitor update; is just session_data[episode],,,Yes
14226,TODO rename hyper-everthing without hyper,,,Yes
14228,TODO maybe not create new dict per episode and timestep for complexity,,,Yes
14229,TODO or every stage the class instance shd hold its own hyperindex that ends at its axis,,,Yes
14230,TODO increment pattern in break down in AEB,,,Yes
14232,TODO set proper pattern,,Yes,Yes
14233,TODO temp set monitor method in session,,,Yes
14236,TODO AEB space resolver; lineup index,,,Yes
14237,TODO save or smth,,,Yes
14240,TODO need a mechanism that compose the components together using spec,,,Yes
14241,TODO AEB space resolver pending; needs to be powerful enuf to for auto-architecture; action space; body num resolution; other dim counts from env,,Yes,Yes
14242,TODO implement generic method,,Yes,Yes
14244,TODO link in AEB space properly,,Yes,Yes
14245,TODO maybe stop at timestep since episode is the lowest sensible refinement of data without bloat,,Yes,Yes
14246,TODO maybe not create new dict per episode and timestep for complexity,,,Yes
14247,TODO or every stage the class instance shd hold its own data_coor that ends at its axis,,No,Yes
14250,TODO trial data checker method,,,Yes
14253,TODO session data checker method,,,Yes
14254,TODO trial data checker method,,,Yes
14256,TODO ok need architecture spec for each agent: disjoint or joint; time or space multiplicity,,,Yes
14257,TODO then for high level call; update active_eb_coor (switch focus body); call atomic methods,,,Yes
14259,TODO also resolve architecture and data input; output dims via some architecture spec,,Yes,Yes
14260,TODO tmp make act across bodies,,Yes,Yes
14262,TODO rename method args to space,,Yes,Yes
14263,TODO tmp; resolve later from AEB,,Yes,Yes
14265,TODO tmp,,No,Yes
14268,TODO rename method args to space,,Yes,Yes
14271,TODO tmp hack till env properly carries its own max timestep,,,Yes
14275,TODO generalize and make state to include observables,,,Yes
14280,TODO need to assert when accessing index data_proj[idx] idx != -1,,Yes,Yes
14282,TODO AEB needs to check agent output dim is sufficient,,,Yes
14285,TODO construct the AEB space proj to A; E from spec,,Yes,Yes
14287,TODO call update in session; trial; experiment loops to collect data visible there too; for unit_data,,Yes,Yes
14289,TODO check aeb_space body index increasing for the same AE pair (no skip),,Yes,Yes
14290,TODO tmp,,No,Yes
14291,TODO rename method args to space,,Yes,Yes
14292,TODO merge OpenAI Env in SLM Lab,,,Yes
14293,TODO metaspec to specify specs to run; can be sourced from evolution suggestion,,Yes,Yes
14295,TODO discrete int,,No,Yes
14301,TODO standardize sample method,,,Yes
14303,TODO also for multi state; multi actions per body; need to be 3D,,Yes,Yes
14304,TODO store directly from data_space?,,Yes,Yes
14306,TODO this is still single body,,,Yes
14307,Move head pointer. Wrap around if necessary,,Yes,Yes
14308,self.actions[self.head] = one hot of multi-action (matrix) on a 3rd axis; to be implement,,,Yes
14310,TODO shove,,No,Yes
14312,TODO tmp; single body (last); use monitor later,,Yes,Yes
14313,TODO can handle identical bodies now; to use body_net for specific body.,,,Yes
14314,TODO tmp return; to unify with monitor auto-fetch later,,Yes,Yes
14317,''' || Functions used by more than one algorithm || TODO refactor properly later || ''',,,Yes
14318,TODO auto-architecture to handle multi-head; multi-tail nets,,,Yes
14319,TODO adjust learning rate http:\/\/pytorch.org\/docs\/master\/optim.html#how-to-adjust-learning-rate,,Yes,Yes
14320,TODO hackish optimizer learning rate; also it fails for SGD wtf,,,Yes
14322,TODO hack add,,Yes,Yes
14323,TODO rename this as action_net or policy_net,,,Yes
14325,TODO handle this with better design,,Yes,Yes
14326,TODO Generalize to more than two tasks,,Yes,Yes
14327,TODO when backprop need to use relevant r too,,No,Yes
14328,TODO add warning that memory is env-specific now,,Yes,Yes
14330,TODO cant we do like tf?: layers.fully_connected(out; num_outputs=hidden; activation_fn=None),,Yes,Yes
14331,TODO hack for mismaching env timesteps,,Yes,Yes
14332,TODO tick body clock,,No,Yes
14333,TODO hack for a reliable done; otherwise all needs to be coincidental,,,Yes
14335,TODO monitor record all data spaces; including body with body.clock. cuz all data spaces have history,,Yes,Yes
14337,fix offset in cumsum (True entry belongs to the chunk before it),,,Yes
14340,TODO allow list in auto-expansion,,Yes,Yes
14342,TODO standardize agent and env print self,,Yes,Yes
14344,TODO uhh what's this?,,No,Yes
14345,TODO rename this as action_net or policy_net,,Yes,Yes
14346,TODO: Check this is working,,,Yes
14347,TODO when backprop need to use relevant r too,,,Yes
14349,TODO more concise creation using nn.Sequential,,No,Yes
14350,TODO experiment to find out optimal benchmarking max_timestep; set,,Yes,Yes
14353,TODO since u have to create anyway; why not just use a canonical form as standard,,,Yes
14356,TODO internalize render code,,No,Yes
14357,TODO write file properly once session_data is in tabular form,,No,Yes
14358,TODO form proper session data for plot and return,,Yes,Yes
14359,TODO generalize and make state_space to include observables,,Yes,Yes
14360,TODO rewrite this whole shit,,,Yes
14364,TODO save full data to db,,,Yes
14365,TODO form proper session data for plot and return,,Yes,Yes
14367,TODO Handle returning all explore vars,,,Yes
14368,TODO: Return other losses as well.,,,Yes
14370,TODO generalize to use experiment timestamp; id; sesison coor in info space; to replace timestamp,,Yes,Yes
14371,TODO generalize to take different search algo,,Yes,Yes
14372,TODO proper id from top level,,,Yes
14378,TODO sort experiment_df,,,Yes
14379,TODO timesteps = episode len or total_t from space_clock,,Yes,Yes
14380,TODO use hyperband,,,Yes
14381,TODO use advanced conditional config space via lambda func,,Yes,Yes
14382,# TODO session data checker method,,Yes,Yes
14384,# TODO experiment data checker method,,Yes,Yes
14387,TODO session data checker method,,Yes,Yes
14389,TODO experiment data checker method,,Yes,Yes
14393,TODO put reporter into info space so it can be called to update. easy.,,,Yes
14396,TODO remove when analysis can save all plotly plots,,,Yes
14397,TODO remove when plotly can save all,,Yes,Yes
14400,Convert actions to one hot (both representations are needed for SARSA),,,Yes
14401,to fix ray consecutive run crash due to bad cleanup,,Yes,Yes
14402,Hack to keep size of data storage small - only store most recent state,,,Yes
14403,TODO fix access to info_space then set below,,No,Yes
14407,TODO fix scope using prepath name,,,Yes
14408,TODO dont hard code activation,,,Yes
14410,TODO not encountered yet; generalization needed,,Yes,Yes
14413,TODO make proper and general: log first reward,,Yes,Yes
14414,TODO add beta distribution,,Yes,Yes
14417,TODO move away from list-based construction API; too many things to keep track off and might drop the ball,,,Yes
14420,TODO call these from inside memory; always return torch batch,,,Yes
14421,TODO tmp correction. state_a has 1 dim too deep,,Yes,Yes
14423,TODO generalize for multi-action,,Yes,Yes
14424,TODO generalize Replay to take data_keys,,No,Yes
14427,TODO move away from space,,,Yes
14428,TODO also create shared optimizer here,,,Yes
14430,TODO implement clock_speed: step only if self.clock.to_step(),,No,Yes
14431,TODO disable for now,,,Yes
14434,TODO In future; need to update action to handle (continuous) DELTA buttons using gym's Box space,,Yes,Yes
14438,TODO remove,,,Yes
14439,TODO fix with entropy anneal generalization,,Yes,Yes
14440,TODO decay clip_eps along with entropy,,Yes,Yes
14441,TODO fix with entropy anneal generalization,,Yes,Yes
14442,TODO rewrite Q-value loss compute to use max,,Yes,Yes
14443,TODO fancy sampling only took early experiences somehow. could be due to binning stuff,,Yes,Yes
14445,TODO restore per,,Yes,Yes
14446,TODO restore per,,,Yes
14450,hack around bad Ray design of hard-coding,,Yes,Yes
14451,TODO fractional ray_gpu is broken,,Yes,Yes
14459,TODO figure out a way to cycle CUDA id,,,Yes
14460,TODO ckpt and eval not implemented for SpaceSession,,Yes,Yes
14461,TODO shifting is expensive. rewrite,,Yes,Yes
14462,TODO change this to one slicable layer for efficiency,,,Yes
14464,TODO update Unity ml-agents to use seed=seed below,,,Yes
14467,TODO retire this,,,Yes
14468,TODO sample minibatch from batch with size < length of batch,,,Yes
14469,TODO downcast to dtype,,,Yes
14471,TODO downcast to dtype,,,Yes
14472,TODO This is unsafe,,No,Yes
14473,TODO retrieve lr more generally,,No,Yes
14474,TODO unify these later,,,Yes
14475,can't use Pool since it cannot spawn nested Process; which is needed for VecEnv and parallel sessions. So these will run and wait by chunks,,Yes,Yes
14476,TODO check if below is really needed?,,,Yes
14477,TODO expand to be more comprehensive,,,Yes
14478,hack to mute poorly designed ray TF warning log,,No,Yes
14480,TODO also create shared optimizer here,,,Yes
14481,TODO add method in net_util,,Yes,Yes
14482,naming convention,,Yes,Yes
14483,local net name by naming convention,,,Yes
14484,naming convention,,Yes,Yes
14485,TODO expand to be more comprehensive,,No,Yes
14487,TODO rework unity outdated,,,Yes
14488,hack to mute poorly designed ray TF warning log,,,Yes
14489,can't use Pool since it cannot spawn nested Process; which is needed for VecEnv and parallel sessions. So these will run and wait by chunks,,,Yes
14490,TODO track both total_reward and episodic total reward,,,Yes
14492,TODO support multi-discrete actions,,Yes,Yes
14494,TODO: add n_init option,,,Yes
14495,TODO: The following is ugly; I just do not know why using inheritance does not work (KMeans.fit(self; X_; y)),,Yes,Yes
14496,TODO: cythonize,,Yes,Yes
14497,TODO: Shape Extraction (Alg. 2 in paper),,Yes,Yes
14498,TODO using Alg. 1,,Yes,Yes
14499,TODO: provide norms,,Yes,Yes
14500,TODO using Alg. 1,,Yes,Yes
14502,Needed to deal with edge cases in the recursion.,,Yes,Yes
14503,TODO: gamma auto,,Yes,Yes
14506,TODO: not great,,Yes,Yes
14507,TODO: gamma,,Yes,Yes
14509,columns = range(tuple(shape)[2]),,,Yes
14513,TODO: the clustering algorithm can handle it.,,,Yes
14514,TODO: make this exception more specific,,,Yes
14515,TODO: What is difference check_equal_size <--> this?,,No,Yes
14518,# TODO: copying this and applying predict directly will cause crashes.,,,Yes
14519,# TODO: It is currently here bcs of an sklearn requirement to NOT,,Yes,Yes
14522,# TODO: <tslearn.svm.GAKKernel object at 0x7f1a84d9b860> during fit.,,Yes,Yes
14524,TODO: Remove what's below,,No,Yes
14525,TODO: Remove the above,,Yes,Yes
14527,TODO: better doc (formula for the kernel),,No,Yes
14528,TODO,,Yes,Yes
14531,TODO: unequal-length case???,,,Yes
14532,TODO: weight is ignored for now,,,Yes
14535,Maybe shall right indice_ck_cm rather than ck_cm; dunno what ck_cm is,,,Yes
14536,Ugly hack; not sure how to to it better,,Yes,Yes
14537,"\""\""\"" || KShape || ====== ||  || This example uses the KShape clustering method [1] that is based on || cross-correlation to cluster time series. ||  ||  || [1] J. Paparrizos & L. Gravano. k-Shape: Efficient and Accurate Clustering \\ || of Time Series. SIGMOD 2015. pp. 1855-1870. || \""\""\""",,Yes,Yes
14539,normalize parameter seems to be quite recent in sklearn;,,Yes,Yes
14541,normalize parameter seems to be quite recent in sklearn;,,Yes,Yes
14542,XXX: numerical imprecision can result in a candidate_id out of range,,Yes,Yes
14543,Permanently add best center candidate found in local tries,,,Yes
14544,TODO: add a check that ensures that cluster centers maintain their,,Yes,Yes
14545,TODO: probably we could remove multioutput since it should be inherited from sklearn parent class,,Yes,Yes
14548,Then maybe it was rather a list of arrays,,,Yes
14551,TODO: only if possible,,No,Yes
14552,Then maybe it was rather a list of arrays,,No,Yes
14554,TODO: v2-compatible initializer,,Yes,Yes
14555,Then maybe it was rather a list of arrays,,No,Yes
14558,"''' || >>> from pycm import * || >>> import os || >>> import json || >>> y_actu = [2; 0; 2; 2; 0; 1; 1; 2; 2; 0; 1; 2] || >>> y_pred = [0; 0; 2; 1; 0; 2; 1; 0; 2; 0; 2; 2] || >>> cm = ConfusionMatrix(y_actu; y_pred) || >>> cm.relabel({0:\""L1\"";1:\""L2\"";2:\""L3\""}) || >>> pycm_help() || <BLANKLINE> || PyCM is a multi-class confusion matrix library written in Python that || supports both input data vectors and direct matrix; and a proper tool for || post-classification model evaluation that supports most classes and overall || statistics parameters. || PyCM is the swiss-army knife of confusion matrices; targeted mainly at || data scientists that need a broad array of metrics for predictive models || and an accurate evaluation of large variety of classifiers. || <BLANKLINE> || Repo : https:\/\/github.com\/sepandhaghighi\/pycm || Webpage : http:\/\/www.pycm.ir || <BLANKLINE> || <BLANKLINE> || >>> RCI_calc(24;0) || 'None' || >>> CBA_calc([1;2]; {1:{1:0;2:0};2:{1:0;2:0}}; {1:0;2:0}; {1:0;2:0}) || 'None' || >>> RR_calc([]; {1:0;2:0}) || 'None' || >>> overall_MCC_calc([1;2]; {1:{1:0;2:0};2:{1:0;2:0}}; {1:0;2:0}; {1:0;2:0}) || 'None' || >>> CEN_misclassification_calc({1:{1:0;2:0};2:{1:0;2:0}};{1:0;2:0};{1:0;2:0};1;1;2) || 'None' || >>> vector_check([1;2;3;0.4]) || False || >>> vector_check([1;2;3;-2]) || False || >>> matrix_check({1:{1:0.5;2:0};2:{1:0;2:0}}) || False || >>> matrix_check([]) || False || >>> TTPN_calc(0;0) || 'None' || >>> TTPN_calc(1;4) || 0.2 || >>> FXR_calc(None) || 'None' || >>> FXR_calc(0.2) || 0.8 || >>> ACC_calc(0;0;0;0) || 'None' || >>> ACC_calc(1;1;3;4) || 0.2222222222222222 || >>> MCC_calc(0;2;0;2) || 'None' || >>> MCC_calc(1;2;3;4) || -0.408248290463863 || >>> LR_calc(1;2) || 0.5 || >>> LR_calc(1;0) || 'None' || >>> MK_BM_calc(2;\""None\"") || 'None' || >>> MK_BM_calc(1;2) || 2 || >>> PRE_calc(None;2) || 'None' || >>> PRE_calc(1;5) || 0.2 || >>> PRE_calc(1;0) || 'None' || >>> G_calc(None;2) || 'None' || >>> G_calc(1;2) || 1.4142135623730951 || >>> RACC_calc(2;3;4) || 0.375 || >>> reliability_calc(1;None) || 'None' || >>> reliability_calc(2;0.3) || 1.7 || >>> micro_calc({1:2;2:3};{1:1;2:4}) || 0.5 || >>> micro_calc({1:2;2:3};None) || 'None' || >>> macro_calc(None) || 'None' || >>> macro_calc({1:2;2:3}) || 2.5 || >>> F_calc(TP=0;FP=0;FN=0;Beta=1) || 'None' || >>> F_calc(TP=3;FP=2;FN=1;Beta=5) || 0.7428571428571429 || >>> ERR_calc(None) || 'None' || >>> ERR_calc(0.1) || 0.9 || >>> cm.F_beta(4)[\""L1\""] || 0.9622641509433962 || >>> cm.F_beta(4)[\""L2\""] || 0.34 || >>> cm.F_beta(4)[\""L3\""] || 0.504950495049505 || >>> kappa_analysis_koch(-0.1) || 'Poor' || >>> kappa_analysis_koch(0) || 'Slight' || >>> kappa_analysis_koch(0.2) || 'Fair' || >>> kappa_analysis_koch(0.4) || 'Moderate' || >>> kappa_analysis_koch(0.6) || 'Substantial' || >>> kappa_analysis_koch(0.8) || 'Almost Perfect' || >>> kappa_analysis_koch(1.2) || 'None' || >>> kappa_analysis_fleiss(0.4) || 'Intermediate to Good' || >>> kappa_analysis_fleiss(0.75) || 'Excellent' || >>> kappa_analysis_fleiss(1.2) || 'Excellent' || >>> kappa_analysis_altman(-0.2) || 'Poor' || >>> kappa_analysis_altman(0.2) || 'Fair' || >>> kappa_analysis_altman(0.4) || 'Moderate' || >>> kappa_analysis_altman(0.6) || 'Good' || >>> kappa_analysis_altman(0.8) || 'Very Good' || >>> kappa_analysis_altman(1.2) || 'None' || >>> kappa_analysis_fleiss(0.2) || 'Poor' || >>> kappa_analysis_cicchetti(0.3) || 'Poor' || >>> kappa_analysis_cicchetti(0.5) || 'Fair' || >>> kappa_analysis_cicchetti(0.65) || 'Good' || >>> kappa_analysis_cicchetti(0.8) || 'Excellent' || >>> PLR_analysis(1) || 'Negligible' || >>> PLR_analysis(3) || 'Poor' || >>> PLR_analysis(7) || 'Fair' || >>> PLR_analysis(11) || 'Good' || >>> DP_analysis(0.2) || 'Poor' || >>> DP_analysis(1.5) || 'Limited' || >>> DP_analysis(2.5) || 'Fair' || >>> DP_analysis(10) || 'Good' || >>> AUC_analysis(0.5) || 'Poor' || >>> AUC_analysis(0.65) || 'Fair' || >>> AUC_analysis(0.75) || 'Good' || >>> AUC_analysis(0.86) || 'Very Good' || >>> AUC_analysis(0.97) || 'Excellent' || >>> AUC_analysis(1.0) || 'Excellent' || >>> PC_PI_calc(1;1;1) || 'None' || >>> PC_PI_calc({1:12};{1:6};{1:45}) || 0.04000000000000001 || >>> PC_AC1_calc(1;1;1) || 'None' || >>> PC_AC1_calc({1:123;2:2};{1:120;2:5};{1:125;2:125}) || 0.05443200000000002 || >>> y_act=[0;0;0;0;0;0;0;0;0;0;0;0;1;1;1;1;1;1;1;1;1;2;2;2;2;2;2] || >>> y_pre=[0;0;0;0;0;0;0;0;0;1;1;1;0;0;0;1;1;1;1;1;2;0;1;2;2;2;2] || >>> cm2=ConfusionMatrix(y_act;y_pre) || >>> chi_squared=chi_square_calc(cm2.classes;cm2.table;cm2.TOP;cm2.P;cm2.POP) || >>> chi_squared || 15.525641025641026 || >>> population = list(cm2.POP.values())[0] || >>> phi_squared=phi_square_calc(chi_squared;population) || >>> phi_squared || 0.5750237416904084 || >>> V=cramers_V_calc(phi_squared;cm2.classes) || >>> V || 0.5362013342441477 || >>> DF=DF_calc(cm2.classes) || >>> DF || 4 || >>> SE=se_calc(cm2.Overall_ACC;population) || >>> SE || 0.09072184232530289 || >>> CI=CI_calc(cm2.Overall_ACC;SE) || >>> CI || (0.48885185570907297; 0.8444814776242603) || >>> response_entropy=entropy_calc(cm2.TOP;cm2.POP) || >>> response_entropy || 1.486565953154142 || >>> reference_entropy=entropy_calc(cm2.P;cm2.POP) || >>> reference_entropy || 1.5304930567574824 || >>> cross_entropy = cross_entropy_calc(cm2.TOP;cm2.P;cm2.POP) || >>> cross_entropy || 1.5376219392005763 || >>> join_entropy = joint_entropy_calc(cm2.classes;cm2.table;cm2.POP) || >>> join_entropy || 2.619748965432189 || >>> conditional_entropy = conditional_entropy_calc(cm2.classes;cm2.table;cm2.P;cm2.POP) || >>> conditional_entropy || 1.089255908674706 || >>> kl_divergence=kl_divergence_calc(cm2.P;cm2.TOP;cm2.POP) || >>> kl_divergence || 0.007128882443093773 || >>> lambda_B=lambda_B_calc(cm2.classes;cm2.table;cm2.TOP;population) || >>> lambda_B || 0.35714285714285715 || >>> lambda_A=lambda_A_calc(cm2.classes;cm2.table;cm2.P;population) || >>> lambda_A || 0.4 || >>> IS_calc(13;0;0;38) || 1.5474877953024933 || >>> kappa_no_prevalence_calc(cm2.Overall_ACC) || 0.33333333333333326 || >>> reliability_calc(cm2.Overall_RACC;cm2.Overall_ACC) || 0.4740259740259741 || >>> mutual_information_calc(cm2.ResponseEntropy;cm2.ConditionalEntropy) || 0.39731004447943596 || >>> cm3=ConfusionMatrix(matrix=cm2.table) || >>> cm3 || pycm.ConfusionMatrix(classes: [0; 1; 2]) || >>> cm3.CI || (0.48885185570907297; 0.8444814776242603) || >>> cm3.Chi_Squared || 15.525641025641026 || >>> cm3.Phi_Squared || 0.5750237416904084 || >>> cm3.V || 0.5362013342441477 || >>> cm3.DF || 4 || >>> cm3.ResponseEntropy || 1.486565953154142 || >>> cm3.ReferenceEntropy || 1.5304930567574824 || >>> cm3.CrossEntropy || 1.5376219392005763 || >>> cm3.JointEntropy || 2.619748965432189 || >>> cm3.ConditionalEntropy || 1.089255908674706 || >>> cm3.KL || 0.007128882443093773 || >>> cm3.LambdaA || 0.4 || >>> cm3.LambdaB || 0.35714285714285715 || >>> online_help(param=None) || Please choose one parameter : || <BLANKLINE> || Example : online_help(\""J\"") or online_help(2) || <BLANKLINE> || 1-95% CI || 2-ACC || 3-AUC || 4-AUCI || 5-AUNP || 6-AUNU || 7-BM || 8-Bennett S || 9-CBA || 10-CEN || 11-Chi-Squared || 12-Chi-Squared DF || 13-Conditional Entropy || 14-Cramer V || 15-Cross Entropy || 16-DOR || 17-DP || 18-DPI || 19-ERR || 20-F0.5 || 21-F1 || 22-F2 || 23-FDR || 24-FN || 25-FNR || 26-FOR || 27-FP || 28-FPR || 29-G || 30-GI || 31-Gwet AC1 || 32-Hamming Loss || 33-IS || 34-J || 35-Joint Entropy || 36-KL Divergence || 37-Kappa || 38-Kappa 95% CI || 39-Kappa No Prevalence || 40-Kappa Standard Error || 41-Kappa Unbiased || 42-LS || 43-Lambda A || 44-Lambda B || 45-MCC || 46-MCEN || 47-MK || 48-Mutual Information || 49-N || 50-NIR || 51-NLR || 52-NPV || 53-Overall ACC || 54-Overall CEN || 55-Overall J || 56-Overall MCC || 57-Overall MCEN || 58-Overall RACC || 59-Overall RACCU || 60-P || 61-P-Value || 62-PLR || 63-PLRI || 64-POP || 65-PPV || 66-PPV Macro || 67-PPV Micro || 68-PRE || 69-Phi-Squared || 70-RACC || 71-RACCU || 72-RCI || 73-RR || 74-Reference Entropy || 75-Response Entropy || 76-SOA1(Landis & Koch) || 77-SOA2(Fleiss) || 78-SOA3(Altman) || 79-SOA4(Cicchetti) || 80-Scott PI || 81-Standard Error || 82-TN || 83-TNR || 84-TON || 85-TOP || 86-TP || 87-TPR || 88-TPR Macro || 89-TPR Micro || 90-Y || 91-Zero-one Loss || 92-dInd || 93-sInd || >>> online_help(\""J\"") || ... || >>> online_help(4) || ... || >>> NIR_calc({'Class2': 804; 'Class1': 196};1000) # Verified Case || 0.804 || >>> cm = ConfusionMatrix(matrix={0:{0:3;1:1};1:{0:4;1:2}})   # Verified Case || >>> cm.LS[1] || 1.1111111111111112 || >>> cm.LS[0] || 1.0714285714285714 || >>> cm = ConfusionMatrix(matrix={\""Class1\"":{\""Class1\"":183;\""Class2\"":13};\""Class2\"":{\""Class1\"":141;\""Class2\"":663}})  # Verified Case || >>> cm.PValue || 0.000342386296143693 || >>> cm = ConfusionMatrix(matrix={\""Class1\"":{\""Class1\"":4;\""Class2\"":2};\""Class2\"":{\""Class1\"":2;\""Class2\"":4}}) # Verified Case || >>> cm.Overall_CEN || 0.861654166907052 || >>> cm.Overall_MCEN || 0.6666666666666666 || >>> cm.IS[\""Class1\""] || 0.4150374992788437 || >>> cm.IS[\""Class2\""] || 0.4150374992788437 || >>> cm = ConfusionMatrix(matrix={1:{1:5;2:0;3:0};2:{1:0;2:10;3:0};3:{1:0;2:300;3:0}})  # Verified Case || >>> cm.Overall_CEN || 0.022168905807495587 || >>> cm.Overall_MCC || 0.3012440235352457 || >>> cm.CBA || 0.3440860215053763 || >>> cm = ConfusionMatrix(matrix={1:{1:1;2:3;3:0;4:0};2:{1:9;2:1;3:0;4:0};3:{1:0;2:0;3:100;4:0};4:{1:0;2:0;3:0;4:200}}) # Verified Case || >>> cm.RCI || 0.9785616782831341 || >>> cm = ConfusionMatrix(matrix={1:{1:1;2:0;3:3};2:{1:0;2:100;3:0};3:{1:0;2:0;3:200}}) # Verified Case || >>> cm.RCI || 0.9264007150415143 || >>> cm = ConfusionMatrix(matrix={1:{1:5;2:0;3:0};2:{1:0;2:10;3:0};3:{1:0;2:300;3:0}}) || >>> cm.RCI || 0.3675708571923818 || >>> cm = ConfusionMatrix(matrix={1:{1:12806;2:26332};2:{1:5484;2:299777}};transpose=True) # Verified Case || >>> cm.AUC[1] || 0.8097090079101759 || >>> cm.GI[1] || 0.6194180158203517 || >>> cm.Overall_ACC || 0.9076187793808925 || >>> cm.DP[1] || 0.7854399677022138 || >>> cm.Y[1] || 0.6194180158203517 || >>> cm.BM[1] || 0.6194180158203517 || >>> cm = ConfusionMatrix(matrix={1:{1:13182;2:30516};2:{1:5108;2:295593}};transpose=True) # Verified Case || >>> cm.AUC[1] || 0.8135728157964055 || >>> cm.GI[1] || 0.627145631592811 || >>> cm.Overall_ACC || 0.896561836706843 || >>> cm.DP[1] || 0.770700985610517 || >>> cm.Y[1] || 0.627145631592811 || >>> cm.BM[1] || 0.627145631592811 || '''",,,Yes
14559,TODO: remove and use utils.classes implementation,,,Yes
14564,TODO: update requires,,,Yes
14567,TODO: versioning,,No,Yes
14568,TODO: versioning,,No,Yes
14571,TODO: is there a cleaner way to do this?,,No,Yes
14572,TODO: might want to break this out of the partial,,,Yes
14574,Author: Abhi Sivasailam < your email here >,,Yes,Yes
14578,TODO: remove and use utils.classes implementation,,,Yes
14582,TODO: use scipy sparse matrices,,Yes,Yes
14584,#TODO: PASSED,,No,Yes
14586,# TODO: implement this below,,,Yes
14587,TODO: use scipy sparse matrices,,Yes,Yes
14588,TODO: NOT PASSED,,No,Yes
14590,TODO,,Yes,Yes
14592,Need to make the number of hidden units configurable,,Yes,Yes
14594,TODO: Write docs,,,Yes
14595,TODO: Handle stereo files,,Yes,Yes
14597,TODO: Handle other sample rates by re-sampling,,No,Yes
14600,KLUDGE: This is copied straight from zounds\/onsets.py,,Yes,Yes
14607,TODO: Write Docs,,,Yes
14608,TODO: ExtractorChains need to know about _id; so they can create,,Yes,Yes
14609,a list of other extractors needed by this one,,Yes,Yes
14611,TODO: Derived classes shouldn't have to know to set done to,,,Yes
14612,TODO: Sum extractor with a step size of 2,,No,Yes
14615,TODO: Implement Pitch; BFCC; Centroid; Flatness; Bark; Tempo; Chroma;,,,Yes
14620,KLUDGE: This feels like kind of a stupid test; since the behavior,,Yes,Yes
14621,TODO: package up these activation functions somehow,,Yes,Yes
14622,a list of other extractors needed by this one,,,Yes
14627,factored out into a *better*; common location?,,Yes,Yes
14628,TODO: Write documentation,,Yes,Yes
14631,Possible KLUDGE: Creating a dictionary with a subset of class,,Yes,Yes
14634,been built by the time they're needed by another extractor,,,Yes
14635,TODO: This has to work with multi-threaded and\/or multi-process applications,,Yes,Yes
14636,TODO: This should be an abstract base class,,No,Yes
14638,TODO: Chain should be a function that can create an appropriate,,,Yes
14642,KLUDGE: I have to pass a filename to build an extractor chain;,,,Yes
14644,TODO: How do I switch between read and write modes as necessary in a,,,Yes
14645,KLUDGE: PyTables allows the creation of columns using a string,,Yes,Yes
14647,KLUDGE: This should be somehow determined by FrameModel also,,Yes,Yes
14648,TODO: Set a flag that lets everyone know we're writing,,,Yes
14649,TODO: Write documentation,,Yes,Yes
14650,TODO: Consider moving this out of __init__,,Yes,Yes
14654,BUG: This won't work. A span of frames should,,Yes,Yes
14656,TODO: Factor out 36-length string dtype here,,,Yes
14658,KLUDGE: This is a bit odd.   The RawAudio extractor is telling,,Yes,Yes
14660,TODO: Call the FrameController sync() method. This should:,,Yes,Yes
14661,TODO: This should return a Frames-derived instance,,No,Yes
14662,TODO: Deal with multiple concurrent processes,,Yes,Yes
14665,"''' || A leaf pattern represents a block of contiguous; ascending (in time) frames in the frames || database. ||  || A branch pattern contains \""pointers\"" to leaf patterns (or contiguous subsets of them);  || or other branch patterns. ||  || An audio_event; in the parlance of zounds 1; is a branch pattern that points at || {_id : 1234; source : 'FreeSound'; external_id : '9'}[100:200]; e.g.. This means ||  that there can be pattern ids in the patterns database that don't exist in the ||  frames database. ||  || If a user creates a non-contiguous leaf pattern; this pattern should be appended || to the frames database so that it becomes contiguous; e.g.; the pattern  || [10;30;1;16] would be appended to the end of the frames database with a new id; || a source equal to the user's name; a new external id; and an address equal to || [original_db_length : original_db_length + 4] ||  || There needs to be a level of indirection regarding the address space. Row numbers || might not be appropriate to every conceivable backing store. ||  || BUG: Consider a branch pattern whose phenotype is one measure of the same hihat || sound playing eighth-notes.  This pattern is two-deep. It consists of a single || branch pattern; repeated; which points at a slice of an original; longer sound. || If it is to be a candidate for similarity searches; it must be analyzed and saved || to the frames database. ||  || BUG: What if I edit the aforementioned pattern so that its length changes; or || I delete it?  That means that the addresses of all patterns following it in the || frames database also change; which means all patterns following it must be updated. ||  || BUG: What if I make small changes to a pattern? Must it be re-stored?  What  || about patterns that reference it?  The dumb solution seems to be to always || re-store it; so that I don't have to worry about updating pattern references; || but won't this lead to a very large frames database full of redundant info? ||  || BUG: Consider the last; musical pattern below. What if I simply repeated it || four times (ie; four measures of four quarter notes each)?  Would it be  || re-stored? ||  || \/\/ Leaf Pattern || leaf = { ||     _id         : leaf_uuid; ||     source      : 'FreeSound'; ||     external_id : '9'; ||     ancestors   : (); ||     address     : (start;stop) OR (_id) || } ||  || \/\/ Audio-Event-like pattern. This would not be re-stored; since it represents || \/\/ a single occurrence of a block of contiguous; ascending frames || ae = { ||     _id         : branch_uuid; ||     source      : 'John'; ||     external_id : other_uuid; ||     ancestors   : (leaf_uuid) ||     address     : (start;stop)  || } ||  || \/\/ Musical Patern. This would be re-stored; since it represents multiple  || \/\/ occurrences of a contiguous block. || m = { ||     _id         : music_uuid; ||     source      : 'John'; ||     external_id : other_uuid; ||     ancestors   : (leaf_uuid;branch_uuid); ||     address     : (start;stop); ||     pattern     : [ ||         { ||             time : [0;1;2;3]; ||             _id  : branch_uuid ||         } ||     ]  || } || '''",,Yes,Yes
14669,Here's the less simple workaround,,,Yes
14671,TODO: Write better documentation,,Yes,Yes
14674,TODO: Should this return a slice of the _data recarray; or,,,Yes
14680,TODO: Rename the classes in this file in the correct way;,,Yes,Yes
14684,be sampled; ignoring pattern boundaries and the tail end of the frames,,Yes,Yes
14688,TODO: Ensure path exists method in util. Factor out of,,Yes,Yes
14689,TODO: Define __getitem__ on class,,Yes,Yes
14690,KLUDGE: This is a bit odd.   The RawAudio extractor is telling,,Yes,Yes
14691,TODO: Group into batches!,,No,Yes
14693,KLUDGE: We're in a situation where the old feature doesn't,,Yes,Yes
14695,happens in PyTablesFramesController. Maybe it can be factored out.,,Yes,Yes
14696,TODO: This should also take an address; and take advantage of precomputed,,,Yes
14699,Crazy Bad KLUDGE: I rely on FrameController-derived classes to define a back-end,,,Yes
14700,KLUDGE: I'm doing this because SingleInput-derived extractors,,Yes,Yes
14701,KLUDGE: How do I know *exactly* how long to make the sparse matrix,,,Yes
14703,keep track of scores in an array where columns represent,,,Yes
14704,blocks; and columns represent the n best matches for that block,,Yes,Yes
14706,TODO: do updates,,No,Yes
14708,KLUDGE: I've excluded int -> int comparisons,,Yes,Yes
14711,KLUDGE: This is cheating. I'm using knowledge about the frames back-end,,,Yes
14712,BUG: What if indim isn't evenly divisible by nprocesses?,,,Yes
14714,''' || A parallel rbm training implementation that results in negligible; perhaps even || non-existent speed gains. || ''',,Yes,Yes
14717,TODO: Just save the sorted version of the hash codes. The original,,,Yes
14719,KLUDGE: This is cheating. Searches should always return back-end,,,Yes
14720,TODO: Make evaluation method configurable,,Yes,Yes
14725,KLUDGE: Is this always OK?,,No,Yes
14726,"KLUDGE: I shouldn't know about the \""learn\"" property here.  Pipeline",,No,Yes
14730,KLUDGE: This method leaves rough; raw edges around the filter when it's,,,Yes
14731,Configurable step size (instead of always 1),,No,Yes
14732,TODO: Rename this; and the method in the abstract class,,Yes,Yes
14733,TODO: Get rid of this file! Move pad into a more appropriate location,,Yes,Yes
14734,KLUDGE: This is set explicitly to yield a signal whose length is a,,Yes,Yes
14736,KLUDGE: What does this number mean? It's repeated above,,Yes,Yes
14737,KLUDGE: WTF is j?,,,Yes
14739,KLUDGE: This is cheating. Searches should always return back-end,,,Yes
14744,KlUDGE: Generalize this; and collapse into FFT,,,Yes
14747,via the command-line interface. There's probably a better way; but this,,Yes,Yes
14749,KLUDGE ###################################################################,,,Yes
14750,Perhaps I should move all things ExhautiveSearch into a seperate module;,,,Yes
14753,TODO: Visualize the distance between,,,Yes
14755,KLUDGE: We're choosing the max number of frames from all extractors,,Yes,Yes
14757,TODO: Uncomment the following,,,Yes
14758,TODO: Uncomment the following 4 lines,,No,Yes
14759,KLUDGE: I should be passing the codeoboks as numpy arrays; however;,,,Yes
14760,KLUDGE: I should be passing the codeoboks as numpy arrays; however;,,Yes,Yes
14761,KLUDGE: numpy arrays aren't hashable. Is this the best way to,,Yes,Yes
14762,KLUDGE: This code is duplicated in DivideByStd; but I'm not quite,,Yes,Yes
14763,KLUDGE: This code is duplicated in SubtractMean; but I'm not quite,,,Yes
14764,TODO: Explain each of these steps,,,Yes
14765,TODO: This is discarding phase. Is that ok?,,No,Yes
14767,TODO: Why does this have to be recalculated,,,Yes
14768,TODO: What is this for?,,,Yes
14769,KLUDGE: I have no idea if this is correct,,,Yes
14772,TODO: FFT synthesizer,,,Yes
14773,TODO: DCT synthesizer,,Yes,Yes
14779,KLUDGE: This feels like kind of a stupid test; since the behavior,,Yes,Yes
14780,KLUDGE: I should really write my own Extractor-derived class for this,,No,Yes
14781,"''' || # KLUDGE: this should be a PyTablesFrameController class method; if at all possible || @task(name='data.frame.sync_one') || def sync_one(newmodel;filepath;_id;add;update;delete;recompute): ||     oldc = PyTablesFrameController(newmodel;filepath) ||     newc = PyTablesFrameController(newmodel;oldc._temp_filepath) ||     _id_query = '_id == \""%s\""' % _id ||     oldrows = oldc.db_read.getWhereList(_id_query) ||     newrows = newc.db_read.getWhereList(_id_query) ||     oldlen = len(oldrows) ||     newlen = len(newrows) ||      ||     if oldlen == newlen: ||         # this id has already been processed ||         return ||       ||     if newlen: ||         # There are some rows in the new database with id; but ||         # there aren't the same number as oldlen; meaning that  ||         # something probably went wrong during the sync. To keep ||         # things simple; let's delete what's there and start over ||         newc.acquire_lock(newc._max_buffer_size; wait = True) ||         newc._write_mode() ||         newc.db_write.removeRows(newrows) ||         newc._read_mode() ||         newc.release_lock() ||      ||     p = Pattern(_id;*oldc.external_id(_id)) ||     ec = newmodel.extractor_chain(p;transitional = True;recompute = recompute) ||     newc.append(ec) ||     print 'processed %s' % _id ||     oldc.close() ||     newc.close() ||     return (newmodel;filepath) ||      ||  || # KLUDGE: this should be a PyTablesFrameController class method; if at all possible || @task(name='data.frame.sync_complete') || def sync_complete(results): ||     newmodel = results[0][0] ||     filepath = results[0][1] ||     oldc = PyTablesFrameController(newmodel;filepath) ||     tmpfilepath = oldc._temp_filepath ||     newc = PyTablesFrameController(newmodel;tmpfilepath) ||     oldids = oldc.list_ids() ||     newids = newc.list_ids() ||      ||     if (len(oldc) != len(newc) or oldids != newids): ||         raise PyTablesUpdateNotCompleteError() ||      ||      ||     oldc.close() ||     newc.close() ||     os.remove(filepath) ||     os.rename(tmpfilepath;filepath) ||     print 'sync complete' ||     return True || '''",,Yes,Yes
14782,"TODO: This should go into a new \""synthesize\"" module",,,Yes
14784,TODO: How does this work on other systems; where matplotlib is working correctly?,,No,Yes
14787,TODO: I'm not calling ravel for the sequence search,,,Yes
14790,TODO: This is the original line,,No,Yes
14793,KLUDGE: This needs to be an environment variable,,,Yes
14794,KLUDGE: The following two lines seem to solve a bug whereby,,Yes,Yes
14797,KLUDGE: We're choosing the max number of frames from all extractors,,Yes,Yes
14799,KLUDGE: This is a bit odd.   The RawAudio extractor is telling,,,Yes
14800,KLUDGE: These are temporarily set to point at the experimental analyze2 module,,Yes,Yes
14801,KLUDGE: This is temporarily set to point at the experimental; chunk-based,,Yes,Yes
14802,Possible KLUDGE: Since this extractor has frames = 1 and stepsize = 1;,,Yes,Yes
14804,KLUDGE: Refactor this. There's a lot of duplicated code,,,Yes
14805,TODO: Once I've filled up self so that it's non-jagged; append as much,,Yes,Yes
14806,KLUDGE: Refactor this. There's a lot of duplicated code,,,Yes
14809,KLUDGE: I'm assuming that chunksize will always be larger than,,No,Yes
14810,KLUDGE: Factor this code out from this and the following extractor,,Yes,Yes
14812,KLUDGE: Do some real logging here,,,Yes
14819,KLUDGE: Because of the way nputil.windowed behaves; this can return,,,Yes
14820,Indexing of unsigned 64 bit columns is not currently,,No,Yes
14822,TODO: Factor this out,,,Yes
14824,TODO: This could be sped up by writing a cython function that takes,,Yes,Yes
14825,TODO: Refactor the following four methods to loop over data files once,,,Yes
14828,TODO: What can I factor out from this and PyTablesFrameController.Address?,,No,Yes
14832,TODO: Move these hardcoded values (_id;source;external_id) somewhere more central,,No,Yes
14834,TODO: Refactor common code out of audio and image classes,,,Yes
14835,TODO: Query lengths should be specified in arguments when the webserver,,Yes,Yes
14837,TODO: Render the results to a template,,,Yes
14838,TODO: I should be using the address class itself here!,,No,Yes
14839,TODO: Make this size configurable,,Yes,Yes
14840,TODO: I should be using the address class itself here!,,No,Yes
14843,Indexing of unsigned 64 bit columns is not currently,,No,Yes
14845,Crazy Bad KLUDGE: I rely on FrameController-derived classes to define a back-end,,Yes,Yes
14847,TODO: Perhaps these should be loaded lazily,,,Yes
14850,def test_correct_num_columns(self):,,Yes,Yes
14851,TODO: Shouldn't these also be persisted to disk?,,,Yes
14852,KLUDGE: I've excluded int -> int comparisons,,,Yes
14855,KLUDGE: In the special case of 0-d recarrays (i.e.;,,,Yes
14857,TODO: Try np.lib.recfunctions.drop_fields,,Yes,Yes
14858,TODO: Try np.lib.recfunctions.append_fields,,,Yes
14859,TODO: Shouldn't these also be persisted to disk?,,Yes,Yes
14860,KLUDGE: Do some real logging here,,Yes,Yes
14861,TODO: How do I recover from an error once partial data has,,No,Yes
14863,KLUDGE: I have no idea what a reasonable time span is for this,,Yes,Yes
14864,The total number of bytes needed at the beginning of each file for,,Yes,Yes
14867,KLUDGE: I have no idea what a reasonable time span is for this,,,Yes
14868,TODO: Consider excluding codes contained in self._filter from,,,Yes
14869,lop off any unused indices,,Yes,Yes
14871,TODO: Would it make sense to chunk patches and do the distance calculation,,Yes,Yes
14873,TODO: Maybe this should go in the acquirer module,,No,Yes
14875,TODO: This class really sucks in the case where one; or a few new patterns,,Yes,Yes
14876,is very efficient; but makes it more difficult to differnentiate between,,Yes,Yes
14878,TODO: Consider making the _load function an abstract method on the,,,Yes
14879,KLUDGE: something was wrong with the on-disk index. Rebuild it from,,Yes,Yes
14880,KLUDGE: something was wrong with the on-disk index. Rebuild it from,,Yes,Yes
14881,KLUDGE: This assumes that lock will always be the final argument,,No,Yes
14882,KLUDGE: There have been a couple instances (the multiprocess,,,Yes
14883,KLUDGE: How can I avoid hard-coding the url here?,,Yes,Yes
14885,Crazy Bad KLUDGE: I rely on FrameController-derived classes to define a back-end,,Yes,Yes
14886,KLUDGE: The following two methods were added to make writing,,Yes,Yes
14888,TODO: This needs to be configurable from the command line when the server is,,,Yes
14889,KLUDGE: The way addresses are being handled is atrocious!,,,Yes
14891,TODO: Should this be a part of the Tile class?,,,Yes
14892,TODO: Refactor common code out of audio and image classes,,No,Yes
14894,TODO: nresults should be specified by a command-line arg when the server,,,Yes
14895,TODO: Render the results to a template,,No,Yes
14898,KLUDGE: I need to be able to pass arbitrary kwargs to the search class,,Yes,Yes
14899,via the command-line interface. There's probably a better way; but this,,,Yes
14900,TODO: __str__ and __repr__ methods that show fullsize and patch size,,,Yes
14901,KLUDGE: Is there a better way to get setuptools commands?,,Yes,Yes
14902,KLUDGE: This is a hack. Right?  I'd like to add the currently logged-in user,,,Yes
14904,TODO: How do I cancel the event?,,,Yes
14906,KLUDGE: I don't know how to determine when the JACK server is ready,,Yes,Yes
14911,TODO: Consider adding an option to normalize (i.e. give unit-norm) to frames,,Yes,Yes
14912,KLUDGE: This doesn't belong in this module,,,Yes
14915,TODO: Add a sparsify option which will zero out values below the row's mean;,,,Yes
14918,TODO: use the mappings defined in nputil,,,Yes
14919,TODO: Is this method necessary? Isn't this defined on the MetaFrameSearch,,Yes,Yes
14923,Maybe fullsize should be optional. It will only be required if feature is,,Yes,Yes
14924,TODO: Don't save the mean if axis = 1,,No,Yes
14925,TODO: Don't save the std if axis = 1,,No,Yes
14926,TODO: What effect does altering this size have?,,No,Yes
14930,how much distortion did we introduce by rounding to a whole number of bins?,,Yes,Yes
14931,TODO: Alter the edges of the triangle window so they're rounding-aware,,,Yes
14932,TODO: Should this be different for Bark and Mel scales?  Isn't equivalent,,No,Yes
14934,"KLUDGE: \""NeuralNetwork\"" is too general a name.  This class and its derived classes",,No,Yes
14935,TODO: Replace this with the TypeCodes class in nputil,,No,Yes
14937,TODO: This should accept constant and variable rate amplitude data too,,No,Yes
14938,TODO: Dirac-based time and pitch stretch,,,Yes
14939,TODO: Basic low and high-pass filters,,No,Yes
14941,KLUDGE: There's gotta be a better way than this,,Yes,Yes
14943,TODO: Hash the pattern somehow; so it can be compared to ... itself?,,,Yes
14947,TODO: Add a changed() method; which determines whether the pattern has changed,,Yes,Yes
14948,KLUDGE: This is a stop-gap solution for when set_up fails.  Get,,,Yes
14949,KLUDGE: This is a FileSystemFrameController specific test,,No,Yes
14950,have an address attribute.  This is really a bug; but it's expected,,Yes,Yes
14951,KLUDGE: This doesn't guarantee equivalence; but it's probably,,,Yes
14952,TODO: be sure to remove items from all_ids and _to_store; when necessary,,Yes,Yes
14953,TODO: Should this be asynchronous ?,,No,Yes
14954,TODO: Ensure that transform isn't None; and has at least one,,Yes,Yes
14955,TODO: Is this method necessary; or is it made superfluous by transform(),,,Yes
14956,KLUDGE: Given the following implementation; this copy() is necessary for,,,Yes
14957,TODO: Composable types with different atomic behaviors,,,Yes
14958,TODO: Ensure that transform isn't None; and has at least one,,,Yes
14964,TODO: logic to translate frames to samples is already defined in,,Yes,Yes
14965,TODO: Which values should have MongoDb indexes ?,,Yes,Yes
14967,KLUDGE: This is a stop-gap solution for when set_up fails.  Get,,Yes,Yes
14968,TODO: What happens if the slice bisects a pattern?  Should events,,Yes,Yes
14969,TODO: Run the setup.sh script from here,,Yes,Yes
14975,TODO: There's a ton of duplicated logic in self._build_index. Factor some,,Yes,Yes
14976,KLUDGE: This is duplicated exactly in _build_index(),,Yes,Yes
14978,TODO: Implement the _add_index() method,,Yes,Yes
14980,TODO: Since patterns are immutable; is it safe to store the result of,,Yes,Yes
14981,TODO: What if self and\/or other are leaf patterns,,No,Yes
14984,TODO: Maybe copy should rectify any negative or wrapped times,,Yes,Yes
14985,BUG: What if self has negative or wrapped event times? The same,,Yes,Yes
14987,TODO: It'd probably be better to do a max size in bytes; rather than an,,,Yes
14989,TODO: This should include transform data too,,,Yes
14991,TODO: Maybe copy should rectify any negative or wrapped times,,Yes,Yes
14993,TODO: Composable types with different atomic behaviors,,,Yes
14995,BUG: What if a transform changes the length of the samples?,,,Yes
14996,KLUDGE: Maybe _render should be an iterator; for very long patterns,,,Yes
14999,TODO: Don't perform the same transformation twice!,,,Yes
15004,acceptable latency value is. I think this value is too high.,,,Yes
15007,TODO: be sure to remove items from all_ids and _to_store; when necessary,,,Yes
15008,TODO: What happens if the slice bisects a pattern?  Should events,,Yes,Yes
15009,KLUDGE: Given the following implementation; this copy() is necessary for,,Yes,Yes
15010,TODO: Should this be asynchronous ?,,No,Yes
15012,TODO: It'd probably be better to do a max size in bytes; rather than an,,,Yes
15013,KLUDGE: This class doesn't really belong here,,No,Yes
15015,TODO: Run dependencies.sh from here,,No,Yes
15016,TODO: Start mongodb after running dependencies.sh,,No,Yes
15017,TODO: install numpy and scipy from here,,No,Yes
15018,TODO: Do installation until it succeeds,,Yes,Yes
15025,KLUDGE: This class should be named AudioTransform to distinguish it from,,Yes,Yes
15026,KLUDGE: The C interpolations array type is char.  I'm using np.uint8,,,Yes
15027,KLUDGE: Wouldn't it simpler to just wrap the C transform struct in,,,Yes
15028,TODO: Only the times array depends on the current pattern and samplerate.,,,Yes
15031,KLUDGE: This only works with the FileSystemFrameController.Address,,No,Yes
15032,TODO: When do I save the index back to disk?  Everytime this is called?,,,Yes
15036,Using _add_index for each _id is actually more robust; but less efficient;,,Yes,Yes
15037,KLUDGE: Results may not be unique,,,Yes
15038,TODO: Make this size configurable,,,Yes
15041,TODO: Write documentation,,,Yes
15042,more physical memory is needed than has been allocated so far,,,Yes
15043,make enough room. Allocate exactly as much memory as is needed,,Yes,Yes
15045,TODO: I should be using a thread and process safe lock here,,No,Yes
15046,TODO: Implement the _check_index() method,,Yes,Yes
15047,TODO: Handle web-services; like FreeSound; or SoundCloud,,Yes,Yes
15051,TODO: How do I recover from an error once partial data has,,No,Yes
15052,TODO: I should wrap Sndfile so it has __enter__ and __exit__ methods;,,,Yes
15055,TODO: Set the start and stop freqs in hz,,,Yes
15061,TODO: Here the DataWriter is monolithic.  What if the data writer,,Yes,Yes
15063,KLUDGE: The following line seems to solve a bug whereby,,Yes,Yes
15065,then; once a chunk in the pool has received some number of writes maybe,,Yes,Yes
15067,TODO: yield each well-mixed chunk (data will simply be a set of indices),,No,Yes
15068,TODO: What happens if we have filled up all the sample slots and we run,,,Yes
15069,TODO: This should probably be self._r[:self._index],,No,Yes
15071,TODO: Is this class really necessary?  There must be a better way to handle,,,Yes
15072,TODO: Get rid of this class once I'm sure that TimeSeriesIndex works well,,Yes,Yes
15073,TODO: Make sure this can work with streaming numpy decoders as well,,Yes,Yes
15075,TODO: Replace these with the SampleRate-derived classes from samplerate,,Yes,Yes
15079,TODO: Add a class (mixin) in the flow library for this pattern where,,No,Yes
15081,TODO: A subclass of this that turns each pair into a timeslice,,No,Yes
15082,TODO: Should PeakPicker always emit the *end* of the timeseries; so that the,,,Yes
15085,KLUDGE: PySoundfile no longer supports __len__; which means that,,Yes,Yes
15086,TODO: Update this to use BytesIO instead of writing a file to disk,,,Yes
15088,# KLUDGE: This is a hack. Right?  I'd like to add the currently logged-in user,,,Yes
15090,KLUDGE: I should figure out a way to do paging here,,,Yes
15091,TODO: Seperate serializer for ConstantRateTimeSeries,,,Yes
15093,TODO: Is this the correct implementation for both Rbm and LinearRbm?,,,Yes
15094,# TODO: Update this to use BytesIO instead of writing a file to disk,,Yes,Yes
15095,TODO: this pattern of hanging on to the last sample of the previous chunk;,,Yes,Yes
15097,TODO: Consider using a bisection approach here to make this much,,Yes,Yes
15099,TODO: Deprecate stuff in psychoacoustics.py in favor of these classes,,Yes,Yes
15101,TODO: Factor this common behavior from WindowingFunc out into a common,,,Yes
15102,compute the array needed to perceptually weight the MDCT frequencies,,Yes,Yes
15104,KLUDGE: This check is necessary for an initial; incremental,,Yes,Yes
15105,refactoring; and should be removed once there are some nice;,,,Yes
15109,KLUDGE: This assumes that all FrequencyScale-derived classes live in,,Yes,Yes
15113,# TODO: How can I find the perfect window?,,,Yes
15114,TODO: How does this work if I use linearly-spaced; half-lapped,,Yes,Yes
15116,TODO: These dimensions work for vanilla GANs; but need to be,,Yes,Yes
15118,KLUDGE: This is here to support building documentation on readthedocs,,,Yes
15121,TODO: this would be much more efficient for repeated calls if I,,Yes,Yes
15123,TODO: it should be possible to apply windowing at the synthesis step,,No,Yes
15124,TODO: Factor all of this out from MusicNet and NSynth,,Yes,Yes
15125,TODO: These dimensions work for vanilla GANs; but need to be,,Yes,Yes
15126,TODO: this should have the same number of dimensions as real and,,Yes,Yes
15127,TODO: Why is this necessary?,,,Yes
15128,TODO: what about functions with imports that aren't in the calling namespace?,,,Yes
15130,TODO: it should be possible to hand this intermediate value off,,Yes,Yes
15132,"\""\""\"" || Demonstrate how to build a hamming-distance index over a binary\/bit-packed || feature. ||  || This example is particularly handy for performance profiling of the hamming || index. || \""\""\""",,Yes,Yes
15133,"\""\""\"" || Log || - reduced sample size from 8192 to 4096.  No difference || - Introduced batch norm.  Discriminator loss seems to stall out; and generator ||   produces very periodic sine-like sound with many harmonics || - leaky RELU in discriminator seems to make little or no difference || - tanh for all layers produces noise || - leaky RELU in the generator seem to produce more plausible *looking* waveforms. ||   generated examples are a combination of a single tone and noise || - add batch norm to the last generator layer - this seems to have really helped ||    with the visual appearance of generated samples ||  ||  || - don't do instance scaling? there seems to be more variability; but still noise || - try with mu_law this results in noise; and strong peaks at convolution boundaries.  Why do things totally break down with mu_law? || - try the mu-law one-hot encoding.  this is very slow; and it's producing some pretty awful output.  Perhaps I should train longer with softmax. ||  || - try penalizing the norm (improved WGAN) much more variation.  Still some noise || - try tanh all the way through - doesn't learn at all ||  || - try interpolating in sample space - learns a good deal of variety || - try learning on downsampled 8192 samples -  there is some movement in the samples || - try without dropout - this seems to be slightly worse\/noisier ||  || - now that I'm doing WGAN; try instance scaling again - this seems to be OK now; and produces more variation || - try A-weighing the frequency domain and then IFFT back to samples- this seems to slightly improve variation || - try without tanh? - doesn't get rid of the noise || - try without batch norm in last layer? - doesn't change noise situation || - try with tanh in first layer of discriminator? - doesn't change noise ||  ||  || - can I scale up to 8192 and capture meaningful structure; even if noisy? ||     - yes; at least for Bach || - try with phat drum loops ||     - yes; starts to learn drum-like sounds || - try with speech ||     - yes; starts to learn speech-like sounds || - try with a toy dataset so I can understand the biases\/problems || - try with Kevin Gates ||     - yes; learns speech-like sounds plus kick drums and bass || - try with a mixture of different types of sample ||  || - residuals in the network || - dilated convolutions || - try adding batch norm back into discriminator? || - try training on mdct - nope; learns nothing || - progressively growing WGAN || \""\""\""",,Yes,Yes
15134,KLUDGE: Should we *ever* implicitly move things to the GPU?  If not;,,Yes,Yes
15135,window the audio using a power-of-2 frame size for more efficient FFT,,Yes,Yes
15137,KLUDGE: This logic is very similar to logic in the OggVorbis,,Yes,Yes
15139,gather text from columns and place in single list for processing if not empty,,,Yes
15140,gather text from columns and place in single list for processing if not empty,,No,Yes
15141,once we refactor Faster RCNN models to set is_training through an outer,,,Yes
15143,TODO(mttang): This method is needed because the current,,Yes,Yes
15145,TODO(b\/65130867): Use image_id tensor once we fix the input data,,,Yes
15146,add_single_ground_truth_image_info expects a single image. Fix,,,Yes
15147,A dictionary of metric names to classes that implement the metric. The classes,,Yes,Yes
15149,Unused by updated loading code.,,Yes,Yes
15150,"\""\""\""Argmax matcher implementation. ||  || This class takes a similarity matrix and matches columns to rows based on the || maximum value per column. One can specify matched_thresholds and || to prevent columns from matching to rows (generally resulting in a negative || training example) and unmatched_theshold to ignore the match (generally || resulting in neither a positive or negative training example). ||  || This matcher is used in Fast(er)-RCNN. ||  || Note: matchers are used in TargetAssigners. There is a create_target_assigner || factory function for popular implementations. || \""\""\""",,,Yes
15152,TODO(rathodv): add_summaries is currently unused. Respect that directive,,Yes,Yes
15153,TODO(rathodv): add_summaries is currently unused. Respect that directive,,Yes,Yes
15154,Needed for fine-tuning from classification checkpoints whose,,,Yes
15155,TODO(chensun): Figure out if it is needed when image,,,Yes
15159,"TODO: \""Thurs\""",,Yes,Yes
15161,"TODO: ERA = [\""AD\""; \""BC\""; \""CE\""; \""BCE\""; \""Stardate\"";",,Yes,Yes
15162,move to info,,,Yes
15166,TODO: Check that l[i+3] is minute-like?,,No,Yes
15167,TODO: Check if res attributes already set.,,Yes,Yes
15169,TODO: try\/except for this?,,No,Yes
15170,TODO: Are we sure this is the right condition here?,,Yes,Yes
15171,TODO: Every usage of this function sets res.second to the return,,No,Yes
15172,TODO: Is this going to admit a lot of false-positives for when we,,,Yes
15173,TODO: Check -numweeks for next year.,,No,Yes
15175,TODO  switch to FileNotFoundError?,,,Yes
15176,a stateful class. So as a workaround for now; without changing the API; we,,,Yes
15179,needed for python 2 to preserve identity through a pickle,,Yes,Yes
15181,This calls itself recursively but should eventually hit,,,Yes
15183,Note: Both scalartypes.c.src and arrayprint.py implement strs for numpy,,,Yes
15186,DDOT without aligned data (better to use einsum),,,Yes
15188,This branch is needed for reductions like any which don't,,,Yes
15189,"\""\""\"" || Machine arithmetics - determine the parameters of the || floating-point arithmetic system ||  || Author: Pearu Peterson; September 2003 ||  || \""\""\""",,Yes,Yes
15190,needed instead of a 0 to get same result as zeros for for string dtypes,,Yes,Yes
15192,fix hack in scipy which imports this function,,Yes,Yes
15193,Move working axis to the end of the shape,,,Yes
15194,Needed to treat masked arrays correctly. = True would not work.,,Yes,Yes
15196,XXX: ugly; we use a class to avoid calling twice some expensive functions in,,Yes,Yes
15198,Distutils hack on AMD64 on windows,,Yes,Yes
15200,Ugly: this can be called within a library and not an extension;,,,Yes
15201,needed).,,No,Yes
15204,MMX only needed for icc; but some clangs don't have it,,Yes,Yes
15205,# wasn't what I expected... is np.array(o) supposed to equal a ?,,Yes,Yes
15207,check it works properly with object arrays too,,No,Yes
15208,TODO: Changing to 'same_kind' or 'safe' casting in the ufuncs by,,No,Yes
15209,default is needed to properly catch this kind of thing...,,,Yes
15210,TODO: Allowing unsafe casting by,,,Yes
15212,"\""\""\"" || Tests related to deprecation warnings. Also a convenient place || to document how deprecations should eventually be turned into errors. ||  || \""\""\""",,Yes,Yes
15213,Needed so Python 3 does not raise DeprecationWarning twice.,,Yes,Yes
15215,Before `...` would return a itself.,,Yes,Yes
15216,This object here is very dubious and probably bad though:,,No,Yes
15217,numpy should maybe raise an error if casting to intp,,No,Yes
15218,Maybe never happens...,,Yes,Yes
15219,too many dimensions; probably,,Yes,Yes
15220,Fixme; this needs to raise a 'skip' exception.,,Yes,Yes
15221,FIXME:,,,Yes
15223,It would be nice to support in-place matmul eventually; but for now,,,Yes
15229,Copy needed; 3 ops; read-write overlap,,Yes,Yes
15232,When buffering is unused; 'writemasked' effectively does nothing.,,,Yes
15233,Probably ~t (bitwise negation) is more proper to use here;,,No,Yes
15234,Fix in r2836,,,Yes
15236,Correct way,,No,Yes
15240,Check that scalar unpickling hack in Py3 that supports,,,Yes
15241,100MB times 1000 would give 100GB of memory usage if it leaks,,,Yes
15242,2 ** -1 perhaps generic,,Yes,Yes
15243,This should probably be deprecated:,,No,Yes
15245,FIXME These should be using assert_raises,,Yes,Yes
15251,XXX: spacing does not handle long double yet,,Yes,Yes
15252,TODO: branch cuts (use Pauli code),,No,Yes
15254,TODO: FPU exceptions,,,Yes
15255,FIXME: this will probably change when we require full C99 campatibility,,,Yes
15257,XXX: most implementations get it wrong here (including glibc <= 2.10),,Yes,Yes
15258,XXX: check exceptions raised,,,Yes
15259,Fixme: ugly workaround for isinf bug.,,Yes,Yes
15263,white-space. XXX: send a patch to distutils,,No,Yes
15266,problem; msvc uses its own convention :(,,,Yes
15267,fix library dependencies,,Yes,Yes
15268,Determine if C++\/Fortran 77\/Fortran 90 compilers are needed.,,No,Yes
15270,Needed to compile kiva.agg._agg extension.,,Yes,Yes
15273,XXX: Fix find_source_files for item in py_modules such that item is 3-tuple,,,Yes
15275,XXX TODO: --inplace support for sdist command,,,Yes
15276,XXX: hack to circumvent a python 2.6 bug with msvc9compiler:,,,Yes
15277,XXX: Linker flags,,Yes,Yes
15278,Kind of a hack; but I don't know where else to change this...,,No,Yes
15280,replaces occurrences of xxx*3 with xxx; xxx; xxx,,,Yes
15281,XXX Hack to get numpy installable with easy_install.,,Yes,Yes
15283,XXX: what does the value of,,No,Yes
15285,XXX: other OS's. Eg. use _winreg on Win32. Or os.uname on unices.,,Yes,Yes
15286,stdio uses bytes in python 2; so to avoid issues; we simply,,,Yes
15287,XXX Assuming that free format is default for f90 compiler.,,,Yes
15288,XXX: Do we need LDSHARED->SOSHARED; LDFLAGS->SOFLAGS,,,Yes
15289,TODO: implement get_f90flags and use it in _compile similarly to get_f77flags,,,Yes
15290,of Absoft though I don't think versions earlier than 9 can,,Yes,Yes
15291,XXX: handle cross compilation,,Yes,Yes
15295,newnames are constructed as needed,,Yes,Yes
15297,kind of bad consequences; like using Py_ModuleInit4 instead of,,Yes,Yes
15298,no additional libraries needed,,No,Yes
15299,XXX: ideally; we should use exactly the same version as used by python. I,,,Yes
15300,XXX need support for .C that is also C++,,Yes,Yes
15301,break  # XXX can we assume that there is one module per file?,,No,Yes
15304,## XXX Implement add_py_modules,,No,Yes
15305,XXX: import here for bootstrapping reasons,,Yes,Yes
15306,FIXME: document this. If pkgname is defined in the variables section; and,,Yes,Yes
15307,Trivial cache to cache LibraryInfo instances creation. To be really,,Yes,Yes
15308,efficient; the cache should be handled in read_config; since a same file can,,Yes,Yes
15311,XXX: Handle setuptools ?,,Yes,Yes
15312,good to keep its class name. Use of RawConfigParser is needed in,,,Yes
15313,XXX: disabled by default; may disappear in,,,Yes
15315,XXX: is it generally true?,,,Yes
15317,all headers needed by a c file as a side effect of compilation (-MMD),,,Yes
15319,needed -- or maybe Python's configure script took care of,,,Yes
15321,"\""\""\"" || ======================== || Broadcasting over arrays || ======================== ||  || The term broadcasting describes how numpy treats arrays with different || shapes during arithmetic operations. Subject to certain constraints; || the smaller array is \""broadcast\"" across the larger array so that they || have compatible shapes. Broadcasting provides a means of vectorizing || array operations so that looping occurs in C instead of Python. It does || this without making needless copies of data and usually leads to || efficient algorithm implementations. There are; however; cases where || broadcasting is a bad idea because it leads to inefficient use of memory || that slows computation. ||  || NumPy operations are usually done on pairs of arrays on an || element-by-element basis.  In the simplest case; the two arrays must || have exactly the same shape; as in the following example: ||  ||   >>> a = np.array([1.0; 2.0; 3.0]) ||   >>> b = np.array([2.0; 2.0; 2.0]) ||   >>> a * b ||   array([ 2.;  4.;  6.]) ||  || NumPy's broadcasting rule relaxes this constraint when the arrays' || shapes meet certain constraints. The simplest broadcasting example occurs || when an array and a scalar value are combined in an operation: ||  || >>> a = np.array([1.0; 2.0; 3.0]) || >>> b = 2.0 || >>> a * b || array([ 2.;  4.;  6.]) ||  || The result is equivalent to the previous example where ``b`` was an array. || We can think of the scalar ``b`` being *stretched* during the arithmetic || operation into an array with the same shape as ``a``. The new elements in || ``b`` are simply copies of the original scalar. The stretching analogy is || only conceptual.  NumPy is smart enough to use the original scalar value || without actually making copies; so that broadcasting operations are as || memory and computationally efficient as possible. ||  || The code in the second example is more efficient than that in the first || because broadcasting moves less memory around during the multiplication || (``b`` is a scalar rather than an array). ||  || General Broadcasting Rules || ========================== || When operating on two arrays; NumPy compares their shapes element-wise. || It starts with the trailing dimensions; and works its way forward.  Two || dimensions are compatible when ||  || 1) they are equal; or || 2) one of them is 1 ||  || If these conditions are not met; a || ``ValueError: frames are not aligned`` exception is thrown; indicating that || the arrays have incompatible shapes. The size of the resulting array || is the maximum size along each dimension of the input arrays. ||  || Arrays do not need to have the same *number* of dimensions.  For example; || if you have a ``256x256x3`` array of RGB values; and you want to scale || each color in the image by a different value; you can multiply the image || by a one-dimensional array with 3 values. Lining up the sizes of the || trailing axes of these arrays according to the broadcast rules; shows that || they are compatible:: ||  ||   Image  (3d array): 256 x 256 x 3 ||   Scale  (1d array):             3 ||   Result (3d array): 256 x 256 x 3 ||  || When either of the dimensions compared is one; the other is || used.  In other words; dimensions with size 1 are stretched or \""copied\"" || to match the other. ||  || In the following example; both the ``A`` and ``B`` arrays have axes with || length one that are expanded to a larger size during the broadcast || operation:: ||  ||   A      (4d array):  8 x 1 x 6 x 1 ||   B      (3d array):      7 x 1 x 5 ||   Result (4d array):  8 x 7 x 6 x 5 ||  || Here are some more examples:: ||  ||   A      (2d array):  5 x 4 ||   B      (1d array):      1 ||   Result (2d array):  5 x 4 ||  ||   A      (2d array):  5 x 4 ||   B      (1d array):      4 ||   Result (2d array):  5 x 4 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (3d array):  15 x 1 x 5 ||   Result (3d array):  15 x 3 x 5 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (2d array):       3 x 5 ||   Result (3d array):  15 x 3 x 5 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (2d array):       3 x 1 ||   Result (3d array):  15 x 3 x 5 ||  || Here are examples of shapes that do not broadcast:: ||  ||   A      (1d array):  3 ||   B      (1d array):  4 # trailing dimensions do not match ||  ||   A      (2d array):      2 x 1 ||   B      (3d array):  8 x 4 x 3 # second from last dimensions mismatched ||  || An example of broadcasting in practice:: ||  ||  >>> x = np.arange(4) ||  >>> xx = x.reshape(4;1) ||  >>> y = np.ones(5) ||  >>> z = np.ones((3;4)) ||  ||  >>> x.shape ||  (4;) ||  ||  >>> y.shape ||  (5;) ||  ||  >>> x + y ||  <type 'exceptions.ValueError'>: shape mismatch: objects cannot be broadcast to a single shape ||  ||  >>> xx.shape ||  (4; 1) ||  ||  >>> y.shape ||  (5;) ||  ||  >>> (xx + y).shape ||  (4; 5) ||  ||  >>> xx + y ||  array([[ 1.;  1.;  1.;  1.;  1.]; ||         [ 2.;  2.;  2.;  2.;  2.]; ||         [ 3.;  3.;  3.;  3.;  3.]; ||         [ 4.;  4.;  4.;  4.;  4.]]) ||  ||  >>> x.shape ||  (4;) ||  ||  >>> z.shape ||  (3; 4) ||  ||  >>> (x + z).shape ||  (3; 4) ||  ||  >>> x + z ||  array([[ 1.;  2.;  3.;  4.]; ||         [ 1.;  2.;  3.;  4.]; ||         [ 1.;  2.;  3.;  4.]]) ||  || Broadcasting provides a convenient way of taking the outer product (or || any other outer operation) of two arrays. The following example shows an || outer addition operation of two 1-d arrays:: ||  ||   >>> a = np.array([0.0; 10.0; 20.0; 30.0]) ||   >>> b = np.array([1.0; 2.0; 3.0]) ||   >>> a[:; np.newaxis] + b ||   array([[  1.;   2.;   3.]; ||          [ 11.;  12.;  13.]; ||          [ 21.;  22.;  23.]; ||          [ 31.;  32.;  33.]]) ||  || Here the ``newaxis`` index operator inserts a new axis into ``a``; || making it a two-dimensional ``4x1`` array.  Combining the ``4x1`` array || with ``b``; which has shape ``(3;)``; yields a ``4x3`` array. ||  || See `this article <http:\/\/wiki.scipy.org\/EricsBroadcastingDoc>`_ || for illustrations of broadcasting concepts. ||  || \""\""\""",,,Yes
15323,"\""\""\""============== || Array indexing || ============== ||  || Array indexing refers to any use of the square brackets ([]) to index || array values. There are many options to indexing; which give numpy || indexing great power; but with power comes some complexity and the || potential for confusion. This section is just an overview of the || various options and issues related to indexing. Aside from single || element indexing; the details on most of these options are to be || found in related sections. ||  || Assignment vs referencing || ========================= ||  || Most of the following examples show the use of indexing when || referencing data in an array. The examples work just as well || when assigning to an array. See the section at the end for || specific examples and explanations on how assignments work. ||  || Single element indexing || ======================= ||  || Single element indexing for a 1-D array is what one expects. It work || exactly like that for other standard Python sequences. It is 0-based; || and accepts negative indices for indexing from the end of the array. :: ||  ||     >>> x = np.arange(10) ||     >>> x[2] ||     2 ||     >>> x[-2] ||     8 ||  || Unlike lists and tuples; numpy arrays support multidimensional indexing || for multidimensional arrays. That means that it is not necessary to || separate each dimension's index into its own set of square brackets. :: ||  ||     >>> x.shape = (2;5) # now x is 2-dimensional ||     >>> x[1;3] ||     8 ||     >>> x[1;-1] ||     9 ||  || Note that if one indexes a multidimensional array with fewer indices || than dimensions; one gets a subdimensional array. For example: :: ||  ||     >>> x[0] ||     array([0; 1; 2; 3; 4]) ||  || That is; each index specified selects the array corresponding to the || rest of the dimensions selected. In the above example; choosing 0 || means that the remaining dimension of length 5 is being left unspecified; || and that what is returned is an array of that dimensionality and size. || It must be noted that the returned array is not a copy of the original; || but points to the same values in memory as does the original array. || In  this case; the 1-D array at the first position (0) is returned. || So using a single index on the returned array; results in a single || element being returned. That is: :: ||  ||     >>> x[0][2] ||     2 ||  || So note that ``x[0;2] = x[0][2]`` though the second case is more || inefficient as a new temporary array is created after the first index || that is subsequently indexed by 2. ||  || Note to those used to IDL or Fortran memory order as it relates to || indexing.  NumPy uses C-order indexing. That means that the last || index usually represents the most rapidly changing memory location; || unlike Fortran or IDL; where the first index represents the most || rapidly changing location in memory. This difference represents a || great potential for confusion. ||  || Other indexing options || ====================== ||  || It is possible to slice and stride arrays to extract arrays of the || same number of dimensions; but of different sizes than the original. || The slicing and striding works exactly the same way it does for lists || and tuples except that they can be applied to multiple dimensions as || well. A few examples illustrates best: :: ||  ||  >>> x = np.arange(10) ||  >>> x[2:5] ||  array([2; 3; 4]) ||  >>> x[:-7] ||  array([0; 1; 2]) ||  >>> x[1:7:2] ||  array([1; 3; 5]) ||  >>> y = np.arange(35).reshape(5;7) ||  >>> y[1:5:2;::3] ||  array([[ 7; 10; 13]; ||         [21; 24; 27]]) ||  || Note that slices of arrays do not copy the internal array data but || also produce new views of the original data. ||  || It is possible to index arrays with other arrays for the purposes of || selecting lists of values out of arrays into new arrays. There are || two different ways of accomplishing this. One uses one or more arrays || of index values. The other involves giving a boolean array of the proper || shape to indicate the values to be selected. Index arrays are a very || powerful tool that allow one to avoid looping over individual elements in || arrays and thus greatly improve performance. ||  || It is possible to use special features to effectively increase the || number of dimensions in an array through indexing so the resulting || array aquires the shape needed for use in an expression or with a || specific function. ||  || Index arrays || ============ ||  || NumPy arrays may be indexed with other arrays (or any other sequence- || like object that can be converted to an array; such as lists; with the || exception of tuples; see the end of this document for why this is). The || use of index arrays ranges from simple; straightforward cases to || complex; hard-to-understand cases. For all cases of index arrays; what || is returned is a copy of the original data; not a view as one gets for || slices. ||  || Index arrays must be of integer type. Each value in the array indicates || which value in the array to use in place of the index. To illustrate: :: ||  ||  >>> x = np.arange(10;1;-1) ||  >>> x ||  array([10;  9;  8;  7;  6;  5;  4;  3;  2]) ||  >>> x[np.array([3; 3; 1; 8])] ||  array([7; 7; 9; 2]) ||  ||  || The index array consisting of the values 3; 3; 1 and 8 correspondingly || create an array of length 4 (same as the index array) where each index || is replaced by the value the index array has in the array being indexed. ||  || Negative values are permitted and work as they do with single indices || or slices: :: ||  ||  >>> x[np.array([3;3;-3;8])] ||  array([7; 7; 4; 2]) ||  || It is an error to have index values out of bounds: :: ||  ||  >>> x[np.array([3; 3; 20; 8])] ||  <type 'exceptions.IndexError'>: index 20 out of bounds 0<=index<9 ||  || Generally speaking; what is returned when index arrays are used is || an array with the same shape as the index array; but with the type || and values of the array being indexed. As an example; we can use a || multidimensional index array instead: :: ||  ||  >>> x[np.array([[1;1];[2;3]])] ||  array([[9; 9]; ||         [8; 7]]) ||  || Indexing Multi-dimensional arrays || ================================= ||  || Things become more complex when multidimensional arrays are indexed; || particularly with multidimensional index arrays. These tend to be || more unusual uses; but they are permitted; and they are useful for some || problems. We'll  start with the simplest multidimensional case (using || the array y from the previous examples): :: ||  ||  >>> y[np.array([0;2;4]); np.array([0;1;2])] ||  array([ 0; 15; 30]) ||  || In this case; if the index arrays have a matching shape; and there is || an index array for each dimension of the array being indexed; the || resultant array has the same shape as the index arrays; and the values || correspond to the index set for each position in the index arrays. In || this example; the first index value is 0 for both index arrays; and || thus the first value of the resultant array is y[0;0]. The next value || is y[2;1]; and the last is y[4;2]. ||  || If the index arrays do not have the same shape; there is an attempt to || broadcast them to the same shape.  If they cannot be broadcast to the || same shape; an exception is raised: :: ||  ||  >>> y[np.array([0;2;4]); np.array([0;1])] ||  <type 'exceptions.ValueError'>: shape mismatch: objects cannot be ||  broadcast to a single shape ||  || The broadcasting mechanism permits index arrays to be combined with || scalars for other indices. The effect is that the scalar value is used || for all the corresponding values of the index arrays: :: ||  ||  >>> y[np.array([0;2;4]); 1] ||  array([ 1; 15; 29]) ||  || Jumping to the next level of complexity; it is possible to only || partially index an array with index arrays. It takes a bit of thought || to understand what happens in such cases. For example if we just use || one index array with y: :: ||  ||  >>> y[np.array([0;2;4])] ||  array([[ 0;  1;  2;  3;  4;  5;  6]; ||         [14; 15; 16; 17; 18; 19; 20]; ||         [28; 29; 30; 31; 32; 33; 34]]) ||  || What results is the construction of a new array where each value of || the index array selects one row from the array being indexed and the || resultant array has the resulting shape (number of index elements; || size of row). ||  || An example of where this may be useful is for a color lookup table || where we want to map the values of an image into RGB triples for || display. The lookup table could have a shape (nlookup; 3). Indexing || such an array with an image with shape (ny; nx) with dtype=np.uint8 || (or any integer type so long as values are with the bounds of the || lookup table) will result in an array of shape (ny; nx; 3) where a || triple of RGB values is associated with each pixel location. ||  || In general; the shape of the resultant array will be the concatenation || of the shape of the index array (or the shape that all the index arrays || were broadcast to) with the shape of any unused dimensions (those not || indexed) in the array being indexed. ||  || Boolean or \""mask\"" index arrays || ============================== ||  || Boolean arrays used as indices are treated in a different manner || entirely than index arrays. Boolean arrays must be of the same shape || as the initial dimensions of the array being indexed. In the || most straightforward case; the boolean array has the same shape: :: ||  ||  >>> b = y>20 ||  >>> y[b] ||  array([21; 22; 23; 24; 25; 26; 27; 28; 29; 30; 31; 32; 33; 34]) ||  || Unlike in the case of integer index arrays; in the boolean case; the || result is a 1-D array containing all the elements in the indexed array || corresponding to all the true elements in the boolean array. The || elements in the indexed array are always iterated and returned in || :term:`row-major` (C-style) order. The result is also identical to || ``y[np.nonzero(b)]``. As with index arrays; what is returned is a copy || of the data; not a view as one gets with slices. ||  || The result will be multidimensional if y has more dimensions than b. || For example: :: ||  ||  >>> b[:;5] # use a 1-D boolean whose first dim agrees with the first dim of y ||  array([False; False; False;  True;  True]) ||  >>> y[b[:;5]] ||  array([[21; 22; 23; 24; 25; 26; 27]; ||         [28; 29; 30; 31; 32; 33; 34]]) ||  || Here the 4th and 5th rows are selected from the indexed array and || combined to make a 2-D array. ||  || In general; when the boolean array has fewer dimensions than the array || being indexed; this is equivalent to y[b; ...]; which means || y is indexed by b followed by as many : as are needed to fill || out the rank of y. || Thus the shape of the result is one dimension containing the number || of True elements of the boolean array; followed by the remaining || dimensions of the array being indexed. ||  || For example; using a 2-D boolean array of shape (2;3) || with four True elements to select rows from a 3-D array of shape || (2;3;5) results in a 2-D result of shape (4;5): :: ||  ||  >>> x = np.arange(30).reshape(2;3;5) ||  >>> x ||  array([[[ 0;  1;  2;  3;  4]; ||          [ 5;  6;  7;  8;  9]; ||          [10; 11; 12; 13; 14]]; ||         [[15; 16; 17; 18; 19]; ||          [20; 21; 22; 23; 24]; ||          [25; 26; 27; 28; 29]]]) ||  >>> b = np.array([[True; True; False]; [False; True; True]]) ||  >>> x[b] ||  array([[ 0;  1;  2;  3;  4]; ||         [ 5;  6;  7;  8;  9]; ||         [20; 21; 22; 23; 24]; ||         [25; 26; 27; 28; 29]]) ||  || For further details; consult the numpy reference documentation on array indexing. ||  || Combining index arrays with slices || ================================== ||  || Index arrays may be combined with slices. For example: :: ||  ||  >>> y[np.array([0;2;4]);1:3] ||  array([[ 1;  2]; ||         [15; 16]; ||         [29; 30]]) ||  || In effect; the slice is converted to an index array || np.array([[1;2]]) (shape (1;2)) that is broadcast with the index array || to produce a resultant array of shape (3;2). ||  || Likewise; slicing can be combined with broadcasted boolean indices: :: ||  ||  >>> y[b[:;5];1:3] ||  array([[22; 23]; ||         [29; 30]]) ||  || Structural indexing tools || ========================= ||  || To facilitate easy matching of array shapes with expressions and in || assignments; the np.newaxis object can be used within array indices || to add new dimensions with a size of 1. For example: :: ||  ||  >>> y.shape ||  (5; 7) ||  >>> y[:;np.newaxis;:].shape ||  (5; 1; 7) ||  || Note that there are no new elements in the array; just that the || dimensionality is increased. This can be handy to combine two || arrays in a way that otherwise would require explicitly reshaping || operations. For example: :: ||  ||  >>> x = np.arange(5) ||  >>> x[:;np.newaxis] + x[np.newaxis;:] ||  array([[0; 1; 2; 3; 4]; ||         [1; 2; 3; 4; 5]; ||         [2; 3; 4; 5; 6]; ||         [3; 4; 5; 6; 7]; ||         [4; 5; 6; 7; 8]]) ||  || The ellipsis syntax maybe used to indicate selecting in full any || remaining unspecified dimensions. For example: :: ||  ||  >>> z = np.arange(81).reshape(3;3;3;3) ||  >>> z[1;...;2] ||  array([[29; 32; 35]; ||         [38; 41; 44]; ||         [47; 50; 53]]) ||  || This is equivalent to: :: ||  ||  >>> z[1;:;:;2] ||  array([[29; 32; 35]; ||         [38; 41; 44]; ||         [47; 50; 53]]) ||  || Assigning values to indexed arrays || ================================== ||  || As mentioned; one can select a subset of an array to assign to using || a single index; slices; and index and mask arrays. The value being || assigned to the indexed array must be shape consistent (the same shape || or broadcastable to the shape the index produces). For example; it is || permitted to assign a constant to a slice: :: ||  ||  >>> x = np.arange(10) ||  >>> x[2:7] = 1 ||  || or an array of the right size: :: ||  ||  >>> x[2:7] = np.arange(5) ||  || Note that assignments may result in changes if assigning || higher types to lower types (like floats to ints) or even || exceptions (assigning complex to floats or ints): :: ||  ||  >>> x[1] = 1.2 ||  >>> x[1] ||  1 ||  >>> x[1] = 1.2j ||  <type 'exceptions.TypeError'>: can't convert complex to long; use ||  long(abs(z)) ||  ||  || Unlike some of the references (such as array and mask indices) || assignments are always made to the original data in the array || (indeed; nothing else would make sense!). Note though; that some || actions may not work as one may naively expect. This particular || example is often surprising to people: :: ||  ||  >>> x = np.arange(0; 50; 10) ||  >>> x ||  array([ 0; 10; 20; 30; 40]) ||  >>> x[np.array([1; 1; 3; 1])] += 1 ||  >>> x ||  array([ 0; 11; 20; 31; 40]) ||  || Where people expect that the 1st location will be incremented by 3. || In fact; it will only be incremented by 1. The reason is because || a new array is extracted from the original (as a temporary) containing || the values at 1; 1; 3; 1; then the value 1 is added to the temporary; || and then the temporary is assigned back to the original array. Thus || the value of the array at x[1]+1 is assigned to x[1] three times; || rather than being incremented 3 times. ||  || Dealing with variable numbers of indices within programs || ======================================================== ||  || The index syntax is very powerful but limiting when dealing with || a variable number of indices. For example; if you want to write || a function that can handle arguments with various numbers of || dimensions without having to write special case code for each || number of possible dimensions; how can that be done? If one || supplies to the index a tuple; the tuple will be interpreted || as a list of indices. For example (using the previous definition || for the array z): :: ||  ||  >>> indices = (1;1;1;1) ||  >>> z[indices] ||  40 ||  || So one can use code to construct tuples of any number of indices || and then use these within an index. ||  || Slices can be specified within programs by using the slice() function || in Python. For example: :: ||  ||  >>> indices = (1;1;1;slice(0;2)) # same as [1;1;1;0:2] ||  >>> z[indices] ||  array([39; 40]) ||  || Likewise; ellipsis can be specified by code by using the Ellipsis || object: :: ||  ||  >>> indices = (1; Ellipsis; 1) # same as [1;...;1] ||  >>> z[indices] ||  array([[28; 31; 34]; ||         [37; 40; 43]; ||         [46; 49; 52]]) ||  || For this reason it is possible to use the output from the np.nonzero() || function directly as an index since it always returns a tuple of index || arrays. ||  || Because the special treatment of tuples; they are not automatically || converted to an array as a list would be. As an example: :: ||  ||  >>> z[[1;1;1;1]] # produces a large array ||  array([[[[27; 28; 29]; ||           [30; 31; 32]; ... ||  >>> z[(1;1;1;1)] # returns a single value ||  40 ||  || \""\""\""",,Yes,Yes
15329,As the needed functions cannot be determined by static inspection of the,,,Yes
15330,XXX: Evaluate intent_flags here.,,Yes,Yes
15331,XXX: Note that CNUMFROMARROBJ is identical with NUMFROMARROBJ,,No,Yes
15333,As the needed functions cannot be determined by static inspection of the,,,Yes
15335,XXX: subsequent init expressions may get wrong values.,,Yes,Yes
15337,XXX: How to catch dependence cycles correctly?,,,Yes
15338,XXX: return something sensible.,,,Yes
15340,FIXME complex numbers may also have exponents,,,Yes
15341,FIXME; unused l looks like potential bug,,Yes,Yes
15342,XXX,,Yes,Yes
15343,The eviroment provided by auxfuncs.py is needed for some calls to eval.,,Yes,Yes
15344,As the needed functions cannot be determined by static inspection of the,,Yes,Yes
15345,Workaround for Python 2.6; 2.6.1 bug: http:\/\/bugs.python.org\/issue4720,,Yes,Yes
15346,XXX: this is really ugly. But I don't know how to invoke Distutils,,,Yes
15348,gzip is lacking read1 needed for TextIOWrapper,,,Yes
15349,deferring the import of lzma; bz2 and gzip until needed,,,Yes
15351,BUG : URLs require a scheme string ('http:\/\/') to be used.,,Yes,Yes
15352,TODO: Doesn't handle compressed files!,,,Yes
15355,Structured dtype: just validate the names as needed,,,Yes
15357,Fix index; handling ellipsis and incomplete slices.,,,Yes
15358,"\""\""\"" || Binary serialization ||  || NPY format || ========== ||  || A simple format for saving numpy arrays to disk with the full || information about them. ||  || The ``.npy`` format is the standard binary file format in NumPy for || persisting a *single* arbitrary NumPy array on disk. The format stores all || of the shape and dtype information necessary to reconstruct the array || correctly even on another machine with a different architecture. || The format is designed to be as simple as possible while achieving || its limited goals. ||  || The ``.npz`` format is the standard format for persisting *multiple* NumPy || arrays on disk. A ``.npz`` file is a zip file containing multiple ``.npy`` || files; one for each array. ||  || Capabilities || ------------ ||  || - Can represent all NumPy arrays including nested record arrays and ||   object arrays. ||  || - Represents the data in its native binary form. ||  || - Supports Fortran-contiguous arrays directly. ||  || - Stores all of the necessary information to reconstruct the array ||   including shape and dtype on a machine of a different ||   architecture.  Both little-endian and big-endian arrays are ||   supported; and a file with little-endian numbers will yield ||   a little-endian array on any machine reading the file. The ||   types are described in terms of their actual sizes. For example; ||   if a machine with a 64-bit C \""long int\"" writes out an array with ||   \""long ints\""; a reading machine with 32-bit C \""long ints\"" will yield ||   an array with 64-bit integers. ||  || - Is straightforward to reverse engineer. Datasets often live longer than ||   the programs that created them. A competent developer should be ||   able to create a solution in their preferred programming language to ||   read most ``.npy`` files that he has been given without much ||   documentation. ||  || - Allows memory-mapping of the data. See `open_memmep`. ||  || - Can be read from a filelike stream object instead of an actual file. ||  || - Stores object arrays; i.e. arrays containing elements that are arbitrary ||   Python objects. Files with object arrays are not to be mmapable; but ||   can be read and written to disk. ||  || Limitations || ----------- ||  || - Arbitrary subclasses of numpy.ndarray are not completely preserved. ||   Subclasses will be accepted for writing; but only the array data will ||   be written out. A regular numpy.ndarray object will be created ||   upon reading the file. ||  || .. warning:: ||  ||   Due to limitations in the interpretation of structured dtypes; dtypes ||   with fields with empty names will have the names replaced by 'f0'; 'f1'; ||   etc. Such arrays will not round-trip through the format entirely ||   accurately. The data is intact; only the field names will differ. We are ||   working on a fix for this. This fix will not require a change in the ||   file format. The arrays with such structures can still be saved and ||   restored; and the correct dtype may be restored by using the ||   ``loadedarray.view(correct_dtype)`` method. ||  || File extensions || --------------- ||  || We recommend using the ``.npy`` and ``.npz`` extensions for files saved || in this format. This is by no means a requirement; applications may wish || to use these file formats but use an extension specific to the || application. In the absence of an obvious alternative; however; || we suggest using ``.npy`` and ``.npz``. ||  || Version numbering || ----------------- ||  || The version numbering of these formats is independent of NumPy version || numbering. If the format is upgraded; the code in `numpy.io` will still || be able to read and write Version 1.0 files. ||  || Format Version 1.0 || ------------------ ||  || The first 6 bytes are a magic string: exactly ``\\\\x93NUMPY``. ||  || The next 1 byte is an unsigned byte: the major version number of the file || format; e.g. ``\\\\x01``. ||  || The next 1 byte is an unsigned byte: the minor version number of the file || format; e.g. ``\\\\x00``. Note: the version of the file format is not tied || to the version of the numpy package. ||  || The next 2 bytes form a little-endian unsigned short int: the length of || the header data HEADER_LEN. ||  || The next HEADER_LEN bytes form the header data describing the array's || format. It is an ASCII string which contains a Python literal expression || of a dictionary. It is terminated by a newline (``\\\ || ``) and padded with || spaces (``\\\\x20``) to make the total of || ``len(magic string) + 2 + len(length) + HEADER_LEN`` be evenly divisible || by 64 for alignment purposes. ||  || The dictionary contains three keys: ||  ||     \""descr\"" : dtype.descr ||       An object that can be passed as an argument to the `numpy.dtype` ||       constructor to create the array's dtype. ||     \""fortran_order\"" : bool ||       Whether the array data is Fortran-contiguous or not. Since ||       Fortran-contiguous arrays are a common form of non-C-contiguity; ||       we allow them to be written directly to disk for efficiency. ||     \""shape\"" : tuple of int ||       The shape of the array. ||  || For repeatability and readability; the dictionary keys are sorted in || alphabetic order. This is for convenience only. A writer SHOULD implement || this if possible. A reader MUST NOT depend on this. ||  || Following the header comes the array data. If the dtype contains Python || objects (i.e. ``dtype.hasobject is True``); then the data is a Python || pickle of the array. Otherwise the data is the contiguous (either C- || or Fortran-; depending on ``fortran_order``) bytes of the array. || Consumers can figure out the number of bytes by multiplying the number || of elements given by the shape (noting that ``shape=()`` means there is || 1 element) by ``dtype.itemsize``. ||  || Format Version 2.0 || ------------------ ||  || The version 1.0 format only allowed the array header to have a total size of || 65535 bytes.  This can be exceeded by structured arrays with a large number of || columns.  The version 2.0 format extends the header size to 4 GiB. || `numpy.save` will automatically save in 2.0 format if the data requires it; || else it will always use the more compatible 1.0 format. ||  || The description of the fourth element of the header therefore has become: || \""The next 4 bytes form a little-endian unsigned int: the length of the header || data HEADER_LEN.\"" ||  || Notes || ----- || The ``.npy`` format; including motivation for creating it and a comparison of || alternatives; is described in the `\""npy-format\"" NEP  || <http:\/\/www.numpy.org\/neps\/nep-0001-npy-format.html>`_; however details have || evolved with time and this document is more current. ||  || \""\""\""",,Yes,Yes
15359,This is a record array. The .descr is fine.  XXX: parts of the,,,Yes
15360,adding newline as python 2.7.5 workaround,,,Yes
15361,removing newline (see above) as python 2.7.5 workaround,,No,Yes
15362,needed in this module for compatibility,,,Yes
15364,Caching to improve default performance,,Yes,Yes
15365,truncate the range if needed,,,Yes
15369,which do not implement isnan (gh-9009); or fmin correctly (gh-8975),,,Yes
15371,action is needed to handle bad results.,,Yes,Yes
15372,convention.,,Yes,Yes
15376,python 3. We forgot to implement itervalues() at all in earlier,,No,Yes
15379,Check the columns to use: make sure `usecols` is a list,,Yes,Yes
15380,Check the names and overwrite the dtype.names if needed,,,Yes
15381,Redefine the key as needed if it's a column number,,Yes,Yes
15385,Find the columns with strings...,,,Yes
15386,Overwrite the initial dtype names if needed,,Yes,Yes
15387,We have only one field: drop the name if not needed.,,No,Yes
15388,Minimal processing needed: just make sure everythng's a-ok,,No,Yes
15389,Get the dtype of the output (flattening if needed),,,Yes
15393,never really has writebackifcopy semantics,,,Yes
15394,TODO: consider making the results of broadcast_arrays readonly to match,,,Yes
15396,Fixme: used to crash on windows,,Yes,Yes
15397,dtypes should not be promoted in a different way to what diff does,,No,Yes
15401,TODO: specify exact message,,No,Yes
15404,Test usecols with named columns,,Yes,Yes
15410,Hack to avoid pyflakes unused variable warnings,,,Yes
15411,perhaps should check higher dimensions,,,Yes
15414,Fixme,,Yes,Yes
15416,XXX: maybe using a real stemming search engine would be better?,,Yes,Yes
15417,XXX: this is full Harrison-Stetson heuristics now;,,Yes,Yes
15418,XXX: it probably could be improved,,Yes,Yes
15420,Convention is to return scalars instead of 0d arrays,,Yes,Yes
15422,m[i;j]: min number of scalar multiplications needed to compute A_{i..j},,No,Yes
15423,Warning should be raised exactly once (first command),,,Yes
15425,There's a bug gh-8577 on OSX that can trigger this; and perhaps,,Yes,Yes
15427,no warning needed - but switch to -1 anyway; to avoid surprising,,Yes,Yes
15428,subclasses; which are more likely to implement scalar axes.,,,Yes
15432,XX: This looks like a bug -- shouldn't it check self.dtype,,No,Yes
15434,Make sure to reset the _fill_value if needed,,Yes,Yes
15435,Update the mask if needed,,,Yes
15436,Reshape if needed,,No,Yes
15437,Temporary workaround to account for the fact that str and bytes,,,Yes
15440,Fix the invalid parts,,Yes,Yes
15441,Needed by dot; so move here from extras.py. It will still be exported,,Yes,Yes
15442,workaround for #8666; to preserve identity. Ideally the bottom line,,Yes,Yes
15446,lots of things could go wrong here,,No,Yes
15449,append columns,,No,Yes
15451,produces a better error message than assert_(a.startswith(b)),,No,Yes
15452,Fixme: this does not look right.,,Yes,Yes
15453,"\""\""\"" || Abstract base class for the various polynomial Classes. ||  || The ABCPolyBase class provides the methods needed to implement the common API || for the various polynomial classes. It operates as a mixin; but uses the || abc module from the stdlib; hence it is only available for Python >= 2.6. ||  || \""\""\""",,,Yes
15455,Determine the norms of the design matrix columns.,,Yes,Yes
15456,This can be made more efficient by using powers of two,,,Yes
15457,Determine the norms of the design matrix columns.,,Yes,Yes
15458,matrix is symmetric in this case in order to obtain better zeros.,,Yes,Yes
15463,Determine the norms of the design matrix columns.,,Yes,Yes
15464,matrix is symmetric in this case in order to obtain better zeros.,,Yes,Yes
15466,as reverse recursion in this application but it is more efficient.,,,Yes
15467,Determine the norms of the design matrix columns.,,,Yes
15468,matrix is symmetric in this case in order to obtain better zeros.,,,Yes
15470,Determine the norms of the design matrix columns.,,,Yes
15471,We need the mingw workaround for _ftime if the msvc runtime version is,,,Yes
15473,TODO: Uncomment once randint can broadcast arguments,,No,Yes
15474,"These classes implement a doctest runner plugin for nose; a \""known failure\""",,,Yes
15477,our way of doing coverage,,Yes,Yes
15478,Relies on pkg_resources; not a hard dependency,,Yes,Yes
15480,precision argument is only needed if the objects are ndarrays,,No,Yes
15483,Let users know if they're missing any of our hard dependencies,,,Yes
15486,until our algos support uint8 directly (see TODO),,No,Yes
15488,3.) Maybe boxing the output in an Index,,Yes,Yes
15490,TODO: this should support float64,,,Yes
15492,Last column in columns or values are unique in,,Yes,Yes
15494,curry if needed,,No,Yes
15495,TODO: mixed type case,,No,Yes
15496,we *always* preserve the original index \/ columns,,,Yes
15498,on the number of bytes needed.,,,Yes
15499,the same (maybe up to ordering; depending on ordered),,Yes,Yes
15500,By convention; empty lists result in object dtype:,,Yes,Yes
15501,FIXME,,,Yes
15502,Strip all leading spaces; which format_array adds for columns...,,Yes,Yes
15503,FIXME: remove when numpy 1.9 is the lowest numpy version pandas,,Yes,Yes
15504,Implement the ExtensionArray interface,,Yes,Yes
15506,the keys must be in the columns,,,Yes
15508,TODO: Remove after 0.23.x,,,Yes
15509,turn a datetime like into a Timestamp\/timedelta as needed,,No,Yes
15511,python 3 compat kludge,,,Yes
15513,assign if needed,,,Yes
15514,nodes that we don't support directly but are needed for parsing,,,Yes
15516,TODO: bug?,,No,Yes
15517,capture the environment if needed,,Yes,Yes
15519,automatically determine optimal number of columns,,Yes,Yes
15520,cannot determine optimal number of columns,,Yes,Yes
15522,force the dtype if needed,,No,Yes
15526,TODO: gh-15585: consider making the checks stricter.,,,Yes
15528,coerce to object if needed,,No,Yes
15531,find a better solution,,Yes,Yes
15532,Reconsider this decision once this numpy bug is fixed:,,,Yes
15533,"\""\""\"" || DataFrame || --------- || An efficient 2D container for potentially mixed-type time series or other || labeled data series. ||  || Similar to its R counterpart; data.frame; except providing automatic data || alignment and a host of useful data manipulation methods having to do with the || labeling information || \""\""\""",,Yes,Yes
15535,XXX: In IPython 3.x and above; the Qt console will not attempt to,,No,Yes
15536,IPython 2.x is no longer needed.,,No,Yes
15538,Make a copy of the input columns so we can modify it,,Yes,Yes
15539,TODO: a generic formatter wld b in DataFrameFormatter,,,Yes
15540,hack,,No,Yes
15541,duplicate columns & possible reduce dimensionality,,,Yes
15543,broadcast across multiple columns if necessary,,,Yes
15544,to ndarray and maybe infer different dtype,,,Yes
15545,Verify all columns in subset exist in the queried dataframe,,,Yes
15546,TODO: this can be combined with Series.sort_index impl as,,,Yes
15548,for the mixed_type case where we iterate over columns;,,,Yes
15549,iterate over columns,,Yes,Yes
15551,non-unique columns,,,Yes
15552,TODO: Support other joins,,,Yes
15554,TODO: flipped axis,,,Yes
15555,TODO: Make other agg func handle axis=None properly,,,Yes
15558,fill if needed,,No,Yes
15561,index or columns,,,Yes
15564,Handle dropping columns labels,,Yes,Yes
15565,Allow shorthand to delete all columns whose first len(key),,,Yes
15566,Maybe set copy if we didn't actually change the index.,,,Yes
15567,TODO: Decide if we care about having different examples for different,,,Yes
15569,TODO: Not sure if above is correct - need someone to confirm.,,Yes,Yes
15570,TODO: Better unicode\/repr for GroupBy object,,Yes,Yes
15573,fails on *some* columns; e.g. a numeric operation,,,Yes
15574,"iterate through \""columns\"" ex exclusions to populate output dict",,No,Yes
15575,TODO: implement at Cython level?,,Yes,Yes
15579,TODO: These if-block and else-block are almost same.,,,Yes
15581,CombinedDatetimelikeProperties isn't really instantiated. Instead,,,Yes
15582,TODO: handle index names!,,Yes,Yes
15584,maybe coerce to a sub-class,,No,Yes
15586,TODO: i; j are not used anywhere,,No,Yes
15587,TODO: is_dtype_union_equal is a hack around,,No,Yes
15588,Once those are fixed; this workaround can be removed,,Yes,Yes
15590,TODO: if we are a MultiIndex; we can do better,,,Yes
15592,Indexing on codes is more efficient if categories are the same:,,Yes,Yes
15596,Following Timestamp convention; __eq__ is all-False,,,Yes
15599,do better,,Yes,Yes
15600,TODO: integrate with categorical and make generic,,,Yes
15601,name argument is unused here; just for compat with base \/ categorical,,Yes,Yes
15602,TODO: arithmetic operations,,No,Yes
15603,Calculate the number of bits needed to represent labels in each,,Yes,Yes
15604,that each level needs to be shifted by the number of bits needed to,,Yes,Yes
15605,Check the total number of bits needed for our representation:,,,Yes
15606,TODO: what if a level contains tuples??,,No,Yes
15607,little bit of a kludge job for #1217,,No,Yes
15608,Since few levels are typically unused; bincount() is more,,No,Yes
15609,efficient than unique() - however it only accepts positive values,,Yes,Yes
15610,We have unused levels,,No,Yes
15611,set nan if needed,,No,Yes
15612,kludge for #1796,,No,Yes
15616,maybe partial set,,,Yes
15618,no columns and scalar,,Yes,Yes
15619,must have conforming columns,,Yes,Yes
15620,which means essentially reassign to the columns of a,,,Yes
15622,need to conform to the convention,,Yes,Yes
15623,of what is needed,,,Yes
15626,we maybe be using a tuple to represent multiple dimensions here,,Yes,Yes
15627,df.ix[d1:d2; 0] -> columns first (True),,,Yes
15630,maybe coerce a float scalar to integer,,Yes,Yes
15632,TODO: this prob needs some better checking,,Yes,Yes
15635,mask if needed,,Yes,Yes
15636,transpose if needed,,No,Yes
15637,XXX: We may need to think about pushing this onto the array.,,Yes,Yes
15639,TODO: Refactor when convert_objects is removed since there will be 1 path,,Yes,Yes
15640,TODO: this still uses asarray; instead of dtype.type,,Yes,Yes
15644,This is a workaround for pre-0.14.1 pickles that didn't,,Yes,Yes
15646,fillna internally does putmask; maybe it's better to do this,,Yes,Yes
15647,FIXME: optimization potential,,,Yes
15648,Workaround for numpy 1.7 bug:,,,Yes
15652,FIXME: mgr_groupby_blknos must return mgr_locs in ascending order;,,,Yes
15655,TODO: lexsort depth needs to be 2!!,,,Yes
15657,change the dtype if needed,,Yes,Yes
15662,reshape a 1 dim if needed,,,Yes
15664,promote if needed,,,Yes
15665,to fix the fperr to treat m2 <1e-14 as zero,,,Yes
15666,to fix the fperr to treat denom <1e-14 as zero,,Yes,Yes
15667,#18044 reference this behavior to fix rolling skew\/kurt issue,,Yes,Yes
15668,TODO: what if they both have np.nan for their names?,,,Yes
15670,TODO: can we make a no-copy implementation?,,,Yes
15671,TODO: Can we make the allowed_types arg unnecessary?,,,Yes
15675,rename is needed in case res_name is None and self.name,,No,Yes
15676,default axis is columns,,,Yes
15677,FIXME: GH#5284; GH#5035; GH#19448,,Yes,Yes
15678,straight boolean comparisons we want to allow all columns,,Yes,Yes
15679,TODO: Make other agg func handle axis=None properly,,,Yes
15680,convert if needed,,No,Yes
15681,.resample uses 'on' similar to how .groupby uses 'key',,Yes,Yes
15682,thus last bin maybe slightly before the end if the end contains,,Yes,Yes
15683,a little hack,,,Yes
15684,hack!,,Yes,Yes
15686,creating column numbers as needed,,No,Yes
15687,combine as columns in a frame,,,Yes
15688,TODO: what about the existing index?,,Yes,Yes
15689,asanyarray will keep the columns as an Index,,,Yes
15690,TODO; should _merge_pieces do this?,,Yes,Yes
15691,TODO: transformations??,,No,Yes
15692,TODO: only copy DataFrames when modification necessary,,,Yes
15695,work-around for merge_asof(left_index=True),,Yes,Yes
15696,columns; and end up trying to merge,,,Yes
15697,use the common columns,,,Yes
15699,initial type conversion as needed,,Yes,Yes
15700,fix right labels if there were any nulls,,Yes,Yes
15701,_shared_docs['pivot_table'] will not yet exist.  TODO: Fix this dependency,,,Yes
15702,GH 15193 Make sure empty columns are removed if dropna=True,,,Yes
15704,slight hack,,,Yes
15705,to keep index and columns names,,,Yes
15706,Fix Margins,,Yes,Yes
15707,XXX: Makes SparseArray *dense*; but it's supposedly,,Yes,Yes
15709,The two indices differ only if the unstacked level had unused items:,,No,Yes
15710,NOTE: This doesn't deal with hierarchical columns yet,,Yes,Yes
15711,and isn't needed for a single level,,Yes,Yes
15713,tuple list excluding level for grouping columns,,,Yes
15714,can make more efficient?,,,Yes
15715,something better?,,Yes,Yes
15716,more efficient way to go about this? can do the whole masking biz but,,Yes,Yes
15721,kludge,,,Yes
15722,hack,,,Yes
15723,TODO: integrate bottleneck,,Yes,Yes
15724,TODO: Add option for bins like value_counts(),,No,Yes
15725,TODO: it must return DatetimeArray with tz in pandas 2.0,,No,Yes
15729,Maybe set copy if we didn't actually change the index.,,Yes,Yes
15730,move labels to right locations (ie; unsort ascending labels),,Yes,Yes
15732,TODO: figure out how to handle this case; all nan's?,,Yes,Yes
15733,add in any other columns we want to have (completeness),,No,Yes
15734,Add any columns that were empty and thus not grouped on above,,Yes,Yes
15735,TODO: be a bit more intelligent here,,No,Yes
15736,patched version of DataFrame._combine_match_columns to account for,,Yes,Yes
15737,TODO: fill value handling,,No,Yes
15738,TODO: Figure out whether this can be reached.,,No,Yes
15739,TODO: how to do this better? cleanly slice nonnull_labels given the,,Yes,Yes
15741,TODO: specify kind?,,Yes,Yes
15742,TODO: make more efficient,,Yes,Yes
15744,not needed when inferred,,No,Yes
15745,better represented as a regular Index.,,Yes,Yes
15747,Need to add keys for uniqueness in case of duplicate columns,,,Yes
15748,TODO: GH 15362,,,Yes
15751,FIXME: pyperclip currently does not support Cygwin;,,Yes,Yes
15752,Workaround for https:\/\/bugs.kde.org\/show_bug.cgi?id=342874,,,Yes
15753,TODO: https:\/\/github.com\/asweigart\/pyperclip\/issues\/43,,,Yes
15754,try to decode (if needed on PY3),,Yes,Yes
15755,TODO: support other fill patterns,,,Yes
15756,validate columns,,,Yes
15758,TODO: support %,,No,Yes
15759,hack for 'large' etc.,,Yes,Yes
15760,TODO: don't lowercase case sensitive parts of values (strings),,Yes,Yes
15761,update columns to include possible multiplicity of dupes,,,Yes
15762,TODO: memoize?,,No,Yes
15763,TODO: support number format,,,Yes
15767,MultiIndex columns require an extra row,,Yes,Yes
15770,Format only rows and columns that could potentially fit the,,,Yes
15771,`self._to_str_columns,,,Yes
15772,self.str_columns = str_columns,,Yes,Yes
15773,empty space for columns,,Yes,Yes
15774,string representation of the columns,,,Yes
15775,sum up columns to multicolumns,,,Yes
15778,Blank for Index columns...,,Yes,Yes
15779,... except maybe the last for columns.names,,Yes,Yes
15780,TODO: namespace all the pandas keys,,,Yes
15781,needed for window's python in cygwin's xterm!,,,Yes
15782,"\""\""\"":mod:`pandas.io.html` is a module containing functionality for dealing with || HTML IO. ||  || \""\""\""",,Yes,Yes
15784,TODO: Do this timedelta properly in objToJSON.c See GH #15137,,,Yes
15785,possibly handle dup columns,,,Yes
15789,obj['data']; columns=obj['columns'];,,Yes,Yes
15790,TODO: Remove in pandas 0.23.0,,Yes,Yes
15792,May alter columns \/ col_dict,,,Yes
15793,extract the columns,,Yes,Yes
15794,XXX this is for consistency with,,No,Yes
15796,we have a multi index in the columns,,Yes,Yes
15798,The names attribute should have the correct columns,,Yes,Yes
15801,Now self.columns has the set of columns that we will process.,,Yes,Yes
15804,we have a mi columns; so read an extra line,,Yes,Yes
15810,use the meta if needed,,Yes,Yes
15811,Handle case of NaN-only categorical columns in which case,,Yes,Yes
15813,Transform needed to interface with pytables row\/col notation,,Yes,Yes
15815,index columns,,Yes,Yes
15816,values columns,,Yes,Yes
15817,index all indexables and data_columns,,Yes,Yes
15818,evaluate the passed data_columns; True == use all columns,,,Yes
15819,return valid columns in the order of our axis,,No,Yes
15821,do we have an existing table (if so; use its axes & data_columns),,Yes,Yes
15822,reindex by our non_index_axes & compute data_columns,,No,Yes
15824,make sure that we match up the existing columns,,,Yes
15826,hack until we support reversed dim flags,,,Yes
15829,broadcast the indexes if needed,,No,Yes
15830,reshape the values if needed,,Yes,Yes
15831,the index columns is just a simple index,,Yes,Yes
15832,encode if needed,,Yes,Yes
15833,"\""\""\"" || Collection of query wrappers \/ abstractions to both facilitate data || retrieval and to reduce dependency on DB-specific API. || \""\""\""",,,Yes
15836,return the used column labels for the index columns,,Yes,Yes
15839,TODO(wesm): unused?,,,Yes
15841,Convert columns (if needed) to match input type,,No,Yes
15842,Copy information for retained columns for later processing,,Yes,Yes
15843,TODO: is the next line needed above in the data(...) method?,,,Yes
15845,Upcast if needed so that correct missing values can be set,,Yes,Yes
15846,Check date conversion; and fix key if needed,,,Yes
15847,Check columns for compatibility with stata; upcast if necessary,,,Yes
15848,Ensure all date columns are converted,,Yes,Yes
15849,xxx...xxx,,,Yes
15851,TODO(wesm) unused?,,,Yes
15853,TODO: Check the following : is it really info['fmt'] ?,,No,Yes
15856,Probably better to accept either.,,Yes,Yes
15857,TODO: unused?,,,Yes
15860,columns = data.columns,,,Yes
15861,TODO: use Matplotlib public API when available,,No,Yes
15863,probably a better place to check \/ set this.,,Yes,Yes
15864,flier colors isn't needed here,,No,Yes
15867,hack this for 0.10.1; creating more technical debt...sigh,,Yes,Yes
15869,top-level to deprecate in the future,,Yes,Yes
15870,check unused categories,,No,Yes
15871,"This doesn't work -> this would probably need some kind of \""remember",,Yes,Yes
15872,hack because array_repr changed in numpy > 1.6.x,,,Yes
15873,TODO: the code below should be added back when left and right,,Yes,Yes
15874,maybe someday... numexpr has too many upcasting rules now,,No,Yes
15877,TODO: Use a regular dict. See _NDFrameIndexer._setitem_with_indexer,,Yes,Yes
15878,TODO (EA.factorize): see if _values_for_factorize allows this.,,Yes,Yes
15880,TODO should set_index check_names ?,,,Yes
15882,partial columns,,Yes,Yes
15883,only remove certain columns,,Yes,Yes
15885,equivalence of the labels\/axis and index\/columns API's,,,Yes
15887,works when only those columns are selected,,,Yes
15888,ensure this works; bug report,,,Yes
15890,partial overlapping columns,,,Yes
15891,Given the wide dataframe with a lot of columns,,No,Yes
15893,TODO(wesm): unused?,,,Yes
15894,named columns,,Yes,Yes
15895,interaction of named columns & series,,,Yes
15896,TODO(wesm): unused,,,Yes
15897,DataFrame whose columns are identifiers shall have them in __dir__.,,,Yes
15898,DataFrame whose first-level columns are identifiers shall have,,,Yes
15899,preserve columns,,,Yes
15901,equivalence of the labels\/axis and index\/columns API's (GH12392),,,Yes
15903,GH 14992; reindexing over columns ignored method,,Yes,Yes
15904,equivalence of the labels\/axis and index\/columns API's,,,Yes
15905,TODO(wesm): unused?,,Yes,Yes
15907,as B and C are both unsigned; no forcing to float is needed,,,Yes
15908,f7u12; this does not work without extensive workaround,,Yes,Yes
15909,TODO(wesm): unused?,,Yes,Yes
15910,numeric and object columns,,Yes,Yes
15913,Non-Empty df with columns append empty df,,Yes,Yes
15914,these must be the same results (but columns are flipped),,No,Yes
15916,Columns\/1 Series,,,Yes
15917,ToDo: this must be datetime64,,,Yes
15918,empty with index and columns,,,Yes
15919,dict with scalar values should raise error; even if columns passed,,Yes,Yes
15920,passing an empty array with columns specified.,,Yes,Yes
15922,does not error but ends up float,,,Yes
15923,TODO: Fix this Exception to be better...,,Yes,Yes
15924,with columns,,No,Yes
15927,tuples is in the order of the columns,,Yes,Yes
15928,columns is in a different order here than the actual items iterated,,Yes,Yes
15937,no columns but Index(dtype=object),,Yes,Yes
15938,this *does* align; though has no matching columns,,Yes,Yes
15939,Upcast needed,,,Yes
15941,TODO should this check_names ?,,,Yes
15942,df2 may have different index and columns,,Yes,Yes
15944,TODO(wesm): unused?,,Yes,Yes
15945,from the vb_suite\/frame_methods\/frame_insert_columns,,,Yes
15946,preserve columns name field,,Yes,Yes
15950,no upcast needed,,,Yes
15951,vs mix (upcast) as needed,,No,Yes
15952,columns,,,Yes
15957,columns are not sortable,,Yes,Yes
15959,pivot multiple columns,,No,Yes
15960,flat columns:,,No,Yes
15961,MultiIndex columns:,,,Yes
15962,Workaround for GH #17886 (unnecessarily casts to float):,,Yes,Yes
15963,Checks fix for #11847,,No,Yes
15964,GH 17845: unused labels in index make unstack() cast int to float,,No,Yes
15965,Unused items on both levels,,No,Yes
15967,Two columns,,No,Yes
15968,Compute expected by sorting on columns and the setting index,,,Yes
15970,Accessing multi-level columns that are not lexsorted raises a,,,Yes
15972,only correct for datetime64 columns.,,,Yes
15973,"NaT is not a \""na\"" for int64 columns; so na_position must not",,Yes,Yes
15975,axis=1 : sort columns by column names,,No,Yes
15976,in the presence of duplicate columns,,,Yes
15980,TODO: remove renaming when GH 10875 is solved,,,Yes
15982,labeling them dupe.1;dupe.2; etc'. monkey patch columns,,Yes,Yes
15983,GH 3624; after appending columns; to_csv fails,,,Yes
15986,needed if setUp becomes class method,,Yes,Yes
15987,read_csv will rename the dups columns,,Yes,Yes
15988,Check that columns get converted,,Yes,Yes
15989,Columns don't get converted to ints by read_csv,,Yes,Yes
15990,TODO,,Yes,Yes
15993,TODO(wesm): unused,,Yes,Yes
15994,multiple columns,,,Yes
15997,Grouping on two columns,,,Yes
15998,TODO: min; max *should* handle,,Yes,Yes
16001,Group by two columns,,No,Yes
16002,reset_index changes columns dtype to object,,,Yes
16004,XXX,,,Yes
16006,group columns,,,Yes
16008,bit a of hack to make sure the cythonized shift,,,Yes
16010,TODO check groupby with > 1 col ?,,No,Yes
16015,GH issue #17965; test for ability to compare datetime64[ns] columns,,,Yes
16018,Is this really how it should fail??,,,Yes
16021,extra columns,,Yes,Yes
16024,TODO: is this right?,,No,Yes
16025,TODO: @shoyer believes this should raise; master branch doesn't,,,Yes
16028,TODO: Some of these are misnomers because of non-Tick DateOffsets,,,Yes
16034,TODO: Try creating a UnicodeDecodeError in exception message,,,Yes
16035,FIXME data types changes to float because,,,Yes
16036,if this fails; probably didn't reset the cache correctly.,,,Yes
16038,TODO: Needs more informative name; probably split up into,,,Yes
16040,TODO(wesm): unused?,,Yes,Yes
16042,TODO should this work? (-1 is not contained in any of the Intervals),,,Yes
16045,TODO(wesm): unused?,,,Yes
16048,TODO(wesm): unused?,,Yes,Yes
16049,ToDo: check_index_type can be True after GH 11497,,,Yes
16051,GH8258; tests that both rows & columns are aligned to what is,,,Yes
16053,set all columns,,,Yes
16056,reindex columns is ok,,,Yes
16058,FIXME: doesn't support num_rows != 10,,Yes,Yes
16059,TODO: merge with mixed type?,,No,Yes
16060,we maybe using an ndarray to test slicing and,,Yes,Yes
16063,TODO: use mock fixutre.,,,Yes
16064,regular columns,,,Yes
16068,test hiding mulitiple columns,,,Yes
16069,hide top column level; which hides both columns,,Yes,Yes
16070,panels if their columns\/items were non-unique.,,,Yes
16072,TODO,,,Yes
16074,TODO: When DF coercion issue (#21345) is resolved tighten type checks,,No,Yes
16076,index and columns are strings as all unserialised JSON object keys,,Yes,Yes
16078,too many columns,,No,Yes
16079,the same with multiple columns threw segfaults,,No,Yes
16080,GH15096: escaped characters in columns and data,,,Yes
16088,parser when faced with no provided columns,,No,Yes
16091,"\""\""\"" || Tests that duplicate columns are handled appropriately when parsed by the || CSV engine. In general; the expected result is that they are either thoroughly || de-duplicated (if mangling requested) or ignored otherwise. || \""\""\""",,,Yes
16093,specify columns out of order!,,Yes,Yes
16094,can probably mock this though.,,No,Yes
16095,GH 17351 - usecols needs to be sorted in _setnoconvert_columns,,Yes,Yes
16096,before GH 17351 would cause the wrong columns to be,,Yes,Yes
16097,From Thomas Kluyver: apparently some non-space filler characters can,,Yes,Yes
16101,TODO add index to xls; read xls ignores index name ?,,,Yes
16102,TODO add index to xls file,,,Yes
16105,MultiIndex as columns is not yet implemented 9794,,Yes,Yes
16107,XXX: should find a better way to check equality,,,Yes
16108,XXX: openpyxl (as at 2.4) prefixes colors with 00; xlsxwriter with FF,,,Yes
16110,not currently able to handle duplicate columns,,,Yes
16115,seee GH7796 FIXME,,Yes,Yes
16117,multiple data columns,,,Yes
16118,GH5717 not handling data_columns,,No,Yes
16119,data columns,,,Yes
16120,recreate multi-indexes when columns is passed,,No,Yes
16121,multiple invalid columns,,,Yes
16122,a bit hacky here as we don't really deal with the NaT properly,,Yes,Yes
16123,TODO: unused?,,No,Yes
16124,duplicates on both index and columns,,,Yes
16125,selection on the non-indexable with a large number of columns,,,Yes
16128,bool columns (GH #2849),,Yes,Yes
16129,big selector along the columns,,Yes,Yes
16130,Check that read_hdf with categorical columns doesn't return rows if,,,Yes
16133,TODO: Add back to types_should_fail,,,Yes
16136,multiple columns as key (GH10385),,,Yes
16137,XXX:,,Yes,Yes
16139,{c : c[-2:] for c in columns},,,Yes
16140,Multiple columns with an ax argument should use same figure,,,Yes
16141,TODO,,Yes,Yes
16142,TODO (GH14330; GH14322),,Yes,Yes
16143,columns.inferred_type == 'string',,,Yes
16144,columns.inferred_type == 'integer',,Yes,Yes
16145,columns.inferred_type == 'mixed',,,Yes
16147,Other columns should not be visible,,,Yes
16151,aggregate multiple columns,,Yes,Yes
16152,_assert_same_contents(expected; expected2.loc[:; expected.columns]),,,Yes
16155,Merge on multiple columns,,,Yes
16156,TODO check_names on merge?,,Yes,Yes
16157,TODO: columns aren't in the same order yet,,Yes,Yes
16158,merging on float and int columns,,Yes,Yes
16159,float columns where the float values are not exactly,,Yes,Yes
16160,TODO ([0; 1]; pd.Series([False; True]; dtype=bool));,,Yes,Yes
16161,non-merge columns should preserve if possible,,,Yes
16162,our merging columns; X now has 2 different dtypes,,Yes,Yes
16164,Convert remaining index levels to columns,,,Yes
16166,ToDo: suspicious,,,Yes
16167,see gh-6129: new columns,,Yes,Yes
16168,See also test 'test_append_different_columns_types_raises' below,,Yes,Yes
16170,columns have mixed tuples; so handle properly,,Yes,Yes
16173,TODO: unused?,,,Yes
16175,Sparse dataframes do not allow nan labelled columns; see #GH8822,,No,Yes
16176,hack (NaN handling in assert_index_equal),,No,Yes
16178,TODO: GH-19761. Change to TypeError.,,,Yes
16179,TODO: unused?,,No,Yes
16182,TODO: unused?,,No,Yes
16183,GH XXX,,Yes,Yes
16184,TODO: unused,,No,Yes
16186,HACK: By doing this in two stages; we avoid 2to3 wrapping the call,,No,Yes
16187,and the methods '.set_categories()' 'drop_unused_categories()' to the,,No,Yes
16190,TODO: the direct operation TimedeltaIndex \/ Series still,,Yes,Yes
16192,TODO: Decide if this ought to work.,,Yes,Yes
16196,multi-columns sort,,No,Yes
16198,ToDo: apply must return subclassed dtype,,,Yes
16201,no index or columns,,,Yes
16202,wrong length index \/ columns,,,Yes
16203,TODO: x_sparse is unused...fix,,,Yes
16204,TODO: y_sparse is unsused...fix,,,Yes
16206,reindex columns,,No,Yes
16207,Over columns,,,Yes
16208,TODO: sp_zero is not used anywhere...remove?,,,Yes
16211,ToDo: sparse sum includes str column,,Yes,Yes
16212,TODO: index variables are not used...is that right?,,,Yes
16213,ToDo: sum doesn't handle nan properly,,Yes,Yes
16214,TODO(wesm): unused?,,Yes,Yes
16215,TODO same for (timedelta),,,Yes
16216,Delegate does not implement memory_usage.,,No,Yes
16217,Following DatetimeIndex (and Timestamp) convention;,,Yes,Yes
16218,TODO: FIGURE OUT HOW TO GET IT TO WORK...,,No,Yes
16219,TODO(wesm): unused?,,,Yes
16221,more than 2 levels in the columns,,,Yes
16225,sorting fails after columns added,,Yes,Yes
16226,some nanops handle object dtypes better than their numpy,,,Yes
16228,bug for numpy < 1.13; where result is a series; should be a scalar,,Yes,Yes
16229,TODO: this converts back to object,,,Yes
16234,odd results when rounding is needed,,No,Yes
16236,df.columns = ['PRICE'; 'PRICE'],,Yes,Yes
16237,dup columns with resample raising,,Yes,Yes
16238,TODO: replace calls to .create_series() by injecting the series,,,Yes
16239,This is a bug; these should be implemented,,Yes,Yes
16240,def test_monthly_convention_span(self):,,,Yes
16243,TODO see GH 18463,,Yes,Yes
16246,TODO: xref gh-15826,,No,Yes
16248,invalid columns,,,Yes
16252,ToDo: enable when we can support native PeriodDtype,,Yes,Yes
16253,res = pd.to_numeric(pd.Series(idx; name='xxx')),,Yes,Yes
16256,TODO: WTF?  What is this range(10) supposed to do?,,,Yes
16258,TODO: Combine this with BusinessMixin version by defining a whitelisted,,,Yes
16259,XXX; see #1395,,Yes,Yes
16261,TODO: standardize `_offset` vs `offset` naming convention,,Yes,Yes
16262,TODO: Cache this once offsets are immutable,,,Yes
16263,TODO: cache this once offsets are immutable,,,Yes
16264,TODO: Figure out the end of this sente,,No,Yes
16265,TODO: Consider combining QuarterOffset and YearOffset __init__ at some,,Yes,Yes
16267,TODO: there may be a more performant way to do this,,,Yes
16268,TODO: Why does this handle the 0 case the opposite of others?,,No,Yes
16269,TODO: do Tick classes with normalize=True make sense?,,Yes,Yes
16270,TODO: Should Tick have its own apply_index?,,,Yes
16272,like out = {'index': foo; 'columns': bar},,Yes,Yes
16274,TODO: big hack here,,,Yes
16276,compare by columns,,,Yes
16277,Both of the above shouldn't mask real issues such as 404's,,Yes,Yes
16279,XXX Linux and other platforms' special cases should go here,,Yes,Yes
16280,XXX add more info,,,Yes
16286,Python 2 on Windows needs to be handled this way :(,,,Yes
16287,metadata until\/unless it's actually needed.  (i.e.; some distributions,,,Yes
16288,this method. In the future this should be smarter and follow PEP 440,,,Yes
16290,implement this in terms of the other specifiers instead of,,Yes,Yes
16293,This is a bit ugly; but it avoids running this again by,,,Yes
16296,and ends at 2am (DST time; 1am standard time) on the last Sunday of Oct.,,,Yes
16297,doubt this will ever been needed in real life.,,Yes,Yes
16301,which uses the defacto standard originally implemented by setuptools;,,Yes,Yes
16302,"\""\""\""(Deprecated) Predefined expression of 1 or more printable words or quoted strings; separated by commas.\r ||    This expression is deprecated in favor of L{pyparsing_common.comma_separated_list}.\""\""\""",,No,Yes
16303,This is a bit ugly; but it avoids running this again by,,Yes,Yes
16304,Workaround for standalone backslash,,,Yes
16305,XXX Ugh,,No,Yes
16307,Hack for packages that install data to install's --install-lib,,Yes,Yes
16308,XXX else: raise ???,,,Yes
16309,XXX Help!  I don't have any idea whether these are right...,,,Yes
16310,XXX what to do with conflicts?,,No,Yes
16311,hack so distutils' build_extension() builds a library instead,,Yes,Yes
16313,XXX as dynamic; and not just using a locally-found version or a,,No,Yes
16314,XXX static-compiled version,,Yes,Yes
16315,XXX we need to either disallow these attrs on Library instances;,,,Yes
16317,XXX should also check for entry point scripts!,,No,Yes
16318,cast to str as workaround for #709 and #710 and #712,,No,Yes
16319,Installation is also needed if file in tmpdir or is not an egg,,,Yes
16321,if the only thing there is a directory; move it instead,,,Yes
16323,TODO: self.report_extras(req; dist),,,Yes
16325,exact loader instance used when importing them. Python 3.4 docs state,,Yes,Yes
16326,this is really needed.,,,Yes
16329,Fix older sdists built on Windows,,,Yes
16330,XXX Python 3.1 doesn't see _nc if this is inside the class,,Yes,Yes
16331,TODO: is it necessary to short-circuit here? i.e. what's the cost,,,Yes
16334,"Some people apparently take \""version number\"" too literally :)",,,Yes
16335,XXX may convert to set here when we can rely on set being builtin,,,Yes
16336,workaround for #334.,,Yes,Yes
16337,The *args is needed for compatibility as calls may use positional,,Yes,Yes
16338,mysterious hack:,,,Yes
16340,fix findall bug in distutils (http:\/\/bugs.python.org\/issue12885),,,Yes
16341,For VC++ 9.0; if IA64 support is needed; redirect user,,Yes,Yes
16342,XXX Yuck,,No,Yes
16343,this line is here to fix emacs' cruddy broken syntax highlighting,,,Yes
16345,"\""\""\""Workaround for http:\/\/bugs.python.org\/issue24672\""\""\""",,Yes,Yes
16346,XXX according to RFC 2818; the most specific Common Name,,,Yes
16347,This is a bit ugly; but it avoids running this again by,,,Yes
16348,Workaround for standalone backslash,,Yes,Yes
16351,XXX backward compat,,Yes,Yes
16352,XXX Linux and other platforms' special cases should go here,,Yes,Yes
16354,workaround a cache issue,,,Yes
16356,Register the new requirements needed by req,,No,Yes
16357,XXX backward compatibility,,No,Yes
16359,Python 2 on Windows needs to be handled this way :(,,Yes,Yes
16364,which uses the defacto standard originally implemented by setuptools;,,Yes,Yes
16366,This is a bit ugly; but it avoids running this again by,,,Yes
16367,Workaround for standalone backslash,,,Yes
16368,mysterious hack:,,No,Yes
16369,copy it and modify as needed.,,,Yes
16372,implement this in terms of the other specifiers instead of,,Yes,Yes
16373,which uses the defacto standard originally implemented by setuptools;,,,Yes
16374,"\""\""\""(Deprecated) Predefined expression of 1 or more printable words or quoted strings; separated by commas.\r ||    This expression is deprecated in favor of L{pyparsing_common.comma_separated_list}.\""\""\""",,No,Yes
16375,This is a bit ugly; but it avoids running this again by,,Yes,Yes
16376,Workaround for standalone backslash,,,Yes
16377,XXX Ugh,,,Yes
16379,Hack for packages that install data to install's --install-lib,,Yes,Yes
16380,XXX else: raise ???,,No,Yes
16382,XXX what to do with conflicts?,,No,Yes
16384,XXX this should check to ensure the lib is actually being built,,Yes,Yes
16388,XXX,,,Yes
16390,cast to str as workaround for #709 and #710 and #712,,,Yes
16391,Installation is also needed if file in tmpdir or is not an egg,,Yes,Yes
16392,XXX this is not the distribution we were looking for,,Yes,Yes
16393,if the only thing there is a directory; move it instead,,Yes,Yes
16394,XXX,,Yes,Yes
16395,TODO: self.report_extras(req; dist),,Yes,Yes
16397,exact loader instance used when importing them. Python 3.4 docs state,,Yes,Yes
16398,this is really needed.,,Yes,Yes
16399,and have PyPy repopulate it as needed. The downside is that if there are any,,No,Yes
16400,spelling; but that seems like a way too invasive move (this cache,,No,Yes
16404,only needed on Python prior to 3.6.,,Yes,Yes
16406,"Some people apparently take \""version number\"" too literally :)",,,Yes
16407,XXX may convert to set here when we can rely on set being builtin,,No,Yes
16408,workaround for #334.,,,Yes
16409,The *args is needed for compatibility as calls may use positional,,Yes,Yes
16410,mysterious hack:,,,Yes
16413,For VC++ 9.0; if IA64 support is needed; redirect user,,,Yes
16415,this line is here to fix emacs' cruddy broken syntax highlighting,,,Yes
16417,"\""\""\""Workaround for http:\/\/bugs.python.org\/issue24672\""\""\""",,,Yes
16419,"\""\""\""Import workaround so that Bazel; Py2\/Py3; and enum34 package work together. ||  || This works around a problem due to the combination of Bazel putting || third party packages before the stdlib in PYTHONPATH. What happens is: ||   * The enum34 PyPi package is imported as 'enum'. ||   * Bazel puts the path to enum34 before the stdlib; hence 'import enum' ||     will prefer to use enum34 from above instead of the stdlib. ||   * In Python 3; enum34 is used instead of the stdlib; which breaks ||     lots of things. It works fine in Python 2; since there is no enum ||     module. ||  || To work around this; we do 3 things: ||   1. Put the enum34 code on PYTHONPATH; but not directly importable as ||      'enum'; it is under the (non importable) directory name with the ||      PyPi package name and version. ||   2. Try to import enum normally; if it works; great. This makes Py3 work ||      (as well as Py2 when enum is available as normal). ||   3. If the normal enum import failed; then try to find the enum34 ||      entry on sys.path; and append the missing directory name. ||  || Once it is successfully imported; expose the module directly. This || prevents importing the module twice under different names. e.g.; || the following is true: ||   from absl._enum_module import enum as absl_enum ||   import enum as normal_enum ||   assert absl_enum is normal_enum || \""\""\""",,Yes,Yes
16420,Unused.,,,Yes
16422,Unused.,,Yes,Yes
16424,allow_using_method_names=True in DEFINE_xxx functions.,,,Yes
16425,"\""no\"" then maybe it was a boolean flag specified in the",,No,Yes
16426,"\""\""\""Module to convert log levels between Abseil Python; C++; and Python standard. ||  || This converter has to convert (best effort) between three different || logging level schemes: ||   cpp      = The C++ logging level scheme used in Abseil C++. ||   absl     = The absl.logging level scheme used in Abseil Python. ||   standard = The python standard library logging level scheme. ||  || Here is a handy ascii chart for easy mental mapping. ||  ||   LEVEL    | cpp |  absl  | standard | ||   ---------+-----+--------+----------+ ||   DEBUG    |  0  |    1   |    10    | ||   INFO     |  0  |    0   |    20    | ||   WARNING  |  1  |   -1   |    30    | ||   ERROR    |  2  |   -2   |    40    | ||   CRITICAL |  3  |   -3   |    50    | ||   FATAL    |  3  |   -3   |    50    | ||  || Note: standard logging CRITICAL is mapped to absl\/cpp FATAL. || However; only CRITICAL logs from the absl logger (or absl.logging.fatal) will || terminate the program. CRITICAL logs from non-absl loggers are treated as || error logs with a message prefix \""CRITICAL - \"". ||  || Converting from standard to absl or cpp is a lossy conversion. || Converting back to standard will lose granularity.  For this reason; || users should always try to convert to standard; the richest || representation; before manipulating the levels; and then only to cpp || or absl if those level schemes are absolutely necessary. || \""\""\""",,,Yes
16427,This is a workaround if unittest.TestCase.__init__ was never run.,,,Yes
16428,seems to often end up being too smart for it's own good not escaping properly.,,No,Yes
16430,Worse; unittest uses _ErrorHandler instances to represent class \/ module,,Yes,Yes
16431,clear the outcome; no more needed,,,Yes
16432,XXX: Python 2.6 \/ 3.0 compatibility,,No,Yes
16433,XXX: self?,,Yes,Yes
16437,maybe 2020 for compatibility reason (with 3.4.1 only).,,No,Yes
16439,TODO(jieluo): Fix python to raise correct errors.,,,Yes
16440,"\""\""\""Code for encoding protocol message primitives. ||  || Contains the logic for encoding every logical protocol field type || into one of the 5 physical wire types. ||  || This code is designed to push the Python interpreter's performance to the || limits. ||  || The basic idea is that at startup time; for every field (i.e. every || FieldDescriptor) we construct two functions:  a \""sizer\"" and an \""encoder\"".  The || sizer takes a value of this field's type and computes its byte size.  The || encoder takes a writer function and a value.  It encodes the value into byte || strings and invokes the writer function to write those strings.  Typically the || writer function is the write() method of a BytesIO. ||  || We try to do as much work as possible when constructing the writer and the || sizer rather than when calling them.  In particular: || * We copy any needed global functions to local variables; so that we do not need ||   to do costly global table lookups at runtime. || * Similarly; we try to do any attribute lookups at startup time if possible. || * Every field's tag is encoded to bytes at startup; since it can't change at ||   runtime. || * Whatever component of the field size we can compute at startup; we do. || * We *avoid* sharing code if doing so would make the code slower and not sharing ||   does not burden us too much.  For example; encoders for repeated fields do ||   not just call the encoders for singular fields in a loop because this would ||   add an extra function call overhead for every loop iteration; instead; we ||   manually inline the single-value encoder into the loop. || * If a Python function lacks a return statement; Python actually generates ||   instructions to pop the result of the last statement off the stack; push ||   None onto the stack; and then return that.  If we really don't care what ||   value is returned; then we can save two instructions by returning the ||   result of the last statement.  It looks funny but it helps. || * We assume that type and bounds checking has happened at a higher level. || \""\""\""",,Yes,Yes
16441,obvious way to avoid this within the current design without tons of code,,Yes,Yes
16445,Kenton says:  The above is a BAD IDEA.  People rely on being able to use,,Yes,Yes
16447,TODO(robinson): This probably needs to be thread-safe(?),,Yes,Yes
16449,TODO(jieluo): Fix type checking difference for python and c extension,,No,Yes
16450,TODO(anuraag): Implement deepcopy for extension dict,,,Yes
16452,themselves in the foot in obvious ways.,,Yes,Yes
16453,efficient.,,,Yes
16454,Fetching the enum field shouldn't crash; instead returning the,,Yes,Yes
16456,TODO(robinson): Decide whether we like these better,,,Yes
16458,"length.  So; \""\\0011\"".encode('string_escape') ends up being \""\\\\x011\""; which",,No,Yes
16464,"\""\""\""The base interface of RPC Framework. ||  || Implementations of this interface support the conduct of \""operations\"": || exchanges between two distinct ends of an arbitrary number of data payloads || and metadata such as a name for the operation; initial and terminal metadata || in each direction; and flow control. These operations may be used for transfers || of data; remote procedure calls; status indication; or anything else || applications choose. || \""\""\""",,,Yes
16465,is compatible; and reshape if needed.,,Yes,Yes
16466,to workaround a possible h5py bug in the conversion.,,Yes,Yes
16470,TODO: more elegant way to pass these (dcpl to create_dataset?),,No,Yes
16471,TODO: support kwargs like require_dataset,,No,Yes
16475,TODO Change path to v1.1,,,Yes
16476,"\""\""\""NASNet-A models for Keras. ||  || NASNet refers to Neural Architecture Search Network; a family of models || that were designed automatically by learning the model architectures || directly on the dataset of interest. ||  || Here we consider NASNet-A; the highest performance model that was found || for the CIFAR-10 dataset; and then extended to ImageNet 2012 dataset; || obtaining state of the art performance on CIFAR-10 and ImageNet 2012. || Only the NASNet-A models; and their respective weights; which are suited || for ImageNet 2012 are provided. ||  || The below table describes the performance on ImageNet 2012: || -------------------------------------------------------------------------------- ||       Architecture       | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M) || -------------------------------------------------------------------------------- || |   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    | || |   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9    | || -------------------------------------------------------------------------------- ||  || Weights obtained from the official TensorFlow repository found at || https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/slim\/nets\/nasnet ||  || # References ||  ||  - [Learning Transferable Architectures for Scalable Image Recognition] ||     (https:\/\/arxiv.org\/abs\/1707.07012) ||  || This model is based on the following implementations: ||  ||  - [TF Slim Implementation] ||    (https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/slim\/nets\/nasnet\/nasnet.py) ||  - [TensorNets implementation] ||    (https:\/\/github.com\/taehoonlee\/tensornets\/blob\/master\/tensornets\/nasnets.py) || \""\""\""",,No,Yes
16477,Needed if we want to do something like:,,Yes,Yes
16483,TODO: remove this later,,,Yes
16488,Assemble major; minor; micro version and append `pre`; `post`; or `dev` if needed..,,,Yes
16491,TODO: If\/when py2 support is dropped change to:,,Yes,Yes
16492,TODO: remove this later,,,Yes
16498,hack to obtain the native and swapped byte order characters,,Yes,Yes
16501,"\""\""\"" || Conversion from ctypes to dtype. ||  || In an ideal world; we could acheive this through the PEP3118 buffer protocol; || something like:: ||  ||     def dtype_from_ctypes_type(t): ||         # needed to ensure that the shape of `t` is within memoryview.format ||         class DummyStruct(ctypes.Structure): ||             _fields_ = [('a'; t)] ||  ||         # empty to avoid memory allocation ||         ctype_0 = (DummyStruct * 0)() ||         mv = memoryview(ctype_0) ||  ||         # convert the struct; and slice back out the field ||         return _dtype_from_pep3118(mv.format)['a'] ||  || Unfortunately; this fails because: ||  || * ctypes cannot handle length-0 arrays with PEP3118 (bpo-32782) || * PEP3118 cannot represent unions; but both numpy and ctypes can || * ctypes cannot handle big-endian structs with PEP3118 (bpo-32780) || \""\""\""",,Yes,Yes
16502,This calls itself recursively but should eventually hit,,,Yes
16504,Note: Both scalartypes.c.src and arrayprint.py implement strs for numpy,,,Yes
16507,Now propagate as many unused contractions as possible to next iteration,,Yes,Yes
16508,DDOT without aligned data (better to use einsum),,Yes,Yes
16509,Build a new view if needed,,No,Yes
16510,This branch is needed for reductions like any which don't,,,Yes
16511,FIXME: ordered_funcs_api is unused,,,Yes
16513,needed instead of a 0 to get same result as zeros for for string dtypes,,Yes,Yes
16514,TODO: this works around .astype(bool) not working properly (gh-9847),,Yes,Yes
16515,fix hack in scipy which imports this function,,,Yes
16516,Move working axis to the end of the shape,,,Yes
16518,TODO: remove this when we drop Python 2 support (functools.wraps,,,Yes
16519,"\""\""\"" || Record Arrays || ============= || Record arrays expose the fields of structured arrays as properties. ||  || Most commonly; ndarrays contain elements of a single type; e.g. floats; || integers; bools etc.  However; it is possible for elements to be combinations || of these using structured types; such as:: ||  ||   >>> a = np.array([(1; 2.0); (1; 2.0)]; dtype=[('x'; int); ('y'; float)]) ||   >>> a ||   array([(1; 2.0); (1; 2.0)]; ||         dtype=[('x'; '<i4'); ('y'; '<f8')]) ||  || Here; each element consists of two fields: x (and int); and y (a float). || This is known as a structured array.  The different fields are analogous || to columns in a spread-sheet.  The different fields can be accessed as || one would a dictionary:: ||  ||   >>> a['x'] ||   array([1; 1]) ||  ||   >>> a['y'] ||   array([ 2.;  2.]) ||  || Record arrays allow us to access fields as properties:: ||  ||   >>> ar = np.rec.array(a) ||  ||   >>> ar.x ||   array([1; 1]) ||  ||   >>> ar.y ||   array([ 2.;  2.]) ||  || \""\""\""",,,Yes
16521,Perhaps a fancier check is in order here.,,Yes,Yes
16522,Distutils hack on AMD64 on windows,,Yes,Yes
16524,Ugly: this can be called within a library and not an extension;,,Yes,Yes
16525,needed).,,,Yes
16527,recompile of extension modules is needed.,,Yes,Yes
16529,algorithm is implemented which would likely be faster than the python,,Yes,Yes
16530,FIXME:RELATIVE_IMPORT,,,Yes
16533,Fix Python distutils bug sf #1718574:,,Yes,Yes
16534,this hack works around the msvc compiler attributes,,No,Yes
16537,Determine if C++\/Fortran 77\/Fortran 90 compilers are needed.,,No,Yes
16538,FIXME: In the case where there are more than two packages;,,Yes,Yes
16539,Needed to compile kiva.agg._agg extension.,,,Yes
16540,this hack works around the msvc compiler attributes,,No,Yes
16541,problem; msvc uses its own convention :(,,No,Yes
16542,XXX: Fix find_source_files for item in py_modules such that item is 3-tuple,,,Yes
16543,XXX: another ugly workaround to circumvent distutils brain damage. We,,Yes,Yes
16544,XXX TODO: --inplace support for sdist command,,,Yes
16545,XXX: hack to circumvent a python 2.6 bug with msvc9compiler:,,No,Yes
16546,XXX: Linker flags,,Yes,Yes
16548,"\""\""\"" || takes templated file .xxx.src and produces .xxx file  where .xxx is || .i or .c or .h; using the following template rules ||  || \/**begin repeat  -- on a line by itself marks the start of a repeated code ||                     segment || \/**end repeat**\/ -- on a line by itself marks it's end ||  || After the \/**begin repeat and before the *\/; all the named templates are placed || these should all have the same number of replacements ||  || Repeat blocks can be nested; with each nested block labeled with its depth; || i.e. || \/**begin repeat1 ||  *.... ||  *\/ || \/**end repeat1**\/ ||  || When using nested loops; you can optionally exclude particular || combinations of the variables using (inside the comment portion of the inner loop): ||  ||  :exclude: var1=value1; var2=value2; ... ||  || This will exclude the pattern where var1 is value1 and var2 is value2 when || the result is being generated. ||  ||  || In the main body each replace will use one entry from the list of named replacements ||  ||  Note that all #..# forms in a block must have the same number of ||    comma-separated entries. ||  || Example: ||  ||     An input file containing ||  ||         \/**begin repeat ||          * #a = 1;2;3# ||          * #b = 1;2;3# ||          *\/ ||  ||         \/**begin repeat1 ||          * #c = ted; jim# ||          *\/ ||         @a@; @b@; @c@ ||         \/**end repeat1**\/ ||  ||         \/**end repeat**\/ ||  ||     produces ||  ||         line 1 \""template.c.src\"" ||  ||         \/* ||          ********************************************************************* ||          **       This file was autogenerated from a template  DO NOT EDIT!!** ||          **       Changes should be made to the original source (.src) file ** ||          ********************************************************************* ||          *\/ ||  ||         #line 9 ||         1; 1; ted ||  ||         #line 9 ||         1; 1; jim ||  ||         #line 9 ||         2; 2; ted ||  ||         #line 9 ||         2; 2; jim ||  ||         #line 9 ||         3; 3; ted ||  ||         #line 9 ||         3; 3; jim ||  || \""\""\""",,,Yes
16549,replaces occurrences of xxx*3 with xxx; xxx; xxx,,Yes,Yes
16550,XXX Hack to get numpy installable with easy_install.,,Yes,Yes
16552,XXX: what does the value of,,,Yes
16554,XXX: other OS's. Eg. use _winreg on Win32. Or os.uname on unices.,,Yes,Yes
16557,XXX: Do we need LDSHARED->SOSHARED; LDFLAGS->SOFLAGS,,,Yes
16558,TODO: implement get_f90flags and use it in _compile similarly to get_f77flags,,Yes,Yes
16561,TODO: could use -Xlinker here; if it's supported,,Yes,Yes
16562,XXX status==256 may indicate 'unrecognized option' or,,,Yes
16564,XXX this is a wild guess,,No,Yes
16565,"\""\""\"" ||  || process_file(filename) ||  ||   takes templated file .xxx.src and produces .xxx file where .xxx ||   is .pyf .f90 or .f using the following template rules: ||  ||   '<..>' denotes a template. ||  ||   All function and subroutine blocks in a source file with names that ||   contain '<..>' will be replicated according to the rules in '<..>'. ||  ||   The number of comma-separated words in '<..>' will determine the number of ||   replicates. ||  ||   '<..>' may have two different forms; named and short. For example; ||  ||   named: ||    <p=d;s;z;c> where anywhere inside a block '<p>' will be replaced with ||    'd'; 's'; 'z'; and 'c' for each replicate of the block. ||  ||    <_c>  is already defined: <_c=s;d;c;z> ||    <_t>  is already defined: <_t=real;double precision;complex;double complex> ||  ||   short: ||    <s;d;c;z>; a short form of the named; useful when no <p> appears inside ||    a block. ||  ||   In general; '<..>' contains a comma separated list of arbitrary ||   expressions. If these expression must contain a comma|leftarrow|rightarrow; ||   then prepend the comma|leftarrow|rightarrow with a backslash. ||  ||   If an expression matches '\\\\<index>' then it will be replaced ||   by <index>-th expression. ||  ||   Note that all '<..>' forms in a block must have the same number of ||   comma-separated entries. ||  ||  Predefined named template rules: ||   <prefix=s;d;c;z> ||   <ftype=real;double precision;complex;double complex> ||   <ftypereal=real;double precision;\\\\0;\\\\1> ||   <ctype=float;double;complex_float;complex_double> ||   <ctypereal=float;double;\\\\0;\\\\1> ||  || \""\""\""",,Yes,Yes
16566,newnames are constructed as needed,,,Yes
16569,no additional libraries needed,,,Yes
16570,XXX: ideally; we should use exactly the same version as used by python. I,,Yes,Yes
16571,XXX need support for .C that is also C++,,,Yes
16572,break  # XXX can we assume that there is one module per file?,,,Yes
16573,XXX: *.hpp files??,,Yes,Yes
16574,XXX scan sources for include statements,,Yes,Yes
16575,## XXX Implement add_py_modules,,,Yes
16578,Trivial cache to cache LibraryInfo instances creation. To be really,,Yes,Yes
16580,TODO:,,No,Yes
16581,pkg-config simple emulator - useful for debugging; and maybe later to query,,,Yes
16583,good to keep its class name. Use of RawConfigParser is needed in,,Yes,Yes
16585,FIXME: lapack_atlas is unused,,,Yes
16587,XXX: is it generally true?,,No,Yes
16588,XXX: should we check here actual existence of source files?,,No,Yes
16589,FIXME: r not used,,No,Yes
16594,"\""\""\"" || ======================== || Broadcasting over arrays || ======================== ||  || .. note:: ||     See `this article ||     <https:\/\/numpy.org\/devdocs\/user\/theory.broadcasting.html>`_ ||     for illustrations of broadcasting concepts. ||  ||  || The term broadcasting describes how numpy treats arrays with different || shapes during arithmetic operations. Subject to certain constraints; || the smaller array is \""broadcast\"" across the larger array so that they || have compatible shapes. Broadcasting provides a means of vectorizing || array operations so that looping occurs in C instead of Python. It does || this without making needless copies of data and usually leads to || efficient algorithm implementations. There are; however; cases where || broadcasting is a bad idea because it leads to inefficient use of memory || that slows computation. ||  || NumPy operations are usually done on pairs of arrays on an || element-by-element basis.  In the simplest case; the two arrays must || have exactly the same shape; as in the following example: ||  ||   >>> a = np.array([1.0; 2.0; 3.0]) ||   >>> b = np.array([2.0; 2.0; 2.0]) ||   >>> a * b ||   array([ 2.;  4.;  6.]) ||  || NumPy's broadcasting rule relaxes this constraint when the arrays' || shapes meet certain constraints. The simplest broadcasting example occurs || when an array and a scalar value are combined in an operation: ||  || >>> a = np.array([1.0; 2.0; 3.0]) || >>> b = 2.0 || >>> a * b || array([ 2.;  4.;  6.]) ||  || The result is equivalent to the previous example where ``b`` was an array. || We can think of the scalar ``b`` being *stretched* during the arithmetic || operation into an array with the same shape as ``a``. The new elements in || ``b`` are simply copies of the original scalar. The stretching analogy is || only conceptual.  NumPy is smart enough to use the original scalar value || without actually making copies; so that broadcasting operations are as || memory and computationally efficient as possible. ||  || The code in the second example is more efficient than that in the first || because broadcasting moves less memory around during the multiplication || (``b`` is a scalar rather than an array). ||  || General Broadcasting Rules || ========================== || When operating on two arrays; NumPy compares their shapes element-wise. || It starts with the trailing dimensions; and works its way forward.  Two || dimensions are compatible when ||  || 1) they are equal; or || 2) one of them is 1 ||  || If these conditions are not met; a || ``ValueError: operands could not be broadcast together`` exception is  || thrown; indicating that the arrays have incompatible shapes. The size of  || the resulting array is the maximum size along each dimension of the input  || arrays. ||  || Arrays do not need to have the same *number* of dimensions.  For example; || if you have a ``256x256x3`` array of RGB values; and you want to scale || each color in the image by a different value; you can multiply the image || by a one-dimensional array with 3 values. Lining up the sizes of the || trailing axes of these arrays according to the broadcast rules; shows that || they are compatible:: ||  ||   Image  (3d array): 256 x 256 x 3 ||   Scale  (1d array):             3 ||   Result (3d array): 256 x 256 x 3 ||  || When either of the dimensions compared is one; the other is || used.  In other words; dimensions with size 1 are stretched or \""copied\"" || to match the other. ||  || In the following example; both the ``A`` and ``B`` arrays have axes with || length one that are expanded to a larger size during the broadcast || operation:: ||  ||   A      (4d array):  8 x 1 x 6 x 1 ||   B      (3d array):      7 x 1 x 5 ||   Result (4d array):  8 x 7 x 6 x 5 ||  || Here are some more examples:: ||  ||   A      (2d array):  5 x 4 ||   B      (1d array):      1 ||   Result (2d array):  5 x 4 ||  ||   A      (2d array):  5 x 4 ||   B      (1d array):      4 ||   Result (2d array):  5 x 4 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (3d array):  15 x 1 x 5 ||   Result (3d array):  15 x 3 x 5 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (2d array):       3 x 5 ||   Result (3d array):  15 x 3 x 5 ||  ||   A      (3d array):  15 x 3 x 5 ||   B      (2d array):       3 x 1 ||   Result (3d array):  15 x 3 x 5 ||  || Here are examples of shapes that do not broadcast:: ||  ||   A      (1d array):  3 ||   B      (1d array):  4 # trailing dimensions do not match ||  ||   A      (2d array):      2 x 1 ||   B      (3d array):  8 x 4 x 3 # second from last dimensions mismatched ||  || An example of broadcasting in practice:: ||  ||  >>> x = np.arange(4) ||  >>> xx = x.reshape(4;1) ||  >>> y = np.ones(5) ||  >>> z = np.ones((3;4)) ||  ||  >>> x.shape ||  (4;) ||  ||  >>> y.shape ||  (5;) ||  ||  >>> x + y ||  ValueError: operands could not be broadcast together with shapes (4;) (5;) ||  ||  >>> xx.shape ||  (4; 1) ||  ||  >>> y.shape ||  (5;) ||  ||  >>> (xx + y).shape ||  (4; 5) ||  ||  >>> xx + y ||  array([[ 1.;  1.;  1.;  1.;  1.]; ||         [ 2.;  2.;  2.;  2.;  2.]; ||         [ 3.;  3.;  3.;  3.;  3.]; ||         [ 4.;  4.;  4.;  4.;  4.]]) ||  ||  >>> x.shape ||  (4;) ||  ||  >>> z.shape ||  (3; 4) ||  ||  >>> (x + z).shape ||  (3; 4) ||  ||  >>> x + z ||  array([[ 1.;  2.;  3.;  4.]; ||         [ 1.;  2.;  3.;  4.]; ||         [ 1.;  2.;  3.;  4.]]) ||  || Broadcasting provides a convenient way of taking the outer product (or || any other outer operation) of two arrays. The following example shows an || outer addition operation of two 1-d arrays:: ||  ||   >>> a = np.array([0.0; 10.0; 20.0; 30.0]) ||   >>> b = np.array([1.0; 2.0; 3.0]) ||   >>> a[:; np.newaxis] + b ||   array([[  1.;   2.;   3.]; ||          [ 11.;  12.;  13.]; ||          [ 21.;  22.;  23.]; ||          [ 31.;  32.;  33.]]) ||  || Here the ``newaxis`` index operator inserts a new axis into ``a``; || making it a two-dimensional ``4x1`` array.  Combining the ``4x1`` array || with ``b``; which has shape ``(3;)``; yields a ``4x3`` array. ||  || \""\""\""",,,Yes
16597,"\""\""\"" || =============== || Array Internals || =============== ||  || Internal organization of numpy arrays || ===================================== ||  || It helps to understand a bit about how numpy arrays are handled under the covers to help understand numpy better. This section will not go into great detail. Those wishing to understand the full details are referred to Travis Oliphant's book \""Guide to NumPy\"". ||  || NumPy arrays consist of two major components; the raw array data (from now on; || referred to as the data buffer); and the information about the raw array data. || The data buffer is typically what people think of as arrays in C or Fortran; || a contiguous (and fixed) block of memory containing fixed sized data items. || NumPy also contains a significant set of data that describes how to interpret || the data in the data buffer. This extra information contains (among other things): ||  ||  1) The basic data element's size in bytes ||  2) The start of the data within the data buffer (an offset relative to the ||     beginning of the data buffer). ||  3) The number of dimensions and the size of each dimension ||  4) The separation between elements for each dimension (the 'stride'). This ||     does not have to be a multiple of the element size ||  5) The byte order of the data (which may not be the native byte order) ||  6) Whether the buffer is read-only ||  7) Information (via the dtype object) about the interpretation of the basic ||     data element. The basic data element may be as simple as a int or a float; ||     or it may be a compound object (e.g.; struct-like); a fixed character field; ||     or Python object pointers. ||  8) Whether the array is to interpreted as C-order or Fortran-order. ||  || This arrangement allow for very flexible use of arrays. One thing that it allows || is simple changes of the metadata to change the interpretation of the array buffer. || Changing the byteorder of the array is a simple change involving no rearrangement || of the data. The shape of the array can be changed very easily without changing || anything in the data buffer or any data copying at all ||  || Among other things that are made possible is one can create a new array metadata || object that uses the same data buffer || to create a new view of that data buffer that has a different interpretation || of the buffer (e.g.; different shape; offset; byte order; strides; etc) but || shares the same data bytes. Many operations in numpy do just this such as || slices. Other operations; such as transpose; don't move data elements || around in the array; but rather change the information about the shape and strides so that the indexing of the array changes; but the data in the doesn't move. ||  || Typically these new versions of the array metadata but the same data buffer are || new 'views' into the data buffer. There is a different ndarray object; but it || uses the same data buffer. This is why it is necessary to force copies through || use of the .copy() method if one really wants to make a new and independent || copy of the data buffer. ||  || New views into arrays mean the object reference counts for the data buffer || increase. Simply doing away with the original array object will not remove the || data buffer if other views of it still exist. ||  || Multidimensional Array Indexing Order Issues || ============================================ ||  || What is the right way to index || multi-dimensional arrays? Before you jump to conclusions about the one and || true way to index multi-dimensional arrays; it pays to understand why this is || a confusing issue. This section will try to explain in detail how numpy || indexing works and why we adopt the convention we do for images; and when it || may be appropriate to adopt other conventions. ||  || The first thing to understand is || that there are two conflicting conventions for indexing 2-dimensional arrays. || Matrix notation uses the first index to indicate which row is being selected and || the second index to indicate which column is selected. This is opposite the || geometrically oriented-convention for images where people generally think the || first index represents x position (i.e.; column) and the second represents y || position (i.e.; row). This alone is the source of much confusion; || matrix-oriented users and image-oriented users expect two different things with || regard to indexing. ||  || The second issue to understand is how indices correspond || to the order the array is stored in memory. In Fortran the first index is the || most rapidly varying index when moving through the elements of a two || dimensional array as it is stored in memory. If you adopt the matrix || convention for indexing; then this means the matrix is stored one column at a || time (since the first index moves to the next row as it changes). Thus Fortran || is considered a Column-major language. C has just the opposite convention. In || C; the last index changes most rapidly as one moves through the array as || stored in memory. Thus C is a Row-major language. The matrix is stored by || rows. Note that in both cases it presumes that the matrix convention for || indexing is being used; i.e.; for both Fortran and C; the first index is the || row. Note this convention implies that the indexing convention is invariant || and that the data order changes to keep that so. ||  || But that's not the only way || to look at it. Suppose one has large two-dimensional arrays (images or || matrices) stored in data files. Suppose the data are stored by rows rather than || by columns. If we are to preserve our index convention (whether matrix or || image) that means that depending on the language we use; we may be forced to || reorder the data if it is read into memory to preserve our indexing || convention. For example if we read row-ordered data into memory without || reordering; it will match the matrix indexing convention for C; but not for || Fortran. Conversely; it will match the image indexing convention for Fortran; || but not for C. For C; if one is using data stored in row order; and one wants || to preserve the image index convention; the data must be reordered when || reading into memory. ||  || In the end; which you do for Fortran or C depends on || which is more important; not reordering data or preserving the indexing || convention. For large images; reordering data is potentially expensive; and || often the indexing convention is inverted to avoid that. ||  || The situation with || numpy makes this issue yet more complicated. The internal machinery of numpy || arrays is flexible enough to accept any ordering of indices. One can simply || reorder indices by manipulating the internal stride information for arrays || without reordering the data at all. NumPy will know how to map the new index || order to the data without moving the data. ||  || So if this is true; why not choose || the index order that matches what you most expect? In particular; why not define || row-ordered images to use the image convention? (This is sometimes referred || to as the Fortran convention vs the C convention; thus the 'C' and 'FORTRAN' || order options for array ordering in numpy.) The drawback of doing this is || potential performance penalties. It's common to access the data sequentially; || either implicitly in array operations or explicitly by looping over rows of an || image. When that is done; then the data will be accessed in non-optimal order. || As the first index is incremented; what is actually happening is that elements || spaced far apart in memory are being sequentially accessed; with usually poor || memory access speeds. For example; for a two dimensional image 'im' defined so || that im[0; 10] represents the value at x=0; y=10. To be consistent with usual || Python behavior then im[0] would represent a column at x=0. Yet that data || would be spread over the whole array since the data are stored in row order. || Despite the flexibility of numpy's indexing; it can't really paper over the fact || basic operations are rendered inefficient because of data order or that getting || contiguous subarrays is still awkward (e.g.; im[:;0] for the first row; vs || im[0]); thus one can't use an idiom such as for row in im; for col in im does || work; but doesn't yield contiguous column data. ||  || As it turns out; numpy is || smart enough when dealing with ufuncs to determine which index is the most || rapidly varying one in memory and uses that for the innermost loop. Thus for || ufuncs there is no large intrinsic advantage to either approach in most cases. || On the other hand; use of .flat with an FORTRAN ordered array will lead to || non-optimal memory access as adjacent elements in the flattened array (iterator; || actually) are not contiguous in memory. ||  || Indeed; the fact is that Python || indexing on lists and other sequences naturally leads to an outside-to inside || ordering (the first index gets the largest grouping; the next the next largest; || and the last gets the smallest element). Since image data are normally stored || by rows; this corresponds to position within rows being the last item indexed. ||  || If you do want to use Fortran ordering realize that || there are two approaches to consider: 1) accept that the first index is just not || the most rapidly changing in memory and have all your I\/O routines reorder || your data when going from memory to disk or visa versa; or use numpy's || mechanism for mapping the first index to the most rapidly varying data. We || recommend the former if possible. The disadvantage of the latter is that many || of numpy's functions will yield arrays without Fortran ordering unless you are || careful to use the 'order' keyword. Doing this would be highly inconvenient. ||  || Otherwise we recommend simply learning to reverse the usual order of indices || when accessing elements of an array. Granted; it goes against the grain; but || it is more in line with Python semantics and the natural order of the data. ||  || \""\""\""",,Yes,Yes
16603,XXX: Evaluate intent_flags here.,,Yes,Yes
16605,The eviroment provided by auxfuncs.py is needed for some calls to eval.,,Yes,Yes
16606,As the needed functions cannot be determined by static inspection of the,,,Yes
16608,XXX: subsequent init expressions may get wrong values.,,Yes,Yes
16609,XXX: apply mapping,,,Yes
16611,XXX: return something sensible.,,,Yes
16613,FIXME complex numbers may also have exponents,,Yes,Yes
16614,FIXME; unused l looks like potential bug,,Yes,Yes
16615,XXX,,,Yes
16616,The eviroment provided by auxfuncs.py is needed for some calls to eval.,,Yes,Yes
16618,Workaround for Python 2.6; 2.6.1 bug: https:\/\/bugs.python.org\/issue4720,,No,Yes
16622,TODO: .zip support; .tar support?,,Yes,Yes
16624,TODO: Doesn't handle compressed files!,,,Yes
16625,TODO:  This should be more robust.  Handles case where path includes,,No,Yes
16628,Converting the array with `tolist` seems to improve performance,,,Yes
16629,"\""\""\"" || Set operations for arrays based on sorting. ||  || :Contains: ||   unique; ||   isin; ||   ediff1d; ||   intersect1d; ||   setxor1d; ||   in1d; ||   union1d; ||   setdiff1d ||  || :Notes: ||  || For floating point arrays; inaccurate results may appear due to usual round-off || and floating point comparison issues. ||  || Speed could be gained in some operations by an implementation of || sort(); that can provide directly the permutation vectors; avoiding || thus calls to argsort(). ||  || To do: Optionally return indices analogously to unique for all functions. ||  || :Author: Robert Cimrman ||  || \""\""\""",,,Yes
16631,"\""\""\"" || Binary serialization ||  || NPY format || ========== ||  || A simple format for saving numpy arrays to disk with the full || information about them. ||  || The ``.npy`` format is the standard binary file format in NumPy for || persisting a *single* arbitrary NumPy array on disk. The format stores all || of the shape and dtype information necessary to reconstruct the array || correctly even on another machine with a different architecture. || The format is designed to be as simple as possible while achieving || its limited goals. ||  || The ``.npz`` format is the standard format for persisting *multiple* NumPy || arrays on disk. A ``.npz`` file is a zip file containing multiple ``.npy`` || files; one for each array. ||  || Capabilities || ------------ ||  || - Can represent all NumPy arrays including nested record arrays and ||   object arrays. ||  || - Represents the data in its native binary form. ||  || - Supports Fortran-contiguous arrays directly. ||  || - Stores all of the necessary information to reconstruct the array ||   including shape and dtype on a machine of a different ||   architecture.  Both little-endian and big-endian arrays are ||   supported; and a file with little-endian numbers will yield ||   a little-endian array on any machine reading the file. The ||   types are described in terms of their actual sizes. For example; ||   if a machine with a 64-bit C \""long int\"" writes out an array with ||   \""long ints\""; a reading machine with 32-bit C \""long ints\"" will yield ||   an array with 64-bit integers. ||  || - Is straightforward to reverse engineer. Datasets often live longer than ||   the programs that created them. A competent developer should be ||   able to create a solution in their preferred programming language to ||   read most ``.npy`` files that he has been given without much ||   documentation. ||  || - Allows memory-mapping of the data. See `open_memmep`. ||  || - Can be read from a filelike stream object instead of an actual file. ||  || - Stores object arrays; i.e. arrays containing elements that are arbitrary ||   Python objects. Files with object arrays are not to be mmapable; but ||   can be read and written to disk. ||  || Limitations || ----------- ||  || - Arbitrary subclasses of numpy.ndarray are not completely preserved. ||   Subclasses will be accepted for writing; but only the array data will ||   be written out. A regular numpy.ndarray object will be created ||   upon reading the file. ||  || .. warning:: ||  ||   Due to limitations in the interpretation of structured dtypes; dtypes ||   with fields with empty names will have the names replaced by 'f0'; 'f1'; ||   etc. Such arrays will not round-trip through the format entirely ||   accurately. The data is intact; only the field names will differ. We are ||   working on a fix for this. This fix will not require a change in the ||   file format. The arrays with such structures can still be saved and ||   restored; and the correct dtype may be restored by using the ||   ``loadedarray.view(correct_dtype)`` method. ||  || File extensions || --------------- ||  || We recommend using the ``.npy`` and ``.npz`` extensions for files saved || in this format. This is by no means a requirement; applications may wish || to use these file formats but use an extension specific to the || application. In the absence of an obvious alternative; however; || we suggest using ``.npy`` and ``.npz``. ||  || Version numbering || ----------------- ||  || The version numbering of these formats is independent of NumPy version || numbering. If the format is upgraded; the code in `numpy.io` will still || be able to read and write Version 1.0 files. ||  || Format Version 1.0 || ------------------ ||  || The first 6 bytes are a magic string: exactly ``\\\\x93NUMPY``. ||  || The next 1 byte is an unsigned byte: the major version number of the file || format; e.g. ``\\\\x01``. ||  || The next 1 byte is an unsigned byte: the minor version number of the file || format; e.g. ``\\\\x00``. Note: the version of the file format is not tied || to the version of the numpy package. ||  || The next 2 bytes form a little-endian unsigned short int: the length of || the header data HEADER_LEN. ||  || The next HEADER_LEN bytes form the header data describing the array's || format. It is an ASCII string which contains a Python literal expression || of a dictionary. It is terminated by a newline (``\\\ || ``) and padded with || spaces (``\\\\x20``) to make the total of || ``len(magic string) + 2 + len(length) + HEADER_LEN`` be evenly divisible || by 64 for alignment purposes. ||  || The dictionary contains three keys: ||  ||     \""descr\"" : dtype.descr ||       An object that can be passed as an argument to the `numpy.dtype` ||       constructor to create the array's dtype. ||     \""fortran_order\"" : bool ||       Whether the array data is Fortran-contiguous or not. Since ||       Fortran-contiguous arrays are a common form of non-C-contiguity; ||       we allow them to be written directly to disk for efficiency. ||     \""shape\"" : tuple of int ||       The shape of the array. ||  || For repeatability and readability; the dictionary keys are sorted in || alphabetic order. This is for convenience only. A writer SHOULD implement || this if possible. A reader MUST NOT depend on this. ||  || Following the header comes the array data. If the dtype contains Python || objects (i.e. ``dtype.hasobject is True``); then the data is a Python || pickle of the array. Otherwise the data is the contiguous (either C- || or Fortran-; depending on ``fortran_order``) bytes of the array. || Consumers can figure out the number of bytes by multiplying the number || of elements given by the shape (noting that ``shape=()`` means there is || 1 element) by ``dtype.itemsize``. ||  || Format Version 2.0 || ------------------ ||  || The version 1.0 format only allowed the array header to have a total size of || 65535 bytes.  This can be exceeded by structured arrays with a large number of || columns.  The version 2.0 format extends the header size to 4 GiB. || `numpy.save` will automatically save in 2.0 format if the data requires it; || else it will always use the more compatible 1.0 format. ||  || The description of the fourth element of the header therefore has become: || \""The next 4 bytes form a little-endian unsigned int: the length of the header || data HEADER_LEN.\"" ||  || Notes || ----- || The ``.npy`` format; including motivation for creating it and a comparison of || alternatives; is described in the `\""npy-format\"" NEP  || <https:\/\/www.numpy.org\/neps\/nep-0001-npy-format.html>`_; however details have || evolved with time and this document is more current. ||  || \""\""\""",,Yes,Yes
16634,"Once support for blank names is removed; only \""if name == ''\"" needed)",,,Yes
16635,adding newline as python 2.7.5 workaround,,,Yes
16636,removing newline (see above) as python 2.7.5 workaround,,No,Yes
16637,needed in this module for compatibility,,,Yes
16638,as the shape is needed for the result. Doing it separately optimizes,,,Yes
16639,Caching to improve default performance,,Yes,Yes
16640,truncate the range if needed,,No,Yes
16641,This is needed to don't have tall matrix have the diagonal wrap.,,,Yes
16644,which do not implement isnan (gh-9009); or fmin correctly (gh-8975),,No,Yes
16647,convention.,,Yes,Yes
16648,Implement the Mapping ABC,,Yes,Yes
16649,FIXME: This seems like it will copy strings around,,,Yes
16654,it to estimate the number of columns; N.,,Yes,Yes
16657,Redefine the key as needed if it's a column number,,,Yes
16658,Fixme: possible error as following variable never used.,,,Yes
16660,Upgrade the converters (if needed),,No,Yes
16661,Find the columns with strings...,,,Yes
16663,We have only one field: drop the name if not needed.,,No,Yes
16664,Minimal processing needed: just make sure everythng's a-ok,,,Yes
16666,Get the filling value (if needed),,No,Yes
16668,Fixme: nb2 below is never used. Commenting out for pyflakes.,,Yes,Yes
16669,never really has writebackifcopy semantics,,Yes,Yes
16670,TODO: consider making the results of broadcast_arrays readonly to match,,Yes,Yes
16671,convert to scalar if needed,,,Yes
16672,XXX: maybe using a real stemming search engine would be better?,,Yes,Yes
16673,XXX: this is full Harrison-Stetson heuristics now;,,,Yes
16674,XXX: it probably could be improved,,Yes,Yes
16676,Convention is to return scalars instead of 0d arrays,,,Yes
16677,FIXME: real_t is unused,,,Yes
16678,m[i;j]: min number of scalar multiplications needed to compute A_{i..j},,,Yes
16679,"\""\""\"" || numpy.ma : a package to handle missing or invalid values. ||  || This package was initially written for numarray by Paul F. Dubois || at Lawrence Livermore National Laboratory. || In 2006; the package was completely rewritten by Pierre Gerard-Marchant || (University of Georgia) to make the MaskedArray class a subclass of ndarray; || and to improve support of structured arrays. ||  ||  || Copyright 1999; 2000; 2001 Regents of the University of California. || Released for unlimited redistribution. ||  || * Adapted for numpy_core 2005 by Travis Oliphant and (mainly) Paul Dubois. || * Subclassing of the base `ndarray` 2006 by Pierre Gerard-Marchant ||   (pgmdevlist_AT_gmail_DOT_com) || * Improvements suggested by Reggie Dugard (reggie_AT_merfinllc_DOT_com) ||  || .. moduleauthor:: Pierre Gerard-Marchant ||  || \""\""\""",,Yes,Yes
16680,no warning needed - but switch to -1 anyway; to avoid surprising,,Yes,Yes
16681,subclasses; which are more likely to implement scalar axes.,,Yes,Yes
16682,FIXME _sharedmask is never used.,,Yes,Yes
16683,Force shrinking of the mask if needed (and possible),,No,Yes
16684,that. This is also horribly broken but somewhat less so. Maybe.,,Yes,Yes
16685,XX: This looks like a bug -- shouldn't it check self.dtype,,No,Yes
16686,needed and use astype instead of copy.,,,Yes
16688,Update the mask if needed,,,Yes
16689,Reshape if needed,,,Yes
16690,Temporary workaround to account for the fact that str and bytes,,Yes,Yes
16691,Cast fill value to bool_ if needed. If it cannot be cast; the,,Yes,Yes
16692,!!!: implement out + test!,,Yes,Yes
16697,or whatever restricted keywords.  An idea would be to no bother in the,,,Yes
16699,Set the fill_value if needed,,No,Yes
16702,TODO: we're stuck with disabling math formatting until we handle,,,Yes
16703,This can be made more efficient by using powers of two,,No,Yes
16704,FIXME: t never used,,No,Yes
16705,Determine the norms of the design matrix columns.,,Yes,Yes
16706,This can be made more efficient by using powers of two,,No,Yes
16707,Determine the norms of the design matrix columns.,,Yes,Yes
16708,matrix is symmetric in this case in order to obtain better zeros.,,Yes,Yes
16709,This can be made more efficient by using powers of two,,,Yes
16710,Determine the norms of the design matrix columns.,,Yes,Yes
16711,matrix is symmetric in this case in order to obtain better zeros.,,,Yes
16712,This can be made more efficient by using powers of two,,,Yes
16713,Determine the norms of the design matrix columns.,,Yes,Yes
16720,Determine the norms of the design matrix columns.,,Yes,Yes
16721,We need the mingw workaround for _ftime if the msvc runtime version is,,,Yes
16722,"These classes implement a doctest runner plugin for nose; a \""known failure\""",,Yes,Yes
16723,Subclass nose.plugins.doctests.DocTestCase to work around a bug in,,Yes,Yes
16724,numpy. Those semantics were fine for testing numpy; but not so,,Yes,Yes
16726,Relies on pkg_resources; not a hard dependency,,,Yes
16728,The below comparison is a hack to ensure that fully masked,,,Yes
16730,"TODO: Check default formatting for different values of \""simple\""",,No,Yes
16732,TODO: Support relative imports,,,Yes
16733,TODO: else? relative imports,,Yes,Yes
16737,XXX Linux and other platforms' special cases should go here,,,Yes
16739,workaround a cache issue,,,Yes
16740,"Oops; the \""best\"" so far conflicts with a dependency",,,Yes
16743,XXX,,,Yes
16745,metadata until\/unless it's actually needed.  (i.e.; some distributions,,Yes,Yes
16748,implement this in terms of the other specifiers instead of,,Yes,Yes
16751,This is a bit ugly; but it avoids running this again by,,Yes,Yes
16752,Workaround for standalone backslash,,,Yes
16754,Make sure we have any requirements needed to interpret 'attrs'.,,No,Yes
16757,which uses the defacto standard originally implemented by setuptools;,,,Yes
16758,"\""\""\""(Deprecated) Predefined expression of 1 or more printable words or quoted strings; separated by commas.\r ||    This expression is deprecated in favor of L{pyparsing_common.comma_separated_list}.\""\""\""",,No,Yes
16759,This is a bit ugly; but it avoids running this again by,,Yes,Yes
16760,Workaround for standalone backslash,,,Yes
16761,XXX Ugh,,No,Yes
16762,"\""\""\""A PEP 517 interface to setuptools ||  || Previously; when a user or a command line tool (let's call it a \""frontend\"") || needed to make a request of setuptools to take a certain action; for || example; generating a list of installation requirements; the frontend would || would call \""setup.py egg_info\"" or \""setup.py bdist_wheel\"" on the command line. ||  || PEP 517 defines a different method of interfacing with setuptools. Rather || than calling \""setup.py\"" directly; the frontend should: ||  ||   1. Set the current directory to the directory with a setup.py file ||   2. Import this module into a safe python interpreter (one in which ||      setuptools can potentially set global variables or crash hard). ||   3. Call one of the functions defined in PEP 517. ||  || What each function does is defined in PEP 517. However; here is a \""casual\"" || definition of the functions (this definition should not be relied on for || bug reports or API stability): ||  ||   - `build_wheel`: build a wheel in the folder and return the basename ||   - `get_requires_for_build_wheel`: get the `setup_requires` to build ||   - `prepare_metadata_for_build_wheel`: get the `install_requires` ||   - `build_sdist`: build an sdist in the folder and return the basename ||   - `get_requires_for_build_sdist`: get the `setup_requires` to build ||  || Again; this is not a formal definition! Just a \""taste\"" of the module. || \""\""\""",,,Yes
16764,XXX else: raise ???,,,Yes
16765,XXX Help!  I don't have any idea whether these are right...,,Yes,Yes
16766,XXX what to do with conflicts?,,No,Yes
16767,hack so distutils' build_extension() builds a library instead,,Yes,Yes
16769,XXX as dynamic; and not just using a locally-found version or a,,No,Yes
16770,XXX static-compiled version,,Yes,Yes
16772,XXX,,,Yes
16773,XXX should also check for entry point scripts!,,No,Yes
16776,XXX this is not the distribution we were looking for,,Yes,Yes
16777,if the only thing there is a directory; move it instead,,Yes,Yes
16778,XXX,,,Yes
16781,exact loader instance used when importing them. Python 3.4 docs state,,Yes,Yes
16783,and have PyPy repopulate it as needed. The downside is that if there are any,,No,Yes
16785,Fix older sdists built on Windows,,,Yes
16786,XXX Python 3.1 doesn't see _nc if this is inside the class,,Yes,Yes
16787,TODO: is it necessary to short-circuit here? i.e. what's the cost,,Yes,Yes
16788,only needed on Python prior to 3.6.,,Yes,Yes
16789,This grody hack closes the template file (MANIFEST.in) if an,,No,Yes
16790,"Some people apparently take \""version number\"" too literally :)",,No,Yes
16794,mysterious hack:,,No,Yes
16796,fix findall bug in distutils (http:\/\/bugs.python.org\/issue12885),,No,Yes
16799,this line is here to fix emacs' cruddy broken syntax highlighting,,Yes,Yes
16800,XXX remove distutils dependency,,,Yes
16801,"\""\""\""Workaround for http:\/\/bugs.python.org\/issue24672\""\""\""",,Yes,Yes
16802,XXX according to RFC 2818; the most specific Common Name,,Yes,Yes
16803,This is a bit ugly; but it avoids running this again by,,Yes,Yes
16804,Workaround for standalone backslash,,Yes,Yes
16805,encoding; errors); so that if s is a SafeBytes; it ends up being,,,Yes
16807,"XXX: what to do with token[\""data\""] ?",,No,Yes
16809,XXX: we do not look at the preceding event; so we never omit,,,Yes
16810,XXX: we do not look at the preceding event; so instead we never,,Yes,Yes
16811,XXX: we also look for an immediately following colgroup,,Yes,Yes
16813,XXX Need a check here to see if the first start tag token emitted is,,Yes,Yes
16814,Encoding it as UTF-8 here is a hack; as really we should pass,,Yes,Yes
16815,XXX If we implement a parser for which scripting is disabled we need to,,,Yes
16816,implement this phase.,,Yes,Yes
16818,XXX Localization ...,,,Yes
16820,can move in step 9.7,,Yes,Yes
16822,XXX Have to duplicate logic here to find out if the tag is ignored,,Yes,Yes
16827,"XXX \""inHeadNoscript\"": InHeadNoScriptPhase;",,,Yes
16829,Work around Python bug #20007: read(0) closes the connection.,,No,Yes
16830,number of columns in the last line of the previous chunk,,Yes,Yes
16833,TODO: Add namespace support here,,,Yes
16835,Should speed up this check somehow (e.g. move the set to a constant),,No,Yes
16836,Try\/except needed as UCS-2 Python builds' unichar only works,,Yes,Yes
16840,XXX EMIT,,Yes,Yes
16842,XXX - should this method be made more general?,,No,Yes
16843,XXX - rename these to headElement; formElement,,,Yes
16844,XXX - this is really inelegant,,,Yes
16847,XXX This is not entirely what the specification says. We should,,Yes,Yes
16849,XXX - there may be a better way to do this...,,Yes,Yes
16851,"\""\""\""A collection of modules for iterating through different kinds of || tree; generating tokens identical to those produced by the tokenizer || module. ||  || To create a tree walker for a new type of tree; you need to do || implement a tree walker object (called TreeWalker by convention) that || implements a 'serialize' method taking a tree as sole argument and || returning an iterator generating tokens. || \""\""\""",,No,Yes
16852,XXX: NEVER cache here; caching is done in the etree submodule,,No,Yes
16854,## @@AUTOGENERATED SECTION ENDS HERE@@,,,Yes
16855,Defer event sink creation until needed; this ensures it will only exist in,,Yes,Yes
16856,TODO: reject file version < 2 (at loader level),,Yes,Yes
16859,TODO: support run metadata,,No,Yes
16862,TODO: track computed time from run start times,,,Yes
16865,"\""\""\""Compatibility interfaces for TensorBoard. ||  || This module provides logic for importing variations on the TensorFlow APIs; as || lazily loaded imports to help avoid circular dependency issues and defer the || search and loading of the module until necessary. || \""\""\""",,No,Yes
16866,TODO(#1677): _np_bfloat16 is defined as 0. This causes `as_dtype` to,,,Yes
16867,''' || Some resource has been exhausted; perhaps a per-user quota; or || perhaps the entire file system is out of space. || ''',,Yes,Yes
16870,TODO: Handle gzip and zlib compressed files,,No,Yes
16873,and perhaps we should do that.,,Yes,Yes
16874,TODO(mrry): Handle this better; as it will be useful for handling,,Yes,Yes
16876,load_once() the first time it's needed. The class is nested so we can close,,,Yes
16879,unused,,No,Yes
16881,specific types of exceptions; instead of the broad catching here.,,Yes,Yes
16883,The events file does not exist. Perhaps the user had manually,,Yes,Yes
16891,Workaround the grpc's 4MB message limitation.,,Yes,Yes
16892,TODO: return HTTP status code for malformed requests,,Yes,Yes
16893,times. This seems to work fine; and looking at the superclass,,,Yes
16898,We're counting columns in the terminal; not bytes. So we don't,,Yes,Yes
16899,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
16901,Import boosted trees ops to make sure the ops are registered (but unused).,,Yes,Yes
16903,In general; a better mechanism could look like:,,Yes,Yes
16905,"Or maybe we should just raise an \""unsafe assign\"" error?",,,Yes
16907,"\""\""\""Converter construction support. ||  || This module contains a base class for all converters; as well as supporting || structures. These structures are referred to as contexts. ||  || The class hierarchy is as follows: ||  ||     <your converter> ||       [extends] converter.Base ||         [extends] transformer.Base ||             [extends] gast.nodeTransformer ||           [uses] transfomer.SourceInfo ||         [uses] converter.EntityContext ||           [uses] converter.ProgramContext ||           [uses] transfomer.SourceInfo ||  || converter.Base is a specialization of transformer.Base for AutoGraph. It's a || very lightweight subclass that adds a `ctx` attribute holding the corresponding || EntityContext object (see below). Note that converters are not reusable; and || `visit` will raise an error if called more than once. ||  || converter.EntityContext contains mutable state associated with an entity that || the converter processes. ||  || converter.ProgramContext contains mutable state across related entities. For || example; when converting several functions that call one another; the || ProgramContext should be shared across these entities. ||  || Below is the overall flow at conversion: ||  ||     program_ctx = ProgramContext(<entities to convert>; <global settings>; ...) ||     while <program_ctx has more entities to convert>: ||       entity; source_info = <get next entity from program_ctx> ||       entity_ctx = EntityContext(program_ctx; source_info) ||       for <each ConverterClass>: ||         converter = ConverterClass(entity_ctx) ||  ||         # May update entity_ctx and program_ctx ||         entity = converter.visit(entity) ||  ||       <add entity's dependencies to program_ctx> ||  || Note that pyct contains a small number of transformers used for static analysis. || These implement transformer.Base; rather than converter.Base; to avoid a || dependency on AutoGraph. || \""\""\""",,Yes,Yes
16909,This is a bit of a hack; but works for things like tf.int32,,,Yes
16911,needed so long as the function doesn't return any executable code.,,,Yes
16912,Remove self to avoid circular references. This will probably only work,,,Yes
16913,TODO(b\/120224672): Fix this.,,,Yes
16914,it uses regex matching to adjust the exact location around the line number,,Yes,Yes
16916,a dummy state variable that remains unused.,,No,Yes
16917,which is probably never what you want.,,No,Yes
16919,TODO(mdan): Perhaps detail this in a markdown doc.,,Yes,Yes
16920,Subsequent splits move back to the split point; and memorize the,,,Yes
16921,and explicitly name the intermediate values needed to compute the value of,,Yes,Yes
16922,Any additional assignments needed to name all the intermediate values in the,,Yes,Yes
16923,TODO(mdan): Figure out why six.get_unbound_function fails in some cases.,,Yes,Yes
16924,Python 3 class methods only work this way it seems :S,,,Yes
16929,probably a case of undefined assignment; like this:,,Yes,Yes
16930,Note: additional nodes may be added as needed.,,No,Yes
16931,TODO(mdan): Move this to the superclass?,,Yes,Yes
16934,are deleted when `movers` goes out of scope when this _run() ends.,,No,Yes
16935,Transfer a tensor to the right device if needed.,,Yes,Yes
16936,#NAME?,,,Yes
16937,other user-defined collections. A better way would be to use,,,Yes
16938,TODO(laigd): maybe add back AssetFileDef.,,,Yes
16939,TODO(laigd): a better way would be to use self._calibration_sess to list,,,Yes
16940,As a temporary fix we enter the following implicit contract between this,,,Yes
16941,tensors when needed.,,Yes,Yes
16942,implement `element_structure`.,,,Yes
16944,TODO(b\/121378567): Get rid of this shared_name hack.,,Yes,Yes
16947,TODO(cais): Implement list_nodes.,,Yes,Yes
16949,"term \""partition graph\"" means and how it is related to TF graph objects",,,Yes
16950,"\""A tensorflow graph defined in Python is stripped of unused ops",,,Yes
16951,Currently unused.,,,Yes
16954,Currently unused.,,Yes,Yes
16955,Currently unused.,,Yes,Yes
16956,TODO(cais): Implement list_inputs,,Yes,Yes
16958,TODO(cais): Implement node_info,,Yes,Yes
16960,TODO(cais): Implement value_stack.,,,Yes
16962,graph. Let the debugger watch the unused slot 1.,,Yes,Yes
16967,TODO(cais): Perhaps some users will want the effect of the interactive,,Yes,Yes
16969,Unused,,,Yes
16970,Unused; since this is set in __init__ manually.,,Yes,Yes
16974,TODO(yuefengz): when tensor sharding is not needed; static shapes are not,,No,Yes
16975,TODO(tucker): maybe support non-default subdiv spec,,Yes,Yes
16976,Internal context managers used to implement the DistributionStrategy,,,Yes
16977,thread-local; so not needed with multiple threads,,Yes,Yes
16979,needed the reduce result; allowing an efficient implementation:,,No,Yes
16981,to that point that the first result is needed. Most likely this can be,,,Yes
16983,We create them lazily in a function so that we can workaround the circular,,,Yes
16984,TODO(yuefengz): maybe merge the following two functions?,,Yes,Yes
16987,TODO(josh11b;apassos): It would be better if variable initialization,,,Yes
16988,was never recorded on the tape instead of having to do this manually,,,Yes
16993,Ignore user-specified caching device; not needed for mirrored variables.,,No,Yes
16996,Workaround for `tpu.replicate` behaviour when single `Tensor` returned.,,Yes,Yes
16997,when using device_assignment. This is a temporary workaround to support,,Yes,Yes
16998,Needed for GradientTape,,Yes,Yes
16999,Needed to pass ResourceVariable checks.,,,Yes
17000,TODO(b\/119775953): fix the circular dependencies.,,,Yes
17001,better than the alternative; tracing the initialization graph but giving,,,Yes
17002,TODO(josh11b): Could we do a better job if we also passed in the,,Yes,Yes
17003,It might be worth creating a convenient way to re-use status.,,,Yes
17005,method's functionality better. Remove register_gradient_functions argument,,,Yes
17006,TODO(nareshmodi): Skip ndarray conversion to tensor altogether; perhaps,,Yes,Yes
17007,TODO(mdan): For better consistency; use the wrapper's call().,,Yes,Yes
17011,Having the fully expressed variable scope name ends up doubly,,No,Yes
17013,"\""\""\""This API defines FeatureColumn abstraction. ||  || FeatureColumns provide a high level abstraction for ingesting and representing || features. FeatureColumns are also the primary way of encoding features for || canned `tf.estimator.Estimator`s. ||  || When using FeatureColumns with `Estimators`; the type of feature column you || should choose depends on (1) the feature type and (2) the model type. ||  || 1. Feature type: ||  ||   * Continuous features can be represented by `numeric_column`. ||   * Categorical features can be represented by any `categorical_column_with_*` ||   column: ||     - `categorical_column_with_vocabulary_list` ||     - `categorical_column_with_vocabulary_file` ||     - `categorical_column_with_hash_bucket` ||     - `categorical_column_with_identity` ||     - `weighted_categorical_column` ||  || 2. Model type: ||  ||   * Deep neural network models (`DNNClassifier`; `DNNRegressor`). ||  ||     Continuous features can be directly fed into deep neural network models. ||  ||       age_column = numeric_column(\""age\"") ||  ||     To feed sparse features into DNN models; wrap the column with ||     `embedding_column` or `indicator_column`. `indicator_column` is recommended ||     for features with only a few possible values. For features with many ||     possible values; to reduce the size of your model; `embedding_column` is ||     recommended. ||  ||       embedded_dept_column = embedding_column( ||           categorical_column_with_vocabulary_list( ||               \""department\""; [\""math\""; \""philosophy\""; ...]); dimension=10) ||  ||   * Wide (aka linear) models (`LinearClassifier`; `LinearRegressor`). ||  ||     Sparse features can be fed directly into linear models. They behave like an ||     indicator column but with an efficient implementation. ||  ||       dept_column = categorical_column_with_vocabulary_list(\""department\""; ||           [\""math\""; \""philosophy\""; \""english\""]) ||  ||     It is recommended that continuous features be bucketized before being ||     fed into linear models. ||  ||       bucketized_age_column = bucketized_column( ||           source_column=age_column; ||           boundaries=[18; 25; 30; 35; 40; 45; 50; 55; 60; 65]) ||  ||     Sparse features can be crossed (also known as conjuncted or combined) in ||     order to form non-linearities; and then fed into linear models. ||  ||       cross_dept_age_column = crossed_column( ||           columns=[\""department\""; bucketized_age_column]; ||           hash_bucket_size=1000) ||  || Example of building canned `Estimator`s using FeatureColumns: ||  ||   ```python ||   # Define features and transformations ||   deep_feature_columns = [age_column; embedded_dept_column] ||   wide_feature_columns = [dept_column; bucketized_age_column; ||       cross_dept_age_column] ||  ||   # Build deep model ||   estimator = DNNClassifier( ||       feature_columns=deep_feature_columns; ||       hidden_units=[500; 250; 50]) ||   estimator.train(...) ||  ||   # Or build a wide model ||   estimator = LinearClassifier( ||       feature_columns=wide_feature_columns) ||   estimator.train(...) ||  ||   # Or build a wide and deep model! ||   estimator = DNNLinearCombinedClassifier( ||       linear_feature_columns=wide_feature_columns; ||       dnn_feature_columns=deep_feature_columns; ||       dnn_hidden_units=[500; 250; 50]) ||   estimator.train(...) ||   ``` ||  ||  || FeatureColumns can also be transformed into a generic input layer for || custom models using `input_layer`. ||  || Example of building model using FeatureColumns; this can be used in a || `model_fn` which is given to the {tf.estimator.Estimator}: ||  ||   ```python ||   # Building model via layers ||  ||   deep_feature_columns = [age_column; embedded_dept_column] ||   columns_to_tensor = parse_feature_columns_from_examples( ||       serialized=my_data; ||       feature_columns=deep_feature_columns) ||   first_layer = input_layer( ||       features=columns_to_tensor; ||       feature_columns=deep_feature_columns) ||   second_layer = fully_connected(first_layer; ...) ||   ``` ||  || NOTE: Functions prefixed with \""_\"" indicate experimental or private parts of || the API subject to change; and should not be relied upon! || \""\""\""",,No,Yes
17014,TODO(ptucker): Move to third_party\/tensorflow\/python\/ops\/sparse_ops.py,,No,Yes
17016,If the name already exists; re-use the column from columns_by_name;,,Yes,Yes
17017,(new_instance remains unused).,,No,Yes
17019,"\""\""\""AutomaticControlDependencies and related functionality.\""\""\""",,Yes,Yes
17020,probably other things as well).,,No,Yes
17024,Needed when you defined a new Op in C++.,,,Yes
17025,Needed when interfacing tensorflow to new array libraries,,No,Yes
17026,"\""\""\""FuncGraph and related functionality.\""\""\""",,,Yes
17027,inheriting this stack from the default graph even in eager mode. Maybe,,Yes,Yes
17028,converted even though they would meet autograph's whitelisting,,Yes,Yes
17031,The Python callable is only needed to create a FunctionDef. Since we have,,Yes,Yes
17032,This graph only includes the nodes needed to evaluate the output nodes; and,,,Yes
17034,Update the maps with the default; if needed.,,Yes,Yes
17040,execution doesn't implement device stacks and in particular it,,,Yes
17041,However; that would require a circular import dependency.,,Yes,Yes
17042,happen soon; perhaps this hack to work around the circular,,Yes,Yes
17046,TODO(mrry): Handle these maybe.,,Yes,Yes
17047,and perhaps we should do that.,,Yes,Yes
17048,TODO(mrry): Handle this better; as it will be useful for handling,,Yes,Yes
17052,be nice to be able to decorate arbitrary tests in a large test suite and,,Yes,Yes
17053,better isolation.,,Yes,Yes
17054,f1 == f2 is needed here as we might have: f1; f2 = inf; inf,,Yes,Yes
17055,Fix Python 3 compatibility issues,,,Yes
17056,Allows to give unique autogenerated names to layers; in a graph-specific way.,,,Yes
17057,Fix shape representation,,,Yes
17058,Temporary workaround due to `convert_to_tensor` not casting floats.,,Yes,Yes
17061,by convention; use 2 as OOV word,,Yes,Yes
17062,by convention; use 2 as OOV word,,Yes,Yes
17063,implement `compute_output_shape` themselves).,,Yes,Yes
17064,would enable us to run the underlying graph if needed.,,,Yes
17069,needed. This method does initialization or waiting for initialization,,,Yes
17070,Private attributes to implement compatibility with Layer.,,Yes,Yes
17072,and building the layer if needed.,,,Yes
17074,since TPUStrategy does not implement replica local variables.,,,Yes
17076,workaround until new metrics are in place.,,No,Yes
17078,Deserialize loss configuration; if needed.,,Yes,Yes
17080,create a cyclical dependency. Figure out a cleaner solution,,,Yes
17084,"\""\""\""Keras layers that implement explicit (approximate) kernel feature maps.\""\""\""",,No,Yes
17085,used during evaluation; it is more efficient to just update in one,,Yes,Yes
17090,This method is only needed for momentum optimization.,,Yes,Yes
17091,The default isn't needed here because our conditions are mutually,,Yes,Yes
17092,Needed to avoid infinite recursion with __setattr__.,,Yes,Yes
17094,one save is needed once the weights can be copied from the model to clone.,,Yes,Yes
17097,Relocate the model definition under CPU device scope if needed,,Yes,Yes
17098,pydot-ng is a fork of pydot that is better maintained.,,,Yes
17100,Some more reshaping is needed to assemble this tensor with the,,Yes,Yes
17101,Fix shape inference,,,Yes
17103,Prepare reshape by inserting dimensions with size 1 where needed,,Yes,Yes
17104,TODO(nolivia): improve performance with a broadcast,,Yes,Yes
17105,subtle race conditions. TODO(apassos) implement axis != 0 on sparse_read,,,Yes
17106,Move params[axis] up to params[batch_dims].,,,Yes
17107,Move the result dimensions corresponding to params[batch_dims:axis],,,Yes
17110,TODO(agarwal): This colocation seems to run into problems. Fix it.,,,Yes
17111,"\""\""\""cond_v2 and gradient. ||  || This is a version of cond that emits a single If op; as well as the gradient || function for If ops produced by cond_v2. This will eventually replace the || current tf.cond implementation once it reaches feature and performance parity. || \""\""\""",,Yes,Yes
17112,Modify 'op' to output the intermediates needed by the grad functions. Note,,Yes,Yes
17113,that all needed intermediates are wrapped in optionals. Each optional,,,Yes
17114,Information needed by backprop.,,Yes,Yes
17116,We are in a cond context. Use a switch to create zeros only when needed.,,No,Yes
17117,Use the real value if it comes from outer context. This is needed in,,Yes,Yes
17118,We needed to make true_fn\/false_fn keyword arguments for,,Yes,Yes
17119,for the zeros is only needed for the base case when the loop exits,,No,Yes
17120,TODO(skyewm): do something better than hasattr without messing up imports.,,Yes,Yes
17122,input_op is in the gradient context of op's context. This case is needed,,No,Yes
17123,needed when the gradient of a while loop gradient is requested (this,,No,Yes
17124,We want the default convention to be snake_case rather than CamelCase,,,Yes
17127,Best wishes for good luck with your projects!,,No,Yes
17130,following the TF convention. Typically; you might expect to see,,Yes,Yes
17133,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17134,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17135,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17137,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17140,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17141,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17143,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17144,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17146,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17147,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17149,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17150,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17151,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17152,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17155,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17156,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17158,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17160,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17161,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17162,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17163,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17165,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17167,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17168,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17170,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17171,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17173,Needed to trigger the call to _set_call_cpp_shape_fn.,,,Yes
17175,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17176,Needed to trigger the call to _set_call_cpp_shape_fn.,,Yes,Yes
17177,TODO(skyewm): plumbing xs through everywhere is ugly; consider making,,Yes,Yes
17179,For an unused exit; if it has trainable outputs; backprop,,Yes,Yes
17180,"All exits are \""unused\"" so use None as gradient.",,Yes,Yes
17181,reduce performance; but it can improve memory because the,,Yes,Yes
17182,Maybe crop if needed.,,No,Yes
17183,Maybe pad if needed.,,No,Yes
17184,randomly zeroing out some columns,,,Yes
17186,Override if a more efficient implementation is available.,,Yes,Yes
17187,operators with an efficient .add_to_tensor() method.,,,Yes
17189,the following line is NaN * [] = []; as needed.,,Yes,Yes
17190,TODO(langmore) Implement solve using solve_ls if some intermediate,,No,Yes
17191,where vec stacks all the columns of the matrix under each other. In our,,Yes,Yes
17194,Shape of the matrix with only n - 1 columns that we will embed in higher,,,Yes
17195,This could be handled in the future; but seems less common.,,,Yes
17196,TODO(rmlarsen): The implementation could be more efficient:,,Yes,Yes
17198,ends; holding on to a loss when executing eagerly is indistingishable from,,No,Yes
17200,TODO(ebrevdo): Perhaps add the derivative w.r.t. a; b,,,Yes
17203,TODO(aselle): Deprecate this once all internal functionality uses,,Yes,Yes
17204,TODO(apassos) remove _shape_tuple here when it is not needed.,,,Yes
17206,cast needed for SparseTensor reductions,,No,Yes
17207,This special handling is needed because sometimes the metric is created,,Yes,Yes
17209,TODO(ptucker): Make this more efficient; maybe add a sparse version of,,Yes,Yes
17210,Bring more nn-associated functionality into this package.,,,Yes
17211,TODO(apassos) add an efficient way to detect eager zeros here.,,,Yes
17212,sufficient statistics. As a workaround we simply perform the operations,,No,Yes
17213,a matrix.  The gradient of _sum_rows(x) is more efficient than,,,Yes
17217,[0; num_classes). Note: This could break users who call this with bad,,Yes,Yes
17219,employ a hack here. We output a dummy invalid value with an incorrect,,Yes,Yes
17221,Note that we use a list as a hack since we need the nested function body,,No,Yes
17222,partition the inputs if needed.,,Yes,Yes
17223,Move S dimension next to C dimension.,,Yes,Yes
17224,TODO(agarwal): Implement this efficiently.,,Yes,Yes
17227,We use an ugly logic to find whether values in Stack data structure are,,Yes,Yes
17228,TODO(agarwal): move _stack_cache inside pfor?,,Yes,Yes
17229,efficient especially for large inputs.,,,Yes
17232,efficient; and only works for associative ops.  (In particular; it,,Yes,Yes
17236,TODO(shlens): Implement edge case to guarantee output size dimensions.,,Yes,Yes
17238,TODO(akshayka): Implement higher-order derivatives.,,,Yes
17239,Now; reduce over the columns; to achieve the desired sum.,,Yes,Yes
17240,Unused.,,Yes,Yes
17241,This is needed to make documentation without fully qualified module paths,,Yes,Yes
17243,TODO(wangpeng): implement other distributions (`uniform`;,,,Yes
17244,TODO(wangpeng): implement `make_seeds`,,Yes,Yes
17245,TODO(wangpeng): implement `make_generators`,,,Yes
17247,functions to create variables) so we take more than needed in the,,No,Yes
17249,TODO(b\/70206927): Fix handling of ResourceVariables.,,Yes,Yes
17250,"\""\""\""while_v2 and gradient. ||  || This is a version of while_loop that emits a single While op; as well as the || gradient function for While ops produced by while_loop. This will eventually || replace the current tf.while_loop implementation once it reaches feature and || performance parity. || \""\""\""",,Yes,Yes
17253,Modify 'op' to output the intermediate accumulators needed by the grad,,Yes,Yes
17255,these would be good; maybe by adding TensorSpec names to cache keys so renamed,,Yes,Yes
17256,TODO(sukritiramesh): Integrate with Saver for complete restore functionality.,,Yes,Yes
17258,Unused by updated loading code.,,,Yes
17259,TODO(aaroey): ideally we should import everything from contrib; but currently,,Yes,Yes
17260,tensorflow\/contrib\/__init__.py. Fix it.,,Yes,Yes
17263,This is needed for freshly started worker; or if the job,,Yes,Yes
17264,corresponding kernel; nodes without a corresponding kernel (perhaps due to,,Yes,Yes
17266,placeholders so that any unused nodes that are inputs to them are,,,Yes
17267,or TPU mode. So allow non-TPU embedding columns also.,,Yes,Yes
17269,initializer differently. See shared_embedding_columns for details.,,,Yes
17273,TODO(phawkins): consider instead pruning unused TPUReplicatedInput,,Yes,Yes
17274,encapsulate TPU computation pass if unused. However we don't remove,,Yes,Yes
17279,Add a dummy output; if needed.,,Yes,Yes
17280,Offset is unused for cols (no partitioning).,,No,Yes
17282,hack to make it easy to find the saver.  Is there a better way?,,Yes,Yes
17283,since they do most of their dependency management themselves (slot,,Yes,Yes
17285,as needed.,,Yes,Yes
17287,Before .save() finishes; they will be (hopefully; atomically) renamed to,,No,Yes
17288,TODO(allenl): Consider another way to gather device information. Lower,,Yes,Yes
17289,added or deleted. Stores unused attributes so an exception can be,,,Yes
17290,eventually depend. Maps local name -> CheckpointPosition list. Optimizers,,Yes,Yes
17291,restore-on-create when executing eagerly; and so is unused when graph,,,Yes
17293,"\""\""\""Utilities related to layer\/model functionality.\""\""\""",,No,Yes
17294,once __init__ files no longer require all of tf.keras to be imported together.,,Yes,Yes
17295,TODO(allenl): If this ends up in a public API; consider adding LINT.IfChange,,,Yes
17296,when graph building. Creating it earlier would lead to double,,,Yes
17297,this run. This is needed for example Estimator makes all model_fn build,,Yes,Yes
17299,exception if any are unused by the end of the loop.  It is easy to misname,,Yes,Yes
17301,Some Python versions would perform regular diff instead of multi-line,,Yes,Yes
17302,ast.Call's constructor is really picky about how many arguments it,,Yes,Yes
17303,the smallest -> here is another hack,,Yes,Yes
17305,Lots of unused arguments below; since these are called in a standard manner.,,,Yes
17306,Maybe it was a positional arg,,,Yes
17308,TODO(cyfoo): Find a better way to serialize and deserialize,,,Yes
17311,Unused. Part of the rnn_cell_fn interface since user specified functions,,Yes,Yes
17313,Unused. Part of the rnn_cell_fn interface since user specified functions,,Yes,Yes
17314,Unused.,,Yes,Yes
17315,columns.,,Yes,Yes
17317,cat columns separately (it is not as expensive as bucketizing) and then,,No,Yes
17318,merge these processed features with other columns in cond branches.,,Yes,Yes
17319,Split columns into categorical and other columns.,,Yes,Yes
17321,TODO(youngheek): perhaps storage could be optimized by storing stats,,,Yes
17322,a local convention without any special meaning.,,,Yes
17324,Iterate over all feature columns and create appropriate lists for dense,,,Yes
17327,unused,,,Yes
17328,TODO(rohanj): This should subclass Checkpointable and implement,,Yes,Yes
17329,unused; required by Fn signature.,,Yes,Yes
17331,TODO(allenl; agarwal): Consider better ways of warm-starting predictions.,,Yes,Yes
17337,input_from_feature_columns does not support completely unknown,,Yes,Yes
17340,unused,,No,Yes
17341,unused; required by Fn signature.,,Yes,Yes
17342,TODO(sourabhbajaj): Remove this hack once we migrate the other strategies,,Yes,Yes
17344,a local convention without any special meaning.,,,Yes
17345,Unused for this head.,,No,Yes
17346,Unused for this head.,,No,Yes
17348,Unused for this head.,,No,Yes
17351,the training. When the training ends; a new checkpoint is generated; which,,No,Yes
17352,Start in-process TensorFlow server if needed. It's important to start the,,No,Yes
17353,once; even if unused.,,Yes,Yes
17354,Flask works around previous behavior by putting,,Yes,Yes
17358,better quality or same quality but more specific => better match,,,Yes
17359,SpooledTemporaryFile doesn't implement IOBase; get the,,Yes,Yes
17360,if the repr looks like a standard string; add subclass info if needed,,Yes,Yes
17363,XXX: utf8 fallback?,,,Yes
17364,XXX: validate,,Yes,Yes
17365,continuation ends.,,No,Yes
17366,XXX: In theory all of these parameters that are not marked with `None`,,Yes,Yes
17367,todo: remove deprecated keys,,,Yes
17368,this seems like a silly case to ever come up but:,,No,Yes
17371,we want to fix this up manually:,,Yes,Yes
17373,XXX: this should eventually be deprecated.,,Yes,Yes
17375,TODO be aware of contiguous (problematic?),,Yes,Yes
17377,move to GPU,,,Yes
17378,batch_x; batch_y = self._recursive_to_cuda(batch_x); self._recursive_to_cuda(batch_y) # move to GPU,,,Yes
17381,TODO: change default value to None if config not in kwargs,,No,Yes
17382,TODO: add arg style (java\/gnu),,,Yes
17383,TODO: make an util class for this,,No,Yes
17386,-- Options for todo extension ----------------------------------------------,,Yes,Yes
17387,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
17389,TODO: accurate name search,,Yes,Yes
17393,Create the directory if needed...,,Yes,Yes
17395,# Create the directory if needed...,,Yes,Yes
17396,# Create the DB directory if needed...,,Yes,Yes
17397,Create the directory if needed...,,,Yes
17398,TODO: May add this back in later...,,,Yes
17402,Create the directory if needed...,,,Yes
17404,Maybe max instead?,,Yes,Yes
17405,hashes.columns = ['index'],,,Yes
17409,virus_hashes.columns = ['sha256'],,Yes,Yes
17412,output tree row - 8 columns:,,No,Yes
17415,"TODO: smart guidance on \""n_jobs\""",,,Yes
17418,TODO: are the following two lines needed here?,,,Yes
17419,TODO: add prediction; gradient; loss,,Yes,Yes
17421,-> not needed,,Yes,Yes
17422,Needed for real training:,,Yes,Yes
17423,Needed for real training (get it from gunpowder.caffe):,,,Yes
17424,TODO: why copy?,,No,Yes
17427,TODO: implement get_net(),,,Yes
17429,TODO: so far assumed that all points have resolution of raw volume,,No,Yes
17431,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
17433,TODO: so far assumed that all points have resolution of raw volume,,,Yes
17434,TODO: different volumes can have different offsets; needs to be added.,,Yes,Yes
17435,TODO: so far assumed that all points have resolution of raw volume,,,Yes
17437,TODO: This is partially a duplicate of add_gt_binary_map_points:get_binary_map; refactor!,,No,Yes
17438,TODO: Consider problem of negative or 0 id; maybe relabel point id list.,,,Yes
17439,TODO: does not consider problem of having the same location for multiple point ids. Currently; the id is overwritten.,,No,Yes
17440,Silence the not needed data and label integer values,,Yes,Yes
17441,input and output shapes of the network; needed to formulate matching batch,,Yes,Yes
17443,input and output shapes of the network; needed to formulate matching batch,,Yes,Yes
17444,Why don't we update gt_affinities in the same way?,,,Yes
17445,-> not needed,,Yes,Yes
17449,move request to provided crop rois,,No,Yes
17451,grow labels ROI to accomodate padding TODO: vol 2,,Yes,Yes
17452,TODO: optionally add stay_inside_arraytype to request,,No,Yes
17453,TODO: This seems broken. There is code involving a voxel size; but points,,,Yes
17455,use more efficient bitwise operation when possible,,,Yes
17458,TODO: consider voxel size,,No,Yes
17461,part of self have to be replaced; a copy is needed,,,Yes
17463,TODO: move all randomness into the prepare method,,Yes,Yes
17464,TODO: What is the goal of `val.spec.roi is None`? Why should that,,Yes,Yes
17470,better == 'max':,,,Yes
17474,-- Options for todo extension ----------------------------------------------,,Yes,Yes
17476,convert to columns,,No,Yes
17478,@@TODO: write a more robust method for this,,,Yes
17482,simply because it shows better performance in my experiments.,,,Yes
17485,Add He's initialization to trainable layers and improved Wasserstein loss to models,,,Yes
17486,Add He's initialization to trainable layers and improved Wasserstein loss to models,,,Yes
17487,He's normal dynamic weight scaler. Used in paper. Completely not working for me. Probably I'm doing something horribly wrong.,,No,Yes
17488,more outputs is better,,No,Yes
17489,more outputs is better,,No,Yes
17494,if decision cannot be made even though all columns dropped,,Yes,Yes
17496,TO-DO: This block could be paralellised,,,Yes
17501,TO-DO: this causes very long running when unique numbers are high. Find a workaround for this.,,No,Yes
17503,TODO: is this logical for 48x2 cores?,,,Yes
17504,TODO: this control might be modified based on num of cores.,,,Yes
17506,"print(instances;\"" rows; \"";columns;\"" columns\"")",,,Yes
17511,TO-DO: if random forest trees are handled in parallel; this would be a problem. You cannot know the related tree of a rule. You should store a global tree id in a rule.,,,Yes
17514,column_name = df.columns[i]; column_type = df[column_name].dtypes #numeric field already transformed to object. you cannot check it with df itself; you should check df_copy,,Yes,Yes
17515,TODO: obj.write(fp),,,Yes
17516,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
17518,TODO this should be uncertainty,,Yes,Yes
17520,TODO do not allow spaces in between unit symbols,,,Yes
17523,TODO do not allow spaces in between unit symbols => currently handled inside parser.py,,,Yes
17525,TODO do not allow spaces in between unit symbols => currently handled inside parser.py,,Yes,Yes
17526,TODO don't do this comparison at every start up; use a build script,,Yes,Yes
17528,TODO don't do this comparison at every start up; use a build script,,Yes,Yes
17530,TODO be aware that there may never be two identical units,,,Yes
17531,TODO rerun if change occurred,,Yes,Yes
17533,TODO rerun if change occurred,,Yes,Yes
17534,TODO use classifier to decide if 3K is 3 thousand or 3 Kelvin,,,Yes
17535,TODO simplify,,,Yes
17537,TODO remove this; as soon as the correct plural branch is merges into inflect,,Yes,Yes
17538,TODO lang support,,,Yes
17539,TODO language support,,,Yes
17544,This should not raise an error; becaues no fitting is needed,,,Yes
17545,This is to make the loop simpler when handling both ends of the,,No,Yes
17546,Case where order reversal is needed,,,Yes
17547,Case where order reversal is needed,,,Yes
17548,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
17550,Fix assumptions about inputs here,,,Yes
17552,We will hack on connectivity a sub transformer on its `depth` param.,,Yes,Yes
17553,Maybe at some point; molml will include more constants; but it seems outside,,,Yes
17554,Hack to get length of features,,,Yes
17557,We will hack on connectivity a sub transformer on its `depth` param.,,Yes,Yes
17561,TODO: better variable names (see below),,,Yes
17562,TODO: better names (see below),,Yes,Yes
17563,some hack for fasttext vectors where the first line is (num_token; dimensions),,,Yes
17564,TODO: better variable names (see below),,,Yes
17565,TODO: better names (see below),,,Yes
17567,BTO 2012-06: everyone thinks the daringfireball regex should be better; but they're wrong.,,,Yes
17568,TODO: remove obscure country domains?,,,Yes
17569,TODO should try a big precompiled lexicon from Wikipedia; Dan Ramage told me (BTO) he does this,,Yes,Yes
17570,between this and the Java version. One little hack won't hurt...,,Yes,Yes
17572,is ignoring errors a good idea? \uD83E\uDD14,,,Yes
17573,some hack for fasttext vectors where the first line is (num_token; dimensions),,No,Yes
17575,TODO: Counts?,,No,Yes
17580,"\""\""\"" || The seqtools package contains functions to manipulate sequences || (anything that supports indexing such as lists or arrays). || Its objective is to simplify the execution of pipelines transformations. ||  || Unless otherwise specified; all functions feature on-demand evaluation || which means operations on an item or sequence are only executed when || needed which is convenient for rapid prototyping. || Most function apply 'transparently' over sequence and return objects || that support integer indexing; iteration; slicing; item assignment; || slice based assignment... ||  || The library also feature a robust multihreading\/multiprocessing || prefetch routine which hides away the difficulties of concurrent || processing into a simple sequence wrapper. || \""\""\""",,,Yes
17581,TODO: save this value,,No,Yes
17583,TODO: put package requirements here,,,Yes
17585,workaround for https:\/\/github.com\/travis-ci\/travis-api\/issues\/196,,,Yes
17586,TODO: add pronouns for languages other than french.,,Yes,Yes
17587,TODO: Skip saved languagesSekouD <sekoud.pythonail.com>,,,Yes
17590,TODO,,Yes,Yes
17592,TODO to handle all kinds of embedding layer variants,,Yes,Yes
17596,TODO precheck target; df..,,Yes,Yes
17597,TODO check processor and assembler,,,Yes
17599,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
17600,out ends with EOS,,,Yes
17606,(needed by 'check_rules'),,Yes,Yes
17610,maybe to add a rule for m\/n before a consonant that disappears [preceeding vowel becomes nasalized],,,Yes
17611,maybe to add a rule for m\/n before a consonant that disappears [preceeding vowel becomes nasalized],,Yes,Yes
17614,TODO: confirm the correctness of this when the docs are different,,Yes,Yes
17616,TODO: verify restriction,,No,Yes
17617,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
17619,fix upstream,,,Yes
17621,TODO: decide how best to return an error,,Yes,Yes
17623,manually checked against algorithm,,Yes,Yes
17626,do elder\/younger move,,,Yes
17628,do elder\/younger move,,,Yes
17629,TODO: Raise exception?,,No,Yes
17631,Checked against Cunningham; et al. (1969) pp. 127--136; as needed.,,Yes,Yes
17632,"\""\""\""call_and_write_log.py ||  || This helper script takes one argument; a call to pylint; pycodestyle; || or flake8. It captures stdout and writes it to a log file. ||  || The reason for this script to exist is as a workaround for tox || not supporting writing to files; even though I want it to do that || to maintain logs & create badges. || \""\""\""",,,Yes
17636,Rule Ia seems to be covered entirely in II,,Yes,Yes
17640,manually checked against algorithm,,,Yes
17642,TODO: 15 should be 10,,,Yes
17643,TODO: should Hamming.dist be available? Hamming.dist_abs?,,No,Yes
17645,Rule Ia seems to be covered entirely in II,,Yes,Yes
17646,TODO: Should these prefixes be supplemented? (VANDE; DELA; VON),,Yes,Yes
17648,- [25 Jan 2017] Version 0.9.1: Fix bug in LCS alignment computation,,Yes,Yes
17649,10 columns of the CoNLL-U file: ID; FORM; LEMMA;...,,Yes,Yes
17650,Define columns in the first row,,Yes,Yes
17651,Define columns in the first row,,Yes,Yes
17654,hack to handle broken jsonl,,Yes,Yes
17655,hack to handle broken jsonl,,Yes,Yes
17658,'''Example of adding a pipeline component to prohibit sentence boundaries || before certain tokens. ||  || What we do is write to the token.is_sent_start attribute; which || takes values in {True; False; None}. The default value None allows the parser || to predict sentence segments. The value False prohibits the parser from inserting || a sentence boundary before that token. Note that fixing the sentence segmentation || should also improve the parse quality. ||  || The specific example here is drawn from https:\/\/github.com\/explosion\/spaCy\/issues\/2627 || Other versions of the model may not make the original mistake; so the specific || example might not be apt for future versions. || ''',,Yes,Yes
17659,Ideally we would somehow specify the warning to suppress?,,,Yes
17660,TODO: This now seems to be implicated in segfaults. Not sure what's up!,,No,Yes
17662,'''Test that deprojectivization doesn't mess up sentence boundaries.''',,Yes,Yes
17664,The simplest way to implement this would be to vstack the,,Yes,Yes
17667,TODO: update once the new format is ready,,,Yes
17669,TODO: validate_json(dev_data; schema),,Yes,Yes
17670,Create the gold corpus to be able to better analyze data,,,Yes
17671,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17673,TODO: This shuldn't be necessary? Should be handled in merge,,Yes,Yes
17678,Make sure all files and paths exists if they are needed,,No,Yes
17683,TODO: replace doc.merge with doc.retokenize,,No,Yes
17688,TODO: document,,No,Yes
17690,TODO remove hardcoded path,,Yes,Yes
17691,TODO: filter on rank:  preferred; normal or deprecated,,No,Yes
17692,TODO remove hardcoded path,,Yes,Yes
17694,TODO: this doesn't work yet,,,Yes
17698,TODO: this doesn't work yet,,Yes,Yes
17699,TODO,,Yes,Yes
17700,TODO coreference resolution,,,Yes
17701,TODO: investigate these cases,,,Yes
17702,TODO: take care of these conflicts ! Currently they are being removed from the dataset,,,Yes
17703,TODO: full dataset,,,Yes
17704,TODO: this doesn't work yet,,Yes,Yes
17705,TODO: expand to non-persons,,No,Yes
17706,TODO: investigate these cases,,No,Yes
17707,TODO: full dataset,,Yes,Yes
17716,TODO backpropagation also for negative examples,,,Yes
17719,TODO,,,Yes
17720,TODO: expand to more than 2 vectors,,,Yes
17723,TODO: use lowest_mse and combine with prior probability,,,Yes
17725,TODO: batch per doc,,,Yes
17726,TODO: FIX,,No,Yes
17727,TODO: use lowest_mse and combine with prior probability,,Yes,Yes
17728,TODO list,,Yes,Yes
17730,TODO: deprecated ?,,No,Yes
17731,TODO: delete ? try again ?,,Yes,Yes
17732,TODO: proper batches. Currently 1 article at the time,,,Yes
17733,TODO: ReLu instead of LN(Maxout)  ?,,No,Yes
17734,TODO remove,,Yes,Yes
17736,TODO: multiple docs\/articles,,,Yes
17739,TODO: more appropriate loss for the whole cluster (currently only pos entities),,,Yes
17740,TODO: speed up,,No,Yes
17741,TODO: ReLu or LN(Maxout)  ?,,No,Yes
17747,TODO: vector_list !,,,Yes
17748,TODO entity vectors,,No,Yes
17749,TODO: should we remove entities from the KB where there is no description ?,,Yes,Yes
17750,TODO: fix this - doesn't look like all entities are found,,Yes,Yes
17752,TODO proper error,,No,Yes
17756,Minimum number of expected occurrences of dependency labels,,No,Yes
17760,temp fix to avoid import issues cf https:\/\/github.com\/explosion\/spaCy\/issues\/4200,,Yes,Yes
17761,temp fix to avoid import issues cf https:\/\/github.com\/explosion\/spaCy\/issues\/4200,,Yes,Yes
17762,temp fix to avoid import issues cf https:\/\/github.com\/explosion\/spaCy\/issues\/4200,,,Yes
17763,temp fix to avoid import issues cf https:\/\/github.com\/explosion\/spaCy\/issues\/4200,,Yes,Yes
17764,TODO: serialize bloom too. For now just reconstruct it.,,No,Yes
17765,TODO: This shouldn't be necessary? Should be handled in merge,,Yes,Yes
17767,Double newlines seem to mess with the rendering,,Yes,Yes
17770,min() needed to prevent error on windows; cf https:\/\/stackoverflow.com\/questions\/52404416\/,,,Yes
17771,TODO: add more cases from non-English WP's,,Yes,Yes
17772,TODO: check that alias == doc.text[start:end],,Yes,Yes
17779,TODO: document,,,Yes
17780,TODO: fix numbering after merging develop into master,,,Yes
17784,TODO FIX,,,Yes
17786,TODO: document,,,Yes
17788,TODO: experiment with init_w=zero_init,,Yes,Yes
17789,TODO: glorot_uniform_init seems to work a bit better than zero_init here?!,,Yes,Yes
17791,TODO: actual vectors instead of name,,,Yes
17792,TODO FIX,,Yes,Yes
17793,TODO: update,,No,Yes
17794,TODO: use examples instead ?,,,Yes
17795,TODO: this code originally didn't normalize; but shouldn't normalize=True ?,,Yes,Yes
17796,TODO: document,,No,Yes
17797,TODO: relative imports?,,Yes,Yes
17798,TODO: this code originally didn't normalize; but shouldn't normalize=True ?,,,Yes
17801,TODO: replace with config,,No,Yes
17802,TODO: fix numbering after merging develop into master,,Yes,Yes
17803,TODO: document,,,Yes
17804,TODO cf https:\/\/github.com\/explosion\/spaCy\/blob\/2c107f02a4d60bda2440db0aad1a88cbbf4fb52d\/spacy\/_ml.py#L828,,,Yes
17805,TODO: glorot_uniform_init seems to work a bit better than zero_init here?!,,,Yes
17806,TODO: experiment with init_w=zero_init,,Yes,Yes
17807,is a bit ugly here.,,,Yes
17808,TODO FIX,,,Yes
17812,This is a hack to avoid the problem in #3853.,,,Yes
17813,TODO Make concatenate support lists,,,Yes
17817,TODO: document,,,Yes
17818,Bit of a hack after the refactor to get the vectors into a default config,,,Yes
17819,TODO: document,,No,Yes
17821,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
17822,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
17824,TODO: de-uglify (incorporating into component decorator didn't work because of circular imports),,Yes,Yes
17826,TODO: Fix error,,,Yes
17827,TODO: Fix error,,,Yes
17829,TODO: document,,No,Yes
17831,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17835,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17837,TODO Make concatenate support lists,,,Yes
17838,TODO: document,,No,Yes
17840,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
17841,Handle cases where exact version is provided as constraint,,,Yes
17842,if this goes wrong; the initialization of the parser's upper layer is probably broken,,,Yes
17846,XXX This isn't working? Always passes,,Yes,Yes
17848,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
17849,Make sure all files and paths exists if they are needed,,No,Yes
17851,if this goes wrong; the initialization of the parser's upper layer is probably broken,,,Yes
17852,TODO: document,,,Yes
17854,TODO: write,,No,Yes
17856,TODO: support loading from GitHub URLs? Automatically convert to raw?,,Yes,Yes
17857,from ..schemas import ConfigSchema  # TODO: include?,,,Yes
17858,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17859,TODO: is this needed \/ a good idea?,,,Yes
17860,keep the names short; but not needed at the moment.,,Yes,Yes
17861,TODO: doc-level format,,,Yes
17863,"\""conllubio\"": conllu2docs; TODO",,Yes,Yes
17864,"\""conll\"": conllu2docs; TODO",,Yes,Yes
17865,TODO: support msgpack via stdout in srsly?,,Yes,Yes
17866,from ..schemas import ConfigSchema  # TODO: include?,,,Yes
17867,TODO: naming,,No,Yes
17869,TODO: We shouldn't be getting these malformed inputs. Fix this.,,Yes,Yes
17870,TODO,,Yes,Yes
17871,TODO,,Yes,Yes
17873,Handle cases where exact version is provided as constraint,,,Yes
17874,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17876,TODO: find a better solution for this?,,No,Yes
17883,Remove unused and confusing plot templates from .dvc directory,,Yes,Yes
17886,TODO: replace with (stable) Draft6Validator; if available,,,Yes
17887,TODO,,Yes,Yes
17889,from ..schemas import ConfigSchema  # TODO: include?,,Yes,Yes
17890,TODO: document,,No,Yes
17891,TODO,,Yes,Yes
17892,Writing them like this for readability but maybe replace with regex?,,Yes,Yes
17893,TODO: find a solution for caches,,Yes,Yes
17895,Not sure if this is needed or a good idea. Motivation: users may often,,,Yes
17896,TODO: this is currently pretty slow,,No,Yes
17899,keep the names short; but not needed at the moment.,,Yes,Yes
17901,TODO: improve logic to handle simple types like list of strings?,,No,Yes
17904,from ..schemas import ConfigSchema  # TODO: include?,,Yes,Yes
17905,TODO: use a more detailed schema for this?,,Yes,Yes
17906,TODO: add config schema \/ types for components so we can fill and validate,,,Yes
17907,TODO: use a more detailed schema for this?,,,Yes
17910,TODO: Validate data format using the JSON schema,,Yes,Yes
17911,TODO: update once the new format is ready,,,Yes
17916,the dim inference doesn't always work 100%; we need this hack like we have it in pipe.pyx,,,Yes
17920,TODO: maybe we should validate based on the actual components; the list,,Yes,Yes
17922,TODO: customize validation to make it more readable \/ relate it to,,,Yes
17923,TODO - what kind of default makes sense here?,,,Yes
17924,"TODO: make stateful component with \""label\"" config",,Yes,Yes
17925,TODO: do we want to keep these?,,No,Yes
17926,This functionality was available previously; but was broken.,,Yes,Yes
17928,TODO: fix this,,No,Yes
17933,TODO: Adding this back to prevent breaking people's code etc.; but,,,Yes
17936,TODO: document,,No,Yes
17937,TODO: integrate pipeline analyis,,Yes,Yes
17939,TODO: integrate pipeline analyis,,,Yes
17945,TODO: make this feedback more fine-grained and report on updated,,,Yes
17947,TODO: handle errors and mismatches (vectors etc.),,No,Yes
17948,"TODO: base_path: Optional[Path] = Opt(None; \""--base\""; \""-b\""; help=\""Optional base config to fill\""; exists=True; dir_okay=False);",,Yes,Yes
17950,This ends up being RIDICULOUS. omg.,,No,Yes
17955,TODO: why did we add this?,,,Yes
17957,TODO: Should we make this available via  a user-facing property? (The,,No,Yes
17958,TODO: why did we add this?,,Yes,Yes
17959,TODO: maybe add some more checks \/ catch errors that may occur if,,No,Yes
17960,This is pretty grim; but it's hard to do better :(.,,,Yes
17961,TODO: should this warn or error?,,No,Yes
17964,TODO: maybe we should validate based on the actual components; the list,,,Yes
17967,you shouldn't really call this more than once; but for testing it should be fine,,Yes,Yes
17968,you shouldn't really call this more than once; but for testing it should be fine,,Yes,Yes
17969,you shouldn't really call this more than once; but for testing it should be fine,,Yes,Yes
17970,you shouldn't really call this more than once; but for testing it should be fine,,Yes,Yes
17972,TODO: this seems kinda brittle?,,No,Yes
17974,"I had though; \""Why do we do this inside the Language object? Shouldn't",,,Yes
17976,This is a temporary hack to work around the problem that the scorer,,No,Yes
17977,ugly hack to deal with Tok2Vec listeners,,Yes,Yes
17981,the dim inference doesn't always work 100%; we need this hack like we have it in pipe.pyx,,Yes,Yes
17982,ugly hack to deal with Tok2Vec listeners,,Yes,Yes
17984,TODO error,,No,Yes
17987,TODO: This might not be called corpora,,No,Yes
17988,TODO: It might not be 'corpora',,No,Yes
17991,TODO: add more instructions,,,Yes
17992,TODO: this should be handled better?,,,Yes
17994,TODO: add warnings \/ --initialize (?) argument,,Yes,Yes
17996,TODO: move lookups to [initialize]; add vocab data,,,Yes
17997,TODO: this is currently imported by the ray extension and not used otherwise,,No,Yes
17999,TODO: do this better and more fine-grained,,No,Yes
18000,TODO: does this need to be updated?,,No,Yes
18001,TODO: do this better and more fine-grained,,No,Yes
18002,TODO: maybe we should validate based on the actual components; the list,,Yes,Yes
18005,TODO: I think we probably want this to look more like the,,No,Yes
18006,The simplest way to implement this would be to vstack the,,Yes,Yes
18010,TODO: Is this correct? Does this matter?,,No,Yes
18011,TODO: This is kinda hacky and we should probably provide a better,,Yes,Yes
18012,TODO: I think we probably want this to look more like the,,No,Yes
18013,The simplest way to implement this would be to vstack the,,Yes,Yes
18014,TODO,,Yes,Yes
18021,TODO: Validate data format using the JSON schema,,Yes,Yes
18027,TODO: Replace this once we handle vectors consistently as static,,Yes,Yes
18028,Component meta and configs are only needed on the instance,,No,Yes
18029,TODO: Adding this back to prevent breaking people's code etc.; but,,No,Yes
18030,TODO: handle errors and mismatches (vectors etc.),,,Yes
18031,"I had though; \""Why do we do this inside the Language object? Shouldn't",,Yes,Yes
18034,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
18035,TODO: user warning?,,,Yes
18036,is a bit ugly here.,,,Yes
18037,TODO: include schema?,,,Yes
18039,TODO: user warning?,,Yes,Yes
18041,TODO: move to legacy,,No,Yes
18042,TODO: correct checks for numpy rather than ignoring,,,Yes
18045,TODO: make this feedback more fine-grained and report on updated,,No,Yes
18048,TODO: replace with (stable) Draft6Validator; if available,,,Yes
18049,TODO: user warning?,,Yes,Yes
18050,TODO: include schema?,,,Yes
18052,TODO: user warning?,,Yes,Yes
18053,Component meta and configs are only needed on the instance,,No,Yes
18055,TODO: handle errors and mismatches (vectors etc.),,No,Yes
18056,"I had though; \""Why do we do this inside the Language object? Shouldn't",,Yes,Yes
18057,TODO: make this feedback more fine-grained and report on updated,,,Yes
18058,TODO: does this need to be updated?,,No,Yes
18059,TODO: include schema?,,Yes,Yes
18061,TODO: user warning?,,,Yes
18063,TODO: Validate data format using the JSON schema,,Yes,Yes
18064,TODO: update once the new format is ready,,No,Yes
18065,TODO: move validation to GoldCorpus in order to be able to load from dir,,,Yes
18066,TODO: replace with (stable) Draft6Validator; if available,,,Yes
18068,TODO: include schema?,,Yes,Yes
18070,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
18071,TODO: user warning?,,,Yes
18072,TODO: make this feedback more fine-grained and report on updated,,No,Yes
18073,TODO: does this need to be updated?,,,Yes
18076,TODO: Adding this back to prevent breaking people's code etc.; but,,,Yes
18077,TODO: handle errors and mismatches (vectors etc.),,No,Yes
18078,"I had though; \""Why do we do this inside the Language object? Shouldn't",,Yes,Yes
18081,you shouldn't really call this more than once; but for testing it should be fine,,,Yes
18085,TODO: replace with (stable) Draft6Validator; if available,,No,Yes
18086,TODO: user warning?,,Yes,Yes
18087,"TODO: make stateful component with \""label\"" config",,Yes,Yes
18090,TODO: replace with (stable) Draft6Validator; if available,,,Yes
18091,TODO: user warning?,,Yes,Yes
18092,TODO: likely bug in spaCy if this happens,,No,Yes
18094,XXX: once in SVN; should add svn version...,,Yes,Yes
18096,* Neither the author nor the names of any contributors may be used,,,Yes
18097,* Neither the author nor the names of any contributors may be used,,,Yes
18098,* Neither the author nor the names of any contributors may be used,,,Yes
18100,XXX: handling Nan is important here.,,,Yes
18101,TODO: check for overflow here and...,,,Yes
18102,TODO: here...,,No,Yes
18104,TODO: check for overflow here...,,,Yes
18106,hopefully eventually RTRL and EKF,,Yes,Yes
18108,hopefully eventually RTRL and EKF,,Yes,Yes
18112,binary search would be faster,,Yes,Yes
18118,( general EM should be outside this module. This one should be GMM specific; maybe),,,Yes
18119,TODO Check args here,,Yes,Yes
18120,TODO: check each value of inverse distribution is,,,Yes
18121,This one should be a bit faster,,Yes,Yes
18122,initialization. This is ugly; and we should have a class to model a GMM,,No,Yes
18123,TODO: adjustable level (to do in gauss_ell).,,,Yes
18125,initialization. This is ugly; and we should have a class to model a GMM,,No,Yes
18127,the parameters afterward. There should be a better way ?,,Yes,Yes
18129,TODO Check args here,,Yes,Yes
18130,TODO: check each value of inverse distribution is,,Yes,Yes
18131,This one should be a bit faster,,Yes,Yes
18132,TODO:,,,Yes
18134,TODO:,,No,Yes
18140,TODO:,,No,Yes
18141,TODO:,,No,Yes
18142,big problem; but it would be better to really return them as the name implied.,,,Yes
18143,TODO:,,,Yes
18144,To reproduce results; fix the random seed,,,Yes
18146,* Neither the author nor the names of any contributors may be used,,,Yes
18147,XXX: have a public function to compute the pdf at given points,,Yes,Yes
18148,XXX: we need log pdf; not the pdf... this can save some computing,,Yes,Yes
18149,XXX refactor computing pdf,,,Yes
18150,XXX: This is bogus: should do better (in kmean or here; do not know yet),,Yes,Yes
18151,XXX: Bouah; hackish... Will go away once scipydata found its way,,,Yes
18154,XXX: when fromvalues is called; parameters are called twice...,,Yes,Yes
18155,TODO: do it in log domain instead,,No,Yes
18156,* Neither the author nor the names of any contributors may be used,,,Yes
18158,* Neither the author nor the names of any contributors may be used,,Yes,Yes
18160,XXX optimize log case as non log case above,,Yes,Yes
18161,XXX classification models need weights,,Yes,Yes
18163,XXX find better way to keep svm_data reference,,Yes,Yes
18165,XXX setting these to None zeros svm_type,,Yes,Yes
18166,XXX remove this,,Yes,Yes
18170,XXX remove this,,Yes,Yes
18171,XXX this is probably suboptimal when training many models,,Yes,Yes
18172,XXX because libsvm only does a shallow copy of the,,,Yes
18173,XXX maybe we want to cast return value to int,,,Yes
18174,XXX predict_values might also be useful,,Yes,Yes
18176,XXX because libsvm only does a shallow copy of the,,,Yes
18178,XXX possible ctypes bug: setting these to None instead of,,Yes,Yes
18179,XXX workaround for bug in ctypes 0.9.9.6,,Yes,Yes
18180,XXX keep references to y and x inside problem; if ctypes allows,,,Yes
18184,XXX possible numpy bug,,,Yes
18185,XXX N.resize is our friend here,,,Yes
18186,XXX we can handle gamma=None here,,,Yes
18187,XXX we can hide an id in the end of record marker so that we,,,Yes
18189,fix support vector ids in precomputed data,,No,Yes
18192,XXX possible optimization: izip,,,Yes
18193,XXX need to map back from these support vector pointers to,,,Yes
18197,XXX shows bug where we can't get any support vectors,,,Yes
18198,XXX: does this guarantee that the package is the one in the dev trunk; and,,Yes,Yes
18201,XXX: this is to avoid recursive call to itself. This is an horrible hack;,,No,Yes
18202,XXX: this is to avoid recursive call to itself. This is an horrible hack;,,No,Yes
18203,I have no idea why infinite recursion happens otherwise.,,No,Yes
18204,* Neither the author nor the names of any contributors may be used,,Yes,Yes
18205,* Neither the author nor the names of any contributors may be used,,Yes,Yes
18206,TODO:,,No,Yes
18207,TODO: this is where we are spending times. I think things could be,,,Yes
18208,XXX The above code is ugly,,,Yes
18209,Implement partial application (should only be used if functools is not,,,Yes
18210,No error should happen here: it is a bug otherwise,,Yes,Yes
18212,* Neither the author nor the names of any contributors may be used,,Yes,Yes
18213,needed for saving the state,,,Yes
18214,needed for saving the state,,Yes,Yes
18215,needed for saving the state,,,Yes
18216,"\""\""\""Module implementing GM; a class which represents Gaussian mixtures. ||  || GM instances can be used to create; sample mixtures. They also provide || different plotting facilities; such as isodensity contour for multi dimensional || models; ellipses of confidence; etc...\""\""\""",,Yes,Yes
18217,TODO:,,No,Yes
18218,should be a sensible way to modify the result plot (maybe returns a dic,,,Yes
18219,TODO Check args here,,,Yes
18220,TODO: check each value of inverse distribution is different,,,Yes
18222,XXX: make this faster ?,,,Yes
18226,#         # XXX shows bug where we can't get any support vectors,,,Yes
18229,unused_docs = [],,Yes,Yes
18230,unused_docs = [],,Yes,Yes
18231,XXX shows bug where we can't get any support vectors,,Yes,Yes
18233,needed for saving the state,,Yes,Yes
18235,Compute norms of the columns of X,,No,Yes
18240,FIXME : support estimate is done again in predict too in,,,Yes
18245,avoid this ugly slicing by using a two-dim dataset,,Yes,Yes
18246,TODO: not sure of these results.,,No,Yes
18247,dual_gap seems a bit too high,,,Yes
18249,XXX: store a path of Lasso instances instead?,,,Yes
18250,XXX: store a path of Lasso instances instead?,,Yes,Yes
18251,XXX: store a path of Lasso instances instead?,,,Yes
18254,FIXME : should not early stop,,,Yes
18256,avoid this ugly slicing by using a two-dim dataset,,,Yes
18258,TODO: why are we getting all the dataset as support vectors,,No,Yes
18261,TODO: why are we getting all the dataset as support vectors,,,Yes
18262,TODO: why not define a method rsquared that computes this ?,,No,Yes
18264,TODO: why not define a method rsquared that computes this ?,,,Yes
18265,TODO: use numpy.linalg instead,,,Yes
18268,todo; shouldn't most of these have trailing underscores ?,,,Yes
18269,TODO: add intercept,,,Yes
18270,needed by LeastAngleRegression,,No,Yes
18271,todo: not general!,,Yes,Yes
18273,XXX: there seems to be somthing borked in the shape reconstruction of the,,,Yes
18277,XXX: there seems to be somthing borked in the shape reconstruction of the,,Yes,Yes
18281,"\""\""\"" || Machine Learning module in python || ================================= ||  || scikits.learn is a Python module integrating classique machine || learning algorithms in the tightly-nit world of scientific Python || packages (numpy; scipy; matplotlib). ||  || It aims to provide simple and efficient solutions to learning problems || that are accessible to everybody and reusable in various contexts: || machine-learning as a versatile tool for science and engineering. ||  || See http:\/\/scikit-learn.sourceforge.net for complete documentation. || \""\""\""",,Yes,Yes
18285,TODO: implement the remaining domain formats,,No,Yes
18287,representation of a text dataset. Efficient handling of sparse data,,,Yes
18288,TODO: make it possible to plug a several pass system to filter-out tokens,,Yes,Yes
18290,TODO: make it possible to pass stop words list here,,Yes,Yes
18291,TODO: make it possible to select between the current dense representation,,Yes,Yes
18293,TODO:,,,Yes
18294,TODO: put keyword copy to copy on demand,,Yes,Yes
18296,better than nested.,,,Yes
18298,TODO: explicitly specify size,,Yes,Yes
18301,XXX: Should maybe have an argument to raise when,,,Yes
18302,XXX: cross_val_factory should have a default,,Yes,Yes
18303,TODO: some cleanup: is nSV_ really needed ?,,No,Yes
18304,XXX: Should maybe have an argument to raise when,,Yes,Yes
18305,QDA #FIXME,,,Yes
18307,XXX: should have a n_jobs to be able to do this in parallel.,,,Yes
18308,"\""\""\"" || ================================================= || SVM-Anova: SVM with univariate feature selection || ================================================= ||  || This example shows how to perform univariate feature before running a SVC || (support vector classifier) to improve the classification scores. || \""\""\""",,,Yes
18309,Hack to avoid printing the interals of IPython,,Yes,Yes
18312,XXX: Maybe I need an inspect.isbuiltin to detect C-level methods; such,,,Yes
18314,XXX: There might be a more efficient way of doing this,,,Yes
18315,XXX: This conflicts with the debug flag used in children class,,Yes,Yes
18316,XXX: Need argument docstring,,,Yes
18317,FIXME: Too much logic duplicated,,No,Yes
18318,TODO: The following object should have a data store object as a sub,,No,Yes
18319,implement HDF5 pickling.,,,Yes
18320,TODO: Same remark for the logger; and probably use the Python logging,,,Yes
18321,TODO: Track history as objects are called; to be able to garbage,,Yes,Yes
18323,XXX: Should use an exception logger,,Yes,Yes
18324,XXX: Ugly,,,Yes
18325,XXX: Should be using warnings; and giving stacklevel,,,Yes
18326,XXX: Not using logging framework,,Yes,Yes
18328,XXX: Should this use inspect.formatargvalues\/formatargspec?,,Yes,Yes
18329,XXX: Need a method to check if results are available.,,Yes,Yes
18331,XXX: We should have a logging mechanism,,Yes,Yes
18332,XXX: Not using the logger framework: need to,,,Yes
18333,learn to use logger better.,,Yes,Yes
18335,TODO: implement me using the murmurhash that might be faster: but profile,,No,Yes
18336,TODO: make it possible to select between the current dense representation,,Yes,Yes
18339,XXX: Should use numpy.logspace,,Yes,Yes
18342,XXX: Should use numpy.logspace,,,Yes
18343,XXX: Maybe should reorder the models when outputing them; so,,,Yes
18347,how can this be; logisitic *does* implement this,,Yes,Yes
18349,TODO: why are we getting all the dataset as support vectors,,,Yes
18353,XXX: Why mask the image after computing the weights?,,,Yes
18354,"\""\""\"" || =========================================== || Segmenting the picture of Lena in regions || =========================================== ||  || This example uses spectral clustering on a graph created from || voxel-to-voxel difference on an image to break this image into multiple || partly-homogenous regions. ||  || This procedure (spectral clustering on an image) is an efficient || approximate solution for finding normalized graph cuts. || \""\""\""",,,Yes
18357,XXX: Should be renamed to slogdet,,Yes,Yes
18361,todo; shouldn't most of these have trailing underscores ?,,Yes,Yes
18364,TODO: why not define a method rsquared that computes this ?,,No,Yes
18365,needed by LeastAngleRegression,,,Yes
18366,product. Maybe we should implement in C our own masked_dot that does,,,Yes
18367,should have a better name,,Yes,Yes
18368,there are better ways,,Yes,Yes
18370,# TODO: resize (not create) arrays; check shape;,,No,Yes
18371,XXX : wrong label,,No,Yes
18372,XXX : wrong label,,,Yes
18373,TODO: check that Lasso with coordinate descent finds the same,,No,Yes
18375,TODO: add intercept,,Yes,Yes
18377,XXX: these should be optimized; as they can be a bottleneck.,,Yes,Yes
18378,Centering the columns (ie the variables),,No,Yes
18379,TODO: add support for non centered data,,,Yes
18380,TODO: implement me!,,Yes,Yes
18382,"\""\""\"" || ========================== || FastICA on 2D point clouds || ========================== ||  || XXX: Still buggy !!! ||  || \""\""\""",,,Yes
18386,XXX : should use self._set_intercept,,,Yes
18387,XXX: This is going to fail if the init is a staticmethod; but,,Yes,Yes
18388,TODO: precompute : empty for now,,No,Yes
18390,XXX: Hotfit for n_mix that is incompatible with the scikit's,,Yes,Yes
18391,"\""\""\"" || ============================== || Lasso on dense and sparse data || ============================== ||  || We show that glm.Lasso and glm.sparse.Lasso || provide the same results. ||  || XXX : At the end of the day it should also lead to a speed improvement ||  || \""\""\""",,,Yes
18392,"\""\""\"" || ============================== || Lasso on dense and sparse data || ============================== ||  || We show that glm.Lasso and glm.sparse.Lasso || provide the same results. ||  || XXX : At the end of the day it should also lead to a speed improvement ||  || \""\""\""",,Yes,Yes
18393,there are better ways,,,Yes
18394,np.delete (Cov; imax) # very ugly; has to be fixed,,Yes,Yes
18395,To avoid aving to do two passes on the dataset; which would require,,Yes,Yes
18396,XXX : should handle also unnormalized datasets,,,Yes
18397,XXX: Temporary solution to figure out if an estimator is a classifier,,Yes,Yes
18399,TODO: precompute : empty for now,,No,Yes
18400,# TODO: resize (not create) arrays; check shape;,,No,Yes
18401,will only normalize non-zero columns,,Yes,Yes
18402,XXX : should use self._set_intercept,,,Yes
18403,TODO: check that Lasso with coordinate descent finds the same,,No,Yes
18404,To avoid aving to do two passes on the dataset; which would require,,Yes,Yes
18406,TODO: put keyword copy to copy on demand,,Yes,Yes
18407,how can this be; logisitic *does* implement this,,Yes,Yes
18408,TODO: explicitly specify size,,Yes,Yes
18410,TODO: this lacks a docstring,,No,Yes
18412,versions of scipy prior to 0.7 do not implement .tolil(),,,Yes
18413,TODO: make it possible to plug a several pass system to filter-out tokens,,Yes,Yes
18415,FIXME: precision and recall aren't symmetric either,,,Yes
18417,FIXME what if prediction is 0 - break randomly?,,No,Yes
18419,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
18420,TODO: make it possible to plug a several pass system to filter-out tokens,,Yes,Yes
18422,TODO: distance should be sqrt(2)\/2; but libsvm returns 1.,,Yes,Yes
18424,FIXME: sparsity structure changed,,,Yes
18425,FIXME: if enough values became 0; it may be worth changing,,,Yes
18427,TODO: write docstring!,,,Yes
18429,TODO: refactor the HashingVectorizer implementation to reuse the,,Yes,Yes
18430,FIXME what if sign == 0? break randomly?,,Yes,Yes
18433,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
18435,TODO: make it possible to plug a several pass system to filter-out tokens,,Yes,Yes
18438,how can this be; logisitic *does* implement this,,,Yes
18439,2 # XXX : shouldn't verbose be a instance param,,,Yes
18441,FIXME what if sign == 0? break randomly?,,Yes,Yes
18442,how can this be; logisitic *does* implement this,,Yes,Yes
18445,temporary disabling multilabel support to implement proper multiclass,,,Yes
18448,TODO: make it possible to plug a several pass system to filter-out tokens,,Yes,Yes
18452,"\""\""\"" || =========================================================== || A demo of K-Means clustering on the handwritten digits data || =========================================================== ||  || Comparing various initialization strategies in terms of runtime and quality of || the results. ||  || TODO: explode the ouput of the cluster labeling and digits.target groundtruth || as categorical boolean arrays of shape (n_sample; n_unique_labels) and measure || the Pearson correlation as an additional measure of the clustering quality. || \""\""\""",,,Yes
18455,avoid this ugly slicing by using a two-dim dataset,,,Yes
18457,and allows to easily swap columns,,,Yes
18461,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
18464,XXX : can do better to avoid precision overflows,,,Yes
18466,TODO: factorize this out as a utility function in scikit-learn,,,Yes
18467,TODO: find a way to hide the x and y axis,,No,Yes
18468,TODO: plot the top eigenfaces and the singular values absolute values,,Yes,Yes
18470,XXX: some vectors are not equal; while others perfectly match?,,No,Yes
18472,XXX : why doing this below?,,Yes,Yes
18474,XXX : is it really useful to define those lambda if it's just,,Yes,Yes
18475,XXX : computation do not match docstring,,,Yes
18476,XXX : why not storing explicitely X_mean; X_std; y_mean; y_std,,,Yes
18477,XXX : code duplication. You should create a separate,,,Yes
18478,XXX : avoid lambda functions. It won't pickle hence not,,Yes,Yes
18479,XXX : same thing about lambda functions,,,Yes
18480,XXX: alpha = 0.1 seems to cause convergence problems,,Yes,Yes
18484,initt = time(); time limit should probably be removed?,,,Yes
18485,transpose back the results according to the input convention,,,Yes
18487,I probably messed something up.,,Yes,Yes
18488,XXX : can do better to avoid precision overflows,,Yes,Yes
18492,# TODO add flag for intercept learning rate heuristic,,,Yes
18493,disabling joblib as the pickling of large dicts seems much too slow,,Yes,Yes
18494,XXX,,Yes,Yes
18495,!!!!! apparently not!,,Yes,Yes
18497,is this really needed ?,,Yes,Yes
18498,"\""\""\"" || =========================================================== || A demo of feature agglomeration - structured ward || =========================================================== ||  || Author : Vincent Michel; 2010 ||  || \""\""\""",,Yes,Yes
18499,TODO: offer an argument to allow doing this inplace,,No,Yes
18500,TODO:,,No,Yes
18501,FIXME: handle fit_intercept,,Yes,Yes
18503,check that efficient and brute-force LOO give same results,,Yes,Yes
18505,XXX,,Yes,Yes
18506,FIXME: need to implement sample_weight in Ridge,,,Yes
18507,XXX don't like that,,Yes,Yes
18508,XXX: this does not seam to work as expected:,,,Yes
18510,TODO: better names for these variables: z,,No,Yes
18511,XXX: this does not seam to work as expected:,,,Yes
18512,"\""\""\"" || Bench the scikit's ward implement compared to scipy's || \""\""\""",,Yes,Yes
18515,XXX: Should create A and coord_row; coord_row here,,Yes,Yes
18516,for each component; generate all needed samples,,Yes,Yes
18517,TODO: plot the top eigenfaces and the singular values absolute values,,Yes,Yes
18520,Permanently add best center candidate found in local tries,,No,Yes
18528,TODO: define a variable named 'clf',,Yes,Yes
18529,TODO: define a variable named 'y_predicted',,,Yes
18530,"\""\""\""Face recognition using PCA (eigenfaces) and SVM ||  ||  || This exercises has a lot of boilerplate code to extrat the most represented || faces: ||  || TODO: once the LFW dataset loader is stable enough in scikit-learn 0.8; use it || here instead. || \""\""\""",,Yes,Yes
18532,TODO: implement a grid search for the best SVM with gaussian kernel,,Yes,Yes
18534,TODO: plot the top eigenfaces and the singular values absolute values,,,Yes
18535,TODO: the pipeline instance must be named 'clf',,,Yes
18536,TODO: the predicted outcome must be named 'y_predicted',,Yes,Yes
18539,TODO: the predicted outcome must be named 'y_predicted',,Yes,Yes
18540,TODO: uncomment the following once all of the above is implemented,,No,Yes
18544,TODO: check on NuSVR; OneClass; etc.,,Yes,Yes
18545,XXX: Not using the logger framework: need to,,,Yes
18547,XXX: possible race condition shuffling the order of,,,Yes
18548,XXX: Need to make use of Parallel's new pre_dispatch,,Yes,Yes
18550,TODO: function to search dataset name and return best match,,,Yes
18551,TODO: error checking!,,,Yes
18552,XXX: what is 'mldata_descr_ordering'?,,,Yes
18553,XXX : can do better to avoid precision overflows,,,Yes
18554,XXX: Doesn't the below get computed twice if calling fit_transform?,,,Yes
18555,distribution. This class allows for easy and efficient inference,,,Yes
18559,FIXME code deduplication with kmeans fit method,,No,Yes
18563,TODO: Add tree diagram,,Yes,Yes
18565,Author: Fabian Pedregosa <fabian.pedregosa@inria.fr> with help from,,,Yes
18567,the dirichlet process model will only use as many are needed to,,Yes,Yes
18568,XXX: should be in joblib,,Yes,Yes
18569,FIXME,,Yes,Yes
18572,FIXME,,,Yes
18574,This import is needed to modify the way figure behaves,,,Yes
18579,non-standard columns,,Yes,Yes
18583,FIXME: if enough values became 0; it may be worth changing,,,Yes
18584,XXX: Need to make use of Parallel's new pre_dispatch,,,Yes
18586,XXX: In the dense case; we could vectorize this loop. It might be,,,Yes
18588,TODO: multi-class hinge-loss,,Yes,Yes
18590,XXX: In the dense case; we could vectorize this loop. It might be,,Yes,Yes
18592,XXX: where should this be?,,No,Yes
18597,real;imaginary in consecutive columns,,Yes,Yes
18598,in consecutive columns,,Yes,Yes
18600,XXX: make it work with colour images too!,,,Yes
18602,(see XXX up ahead),,,Yes
18606,XXX: make it work with colour images too!,,No,Yes
18607,XXX: Can the residuals be of any use?,,Yes,Yes
18612,XXX: where should this be?,,No,Yes
18613,todo: use preprocessors,,,Yes
18614,TODO: Ridge,,Yes,Yes
18615,XXX: Can the residuals be of any use?,,Yes,Yes
18618,XXX : kwargs is not documented,,Yes,Yes
18619,XXX: should be in joblib,,Yes,Yes
18620,XXX: Can the residuals be of any use?,,Yes,Yes
18621,Maybe we need a stopping criteria based on the amount of,,,Yes
18623,Maybe we need a stopping criteria based on the amount of,,,Yes
18624,XXX: Can the residuals be of any use?,,,Yes
18625,Maybe we need a stopping criteria based on the amount of,,,Yes
18629,XXX: Can the residuals be of any use?,,Yes,Yes
18631,feature vector is split into a positive and negative side,,Yes,Yes
18633,XXX: Can the residuals be of any use?,,Yes,Yes
18637,Maybe we need a stopping criteria based on the amount of,,Yes,Yes
18639,Maybe we need a stopping criteria based on the amount of,,,Yes
18647,XXX: Can the residuals be of any use?,,,Yes
18648,Maybe we need a stopping criteria based on the amount of,,,Yes
18650,XXX: should we always do this?,,,Yes
18651,XXX: should we always do this?,,,Yes
18653,XXX: Can the residuals be of any use?,,,Yes
18654,Maybe we need a stopping criteria based on the amount of,,,Yes
18657,note: there's probably a more efficient way to do this,,No,Yes
18658,FIXME: we should probably reset __new__ for full generality,,Yes,Yes
18660,@TODO Find a way of passing in a pseudo-random generator,,,Yes
18662,XXX: change samples_generator to the transpose problem; makes more sense,,,Yes
18663,FIXME: we should probably reset __new__ for full generality,,,Yes
18664,TODO:,,No,Yes
18665,TODO:,,No,Yes
18666,good way to do this without duplicating kneighbors_graph code.,,,Yes
18667,TODO ALL OF THIS,,Yes,Yes
18669,XXX: Can the residuals be of any use?,,Yes,Yes
18671,XXX: is this the most efficient way? memory-wise yes; cpu wise?,,Yes,Yes
18674,XXX : would be better to avoid a realloc for each image,,Yes,Yes
18675,This ugly construction is required because np.random,,Yes,Yes
18676,choose the most efficient way to find the eigenvectors,,,Yes
18677,FIXME: the distance module doesn't support sparse matrices!,,Yes,Yes
18678,FIXME: the distance module doesn't support sparse matrices!,,Yes,Yes
18681,FIXME: doesn't work... why?,,,Yes
18682,FIXME: the distance module doesn't support sparse matrices!,,,Yes
18683,FIXME: the distance module doesn't support sparse matrices!,,,Yes
18684,XXX: Can the residuals be of any use?,,Yes,Yes
18688,"\""\""\"" || ======================================================== || Topics extraction with Non-Negative Matrix Factorization || ======================================================== ||  || This is a proof of concept application of Non Negative Matrix || Factorization of the term frequency matrix of a corpus of documents so || as to extract an additive model of the topic structure of the corpus. ||  || The default parameters (n_samples \/ n_features \/ n_topics) should make || the example runnable in a couple of tens of seconds. You can try to || increase the dimensions of the problem be ware than the time complexity || is polynomial. ||  || Here are some sample extracted topics that look quite good: ||  || Topic #0: || god people bible israel jesus christian true moral think christians || believe don say human israeli church life children jewish ||  || Topic #1: || drive windows card drivers video scsi software pc thanks vga || graphics help disk uni dos file ide controller work ||  || Topic #2: || game team nhl games ca hockey players buffalo edu cc year play || university teams baseball columbia league player toronto ||  || Topic #3: || window manager application mit motif size display widget program || xlib windows user color event information use events x11r5 values ||  || Topic #4: || pitt gordon banks cs science pittsburgh univ computer soon disease || edu reply pain health david article medical medicine 16 || \""\""\""",,,Yes
18689,FIXME: the distance module doesn't support sparse matrices!,,Yes,Yes
18691,pure python workaround:,,No,Yes
18692,FIXME: the distance module doesn't support sparse matrices!,,,Yes
18693,XXX: should be implemented with a partial sort,,Yes,Yes
18695,check that columns sum to one,,Yes,Yes
18696,FIXME: the distance module doesn't support sparse matrices!,,,Yes
18699,"\""\""\"" || ========================================================== || Adjustment for chance in clustering performance evaluation || ========================================================== ||  || The following plots demonstrate the impact of the number of cluster and || number of samples on various clustering performance evaluation metrics. ||  || Non-adjusted measures such as the V-Measure show a dependency between || the number of clusters and the number of samples: the mean V-Measure || of random labeling increases signicantly as the number of clusters is || closer to the total number of samples used to compute the measure. ||  || Adjusted for chance measure such as ARI display some random variations || centered around a mean score of 0.0 for any number of samples and || clusters. ||  || Only adjusted measures can hence safely be used as a consensus index || to evaluate the average stability of clustering algorithms for a given || value of k on various overlapping sub-samples of the dataset. ||  || \""\""\""",,,Yes
18700,check that columns sum to one,,Yes,Yes
18701,check that columns sum to one,,Yes,Yes
18703,FIXME: this does not look correct,,,Yes
18707,end hack,,,Yes
18709,TODO DO SPARSE STUFF,,No,Yes
18710,TODO: initialize the counts after random assignement here,,,Yes
18712,TODO: implement a cython version to avoid the memory copy of the,,Yes,Yes
18715,FIXME - most of the time is spend on the stmt below.,,,Yes
18716,FIXME compute error for leaf,,,Yes
18718,FIXME free mem - maybe we should use index arrays instead of a mask,,Yes,Yes
18720,y[y == 0] = -1  ## FIXME,,,Yes
18721,TODO: implement a cython version to avoid the memory copy of the,,Yes,Yes
18722,TODO: add support for CSR input,,,Yes
18724,TODO: initialize the counts after random assignement here,,Yes,Yes
18725,TODO: implement a cython version to avoid the memory copy of the,,,Yes
18726,TODO: add support for CSR input,,No,Yes
18728,TODO: compute the variance of the data both for sparse and,,,Yes
18731,TODO: implement a cython version to avoid the memory copy of the,,,Yes
18734,TODO: compute the variance of the data both for sparse and,,No,Yes
18735,TODO: initialize the counts after random assignement here,,Yes,Yes
18736,TODO: make MiniBatchKMeans more stables using either restarts or,,Yes,Yes
18738,TODO: add support for CSR input,,No,Yes
18739,TODO: explicit dtype handling,,,Yes
18741,TODO: implement efficient variance for CSR input,,Yes,Yes
18745,TODO: explicit dtype handling,,No,Yes
18746,dense variant in mostly numpy (not as memory efficient though),,,Yes
18748,TODO: initialize the counts after random assignement here,,Yes,Yes
18749,TODO: make MiniBatchKMeans more stables using either restarts or,,,Yes
18750,TODO: implement a cython version to avoid the memory copy of the,,,Yes
18751,TODO: initialize the counts after random assignement here,,Yes,Yes
18752,TODO: implement a cython version to avoid the memory copy of the,,,Yes
18753,TODO: add support for CSR input,,,Yes
18754,TODO: explicit dtype handling,,No,Yes
18756,TODO: implement efficient variance for CSR input,,,Yes
18757,TODO: initialize the counts after random assignement here,,Yes,Yes
18758,TODO: implement a cython version to avoid the memory copy of the,,,Yes
18760,TODO: make MiniBatchKMeans more stables using either restarts or,,Yes,Yes
18761,TODO: implement a cython version to avoid the memory copy of the,,Yes,Yes
18762,TODO: add support for CSR input,,No,Yes
18763,TODO: explicit dtype handling,,No,Yes
18764,dense variant in mostly numpy (not as memory efficient though),,Yes,Yes
18765,TODO: implement efficient variance for CSR input,,,Yes
18766,TODO: make MiniBatchKMeans more stables using either restarts or,,Yes,Yes
18767,TODO: make MiniBatchKMeans more stables using either restarts or,,Yes,Yes
18768,double old capacity  FIXME this will break if too large,,,Yes
18769,XXX: need to be able to give an initial guess,,Yes,Yes
18770,XXX: verbosity,,,Yes
18771,XXX: need to store the scores in a name consistent with the,,Yes,Yes
18773,svm.NuSVC(tol=1e-6; kernel='linear');  # XXX : why no C ?,,Yes,Yes
18774,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
18775,Bonus: how much can you trust the selection of alpha?,,,Yes
18777,TODO: add support for CSR input,,No,Yes
18779,dense variant in mostly numpy (not as memory efficient though),,,Yes
18780,TODO: implement efficient variance for CSR input,,Yes,Yes
18781,TODO: once the `k_means` function works with sparse input we,,,Yes
18783,FIXME: - should use sets,,No,Yes
18784,#NAME?,,Yes,Yes
18786,TODO: add support for CSR input,,No,Yes
18788,dense variant in mostly numpy (not as memory efficient though),,,Yes
18789,TODO: once the `k_means` function works with sparse input we,,No,Yes
18790,FIXME: use a distribution,,,Yes
18791,Sphinx hack: sphinx copies generated images to the build directory,,No,Yes
18792,The following is a hack that prevents this behavior by clearing the,,,Yes
18794,Toy dataset where features correspond directly to labels.,,Yes,Yes
18796,if the results is better; keep it,,Yes,Yes
18800,if the results is better; keep it,,Yes,Yes
18802,if the results is better; keep it,,Yes,Yes
18805,if the results is better; keep it,,Yes,Yes
18806,FIXME this lacks a proper docstring,,No,Yes
18808,FIXME this lacks a proper docstring,,No,Yes
18809,if the results is better; keep it,,,Yes
18812,if the results is better; keep it,,Yes,Yes
18813,Efficient compressed storage:,,Yes,Yes
18814,disk; it is more efficient to use standard pickling,,Yes,Yes
18818,could be more memory efficient ?,,Yes,Yes
18819,if the results is better; keep it,,Yes,Yes
18821,fixme,,,Yes
18822,XXX: Not using the logger framework: need to,,,Yes
18824,FIXME this lacks a proper docstring,,No,Yes
18825,Efficient compressed storage:,,Yes,Yes
18828,if the results is better; keep it,,,Yes
18829,lambda is needed because we don't want coef_ to be evaluated right away,,,Yes
18831,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,,Yes
18833,Authors: Peter Prettenhofer <peter.prettenhofer@gmail.com> (main author),,Yes,Yes
18835,XXX The following is a stopgap measure; we need to set the dimensions,,Yes,Yes
18836,FIXME: if enough values became 0; it may be worth changing,,Yes,Yes
18839,FIXME: can use n_jobs here too,,No,Yes
18844,libsvm has the convention of returning negative values for,,,Yes
18845,XXX: must implement this in a more generic way so that it can be,,Yes,Yes
18846,XXX: must transform and use OLS to fit,,,Yes
18849,## TODO: bayesian_ridge_regression and bayesian_regression_ard,,,Yes
18850,XXX: should we refit the intercept?,,Yes,Yes
18851,XXX,,Yes,Yes
18854,if the results is better; keep it,,,Yes
18857,XXX: is this really useful: we are fitting models that we won't,,No,Yes
18858,XXX: need to store the whole path later,,Yes,Yes
18859,"\""\""\""Build a sentiment analysis \/ polarity model ||  || Sentiment analysis can be casted as a binary text classification problem; || that is fitting a linear classifier on features extracted from the text || of the user messages so as to guess wether the opinion of the author is || positive or negative. ||  || In this examples we will use a movie review dataset. ||  || \""\""\""",,,Yes
18860,Refit the best parameter set on the complete training set,,No,Yes
18862,generalized cross-validation (efficient leave-one-out;,,Yes,Yes
18863,check that efficient and SVD efficient LOO give same results,,,Yes
18864,FIXME non-uniform sample weights not yet supported,,,Yes
18865,I - L has eigenvalues between -1 and 1.  ARPACK is most efficient,,Yes,Yes
18866,FIXME non-uniform sample weights not yet supported,,Yes,Yes
18867,generalized cross-validation (efficient leave-one-out;,,,Yes
18869,unfortunately python functools package does not have an efficient,,Yes,Yes
18870,XXX: broken,,Yes,Yes
18871,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
18872,unfortunately python functools package does not have an efficient,,Yes,Yes
18873,unfortunately python functools package does not have an efficient,,Yes,Yes
18875,unfortunately python functools package does not have an efficient,,,Yes
18876,unfortunately python functools package does not have an efficient,,Yes,Yes
18877,# FIXME store classes in ``tree``?,,Yes,Yes
18878,# FIXME store classes in ``tree``?,,Yes,Yes
18879,# FIXME this will kill my laptop due to memory consumption,,Yes,Yes
18880,# FIXME,,,Yes
18881,FIXME ``tree.predict`` is faster than taking `tree.terminal_region``,,Yes,Yes
18883,TODO replace with ``np.choice`` if possible.,,,Yes
18884,avoid this ugly slicing by using a two-dim dataset,,Yes,Yes
18886,XXX: Why such a large tolerance?,,Yes,Yes
18888,TODO this might not properly close the files on other Python,,Yes,Yes
18892,TODO check that it actually does something useful,,Yes,Yes
18893,check if backport is actually needed:,,No,Yes
18895,XXX This should be refactored; we're getting an array of indices,,,Yes
18898,XXX FIXME: should we use proximities or similarities ??,,,Yes
18900,TODO,,Yes,Yes
18901,XXX remove closing when Python 2.7+\/3.1+ required,,Yes,Yes
18902,This may not be needed provided classes labels are guaranteed to be,,Yes,Yes
18903,TODO: add keyword copy to copy on demand,,Yes,Yes
18908,TODO this is not a regressor!,,Yes,Yes
18913,XXX we have to update this to support Python 3.x,,Yes,Yes
18914,XXX: use lapack\/blas routines for dot,,,Yes
18915,XXX: above comment is from scipy; but I (@vene)'ll take a look,,Yes,Yes
18916,TODO: fix ridge decision threshold,,Yes,Yes
18917,TODO: find out why,,Yes,Yes
18919,XXX: There is a bug when precompute is not None!,,Yes,Yes
18920,XXX : in the sparse case the data will be centered,,,Yes
18921,better ideas?,,Yes,Yes
18922,XXX : could be moved to the linear_model module,,,Yes
18924,XXX: use lapack\/blas routines for dot,,Yes,Yes
18925,XXX: above comment is from scipy; but I (@vene)'ll take a look,,,Yes
18927,To getter a better understanding of interaction of the dimensions,,,Yes
18929,Maybe the n_features checking can be moved to LinearModel.,,,Yes
18930,XXX refactor the indices -> mask -> indices -> mask thing,,Yes,Yes
18932,"best thing: typecode \""i\"" (int). However; if that gives larger or",,Yes,Yes
18935,but maybe some original features where good?,,Yes,Yes
18936,"\""\""\"" || ================================================= || Concatenating multiple feature extraction methods || ================================================= ||  || In many real-world examples; there are many ways to extract features from a || dataset. Often it is benefitial to combine several methods to obtain good || performance. This example shows how to use ``FeatureStacker`` to combine || features obtained by PCA and univariate selection. ||  || Combining features using this transformer has the benefit that it allows || cross validation and grid searches over the whole process. ||  || The combination used in this example is not particularly helpful on this || dataset and is only used to illustrate the usage of FeatureStacker. || \""\""\""",,Yes,Yes
18937,This dataset is way to high-dimensional. Better do PCA:,,Yes,Yes
18938,Maybe some original features where good; too?,,Yes,Yes
18946,XXX: Should we check that the matrices given is symmetric,,,Yes
18947,Apply spectral clustering (this step goes much faster if you have pyamg,,,Yes
18952,could be swapped around; creating an imperfect sorting. This,,,Yes
18953,concatenate values onto the ends of the curve.,,,Yes
18956,could be swapped around; creating an imperfect sorting. This,,,Yes
18958,Shift columns to the right.,,Yes,Yes
18959,we capture it; as it is ugly,,Yes,Yes
18960,Shift columns to the right.,,Yes,Yes
18963,eigenvalues between -1 and 1.  ARPACK is most efficient when,,Yes,Yes
18964,XXX: Should we check that the matrices given is symmetric,,Yes,Yes
18966,XXX: Should we check that the matrices given is symmetric,,Yes,Yes
18967,XXX should we just bail?,,,Yes
18969,TODO: check,,No,Yes
18970,TODO: check the Johnson Lindenstrauss embedding,,No,Yes
18971,Todo plot here eps vs n_components for a fixed value of n_samples,,Yes,Yes
18972,TODO: compute the expected value of eps and add them to the previous plot,,Yes,Yes
18975,TODO: fix me with some tolerance,,No,Yes
18977,TODO: rewrite the following nested for loops in cython,,Yes,Yes
18979,TODO: implement support for CSC here,,,Yes
18983,FIXME!,,Yes,Yes
18987,if you have a better idea of how to handle negative,,,Yes
18988,XXX: Consider using  ``scipy.integrate`` instead; or moving to,,,Yes
18993,TODO We can do this cheaper; sorted_indices copies the whole matrix.,,Yes,Yes
18996,FIXME BaseString,,No,Yes
18997,XXX we could get rid of this by renaming the new score_func.,,Yes,Yes
19001,TODO this class should fit on either p-values or scores;,,Yes,Yes
19002,FIXME!,,,Yes
19005,TODO not so easy because of multi-output,,Yes,Yes
19006,TODO some complication with -1 label,,,Yes
19007,TODO not so easy because of multi-output,,,Yes
19011,XXX max_df; min_df and max_features have no effect,,Yes,Yes
19012,XXX use a LabelBinarizer?,,,Yes
19013,also a copy; XXX do we need this?,,Yes,Yes
19018,XXX use a least-squares approximation?,,Yes,Yes
19022,A tree approach is better for small number of neighbors;,,,Yes
19023,".setName(\""columns\"")",,,Yes
19024,XXX doesn't work with y_class because RF doesn't support classes_,,Yes,Yes
19025,XXX this is ugly.,,,Yes
19027,workaround for bug in older NumPy:,,Yes,Yes
19028,XXX refactor the indices -> mask -> indices -> mask thing,,Yes,Yes
19031,".setName(\""columns\"")",,,Yes
19032,FIXME: whitespace tokenizing does not work on chinese and japanese,,Yes,Yes
19033,"\""\""\""Build a sentiment analysis \/ polarity model ||  || Sentiment analysis can be casted as a binary text classification problem; || that is fitting a linear classifier on features extracted from the text || of the user messages so as to guess wether the opinion of the author is || positive or negative. ||  || In this examples we will use a movie review dataset. ||  || \""\""\""",,No,Yes
19036,Refit the best parameter set on the complete training set,,,Yes
19037,unused_docs = [],,,Yes
19041,XXX: is there a way to duck-type this condition?,,Yes,Yes
19043,A raw namedtuple is very memory efficient as it packs the attributes,,Yes,Yes
19045,Make a dataset with a lot of noise to get various kind of prediction,,,Yes
19047,Since subclasses must implement either iter_test_masks or,,,Yes
19048,XXX newer versions of SciPy have scipy.sparse.rand for this.,,,Yes
19051,Hack to detect whether we are running by the sphinx builder,,,Yes
19056,For minkowski distance; use more efficient methods where available,,,Yes
19057,A tree approach is better for small number of neighbors;,,,Yes
19060,TODO: create a density estimation base class?,,,Yes
19062,XXX use a least-squares approximation?,,Yes,Yes
19063,For minkowski distance; use more efficient methods where available,,Yes,Yes
19064,A tree approach is better for small number of neighbors;,,Yes,Yes
19067,Author: Gilles Louppe; Peter Prettenhofer; Brian Holt; Noel Dawe; Satrajit Gosh,,,Yes
19071,Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,,Yes,Yes
19072,We can't have more than one value on y_type => The set is no more needed,,Yes,Yes
19073,"\""\""\"" || ========================================================= || Pipelining: chaining a RBM and a logistic regression || ========================================================= ||  || The RestrictedBolzmannMachine does unsupervised feature extraction; || while the logistic regression does the prediction. ||  || We use a GridSearchCV to set the number of hidden units and the learning rate || of the RestrictedBolzmannMachine. ||  || We also train a simple logistic regression for comparison. The example shows || that the features extracted by the RestrictedBolzmannMachine help improve || the classification accuracy. ||  || Note || ---- ||  || Much better performance can be achieved by using larger n_components and n_iter || for the RestrictedBolzmannMachine. ||  || \""\""\""",,,Yes
19074,More component tend to give better prediction performance; but larger,,,Yes
19078,"\""\""\"" || ====================================================== || Imputing missing values before building an estimator || ====================================================== ||  || This example shows that imputing the missing values can give better results || than discarding the samples containing any missing value. ||  || Missing value can be replaced by the mean; the median or the most frequent || value using the `strategy` hyper-parameter. ||  || Script output: ||  ||   Score with the entire dataset = 0.556914670698 ||   Score without the samples containing missing values = 0.520166053514 ||   Score after imputation of the missing values = 0.532282005499 ||  || \""\""\""",,Yes,Yes
19081,To be able access the elements by columns,,,Yes
19083,Create a matrix X with columns,,No,Yes
19084,Create the columns,,,Yes
19086,Ugly; but handle case with a pos_label,,,Yes
19087,Look for the starred columns,,Yes,Yes
19090,If there are more rows than columns; then the algorithm,,,Yes
19091,transpose the cost function when needed. Just have to,,,Yes
19093,We need to swap the columns because we originally,,Yes,Yes
19095,XXX : rename precompute_gram to precompute for consistency,,Yes,Yes
19098,are not an error at this point. These columns will,,,Yes
19099,To be able access the elements by columns,,No,Yes
19101,Create a matrix X with columns,,No,Yes
19102,Create the columns,,,Yes
19103,Mean doesn't support columns containing NaNs; median does,,Yes,Yes
19104,will change with every new kernel instance. This hack,,,Yes
19105,TODO some complication with -1 label,,No,Yes
19107,FIXME: the following snippet does not yield the same results on 32 bits,,No,Yes
19108,Partial fit on very small mini-batches can cause some columns,,Yes,Yes
19111,Hack to detect whether we are running by the sphinx builder,,Yes,Yes
19115,FIXME: can use pairwise_distances_argmin when ready.,,No,Yes
19117,XXX: should silence the SparseEfficiencyWarning,,Yes,Yes
19118,XXX: should retrieve the fixed indices; to complete the,,Yes,Yes
19120,XXX: we probably don't need a LIL anymore; but a CSR would do,,Yes,Yes
19121,XXX: pruning doesn't happen right,,,Yes
19122,XXX: should silence the SparseEfficiencyWarning,,Yes,Yes
19123,XXX: should retrieve the fixed indices; to complete the,,Yes,Yes
19124,XXX: we probably don't need a LIL anymore; but a CSR would do,,Yes,Yes
19125,XXX: would be faster to maitain a table of heads,,,Yes
19126,return numpy array for efficient caching,,Yes,Yes
19132,XXX: distance should be plugable,,,Yes
19134,FIXME check affinity exists.,,,Yes
19136,XXX: should retrieve the fixed indices; to complete the,,,Yes
19137,XXX: we probably don't need a LIL anymore; but a CSR would do,,Yes,Yes
19138,XXX: pruning doesn't happen right,,,Yes
19139,XXX: should silence the SparseEfficiencyWarning,,Yes,Yes
19140,XXX: should retrieve the fixed indices; to complete the,,,Yes
19141,XXX: we probably don't need a LIL anymore; but a CSR would do,,,Yes
19142,XXX: would be faster to maitain a table of heads,,Yes,Yes
19146,XXX: fishy stuff with COO\/LIL,,,Yes
19147,XXX: the above line does a copy anyhow; so we need to remove the,,Yes,Yes
19151,FIXME check affinity exists.,,,Yes
19152,XXX: if affinity is precomputed or callable; the following will,,No,Yes
19160,Shuffling the data artificially breaks the dependency and hides the,,Yes,Yes
19161,fix up negative zeros,,,Yes
19162,auto examples gallery to the _build folder. This works fine as is; but it would be cleaner to,,Yes,Yes
19163,Hack to detect whether we are running by the sphinx builder,,Yes,Yes
19169,In order to improve the overall metric testing; it is a good idea to write,,Yes,Yes
19170,Two type of datastructures are used in order to implement this system:,,Yes,Yes
19171,XXX it would be nice to have a keyword-only n_jobs argument to this function;,,,Yes
19176,Memory has been copied; the pool filesystem folder is unused,,Yes,Yes
19178,HACK as long as boolean indices are allowed in cv generators,,Yes,Yes
19180,Check fix point,,,Yes
19181,TODO replace with grid_search.fit_grid_point(),,No,Yes
19182,TODO why is this necessary?,,Yes,Yes
19184,XXX: Can we do without completing the matrix?,,Yes,Yes
19186,FIXME We compute all the distances; while we could have only computed,,Yes,Yes
19187,XXX: can we avoid switching to lil,,Yes,Yes
19189,FIXME check affinity exists.,,No,Yes
19190,"\""\""\"" || Agglomerative clustering with and without structure || =================================================== ||  || This example shows the effect of imposing a connectivity graph to capture || local structure in the data. The graph is simply the graph of 20 nearest || neighbors. ||  || Two consequences of imposing a connectivity can be seen. First clustering || with a connectivity matrix is much faster. ||  || Second; when using a connectivity matrix; average and complete linkage are || unstable and tend to create a few clusters that grow very quickly. Indeed; || average and complete linkage fight this percolation behavior by considering all || the distances between two clusters when merging them. The connectivity || graph breaks this mechanism. This effect is more pronounced for very || sparse graphs (try decreasing the number of neighbors in || kneighbors_graph) and with complete linkage. In particular; having a very || small number of neighbors in the graph; imposes a geometry that is || close to that of single linkage; which is well known to have this || percolation instability. || \""\""\""",,,Yes
19193,Hacky way of getting predict_proba to raise an AttributeError when,,,Yes
19194,XXX should have random_state_!,,Yes,Yes
19195,XXX: currently scaled to variance=n_samples to match center_data,,Yes,Yes
19196,XXX: currently scaled to variance=n_samples,,,Yes
19200,Only needed to check Python version,,,Yes
19204,matter of replacing repr() above by something smarter.,,,Yes
19205,"\""\""\"" || =================================== || t-SNE Visualization of Iris Dataset || =================================== ||  || TODO || \""\""\""",,Yes,Yes
19206,"\""A less obvious way to improve the optimization; which we call",,Yes,Yes
19208,"\""\""\"" || ===================================== || t-SNE Visualization of Digits Dataset || ===================================== ||  || TODO || \""\""\""",,,Yes
19210,sort classes and reorder columns,,No,Yes
19213,XXX should have random_state_!,,Yes,Yes
19216,FIXME: try to isolate a minimalistic reproduction case only depending,,,Yes
19217,FIXME: try to isolate a minimalistic reproduction case only depending,,,Yes
19219,FIXME: try to isolate a minimalistic reproduction case only depending,,Yes,Yes
19220,the problem as a better starting point. This should also converge,,Yes,Yes
19226,XXX: This should be moved out to a function,,,Yes
19227,XXX: Should this use inspect.formatargvalues\/formatargspec?,,,Yes
19228,XXX This should be refactored; we're getting an array of indices,,,Yes
19229,XXX Why? The behavior when passing a list is undocumented;,,Yes,Yes
19230,FIXME: try to isolate a minimalistic reproduction case only depending,,,Yes
19231,XXX: some transformers are transforming the input,,,Yes
19233,to avoid instant reassignment. This is a pretty dirty hack as it,,,Yes
19234,objects; as it ends up being too fragile,,No,Yes
19236,XXX: Not using logging framework,,Yes,Yes
19237,XXX: This should be moved out to a function,,Yes,Yes
19238,XXX: Should this use inspect.formatargvalues\/formatargspec?,,Yes,Yes
19239,XXX Workaround that will be removed when list of list format is dropped,,No,Yes
19240,ugly hack to make iloc work.,,,Yes
19241,FIXME: try to isolate a minimalistic reproduction case only depending,,,Yes
19242,TODO some complication with -1 label,,,Yes
19243,TODO: find out why PLS and CCA fail. RANSAC is random,,,Yes
19244,FIXME,,,Yes
19245,"\""\""\""Utilities to evaluate the predictive performance of models ||  || Functions named as ``*_score`` return a scalar value to maximize: the higher || the better ||  || Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize: || the lower the better || \""\""\""",,Yes,Yes
19247,"\""\""\""Utilities to evaluate the predictive performance of models ||  || Functions named as ``*_score`` return a scalar value to maximize: the higher || the better ||  || Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize: || the lower the better || \""\""\""",,Yes,Yes
19248,TODO: multi-class hinge-loss,,,Yes
19249,"\""\""\""Utilities to evaluate the predictive performance of models in regression ||  || Functions named as ``*_score`` return a scalar value to maximize: the higher || the better ||  || Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize: || the lower the better || \""\""\""",,Yes,Yes
19250,XXX: do we really want a special API for the binary case?,,,Yes
19251,could be swapped around; creating an imperfect sorting. This,,,Yes
19253,In order to improve the overall metric testing; it is a good idea to write,,Yes,Yes
19256,TODO those metrics doesn't support string label yet,,,Yes
19257,XXX cruel hack to work with partial functions,,Yes,Yes
19259,scores really should be unequal.,,Yes,Yes
19260,"\""\""\""Utilities to evaluate the predictive performance of models ||  || Functions named as ``*_score`` return a scalar value to maximize: the higher || the better ||  || Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize: || the lower the better || \""\""\""",,,Yes
19265,XXX: how to do this with sparse matrices?,,Yes,Yes
19266,XXX: I am not sure that this last line of the Hessian is right,,,Yes
19267,XXX: we should check a few simple properties of our problem; such,,,Yes
19269,XXX: Is this right?,,,Yes
19274,XXX Remove ^^^,,,Yes
19276,XXX remove zeros,,No,Yes
19277,XXX select non zeros,,No,Yes
19279,XXX Validate: p and a have the same length,,No,Yes
19281,XXX np.asarray()?,,,Yes
19282,XXX use a LabelBinarizer?,,,Yes
19286,seen will be unused,,Yes,Yes
19290,XXX use a LabelBinarizer?,,No,Yes
19292,unused,,No,Yes
19294,"best thing: typecode \""i\"" (int). However; if that gives larger or",,,Yes
19297,columns of u; rows of v,,,Yes
19300,unused,,No,Yes
19301,XXX: Update other averaging methods according to the metrics.,,,Yes
19302,XXX: Handle multi_class metrics that has a labels argument as well as a,,,Yes
19303,"\""\""\"" || ============================================= || Feature Union with Heterogeneous Data Sources || ============================================= ||  || Datasets can often contain components of that require different feature || extraction and processing pipelines.  This scenario might occur when: ||  || 1. Your dataset consists of heterogeneous data types (e.g. raster images and ||    text captions) || 2. Your dataset is stored in a Pandas DataFrame and different columns ||    require different processing pipelines. ||  || This example demonstrates how to use || :class:`sklearn.feature_extraction.FeatureUnion` on a dataset containing || different types of features.  We use the 20-newsgroups dataset and compute || standard bag-of-words features for the subject line and body in separate || pipelines as well as ad hoc features on the body. We combine them (with || weights) using a FeatureUnion and finally train a classifier on the combined || set of features. ||  || The choice of features is not particularly helpful; but serves to illustrate || the technique. || \""\""\""",,,Yes
19304,Backport fix for scikit-learn\/scikit-learn#2986 \/ scipy\/scipy#4142,,,Yes
19307,but perhaps reordered,,,Yes
19309,TODO: support equal priors (should probably be the default),,Yes,Yes
19310,"\""\""\"" || Created on Wed Sep 24 10:18:50 2014 ||  || @author: clemens || \""\""\""",,Yes,Yes
19312,XXX: would be great to vectorize or parallelise this:,,,Yes
19313,XXX: Address scipy issue 4304 by adding a tiny value to,,,Yes
19314,needed since _fit_X[np.array([])] doesn't work if _fit_X sparse,,Yes,Yes
19315,XXX: not sure whether this is being calculated correctly wrt,,,Yes
19317,FIXME!,,,Yes
19318,FIXME these should be done also for non-mixin estimators!,,No,Yes
19321,FIXME these should be done also for non-mixin estimators!,,No,Yes
19323,FIXME To be removed in 0.18,,Yes,Yes
19325,Create a subplot with 1 row and 2 columns,,,Yes
19327,XXX: Check if overwrite_a=True is ok when copy is False,,,Yes
19329,XXX: Other solvers than lsqr give different results for Ridge,,Yes,Yes
19330,XXX: we are only equal within the first two decimals,,Yes,Yes
19332,The tolist() is needed for NumPy 1.6.,,Yes,Yes
19334,FIXME,,Yes,Yes
19336,XXX: isotonic regression cannot deal correctly with,,,Yes
19337,XXX : for some reason all probas can be 0,,,Yes
19338,but should improve in both cases,,,Yes
19342,FIXME Remove case insensitivity in 0.18 ---------------------,,Yes,Yes
19343,FIXME loss_l --> loss in 0.18,,Yes,Yes
19345,FIXME remove in 1.0,,Yes,Yes
19354,concerned feature is efficient; for instance by its mean or,,,Yes
19357,FIXME what's with the if?,,,Yes
19358,FIXME CCA; PLS is not robust to rank 1 effects,,,Yes
19359,FIXME CCA; PLS is not robust to rank 1 effects,,,Yes
19361,Hard-coded solution from R glasso package for alpha=0.01,,Yes,Yes
19362,FIXME!,,,Yes
19363,TODO some complication with -1 label,,,Yes
19367,@FIXME change in 0.18,,Yes,Yes
19368,FIXME,,Yes,Yes
19370,concerned feature is efficient; for instance by its mean or,,Yes,Yes
19371,`loss` is unused. Refactoring to avoid computing it does not,,,Yes
19372,concerned feature is efficient; for instance by its mean or,,,Yes
19373,FIXME To be removed in 0.18,,Yes,Yes
19374,FIXME To be removed in 0.18,,Yes,Yes
19375,FIXME Remove gamma=0.0 support in 0.18,,,Yes
19377,(although it would only affect performance if average='macro'\/None),,Yes,Yes
19379,FIXME To be removed in 0.18,,,Yes
19381,XXX: could memoize information used here,,,Yes
19382,workaround is to view the array as bytes before,,,Yes
19389,HACK: precomputed is always allowed; never called,,No,Yes
19391,FIXME To be removed in 0.18,,Yes,Yes
19392,XXX: modifies X's internals in-place,,Yes,Yes
19393,check which type of Sequential Dataset is needed,,Yes,Yes
19395,SAG needs X and y columns to be C-contiguous and np.float64,,Yes,Yes
19397,XXX : can do better to avoid precision overflows,,,Yes
19399,TODO: Remove this check when liblinear is patched to support,,No,Yes
19400,The circular doubly linked list starts and ends with a sentinel element.,,No,Yes
19401,TODO: a version of this algorithm has been incorporated in SciPy; use that,,,Yes
19403,TODO: Should verbose argument be passed to this?,,,Yes
19407,XXX: enforce element-wise comparison to None,,Yes,Yes
19410,XXX: Assert that y is binary and labels are {0; 1},,,Yes
19411,XXX,,,Yes
19413,XXX: more complex convergence criterion,,No,Yes
19414,XXX: quite hacky; works only for current kernels,,,Yes
19417,XXX: Get rid of the np.diag() in the next line,,Yes,Yes
19419,XXX: Check why only 2 digits,,,Yes
19420,XXX,,,Yes
19421,XXX,,Yes,Yes
19422,XXX: std per dim?,,Yes,Yes
19423,avoid this ugly slicing by using a two-dim dataset,,Yes,Yes
19424,A raw namedtuple is very memory efficient as it packs the attributes,,Yes,Yes
19425,FIXME: we should probably reset __new__ for full generality,,,Yes
19429,FIXME remove (self.gamma == 0) in 0.18,,,Yes
19430,FIXME loss.lower() --> loss in 0.18,,Yes,Yes
19435,There is a different convention for l here,,No,Yes
19436,"\""\""\"" || ================================================ || Varying regularization in Multi-layer Perceptron || ================================================ ||  || A comparison of different regularization term 'alpha' values on synthetic || datasets. The plot shows that different alphas yield different decision || functions. ||  || Alpha is a regularization term; or also known as penalty term; that combats || overfitting by constraining the weights' size. Increasing alpha may fix high || variance (a sign of overfitting) by encouraging smaller weights; resulting || in a decision function plot that may appear with lesser curvatures. || Similarly; decreasing alpha may fix high bias (a sign of underfitting) by || encouraging larger weights; potentially resulting in more curvatures in the || decision function plot. ||  || \""\""\""",,,Yes
19437,"\""\""\"" || ===================================== || Visualization of MLP weights on MNIST || ===================================== ||  || Sometimes looking at the learned coefficients of a neural network can provide || inside into the learning behavior. For example if weights look unstructured; || maybe a weight was not used at all; or if very large coefficients exist; maybe || regularization was too low or the learning rate too high. ||  || This example shows how to plot some of the first layer weights in a || MLPClassifier trained on the MNIST dataset. ||  || The input data consists of 28x28 pixel handwritten digits; leading to 784 || features in the dataset. Therefore the first layer weight have the shape (784; || hidden_layer_sizes[0]).  We can therefore visualize a single column of the || weight matrix as a 28x28 pixel image. ||  || To make the example run faster; we use very few hidden units; and train only || for a very short time. Training longer would result in much smoother weights. || \""\""\""",,Yes,Yes
19440,efficient.,,Yes,Yes
19441,XXX: could memoize information used here,,Yes,Yes
19442,A raw namedtuple is very memory efficient as it packs the attributes,,Yes,Yes
19445,XXX This is copied from BaseEstimator's get_params,,Yes,Yes
19446,TODO Import from sklearn.exceptions once merged.,,Yes,Yes
19449,The digits samples are dependent: they are apparently grouped by authors,,No,Yes
19450,Shuffling the data artificially breaks the dependency and hides the,,Yes,Yes
19451,Check if split works correctly,,,Yes
19453,XXX: use 2D array; since 1D X is being detected as a single sample in,,No,Yes
19454,XXX bug when compress!=0:,,Yes,Yes
19457,Cythonize if needed,,Yes,Yes
19461,Needed on Windows because plot_partial_dependence uses multiprocessing,,No,Yes
19464,The next line set the .args correctly. This is needed to,,No,Yes
19465,"\""\""\"" || ============================================================== || Plot Ridge coefficients as a function of the L2 regularization || ============================================================== ||  || .. currentmodule:: sklearn.linear_model ||  || :class:`Ridge` Regression is the estimator used in this example. || Each color in the left plot represents one different dimension of the || coefficient vector; and this is displayed as a function of the || regularization parameter. The right plot shows how exact the solution || is. This example illustrates how a well defined solution is || found by Ridge regression and how regularization affects the || coefficients and their values. The plot on the right shows how || the difference of the coefficients from the estimator changes || as a function of regularization. ||  || In this example the dependent variable Y is set as a function || of the input features: y = X*w + c. The coefficient vector w is || randomly sampled from a normal distribution; whereas the bias term c is || set to a constant. ||  || As alpha tends toward zero the coefficients found by Ridge || regression stabilize towards the randomly sampled vector w. || For big alpha (strong regularisation) the coefficients || are smaller (eventually converging at 0) leading to a || simpler and biased solution. || These dependencies can be observed on the left plot. ||  || The right plot shows the mean squared error between the || coefficients found by the model and the chosen vector w. || Less regularised models retrieve the exact || coefficients (error is equal to 0); stronger regularised || models increase the error. ||  || Please note that in this example the data is non-noisy; hence || it is possible to extract the exact coefficients. || \""\""\""",,,Yes
19466,"\""\""\"" || =========================================== || Comparison of F-test and mutual information || =========================================== ||  || This example illustrates the differences between univariate F-test statistics || and mutual information. ||  || We consider 3 features x_1; x_2; x_3 distributed uniformly over [0; 1]; the || target depends on them as follows: ||  || y = x_1 + sin(6 * pi * x_2) + 0.1 * N(0; 1); that is the third features is completely irrelevant. ||  || The code below plots the dependency of y against individual x_i and normalized || values of univariate F-tests statistics and mutual information. ||  || As F-test captures only linear dependency; it rates x_1 as the most || discriminative feature. On the other hand; mutual information can capture any || kind of dependency between variables and it rates x_2 as the most || discriminative feature; which probably agrees better with our intuitive || perception for this example. Both methods correctly marks x_3 as irrelevant. || \""\""\""",,Yes,Yes
19467,We should retrieve the same component mask by starting by both ends,,No,Yes
19468,as apparently there is way to reliably get the target of a PR with circle,,Yes,Yes
19469,work-around for pearson divide warnings in scipy <= 0.17.0,,Yes,Yes
19470,work-around for pearson divide warnings in scipy <= 0.17.0,,Yes,Yes
19474,XXX remove in 0.19 when r2_score default for multioutput changes,,,Yes
19475,CHECK IF BACKPORT IS ACTUALLY NEEDED,,,Yes
19476,XXX This can be slow!,,Yes,Yes
19481,BZ2File doesn't implement the file object context manager in python 2,,Yes,Yes
19482,"Workaround  occasional \""[Error 5] Access is denied\"" issue",,Yes,Yes
19483,Unused feature should evaluate to NaN,,,Yes
19487,The following is a hack that prevents this behavior by clearing the,,,Yes
19488,it should probably not cause a crash).  Tested successfully,,,Yes
19491,XXX: Should this be fixed?,,,Yes
19492,workaround since _set_intercept will cast self.coef_ into float64,,,Yes
19493,we validate in construction (despite scikit-learn convention),,,Yes
19497,XXX deprecation_msg property again and make __call__ abstract again,,Yes,Yes
19500,detect constant columns,,,Yes
19501,Note that by centering; the other columns are orthogonal to that one,,Yes,Yes
19504,as bigger is better:,,,Yes
19508,fast and memory efficient computation of np.sum(np.dot(W; H)),,Yes,Yes
19510,values justified in the paper (alpha is renamed gamma),,Yes,Yes
19515,"\""\""\"" || ===================================================== || Multiclass sparse logisitic regression on newgroups20 || ===================================================== ||  || Comparison of multinomial logistic L1 vs one-versus-rest L1 logistic regression || to classify documents from the newgroups20 dataset. Multinomial logistic || regression yields more accurate results and is faster to train on the larger || scale dataset. ||  || Here we use the l1 sparsity that trims the weights of not informative || features to zero. This is good if the goal is to extract the strongly || discriminative vocabulary of each class. If the goal is to get the best || predictive accuracy; it is better to use the non sparsity-inducing l2 penalty || instead. ||  || A more traditional (and possibly better) way to predict on a sparse subset of || input features would be to use univariate feature selection followed by a || traditional (l2-penalised) logistic regression model. || \""\""\""",,Yes,Yes
19516,Use Bunch object to improve autocomplete,,,Yes
19519,TODO: rng should be seeded once we drop support for older versions of,,Yes,Yes
19520,of a constant feature and binary feature; the bounds are properly mapped.,,Yes,Yes
19521,XXX : we don't use super(LarsCV; self).__init__,,,Yes
19522,fix for issue 9037,,No,Yes
19523,XXX: Generally can use 0.89 here. On Windows; LinearSVC gets,,,Yes
19526,TODO find a way to report the number of iterations,,No,Yes
19527,fix for issue 9037,,No,Yes
19531,Work-around for indexing with read-only indices in pandas,,,Yes
19532,Require validation_score to be better (less) than at least,,,Yes
19534,to an error. This is needed because specifying a non complex,,,Yes
19535,shallow copy of steps - this should really be steps_,,,Yes
19536,Require validation_score to be better (less) than at least,,,Yes
19538,XXX GaussianProcess deprecated in 0.20,,,Yes
19542,LOF does not implement predict,,,Yes
19544,Exceptions should be raised for arrays with different num_columns,,,Yes
19545,targets; allowing better prediction even with a similar linear model as,,Yes,Yes
19546,XXX: sample_weight is not currently passed to the,,,Yes
19547,transform y and convert back to 1d array if needed,,,Yes
19551,Workaround for crash in PIL. When im is 1-bit; the call array(im),,,Yes
19552,columns show up first,,Yes,Yes
19553,"\""\""\""(Deprecated) Predefined expression of 1 or more printable words or quoted strings; separated by commas.\r ||    This expression is deprecated in favor of L{pyparsing_common.comma_separated_list}.\""\""\""",,No,Yes
19554,only compute the error when needed,,No,Yes
19555,Test feature probabilities uses pseudo-counts (alpha),,Yes,Yes
19556,Ignore the error; columns with a np.nan statistics_,,,Yes
19567,note this is probably too slow for large feature data (d > 100000),,Yes,Yes
19568,and a better way would be good.,,,Yes
19572,XXX: we use int(_num_samples...) because sometimes _num_samples,,Yes,Yes
19573,"\""\""\"" || ================================================== || Column Transformer with Heterogeneous Data Sources || ================================================== ||  || Datasets can often contain components of that require different feature || extraction and processing pipelines.  This scenario might occur when: ||  || 1. Your dataset consists of heterogeneous data types (e.g. raster images and ||    text captions) || 2. Your dataset is stored in a Pandas DataFrame and different columns ||    require different processing pipelines. ||  || This example demonstrates how to use || :class:`sklearn.compose.ColumnTransformer` on a dataset containing || different types of features.  We use the 20-newsgroups dataset and compute || standard bag-of-words features for the subject line and body in separate || pipelines as well as ad hoc features on the body. We combine them (with || weights) using a ColumnTransformer and finally train a classifier on the || combined set of features. ||  || The choice of features is not particularly helpful; but serves to illustrate || the technique. || \""\""\""",,Yes,Yes
19575,"\""\""\"" || The :mod:`sklearn.compose._column_transformer` module implements utilities || to work with heterogeneous data and to apply different transformers to || different columns. || \""\""\""",,,Yes
19576,empty list -> no need to select passthrough columns,,,Yes
19579,specify to drop remaining columns,,Yes,Yes
19581,"\""\""\"" || =================================== || Column Transformer with Mixed Types || =================================== ||  || This example illustrates how to apply different preprocessing and || feature extraction pipelines to different subsets of features; || using :class:`sklearn.compose.ColumnTransformer`. || This is particularly handy for the case of datasets that contain || heterogeneous data types; since we may want to scale the || numeric features and one-hot encode the categorical ones. ||  || In this example; the numeric data is standard-scaled after || mean-imputation; while the categorical data is one-hot || encoded after imputing missing values with a new category || (``'missing'``). ||  || Finally; the preprocessing pipeline is integrated in a || full prediction pipeline using :class:`sklearn.pipeline.Pipeline`; || together with a simple classification model. || \""\""\""",,,Yes
19584,The columns of X which are not transformed need,,Yes,Yes
19585,multiple columns,,,Yes
19586,second and third columns are doubled when remainder = DoubleTrans,,,Yes
19587,columns are doubled when remainder = DoubleTrans,,Yes,Yes
19589,TODO remove cases when corrected,,,Yes
19590,FIXME!,,,Yes
19592,TODO some complication with -1 label,,No,Yes
19594,The columns of X which are not transformed need,,,Yes
19595,FIXME: Future warning to be removed in 0.22,,,Yes
19597,To be removed once this fix is included in six,,Yes,Yes
19598,Redondant np.floating is needed because numbers can't match np.float32,,,Yes
19600,FIXME: The default number of trees was changed and is set to 'warn',,No,Yes
19603,FIXME this is an error in the error_score change!,,Yes,Yes
19605,instead of equality. This fix returns the mask of NaNs in an array of,,Yes,Yes
19606,threshold_ attribute is implicitly 0 and is not needed anymore:,,Yes,Yes
19607,XXX to be removed in 0.22.,,,Yes
19611,"\""\""\""Constructors for 3rd party libraries || Note: These can never be renamed due to client compatibility issues\""\""\""",,Yes,Yes
19612,is what gives us the ``nonlocal`` behavior in a Python 2 compatible way.,,,Yes
19613,essentially save_reduce; but workaround needed to avoid recursion,,,Yes
19614,save the rest of the func data needed by _fill_function,,Yes,Yes
19615,XXX Assert it's a sequence,,Yes,Yes
19618,"python\"" would probably leave unlinked semaphores.",,Yes,Yes
19619,needs to be cast to proper python value. Unix failure convention is to,,,Yes
19620,Multiprocessing module helpers to fix up the main module in,,,Yes
19623,Memory usage stays within bounds: everything is fine.,,,Yes
19624,XXX: results['params'] is a list :|,,Yes,Yes
19626,XXX: unnecessary decompression on first access,,Yes,Yes
19627,TODO: improve for efficiency,,Yes,Yes
19630,XXX: col_slice_y should be all nominal or all numeric,,,Yes
19633,Not usable with sparse data or datasets that have columns marked as,,,Yes
19637,XXX: Global variable,,Yes,Yes
19639,It does not ensure that the line starts with '{' or ends with '}'.,,No,Yes
19640,XXX: int 0 is used for implicit values; not '0',,Yes,Yes
19641,FIXME,,Yes,Yes
19644,XXX: Should use an exception logger,,Yes,Yes
19645,fix missing names,,Yes,Yes
19647,TODO: this warning is not very useful in this case; would be good,,,Yes
19648,a given transformer doesn't have any columns to work on,,,Yes
19651,since all columns should be numeric before stacking them,,Yes,Yes
19654,`is_ignore` flag; these can not be learned on. Also target columns are,,Yes,Yes
19656,TODO: remove once scipy < 0.17 is no longer supported and just use,,,Yes
19657,Let us use a closure to workaround this limitation.,,Yes,Yes
19660,Set categories_ to empty list if no categorical columns exist,,Yes,Yes
19661,needed to tune `scikit-learn` behavior and have different effect if called,,Yes,Yes
19662,XXX Remove in v0.22,,Yes,Yes
19663,XXX remove in v0.22,,,Yes
19664,better results than just l1 or just l2.,,No,Yes
19668,FIXME: Future warning to be removed in 0.23,,,Yes
19669,FIXME: Future warning to be removed in 0.23,,Yes,Yes
19670,better results than just l1 or just l2.,,,Yes
19672,needed for _dispatch[tuple.__repr__] not to be overridden,,Yes,Yes
19673,GH12881 bug in combination of categorical_features with ignore,,Yes,Yes
19674,"\""\""\"" || ================================================= || Imputing missing values using multiple imputation || ================================================= ||  || By default; the IterativeImputer performs single imputation: a method where || every missing value is replaced with one imputed value. The chained character || of the method and the possiblity to draw imputation values from the posterior || distribution of a Bayesian imputation model allows for the finding of unbiased || statistical estimates. However; the disadvantage is that every imputed value is || treated as if the value was observed; leading to an imputed dataset that does || not reflect the uncertainty that occurs due to the presence of missing values. || This makes it hard to find valid statistical inferences because the variance || (and standard error) of statistical estimates become too small. ||  || An alternative is using the IterativeImputer to perform multiple imputation: a || method where every missing value is imputed multiple times. The procedure || results in multiple datasets where the observed data is similar in every || dataset; but the imputed data is different. All desired steps after imputation || are performed on every dataset; such as standardization and other feature || engineering steps. The estimation model is also fitted on each of the datasets. ||  || One final model is obtained by combining the estimates of each model with || Rubin's pooling rules. These rules assume that the parameters of interest are || normally distributed which is the case with; for example; estimates of the mean || and regression coefficients. Other parameters; such as correlation || coefficients need transformation to suit the assumption of normality. || If it is not possible to approximate a normal distribution; it is better to use || robust summary measures such as medians or ranges instead of using Rubin's || pooling rules. This applies to an estimate like explained variance. ||  || In sum; Rubin's pooling rules are as follows. The overall point estimate after || multiple imputation (denoted by Qbar) is the average of all the m point || estimates. The variance of the overall point estimate is a combination of || so-called within imputation variance (Ubar) and between imputation || variance (B). Ubar is the average of the m variances of the m point estimates. || Both Qbar and Ubar are corrected with a factor 1 \/ m to account for sampling || variance. The between imputation variance (B) is the sum of the squared || difference between Qbar and the m point estimates; corrected with a factor || 1 \/ (m \u2013 1). Then; the total variance (T) of the MI overall point estimate is || Ubar + B + B\/m. ||  || In this document we will show how to use the IterativeImputer to perform || multiple imputation. In example 1 we show the effect of Rubin\u2019s pooling || rules on the variance of regression estimates. Due to the between imputation || variance; the standard errors of all regression coefficients are larger with || multiple imputation than with single imputation. This allows for valid || statistical inference making. ||  || In example 2 we show how to set up a prediction model using multiple || imputation. We compare two approaches. In one approach; we make predictions for || each of the m datasets and combine the m evaluation error metrics into one || overall value. In the other approach; we combine the predictions and calculate || one evaluation error metric over the averaged predictions. A short simulation || study shows that the second approach results in the smallest Mean Squared || Error. || \""\""\""",,Yes,Yes
19675,note this is probably too slow for large feature data (d > 100000),,Yes,Yes
19676,and a better way would be good.,,Yes,Yes
19677,note this is probably too slow for large feature data (d > 100000),,Yes,Yes
19678,and a better way would be good.,,Yes,Yes
19679,FIXME Remove once #10440 is merged,,No,Yes
19681,FIXME,,Yes,Yes
19683,If we have both dropped columns and ignored unknown,,Yes,Yes
19684,take care of potential over-subcription performance issues; in sections of,,,Yes
19687,Initialize a fake NCA and variables needed to compute the loss:,,No,Yes
19690,TODO: replace by copy=False; when only scipy > 1.1 is supported.,,,Yes
19691,TODO: handle working_memory somehow?,,,Yes
19693,implement the method to compute the probability given in The Elements,,No,Yes
19698,But choose to perform that LATER when needed; in `fit()` and in,,Yes,Yes
19700,If classification methods produce multiple columns of output;,,No,Yes
19701,binary indicator columns. The output of predict_proba,,Yes,Yes
19702,that's why we're looking at the last 4 columns only.,,,Yes
19704,apprx number of chars to keep on both ends,,No,Yes
19706,Needed on Windows because plot_partial_dependence uses multiprocessing,,No,Yes
19708,needed) and compute r_squared to check that the partial dependence,,No,Yes
19709,add polynomial features if needed,,Yes,Yes
19711,needed for training anyway) for evaluating the training,,,Yes
19712,TODO: not critical but stratify using resample(),,,Yes
19713,maybe we could also early stop if all the trees are stumps?,,,Yes
19715,(if needed),,,Yes
19717,Calling split next applies the next split and computes the best split,,No,Yes
19719,if X has more rows than columns; use decomposition of X^T.X;,,Yes,Yes
19720,XXX: Sparse CG seems to be far less numerically stable than the,,,Yes
19723,note this is probably too slow for large feature data (d > 100000),,,Yes
19727,TODO: do it also for other norms.,,,Yes
19728,Replace columns that are all close to zero with zeros,,,Yes
19729,(Needed for external libraries that may use nose.),,Yes,Yes
19730,FIXME: remove in 0.24,,,Yes
19731,This is needed in order to have the same split when using,,Yes,Yes
19736,TODO: extend to HistGradientBoosting once sample_weight is supported,,No,Yes
19737,TODO: REMOVE in v0.23,,Yes,Yes
19739,TODO: Revert to the following two lines in v0.23,,,Yes
19740,TODO: Revert to the following two lines in v0.23,,Yes,Yes
19743,regression dataset with numeric and categorical columns,,,Yes
19745,FIXME Remove l1\/l2 support in 0.23 ----------------------------------,,Yes,Yes
19747,This is not strictly True; but it's needed since,,,Yes
19752,Expect an accuracy of better than 1E-4 in most cases -,,Yes,Yes
19755,XXX to be removed in 0.22.,,,Yes
19757,FIXME: SAGA on sparse data fits the intercept inaccurately with the,,Yes,Yes
19760,This is not strictly True; but it's needed since,,No,Yes
19763,TODO: remove in v0.24,,,Yes
19766,If norms are passed as float32; they are unused. If arrays are passed as,,Yes,Yes
19768,FIXME Remove l1\/l2 support in 0.23 ----------------------------------,,Yes,Yes
19770,convention is that n_bins == max_bins + 1,,No,Yes
19772,2-d array where columns contain the same value across rows,,No,Yes
19774,models is also orders of magnitude faster making it cheap to compute partial,,Yes,Yes
19775,Removes columns where the training data is all nan,,,Yes
19781,TODO: remove in v0.24,,Yes,Yes
19783,TODO: remove entire file in 0.24,,Yes,Yes
19784,TODO: remove in 0.24,,Yes,Yes
19785,TODO: remove in 0.24 since this shouldn't be needed anymore.,,Yes,Yes
19786,TODO: remove in 0.24,,Yes,Yes
19790,XXX After removing the deprecated scorers (v0.24) remove the,,,Yes
19792,Workaround issue discovered in intel-openmp 2019.5:,,,Yes
19795,TODO: remove in 0.24,,Yes,Yes
19799,TODO: Remove in 0.24,,,Yes
19801,TODO: remove in 0.24,,Yes,Yes
19802,TODO: Remove in 0.24 when None is removed,,Yes,Yes
19804,TODO: Remove in 0.24 when None is removed,,Yes,Yes
19805,TODO: Remove the whole file in 0.24,,Yes,Yes
19806,TODO: Remove when modules are deprecated in 0.24,,,Yes
19807,FIXME: deprecate the usage of None to drop an estimator from the,,,Yes
19809,TODO: Remove drop=None in 0.24 when None is removed in Voting*,,Yes,Yes
19811,TODO 0.24: raise a ValueError instead of a warning,,Yes,Yes
19812,TODO 0.24: raise a ValueError instead of a warning,,Yes,Yes
19815,TODO: Remove in 0.24. This class is now in utils.__init__.,,Yes,Yes
19818,FIXME: remove the None option when it will be deprecated,,Yes,Yes
19819,dependence of the right columns,,Yes,Yes
19822,TODO: remove in 0.24,,Yes,Yes
19823,TODO: remove in 0.24,,Yes,Yes
19824,TODO: remove in 0.24,,,Yes
19826,TODO: Remove in 0.24,,,Yes
19827,TODO: Remove in 0.24 when DummyClassifier's `strategy` default updates,,Yes,Yes
19828,TODO: Remove in 0.24 when DummyClassifier's `strategy` default updates,,Yes,Yes
19829,TODO: Remove in 0.24 when DummyClassifier's `strategy` default changes,,Yes,Yes
19831,to actually build the compiled extensions with OpenMP flags if needed.,,Yes,Yes
19832,TODO: Remove when https:\/\/github.com\/numpy\/numpy\/issues\/14397 is resolved,,No,Yes
19834,TODO: Remove when https:\/\/github.com\/numpy\/numpy\/issues\/14397 is resolved,,No,Yes
19838,FIXME: to be removed in 0.25,,,Yes
19840,writable data-structure whose columns can be shuffled inplace.,,Yes,Yes
19844,TODO: remove in 0.25,,Yes,Yes
19845,TODO: remove in 0.25,,Yes,Yes
19849,XXX unreached code as of v0.22,,Yes,Yes
19853,XXX unreached code as of v0.22,,Yes,Yes
19854,XXX unreached code as of v0.22,,Yes,Yes
19855,FIXME: remove in 0.25,,Yes,Yes
19858,We can observe that the `embarked` and `sex` columns were tagged as,,Yes,Yes
19861,``categorical_transformer`` and the remaining columns to the,,,Yes
19862,If you want some columns to be considered as `category`; you will have to,,,Yes
19863,convert them into categorical columns. If you are using pandas; you can,,,Yes
19864,TODO: remove when PDP suports sample weights,,,Yes
19867,TODO: remove\/fix when PDP supports HGBT with sample weights,,,Yes
19869,TODO: set reset=first_time when addressing reset in,,,Yes
19872,TODO: incorporate sample_weights here in `resample`,,,Yes
19875,The remaining columns can be used to predict the frequency of claim events.,,Yes,Yes
19876,Those columns are very heterogeneous with a mix of categorical and numeric,,,Yes
19877,were to convert this problem into a binary classification task; it would be,,,Yes
19878,a desired behavior. However this effect is limited for deep enough trees,,No,Yes
19880,Thus; among the considered estimators; ``PoissonRegressor`` is better suited,,,Yes
19882,captured in the columns of the dataset or that are indeed random.,,No,Yes
19884,TODO: if alpha=0 check that X is not rank deficient,,No,Yes
19885,TODO: make the returned object immutable,,Yes,Yes
19886,TODO: this line is never executed because _infer_dimension's,,Yes,Yes
19888,As seen previously; the dataset contains columns with different data types,,Yes,Yes
19889,columns;,,,Yes
19891,For the coefficient analysis; scaling is not needed this time.,,,Yes
19892,predictive variables; so neither alone would be very strongly weighted.,,,Yes
19893,Warning is raised only when some of the columns is sparse,,,Yes
19894,all columns but the first column is sparse,,No,Yes
19895,When all dataframe columns are sparse; convert to a sparse array,,,Yes
19896,TODO: remove this check once the estimator is no longer experimental.,,,Yes
19897,TODO: remove this check once the estimator is no longer experimental.,,Yes,Yes
19899,For Poisson distributed target; Poisson loss should give better results,,,Yes
19900,Prepare which columns and data types should be returned for the X and y,,Yes,Yes
19902,back to None if there are not target columns,,Yes,Yes
19903,TODO: Remove warn_checker in 0.25,,Yes,Yes
19905,TODO in 0.24: remove checks on passing a class,,,Yes
19908,TODO: remove this in 0.24,,Yes,Yes
19909,TODO: remove this if block in 0.24 since passing instances isn't,,Yes,Yes
19910,TODO: Always convert to class in 0.24; because check_estimator() will,,,Yes
19912,The version implemented assumes Gaussian (output) variables. If your features,,Yes,Yes
19913,to potentially improve performance.,,Yes,Yes
19914,trees would still perform relatively well and in particular better than,,,Yes
19915,FIXME: to be removed in 0.25,,,Yes
19917,TODO: remove in 0.25,,Yes,Yes
19922,To better visualize the difference; we plot contours of the,,No,Yes
19924,Use columns 0 & 2 as 1 is not quantitative (sex),,,Yes
19926,TODO 0.26: Remove kind == 'legacy' section,,,Yes
19927,FIXME: to be removed in 0.24,,,Yes
19928,TODO this check is redundant with common checks and can be removed,,,Yes
19930,TODO: Remove in v0.26,,Yes,Yes
19934,Use C++11 random number generator fix,,,Yes
19937,TODO: Remove in 0.26 when grid_scores_ is deprecated,,,Yes
19938,FIXME: init_size_ will be deprecated and this line will be removed,,No,Yes
19939,TODO Revisit deprecation of square_distances for 0.26-0.28 (#12401),,,Yes
19944,on the original data. The score is much better than those obtained by,,Yes,Yes
19946,Mark (estimator; check) pairs as XFAIL if needed (see conditions in,,No,Yes
19947,Wrap a check so that it's skipped if needed (see conditions in,,No,Yes
19948,TODO: probably not needed anymore in 0.24 since _generate_class_checks should,,Yes,Yes
19950,TODO: Always convert to class in 0.24; because check_estimator() will,,No,Yes
19955,TODO: remove in v0.24; the deprecation goes away then.,,No,Yes
19959,exactly implement the Wold algorithm since it does not normalize,,Yes,Yes
19963,Release memory used by histograms as they are no longer needed,,Yes,Yes
19964,Release memory used by histograms as they are no longer needed for,,Yes,Yes
19965,TODO: Update in 0.26 to check for the error raised,,No,Yes
19968,n_required_iterations is the number of iterations needed so that the,,,Yes
19969,iterations as needed (while candidates are being,,,Yes
19971,generate exactly as much as needed,,Yes,Yes
19972,TODO: Remove in 0.26,,Yes,Yes
19973,TODO: Remove in 0.26,,,Yes
19974,TODO: Remove in 0.26,,,Yes
19975,TODO: Remove in 0.26,,Yes,Yes
19977,TODO: Remove in 0.26,,Yes,Yes
19980,TODO: Remove in 0.26,,,Yes
19981,TODO: Remove in 0.26,,Yes,Yes
19982,TODO: Remove in 0.26,,,Yes
19984,TODO: Remove in 0.26 when the _pairwise attribute is removed,,Yes,Yes
19986,TODO: Remove in 0.26,,Yes,Yes
19987,TODO: Remove in 0.26,,,Yes
19988,TODO: Remove in 0.26,,,Yes
19990,TODO: Remove in 0.26,,Yes,Yes
19992,TODO: Remove in 0.26,,Yes,Yes
19993,TODO: Remove in 0.26,,Yes,Yes
19994,TODO: Remove when modules are deprecated in 0.24,,Yes,Yes
19996,FIXME : init should be removed in 0.26,,Yes,Yes
19999,TODO: Remove when https:\/\/github.com\/sphinx-doc\/sphinx\/pull\/8234 gets,,Yes,Yes
20000,TODO: Remove in 0.26,,Yes,Yes
20003,Note: Some fine tuning was needed to have metric_poi < metric_dummy on,,,Yes
20006,:math:`x` is the difference in performance of the models;,,No,Yes
20008,way. A naive approach [4]_ would be to define estimators as practically,,,Yes
20010,We could also be interested in comparing the performance of all our models,,Yes,Yes
20011,implement Bonferroni correction,,Yes,Yes
20014,tell us if the performance of one model is better than another with a,,Yes,Yes
20017,better score,,,Yes
20019,to recover an equivalent split that could be obtained in one single split,,,Yes
20021,TODO: Remove coef_ attribute in 0.26,,Yes,Yes
20022,TODO: Remove intercept_ attribute in 0.26,,,Yes
20027,models; but uses much less memory than,,Yes,Yes
20032,FIXME: remove in 1.0,,Yes,Yes
20033,FIXME: remove in 1.1,,Yes,Yes
20035,TODO: remove in 1.1,,,Yes
20036,TODO: remove in 1.1,,,Yes
20037,TODO: Remove in 1.1,,Yes,Yes
20038,TODO: Remove in 0.26,,Yes,Yes
20040,For PLS; TODO remove in 1.1,,Yes,Yes
20043,FIXME: 'normalize' to be removed in 1.2,,,Yes
20046,FIXME: 'normalize' to be removed in 1.2 in LinearRegression,,No,Yes
20047,TODO: Remove when https:\/\/github.com\/numpy\/numpy\/issues\/14397 is resolved,,No,Yes
20048,TODO: remove this file when plot_confusion_matrix will be deprecated in 1.2,,Yes,Yes
20049,"\""\""\"" || =================================== || Polynomial and Spline interpolation || =================================== ||  || This example demonstrates how to approximate a function with polynomials up to || degree ``degree`` by using ridge regression. We show two different ways given || ``n_samples`` of 1d points ``x_i``: ||  || - :class:`~sklearn.preprocessing.PolynomialFeatures` generates all monomials ||   up to ``degree``. This gives us the so called Vandermonde matrix with ||   ``n_samples`` rows and ``degree + 1`` columns:: ||  ||     [[1; x_0; x_0 ** 2; x_0 ** 3; ...; x_0 ** degree]; ||      [1; x_1; x_1 ** 2; x_1 ** 3; ...; x_1 ** degree]; ||      ...] ||  ||   Intuitively; this matrix can be interpreted as a matrix of pseudo features ||   (the points raised to some power). The matrix is akin to (but different from) ||   the matrix induced by a polynomial kernel. ||  || - :class:`~sklearn.preprocessing.SplineTransformer` generates B-spline basis ||   functions. A basis function of a B-spline is a piece-wise polynomial function ||   of degree ``degree`` that is non-zero only between ``degree+1`` consecutive ||   knots. Given ``n_knots`` number of knots; this results in matrix of ||   ``n_samples`` rows and ``n_knots + degree - 1`` columns:: ||  ||     [[basis_1(x_0); basis_2(x_0); ...]; ||      [basis_1(x_1); basis_2(x_1); ...]; ||      ...] ||  || This example shows that these two transformers are well suited to model || non-linear effects with a linear model; using a pipeline to add non-linear || features. Kernel methods extend this idea and can induce very high (even || infinite) dimensional feature spaces. || \""\""\""",,,Yes
20050,constant. Note that most often; you would rather increase the number of knots,,Yes,Yes
20051,columns of both transformers separately.,,,Yes
20055,FIXME: we could consider to support multiclass-multioutput if,,Yes,Yes
20057,TODO: Remove when pyamg removes the use of np.float,,Yes,Yes
20061,We observe that the search procedure identifies that deeper trees are needed,,Yes,Yes
20062,better assess the variability of those estimates.,,,Yes
20063,shifts the mean value for each columns in X further away from,,Yes,Yes
20067,TODO: Remove in 1.2,,No,Yes
20069,FIXME: remove in 1.2,,No,Yes
20071,FIXME: remove in 1.2,,,Yes
20072,TODO: Remove in 1.2,,No,Yes
20073,FIXME: remove in 1.2,,No,Yes
20074,XXX: RuntimeWarning is also raised at predict time because of divisions,,Yes,Yes
20075,regularization: should this be considered a bug? Either by the fit-time,,No,Yes
20077,knot. In the following case we show how periodic splines provide a better fit,,No,Yes
20079,TODO: Remove in v1.2,,,Yes
20080,TODO: Remove in v1.2,,No,Yes
20081,TODO: Remove in v1.2. By then it should raise an error.,,Yes,Yes
20082,"TODO: remove \""ls\"" in verion 1.2",,No,Yes
20083,TODO: Remove entry 'ls' in version 1.2.,,,Yes
20084,TODO: Remove in v1.2,,,Yes
20085,has its minimum at zero; which is needed for the newton method.,,Yes,Yes
20088,TODO: Remove in v1.2,,,Yes
20090,TODO: Remove in v1.2,,No,Yes
20091,"TODO: Remove \""mse\"" in version 1.2.",,,Yes
20096,"\""\""\"" || ===================================== || SGDOneClassSVM benchmark || ===================================== || This benchmark compares the :class:`SGDOneClassSVM` with :class:`OneClassSVM`. || The former is an online One-Class SVM implemented with a Stochastic Gradient || Descent (SGD). The latter is based on the LibSVM implementation. The || complexity of :class:`SGDOneClassSVM` is linear in the number of samples || whereas the one of :class:`OneClassSVM` is at best quadratic in the number of || samples. We here compare the performance in terms of AUC and training time on || classical anomaly detection datasets. ||  || The :class:`OneClassSVM` is applied with a Gaussian kernel and we therefore || use a kernel approximation prior to the application of :class:`SGDOneClassSVM`. || \""\""\""",,Yes,Yes
20097,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
20098,dirty str fix because sklearn is expecting,,Yes,Yes
20099,NOTE: for better parse performance; currently although,,,Yes
20100,then model will be cached; this is a kind of workaround to,,Yes,Yes
20101,BTW if refresh function is wanted; maybe add implement code to,,,Yes
20102,download model from cloud storage if needed and possible,,No,Yes
20105,if this starts failing for the default model; we should think about,,Yes,Yes
20108,TODO Ensure the input format,,Yes,Yes
20111,TODO,,,Yes
20113,(eg: a right forearm ends in a right wrist),,Yes,Yes
20118,TODO  min_sum_hessian_in_leaf,,Yes,Yes
20121,TODO dynamic selection,,,Yes
20122,TODO remove autosklearn extends,,,Yes
20123,We sum the contributions of the columns.,,,Yes
20124,TODO what about mathews correlation coefficient etc?,,No,Yes
20126,Values are dataframe columns such as ('trial_id'; '') and ('params'; 'n_layers').,,,Yes
20129,TODO Preprocess Trial,,Yes,Yes
20133,TODO decorator; add trials to pipeline.,,Yes,Yes
20134,TODO decorator; add trials to pipeline.,,,Yes
20136,As we saw before; the two missing values for embarked columns can be replaced by 'C' (Cherbourg),,,Yes
20137,We replace missing ages by the mean age of passengers who belong to the same group of class\/sex\/family,,Yes,Yes
20139,Create a Family Size; Is Alone; Child and Mother columns,,Yes,Yes
20140,Note : this implementation is ugly and unefficient; if sombody found a way to do it easily with pandas (it must be a way); please comment the kernel with your solution !,,,Yes
20141,These two columns are not useful anymore,,,Yes
20145,TODO: Fix this; it wrong,,Yes,Yes
20146,TODO: Remove this weighted thing,,Yes,Yes
20147,TODO: FIX THIS,,Yes,Yes
20148,TODO: FIX THIS TOO,,Yes,Yes
20149,will be needed as coordinates for position with pygame,,,Yes
20151,(would probably be faster with np boolean indexing),,Yes,Yes
20152,Unused,,No,Yes
20154,# TODO: error check text,,,Yes
20156,simplicity trumps functionality here; we mostly want it to be easy to use,,Yes,Yes
20157,# TODO verfify that recipients are valid here,,,Yes
20158,Fix navigation bar to top of page?,,Yes,Yes
20159,TODO: JM: remove relative imports inside these functions and move to top of file,,Yes,Yes
20160,JM: TODO: make special exception for this purpose,,,Yes
20165,AS A TEMPORARY FIX; I am cutting out descriptors past the maximum,,,Yes
20168,JM: this is stupid hack to get keyword only arguments in python2,,,Yes
20169,JM: this is stupid hack to get keyword only arguments in python2,,Yes,Yes
20170,TODO write out history,,Yes,Yes
20171,TODO make it non clickable,,,Yes
20172,TODO fix history,,Yes,Yes
20178,ND TODO: implement non-blocking runsource call,,No,Yes
20179,TODO center the text,,No,Yes
20180,This is only needed for Python v2 but is harmless for Python v3.,,Yes,Yes
20183,ND TODO: decide on programmable interface \/ items to pass here,,No,Yes
20186,TODO add builtin widgets to the tool box,,No,Yes
20187,TODO add builtin pipelines to the tool box,,No,Yes
20188,TODO add user-defined widgets to the tool box,,,Yes
20190,"TODO add \""run pipeline\"" action",,,Yes
20191,"TODO add \""save pipeline\"" action",,,Yes
20195,"TODO add \""new pipeline\"" action",,,Yes
20197,TODO add actions to toolbars,,Yes,Yes
20198,This is only needed for Python v2 but is harmless for Python v3.,,Yes,Yes
20201,TODO disallow deleting \/ backspacing the prompt,,Yes,Yes
20203,TODO figure out if slots\/signals need to be connected here,,Yes,Yes
20205,ND TODO: implement non-blocking runsource call,,No,Yes
20206,TODO: write out history,,,Yes
20207,TODO disallow deleting \/ backspacing the prompt,,Yes,Yes
20208,TODO make it non clickable,,No,Yes
20210,TODO make this robust,,Yes,Yes
20212,TODO figure this out. Should not need to be set here,,Yes,Yes
20213,TODO: add logo properly,,,Yes
20214,TODO add user cache directory settings,,Yes,Yes
20216,TODO add,,,Yes
20218,TODO: need some sort of module creator function to wrap this ability,,No,Yes
20219,TODO will need programmtic access to the pipeline \/ blocks in it,,Yes,Yes
20220,TODO figure out the opened directory and remember it,,,Yes
20222,TODO set opening directory to something useful \/ make it a setting,,Yes,Yes
20223,TODO add,,Yes,Yes
20225,turn blocks red if they need an input; maybe highlight a field?,,,Yes
20226,TODO Ryan make up a design for these items?,,Yes,Yes
20228,TODO - JM,,,Yes
20230,TODO; add function support,,Yes,Yes
20233,TODO: generate string parse here,,Yes,Yes
20235,"\""\""\"" ||  || goal is to enable this functionality ||  || 1) specify an axis length by equation ||     ArrayType(['N';'M']) : ArrayType(['N*M';'1']) ||  || 2) be able to apply a rule to an unknown number of axis ||     ArrayType(all_axis=\""5*N\"") ||  || 3) be able to pass in your own function to generate an output ||     FuncType(func) where func takes in input_type ||  || 4) add dimensional flexability ||     ArrayType(['<expr>']; error='+\/-1') ||  || 5) ||  || TODO: ||     [ ] string compiler ||     [ ] new IoMap structure ||  || \""\""\""",,,Yes
20236,TODO:,,,Yes
20237,"\""\""\"" ||  || goal is to enable this functionality ||  || 1) specify an axis length by equation ||     ArrayType(['N';'M']) : ArrayType(['N*M';'1']) ||  || 2) be able to apply a rule to an unknown number of axis ||     ArrayType(all_axis=\""5*N\"") ||  || 3) be able to pass in your own function to generate an output ||     FuncType(func) where func takes in input_type ||  || 4) add dimensional flexability ||     ArrayType(['<expr>']; error='+\/-1') ||  || 5) ||  || TODO: ||     [ ] string compiler ||     [ ] new IoMap structure ||  || \""\""\""",,No,Yes
20239,so no more comparisons are needed for this element,,,Yes
20241,TODO:,,,Yes
20245,# move the data into a wavelet plane,,Yes,Yes
20246,maybe this should be called a 'task' instead?????),,No,Yes
20248,# so no more comparisons are needed for this element,,Yes,Yes
20249,edge['data'] = task_a._pipeline_process() # no data needed,,No,Yes
20250,no inputs or outputs - currently unused,,Yes,Yes
20253,NOTE: maybe do a check to ensure shape is a list of lists?,,No,Yes
20255,TODO:,,No,Yes
20256,TODO: support multi-step ahead prediction,,No,Yes
20257,-- Options for todo extension ----------------------------------------------,,,Yes
20260,TODO: this is not memory efficient; need to do this in a,,Yes,Yes
20261,better way in the future,,Yes,Yes
20266,todo : check compatibility between predicted types? (thru key map?),,Yes,Yes
20269,XXX: there seems to be no way to detect static method call - it will,,Yes,Yes
20270,copy needed here due to ocv 3.3 bug,,,Yes
20272,not saving final eval results anywhere...? todo,,Yes,Yes
20273,valid device still ignored; todo,,,Yes
20274,override and return false if reset not needed,,No,Yes
20280,todo: dig into members and check only critical ones,,No,Yes
20284,TODO,,,Yes
20285,TODO @@@,,Yes,Yes
20288,todo: update to use meta keys?,,,Yes
20289,REALLY DIRTY HACK FOR CHECKPOINT BACKWARD COMPAT HERE; TO BE REMOVED ASAP @@@@@@,,Yes,Yes
20290,todo: add new task types (objdetecton; segmentation; regression; superres; ...),,,Yes
20291,extra name added for unlabeled samples (if needed!),,Yes,Yes
20293,todo: add flag to toggle loss comp in validation?,,Yes,Yes
20294,todo: use validation loss instead? more stable?,,Yes,Yes
20295,could add checks to see if the sample already behaves like a dict? todo,,Yes,Yes
20298,todo: add new task types (objdetecton; segmentation; regression; superres; ...),,,Yes
20299,todo: add new task types (objdetecton; segmentation; regression; superres; ...),,Yes,Yes
20300,copy needed here due to ocv 3.3 bug,,Yes,Yes
20301,todo: display predictions if available? (currently skipped),,,Yes
20302,todo: move all 'viz' miniconfig stuff to its own section in the config file?,,,Yes
20304,TODO: update w\/ task-compat structure,,Yes,Yes
20306,todo: find a more efficient way to compute loss w\/ byte vals directly?,,No,Yes
20307,TODO : gt maps are not currently transformed! (need refact w\/ dict keys),,No,Yes
20308,todo: also support reweighting w\/ other compatible tasks? (e.g. semantic segmentation),,Yes,Yes
20309,todo: add support to fraction samples that are too big for a single iteration,,,Yes
20311,loss_params[weight_param_name] = self._upload_tensor(torch.FloatTensor(weight_list); dev=self.devices) # might actually be needed?,,No,Yes
20312,for seed generation below (if needed); will be reseeded afterwards,,Yes,Yes
20313,extra name added for unlabeled samples (if needed!),,Yes,Yes
20314,copy needed here due to ocv 3.3 bug,,Yes,Yes
20315,todo: add more global opencv flags setups here,,,Yes
20317,todo: display both preds and targets below? (still only using one of the two),,No,Yes
20318,fix unsupported negative strides in PyTorch <= 0.4.0,,,Yes
20321,todo: add list unwrapping\/interlacing support like in other wrappers?,,No,Yes
20322,TODO: create 'scheduler' field to restore previous state? (not so important for early versions),,Yes,Yes
20323,move 'loss' section to 'optimization' section,,Yes,Yes
20324,TODO: add scheduler 0-based step fix here? (unlikely to cause serious issues),,Yes,Yes
20325,reassemble string if needed,,,Yes
20327,load model trace if needed (we do it here since we can locate the neighboring file),,No,Yes
20328,@@@ todo: cleanup swap_channels above via flag in superres task?,,No,Yes
20329,@@@@@ todo: use target_min\/target_max and other props from task?,,Yes,Yes
20331,TODO,,Yes,Yes
20332,return None if rendering fails (probably due to matplotlib on displayless server),,Yes,Yes
20333,user should probably implement their own trainer,,Yes,Yes
20334,TODO,,Yes,Yes
20336,maybe need to concat?,,,Yes
20339,TODO,,,Yes
20342,FIXME:,,,Yes
20343,FIXME: experimental,,No,Yes
20345,"\""\""\""Common object interfaces module. ||  || The interfaces defined here are fairly generic and used to eliminate || issues related to circular module importation. || \""\""\""",,,Yes
20347,TODO make config dict comparison smarter...?,,,Yes
20351,note: we use a flag here instead of removing bad features so that end-users can still use them if needed,,,Yes
20352,note: we use a flag here instead of removing bad features so that end-users can still use them if needed,,No,Yes
20354,TODO: MERGE CROP + MASK(DTRANSF) @@@@,,No,Yes
20355,FIXME: no specific mapping of inputs; each is different,,Yes,Yes
20357,@@@@ TODO: add util to truncate size of string in each member of samples below?,,Yes,Yes
20358,@@@@ TODO: add util to truncate size of string in each member of samples below?,,Yes,Yes
20359,TODO: add more,,,Yes
20360,note: this is a pretty 'dumb' way to add coord maps to a model; as it will add them everywhere; even,,Yes,Yes
20361,NOTE DISTINCTION BETWEEN OPERATORS AND TRANSFORMERS? @@@@@ TODO,,,Yes
20362,huge skip; user probably provided ops pipeline as function pointers,,Yes,Yes
20364,todo: replace w\/ pytorch's internal tbx @@@@@,,Yes,Yes
20365,todo: replace w\/ pytorch's internal tbx @@@@@,,,Yes
20368,TODO Check the validity of this assert,,,Yes
20370,check with re-parsed version after fixing release dash,,,Yes
20371,reassemble string if needed,,No,Yes
20374,"\""\""\"" || Agricultural Semantic Segentation Challenge Dataset Interface ||  || Original author: David Landry (david.landry@crim.ca) || Updated by Pierre-Luc St-Charles (April 2020) || \""\""\""",,,Yes
20380,"TODO - Fill in \""Usage\"" section in app\/info.txt",,,Yes
20381,TODO - Support for batching,,No,Yes
20383,TODO - DSG - verify the input data format,,,Yes
20388,callback_uri is needed to sent the responses to,,Yes,Yes
20390,Needed because concurrent workers will retry to remove,,,Yes
20391,callback_uri is needed to sent the responses to,,,Yes
20392,Verify all features needed were sent,,,Yes
20393,Columns,,No,Yes
20394,Subset relevant columns in data,,,Yes
20395,TODO - Add custom return for each backend,,,Yes
20397,Subset relevant columns in data,,Yes,Yes
20399,''' || Created on Aug 8; 2016 || Processing datasets.  || @author: Xiangnan He (xiangnanhe@gmail.com) || ''',,Yes,Yes
20400,''' || Created on Apr 15; 2016 || Evaluate the performance of Top-K recommendation: ||     Protocol: leave-1-out evaluation ||     Measures: Hit Ratio and NDCG ||     (more details are in: Xiangnan He; et al. Fast Matrix Factorization for Online Recommendation with Implicit Feedback. SIGIR'16) || @author: hexiangnan || ''',,Yes,Yes
20401,todo,,No,Yes
20402,implement once UnionFind exists; and second; because the only slow,,,Yes
20404,Todo implement logic to disable previous conected component in _run() method:,,Yes,Yes
20407,## Define folders. Create if needed.,,No,Yes
20409,## Define folders. Create if needed.,,No,Yes
20411,img_obj.working_arr = None  # todo,,,Yes
20412,todo,,No,Yes
20413,# TODO after we verify for DRIVE,,Yes,Yes
20417,TODO,,,Yes
20419,the output consists of 21 columns,,,Yes
20420,the output consists of 21 columns,,No,Yes
20421,the output consists of 21 columns,,,Yes
20422,the output consists of 21 columns,,,Yes
20423,the output consists of 21 columns,,,Yes
20424,the output consists of 21 columns,,,Yes
20426,the output consists of 21 columns,,,Yes
20427,the output consists of 21 columns,,,Yes
20430,the output consists of 21 columns,,No,Yes
20431,the output consists of 21 columns,,No,Yes
20432,the output consists of 21 columns,,No,Yes
20433,the output consists of 21 columns,,,Yes
20434,the output consists of 21 columns,,No,Yes
20435,the output consists of 21 columns,,,Yes
20436,the output consists of 21 columns,,No,Yes
20438,is it needed?,,Yes,Yes
20439,TODO,,,Yes
20440,fix node_num,,Yes,Yes
20441,TODO,,,Yes
20442,fix node_num,,Yes,Yes
20446,the output consists of 21 columns,,No,Yes
20452,fix node_num,,,Yes
20453,TODO: get expression for network with circular nodes,,,Yes
20455,TODO:,,No,Yes
20456,TODO: get expression for network with circular nodes,,No,Yes
20457,fix node_num,,Yes,Yes
20458,TODO: plotting for circular layer network,,,Yes
20459,TODO:,,No,Yes
20460,FIXME: use better implementation later,,No,Yes
20461,fix node_num,,Yes,Yes
20463,FIXME: use better implementation later,,No,Yes
20464,TODO:,,,Yes
20470,TODO:,,,Yes
20472,TODO: find file,,Yes,Yes
20473,fix node_num,,,Yes
20474,FIXME: this one does not work quite well for circular layer case; need further processing,,,Yes
20475,TODO: plotting for circular layer network,,No,Yes
20476,"with open(\""temp_command_file_%d.txt\"" % (self._mynetwork._index); 'a') as temp_command_f:  # FIXME: use better implementation later",,,Yes
20478,ends with exception,,No,Yes
20479,TODO: handle this case,,Yes,Yes
20481,FIXME: modify this later,,Yes,Yes
20483,TODO: parse coef_file,,Yes,Yes
20489,TODO: parse coef_file,,,Yes
20493,TODO: fix this for non-circular case,,,Yes
20495,TODO: add this for non-circular case,,Yes,Yes
20496,FIXME: following expression is out-of-date due to the change in API for higher-dimensional cases,,Yes,Yes
20497,TODO: code not concise and general enough; fix this later,,Yes,Yes
20498,FIXME: why in some cases it is not close to 1??,,Yes,Yes
20504,TODO: plotting for circular layer network,,,Yes
20507,TODO: parse coef_file,,Yes,Yes
20508,TODO: create a file that contains finished jobs.,,,Yes
20509,TODO: code not concise and general enough; fix this later,,Yes,Yes
20510,FIXME: why in some cases it is not close to 1??,,Yes,Yes
20516,TODO: better naming,,Yes,Yes
20518,FIXME: there is seg fault when loading checkpoint?,,No,Yes
20519,FIXME: here we only calculate the first half of the network; need to be fixed later,,Yes,Yes
20520,TODO: this function only works for non-hierarchical cases; for hierarchical cases it is not implemented,,Yes,Yes
20521,TODO: this function only works for non-hierarchical cases; for hierarchical cases it is not implemented,,Yes,Yes
20525,this backup is required to get the correct results; no idea why,,Yes,Yes
20528,TODO: may need to add arbitrary rotation to each frame,,,Yes
20529,TODO: use better way than hardcoding it,,,Yes
20530,TODO: handle this case,,,Yes
20531,TODO,,Yes,Yes
20532,TODO: this is temporary version,,No,Yes
20534,TODO: add GPU support,,,Yes
20537,TODO: temp,,No,Yes
20539,TODO: is it good to combine these two?,,,Yes
20541,TODO: does it work by adding quotation marks to everything,,,Yes
20544,TODO: is it good to use backbone?,,,Yes
20545,TODO: refactor following into a function later and include remove water,,,Yes
20547,TODO: may need better scaling factor?,,No,Yes
20548,_1 = coordinates_data_files_list(['..\/target\/BetaHairpin'])  # TODO: temp version,,,Yes
20549,TODO: temp version,,,Yes
20550,TODO: other way to check shapes of weights..,,,Yes
20552,TODO: refactor this part later,,,Yes
20553,TODO: may need better scaling factor?,,,Yes
20554,TODO: only implemented for 2-CV case,,No,Yes
20555,not needed; but do not want to see endless warning...,,,Yes
20558,TODO: may need better scaling factor?,,No,Yes
20559,fix based on this format: https:\/\/www.cgl.ucsf.edu\/chimera\/docs\/UsersGuide\/tutorials\/pdbintro.html,,No,Yes
20560,return K.mean(K.variable(weight_for_MSE) * K.square(y_pred - y_true); axis=-1)  # TODO: do this later,,,Yes
20562,FIXME: 2. this does not support multi-hidden layer cases,,Yes,Yes
20564,FIXME: fix for multi-hidden layer cases,,Yes,Yes
20566,TODO: what is this line used for?  I do not remember,,No,Yes
20567,TODO: is it good?,,No,Yes
20568,TODO: default setting is to use all pairs; may modify this later,,Yes,Yes
20569,TODO: default setting is to use all pairs; may modify this later,,Yes,Yes
20570,TODO: need to fix following for multi-hidden layer cases,,,Yes
20571,first find two states closest to two ends respectively,,No,Yes
20573,TODO: do this later,,No,Yes
20574,TODO: currently only for first 2 Dense layers,,,Yes
20576,TODO: make this part consistent with else branch,,No,Yes
20580,TODO: fix this; merge mean_penalty and component_penalty in the future,,No,Yes
20581,It is implemented this way to handle hierarchical case;,,,Yes
20585,all_scores  = pd.DataFrame(columns = ['Model'; 'Function'; 'CV Score'; 'Difference'; 'Outcome'; 'Time']),,,Yes
20589,TODO: create an auto-regressive decoder,,Yes,Yes
20590,TODO: does times_transpose behave correctly for unpacked sequence,,,Yes
20593,TODO: assert the shape with no padding,,No,Yes
20594,otherwise we'd need to fix slicing and Param initializers,,,Yes
20596,TODO: should both activations be replaced?,,,Yes
20598,TODO: if this gets usage then offer a Softplus version like Stabilizer() for stability?,,No,Yes
20600,TODO: use regex probably more straightforward,,Yes,Yes
20604,to work around bug,,,Yes
20605,TODO: if initial_state is a CNTK Function rather than an initializer; then require to pass it multiple times; otherwise broadcast to all,,Yes,Yes
20607,TODO: Include RecurrenceFrom in here,,,Yes
20608,TODO: should both activations be replaced?,,,Yes
20612,TODO: potential speed up by splice into one big matrix to times,,Yes,Yes
20613,shape = (-1; -1)  # TODO: input_shape input_rank,,,Yes
20615,TODO: if this gets usage then offer a Softplus version like Stabilizer() for stability?,,No,Yes
20619,TODO: prob's not necessary if other changes below,,Yes,Yes
20621,get columns for new dataFrame (here to reduce computation),,,Yes
20622,yes yes I know so why even load it? TODO: don't load ratings since unused but keep rename \/ change name convention,,,Yes
20623,test_noLabel = test[test.columns.difference(['rating'])],,,Yes
20625,unfortunately loop needed since small adjustments must be made,,No,Yes
20626,neat trick to always ensure path ends in seperator '\/' by appending empty,,,Yes
20627,TODO: devise a method to make erros in nested try; catch,,,Yes
20630,TODO: current assumption is that each document is already less than,,,Yes
20631,this should probably be additional functionality,,Yes,Yes
20633,TODO: this is very awkward because it might be called where conf is None,,,Yes
20634,TODO implement level specific formating,,Yes,Yes
20636,TODO: add an arg for this,,,Yes
20639,TODO: off by one error please for the love of god george,,Yes,Yes
20642,TODO: off by one ... you fool george; sort this out,,,Yes
20643,TODO: off by one ... you fool george; sort this out,,,Yes
20644,"for unused in range(self.args[\""layers\""]-1):",,,Yes
20648,passing the 3 needed args to argument handler and main with minimal,,,Yes
20652,TODO add these in next if user has them seperate,,Yes,Yes
20653,TODO: vectorize on outermost dimension (rowise not elementwise),,Yes,Yes
20657,TODO: call data filling functions,,No,Yes
20660,TODO: Plot reconstruction to show that it is not the same.,,No,Yes
20661,# TODO: We have to fix the fact of TimeZone; the fact that on,,No,Yes
20662,# Maybe displaze date and join stuff.,,,Yes
20663,I could not find a fucking way to modify it inline TODO,,,Yes
20667,"TODO: Use this df[\""date\""] = pd.to_datetime(df.index)",,,Yes
20668,TODO: Event detection; like huge drops and so on; with the Drawdown ?\uFFFF,,,Yes
20669,Maybe same as the measurement noise would be appropiate.,,,Yes
20670,TODO: Obtener las mejores componented de una serie; hacemos PCA y detransformamos ?,,,Yes
20672,TODO: Event detection; like huge drops and so on; with the Drawdown ?\uFFFF,,Yes,Yes
20673,TODO: Obtener las mejores componented de una serie; hacemos PCA y detransformamos ?,,Yes,Yes
20674,"TODO: Use this df[\""date\""] = pd.to_datetime(df.index)",,,Yes
20675,TODO: Event detection; like huge drops and so on; with the Drawdown ?,,,Yes
20676,TODO: Ideas:,,,Yes
20678,# Maybe displaze date and join stuff.,,,Yes
20681,TODO: Be able to automatize the shareX thing,,Yes,Yes
20683,TODO: I think I have to do properly the loading of the info into the mdoel,,No,Yes
20685,TODO: Be able to automatize the shareX thing,,Yes,Yes
20686,TODO: I think I have to do properly the loading of the info into the mdoel,,No,Yes
20687,Download if needed.,,,Yes
20689,TODO: Define what are the dates of a portfolio; or well; it depends on the period,,,Yes
20690,# Get some efficient frontier and simulate the portfolio,,,Yes
20691,# IDEA !! Maybe use the portfolio in the frontier that maximizes,,,Yes
20692,# Alpha and beta say: Does out portolio perform better than the market ?,,,Yes
20693,WARNING !! The calculation of the efficient frontier this way could be,,Yes,Yes
20695,Other way for finding efficient frontier,,,Yes
20700,TODO: Just to put it in the sahpe as it was before writing it to disk,,No,Yes
20702,# Graoca bonita !! TODO,,No,Yes
20703,#### TODO ##################3,,No,Yes
20705,Download if needed.,,,Yes
20706,Download if needed.,,,Yes
20707,Download if needed.,,Yes,Yes
20708,"\""\""\"" || I guess this would show the probability of up or down given that you know the value of || the real signal at that point. More noise will make it less sure with same overall shape. || If we add correlation noise; we should actually get way better estimates... and we do. || Do they depend only on the previous ? Or also in all the previous ? I guess it is just the substaction of both || so the common terms dissapear nicely :) ||  || \""\""\""",,No,Yes
20713,### FOR FUTURE ADDING MAYBE!!!,,No,Yes
20714,"TODO: Maybe some processing on the \""Date part\""",,Yes,Yes
20715,Loads a CSV from the folder with the naming convention for the period.,,,Yes
20718,TODO. Make it work for series Names not in the dataset.,,,Yes
20719,TODO,,,Yes
20720,We have to add this new input (maybe delete some old one as well),,No,Yes
20725,### Crazy idea !! Lets plot where the fucking efficient frontier went,,Yes,Yes
20726,# IDEA !! Maybe use the portfolio in the frontier that maximizes,,Yes,Yes
20728,We calculate it in a gaussian way,,Yes,Yes
20733,Calculate efficient frontier weights using quadratic programming,,,Yes
20734,# TODO: This is not useful,,No,Yes
20737,print df.columns,,,Yes
20739,Maybe same as the measurement noise would be appropiate.,,Yes,Yes
20740,# Shirnk the main axes. TODO; move this to another general func,,No,Yes
20741,TODO me estas puto diciendo que solo port seleccionar esto me jodes ?,,Yes,Yes
20743,# TODO. Second case where NcY = NcX !!,,Yes,Yes
20746,TODO: maybe in the future differentiate between sigma_eps and dy,,Yes,Yes
20747,TODO: what is this     ec='None',,No,Yes
20749,# Function to change position of axes !! TODO,,Yes,Yes
20750,nc is the numbel of columns,,,Yes
20753,# TODO; it used to be this all the way:,,No,Yes
20755,more efficient. (In this example this doesn't matter though.),,,Yes
20757,TODO  : Nada puto funciona !!!!!!!!!!,,No,Yes
20758,### FOR FUTURE ADDING MAYBE!!!,,,Yes
20760,TODO: This could be inf,,,Yes
20761,# TODO !! Improve this shit !!,,Yes,Yes
20762,WHAT WE WANT TO DO IS ELIMINATE THE DATES WHERE THESE IS NEVER TRADING !!,,Yes,Yes
20766,rt.stop() # better in a try\/finally block to make sure the program ends!,,Yes,Yes
20767,this should probably be centralized someplace,,Yes,Yes
20768,Maybe if they start higher the usually go down (unless we are in a possitive trend maybe),,No,Yes
20769,TODO: Preprocess datetome so that it fits in a given interval,,Yes,Yes
20771,Npos_col = len(position_col.columns.tolis()),,No,Yes
20772,# TODO info about the price,,No,Yes
20773,# TODO add the commision,,,Yes
20775,TODO,,Yes,Yes
20776,TODO: We cannot do it like this if the original has Nans.,,Yes,Yes
20777,# TODO -> Closser patterns or patterns in the same periodic state (check periodicity) hace preference,,No,Yes
20778,TODO -> Incorporate metrics for Volume also.,,Yes,Yes
20779,TODO -> Try doinf this with open; close; high; low or other shit instead,,Yes,Yes
20780,# TODO -> Closser patterns or patterns in the same periodic state (check periodicity) hace preference,,No,Yes
20782,TODO -> Try doinf this with open; close; high; low or other shit instead,,Yes,Yes
20784,print df.columns,,,Yes
20786,Maybe same as the measurement noise would be appropiate.,,,Yes
20787,# Shirnk the main axes. TODO; move this to another general func,,No,Yes
20788,TODO me estas puto diciendo que solo port seleccionar esto me jodes ?,,Yes,Yes
20789,"We also need to resize \""where\"" vector if needed.",,No,Yes
20793,TODO: maybe in the future differentiate between sigma_eps and dy,,,Yes
20795,TODO If the position is the same; then;,,,Yes
20797,TODO: the -2 is only if the last element has shared axes; we should detect that,,Yes,Yes
20801,pre post mid ## TODO; part of the step. How thw shit is done,,Yes,Yes
20802,# TODO. Second case where NcY = NcX !!,,,Yes
20804,# Function to change position of axes !! TODO,,Yes,Yes
20805,nc is the numbel of columns,,,Yes
20807,Number of columns of the legend,,,Yes
20808,This funciton will store the data needed to later use the widgets,,Yes,Yes
20811,TODO: the -2 is only if the last element has shared axes; we should detect that,,,Yes
20812,TODO; should it be if nf == 1,,,Yes
20813,# TODO; it used to be this all the way:,,,Yes
20814,of the original signal is needed.,,No,Yes
20815,more efficient. (In this example this doesn't matter though.),,Yes,Yes
20816,######### Efficient Moving Averages ###################,,No,Yes
20819,# Different types of BB bands ? TODO,,No,Yes
20820,TODO: This could be inf,,No,Yes
20824,# TODO; learn really the different timeData types,,,Yes
20826,# the rest of the days as columns,,,Yes
20827,rt.stop() # better in a try\/finally block to make sure the program ends!,,Yes,Yes
20829,this should probably be centralized someplace,,,Yes
20831,# TODO: How are we filling the data ?,,No,Yes
20832,# TODO: How are we filling the data ?,,No,Yes
20833,TODO: Play with norm constant,,No,Yes
20835,# TODO: Not used now,,,Yes
20837,# Obtain the coefficients if needed,,,Yes
20842,Maybe rk is very small and this fails,,No,Yes
20843,TODO: Check what causes the imaginarity,,No,Yes
20844,# TODO: It is a 2 right ?,,Yes,Yes
20845,TODO: Obtain a lot of samples first from np.random.uniform() snd,,Yes,Yes
20846,# TODO: Here is the shit to avoid the problem of that the maximum does not happen,,,Yes
20847,TODO: Play with norm constant,,,Yes
20848,# TODO: better manage this,,Yes,Yes
20850,TODO: Move only the following line inside the function below,,,Yes
20852,Maybe removing the cluster or reininitializing the cluster randomly,,Yes,Yes
20855,way; the a priori probability of going from a state i to a state j is,,Yes,Yes
20858,TODO: Maybe we do not need them ? Maybe we should use the gammas instead ??,,,Yes
20860,that ends atstate number i,,No,Yes
20861,Generate the new journey that ends in state i at time t as the,,,Yes
20862,TODO: Maybe the index of the following is wrong !!,,Yes,Yes
20866,TODO: probably move from here,,,Yes
20867,TODO: Not normalized anymore,,,Yes
20868,# TODO: Idea... project different PCA for classes TO,,,Yes
20871,TODO: Is the supervisor the one saving the state every X time ?,,,Yes
20872,TODO: Make a study of when the prediction of the network is the better possible (which time-step).,,Yes,Yes
20875,TODO: This is the structure we just saw...,,,Yes
20876,TODO: For now we set it the same as the hidden_size. Probably for matrix concatenation purposes ?,,,Yes
20878,TODO: We need to provide info about the Batch size ? That is the number of chains,,,Yes
20879,TODO: This is probably why we want the chains to have the same length. Also maybe to not having to worry later to weight the,,,Yes
20880,Maybe this is so that we do not create the LSTMS a lot of times in the TensorBoard ?,,,Yes
20881,TODO: Not really a TODO; but the important part here is that we changed size vy config.hidden_size,,Yes,Yes
20883,TODO: Remove increased by 2 the cost so that the total cost is more influenced,,Yes,Yes
20884,TODO,,Yes,Yes
20885,TODO: Each batch is going to reuse the state of the previous batch ?,,No,Yes
20886,TODO: Make a network that accepts chains of different length,,Yes,Yes
20887,Probably way harder to program and less efficient in parallel computation,,,Yes
20888,TODO No idea,,Yes,Yes
20889,TODO: We need to set it to at least one.,,No,Yes
20890,## TODO: I have no idea why we multiply by 1,,,Yes
20891,"\""\""\"" || Finally we need to initialize the variables ?? || TODO: why we need to initialize it ? || \""\""\""",,Yes,Yes
20892,TODO: Is the supervisor the one saving the state every X time ?,,Yes,Yes
20894,"\""\""\"" || 1. INITIALIZE VARIABLES || Finally we need to initialize the variables ?? || TODO: why we need to initialize it ? || \""\""\""",,Yes,Yes
20896,We use two summary writers. This is a hack that allows us to write,,Yes,Yes
20897,"\""\""\"" || In this document we will perform a basic Linear Regression including TensorBoard. || It is a very simple manual program with no proper naming of the variables. || We will: ||     - Use the conditional in the huber loss. ||     - We can also save the model parameters. || \""\""\""",,Yes,Yes
20898,We use two summary writers. This is a hack that allows us to write,,Yes,Yes
20900,We use two summary writers. This is a hack that allows us to write,,Yes,Yes
20901,"\""\""\"" || In this document we will perform a basic Linear Regression including TensorBoard. || It is a very simple manual program with no proper naming of the variables. || We will: ||     - Use the conditional in the huber loss. ||     - We can also save the model parameters. || \""\""\""",,,Yes
20903,"\""\""\"" || In this document we will perform a basic Linear Regression including TensorBoard. || It is a very simple manual program with no proper naming of the variables. || We will: ||     - Use the conditional in the huber loss. ||     - We can also save the model parameters. || \""\""\""",,,Yes
20904,Load all the directories needed for the code to be executed both from,,Yes,Yes
20905,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20906,Load all the directories needed for the code to be executed both from,,Yes,Yes
20908,Load all the directories needed for the code to be executed both from,,,Yes
20909,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20910,ax1.set_xticks(data_df_train.columns) # ; rotation='vertical',,,Yes
20911,Load all the directories needed for the code to be executed both from,,,Yes
20912,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20913,Load all the directories needed for the code to be executed both from,,Yes,Yes
20914,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20915,to move the price up; and how many to move it down. This is hard to know from daily data but we can get a better representation from 15M,,,Yes
20916,"\""\""\"" || In this document we will perform a basic Linear Regression including TensorBoard. || It is a very simple manual program with no proper naming of the variables. || We will: ||     - Use the conditional in the huber loss. ||     - We can also save the model parameters. || \""\""\""",,Yes,Yes
20917,"\""\""\"" || I guess this would show the probability of up or down given that you know the value of || the real signal at that point. More noise will make it less sure with same overall shape. || If we add correlation noise; we should actually get way better estimates... and we do. || Do they depend only on the previous ? Or also in all the previous ? I guess it is just the substaction of both || so the common terms dissapear nicely :) ||  || \""\""\""",,No,Yes
20918,## TODO: Create a Vocab from files or previously created or set of Tokens directly.,,Yes,Yes
20919,TODO: It looks like it does show all of the namespaces ?,,,Yes
20924,TODO: Bayesian weights are moved to device by default; we need to change that.,,Yes,Yes
20926,# Move the tensor to cuda,,,Yes
20927,MAnual fix for Dropout,,Yes,Yes
20930,"\""\""\"" || ################ LOAD PRETRAINED MODEL ############### || We load the pretrained model and we can see what parts it has and maybe reused if needed. || \""\""\""",,No,Yes
20932,Not really needed in the end because a Timer() only has a Thread.,,No,Yes
20933,I think we needed to keep them in memory of they would die,,,Yes
20935,Otherwise we would have different time labels and the SQL dabase would need a table per sensor to be efficient;.,,,Yes
20939,# TODO: Big task... manage different windows in gl library,,Yes,Yes
20942,TODO: Change to look over the possible columns,,No,Yes
20943,# HACK,,,Yes
20945,Apparently AllenNLP needs the vocabulary,,Yes,Yes
20948,### TODO: Learning rate scheduler ####,,No,Yes
20949,# Move the tensor to cuda,,Yes,Yes
20951,# Move the tensor to cuda,,Yes,Yes
20952,HACK : global step is not restored for some unknown reason,,Yes,Yes
20957,TODO,,,Yes
20959,# TODO: We have to fix the fact of TimeZone; the fact that on,,No,Yes
20961,Not needed if the sequence was already ordered,,No,Yes
20962,TODO. Make it work for series Names not in the dataset.,,,Yes
20964,TODO: REMOVE THE NEED OF CALLING IT HERE,,No,Yes
20971,# TODO: Redesign this operator,,,Yes
20972,# Hardcoded param:,,,Yes
20973,Otherwise we would have different time labels and the SQL dabase would need a table per sensor to be efficient;.,,Yes,Yes
20974,The data should be provided externally; probably with a DDBB call.,,,Yes
20975,"Monitors is a list of Monitor objects; the \""ID\"" of the object would the columns of data",,,Yes
20976,TODO,,,Yes
20977,# TODO: Big task... manage different windows in gl library,,Yes,Yes
20978,TODO: I need to add it somethow.,,,Yes
20979,might be needed for a different port FTP.connect(host[; port[; timeout]]) and login,,,Yes
20980,TODO: Change to look over the possible columns,,,Yes
20981,Not needed but implemented,,Yes,Yes
20982,Information needed for proper plotting.,,,Yes
20986,# Example on how to construct complex graphs showing better graphs,,Yes,Yes
20989,TODO: Be able to automatize the shareX thing,,,Yes
20990,Load all the directories needed for the code to be executed both from,,Yes,Yes
20991,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20992,Load all the directories needed for the code to be executed both from,,Yes,Yes
20993,Ideally this code should be executed using Spyder with working directory,,Yes,Yes
20995,TODO: UBC strat; epsilon-greedy,,,Yes
20996,Initialization can be poorly specified; this is a hack to make it work,,Yes,Yes
20997,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
20999,needed. We could use np.squeeze here; but we don't want to squeeze,,,Yes
21000,XXX these two are redundant. Please; check.,,Yes,Yes
21001,param was drawn in related contexts,,,Yes
21002,mother with HS education or better; hearing loss identified by 3 months,,,Yes
21003,Hack as assigning a function in the class definition automatically binds,,Yes,Yes
21005,needed for `add_random_variable` method,,,Yes
21008,TODO: It would be great to come up with a way to make,,Yes,Yes
21010,Create a generator object. Apparently the generator object needs to,,,Yes
21014,hack to allow pm.fit() access to loss hist,,,Yes
21017,"\""\""\"" || This is a nice small library to plot things related to the training of the algorithms !! || \""\""\""",,,Yes
21019,this is for efficient update,,Yes,Yes
21020,TODO:,,No,Yes
21021,wtf_loss = wtf_loss + grad_norm[index][task_idx],,No,Yes
21022,wtf_loss.backward(retain_graph=True; create_graph=True),,Yes,Yes
21023,print('WTF 1'; self.coeffs.grad.shape),,Yes,Yes
21025,wtf_loss.backward(),,No,Yes
21027,PHEW; THIS UGLY STUFF IS OVER...,,Yes,Yes
21028,TODO: but seriously; we need to fix it!,,Yes,Yes
21029,TODO: make this thing less ugly. We don't want to track,,Yes,Yes
21031,numbers; ignore the specified FEATURE columns: first column is 1,,Yes,Yes
21032,TODO: can we do this with xpath instead?,,,Yes
21037,TODO: Inherit set from parent,,Yes,Yes
21041,TODO,,Yes,Yes
21042,TODO: Parse CMDI,,,Yes
21043,TODO: node or filename,,No,Yes
21044,TODO: sanity check; there may be no other child within the same set,,Yes,Yes
21045,TODO: IMPLEMENT,,,Yes
21046,TODO: add XMLATTRIB,,,Yes
21052,TODO,,Yes,Yes
21053,TODO: make obsolete,,,Yes
21054,MAYBE TODO: corrected attribute?,,Yes,Yes
21055,TODO: Implement,,,Yes
21059,MAYBE TODO: corrected attribute?,,,Yes
21060,TODO: relaxNG,,No,Yes
21061,TODO parse datetime string,,No,Yes
21063,ugly patch to get rid of namespace prefix,,Yes,Yes
21065,TODO,,,Yes
21066,TODO!,,,Yes
21067,TODO: relaxNG,,No,Yes
21068,TODO!,,Yes,Yes
21071,workaround for xml:id problem,,No,Yes
21072,XML Tree is now obsolete (only needed when partially loaded for xpath queries),,,Yes
21073,TODO: Parse xlink:href,,,Yes
21075,if a quote ends in a sentence; we don't want any delimiter,,,Yes
21076,TODO: add phoneme when it becomes available,,Yes,Yes
21077,XML Tree is now obsolete (only needed when partially loaded for xpath queries); free memory,,Yes,Yes
21081,TODO: won't work in text <x\/> text scenarios,,,Yes
21084,will hold all subdocs (sourcestring => document) ; needed so the index can resolve IDs in subdocs,,Yes,Yes
21086,ugly patch to get rid of namespace prefix,,Yes,Yes
21087,TODO: check validity of elements under subdoc\/text with respect to self.parent,,Yes,Yes
21088,will hold all subdocs (sourcestring => document) ; needed so the index can resolve IDs in subdocs,,Yes,Yes
21089,perhaps the key is in one of our subdocs?,,,Yes
21090,ugly patch to get rid of namespace prefix,,,Yes
21093,TODO,,Yes,Yes
21095,TODO: process modifier,,No,Yes
21101,(twice; better safe than sorry),,,Yes
21102,OPTIONAL_ATTRIBS = (Attrib.ID; Attrib.SETONLY;) #TODO: handle SETONLY in new scheme,,,Yes
21103,REQUIRED_ATTRIBS = (Attrib.ID;)  #TODO: See if this is handled correctly in new scheme,,,Yes
21104,(twice; better safe than sorry),,No,Yes
21105,nasty backward-compatibility hack to allow deprecated listitem element (actually called item),,No,Yes
21106,definitions needed for ForeignData (allow any content) - see http:\/\/www.microhowto.info\/howto\/match_arbitrary_content_using_relax_ng.html,,Yes,Yes
21111,AbstractSpanAnnotation is needed when requesting text() on nested span annotations,,,Yes
21112,well; we couldn't find our textclass in any correction; just fall back to current and let text validation fail if needed,,,Yes
21113,TODO: what about corrections?,,No,Yes
21115,TODO: Add data types #27,,,Yes
21117,signal we are done editing; needed to invoke postprocessing,,Yes,Yes
21121,TODO,,,Yes
21122,Needed to make sure the logging output is visible.,,Yes,Yes
21124,Better parameters and features have higher chances of being chosen.,,Yes,Yes
21127,-- Options for todo extension ----------------------------------------------,,,Yes
21128,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
21131,returning a 2-columns numpy.ndarray,,No,Yes
21133,More efficient version that can be used if .sum() returns a Python scalar,,Yes,Yes
21134,TODO:  Update overflow check + downscale to use Carl's fused kernel.,,,Yes
21135,init_state_dict sets up an alternative way to cast per-param state tensors.,,Yes,Yes
21136,alternative way to cast per-param state tensors:,,Yes,Yes
21138,TODO: Am i going to use this?,,,Yes
21139,net.print_info() #TODO,,No,Yes
21140,TODO: date; time; dateTime; dateDaysSince[0\/1960\/1970\/1980]; timeSeconds; dateTimeSecondsSince[0\/1960\/1970\/1980],,Yes,Yes
21145,Customize these as needed.,,,Yes
21146,Note that my_ext_modules is just a list of Extension objects. We could add any C sources (not coming from Cython modules) here if needed.,,,Yes
21148,TODO: support <Extension> as well,,,Yes
21167,TODO: deal with name_scope conflicts when copying batch_norm,,,Yes
21168,TODO: as_list() fails when static_shape unknown,,Yes,Yes
21169,fix for control flow (Copy _control_flow_context),,No,Yes
21171,TODO: there seems to be a bug because h are using relu already,,,Yes
21178,fix of no static shape inference for tf.lbeta,,,Yes
21179,TODO: add type argument for distributions,,Yes,Yes
21180,TODO: not right when given=0 or 1,,Yes,Yes
21183,TODO make sure adapt_step_size is a placeholder,,Yes,Yes
21184,TODO incorrect shape?,,,Yes
21185,TODO: not right when given=0 or 1,,Yes,Yes
21187,TODO: check ndim of sample axis should be larger than 1; else raise.,,,Yes
21189,TODO: check input shape (N>=2) of samples; hidden and log_probs.,,No,Yes
21190,TODO: properly deal with hidden.,,,Yes
21191,TODO: extend to non-scalar,,No,Yes
21192,You can just specify the packages manually here if your project is,,,Yes
21193,TODO: This failed with a bug in Tensorflow; waiting fix.,,No,Yes
21194,TODO: This failed with a bug in Tensorflow in Dirichlet.,,No,Yes
21195,TODO: remove dependencies on scipy,,No,Yes
21196,TODO: Add Gumbel distribution,,Yes,Yes
21197,TODO: add Logistic distribution,,Yes,Yes
21204,TODO: Check grads when use variance reduction and baseline,,No,Yes
21205,TODO: fix get variable failure for repeated calls.,,,Yes
21206,TODO: __str__; __repr__ for StochasticTensor,,Yes,Yes
21208,TODO: Whether to copy?,,No,Yes
21210,TODO: raise warning,,,Yes
21211,TODO: remove v_log_probs,,Yes,Yes
21214,TODO: raise warning,,No,Yes
21215,TODO: raise warning,,No,Yes
21217,TODO: fix n for generation,,Yes,Yes
21221,TODO: raise warning,,,Yes
21222,TODO: Deprecate deterministic?,,,Yes
21223,TODO: remove direct; use tf.greater,,,Yes
21225,TODO: the cache only works when no further nodes is added to the bn;,,,Yes
21226,TODO: check whether `self` is BayesianNet or _BayesianNet,,,Yes
21229,perhaps interleave keys is not required here?,,Yes,Yes
21231,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21234,HACK: Saving the sort key function as the split() call removes it,,No,Yes
21236,TODO (@mttk): Populate classs with default values of special symbols,,Yes,Yes
21239,TODO: Clean up and use Vocab object,,,Yes
21240,TODO: Remove this once issue was been resolved.,,No,Yes
21242,TODO# Add nltk data back in build_tools\/travis\/install.sh.,,Yes,Yes
21243,TODO: no need to loop through the whole counter,,,Yes
21244,So as workaround we copy the asset data to temporary directory and load it from there.,,Yes,Yes
21245,TODO: Fix utf-8 next line mark,,,Yes
21247,white space fix,,Yes,Yes
21252,TODO: use self.assertRaisesRegex() to check,,,Yes
21253,values is needed to support that behavior for new_fn as well.,,No,Yes
21257,TODO: Fix utf-8 next line mark,,No,Yes
21262,A Hack to unlink liborange.so -> orange.so if it already exists;,,Yes,Yes
21263,Definitely ugly; but I see no other workaround.,,Yes,Yes
21264,sparse data format; begin with '{'; ends with '}',,,Yes
21265,max 5MB sample TODO: What if this is not enough. Try with a bigger sample,,Yes,Yes
21267,TODO escape spaces,,Yes,Yes
21268,TODO: windows drive letters.,,Yes,Yes
21270,TODO: Doc datasets and files should be installed using data_files.,,No,Yes
21272,not conform to StrictVersion needed by bdist_msi).,,Yes,Yes
21273,TODO hide utils from the user,,Yes,Yes
21276,TODO: Simply replace with include_package_data = True and configure missed files in MANIFEST.in?,,,Yes
21277,TODO: Use entry points for automatic script creation,,Yes,Yes
21279,A hack to make setuptools in distutils work together on Ubuntu,,No,Yes
21284,return a new table; create new domain if needed,,Yes,Yes
21286,multiple rows; multiple columns,,,Yes
21287,TODO: check whether .data builds a new buffer; try avoiding it,,Yes,Yes
21288,TODO: is there a better way to do it?!,,No,Yes
21291,TODO: rewrite to Cython,,Yes,Yes
21293,TODO Does not work,,,Yes
21294,TODO implement checking by columns,,,Yes
21295,TODO Should we return an instance of `object` if we have a meta attribute,,,Yes
21297,TODO use source if provided!,,Yes,Yes
21302,TODO: what should be the results of table[1; :],,No,Yes
21303,expand probability predictions with zero columns for class values which are not present,,,Yes
21304,TODO,,,Yes
21306,TODO ... or have we decided that the arguments should be,,,Yes
21307,TODO: do we need locking? Don't we expect the code to be reentrant?,,,Yes
21310,TODO: this is unnecessary; let's remove it,,,Yes
21312,TODO Patch for sparse data or add another class,,No,Yes
21313,TODO Implement __call__ methods for filters below,,,Yes
21316,TODO Add sparse data like in distributions,,,Yes
21318,TODO: Orange Version in the base link,,No,Yes
21319,TODO: This is bad (should be moved here).,,No,Yes
21320,TODO: should the default name be platform specific,,No,Yes
21321,TODO: Use a dialog instance and use 'addSidebarUrls' to,,,Yes
21325,TODO: More sensible size hints.,,Yes,Yes
21328,scene event filter when not needed,,No,Yes
21331,TODO: Important because of this any time the child,,Yes,Yes
21332,Emitted when the interaction ends (canceled or finished),,,Yes
21335,item move as a part of a selection group.,,,Yes
21336,TODO: A uniform size box layout.,,No,Yes
21337,TODO: get the background.,,Yes,Yes
21338,TODO: right to left locale,,Yes,Yes
21344,TODO: add shift for pressed as set by the style (PM_ButtonShift...),,,Yes
21345,Background  (TODO: Should the tab button have native,,,Yes
21346,TODO: wayland??,,No,Yes
21347,TODO: This should be retrieved from orngRegistry.WidgetDescription,,,Yes
21348,TODO: how to set the icon from the svg contents string,,,Yes
21349,workaround for bugs.python.org\/issue11159,,,Yes
21350,TODO: lock,,,Yes
21352,TODO: zipped modules,,No,Yes
21354,TODO: Speedup - keep index of links by nodes and channels,,Yes,Yes
21355,TODO: should we clear the scheme and load it.,,,Yes
21356,TODO: Change how the signal is emitted in signal manager (should,,Yes,Yes
21358,this definitions are needed only to define ExampleTable as subclass of ExampleTableWithClass,,Yes,Yes
21359,directories are better defined this way; otherwise .ini files get written in many places,,,Yes
21360,needed by signalWrapper to know when everything was sent,,,Yes
21361,call this function if needed in __init__ of the widget,,Yes,Yes
21363,implement this in your widget if you want to process something only after you received multiple signals,,Yes,Yes
21368,TODO: Style dependent margins?,,,Yes
21369,TODO: Check ForegroundRole.,,,Yes
21370,TODO: add other styles (Maybe load corrections from .cfg file?),,,Yes
21372,By settings __loader__ to None; we workaround the pkg_resources bug.,,,Yes
21373,TODO checks for quotes; escapes; error checking,,,Yes
21374,TODO: Ensure initialization of the provider,,,Yes
21375,TODO add!,,,Yes
21378,TODO: this is all just a quick hack; do it properly -- call data storage etc.,,Yes,Yes
21379,TODO sparse data,,Yes,Yes
21380,TODO is this needed in Python 3?!,,Yes,Yes
21381,TODO is this needed in Python 3?! Does it work at all?,,Yes,Yes
21385,check whether we have a sparse columns;,,Yes,Yes
21386,TODO: Ales; help!,,,Yes
21387,TODO Reimplement this,,No,Yes
21390,TODO: this is here only since __del__ is not properly called,,,Yes
21391,TODO this method has misleading name (method 'initialize' does what,,No,Yes
21392,called by this class but only by ContextHandlers. Perhaps it should,,Yes,Yes
21395,TODO do we still need this?,,,Yes
21396,TODO: group indexes into ranges,,No,Yes
21397,TODO This does not work in Python 3.0,,Yes,Yes
21399,TODO inputSignal is sometimes (after updating widget and rereading,,,Yes
21400,TODO add!,,,Yes
21402,"\""\""\"" ||     The Axis class display an axis on a graph ||      ||     The axis contains a line with configurable style; possible arrows; and a title ||      ||     .. attribute:: line_style ||         The LineStyle with which the axis line is drawn ||          ||     .. attribute:: title ||         The string to be displayed alongside the axis ||          ||     .. attribute:: title_above ||         A boolean which specifies whether the title should be placed above or below the axis ||         Normally the title would be above for top and left axes.  ||          ||     .. attribute:: title_location ||         can either be AxisStart; AxisEnd or AxisMiddle. The default is AxisMiddle ||          ||     .. attribute:: arrows ||         A bitfield containing AxisEnd if an arrow should be drawn at the line's end (line.p2())  ||         and AxisStart if there should be an arrows at the first point.  ||          ||         By default; there's an arrow at the end of the line ||          ||     .. attribute:: zoomable ||         If this is set to True; the axis line will zoom together with the rest of the graph.  ||         Otherwise; the line will remain in place and only tick marks will zoom.  ||                  ||     .. method:: make_title ||         Makes a pretty title; with the quantity title in italics and the unit in normal text ||                  ||     .. method:: label_pos ||         Controls where the axis title and tick marks are placed relative to the axis || \""\""\""",,,Yes
21407,# TODO: Check if the title is too big,,,Yes
21412,TODO: check hardware for OpenGL 3.x+ support,,No,Yes
21413,TODO: colors is list of QColor,,No,Yes
21416,TODO: Does any widget actually use it; or could it be,,Yes,Yes
21418,TODO: add another box for the entire data set,,No,Yes
21420,TODO: add another box for the entire data set,,No,Yes
21421,TODO check!!!,,Yes,Yes
21423,TODO Check this function!!!,,,Yes
21424,TODO: Check this function,,No,Yes
21425,"\""\""\"" || class Operator: ||     operatorsD = staticmethod([\""equals\"";\""in\""]) ||     operatorsC = staticmethod([\""=\"";\""<\"";\""<=\"";\"">\"";\"">=\"";\""between\"";\""outside\""]) ||     operatorsS = staticmethod([\""=\"";\""<\"";\""<=\"";\"">\"";\"">=\"";\""contains\"";\""begins with\"";\""ends with\"";\""between\"";\""outside\""]) ||     operatorDef = staticmethod(\""is defined\"") ||     getOperators = staticmethod(lambda: Operator.operatorsD + Operator.operatorsS + [Operator.operatorDef]) ||  ||     negations = {\""equals\"": \""does not equal\""; \""in\"": \""is not in\""; ||                  \""between\"": \""not between\""; \""outside\"": \""not outside\""; ||                  \""contains\"": \""does not contain\""; \""begins with\"": \""does not begin with\""; \""ends with\"": \""does not end with\""; ||                  \""is defined\"": \""is undefined\""} ||  || #\""Equal\""; \""NotEqual\""; \""Less\""; \""LessEqual\""; \""Greater\""; \""GreaterEqual\""; || #     \""Between\""; \""Outside\"" ||  ||     _operFilter = {\""=\"":orange.Filter_values.Equal; ||                    \""<\"":orange.Filter_values.Less; ||                    \""<=\"":orange.Filter_values.LessEqual; ||                    \"">\"":orange.Filter_values.Greater; ||                    \"">=\"":orange.Filter_values.GreaterEqual; ||                    \""between\"":orange.Filter_values.Between; ||                    \""outside\"":orange.Filter_values.Outside; ||                    \""contains\"":orange.Filter_values.Contains; ||                    \""begins with\"":orange.Filter_values.BeginsWith; ||                    \""ends with\"":orange.Filter_values.EndsWith} ||  ||     def __init__(self; operator; varType): ||         \""\""Members: operator; varType; isInterval. ||         \""\"" ||         assert operator in Operator.getOperators(); \""Unknown operator: %s\"" % str(operator) ||         self.operator = operator ||         self.varType = varType ||         self.isInterval = False ||         if operator in Operator.operatorsC and Operator.operatorsC.index(operator) > 4 \\ ||            or operator in Operator.operatorsD and Operator.operatorsD.index(operator) > 0 \\ ||            or operator in Operator.operatorsS and Operator.operatorsS.index(operator) > 7: ||             self.isInterval = True ||  ||     def __eq__(self; other): ||         assert other in Operator.getOperators() ||         return  self.operator == other ||  ||     def __ne__(self; other): ||         assert other in Operator.getOperators() ||         return self.operator != other ||  ||     def __repr__(self): ||         return str(self.operator) ||  ||     def __strr__(self): ||         return str(self.operator) ||  ||     def getFilter(self; domain; variable; value1; value2; negate; caseSensitive): ||         \""\""Returns orange filter. ||         \""\"" ||         if self.operator == Operator.operatorDef: ||             try: ||                 id = domain.index(variable) ||             except: ||                 error(\""Error: unknown attribute (%s).\"" % variable) ||  ||             if id >= 0: ||                 f = orange.Filter_isDefined(domain=domain) ||                 for v in domain.variables: ||                     f.check[v] = 0 ||                 f.check[variable] = 1 ||             else: # variable is a meta ||                     f = orange.Filter_hasMeta(id = domain.index(variable)) ||         elif self.operator in Operator.operatorsD: ||             f = orange.Filter_values(domain=domain) ||             f[variable] = value1 ||         else: ||             f = orange.Filter_values(domain=domain) ||             if value2: ||                 f[variable] = (Operator._operFilter[str(self.operator)]; value1; value2) ||             else: ||                 f[variable] = (Operator._operFilter[str(self.operator)]; value1) ||             if self.varType == orange.VarTypes.String: ||                 f[variable].caseSensitive = caseSensitive ||         f.negate = negate ||         return f || \""\""\""",,Yes,Yes
21427,fix!,,Yes,Yes
21428,This is a fix for Qt bug (4.3). When Qt is fixed; the setChecked above should suffice,,Yes,Yes
21429,tr = QtGui.QIcon() # fix: trash,,,Yes
21430,Util methods that really shouldn't be here and should be moved outside of this module,,Yes,Yes
21431,TODO: Util methods that really shouldn't be here and should be moved outside of this module,,,Yes
21432,Util methods that really shouldn't be here and should be moved outside of this module,,Yes,Yes
21433,Try fixing some common problems.,,No,Yes
21434,TODO: Should animate (accept) hide.,,No,Yes
21435,TODO: right to left locale,,Yes,Yes
21437,TODO: Remove the set[Widget|Category]Description. The user should,,Yes,Yes
21438,TODO: The palette should override the `setColor`,,Yes,Yes
21440,TODO: The the current layout implementation is BAD (fix is urgent).,,,Yes
21441,Uncheck the text annotation action if needed.,,Yes,Yes
21442,Uncheck the arrow annotation if needed.,,,Yes
21443,TODO: Should also check that the name is real.,,Yes,Yes
21444,should be able to handle missing types better).,,Yes,Yes
21446,TODO: Ask for overwrite confirmation instead,,,Yes
21447,TODO implement __getitem__ that will return a normal array; not Continuous,,Yes,Yes
21449,TODO Basket column.,,,Yes
21450,needed by signalWrapper to know when everything was sent,,,Yes
21456,TODO comboBox looks overly complicated:,,,Yes
21457,- is the argument control2attributeDict needed? doesn't emptyString do the,,No,Yes
21458,fix to setAttributes. This doesn't break anything; but maybe fixes an,,Yes,Yes
21459,A workaround for a bug in Qt,,Yes,Yes
21460,TODO: SmallWidgetButton is used only in OWkNNOptimization.py. (Re)Move.,,No,Yes
21462,TODO Class Searcher: it doesn't seem to be used anywhere,,Yes,Yes
21463,TODO collapsableWidgetBox is used only in OWMosaicDisplay.py; (re)move,,,Yes
21464,TODO Class widgetHider doesn't seem to be used anywhere; remove?,,,Yes
21465,TODO ControllgedList.item2name is probably never used,,No,Yes
21467,The preceding lines should work as per API; but do not; it's probably a PyQt bug as per March 2010.,,,Yes
21469,TODO: parse schema,,Yes,Yes
21470,TODO: parse schema,,,Yes
21471,TODO if row_idx specify multiple rows; one of the following must,,Yes,Yes
21472,TODO: this returns all rows between min(rows) and max(rows): fix!,,,Yes
21473,TODO: Group messages by message_id not by severity,,No,Yes
21474,FIXME: Who was supposed to fill the settings list?,,No,Yes
21475,TODO this method has misleading name (method 'initialize' does what,,No,Yes
21476,TODO similar to settings_to_widget; update_class_defaults does this for,,,Yes
21478,fix values below zero,,,Yes
21481,FIXME: ; [,,Yes,Yes
21483,FIXME:,,No,Yes
21484,TODO: If the task encounters an critical error it might not emit,,Yes,Yes
21485,DEPRECATED (not to mention extremely ugly),,Yes,Yes
21487,grid[0; :] is the x-axis ( columns have widths ),,,Yes
21490,we remove the space needed for separating different attr. values,,,Yes
21491,TODO: poglej kaj je s tem,,,Yes
21493,zgornja vrstica je diskretizirala tabelo in odstranila unused values,,,Yes
21494,TODO: Extend the reporting for multi-class domains,,No,Yes
21497,Columns to filter unknowns by dropping rows.,,No,Yes
21500,# TODO spodaj je se en POZOR; kjer nastavis palette,,Yes,Yes
21503,# TODO tole je zdej minimum size --> najdi drug nacin za resize,,No,Yes
21504,TODO plot se ne animira vec?,,No,Yes
21505,# TODO: legendi se prekrijeta; ce se malo potrudis,,,Yes
21508,self.pgPlotWidget.replot()     #TODO \u0161e zmeri ne vem kaj je tale replot(),,,Yes
21509,TODO: dinami\u010Dno dolo\u010Di \u0161irino glede na vsebino,,,Yes
21511,# TODO: tale if za sqlTable je \u010Dist brezvezen; ker se itak naredi v poizvedba v sql\/u,,Yes,Yes
21512,#TODO: problem se pojavi; ko so bili atributi diskretizirani (npr. iris),,,Yes
21516,TODO: NE delaj tega!,,Yes,Yes
21517,XXX: StratifiedKFold does not support random_state,,,Yes
21518,TODO: replace xxx with sth autogenerated,,,Yes
21519,TODO: why is the whole distribution computed instead of just min\/max,,,Yes
21521,TODO: Add support for visualizing ExperimentResults or remove code for it,,No,Yes
21522,Need a better way to distinguish discretization states,,No,Yes
21523,Information gain of the best split,,Yes,Yes
21528,for example in self.raw_data]  # FIX!,,,Yes
21529,self.scatterplot_item.setSize(size=self.point_width)  # TODO: FIX,,Yes,Yes
21531,for example in self.raw_data]  # FIX!,,,Yes
21532,for example in self.raw_data]  # FIX!,,,Yes
21533,TODO This could be slow! Can it be somehow changed to vector,,Yes,Yes
21535,Fix points exactly on the right boundary.,,,Yes
21536,TODO: Check for no FP or no TP,,,Yes
21537,Fix points exactly on the right boundary.,,Yes,Yes
21539,TODO: rename ScatterViewBox to something general,,,Yes
21540,TODO Move utility classes to another module; so they can be used elsewhere,,Yes,Yes
21542,Implement a proper model with in-place editing.,,Yes,Yes
21543,(Maybe it should be a TableModel with 2 columns),,Yes,Yes
21544,TODO: enable editing of number_of_decimals; scientific format ...,,Yes,Yes
21545,XXX Maybe convert the error into standard,,No,Yes
21546,Information gain of the best split,,Yes,Yes
21547,TODO Basket column.,,Yes,Yes
21549,TODO Basket column.,,,Yes
21550,TODO do we still need this?,,,Yes
21551,TODO Basket column.,,Yes,Yes
21552,XXX: Non linear intensity scaling,,No,Yes
21553,TODO: Implement selection for sql data,,No,Yes
21554,TODO: make sure that int values are OK,,Yes,Yes
21556,TODO: faster check for size limit,,No,Yes
21557,TODO: faster check for size limit,,,Yes
21559,"fix = lambda str: str.replace(\"">\""; \""&gt;\"").replace(\""<\""; \""&lt;\"")",,Yes,Yes
21560,TODO: this is easily extended to Classification Rules-compatible form,,No,Yes
21561,TODO,,Yes,Yes
21563,TODO This context handler is too strict: we only need the same class,,No,Yes
21564,TODO: This should already be a part of palette,,Yes,Yes
21568,TODO: What about metas.,,Yes,Yes
21570,general does not look nice in a super script so we use,,Yes,Yes
21572,TODO: Should include anchors for text layout (both inside and outside).,,No,Yes
21573,TODO: Fix extended selection.,,Yes,Yes
21574,TODO: This may significantly slow down file reading.,,,Yes
21575,TODO: union of indices; ...,,,Yes
21577,TODO: the original intention was to prevent deadlocks. Locks block;,,No,Yes
21578,TODO: This may significantly slow down file reading.,,,Yes
21580,domain roles for all table columns,,Yes,Yes
21581,check whether we have a sparse columns;,,,Yes
21583,first needed.,,Yes,Yes
21585,TODO Implement,,,Yes
21587,check whether we have a sparse columns;,,,Yes
21588,TODO Implement,,,Yes
21590,TODO: prettify the name (pull the class up if it is imported at,,,Yes
21591,TODO how many columns?!,,Yes,Yes
21592,calculate height needed height of an image,,,Yes
21593,TODO: prettify the name (pull the class up if it is imported at,,Yes,Yes
21596,domain roles for all table columns,,Yes,Yes
21600,check whether we have a sparse columns;,,,Yes
21601,TODO Implement,,,Yes
21607,TODO: Get the proper title bar geometry.,,,Yes
21608,TODO: Fix this (subclass even if just to pass a function,,Yes,Yes
21609,functionality is desired (for instance in Orange v2.* Rank widget,,,Yes
21611,only a subset of the columns is selected,,Yes,Yes
21612,(workaround for QTBUG-18490 \/ QTBUG-28631),,,Yes
21613,Select columns,,No,Yes
21615,enforce fixed size but provide a sensible minimum width constraint.,,Yes,Yes
21616,TODO: decrease the max iteration count by the already,,Yes,Yes
21617,enforce fixed size but provide a sensible minimum width constraint.,,Yes,Yes
21618,TODO: decrease the max iteration count by the already,,,Yes
21619,TODO: improve O(N ** 2),,Yes,Yes
21621,Type of sorting to apply on columns,,Yes,Yes
21622,TODO: Add 'Manage\/Add\/Remove' action.,,No,Yes
21623,Restore\/update the row\/columns items descriptions from cache if,,Yes,Yes
21624,TODO: Move\/delegate to (Scene) helpEvent,,No,Yes
21625,TODO: Update\/sync whenever the widget settings change.,,,Yes
21627,computed as needed in this method.,,Yes,Yes
21628,FIXME here it would be better to just get values,,,Yes
21629,TODO: introduce Table.__eq__() ???,,,Yes
21630,TODO: enable drawing similar pairs within reasonable time,,Yes,Yes
21631,TODO: enable drawing similar pairs within reasonable time,,Yes,Yes
21635,better,,,Yes
21636,For columns,,,Yes
21637,Fix points exactly on the right boundary.,,Yes,Yes
21638,Sort order in OWSave widget combo box; lower is better,,,Yes
21639,Sort order in OWSave widget combo box; lower is better,,Yes,Yes
21646,TODO: adapt scatter plot to work on SqlTables (avoid use of X and Y),,No,Yes
21648,(i.e. all NaN columns). `sklearn.preprocessing.Imputer` already,,Yes,Yes
21649,delete=False is a workaround for https:\/\/bugs.python.org\/issue14243,,No,Yes
21650,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21652,Fix unsupported image types using the Pillow.,,Yes,Yes
21653,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
21654,Fix unsupported image types using the Pillow.,,,Yes
21657,TODO - ko kliknes na webview; oznaci item,,,Yes
21658,not needed for the code below; just for the user,,,Yes
21661,Fix fonts on Os X (QTBUG 47206; 40833; 32789),,,Yes
21663,HACK: Preventing calls to QDockWidget.paintEvent() seems to fix the,,Yes,Yes
21664,with support for pre-standard css (needed at least for Qt 4.8),,Yes,Yes
21666,TODO Remove!,,Yes,Yes
21667,TODO keep selection when changing annotation from None to ... whatever,,,Yes
21668,TODO this should be contex setting,,No,Yes
21669,TODO save selection as setting,,No,Yes
21670,TODO: Errors raised from various data checks should be made consistent,,,Yes
21671,TODO: This signal has to disable or hide the combo boxes,,No,Yes
21674,HACK: Prevent closing of streams,,No,Yes
21676,TODO: check this,,,Yes
21677,# TODO: this function is also used in owsieve --> where to put it?,,,Yes
21678,TODO: check this,,No,Yes
21683,value. This is one way of doing it. If you know of a better one;,,,Yes
21684,This is not needed yet because it is imported from owtreeviewer2d :(,,Yes,Yes
21687,Otherwise check if a better match is available in global_contexts,,,Yes
21689,iterate only over visible columns of QTableView,,Yes,Yes
21690,If all columns are hidden,,Yes,Yes
21693,iterate only over visible columns of QTableView,,Yes,Yes
21694,If all columns are hidden,,,Yes
21695,Hack to make sure the correct plugin search path is added. (Github issue #1143),,,Yes
21697,This ugly hack closes the combo when the user selects an item,,Yes,Yes
21698,setItemDelegate(ForColumn) apparently does not take ownership,,No,Yes
21700,Workaround for NumPy locking on Macintosh.,,,Yes
21701,Workaround for NumPy locking on Macintosh.,,Yes,Yes
21704,z index range; increase if needed,,,Yes
21705,Provide a nice green default in case no color function is provided,,Yes,Yes
21707,We store the offsets from the top left corner to move widget properly,,No,Yes
21709,Move the tranform origin to top left; so it stays in place when,,Yes,Yes
21710,The number of columns is already optimal,,Yes,Yes
21712,TODO this kind of cache can lead to all sorts of problems; but numpy,,Yes,Yes
21718,TODO: Name can be set unconditionally when\/if,,,Yes
21719,This is probably not needed in Qt5?,,No,Yes
21720,Does scipy implement a O(n**2) NN chain algorithm?,,,Yes
21721,TODO: component based,,,Yes
21722,TODO: exclude_metas should be disabled by default,,Yes,Yes
21723,TODO: Fix context settings,,No,Yes
21725,per-class patching would be better than per-instance; but we don't,,Yes,Yes
21726,normalization is not really needed.,,,Yes
21728,anything) by not reserving space for unused threshold space,,,Yes
21729,anything) by not reserving space for unused threshold space,,,Yes
21731,TODO: Use QWebFrame.javaScriptWindowObjectCleared,,,Yes
21732,TODO REMOVE,,,Yes
21733,FIXME: There might be a race condition between here and in JS,,No,Yes
21738,Apparently `currentIndexChanged` just isn't good enough...,,Yes,Yes
21740,TODO this check is suboptimal for sparse since get_column_view,,No,Yes
21741,between the two ends,,,Yes
21742,TODO: Remember if we have seen enter with the proper data,,No,Yes
21745,Needed because the pure-Python Unpickler that dill uses can also fail,,No,Yes
21746,Constants to indicate what kind of problem we're dealing with,,,Yes
21747,TODO This is not okay,,Yes,Yes
21748,Constants to indicate what kind of problem we're dealing with,,,Yes
21751,TODO: Implement __eq__ on preprocessors to avoid comparing reprs,,,Yes
21752,TODO: drop this as soon as possible,,Yes,Yes
21754,TODO calculate variance in tree adapter,,Yes,Yes
21755,TODO do we still need this?,,Yes,Yes
21756,maybe 0?,,,Yes
21757,TODO do we still need this?,,,Yes
21759,Needed because the fitter type needs to be set to regression in order,,,Yes
21762,TODO: add (n) if a column with this name is already in domain,,,Yes
21764,TODO: Implement __eq__ on preprocessors to avoid comparing reprs,,Yes,Yes
21767,Don't match nans. This is needed since numpy supports using nan as,,Yes,Yes
21768,TODO There is still something wrong with this,,Yes,Yes
21769,TODO check & transform to correct format,,,Yes
21771,TODO: remove once we make sure Y is always dense.,,Yes,Yes
21772,TODO: Change\/replace the current implementation of ThreadExecutor,,,Yes
21773,TODO: clear the results view?,,No,Yes
21776,(in a thread safe manner) and to implement cooperative cancellation.,,No,Yes
21777,TODO: Rename the module to something that does not conflict with stdlib,,Yes,Yes
21778,TODO: cache,,No,Yes
21780,: Signal emitted when editing operation ends (the item loses edit focus),,No,Yes
21782,Orange mainly deals with `csr_matrix`; but `lil_matrix` is more efficient,,,Yes
21783,TODO Remove reshaping logic when support for numpy==1.9 is dropped,,Yes,Yes
21784,FIXME: Sadly; schema-only settings aren't cleared when non-contextual,,Yes,Yes
21785,only meta columns,,Yes,Yes
21787,Ugly; but needed for backwards compatibility hack below; to allow,,Yes,Yes
21788,TODO this *private* function is called from several widgets to prepare,,,Yes
21789,Backward compatibility fix,,No,Yes
21790,To be removed as the corresponding functionality is implemented above,,,Yes
21791,TODO I have put this function here as a substitute the above `_preprocess`.,,Yes,Yes
21792,TODO: Appears to have been used only in the Distances widget (where it had,,Yes,Yes
21800,TODO: Appears to have been used only in the Distances widget (where it had,,,Yes
21803,Do not mix data between columns,,,Yes
21804,Scale the changes (the largest anchor move is alpha * radius),,Yes,Yes
21806,TODO: There are possible pending __progress_advance queued,,Yes,Yes
21809,This is a workaround,,,Yes
21814,TODO: fix this,,No,Yes
21817,Pearson distance used for clustering of columns does not,,Yes,Yes
21818,handle all zero columns well,,,Yes
21819,# 1) Qt SVG does not implement clipping paths. This is absurd.,,No,Yes
21820,TODO: correct gradient coordinates inside defs,,Yes,Yes
21821,# correct line widths if needed,,,Yes
21822,override HEADER_SCHEMA to define new columns,,,Yes
21823,Iterate through the columns,,No,Yes
21828,TODO: Read\/store in QSettings; record\/sync as soon as added.,,,Yes
21829,TODO: sync between CanvasMainWindow instances?.,,,Yes
21831,TODO: Notify all instances,,,Yes
21832,Should really have a signal `report_ready` or similar to decouple,,Yes,Yes
21833,NOTE: All columns must have size hinting delegates.,,Yes,Yes
21835,workaround for QTBUG-67583,,No,Yes
21836,A hack that prevents segmentation fault with Nvidia drives on Linux if Qt's browser window,,Yes,Yes
21840,TODO: This should be moved to WidgetManager,,No,Yes
21841,avoid creating widgets if not needed,,Yes,Yes
21843,view (maybe move that shortcut here),,,Yes
21844,TODO labels are missing,,Yes,Yes
21845,indices are unused,,,Yes
21847,TODO: Add this into pull request:,,No,Yes
21848,data that contained only the needed attributes. I think that widget should,,No,Yes
21850,TODO -- just guessing; fix this!,,Yes,Yes
21852,TODO: is this needed? Simplify above code (use return instead of else),,,Yes
21853,TODO This is stupid -- needed for FreeViz; basically. Should be fixed,,,Yes
21857,TODO: do we need this?!,,No,Yes
21858,TODO: is this needed? Simplify above code (use return instead of else),,,Yes
21859,TODO This is stupid -- needed for FreeViz; basically. Should be fixed,,Yes,Yes
21861,TODO: Try avoiding this when we move imputation to the widget,,Yes,Yes
21862,Todo: this button introduces some margin at the bottom?!,,No,Yes
21863,TODO: Rename to remove_plot_items,,No,Yes
21864,TODO: I hate `keep_something` and `reset_something` arguments,,,Yes
21866,`get_coordinates` before sampling (very ugly) or call,,,Yes
21867,`self.master.get_coordinates_data` (beyond ugly) or the widget would,,Yes,Yes
21869,Maybe we leave it as it is.,,No,Yes
21870,"a \""sample size\"" slider); points would move around when the sample",,Yes,Yes
21873,Needed for overlapping,,Yes,Yes
21876,TODO -- just guessing; fix this!,,Yes,Yes
21877,TODO: fix this,,No,Yes
21878,Return string labels for the returned matrix columns e.g. 'Mean';,,,Yes
21879,Prepare vartype indices so ready when needed,,Yes,Yes
21881,TODO: This does not work properly,,,Yes
21883,Send a table with only selected columns to output,,Yes,Yes
21884,bins; it is better to assign each their own bin. We will require,,,Yes
21886,will produce too few columns. This causes problems; so we need to,,No,Yes
21887,TODO It probably isn't a very good idea to convert a sparse row,,,Yes
21890,TODO: This is not setting,,No,Yes
21891,'Unused' imports are used in docstrings,,,Yes
21892,TODO: This needs a better check.,,,Yes
21893,implement it with threads,,No,Yes
21894,implement it with threads,,No,Yes
21895,Build up the affinity matrix; using multiscale if needed,,,Yes
21896,Since scipy apparently can't do mode on sparse matrices; cast it to,,Yes,Yes
21902,The only known workaround with native dialog is to use suffix *.*.,,Yes,Yes
21905,TODO: implement top percentile selection,,Yes,Yes
21908,TODO: decrease the max iteration count by the already,,Yes,Yes
21909,updates warnings for displayed columns,,,Yes
21910,FIXME high-dpi screens,,No,Yes
21911,Logitech's Smart Move).,,,Yes
21913,Ugly; but the alternative is to have yet another signal to which,,Yes,Yes
21917,would require changing `OWDataProjectionWidget` in some strange way;,,Yes,Yes
21919,current phase (iterations_needed),,No,Yes
21921,TODO - optimize - after this line is executed;,,Yes,Yes
21922,number of leading columns,,No,Yes
21923,TODO - inconsistent for different variable types,,No,Yes
21924,Otherwise check if a better match is available in global_contexts,,No,Yes
21925,TODO: This needs a better check.,,No,Yes
21927,TODO: Help button,,No,Yes
21928,Is it better to fail then to lose a item slot?,,Yes,Yes
21930,avoid loading\/parsing the columns,,Yes,Yes
21934,: Signal emitted when the preview content parsing ends with an error.,,No,Yes
21935,TODO: Treat all space (THIN SPACE; NO-BREAK SPACE; ...) the same?,,,Yes
21936,Maybe just use unicodedata.normalize('NFKC'; ...) as a converter?,,,Yes
21937,Might be better to always use buffer? (compressed streams are,,,Yes
21940,TODO: Remove arguments that go to call and swallow them in **kwargs?,,Yes,Yes
21941,TODO: Remove arguments that go to call and swallow them in **kwargs?,,Yes,Yes
21943,Fix fonts on Os X (QTBUG 47206; 40833; 32789),,Yes,Yes
21944,workaround for QTBUG-67583,,,Yes
21945,TODO: SmallWidgetButton is used only in OWkNNOptimization.py. (Re)Move.,,No,Yes
21946,TODO collapsableWidgetBox is used only in OWMosaicDisplay.py; (re)move,,Yes,Yes
21948,TODO: Style dependent margins?,,No,Yes
21949,TODO: Check ForegroundRole.,,,Yes
21950,TODO: add other styles (Maybe load corrections from .cfg file?),,,Yes
21952,TODO: Don't clear selection when replotting; rename _replot to,,,Yes
21953,TODO: do something if all are nan; perhaps in on_var_changed,,,Yes
21957,This is apparently needed to advance the bar,,,Yes
21958,TODO: Use intelligent binning from #3896; when it's merged,,Yes,Yes
21960,For multitarget; recursive call by columns,,,Yes
21962,Proper tests of OWSaveBase would require too much mocking; so we test most,,,Yes
21963,dialog; but I see no better solution.,,No,Yes
21964,Proper tests of OWSaveBase would require too much mocking; so we test most,,Yes,Yes
21965,switch from columns to rows for the second test,,,Yes
21968,between columns; normalized,,Yes,Yes
21969,between columns; not normalized,,,Yes
21970,maybe sorted(set(data.data[...])),,No,Yes
21971,Explicitly skip VariableEditor's __init__; this is ugly but we have,,,Yes
21973,when computing distances by columns; we want < 100 rows,,Yes,Yes
21975,Iterate through the columns,,No,Yes
21976,might view `data` (string columns),,Yes,Yes
21979,Use better better precision then double provides.,,,Yes
21980,scaled by this factor to better condition the geometry,,Yes,Yes
21981,better,,Yes,Yes
21982,Map discrete data to 'ints' (or at least what passes as int around,,,Yes
21983,Iterate through the columns,,,Yes
21984,might view `data` (string columns),,Yes,Yes
21985,TODO: warning because of a weird clash?,,No,Yes
21986,for columns,,Yes,Yes
21991,inflates columns with nans,,Yes,Yes
21992,for columns,,Yes,Yes
21995,inflates columns with nans,,Yes,Yes
21996,add columns with source table id and set id,,Yes,Yes
21998,would probably slow down the process - conversion coo to csr,,,Yes
21999,: define the splits of data over columns; and define dendrogram and\/or,,,Yes
22000,return start - fix,,Yes,Yes
22004,: (0.05; 0.95) squeezes the effective range by 5% from both ends,,No,Yes
22007,Send a table with only selected columns to output,,Yes,Yes
22010,self.split_columns_key = None,,Yes,Yes
22012,TODO: rename here,,Yes,Yes
22013,Send a table with only selected columns to output,,,Yes
22014,Euclidean distance; so we use the latter; which is more efficient,,Yes,Yes
22015,_updateMaxTextSize are no longer needed.,,Yes,Yes
22017,is set. XXX: Always use menu; disable Import relative... action?,,Yes,Yes
22018,Is it better to fail then to lose a item slot?,,,Yes
22019,uninformative and would better be silenced.,,Yes,Yes
22020,data could be a np.array. This would raise an error in the future.,,Yes,Yes
22023,FIXME: after setting focus proxy to the spin; the text is highlighted,,,Yes
22025,workaround for collations that are not case sensitive and,,Yes,Yes
22027,Workaround for QTBUG-89910,,No,Yes
22028,extend selection ranges in `selection` to span all row\/columns,,,Yes
22029,row\/columns.,,Yes,Yes
22030,extend ranges in sym_ranges to span all current rows\/columns,,,Yes
22031,extend selection ranges in `selection` to span all row\/columns,,,Yes
22040,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
22041,Needed to collect coverage data,,Yes,Yes
22042,Needed to collect coverage data,,,Yes
22043,Needed to collect coverage data,,,Yes
22044,Needed to collect coverage data,,,Yes
22045,Needed to collect coverage data,,Yes,Yes
22046,Implement abstract method,,,Yes
22047,TODO: Uncomment the following after 0.1.2 release,,,Yes
22049,TODO: Uncomment the following after 0.1.2 release,,,Yes
22050,TODO: Uncomment the following after 0.1.2 release,,Yes,Yes
22052,TODO: Uncomment the following after 0.1.2 release,,Yes,Yes
22053,TODO: y_pred should be binary after 0.1.2 release,,Yes,Yes
22054,TODO: y_pred should be binary after 0.1.2 release,,Yes,Yes
22055,TODO: Uncomment the following after 0.1.2 release,,Yes,Yes
22056,TODO: y_pred should be binary after 0.1.2 release,,,Yes
22058,TODO: remove refs on batch to avoid high mem consumption ? -> need verification,,,Yes
22061,Move model before creating optimizer,,,Yes
22062,Move model before creating optimizer,,,Yes
22063,Move model before creating optimizer,,Yes,Yes
22066,Move model before creating optimizer,,,Yes
22068,Move model before creating optimizer,,Yes,Yes
22069,Move model before creating optimizer,,Yes,Yes
22070,Maybe wont work with XLA,,,Yes
22072,maybe warn about this,,,Yes
22073,hack to have all proc properly sync:,,No,Yes
22076,Needed by windows to release FileHandler in the loggers,,Yes,Yes
22077,TODO: How about XLA GPU ?,,,Yes
22078,Probably related to https:\/\/github.com\/pytorch\/xla\/issues\/2576,,No,Yes
22079,Probably related to https:\/\/github.com\/pytorch\/xla\/issues\/2576,,,Yes
22081,TODO: see issue https:\/\/github.com\/pytorch\/ignite\/issues\/1405,,Yes,Yes
22082,"\""\""\""Patch to fix MNIST download issue as described here: || - https:\/\/github.com\/pytorch\/ignite\/issues\/1737 || - https:\/\/github.com\/pytorch\/vision\/issues\/3500 || \""\""\""",,,Yes
22084,Fill in the text attribute if needed.,,,Yes
22085,"\""\""\"" || This code implements a basic; Twitter-aware tokenizer. ||  || A tokenizer is a function that splits a string of text into words. In || Python terms; we map string and unicode objects into lists of unicode || objects. ||  || There is not a single right way to do tokenizing. The best method || depends on the application.  This tokenizer is designed to be flexible || and this easy to adapt to new domains and tasks.  The basic logic is || this: ||  || 1. The tuple regex_strings defines a list of regular expression ||    strings. ||  || 2. The regex_strings strings are put; in order; into a compiled ||    regular expression object called word_re. ||  || 3. The tokenization is done by word_re.findall(s); where s is the ||    user-supplied string; inside the tokenize() method of the class ||    Tokenizer. ||  || 4. When instantiating Tokenizer objects; there is a single option: ||    preserve_case.  By default; it is set to True. If it is set to ||    False; then the tokenizer will downcase everything except for ||    emoticons. ||  || The __main__ method illustrates by tokenizing a few examples. ||  || I've also included a Tokenizer method tokenize_random_tweet(). If the || twitter library is installed (http:\/\/code.google.com\/p\/python-twitter\/) || and Twitter is cooperating; then it should tokenize a random || English-language tweet. || \""\""\""",,Yes,Yes
22086,The emoticon string gets its own regex so that we can preserve case for them as needed:,,,Yes
22088,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
22090,- [19 Apr 2018] Version 1.0: Fix bug in MLAS (duplicate entries in functional_children).,,,Yes
22091,10 columns of the CoNLL-U file: ID; FORM; LEMMA;...,,Yes,Yes
22092,fix up multi-word token,,Yes,Yes
22095,TODO: deal with UPOS; XPOS; and UFeats,,Yes,Yes
22096,TODO: fix the BaseVocab interface,,,Yes
22099,the number of total classes needed to predict by all tagger classifiers. This is,,,Yes
22101,hack la_ittb,,No,Yes
22103,- [19 Apr 2018] Version 1.0: Fix bug in MLAS (duplicate entries in functional_children).,,Yes,Yes
22104,10 columns of the CoNLL-U file: ID; FORM; LEMMA;...,,Yes,Yes
22105,fix up multi-word token,,Yes,Yes
22110,TODO: add more types of activations and mul,,,Yes
22111,TODO: wrap it into a function; as also used above.,,Yes,Yes
22112,TODO: Layerwise FT can only be done by one card currently.,,Yes,Yes
22114,"\""\""\"" ||   Uniform Quantization Learner. ||   Without buckets; min\/max is calculated per layer; otherwise per bucket_size. ||   Actually with bucket; better performance could be achieved in most time. || \""\""\""",,Yes,Yes
22116,TODO: the design of states is experimental,,Yes,Yes
22122,tranpose the image tensor if needed,,,Yes
22123,needed whatever the execution mode is,,Yes,Yes
22124,couldn't find better way to pass params from input_fn to model_fn,,,Yes
22125,couldn't find better way to pass params from input_fn to model_fn,,Yes,Yes
22127,TODO use tf.map_fn,,,Yes
22128,FIXME cannot build,,Yes,Yes
22129,skip un-initialized variables; which is not needed in the final *.pb file,,,Yes
22130,record the best combination of pruning ratios,,Yes,Yes
22131,TODO: remove loop when net.history supports tuples,,No,Yes
22133,"\""Using the Output Embedding to Improve Language Models\"" (Press & Wolf 2016)",,,Yes
22137,TODO: lr annealing:,,,Yes
22138,FIXME: this is kind of stupid; we supply TensorDatasets to the loader,,Yes,Yes
22139,FIXME: this is kind of stupid; we supply TensorDatasets to the loader,,Yes,Yes
22141,TODO: set seed,,Yes,Yes
22142,TODO: set seed,,,Yes
22143,TODO: Find a better solution for this mess,,,Yes
22144,TODO,,,Yes
22150,TODO: Find a better solution for this mess,,,Yes
22151,TODO,,,Yes
22154,TODO: discuss this as the iterator is executed twice,,Yes,Yes
22159,TODO: make py2.7 compatible,,Yes,Yes
22160,This is an ugly work-around (relating to #56); but,,Yes,Yes
22161,This is an ugly work-around (relating to #56); but,,,Yes
22162,be obsolete once pytorch scalars arrive.,,Yes,Yes
22163,This is a temporary; ugly work-around (relating to #56); but,,Yes,Yes
22166,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
22167,FIXME: When dataset is initialized; X and y do not matter,,,Yes
22169,remove callbacks to have better control over side_effect,,Yes,Yes
22171,TODO: change import to pytorch,,,Yes
22173,FIXME:: this placeholder value as `y` since they are operating,,Yes,Yes
22174,FIXME:: on batch level. This might be easy to trip over; esp.,,,Yes
22176,ugly work-around - torch constructor does not accept np scalars,,,Yes
22179,TODO: check error message more precisely; depending on what,,,Yes
22180,TODO: check error message more precisely; depending on what,,Yes,Yes
22183,FIXME:: this placeholder value as `y` since they are operating,,Yes,Yes
22184,FIXME:: on batch level. This might be easy to trip over; esp.,,,Yes
22185,FIXME:: since this value may look meaningful.,,No,Yes
22190,TODO: check error message more precisely; depending on what,,Yes,Yes
22191,TODO: Remove warning in a future release,,Yes,Yes
22194,"\""\""\""Benchmark to test time and memory performance of History. ||  || Before #312; the timing would be roughly 5 sec and memory usage would || triple. After #312; the timing would be roughly 2 sec and memory usage || roughly constant. ||  || For the reasons; see #306. ||  || \""\""\""",,Yes,Yes
22196,TODO: remove once argument 3 as string is removed; since won't,,,Yes
22198,TODO: Remove warning in release 0.5.0,,No,Yes
22199,TODO: remove this with the next release,,No,Yes
22200,workaround for cuda_dependent_attributes_ being misused as storage,,No,Yes
22201,TODO: Remove class in 0.7,,,Yes
22202,TODO: raise a ValueError instead of a warning,,,Yes
22203,attributes whose name ends in underscore should not be,,No,Yes
22204,TODO: Remove this warning on 0.10 release,,,Yes
22206,TODO: Remove this warning on 0.10 release,,No,Yes
22207,"\""\""\""Neural net base class ||  || This is the most flexible class; not making assumptions on the kind of || task being peformed. Subclass this to create more specialized and || sklearn-conforming classes like NeuralNetClassifier. ||  || \""\""\""",,No,Yes
22208,TODO: remove after some deprecation period; e.g. skorch 0.12,,Yes,Yes
22210,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
22211,TODO: double check that action names are unique?,,Yes,Yes
22213,intent wrong and maybe action wrong,,,Yes
22214,TODO: this needs to be implemented - slots are not reset yet,,Yes,Yes
22215,probably hit something strange,,,Yes
22219,TODO: we can't use tracker filter here to filter for,,No,Yes
22221,TODO need to align X then,,,Yes
22226,TODO questinable thing: to delete begining of stories,,Yes,Yes
22227,TODO need to align X then,,No,Yes
22228,TODO due to the new system; change below,,,Yes
22230,TODO change path so that we could have several,,,Yes
22231,TODO keras policies with different featurizers,,,Yes
22236,TODO to support code creating stories,,,Yes
22238,TODO if so remove this init; else here is an error,,Yes,Yes
22239,TODO update tracker with last action,,No,Yes
22244,TODO do we want to assert if trackers are the same?,,,Yes
22246,TODO max_history was controlling augmentation,,No,Yes
22247,TODO deal with setting self.featurizer directly,,Yes,Yes
22248,TODO that were not actually set,,,Yes
22249,TODO doing too much work here: generate all prior trackers,,No,Yes
22251,TODO unite with padding,,No,Yes
22253,TODO,,,Yes
22255,TODO,,Yes,Yes
22257,TODO for some reason sometimes it creates 1 or 2 trackers,,Yes,Yes
22259,TODO backwards incompatible change. needs to be added to migrations and changelog,,Yes,Yes
22260,TODO During loading this should be checked,,No,Yes
22261,TODO (comparing the persisted version with the current version),,No,Yes
22268,TODO to support code creating stories,,Yes,Yes
22270,TODO find a number or pass it as an argument,,No,Yes
22273,TODO should it be max?,,Yes,Yes
22275,TODO: deprecate this function,,Yes,Yes
22277,It would be better at this point to properly shutdown every,,Yes,Yes
22281,# TODO: check if dir exists,,,Yes
22282,# TODO: check this doesn't mess anything up,,,Yes
22285,unused_checkpoints = set()  # type: Set[Text],,No,Yes
22287,unused_checkpoints -= used_checkpoints,,Yes,Yes
22288,track unused checkpoints for this phase,,No,Yes
22289,add end checkpoint as unused,,Yes,Yes
22290,TODO move it to config and make it configurable,,Yes,Yes
22292,process trackers ended with unused checkpoints further,,Yes,Yes
22293,after we processed all unused checkpoints,,Yes,Yes
22295,track unused checkpoints for this phase,,No,Yes
22297,add end checkpoint as unused,,Yes,Yes
22299,we will remove unused start ones,,Yes,Yes
22300,the process above may generate unused start checkpoints,,Yes,Yes
22301,also there might be generated unused end checkpoints,,Yes,Yes
22305,process trackers ended with unused checkpoints further,,,Yes
22306,TODO: TB - ask vova what this is needed for,,No,Yes
22307,TODO move it to config and make it configurable,,Yes,Yes
22308,track unused checkpoints for this phase,,,Yes
22310,add end checkpoint as unused,,Yes,Yes
22311,process trackers ended with unused checkpoints further,,Yes,Yes
22312,deduplication of finished trackers is needed;,,No,Yes
22313,TODO do not do dict1 == dict2,,,Yes
22314,track unused checkpoints for this phase,,No,Yes
22315,deduplication of finished trackers is needed;,,,Yes
22316,TODO : Not ask a new token if token still valid. Expiration check,,,Yes
22317,TODO move it to config and make it configurable,,Yes,Yes
22318,track unused checkpoints for this phase,,No,Yes
22319,add end checkpoint as unused,,,Yes
22320,process trackers ended with unused checkpoints further,,Yes,Yes
22321,deduplication of finished trackers is needed;,,,Yes
22322,TODO: TB - ensure backward compatibility with old webhooks,,,Yes
22323,TODO: TB - rethink; should read from file and post to simple web channel,,Yes,Yes
22324,TODO: TB - think about making this removal backwards compatible,,,Yes
22325,TODO: deprecate this function,,Yes,Yes
22326,TODO: TB - check if we should really do it this way,,No,Yes
22328,TODO: TB - handle channel is gone!,,No,Yes
22329,TODO: TB - figure out how NLG works with remote core,,,Yes
22332,FIX!,,,Yes
22334,deduplication of finished trackers is needed;,,No,Yes
22335,TODO move it to config and make it configurable,,,Yes
22337,add end checkpoint as unused,,,Yes
22340,deduplication of finished trackers is needed;,,No,Yes
22342,TODO: deprecate this function,,Yes,Yes
22343,TODO: TB - ask vova what this is needed for,,No,Yes
22344,TODO: DEPRECATED - remove in version 0.10,,No,Yes
22345,TODO: TB - start server instead and then run cmd to communicate with,,Yes,Yes
22346,FIX!,,,Yes
22350,TODO: DEPRECATED - remove in version 0.10,,,Yes
22352,TODO: TB - make sure no invalid events are logged,,,Yes
22353,TODO: deprecate this function,,Yes,Yes
22354,TODO: TB - make use of the additional information about the channel,,Yes,Yes
22358,TODO: deprecate this function,,,Yes
22359,TODO: DEPRECATED - remove in version 0.10,,,Yes
22360,TODO: TB - figure out if this condition is a BUG,,,Yes
22361,TODO: TB - make sure the json is valid,,No,Yes
22364,TODO: TB - properly handling failing status codes,,,Yes
22365,is needed to calculate train accuracy,,,Yes
22366,TODO: TB - make sure the json is valid,,No,Yes
22368,TODO: TB - add link to endpoint docs,,,Yes
22369,TODO: TB - properly handling failing status codes,,Yes,Yes
22371,intent wrong and maybe action wrong,,No,Yes
22372,TODO: deprecate this function,,Yes,Yes
22373,TODO: TB - figure out if this condition is a BUG,,No,Yes
22374,TODO: TB - start server instead and then run cmd to communicate with,,Yes,Yes
22375,FIX!,,Yes,Yes
22377,TODO: DEPRECATED - remove in version 0.10,,,Yes
22378,TODO: deprecate this function,,,Yes
22382,TODO: deprecate this function,,,Yes
22384,we will remove unused start ones,,Yes,Yes
22385,TODO: TB - make sure the json is valid,,No,Yes
22386,TODO: TB - make sure no invalid events are logged,,Yes,Yes
22387,TODO: TB - add link to endpoint docs,,No,Yes
22389,TODO: deprecate this function,,,Yes
22390,TODO: TB - handle channel is gone!,,,Yes
22393,TODO: DEPRECATED - remove in version 0.10,,No,Yes
22394,TODO: TB - implement properly for agent \/ bot,,,Yes
22395,TODO: Decide if this should do more,,,Yes
22397,TODO: TB - make sure the json is valid,,No,Yes
22398,TODO: TB - make sure no invalid events are logged,,,Yes
22399,TODO: TB - add link to endpoint docs,,,Yes
22400,TODO: TB - ensure backward compatibility with old webhooks,,,Yes
22405,TODO: DEPRECATED - remove in version 0.10,,,Yes
22406,TODO: TB - implement properly for agent \/ bot,,Yes,Yes
22407,TODO: TB - make sure the json is valid,,No,Yes
22408,TODO: TB - make sure no invalid events are logged,,,Yes
22409,TODO: TB - add link to endpoint docs,,,Yes
22412,TODO: TB - make sure the json is valid,,,Yes
22413,TODO: TB - make sure no invalid events are logged,,Yes,Yes
22414,TODO: TB - add link to endpoint docs,,No,Yes
22416,TODO: deprecate this function,,Yes,Yes
22418,TODO: deprecate this function,,Yes,Yes
22420,Step 8: Maybe copy output and cell state from history,,,Yes
22423,AugmentedMemoizationPolicy also ends with MemoizationPolicy,,,Yes
22424,TODO: this should really only be done when there's a FormPolicy present,,Yes,Yes
22425,no validation needed,,Yes,Yes
22426,TODO: remove when https:\/\/github.com\/sphinx-doc\/sphinx\/issues\/5480 fixed,,Yes,Yes
22427,TODO add policy and confidence back in once #1013 merged,,,Yes
22428,TODO add policy and confidence back in once #1013 merged,,,Yes
22429,TODO add policy and confidence back in once #1013 merged,,,Yes
22432,add trackers with unused checkpoints,,,Yes
22434,1 with unused start checkpoints -> ignored,,Yes,Yes
22435,TODO: Revert old events here?,,Yes,Yes
22436,TODO AS adapt to use asyncio loop,,Yes,Yes
22438,TODO AS this needs fixing,,,Yes
22439,todo: follow,,,Yes
22443,TODO check by sending a request,,,Yes
22444,TODO AS adapt to asyncio loop,,,Yes
22445,TODO AS adapt to asyncio loop,,,Yes
22448,TODO check by sending a request,,,Yes
22449,can be adjusted to taste later if needed;,,Yes,Yes
22450,a bit arbitrary but probably OK,,,Yes
22452,todo follow,,,Yes
22453,TODO check by sending a request,,,Yes
22454,TODO: check if this properly receives UTF-8 data,,,Yes
22457,needed for python 3.5 compatibility,,Yes,Yes
22463,TODO check by sending a request,,,Yes
22466,TODO check by sending a request,,,Yes
22469,TODO: Fix,,No,Yes
22470,TODO: Fix,,,Yes
22473,TODO: make sure priority persists,,No,Yes
22474,TODO: Update priority here,,No,Yes
22475,TODO: Raise no priority error here,,No,Yes
22477,It would be better at this point to properly shutdown every,,,Yes
22478,TODO: find a better way to check this,,No,Yes
22479,TODO: hotfix to append attributes that NLU is adding as a server,,Yes,Yes
22480,TODO: LOCAL make endpoints more configurable; esp ports,,Yes,Yes
22484,It would be better at this point to properly shutdown every,,,Yes
22485,TODO LOCAL: validate namespace json in request,,No,Yes
22487,TODO: find a better way to check this,,,Yes
22489,TODO: find a better way to check this,,No,Yes
22490,TODO: hotfix to append attributes that NLU is adding as a server,,Yes,Yes
22491,TODO LOCAL: validate namespace json in request,,No,Yes
22493,TODO: hotfix to append attributes that NLU is adding as a server,,,Yes
22494,TODO LOCAL: validate namespace json in request,,No,Yes
22497,TODO: I doubt we should allow the NLU interpreter here!,,,Yes
22498,It would be better at this point to properly shutdown every,,Yes,Yes
22499,HACK: this skips loading the interpreter and directly sets it afterwards,,,Yes
22502,needed for python 3.5 compatibility,,Yes,Yes
22504,needed to properly handle async functions in docs,,No,Yes
22512,TODO: u; is this a good thing?,,Yes,Yes
22513,TODO: make representation numpy\/tensor from pytorch,,Yes,Yes
22514,TODO: make message\/update functions pytorch functions,,Yes,Yes
22518,TODO: per node update function,,,Yes
22520,TODO: u; is this a good thing?,,Yes,Yes
22521,TODO: ugly hack,,,Yes
22523,TODO: does it make sense to batch update the nodes?,,No,Yes
22524,FIXME: really using self.x is a bad design here,,,Yes
22525,TODO: add an attribute (g) to h,,No,Yes
22528,TODO: the following two lines is needed for single object,,Yes,Yes
22529,TODO: but not useful or wrong for multi-obj,,No,Yes
22530,TODO: the following two lines is needed for single object,,,Yes
22532,XXX(minjie): could replace the following loop with propagate call.,,,Yes
22533,TODO: we don't need this one anymore,,Yes,Yes
22535,TODO: (lingfan) use gather to speed up,,No,Yes
22536,FIXME: does pytorch has something similar to tf.add_n which sum over a list?,,,Yes
22541,TODO context manager,,,Yes
22543,TODO SBM,,,Yes
22545,TODO (lingfan): use batched dropout once we have better api,,Yes,Yes
22547,TODO: device,,Yes,Yes
22549,TODO: tensorize the loop,,No,Yes
22550,TODO: clear partial messages,,,Yes
22554,FIXME (lingfan): Do we really need the batch API?,,Yes,Yes
22555,TODO,,Yes,Yes
22557,delete all the columns,,,Yes
22558,the rhs of the spmv is the concatenation of all the frame columns,,,Yes
22559,generate dataset if needed,,No,Yes
22560,FIXME: this will only trigger if reduced_msgs is empty.  Remove?,,Yes,Yes
22561,FIXME: this will only trigger if reduced_msgs is empty.  Remove?,,Yes,Yes
22563,TVM_FREE_PYOBJ will be called after it is no longer needed.,,No,Yes
22564,this function is needed for python3,,No,Yes
22565,TODO: dtype,,No,Yes
22569,TODO: support this with g-spmv,,,Yes
22570,TODO: support max,,No,Yes
22571,TODO: keyword attr,,Yes,Yes
22572,TODO: attributes,,,Yes
22574,NOTE: following code will materialize the columns of the input graphs.,,No,Yes
22575,TODO: device context,,No,Yes
22576,TODO: keyword attr,,Yes,Yes
22579,TODO: device context,,No,Yes
22582,TODO: context,,No,Yes
22585,TODO this isn't the best way of running unique.,,,Yes
22586,TODO this isn't an ideal implementation.,,,Yes
22588,TODO we need to enable it after index_copy is implemented.,,,Yes
22589,Implement equation 2 in the paper.,,,Yes
22590,TODO: convert directly from ndarary to python list?,,No,Yes
22592,FIXME (lingfan): handle zero-degree case,,,Yes
22595,FIXME: also take into account,,,Yes
22596,TODO(minjie): Fix these codes in next PR.,,Yes,Yes
22598,"\""\""\"" || Your first example in DGL || ========================= ||  || TODO: either a pagerank or SSSP example || \""\""\""",,Yes,Yes
22600,"\""\""\"" || .. _tutorial-first: ||  || Your first example in DGL || ========================= ||  || TODO: either a pagerank or SSSP example || \""\""\""",,,Yes
22603,"\""\""\"" || Capsule Network || ================ ||  || **Author**: `Jinjing Zhou` ||   || This tutorial explains how to use DGL library and its language to implement the || `capsule network <http:\/\/arxiv.org\/abs\/1710.09829>`__ proposed by Geoffrey Hinton and his team. || The algorithm aims to provide a better alternative to current neural network structures. || By using DGL library; users can implement the algorithm in a more intuitive way. || \""\""\""",,Yes,Yes
22604,TODO should we use concat?,,Yes,Yes
22605,TODO what is the dimension here?,,,Yes
22607,TODO we can't generate a csr_matrix with np.int64 directly.,,,Yes
22610,It's more efficient to add many edges with a pair of list; or better still; with a pair of tensors.,,Yes,Yes
22614,The shape of the input :math:`H^{(0)}` is :math:`N \\times D`; where :math:`N` is the number of nodes and :math:`D` is the number of input features. We can chain up multiple layers as such to produce a node-level representation output with shape :math:`N \\times F`; where :math:`F` is the dimension of the output node feature vector.,,No,Yes
22615,It could be both tedious and inefficient for user to call ``send()`` and ``recv()`` respectively. DGL comes into aid by providing a series of higher level APIs which also increase the performance by operator fusion in the backend ``\/TODO(gaiyu) verify this statement please``.,,Yes,Yes
22617,A better structured implementation would wrap the update procedure as a,,Yes,Yes
22618,These functions are performance critical; so it's better to have efficient,,Yes,Yes
22619,numpy operators if currently missing in the framework. Ideally in the future;,,,Yes
22620,TODO: this isn't an ideal implementation.,,Yes,Yes
22621,"\""\""\"" || PageRank with DGL Message Passing || ================================= ||  || **Author**: Minjie Wang; Quan Gan; Yu Gai; Zheng Zhang ||  || In this section we illustrate the usage of different levels of message || passing API with PageRank on a small graph. In DGL; the message passing and || feature transformations are all **User-Defined Functions** (UDFs). ||  || The goal of this tutorial: to implement PageRank using DGL message passing || interface. || \""\""\""",,,Yes
22622,for more details. (TODO: a link to the document).,,,Yes
22624,thus allows more efficient implementation for you. For example; in the case,,Yes,Yes
22625,Computing this equation is quite efficient because there exists efficient,,Yes,Yes
22627,"\""\""\"" || .. _model-capsule: ||  || Capsule Network || ================ ||  || **Author**: `Jinjing Zhou` ||   || This tutorial explains how to use DGL library and its language to implement the || `capsule network <http:\/\/arxiv.org\/abs\/1710.09829>`__ proposed by Geoffrey || Hinton and his team.  The algorithm aims to provide a better alternative to || current neural network structures.  By using DGL library; users can implement || the algorithm in a more intuitive way. || \""\""\""",,Yes,Yes
22630,"\""\""\"" || .. _model-capsule: ||  || Capsule Network Tutorial || =========================== ||  || **Author**: `Jinjing Zhou`; `Zheng Zhang` ||  || It is perhaps a little surprising that some of the more classical models can also be described in terms of graphs; || offering a different perspective. || This tutorial describes how this is done for the `capsule network <http:\/\/arxiv.org\/abs\/1710.09829>`__. || \""\""\""",,Yes,Yes
22631,way to construct higher level feature from its low levels. Consider a,,,Yes
22632,FIXME:,,,Yes
22633,Python 3.5.2 is unable to pickle torch dtypes; this is a workaround.,,Yes,Yes
22635,TODO here we apply dropout on all vertex representation.,,,Yes
22638,XXX: convert directly from ndarary to python list?,,,Yes
22639,TODO: handle duplicate messages,,Yes,Yes
22640,FIXME: for now; use send_and_recv to implement push,,Yes,Yes
22643,FIXME(minjie): data type,,,Yes
22644,is no edge to node#0 so the send_and_recv is skipped. Fix this,,Yes,Yes
22645,TODO(minjie): hack; cannot rely on keys as the _initializers,,Yes,Yes
22646,now supports non-exist columns.,,Yes,Yes
22650,FIXME (lingfan): not sure about python 2 and 3 str compatibility,,Yes,Yes
22652,Implement R-GCN in DGL,,Yes,Yes
22653,"\""\""\"" || .. currentmodule:: dgl ||  || DGL at a Glance || ========================= ||  || **Author**: `Minjie Wang <https:\/\/jermainewang.github.io\/>`_; Quan Gan; `Jake || Zhao <https:\/\/cs.nyu.edu\/~jakezhao\/>`_; Zheng Zhang ||  || The goal of this tutorial: ||  || - Understand how DGL builds a graph and performs computation on graph from a ||   high level. || - Train a simple graph neural network in DGL to classify nodes in a graph. ||  || At the end of this tutorial; we hope you get a brief feeling of how DGL works. || \""\""\""",,Yes,Yes
22654,The GCN layer can be easily implemented in DGL using the message passing,,Yes,Yes
22655,TODO: either support pickling or get around ctypes pointers using scipy,,Yes,Yes
22656,TODO (lingfan): implement filtered metrics,,Yes,Yes
22658,Implement LGNN in DGL,,Yes,Yes
22659,and implement :math:`\\text{fuse}` as a sparse matrix multiplication.,,,Yes
22660,To implement:,,,Yes
22661,Here; we implement :math:`\\{Pm; Pd\\}` as scipy coo sparse matrix in the datset;,,,Yes
22662,FIXME: cannot use int64,,Yes,Yes
22663,FIXME(minjie): calculate the shuffle index,,Yes,Yes
22667,Efficient semi-supervised learning on graph,,Yes,Yes
22669,DGL supports very efficient subgraph sampling natively to help users,,,Yes
22670,TODO we can't generate a csr_matrix with np.int64 directly.,,,Yes
22676,TODO we can't generate a csr_matrix with np.int64 directly.,,Yes,Yes
22678,TODO: disabled due to torch support,,Yes,Yes
22679,XXX: not enabled for pytorch,,Yes,Yes
22680,It is time to move on to some real models in DGL.,,,Yes
22681,This is a workaround.,,Yes,Yes
22686,append dict of different length columns should fail,,,Yes
22690,We implement a synthetic dataset :class:`data.MiniGCDataset` in DGL. The dataset has 8,,,Yes
22691,degrees; which gives a better performance for this experiment.,,,Yes
22694,TODO (lingfan): check if apply_func is a DGL builtin,,Yes,Yes
22696,"\""\""\"" || .. _model-gat: ||  || Understand Graph Attention Network || ================================== ||  || **Authors:** `Hao Zhang <https:\/\/github.com\/sufeidechabei\/>`_; `Mufei Li || <https:\/\/github.com\/mufeili>`_; `Minjie Wang || <https:\/\/jermainewang.github.io\/>`_  `Zheng Zhang || <https:\/\/shanghai.nyu.edu\/academics\/faculty\/directory\/zheng-zhang>`_ ||  || From `Graph Convolutional Network (GCN) <https:\/\/arxiv.org\/abs\/1609.02907>`_; || we learned that combining local graph structure and node-level features yields || good performance on node classification task. However; the way GCN aggregates || is structure-dependent; which may hurt its generalizability. ||  || One workaround is to simply average over all neighbor node features as in || `GraphSAGE || <https:\/\/www-cs-faculty.stanford.edu\/people\/jure\/pubs\/graphsage-nips17.pdf>`_. || `Graph Attention Network <https:\/\/arxiv.org\/abs\/1710.10903>`_ proposes an || alternative way by weighting neighbor features with feature dependent and || structure free normalization; in the style of attention. ||  || The goal of this tutorial: ||  || * Explain what is Graph Attention Network. || * Demonstrate how it can be implemented in DGL. || * Understand the attentions learnt. || * Introduce to inductive learning. || \""\""\""",,Yes,Yes
22700,# FIXME(minjie): data type,,Yes,Yes
22703,TODO get all edges in the block.,,Yes,Yes
22704,TODO why is this constructed twice?,,,Yes
22705,TODO Why invoking adjacency_matrix twice?,,,Yes
22707,TODO: replace with more efficient PPR estimation,,,Yes
22713,implementation of pull is very slow. Let's manually do it for now.,,Yes,Yes
22714,Here I manually implement multi-processing barrier with RPC.,,,Yes
22717,moderately deep (e.g.\u00A03 layers) GCN would often depend on input features,,No,Yes
22718,We then implement *neighbor smapling* by ``NodeFlow``:,,,Yes
22720,implementation of pull is very slow. Let's manually do it for now.,,,Yes
22723,TODO(minjie): better behavior in the future,,,Yes
22724,"todo need fix for \""both\""",,Yes,Yes
22725,TODO: should replace this with an IR call to make the program,,,Yes
22726,This allows child class to implement their own __init__,,,Yes
22727,"\""\""\""Common implementation of Object generic related logic\""\""\""",,No,Yes
22728,TODO(minjie): very ugly code; should fix this,,Yes,Yes
22729,FIXME(minjie): data type,,,Yes
22730,a more efficient way is to use segment max; we need to implement it in,,Yes,Yes
22732,TODO(zihao): fix -inf issue,,Yes,Yes
22733,Todo: Allow different evaluation metrics,,,Yes
22734,Todo: support categorical classes,,Yes,Yes
22735,Todo: this is not true for all metrics.,,No,Yes
22736,TODO: replace this after implementing frame,,Yes,Yes
22737,FIXME(minjie): data type,,Yes,Yes
22739,Only newly generated nodes are needed for label prediction,,,Yes
22740,TODO: context?,,No,Yes
22744,We hack the msg format here,,Yes,Yes
22745,TODO(minjie): with_edge_id is only reasonable for csr matrix. How to fix?,,Yes,Yes
22746,XXX: assuming networkx iteration order is deterministic,,Yes,Yes
22747,TODO attributes,,,Yes
22748,find common columns and check if their schemes match,,Yes,Yes
22749,concatenate the columns,,No,Yes
22750,"\""\""\""This model shows an example of using dgl.metapath_reachable_graph on the original heterogeneous || graph. ||  || Because the original HAN implementation only gives the preprocessed homogeneous graph; this model || could not reproduce the result in HAN as they did not provide the preprocessing code; and we || constructed another dataset from ACM with a different set of papers; connections; features and || labels. || \""\""\""",,,Yes
22751,hack to dodge the potential bugs of to_networkx,,,Yes
22754,TODO: add subsampling to new sampler,,,Yes
22756,TODO: check if there exists minus sign and if gamma should be used here(jin),,,Yes
22757,TODO(zhengda) fix this later,,,Yes
22758,TODO: check if use self.gamma,,,Yes
22761,which we implement in MXNet,,,Yes
22763,TODO: check if use self.gamma,,,Yes
22768,Here; you implement :math:`\\{Pm; Pd\\}` as a SciPy COO sparse matrix in the dataset;,,,Yes
22769,essential building block. The tutorial ends with a simple optimization that,,,Yes
22772,Fix for torch 1.3.1,,No,Yes
22773,TODO(BarclayII): this is a temporary fix of memory leakage in PyTorch,,Yes,Yes
22774,Hack the case when we are working with a single graph.,,,Yes
22775,Only newly generated nodes are needed for label prediction,,,Yes
22778,TODO: either support pickling or get around ctypes pointers using scipy,,Yes,Yes
22779,XXX(minjie): a temporary hack to detect Nodeflow object,,,Yes
22781,Fix the number of threads to 1 on kvstore,,,Yes
22783,input format is differnet than training; thus rehybridization is needed.,,Yes,Yes
22784,NOTE: following code will materialize the columns of the input graphs.,,,Yes
22785,a more efficient way is to use segment max; we need to implement it in,,Yes,Yes
22786,a more efficient way is to use segment sum\/max; we need to implement,,Yes,Yes
22788,TODO: confirm if this is necessary for MXNet and Tensorflow.  If so; we need,,Yes,Yes
22791,Our implementation is much efficient because we do not need to,,,Yes
22794,alignment and make a copy if needed. The functionality is better in TF's main repo.,,No,Yes
22795,TODO: can we standardize this?,,No,Yes
22798,TODO: can we standardize this?,,,Yes
22803,TODO: we should store a storage version number in later releases.,,,Yes
22806,TODO: we should store a storage version number in later releases.,,No,Yes
22807,TODO: confirm if this is necessary for MXNet and Tensorflow.  If so; we need,,,Yes
22809,TODO: can we standardize this?,,,Yes
22811,TODO(0.5 release; xiangsx) need to handle BLOCK,,,Yes
22813,TODO: can we standardize this?,,,Yes
22814,g is no longer needed. Free memory.,,,Yes
22815,TODO(minjie): temporary hack,,Yes,Yes
22824,TODO: can we standardize this?,,No,Yes
22827,Pickling torch dtypes could be problemetic; this is a workaround.,,,Yes
22828,directly updating columns.,,Yes,Yes
22829,pad columns that are not provided in the other frame with initial values,,,Yes
22830,TODO(minjie): hack; cannot rely on keys as the _initializers,,Yes,Yes
22832,XXX(minjie): There is a bug in MXNet's autograd system when one of the inputs,,,Yes
22833,input gradients to be zero. Fix this by enforcing all the inputs to require,,,Yes
22834,XXX(minjie): Normally; the copy_to here is unnecessary. However; TF has this,,,Yes
22835,TODO: tmp hack,,,Yes
22837,TODO(zhengda) this is a temporary fix. We need to make initialize work,,No,Yes
22840,TODO: can we standardize this?,,,Yes
22843,XXX: assuming networkx iteration order is deterministic,,,Yes
22844,Todo (Mufei) Replace the syntax g.nodes[...].ndata[...] with g.nodes[...][...],,,Yes
22846,(TODO) (BarclayII) DGL distributed fails with bus error; freezes; or other,,Yes,Yes
22847,The following code is a fix to the PyTorch-specific issue in,,,Yes
22849,this function does not work.  I'm again skipping this step as a workaround.,,Yes,Yes
22850,Our implementation is much efficient because we do not need to,,Yes,Yes
22851,move to device,,Yes,Yes
22853,After idtype and device get properly implemented; we should remove these two,,,Yes
22854,TODO: check if items match output nodes\/edges,,,Yes
22855,If you have an undirected graph; it is better to convert it,,,Yes
22857,here is how you can implement GraphSAGE convolution in DGL by your own.,,Yes,Yes
22858,-  :ref:`Writing Efficient Message Passing,,,Yes
22860,-  ``graph_edges.csv``: containing three columns:,,Yes,Yes
22863,maybe there's more efficient way?,,No,Yes
22866,''' || Created on Oct 10; 2018 || Tensorflow Implementation of Neural Graph Collaborative Filtering (NGCF) model in: || Wang Xiang et al. Neural Graph Collaborative Filtering. In SIGIR 2019. || @author: Xiang Wang (xiangwang@u.nus.edu) || ''',,Yes,Yes
22867,"\""\""\"" || Introduction of Neighbor Sampling for GNN Training || ================================================== ||  || In :doc:`previous tutorials <1_introduction>` you have learned how to || train GNNs by computing the representations of all nodes on a graph. || However; sometimes your graph is too large to fit the computation of all || nodes in a single GPU. ||  || By the end of this tutorial; you will be able to ||  || -  Understand the pipeline of stochastic GNN training. || -  Understand what is neighbor sampling and why it yields a bipartite ||    graph for each GNN layer. || \""\""\""",,,Yes
22868,aggregation is often too costly since the nodes needed for input,,Yes,Yes
22869,You can see that this method uses much fewer nodes needed in message,,Yes,Yes
22870,are needed on the first GNN layer for this minibatch.,,Yes,Yes
22871,whose input features are needed on the first GNN layer for this minibatch.,,,Yes
22873,Putting them together; you can implement a GraphSAGE convolution for,,,Yes
22874,Get the first two columns which is the node ID and node type.,,No,Yes
22877,This is showing how to implement an R-GCN from scratch.  DGL provides a more,,Yes,Yes
22883,"\""\""\""gengraph.py\r || \r ||    Generating and manipulaton the synthetic graphs needed for the paper's experiments.\r || \""\""\""",,,Yes
22884,Implement skip connection,,Yes,Yes
22887,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
22888,"\""\""\""Feature extraction blocks. || Feature or Multi-Feature extraction is a key component in object detection. || Class predictor\/Box predictor are usually applied on feature layer(s). || A good feature extraction mechanism is critical to performance. || \""\""\""",,,Yes
22890,append sentinel values at both ends,,,Yes
22891,move images to proper subfolders,,,Yes
22901,If you have read our introductory [tutorial](http:\/\/gluon.mxnet.io\/chapter08_computer-vision\/object-detection.html) of SSD; you may have better idea how it works.,,,Yes
22902,the name convention for ssd models is: 'ssd_size_basename_dataset',,No,Yes
22903,the image from -10 to 10 degrees; and crop the image with padding if needed.,,Yes,Yes
22905,Later we'll show how to implement it.,,,Yes
22906,#NAME?,,No,Yes
22908,TODO; print several images,,No,Yes
22909,"\""\""\""Dive deep into SSD training: 3 tips to boost performance || ============================================================ ||  || In the previous tutorial :ref:`sphx_glr_build_examples_detection_train_ssd_voc.py`; we briefly went through || the fundamental APIs that help building the training pipeline of SSD. ||  || In this article; we will dive deep into the details and introduce something critical || to reproduce SOTA that you may never know by reading the paper and tech reports. ||  || .. contents:: :local: ||  || \""\""\""",,Yes,Yes
22910,But the question is; what is the proper way to calculate ``N``? Should we sum up,,Yes,Yes
22912,In our experiments; batch-wise norm is always better on Pascal VOC dataset;,,Yes,Yes
22914,resume checkpoint if needed,,,Yes
22916,Take bounding boxes by slice columns from 0 to 4,,,Yes
22917,use valid only; loading training split is very slow,,Yes,Yes
22919,use valid only; loading training split is very slow,,Yes,Yes
22920,fix batchnorm; fix first stage; etc...,,,Yes
22921,"\""\""\""5. Train Faster-RCNN end-to-end on PASCAL VOC || ================================================ ||  || This tutorial goes through the basic steps of training a Faster-RCNN object detection model || provided by GluonCV. || Specifically; we show how to build a state-of-the-art Faster-RCNN model by stacking GluonCV components. ||  ||  || .. hint:: ||  ||     You can skip the rest of this tutorial and start training your SSD model ||     right away by downloading this script: ||  ||     :download:`Download train_faster_rcnn.py<..\/..\/..\/scripts\/detection\/faster_rcnn\/train_faster_rcnn.py>` ||  ||     Example usage: ||  ||     Train a default resnet50_v2a model with Pascal VOC on GPU 0: ||  ||     .. code-block:: bash ||  ||         python train_faster_rcnn.py --gpus 0 ||  ||     Train a resnet50_v2a model on GPU 0;1;2;3: ||  ||     .. code-block:: bash ||  ||         python train_faster_rcnn.py --gpus 0;1;2;3 --network resnet50_v2a ||  ||     Check the supported arguments: ||  ||     .. code-block:: bash ||  ||         python train_faster_rcnn.py --help ||  ||  || .. hint:: ||  ||     Since lots of contents in this tutorial is very similar to :doc:`.\/train_ssd_voc`; you can skip any part ||     if you feel comfortable. ||  || \""\""\""",,,Yes
22923,A handy DataLoader would be very convenient for us to apply different transforms and aggregate data into mini-batches.,,,Yes
22924,the image from -10 to 10 degrees; and crop the image with padding if needed.,,,Yes
22927,"\""\""\""7. Train YOLOv3 on PASCAL VOC || ================================ ||  || This tutorial goes through the basic steps of training a YOLOv3 object detection model || provided by GluonCV. ||  || Specifically; we show how to build a state-of-the-art YOLOv3 model by stacking GluonCV components. ||  ||  || .. hint:: ||  ||     You can skip the rest of this tutorial and start training your YOLOv3 model ||     right away by downloading this script: ||  ||     :download:`Download train_yolo3.py<..\/..\/..\/scripts\/detection\/yolo\/train_yolo3.py>` ||     or a random shape training script: ||     :download:`Download train_yolo3_rand_size.py<..\/..\/..\/scripts\/detection\/yolo\/train_yolo3_rand_size.py>` ||     Random shape training requires more GPU memory but generates better results. ||  ||     Example usage: ||  ||     Train a default darknet53 model with Pascal VOC on GPU 0: ||  ||     .. code-block:: bash ||  ||         python train_yolo3(_rand_size).py --gpus 0 ||  ||     Train a darknet53 model on GPU 0;1;2;3 with synchronize BatchNorm: ||  ||     .. code-block:: bash ||  ||         python train_yolo3(_rand_size).py --gpus 0;1;2;3 --network darknet53 --syncbn ||  ||     Check the supported arguments: ||  ||     .. code-block:: bash ||  ||         python train_yolo3(_rand_size).py --help ||  ||  || .. hint:: ||  ||     Since lots of contents in this tutorial is very similar to :doc:`.\/train_ssd_voc`; you can skip any part ||     if you feel comfortable. ||  || \""\""\""",,,Yes
22929,A handy DataLoader would be very convenient for us to apply different transforms and aggregate data into mini-batches.,,Yes,Yes
22930,fix batchnorm; fix first stage; etc...,,,Yes
22931,use valid only; loading training split is very slow,,Yes,Yes
22932,use valid only; loading training split is very slow,,,Yes
22933,Following the convention used in MXNet; we recommand a LST file which is a plain text list file to store labels.,,Yes,Yes
22934,"\""\""\""2. Train Mask RCNN end-to-end on MS COCO || =========================================== ||  || This tutorial goes through the steps for training a Mask R-CNN [He17]_ instance segmentation model || provided by GluonCV. ||  || Mask R-CNN is an extension to the Faster R-CNN [Ren15]_ object detection model. || As such; this tutorial is also an extension to :doc:`..\/examples_detection\/train_faster_rcnn_voc`. || We will focus on the extra work on top of Faster R-CNN to show how to use GluonCV components || to construct a Mask R-CNN model. ||  || It is highly recommended to read the original papers [Girshick14]_; [Girshick15]_; [Ren15]_; [He17]_ || to learn more about the ideas behind Mask R-CNN. || Appendix from [He16]_ and experiment detail from [Lin17]_ may also be useful reference. ||  || .. hint:: ||  ||     Please first go through this :ref:`sphx_glr_build_examples_datasets_mscoco.py` tutorial to ||     setup MSCOCO dataset on your disk. ||  || .. hint:: ||  ||     You can skip the rest of this tutorial and start training your Mask RCNN model ||     right away by downloading this script: ||  ||     :download:`Download train_mask_rcnn.py<..\/..\/..\/scripts\/instance\/mask_rcnn\/train_mask_rcnn.py>` ||  ||     Example usage: ||  ||     Train a default resnet50_v1b model with COCO dataset on GPU 0: ||  ||     .. code-block:: bash ||  ||         python train_mask_rcnn.py --gpus 0 ||  ||     Train on GPU 0;1;2;3: ||  ||     .. code-block:: bash ||  ||         python train_mask_rcnn.py --gpus 0;1;2;3 ||  ||     Check the supported arguments: ||  ||     .. code-block:: bash ||  ||         python train_mask_rcnn.py --help ||  || \""\""\""",,,Yes
22935,fix seed in this tutorial,,Yes,Yes
22937,load checkpoint if needed,,No,Yes
22938,"\""\""\""1. Export trained GluonCV network to JSON || ============================================ ||  || It is awesome if you are enjoy using GluonCV in Python for training and testing. || At some point; you might ask: \""Is it possible to deploy the existing models to somewhere out of Python environments?\"" ||  || The answer is \""Absolutely!\""; and it's super easy actually. ||  || This article will show you how to export networks\/models to be used somewhere other than Python. ||  || \""\""\""",,Yes,Yes
22940,use valid only; loading training split is very slow,,,Yes
22941,"\""\""\""8. Finetune a pretrained detection model || ============================================ ||  || Fine-tuning is commonly used approach to transfer previously trained model to a new dataset. || It is especially useful if the targeting new dataset is relatively small. ||  || Finetuning from pre-trained models can help reduce the risk of overfitting. || Finetuned model may also generalizes better if the previously used dataset is in the similar domain of the new dataset. ||  || This tutorial opens up a good approach for fine-tuning object detection models || provided by GluonCV. || More Specifically; we show how to use a customized Pikachu dataset and illustrate the finetuning fundamentals step by step. || You will be familiarize the steps and modify it to fit your own object detection projects. ||  || \""\""\""",,Yes,Yes
22942,First we will start with a nice Pikachu dataset generated by rendering 3D models on random real-world scenes.,,Yes,Yes
22943,Therefore finetuning may converge significantly faster and better in some situations.,,,Yes
22953,fix batchnorm; fix first stage; etc...,,Yes,Yes
22954,"\""\""\""Prepare the Kinetics400 dataset || ============================ ||  || `Kinetics400 <https:\/\/deepmind.com\/research\/open-source\/kinetics>`_  is an action recognition dataset || of realistic action videos; collected from YouTube. With 306;245 short trimmed videos || from 400 action categories; it is one of the largest and most widely used dataset in the research || community for benchmarking state-of-the-art video action recognition models. This tutorial || will go through the steps of preparing this dataset for GluonCV. ||  ||  || Download || -------- ||  || Please refer to the `official website <https:\/\/github.com\/activitynet\/ActivityNet\/tree\/master\/Crawler\/Kinetics>`_ on how to download the videos. || Note that the downloaded videos will consume about 450G disk space; make sure there is enough space before downloading. The crawling process can take several days. ||  || Once download is complete; please rename the folder names (since class names have white space) for ease of processing. Suppose the videos are || downloaded to ``~\/.mxnet\/datasets\/kinetics400``; there will be three folders in it: ``annotations``; ``train`` and ``val``. You can use the following command to || rename the folder names: ||  || .. code-block:: bash ||  ||    # sudo apt-get install detox ||    detox -r train\/ ||    detox -r val\/ ||  || Decode into frames || ------------------ ||  || The easiest way to prepare the videos in frames format is to download helper script || :download:`kinetics400.py<..\/..\/..\/scripts\/datasets\/kinetics400.py>` and run the following command: ||  || .. code-block:: bash ||  ||    python kinetics400.py --src_dir ~\/.mxnet\/datasets\/kinetics400\/train --out_dir ~\/.mxnet\/datasets\/kinetics400\/rawframes_train --decode_video --new_width 450 --new_height 340 ||    python kinetics400.py --src_dir ~\/.mxnet\/datasets\/kinetics400\/val --out_dir ~\/.mxnet\/datasets\/kinetics400\/rawframes_val --decode_video --new_width 450 --new_height 340 ||  || This script will help you decode the videos to raw frames. We specify the width and height of frames for resizing because this will save lots of disk space without losing much accuracy. || All the resized frames will consume 2.9T disk space. If we don't specify the dimension; the original decoded frames will consume 6.8T disk space. || The data preparation process may take a while. The total time to prepare the dataset depends on your machine. For example; it takes about 8 hours on an AWS EC2 instance with EBS and using 56 workers. ||  ||  || Generate the training files || --------------------------- ||  || The last step is to generate training files for standard data loading. You can run the helper script as: ||  || .. code-block:: bash ||  ||    python kinetics.py --build_file_list --frame_path ~\/.mxnet\/datasets\/kinetics400\/rawframes_train --subset train --shuffle ||    python kinetics.py --build_file_list --frame_path  ~\/.mxnet\/datasets\/kinetics400\/rawframes_val --subset val --shuffle ||  || Now you can start training your action recognition models on Kinetics400 dataset. ||  || .. note:: ||  ||    You need at least 4T disk space to download and extract the dataset. SSD ||    (Solid-state disks) is preferred over HDD because of faster speed. ||  ||    You may need to install ``Cython`` and ``mmcv`` by ``pip install Cython mmcv``. || \""\""\""",,Yes,Yes
22955,semantic segmentation models require fixed data shape,,Yes,Yes
22958,"\""\""\""Prepare the Kinetics400 dataset || ================================== ||  || `Kinetics400 <https:\/\/deepmind.com\/research\/open-source\/kinetics>`_  is an action recognition dataset || of realistic action videos; collected from YouTube. With 306;245 short trimmed videos || from 400 action categories; it is one of the largest and most widely used dataset in the research || community for benchmarking state-of-the-art video action recognition models. This tutorial || will go through the steps of preparing this dataset for GluonCV. ||  ||  || Download || -------- ||  || Please refer to the `official website <https:\/\/github.com\/activitynet\/ActivityNet\/tree\/master\/Crawler\/Kinetics>`_ on how to download the videos. || Note that the downloaded videos will consume about 450G disk space; make sure there is enough space before downloading. The crawling process can take several days. ||  || Once download is complete; please rename the folder names (since class names have white space and parenthese) for ease of processing. Suppose the videos are || downloaded to ``~\/.mxnet\/datasets\/kinetics400``; there will be three folders in it: ``annotations``; ``train`` and ``val``. You can use the following command to || rename the folder names: ||  || .. code-block:: bash ||  ||    # sudo apt-get install detox ||    detox -r train\/ ||    detox -r val\/ ||  || Decode into frames || ------------------ ||  || If you decide to train your model using video data directly; you can skip this section. ||  || The easiest way to prepare the videos in frames format is to download helper script || :download:`kinetics400.py<..\/..\/..\/scripts\/datasets\/kinetics400.py>` and run the following command: ||  || .. code-block:: bash ||  ||    python kinetics400.py --src_dir ~\/.mxnet\/datasets\/kinetics400\/train --out_dir ~\/.mxnet\/datasets\/kinetics400\/rawframes_train --decode_video --new_width 450 --new_height 340 ||    python kinetics400.py --src_dir ~\/.mxnet\/datasets\/kinetics400\/val --out_dir ~\/.mxnet\/datasets\/kinetics400\/rawframes_val --decode_video --new_width 450 --new_height 340 ||  || This script will help you decode the videos to raw frames. We specify the width and height of frames for resizing because this will save lots of disk space without losing much accuracy. || All the resized frames will consume 2.9T disk space. If we don't specify the dimension; the original decoded frames will consume 6.8T disk space. || The data preparation process may take a while. The total time to prepare the dataset depends on your machine. For example; it takes about 8 hours on an AWS EC2 instance with EBS and using 56 workers. ||  ||  || Generate the training files || --------------------------- ||  || The last step is to generate training files for standard data loading. You can run the helper script as: ||  || .. code-block:: bash ||  ||    python kinetics400.py --build_file_list --frame_path ~\/.mxnet\/datasets\/kinetics400\/rawframes_train --subset train --shuffle ||    python kinetics400.py --build_file_list --frame_path  ~\/.mxnet\/datasets\/kinetics400\/rawframes_val --subset val --shuffle ||  || Now you can start training your action recognition models on Kinetics400 dataset. ||  || .. note:: ||  ||    You need at least 4T disk space to download and extract the dataset. SSD ||    (Solid-state disks) is preferred over HDD because of faster speed. ||  ||    You may need to install ``Cython`` and ``mmcv`` by ``pip install Cython mmcv``. || \""\""\""",,,Yes
22959,I3D is proposed to improve C3D model by inflating from 2D models.,,Yes,Yes
22960,"\""\""\""8. Extracting features from I3D models || ========================================= ||  || This is a video action recognition tutorial using Gluon CV toolkit; a step-by-step example. || The readers should have basic knowledge of deep learning and should be familiar with Gluon API. || New users may first go through `A 60-minute Gluon Crash Course <http:\/\/gluon-crash-course.mxnet.io\/>`_. || You can `Start Training Now`_ or `Dive into Deep`_. ||  || Feature extraction is a very useful tool to have when you don't have large annotated dataset or don't have the || computing resources to train a model for your use cases. In this tutorial; we provide a simple solution. || The only thing you need to prepare is a text file containing the video paths; we will take care of the rest. || You can extract all kinds of features from many popular pre-trained models using a single command line. ||  || .. note:: ||  ||     Feel free to skip the tutorial because the feature extraction script is self-complete and ready to launch. ||  ||     :download:`Download Full Python Script: feat_extract.py<..\/..\/..\/scripts\/action-recognition\/feat_extract.py>` ||  ||     For more command options; please run ``python feat_extract.py -h`` ||     Please checkout the `model_zoo <..\/model_zoo\/index.html#action_recognition>`_ to select your preferred pretrained model. ||  ||  || \""\""\""",,Yes,Yes
22961,"\""\""\""10. Introducing Decord: an efficient video reader || ==================================================== ||  || Training deep neural networks on videos is very time consuming. For example; training a state-of-the-art SlowFast network || on Kinetics400 dataset using a server with 8 V100 GPUs takes more than 10 days. Slow training causes long research cycles || and is not friendly for new comers and students to work on video related problems. There are several reasons causing the slowness; || big batch of data; inefficiency of video reader and huge model computation. ||  || In this tutotial; we start to solve this problem by introduing a new video reader; `Decord <https:\/\/github.com\/zhreshold\/decord>`_. || Decord is efficient and flexible. It provides convenient video slicing methods based on a wrapper on top of hardware accelerated video decoders; || e.g. FFMPEG\/LibAV and Nvidia Codecs. It is designed to handle awkward video shuffling experience in order to provide smooth experiences || similar to random image loader for deep learning. In additin; it works cross-platform; e.g.; Linux; Windows and Mac OS. ||  || \""\""\""",,Yes,Yes
22962,In conclusion; Decord is an efficient and flexible video reader. It supports get_batch; GPU loading; fast random access; etc; which is,,,Yes
22963,"\""\""\""1. Distributed training of deep video models || ================================================ ||  || Training deep neural networks on videos is very time consuming. For example; training a state-of-the-art SlowFast network [Feichtenhofer18]_ || on Kinetics400 dataset using a server with 8 V100 GPUs takes more than 10 days. Slow training causes long research cycles || and is not friendly for new comers and students to work on video related problems. ||  || Using distributed training is a natural choice. Spreading the huge computation over multiple machines can speed up training || a lot. However; only a few open sourced Github repositories on video understanding support distributed training; || and they often lack documentation for this feature. || Besides; there is not much information\/tutorial online on how to perform distributed training for deep video models. ||  || Hence; we provide a simple tutorial here to demonstrate how to use our code to perform distributed training of SlowFast models || on Kinetics400 dataset. ||  || \""\""\""",,Yes,Yes
22965,Before kickstarting the actual distributed training; it is better to perform some sanity checks to make sure the communication is good.,,Yes,Yes
22966,If you would like to use a bigger 3D model (e.g.; I3D) on a larger dataset (e.g.; Kinetics400);,,Yes,Yes
22967,Try fine-tuning other SOTA video models on your own dataset and see how it goes.,,Yes,Yes
22969,TODO: Now; We use OrigHRBottleneck to match with the origial implementation. You,,Yes,Yes
22970,resume checkpoint if needed,,Yes,Yes
22973,muxing queue size bug workaround:,,Yes,Yes
22974,TODO: multiscale corner cropping,,Yes,Yes
22975,TODO: need to add zero initialized BN; also the conv output,,,Yes
22976,Disable tutorial if needed,,,Yes
22978,"\""\""\""3. Extracting video features from pre-trained models || ======================================================= ||  || Feature extraction is a very useful tool when you don't have large annotated dataset or don't have the || computing resources to train a model from scratch for your use case. It's also useful to visualize what the model have learned. || In this tutorial; we provide a simple unified solution. || The only thing you need to prepare is a text file containing the information of your videos (e.g.; the path to your videos); || we will take care of the rest. || You can extract strong video features from many popular pre-trained models in the GluonCV video model zoo using a single command line. ||  || .. note:: ||  ||     Feel free to skip the tutorial because the feature extraction script is self-complete and ready to launch. ||  ||     :download:`Download Full Python Script: feat_extract_pytorch.py<..\/..\/..\/scripts\/action-recognition\/feat_extract_pytorch.py>` ||  ||     Please checkout the `model_zoo <..\/model_zoo\/index.html#action_recognition>`_ to select your preferred pretrained model. ||  ||     ``python feat_extract_pytorch.py --config-file CONFIG`` ||  ||  || \""\""\""",,,Yes
22979,Try fine-tuning these SOTA video models on your own dataset and see how it goes.,,Yes,Yes
22981,input format is differnet than training; thus rehybridization is needed.,,,Yes
22982,"\""\""\""5. DistributedDataParallel (DDP) Framework || ======================================================= ||  || Training deep neural networks on videos is very time consuming. || For example; training a state-of-the-art SlowFast network on Kinetics400 dataset (with 240K 10-seconds short videos) || using a server with 8 V100 GPUs takes more than 10 days. || Slow training causes long research cycles and is not friendly for new comers and students to work on video related problems. || Using distributed training is a natural choice. || Spreading the huge computation over multiple machines can speed up training a lot. || However; only a few open sourced Github repositories on video understanding support distributed training; || and they often lack documentation for this feature. || Besides; there is not much information\/tutorial online on how to perform distributed training for deep video models. ||  || Hence; we provide a simple tutorial here to demonstrate how to use our DistributedDataParallel (DDP) framework to perform || efficient distributed training. Note that; even in a single instance with multiple GPUs; || DDP should be used and is much more efficient that vanilla dataparallel. ||  ||  || \""\""\""",,,Yes
22985,python train_ddp_pytorch.py --config-file XXX.yaml,,No,Yes
22986,"\""\""\""03. Multiple object tracking with pre-trained SMOT models || ============================================================= ||  || In this tutorial; we present a method; || called `Single-Shot Multi Object Tracking (SMOT) <https:\/\/arxiv.org\/abs\/2010.16031>`_; to perform multi-object tracking. || SMOT is a new tracking framework that converts any single-shot detector (SSD) model into an online multiple object tracker; || which emphasizes simultaneously detecting and tracking of the object paths. || As an example below; we directly use the SSD-Mobilenet object detector pretrained on COCO from :ref:`gluoncv-model-zoo` || and perform multiple object tracking on an arbitrary video. || We want to point out that; SMOT is very efficient; its runtime is close to the runtime of the chosen detector. ||  || \""\""\""",,,Yes
22987,set anchors if needed,,No,Yes
22988,TODO: convert the return to an object class or maybe dictionary,,No,Yes
22990,The dataset supports random split as well,,Yes,Yes
22991,"\""\""\""03. Train classifier or detector with HPO using GluonCV Auto task || ==================================================================== ||  || The previous image classification example shows the basic usages to train\/evaluate\/predict || using estimators provided by `gluoncv.auto.estimators`. Similarly; you can train object detectors || using  `SSDEstimator`; `YOLOv3Estimator`; `CenterNetEstimator`; `FasterRCNNEstimator`. ||  || In this tutorial; we will move forward a little bit; into the hyper-parameter tunning space! || We will show you how to offload an experiment to the backend HPO searcher; to offer better result if || computational cost is abundant. || \""\""\""",,Yes,Yes
22992,in order to achieve better results,,,Yes
22993,set anchors if needed,,No,Yes
22994,TODO: @ClemDoum maybe not the best place to ensure consistency,,Yes,Yes
22998,TODO: handle use_learning = True,,,Yes
23000,TODO: update engine with builtin parsers using builtin_byte_array,,Yes,Yes
23001,TODO: dump as json + use PyCRFSuite serialization,,No,Yes
23002,TODO: if possible avoid looping on the tokens for better efficiency,,Yes,Yes
23003,TODO: if possible avoid looping on the tokens for better efficiency,,Yes,Yes
23004,TODO: Find a way to avoid tagging multiple times,,,Yes
23005,TODO: Find a way to avoid tagging multiple times,,Yes,Yes
23006,TODO handle case properly but can be tricky with the synonyms mapping,,Yes,Yes
23008,TODO: put it in a capitalization config in the probabilistic parser,,Yes,Yes
23009,Hack for Rust parallelism (we could use istitle but it does not exists),,Yes,Yes
23010,Validate format and filter out unused data,,No,Yes
23011,This is a hack; here we don't care what language is actually used to,,,Yes
23013,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
23019,TODO: missing docstring,,No,Yes
23021,TODO: finish docstring,,,Yes
23022,TODO: raise a custom error here,,No,Yes
23023,TODO: fix top k,,,Yes
23024,Remove the unknownword strings if needed,,No,Yes
23025,HACK!!!,,Yes,Yes
23026,return self.commit_if_needed('DVC repro: {}'.format(' '.join(target))),,No,Yes
23027,FIXME add cmdline argument and config option for POOL_SIZE,,No,Yes
23028,"NOTE: this name is really confusing. It should really be called \""command\"" or smth;",,,Yes
23032,FIX: It won't work in Windows.,,,Yes
23035,FIXME OLOLO don't forget to overwrite with cmdline args,,Yes,Yes
23036,FIX: It won't work in Windows.,,,Yes
23037,Python3 workaround for ResumableDownloadHandler.,,,Yes
23040,FIXME check status output,,,Yes
23043,FIXME debug,,,Yes
23044,FIXME better msgs,,Yes,Yes
23045,FIXME actually compare md5,,,Yes
23046,FIXME: enable on windows,,,Yes
23047,FIXME: this is ugly,,Yes,Yes
23049,FIXME enable on windows,,Yes,Yes
23050,FIXME better msgs,,Yes,Yes
23051,FIXME better msgs,,,Yes
23055,FIXME,,Yes,Yes
23056,FIXME,,Yes,Yes
23057,FIXME,,,Yes
23058,FIXME,,Yes,Yes
23059,FIXME,,Yes,Yes
23060,FIXME,,Yes,Yes
23061,FIXME,,,Yes
23062,NOTE: Workaround for bug in Python 3,,No,Yes
23063,FIXME,,Yes,Yes
23064,Move,,Yes,Yes
23067,"find pipeline ends aka \""output stages\""",,Yes,Yes
23069,FIXME: we could've used `md5 = state.update(path; dump=False)`,,Yes,Yes
23070,NOTE: Fix env variables modified by PyInstaller,,No,Yes
23073,FIXME check output,,,Yes
23074,"find pipeline ends aka \""output stages\""",,,Yes
23075,Dirty hack so the for loop below can at least enter once,,,Yes
23078,FIXME better msgs,,,Yes
23080,needed to look at all the files (project root_dir),,No,Yes
23081,GitPython's obj.data_stream is a fragile thing; it is better to,,,Yes
23083,not needed to decode the path from py2's str,,Yes,Yes
23084,move instead of remove; to lock inode assigned to stage_files[0].path,,,Yes
23085,would fix itself once class-based fixtures are removed,,,Yes
23086,NOTE: staticmethod is only needed in Python 2,,,Yes
23088,FIXME: if we have Windows path containig \/ or posix one with \\,,,Yes
23090,we won't be able to use move properly.,,,Yes
23093,NOTE: this is how `hadoop fs -cp` works too: it copies through,,,Yes
23098,"TODO: persistent progress only for \""large\"" files?",,Yes,Yes
23099,but maybe no intermediate ones,,,Yes
23101,XXX: We can remove the `exists` call; since `makedirs`,,Yes,Yes
23103,XXX: This is a fallback until the following methods are,,Yes,Yes
23105,XXX: This is a fallback until the following methods are,,Yes,Yes
23108,That's why we simply create an empty file rather than a link.,,Yes,Yes
23110,adding a file so that dvc creates `.dvc\/cache`; that is needed for proper,,,Yes
23113,We need to make sure that the path ends with a forward slash;,,Yes,Yes
23115,A clunky way to detect cache dir,,,Yes
23117,FIXME: enable on windows,,No,Yes
23118,NOTE: staticmethod is only needed in Python 2,,,Yes
23120,TODO: simplify; we shouldn't need run. This also duplicates the previous one.,,,Yes
23121,Not needed in Python 3.6+,,,Yes
23126,This might happen when pull haven't really pulled all the files,,Yes,Yes
23131,XXX: No such YAML file with path: '<path>',,,Yes
23132,XXX: Failed to parse YAML correctly,,,Yes
23133,"XXX: YAML file doesn't include the \""objects\"" keyword",,,Yes
23140,not needed to decode the path from py2's str,,Yes,Yes
23141,Dummy exception raised to signal a plain file copy is needed,,Yes,Yes
23142,XXX: Some issues with this approach:,,No,Yes
23143,"* sys.path manipulation is \""theoretically\"" not needed;",,,Yes
23145,Only pull unless all needed cache is present,,Yes,Yes
23146,"Windows absolute paths should really have scheme == \""\"" (local)",,Yes,Yes
23147,TODO: Make support for `eropo=` as well ?,,Yes,Yes
23149,more details. The hack can be used as:,,Yes,Yes
23150,check that our hack can be enabled,,,Yes
23152,NOTE: this ends up re-fetching checksums that were already,,,Yes
23153,TODO: Better exception,,,Yes
23156,temporary hack to make cache use WorkingTree and not GitTree; because,,,Yes
23159,will pull dir cache if needed,,Yes,Yes
23164,NOTE: temporary workaround,,No,Yes
23166,help message instead of generic `dvc` usage.,,Yes,Yes
23170,workaround for MacOS bug,,Yes,Yes
23175,pull dir cache if needed,,Yes,Yes
23178,Create `.dvc\/cache`; that is needed to check supported link types.,,No,Yes
23181,Dirty hack so the for loop below can at least enter once,,Yes,Yes
23184,Create final checkpoint commit if needed,,,Yes
23186,FIXME: using for convenience; figure out better way to do it,,,Yes
23187,NOTE: this ends up re-fetching hashes that were already,,,Yes
23189,FIXME: Should `vars` be templatized?,,No,Yes
23190,Fix if\/when those assumptions are no longer valid.,,Yes,Yes
23191,FIXME: Decide if we should track them or not (it does right now),,Yes,Yes
23192,needed before we can fix it in __init__,,Yes,Yes
23193,GitPython's obj.data_stream is a fragile thing; it is better to,,,Yes
23196,It is needed to be dict of lists to cover cases,,,Yes
23197,xxx\/newdir\/. exists if xxx\/newdir exists,,,Yes
23198,Needed for some providers; and http open(),,,Yes
23199,xxx\/newdir\/. exists if xxx\/newdir exists,,Yes,Yes
23202,file where it's name ends with a forward slash,,,Yes
23205,needed for gitpython,,,Yes
23208,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23210,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23211,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23212,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23213,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23214,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23215,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23216,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23217,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23220,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23224,TODO error logging to file,,No,Yes
23225,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23227,'''trial_job_id of all ended trials. || We need this because NNI manager may send metrics after reporting a trial ended. || TODO: move this logic to NNI manager || ''',,,Yes
23228,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23229,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23234,TODO - catch exact Exception,,Yes,Yes
23236,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23237,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23239,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23240,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23241,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23242,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23243,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23244,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23245,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23246,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23247,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23248,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23252,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23253,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23254,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23255,TODO: may be unnecessary,,No,Yes
23256,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23262,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23263,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23264,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23265,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23266,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23267,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23269,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23271,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23272,TODO: check the output of rest server,,Yes,Yes
23273,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23275,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23277,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23278,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23281,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23282,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23283,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23285,FIXME: search space not generated,,Yes,Yes
23287,"'''MobileNet in PyTorch. ||  || See the paper \""MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\"" || for more details. || '''",,No,Yes
23289,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23290,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23291,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23293,'''trial_job_id of all ended trials. || We need this because NNI manager may send metrics after reporting a trial ended. || TODO: move this logic to NNI manager || ''',,Yes,Yes
23294,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23296,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23297,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23298,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23300,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23301,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23302,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23303,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23304,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23305,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23306,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23307,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23308,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23309,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23310,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23313,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23315,TODO: support lower bound in randint,,No,Yes
23318,TODO error logging to file,,,Yes
23319,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23321,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23325,'''trial_job_id of all ended trials. || We need this because NNI manager may send metrics after reporting a trial ended. || TODO: move this logic to NNI manager || ''',,,Yes
23328,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23329,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23330,4.If the id ends with *; nnictl will match all ids matchs the regular,,,Yes
23335,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23336,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23339,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23340,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23341,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23342,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23343,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23346,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23348,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23351,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23353,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23354,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23356,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23358,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23359,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23360,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23366,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23368,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23369,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23370,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23372,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23377,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23379,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23380,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23381,TODO check process in windows,,,Yes
23386,TODO: support randint; quniform,,,Yes
23387,Store it if better than previous minimum(maximum).,,No,Yes
23389,TODO why int here ?,,No,Yes
23390,TODO: sample_y ??,,No,Yes
23391,TODO: support all platforms,,Yes,Yes
23392,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23393,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23394,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23395,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23397,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23398,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23399,TODO: Calculate loss,,,Yes
23401,ugly,,,Yes
23405,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23408,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,,Yes
23410,TODO: this is ugly; we put all the initialization work in this method; because initialization relies,,,Yes
23411,note: this is not written by original author; feel free to modify if you think it's incorrect,,Yes,Yes
23413,FIXME: because tuner is designed as interface; this API should not be here,,Yes,Yes
23416,FIXME: because Tuner is designed as interface; this API should not be here,,Yes,Yes
23418,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23421,NOTE(yuge): We might implement an interface later. Judging by key now.,,Yes,Yes
23422,Pruning Configuration; in paper 'PRUNING FILTERS FOR EFFICIENT CONVNETS';,,Yes,Yes
23423,Pruning Configuration; in paper 'Learning efficient convolutional networks through network slimming';,,Yes,Yes
23425,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and associated,,Yes,Yes
23426,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23428,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,No,Yes
23430,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23432,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23433,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23434,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23435,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,,Yes
23436,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23437,TODO: use a passed-in RNG here,,No,Yes
23439,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23441,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23443,Permission is hereby granted; free of charge; to any person obtaining a copy of this software and,,Yes,Yes
23444,The above copyright notice and this permission notice shall be included in all copies or,,,Yes
23445,TODO: consider other functions here,,,Yes
23447,should be the average of the gradients of the columns,,Yes,Yes
23449,The above copyright notice and this permission notice shall be included in all copies or,,No,Yes
23452,TODO simulate folded weight,,,Yes
23453,FIXME: risk; candidates might also have None,,,Yes
23455,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,,,Yes
23457,use a fixed set of image will improve the performance,,,Yes
23459,Pruning Configuration; in paper 'PRUNING FILTERS FOR EFFICIENT CONVNETS';,,Yes,Yes
23462,TODO: scope name could be empty,,,Yes
23466,move network to GPU if available,,Yes,Yes
23467,TODO: unify idx format,,,Yes
23470,remove unused module for speedup,,Yes,Yes
23473,must be in pattern `xxx[xxx]`,,Yes,Yes
23474,TODO: move outside of torch.onnx?,,No,Yes
23477,hack for kubeflow trial config,,,Yes
23478,hack for windows,,,Yes
23484,remove unused parameters,,,Yes
23488,TODO: status,,Yes,Yes
23490,TODO: directly use weight_mask is not good,,Yes,Yes
23491,TODO In current L1\/L2 Filter Pruner; the 'op_types' is still necessary,,No,Yes
23492,Fix the mask conflict,,,Yes
23494,training=training is needed only if there are layers with different,,,Yes
23495,training=False is needed only if there are layers with different,,Yes,Yes
23498,input info needed,,,Yes
23499,init current performance & best performance,,No,Yes
23500,if better evaluation result; then accept the perturbation,,,Yes
23501,save best performance and best params,,,Yes
23503,TODO: designed to replace `patch_optimizer`,,No,Yes
23510,fixme: launching logic needs refactor,,Yes,Yes
23511,todo: I don't think these should be here,,No,Yes
23515,"\""\""\"" || Unit test of NNI Python modules. ||  || Test cases of each module should be placed at same path of their source files. || For example if `nni\/tool\/annotation` has one test case; it should be placed at `test\/ut\/tool\/annotation.py`; || if it has multiple test cases; they should be placed in `test\/ut\/tool\/annotation\/` directory. ||  || \""Legacy\"" test cases carried from NNI v1.x might not follow above convention: ||  ||   + Directory `sdk` contains old test cases previously in `src\/sdk\/pynni\/tests`. ||   + Directory `tools\/cmd` contains old test cases previously in `tools\/cmd\/tests`. ||   + Directory `tools\/annotation` contains old test cases previously in `tools\/nni_annotation`. ||   + Directory `tools\/trial_tool` contains old test cases previously in `tools\/nni_trial_tool\/test`. || \""\""\""",,Yes,Yes
23516,FIXME:,,,Yes
23520,TODO,,,Yes
23522,FIXME: topological sort is needed here,,No,Yes
23523,TODO: handle imports,,Yes,Yes
23525,"\""\""\"" || To be designed.  Discussion needed. ||  || This describes the properties of a worker machine. (e.g. memory size) || \""\""\""",,No,Yes
23526,TODO: we will need at least two (maybe three) data loaders in future.,,Yes,Yes
23527,TODO: fix: inputs is a list; how to deal with single element list and single element,,Yes,Yes
23528,TODO: set correct PATH for the packages (after launch refactor),,No,Yes
23529,TODO: remove _convert_names (after merging input_names and input_node),,No,Yes
23531,TODO: add scope name,,Yes,Yes
23532,TODO: support constant expression,,,Yes
23533,TODO: try not-connected placeholder in TorchScript,,,Yes
23541,TODO: ugly; think about how to refactor this part,,Yes,Yes
23542,"TODO: restrict that \""choose\"" can only be used within mutator",,Yes,Yes
23545,TODO: new interface,,,Yes
23546,TODO: use node copy instead,,,Yes
23547,TODO: why not merge the names into input_node and output_node???,,,Yes
23548,FIXME this is a hack to work around mismatch in origin impl input,,Yes,Yes
23550,fix random seeds,,,Yes
23552,"\""\""\"" || Unit test of NNI Python modules. ||  || Test cases of each module should be placed at same path of their source files. || For example if `nni\/tool\/annotation` has one test case; it should be placed at `test\/ut\/tool\/test_annotation.py`; || if it has multiple test cases; they should be placed in `test\/ut\/tool\/annotation\/` directory. ||  || \""Legacy\"" test cases carried from NNI v1.x might not follow above convention: ||  ||   + Directory `sdk` contains old test cases previously in `src\/sdk\/pynni\/tests`. ||   + Directory `tools\/nnictl` contains old test cases previously in `tools\/nni_cmd\/tests`. ||   + Directory `tools\/annotation` contains old test cases previously in `tools\/nni_annotation`. ||   + Directory `tools\/trial_tool` contains old test cases previously in `tools\/nni_trial_tool\/test`. || \""\""\""",,Yes,Yes
23553,TODO bug here; the groups is directly get from conv.groups; if the whole group is removed;,,Yes,Yes
23554,TODO support the Convtranspose2d Pruning for the L1FilterPruner,,,Yes
23555,FIXME: For demonstration only. It should not be here,,No,Yes
23556,check type (TODO),,,Yes
23559,TODO: port shangning's work here; and use it in Experiment.start()\/.stop(),,,Yes
23563,TODO: currently; only support single input slot and output slot.,,,Yes
23564,TODO: it does not have duplicated edges if only supporting dedup input,,,Yes
23565,TODO: check type,,No,Yes
23566,FIXME: expose this field to users,,Yes,Yes
23567,FIXME: remove this argument,,No,Yes
23569,"%25 : __torch__.xxx = prim::GetAttr[name=\""input_switch\""](%self)",,,Yes
23573,check type (TODO),,No,Yes
23574,when slice is for one dimension list; there are only 4 inputs; thus merge is not needed,,Yes,Yes
23579,TODO: double check the status,,No,Yes
23584,TODO: the operation is likely to be considered editable by end-user and it will be hard to debug,,,Yes
23586,TODO: fix ut,,,Yes
23587,TODO: refactor later,,No,Yes
23589,TODO: add future as input with default val,,Yes,Yes
23590,TODO: chunk call should appear as the for loop iterable,,No,Yes
23593,TODO: docstring,,,Yes
23594,Reproduced result in paper 'PRUNING FILTERS FOR EFFICIENT CONVNETS';,,Yes,Yes
23595,TODO: The current design of init interface of Retiarii experiment needs to be reviewed.,,,Yes
23596,TODO: serialize complex data type; and output proper error message,,,Yes
23597,TODO: support non member functions,,,Yes
23598,TODO: check whether there could be multiple output nodes???,,No,Yes
23600,TODO: refactor this part; maybe we can remove the code gen of prim::Constant,,Yes,Yes
23601,TODO: deal with all the types,,No,Yes
23602,TODO: deal with this argument,,,Yes
23605,TODO: topological sort should be improved,,,Yes
23609,FIXME: should be a warning message here,,,Yes
23610,input info needed,,No,Yes
23611,TODO: build this,,,Yes
23613,TODO: build this,,No,Yes
23615,TODO: don't read whole input dataset every time,,Yes,Yes
23616,"\""\""\"" || The Simple Python Fixed-Point Module (SPFPM) provides objects of types || FXnum and FXfamily which implement basic mathematical operations || on fixed-point binary numbers (i.e. having a fixed number of || fractional binary digits; with the number of integer digits being either || arbitrary or subject to a user-defined limit). ||  || FXnum objects exist within a user-controllable collection of families || managed by the FXfamily class; which sets the number of fractional || & integer digits for each family. This can be used; for example; || to ensure that a set of 8-bit quantities can be manipulated consistently || and kept separate from a set of 200-bit quantities in the same program. || Conversion between FXnum objects in different families is supported; || but solely through an explicit cast. ||  || >>> x = FXnum(2.1)                  # default FXfamily; with 64-bits || >>> print(x) || 2.100000000000000088817 || >>> x = FXnum(21) \/ 10              # fractional error ~1\/2^64 or ~5e-20 || >>> print(x) || 2.099999999999999999967 || >>> rx = x.sqrt()                   # rx created in same family as x || >>> print(rx) || 1.449137674618943857354 || >>> v = x + 2 * rx || >>> print(v) || 4.998275349237887714675 ||  || >>> y = FXnum(3.2; FXfamily(12))    # lower-precision 12-bit number || >>> ly = y.log()                    # ly created in same family as y || >>> print(ly)                       # fractional error ~1\/2^12 or ~2e-4 || 1.1628 || >>> print(ly.exp()) || 3.1987 || >>> fy = float(y) || >>> print(fy) || 3.199951171875 ||  || >>> # a = x + y                     # throws exception - different families || >>> a = x + FXnum(y; _defaultFamily) || >>> print(a) || 5.300073242187499999967 || >>> b = rx + x                      # ok - same families || >>> # c = rx + ly                   # throws exception - different families || >>> d = ly + y                      # ok - same families ||  || >>> a = FXnum(1.4; FXfamily(12; 4)) # limit magnitude to 2^(4-1) || >>> print(a) || 1.3999 || >>> print(a * 5; a * -5) || 6.9995 -6.9995 || >>> #print(a * 6; a * -6)           # throws exception indicating overflow ||  || >>> fam = FXfamily(200) || >>> print(fam.pi) || 3.141592653589793238462643383279502884197169399375105820974944478108 ||  || Note: ||     Be careful not to assume that a large number of fractional bits within ||     a number will necessarily mean large accuracy. For example; computations ||     involving exponentiation and logarithms are intrinsically vulnerable to ||     magnifying mere rounding errors in their inputs into significant errors ||     in their outputs. This is a fact of life with any approximation to ||     real arithmetic using finite-precision quantities. ||  || SPFPM is provided as-is; with no warranty of any form. || \""\""\""",,,Yes
23617,However; the author welcomes *constructive* feedback,,Yes,Yes
23619,TODO: this fails with x = x + x if x is a FloatTensor,,No,Yes
23620,TODO: this fails with x = x + x if x is a FloatTensor,,No,Yes
23621,TODO: this fails with x = x + x if x is a FloatTensor,,,Yes
23622,TODO backward() to be implemented: grad = target - prediction,,,Yes
23623,TODO backward(): until IntegerTensor is available assume a one-hot vector is passed in.,,No,Yes
23624,TODO backward() to be implemented: grad = target - prediction,,No,Yes
23625,TODO backward(): until IntegerTensor is available assume a one-hot vector is passed in.,,No,Yes
23627,TODO backward(): until IntegerTensor is available assume a one-hot vector is passed in.,,No,Yes
23628,"TODO: May want to handle the ones in \""exclude\"" manually at",,No,Yes
23629,This one wasn't in dir(Variable) -- probably a C++ thing,,No,Yes
23630,TODO: Assign default id more intelligently (low priority),,No,Yes
23631,TODO: extend to iterables of tensor pointers,,Yes,Yes
23633,TODO: fully generalize this to multiple workers; consider,,,Yes
23636,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
23637,"TODO: May want to handle the ones in \""exclude\"" manually at",,No,Yes
23638,This one wasn't in dir(Variable) -- probably a C++ thing,,No,Yes
23639,TODO: extend to iterables of pointers,,,Yes
23641,# TODO: extend to iterables of tensor pointers,,,Yes
23642,# TODO: Extend to responses that are iterables.,,Yes,Yes
23643,# TODO: fully generalize this to multiple workers; consider,,Yes,Yes
23645,TODO: Assign default id more intelligently (low priority),,No,Yes
23650,workaround seems to work well for now. Anyway; we don't need the temporary objects past this point.,,Yes,Yes
23652,if grad isn't returned here. It re-initializes the gradient somehow but in a way,,Yes,Yes
23654,store objects temporarily in self._tmpobjects which seems to fix it. Super strange bug which took,,Yes,Yes
23657,TODO: pass in just the id instead of the entire obj_msg.,,Yes,Yes
23660,previously; newly created Variable objects would lose their OpenMined given,,,Yes
23661,is experimental functionality but seems to solve the symptoms we,,Yes,Yes
23662,are created before their parents? TODO: fix,,,Yes
23663,TODO: Extend to responses that are iterables.,,,Yes
23665,TODO: Assign default id more intelligently (low priority),,No,Yes
23666,is experimental functionality but seems to solve the symptoms we,,Yes,Yes
23667,TODO: Implement get_owners and refactor to make it prettier,,Yes,Yes
23672,TODO: implementing _execute_remote_fixed_precision_call for remote fixed precision tensors,,Yes,Yes
23673,# previously; newly created Variable objects would lose their OpenMined given,,Yes,Yes
23674,TODO: implementing _execute_remote_fixed_precision_call for remote fixed precision tensors,,Yes,Yes
23675,previously; newly created Variable objects would lose their OpenMined given,,,Yes
23676,"TODO: May want to handle the ones in \""exclude\"" manually at",,No,Yes
23678,# previously; newly created Variable objects would lose their OpenMined given,,,Yes
23680,TOOD: figure out how to avoid this performance waste.,,No,Yes
23682,previously; newly created Variable objects would lose their OpenMined given,,,Yes
23684,# previously; newly created Variable objects would lose their OpenMined given,,,Yes
23685,TODO .id_at_location,,No,Yes
23687,TODO Will break with PyTorch >= 0.4,,,Yes
23688,TODO Guard (self._command_guard(command_msg['command']; self.hook.tensorvar_methods)),,,Yes
23689,TODO Guard (self._command_guard(command_msg['command']; self.hook.tensorvar_methods)),,,Yes
23690,TODO: add pointer on attr grad: create .grad as a property,,Yes,Yes
23691,TODO: get grad if any,,Yes,Yes
23693,TODO: 'type' is compulsory to pass the guard; but is not very appropriate,,No,Yes
23695,TODO: want to define a particular id ? cant use new_id 2 or 3 times,,,Yes
23696,# TODO: Implement get_owners and refactor to make it prettier,,Yes,Yes
23697,TODO: 'type' is compulsory to pass the guard; but is not very appropriate,,No,Yes
23700,TODO: put this in an appropriate place,,,Yes
23702,TODO: Extend to responses that are iterables.,,Yes,Yes
23705,Probably a LocalTensor (TODO and if not ? or if list ?),,,Yes
23706,TODO: Extend to responses that are iterables.,,Yes,Yes
23707,TODO: Fix the case when response contains only a numeric,,,Yes
23708,TODO Guard,,,Yes
23710,TODO: Find a smart way to skip register and not leaking the info to the local worker,,,Yes
23712,if(is_binary): # Todo fix type handling,,Yes,Yes
23713,TODO: Extend to response which is iterable.,,,Yes
23716,TOOD: figure out how to avoid this performance waste.,,,Yes
23717,ok... now we can deregister it. This is a little bit of a hack but it works,,No,Yes
23718,TODO: perhaps there's a better strategy for getting access to the local_worker,,Yes,Yes
23719,TODO .id_at_location,,No,Yes
23720,args = args[1:] # TODO compare to master,,Yes,Yes
23723,TODO .id_at_location,,No,Yes
23725,TODO: modifying self is maybe not a good practice; but it's the only way I found,,,Yes
23727,TODO: Assign default id more intelligently (low priority),,No,Yes
23728,TODO: Implement get_owners and refactor to make it prettier,,Yes,Yes
23729,TODO: pass in just the id instead of the entire obj_msg.,,Yes,Yes
23730,Todo there is a pb with decode because it acquire a Variable in any case (it has a child);,,Yes,Yes
23733,if(is_binary): # Todo fix type handling,,Yes,Yes
23734,TODO: Extend to response which is iterable.,,,Yes
23736,TODO: Extend to responses that are iterables.,,Yes,Yes
23737,TODO: Assign default id more intelligently (low priority),,,Yes
23738,TODO: Implement get_owners and refactor to make it prettier,,,Yes
23740,TODO: handle this conversion again if needed,,Yes,Yes
23741,if(is_binary): # Todo fix type handling,,Yes,Yes
23742,TODO: Extend to response which is iterable.,,Yes,Yes
23743,TODO: Implement get_owners and refactor to make it prettier,,Yes,Yes
23744,TODO: Extend to responses that are iterables.,,,Yes
23745,TODO: Assign default id more intelligently (low priority),,No,Yes
23746,TODO: Implement get_owners and refactor to make it prettier,,,Yes
23748,TODO: handle this conversion again if needed,,Yes,Yes
23749,if(is_binary): # Todo fix type handling,,,Yes
23751,TODO It would be good to have a standardized place to put the 'mode' argument,,Yes,Yes
23752,TODO: Extend to response which is iterable.,,Yes,Yes
23753,# previously; newly created Variable objects would lose their OpenMined given,,Yes,Yes
23755,TODO Guard,,,Yes
23756,TODO: This is added because of the following contradiction: instanciate x = FloatTensor(...),,,Yes
23758,TODO: and is an inplace mthod,,,Yes
23759,TODO specify owner,,Yes,Yes
23761,TODO: remove duplicate on base.py,,No,Yes
23762,TODO : controled registration process,,Yes,Yes
23764,TODO: use the wrapper,,,Yes
23766,ToDO: For LOCAL,,No,Yes
23767,TODO keep it ?,,,Yes
23769,TODO,,Yes,Yes
23772,TODO: instead of looping on the objects;,,,Yes
23773,TODO: Stop with this prior that data should be a dict;,,,Yes
23774,If we have the original object (TODO: add checks) return it,,,Yes
23775,"TODO: May want to handle the ones in \""exclude\"" manually at",,No,Yes
23776,retrieve the var to fix,,,Yes
23777,then this is a TODO!,,Yes,Yes
23778,then this is a TODO!,,Yes,Yes
23783,TODO: Stop with this prior that data should be a dict;,,,Yes
23784,Init new remote ids if needed,,,Yes
23785,TODO Will break with PyTorch >= 0.4,,,Yes
23787,TODO: Find a smart way to skip register and not leaking the info to the local worker,,No,Yes
23792,TODO: Implement get_owners and refactor to make it prettier,,Yes,Yes
23793,TODO: pass in just the id instead of the entire obj_msg.,,,Yes
23796,{'__range__': }; TODO,,Yes,Yes
23797,{'__slice__': }  TODO,,,Yes
23799,then this is a TODO!,,,Yes
23800,TODO: What are the risks due to this assimilation? (see usage @ torch\/utils.py l.74),,Yes,Yes
23804,it does not exist. As a result; we've needed to store objects temporarily,,,Yes
23805,in self._tmpobjects which seems to fix it. Super strange bug which took,,,Yes
23807,#{'__tuple__':}; TODO,,Yes,Yes
23808,#{'__set__':}; TODO,,Yes,Yes
23809,#{'__range__': }; TODO,,Yes,Yes
23810,#{'__slice__': }  TODO,,Yes,Yes
23812,Remove this pointer - TODO: call deregister function instead of doing it by hand,,Yes,Yes
23818,TODO: See Issue #1480,,,Yes
23821,self.mpc_mul(5; -5) TODO: Future work: how to handle gracefully minus numbers,,Yes,Yes
23822,Torch is circular this creates an infinite recursion. TODO: fix after Torch 1.0,,,Yes
23823,TODO: See Issue #1480,,No,Yes
23825,Fixme: Add a generic child depending on a torch_type,,Yes,Yes
23832,TODO : control registration process,,,Yes
23835,Remove this pointer - TODO: call deregister function instead of doing it by hand,,Yes,Yes
23836,TODO: same for grad ?,,No,Yes
23837,If we have retrieved an already existing object (TODO: add checks) then return it,,Yes,Yes
23839,Ensure that the loop is made; if needed,,No,Yes
23840,Init new remote ids if needed,,,Yes
23842,TODO: deregister_ptr doesn't work,,,Yes
23844,TODO: value per value,,,Yes
23845,TODO: figure out why some machines prefer one of these options,,,Yes
23851,"TODO: send a \""successful\"" or \""not successful\"" response?",,,Yes
23852,67 in original # TODO: extend to ops over multiple rings,,,Yes
23858,FIXME: generate_zero_shares_communication should be updated with new pysyft API,,,Yes
23861,TODO: Doublon with the new functionality send(*worker),,No,Yes
23862,TODO: Add this thing for negative values,,Yes,Yes
23864,FIXME: is it necessary?,,No,Yes
23865,FIXME: implement share convert protocol,,Yes,Yes
23867,TODO rangeindex; multiindex; CategoricalIndex; IntervalIndex on return function,,,Yes
23868,TODO: make this secure by exchanging shares remotely,,,Yes
23869,so coerces the shares to an odd ring if needed (FIXME),,,Yes
23871,TODO: and the grad ?,,No,Yes
23872,TODO: recombine c properly here,,,Yes
23873,FIXME: implement share convert protocol,,Yes,Yes
23874,FIXME: the conditional on the right should include a plaintext add of x and y;,,,Yes
23875,needed for share_convert,,,Yes
23876,.send(bob; alice) #TODO: make this secure by exchanging shares remotely,,Yes,Yes
23879,TODO: and the grad ?,,No,Yes
23880,TODO: Should fix_me be an inplace op?,,Yes,Yes
23882,FIXME:,,No,Yes
23883,TODO: and the grad ?,,No,Yes
23884,getting the dimension of the tensor which prod will be applied to. (needed for fixing,,,Yes
23885,TODO: fix this properly: don't wrap the same way if syft or Variable,,No,Yes
23886,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23889,time to fix. TODO: optimize the crap out of this,,Yes,Yes
23891,time to fix. TODO: optimize the crap out of this,,Yes,Yes
23892,FIXME: this doesn't work since putting owner='...' => RuntimeError: torch.FloatTensor constructor doesn't accept any keyword arguments,,Yes,Yes
23893,time to fix. TODO: optimize the crap out of this,,Yes,Yes
23894,FIXME: this doesn't work since putting owner='...' => RuntimeError: torch.FloatTensor constructor doesn't accept any keyword arguments,,,Yes
23895,time to fix. TODO: optimize the crap out of this,,,Yes
23897,TODO: and the grad ?,,No,Yes
23898,TODO: figure out how to let this be hooked here so that it happens,,Yes,Yes
23900,torch_utils.fix_chain_ends(self),,,Yes
23903,Fix chain ends and links between chains,,No,Yes
23904,Ensure that the loop is made; if needed,,,Yes
23905,todo: fix this in link_var_chain_to_data_and_grad_chains,,,Yes
23907,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,,Yes
23911,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23912,FIXME: this doesn't work since putting owner='...' => RuntimeError: torch.FloatTensor constructor doesn't accept any keyword arguments,,Yes,Yes
23913,Torch is circular this creates an infinite recursion. TODO: fix after Torch 1.0,,,Yes
23914,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,,Yes
23915,todo: fix this in link_var_chain_to_data_and_grad_chains,,,Yes
23916,Fix chain ends and links between chains,,No,Yes
23917,Fix parents,,,Yes
23918,Torch is circular this creates an infinite recursion. TODO: fix after Torch 1.0,,Yes,Yes
23919,Ensure that the loop is made; if needed,,No,Yes
23920,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23921,todo: fix this in link_var_chain_to_data_and_grad_chains,,No,Yes
23924,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23925,not needed: torch_utils.is_syft_tensor(child):,,No,Yes
23926,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,Yes,Yes
23927,FIXME: This shouldn't be here,,No,Yes
23928,TODO: rm .data; .grad; .grad.data if any,,,Yes
23929,TODO: rm .grad; .grad.data if any,,,Yes
23930,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23931,If we have retrieved an already existing object (TODO: add checks) then return it,,Yes,Yes
23932,Fix chain ends and links between chains,,,Yes
23935,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,Yes,Yes
23936,TODO: calculating the inverse every time is stupid slow - but i need to keep moving,,Yes,Yes
23937,If we have retrieved an already existing object (TODO: add checks) then return it,,,Yes
23938,Fix chain ends and links between chains,,,Yes
23946,"\""\""\"" || This file exists to provide one common place for all serialization to occur || regardless of framework. As msgpack only supports basic types and binary formats || every type must be first be converted to one of these types. Thus; we've split our || functionality into two sections. || \""\""\""",,Yes,Yes
23948,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,,Yes
23949,Fixme: remove the share on init;,,Yes,Yes
23951,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,Yes,Yes
23955,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,,Yes
23956,Fixme: remove the share on init;,,Yes,Yes
23958,FIXME: this check is only here because when you bring back a GenPtrTensor from remote;,,,Yes
23960,Fixme: remove the share on init;,,Yes,Yes
23961,Fixme: remove the share on init;,,Yes,Yes
23963,TODO: isn't it redundant iwth the upper one ?,,No,Yes
23965,TODO: Not useful for the moment,,No,Yes
23966,TODO: finish AbstractTensor which should handle register\/parent\/id stuff,,,Yes
23967,TODO: Not useful for the moment,,No,Yes
23969,TODO: fix comment for this and simplifier,,No,Yes
23970,TODO: finish AbstractTensor which should handle register\/parent\/id stuff,,Yes,Yes
23972,FIXME: should be added automatically,,Yes,Yes
23974,TODO Replace with syft.torch.torch_modules when hooking 'torch' will not break msgpack,,Yes,Yes
23975,4. Move the native function,,Yes,Yes
23976,Not needed in the headless setting,,No,Yes
23977,Not needed at the moment,,No,Yes
23978,"TODO: change if statement to \""if has_pointer_child\""",,Yes,Yes
23979,TODO: analyse exactly the role of adding the type of self in the id,,,Yes
23981,TODO: add kwargs,,No,Yes
23982,Put back the wrappers where needed,,,Yes
23985,TODO: add kwargs in command,,No,Yes
23988,TODO add kwargs,,No,Yes
23989,TODO rename registry or use another one than for methods,,Yes,Yes
23990,TODO: add kwargs,,,Yes
23993,TODO: guard,,,Yes
23994,TODO: add kwargs in command,,,Yes
23995,TODO: I can't manage the import issue; can you?,,Yes,Yes
23999,TODO: confusion between inplace and not inplace method to disambiguate,,,Yes
24002,TODO: remove these 3 lines,,Yes,Yes
24004,TODO Replace with syft.torch.torch_modules when hooking 'torch' will not break msgpack,,Yes,Yes
24008,TODO: add kwargs in command,,,Yes
24009,TODO: I can't manage the import issue; can you?,,,Yes
24011,# TODO: I can't manage the import issue; can you?,,,Yes
24013,TODO fix pointer bug,,,Yes
24014,TODO and add special functions to include \/ avoid,,Yes,Yes
24015,Could add more checks but not sure it is needed so far.,,Yes,Yes
24017,TODO: add .data and .grad to syft tensors,,,Yes
24018,# TODO: confusion between inplace and not inplace method to disambiguate,,No,Yes
24022,# TODO: confusion between inplace and not inplace method to disambiguate,,,Yes
24024,TODO: add .data and .grad to syft tensors,,,Yes
24025,# TODO: confusion between inplace and not inplace method to disambiguate,,No,Yes
24026,Convert in the Federated format if needed,,No,Yes
24028,Fix for old versions of torchvision,,,Yes
24031,TODO: add kwargs in command,,No,Yes
24032,TODO: I can't manage the import issue; can you?,,Yes,Yes
24033,constructed GradFunc classes to gradients.py. It could probably be optimized a bit.,,Yes,Yes
24034,There is probably a better way to do this,,No,Yes
24035,TODO: add kwargs,,No,Yes
24038,Update plan with current args for every argument (TODO: remotely),,,Yes
24039,1) Decompress the binary if needed,,No,Yes
24041,TODO: should one set this boolean to true?,,,Yes
24046,TODO: fix comment for this and simplifier,,No,Yes
24047,TODO: not sure if someone needed this - if this comment,,,Yes
24049,TODO: should one set this boolean to true?,,Yes,Yes
24053,FIXME: should be added automatically,,,Yes
24054,FIXME: should be added automatically,,,Yes
24055,TODO: Handle when the response is not simply a tensor,,,Yes
24056,FIXME: should be added automatically,,,Yes
24057,TODO: Handle when the response is not simply a tensor,,Yes,Yes
24058,FIXME: should be added automatically,,Yes,Yes
24059,TODO: Handle when the response is not simply a tensor,,Yes,Yes
24060,TODO: Why do we need to cast it in a tuple? this is a (small) time waste,,,Yes
24061,FIXME: should be added automatically,,,Yes
24063,TODO: fix comment for this and simplifier,,No,Yes
24067,TODO: Handle public mul more efficiently,,No,Yes
24068,so doing this to work my way down the chain to the base tensor. TODO,,,Yes
24069,1) Decompress the binary if needed,,No,Yes
24071,1) Decompress the binary if needed,,No,Yes
24072,TODO: Handle public mul more efficiently,,,Yes
24073,1) Decompress the binary if needed,,No,Yes
24074,TODO: fix comment for this and simplifier,,No,Yes
24076,TODO have a better way,,,Yes
24077,TODO: I can't manage the import issue; can you?,,,Yes
24078,TODO have a better way,,,Yes
24079,TODO: I can't manage the import issue; can you?,,,Yes
24080,TODO: I can't manage the import issue; can you?,,Yes,Yes
24081,TODO: I can't manage the import issue; can you?,,Yes,Yes
24082,TODO: I can't manage the import issue; can you?,,Yes,Yes
24083,TODO: I can't manage the import issue; can you?,,Yes,Yes
24084,TODO add kwargs,,,Yes
24087,FIXME,,,Yes
24088,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,No,Yes
24093,should perhaps be of type ShareDict extending dict or something like this,,Yes,Yes
24094,"\""__eq__\""; # FIXME it now overwritten in native.py to use torch.eq; because of pb between == & __eq__",,Yes,Yes
24097,FIXME: Add 14): permutation and sending to crypto provider,,,Yes
24100,TODO: I can't manage the import issue; can you?,,Yes,Yes
24101,# TODO: sum shares remotely,,,Yes
24103,TODO: I can't manage the import issue; can you?,,Yes,Yes
24104,TODO: implement a length function. It should return the number of elements of the federated dataset that are,,No,Yes
24106,TODO momentum is not supported at the moment,,,Yes
24107,TODO: add .data and .grad to syft tensors,,Yes,Yes
24108,mul with non standard fix precision,,,Yes
24109,We build the plan only if needed,,Yes,Yes
24110,TODO: fix comment for this and simplifier,,,Yes
24111,TODO: send to P2 (or is it the local worker?),,No,Yes
24113,FIXME security,,No,Yes
24114,FIXME make it cleaner and robust for more options,,No,Yes
24116,TODO: fix comment for this and simplifier,,,Yes
24117,mul with non standard fix precision,,Yes,Yes
24118,Daniele Gadler: Fix timeout issues on the server-side,,,Yes
24119,Daniele Gadler: fix the timeout issues at the client side,,Yes,Yes
24120,-- Options for todo extension ----------------------------------------------,,,Yes
24122,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,No,Yes
24124,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,,Yes
24126,TODO: remove this line when issue #2062 is fixed,,No,Yes
24127,TODO: remove this line when issue #2062 is fixed,,,Yes
24128,so we better check it beforehand,,,Yes
24129,Search multiple times should still work,,Yes,Yes
24131,TODO: use sorted container to quickly check whether a value is contained,,Yes,Yes
24132,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,,Yes
24133,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,No,Yes
24134,TODO Andrew thinks this is gross; please fix. Instead need to properly deserialize strings,,No,Yes
24135,TODO Start with a single dim,,Yes,Yes
24137,TODO Check types; precision,,Yes,Yes
24139,TODO[jason]: this is currently very ugly; sync on this with Andrew & Theo,,,Yes
24141,TODO[jason]: find a better way,,Yes,Yes
24142,The code is the same for cat and stack; maybe we could factorize,,,Yes
24143,Add a bias if needed,,Yes,Yes
24144,Add a bias if needed,,,Yes
24145,The code is the same for cat and stack; maybe we could factorize,,Yes,Yes
24146,Add a bias if needed,,Yes,Yes
24147,TODO refs_ok might not be needed as we are passing now torch.tensors here,,No,Yes
24148,TODO Is Vectorization possible here?,,No,Yes
24149,needed as otherwise we will get: module 'lz4' has no attribute 'frame',,Yes,Yes
24152,TODO: force forward build,,,Yes
24155,TODO: how to create\/set a dataset?,,,Yes
24156,TODO: check if multiple returns are supported.,,No,Yes
24157,TODO: uncomment these lines.,,Yes,Yes
24158,TODO: maybe by default is_client_worker could be False?,,,Yes
24162,TODO: raise instead of assert,,No,Yes
24163,TODO: better support to method execution,,No,Yes
24164,TODO: better support for method execution,,No,Yes
24165,TODO i - max_index doesn't work,,Yes,Yes
24166,TODO: better support to method execution,,,Yes
24168,The code is the same for cat and stack; maybe we could factorize,,,Yes
24169,Add a bias if needed,,Yes,Yes
24171,TODO i - max_index doesn't work,,Yes,Yes
24172,Add a bias if needed,,Yes,Yes
24173,TODO i - max_index doesn't work,,,Yes
24174,TODO i - max_index doesn't work,,Yes,Yes
24175,TODO: fix comment for this and simplifier,,No,Yes
24176,TODO: fix comment for this and simplifier,,No,Yes
24177,TODO: fix comment for this and simplifier,,No,Yes
24179,TODO: A more complex strategy could be used,,Yes,Yes
24180,TODO This should be done by the backward_func.,,Yes,Yes
24181,self_ + other returns a np.array which is probably why it's not going through hook_args.backward_func,,No,Yes
24183,Hard fix for PyTorch versions < 1.0.2,,Yes,Yes
24184,unused args,,,Yes
24186,TODO: truediv in Zq,,No,Yes
24187,TODO: fix comment for this and simplifier,,No,Yes
24188,Initialize the dimension if needed,,No,Yes
24189,Inverse x and y if needed to satisfy len(x_shape) <= len(y_shape),,Yes,Yes
24190,Flip self and other if needed,,Yes,Yes
24191,TODO: truediv in Zq,,,Yes
24192,TODO: how to correctly handle division in Zq?,,No,Yes
24197,This is a bit ugly; I want the result to be stored in a CRT tensor with same modulos,,No,Yes
24198,TODO: how to correctly handle division in Zq?,,No,Yes
24200,TODO: how to correctly handle division in Zq?,,,Yes
24207,Initiate states if needed,,,Yes
24210,TODO,,,Yes
24211,TODO: I can't manage the import issue; can you?,,,Yes
24213,TODO: use array instead of a sharing zeros,,No,Yes
24214,So this needs to be done manually,,,Yes
24215,TODO: uncomment maxpool2d operations,,No,Yes
24218,TODO: add more efficient detailer and simplifier custom for this type,,Yes,Yes
24219,FIXME This is for additiveShareTensor.child; it can be confusing and AST.child,,Yes,Yes
24222,return the same obj with an identity fct with a type check if needed,,Yes,Yes
24223,Could add more checks but not sure it is needed so far.,,,Yes
24233,TODO: A more complex strategy could be used,,Yes,Yes
24234,We build the plan only if needed,,Yes,Yes
24235,TODO Make it only valid for AST,,Yes,Yes
24236,TODO: fix comment for this and simplifier,,No,Yes
24237,TODO: I'm not sure this is valid torch JIT anyway,,No,Yes
24239,Hook .data to handle chain assignment when needed,,No,Yes
24240,TODO[jvmancuso]: avoid branching here if possible; maybe by changing code in,,Yes,Yes
24241,TODO: support dilation.,,Yes,Yes
24242,TODO: make this operation more efficient in order to be used with cnn modules.,,Yes,Yes
24244,FIXME Ugly fix because I had id_to_add != self.owner.get_obj(id_to_add).id...,,Yes,Yes
24247,TODO if self.location is not None:,,Yes,Yes
24251,if there's a type mismatch; try to fix it!,,Yes,Yes
24252,TODO: add check to make sure this isn't getting around a security class,,No,Yes
24253,Put back the wrappers where needed,,No,Yes
24260,needed as otherwise we will get: module 'lz4' has no attribute 'frame',,,Yes
24261,1) Decompress the binary if needed,,,Yes
24263,TODO is only works up to 9 return values; because comparison is done on str and '7' > '16',,,Yes
24265,TODO,,,Yes
24266,TODO is only works up to 9 return values; because comparison is done on str and '7' > '16',,Yes,Yes
24268,TODO is only works up to 9 return values; because comparison is done on str and '7' > '16',,Yes,Yes
24270,NOTE: this is a fix to correct faulty registration that can sometimes happen,,,Yes
24271,TODO: add more efficient detailer and simplifier custom for this type,,Yes,Yes
24273,TODO this code is currently necessary for the async_fit method in websocket_client.py,,Yes,Yes
24274,Create the pointer if needed,,,Yes
24275,move to local target is equivalent to doing .get(),,No,Yes
24277,Create the pointer if needed,,Yes,Yes
24279,NOTE Maybe state shouldn't contain instanciated placeholders but values directly?,,Yes,Yes
24280,# because my particular experiment does not demand full functionality of,,,Yes
24281,# a convolutional layer; I will only implement the basic functionality.,,,Yes
24282,Add a bias if needed,,,Yes
24283,TODO Workaround to cyclic import,,Yes,Yes
24284,HELP NEEDED HERE,,,Yes
24285,TODO: uncomment maxpool2d operations,,,Yes
24286,TODO: A more complex strategy could be used,,Yes,Yes
24290,TODO isn't it weird that state placeholders are both in state and plan?,,,Yes
24294,self.result = None TODO: Broken as of Garbage Collection for `AutoGradTensor` (#3387),,Yes,Yes
24295,The code is the same for cat and stack; maybe we could factorize,,Yes,Yes
24296,TODO clean this function,,Yes,Yes
24302,TODO: can we reuse result_ids?,,,Yes
24303,NOTE Maybe state shouldn't contain instanciated placeholders but values directly?,,Yes,Yes
24305,TODO temporary trick to tell during the protocol building to whom belongs the tensors,,,Yes
24307,implementations; but must implement their own conversions to the appropriate classes.,,,Yes
24308,TODO case >2 workers ?,,,Yes
24309,TODO add a reset method on Role,,,Yes
24310,TODO mock for now; fetch will use worker's store in a future work,,,Yes
24311,TODO case >2 workers ?,,Yes,Yes
24313,NOTE: this is a fix to correct faulty registration that can sometimes happen,,,Yes
24314,TODO case >2 workers ?,,Yes,Yes
24315,TODO,,Yes,Yes
24317,TODO case >2 workers ?,,Yes,Yes
24318,TODO: add .data and .grad to syft tensors,,Yes,Yes
24320,No correction needed,,No,Yes
24321,TODO: uncomment this when solving the WorkerCommandMessage issue.,,No,Yes
24323,TODO: this should be fixed in a future PR.,,Yes,Yes
24325,TODO [midokura-silvia]: send the tensor directly,,Yes,Yes
24327,TODO case >2 workers ?,,Yes,Yes
24328,TODO: run ttp in a specified worker,,Yes,Yes
24329,TODO: add .data and .grad to syft tensors,,Yes,Yes
24331,TODO case >2 workers ?,,Yes,Yes
24333,Additionally it helps us to avoid running apidoc manually,,Yes,Yes
24335,TODO: lookup actual return type instead of just guessing that it's identical,,,Yes
24336,"\""\""\"" || This is a skeleton file that can serve as a starting point for a Python || console script. To run this script uncomment the following lines in the || [options.entry_points] section in setup.cfg: ||  ||     console_scripts = ||          fibonacci = syft.skeleton:run ||  || Then run `python setup.py install` which will install the command `fibonacci` || inside your current environment. || Besides console scripts; the header (i.e. until _logger...) of this file can || also be used as template for Python modules. ||  || Note: This skeleton file can be safely removed if not needed! || \""\""\""",,Yes,Yes
24337,TODO Change this; we need a way to handle multiple plan definitions,,,Yes
24341,"\""\""\"" || Methods which we overwrite when building the plan || This list might become bigger as we should support more operations ||  || Why is needed? || When the local party builds the plan it needs to trace the operations that || are done on a CrypTensor and CrypTenModule. It does not know about || what data\/model are involved in the computation. || Because of this; when building the plan; the local party can work with || only some \""shells\"" of specific operations ||  || Workflow for local party -- can be seen in syft\/frameworks\/crypten\/context.py: || 1. replace real functions\/methods with shell like functions\/methods (only for some) || 2. Call \""crypten_init\"" (to be able to perform some of the CrypTen computation on the ||   shell CryptenTensors\/CryptenModules) ||    Eg: cryptensor + cryptensor ||   If this is not done CrypTen will throw an exception because there is tried || to run crypten specific computation in a not crypten environment || 3. build the plan (register the set of actions that should be performed) || 4. Call \""crypten_uninit\"" || 5. Undo the operations done at step 1 ||  || Q: Why get_plain_text appears only in the crypten_to_auto_overload; but not || in crypten_plan_hook? || A: 1. The method is added to the PlaceHolder class such that when the plan is || built it would be traced. ||    2. The local party will build the plan by being in a CrypTen context (there || is called \""crypten.init()\"" before building the plan) and calling \""get_plain_text\"" || on the \""shell\"" CrypTensor (in our case is a CrypTensor that has only values of 0) || will not require to overwrite another function || \""\""\""",,,Yes
24344,Create action informat needed for role's register_action method,,Yes,Yes
24345,"\""\""\"" || Welcome to the :py:mod:`syft.core.worker` module! This is a good place to begin your education of || what Syft is and how it works. ||  || At it's core; Syft is a set of libraries which allows you to perform data processing on data you || cannot see. We have two core \""personas\"" within the Syft ecosystem; the \""data owner\"" and the \""data scientist\"" || (who is sometimes referred to as the \""model owner\""). The data owner has data to protect; and the data scientist || wants to answer a question using data owned by one or more data owners. ||  || Note that a data owner could be a consumer who has data on their phone; a hospital with medical records; or || even a Raspberry PI floating in the middle of the Pacific Ocean! It just represents a collection of data || within a Data Owner's domain of ownership. As such; there are three core abstractions you should know about: ||  || * :py:mod:`syft.core.worker.domain` - this API is the interface to a collection of datasets owned by a single entity. || * :py:mod:`syft.core.worker.worker` - this API is the interface to a remote machine within a data owner's domain. || * :py:mod:`syft.core.worker.client` - This API is the interface a data scientist uses to interact with a worker within\\ ||  a domain ||  || So; a domain would be something like \""Big Fancy Hospital\"" and a worker would be a single machine within that hospital || which a Data Scientist can use to process some data. A domain will have many workers; each of which could be serving || a different Data Scientist. Alternatively; one Data Scientist could be using multiple workers (such as if they have || very computationally expensive programs to run and they want to run them in parallel). ||  || \""\""\""",,Yes,Yes
24347,4. Move the native function,,,Yes
24352,FIXME make it cleaner and robust for more options,,No,Yes
24354,TODO: change services type  to List[WorkerService] when typechecker allows subclassing,,,Yes
24357,TODO: add available compute types,,,Yes
24359,particular kind of context to know how to use it. We should be,,No,Yes
24362,FIXME make it cleaner and robust for more options,,,Yes
24364,"\""\""\""The purpose of this application is to allow us to dev and test PySyft || functionality on an actual local network. This is NOT meant to be run in || production (that's the *actual* grid's job).\""\""\""",,,Yes
24366,"\""\""\""The purpose of this application is to allow us to dev and test PySyft || functionality on an actual local network. This is NOT meant to be run in || production (that's the *actual* grid's job).\""\""\""",,Yes,Yes
24368,TODO create,,,Yes
24370,TODO: instead of passing in a list; come up with an abstractoin for,,Yes,Yes
24374,TODO: solve this with node group address?,,No,Yes
24377,TODO: send EventualActionWithoutReply to delete the object at the node's,,,Yes
24379,FIXME make it cleaner and robust for more options,,No,Yes
24381,breaking convention here because index_globals needs,,Yes,Yes
24383,Put the other way around - blocking people from modifying,,No,Yes
24384,TODO: filter on this error to only include errors,,No,Yes
24386,"\""\""\"" ||  || *************************************************** || Tutorial: Serialization and Deserialization in Syft || *************************************************** ||  || In this file; we have the main Serializable class which orchestrates || the serialization of objects within the Syft ecosystem. Users and || developers of Syft need to serialize objects for a myriad of reasons; || but the most common 3 are: ||  || - to save an object into a database which requires serialization (such as key-value dbs like Redis) || - to send an object over the network (any protocol). || - to save an object to disk. ||  || All serialization in Syft uses a library called 'protobuf'. || This is a technology developed at Google for fast; secure || serialization of objects (https:\/\/developers.google.com\/protocol-buffers). || We use an existing library like Protobuf for multiple reasons: ||  || - Protobuf creates cross-language serialization abilities || - Protobuf is secure || - Protobuf is fast. ||  || In short; lots of projects need serialization and so a lot of time || and effort has gone into creating great serialization libraries. Thus; || we want to inherit the work of others instead of having to reinvest the time || to build these things ourselves. ||  || .. note:: DO NOT attempt to create your own serialization by ||     creating strings out of objects yourself. Not only will this almost ||     certainly be slower than using a technology like protobuf; ||     but you will require everyone to re-implement your serialization ||     techniques in every language which needs to support your object ||     AND you run the risk of introducing dangerous SECURITY FLAWS. ||     This is a place where we definitely want to use a robust library ||     like protobuf. ||  ||  || Serializing and Deserializing Syft Objects: || ########################################### ||  || If you want to serialize an object in the syft ecosystem; the easiest way || to do so is to just call one of the serialization methods which we install || on the object for your convenience:: ||  ||     import syft as sy ||  ||     # ObjectWithID is the simplest object in the Syft ecosystem ||     # It's the parent class of many other classes. As the name ||     # implies; it's literally just an object with an ID. ||     # We'll use it to show serialization; but you can use the ||     # same approach with any serializable object in the Syft ||     # ecosystem. ||     from syft.core.common.object import ObjectWithID ||  ||     # this creates an object which has an id ||     my_object = ObjectWithID() ||  ||     print(my_object) ||     # >>> <ObjectWithID:fb1bb067-5bb7-4c49-bece-e700ab0a1514> ||  ||     # by default; .serialize() will serialize it to a protobuf Message object ||     proto_obj = my_object.serialize() ||  ||     print(proto_obj) ||     # >>> obj_type: \""syft.core.common.object.ObjectWithID\"" ||     # >>> id { ||     # >>>   obj_type: \""syft.core.common.uid.UID\"" ||     # >>>   value: \""23hi23hgo2ih23ih2;o3igh;2oih;iagapwihpag\"" ||     # >>> } ||  ||     # deserialization also assumes you are accepting a protobuf object ||     my_object_again = sy.deserialize(blob=proto_obj) ||  ||     print(my_object_again) ||     # >>> <ObjectWithID:fb1bb067-5bb7-4c49-bece-e700ab0a1514> ||  || However; perhaps the best thing about protobuf is that it can easily || be turned into a wide variety of very portable representations. We have || convenience functions for 4 popular represenations: protobuf; json; binary; || and hex. Setup:: ||  ||     import syft as sy ||     from syft.core.common.object import ObjectWithID ||  ||     obj = ObjectWithId() ||  || Protobuf || ******** ||  || .. code:: ||  ||     proto_obj = obj.serialize(to_proto=True) ||     proto_obj = obj.to_proto() ||     proto_obj = obj.proto() ||  ||     print(proto_obj) ||     # >>> obj_type: \""syft.core.common.object.ObjectWithID\"" ||     # >>> id { ||     # >>>   obj_type: \""syft.core.common.uid.UID\"" ||     # >>>   value: \""23hi23hgo2ih23ih2;o3igh;2oih;iagapwihpag\"" ||     # >>> } ||  ||     obj_again = sy.deserialize(blob=proto_obj; from_proto=True) ||  || JSON || **** ||  || .. code:: ||  ||     json_obj = obj.serialize(to_json=True) ||     json_obj = obj.to_json() ||     json_obj = obj.json() ||  ||     print(json_obj) ||     # >>> { ||     # >>>   \""objType\"": \""syft.core.common.object.ObjectWithID\""; ||     # >>>   \""id\"": { ||     # >>>     \""objType\"": \""syft.core.common.uid.UID\""; ||     # >>>     \""value\"": \""+xuwZ1u3TEm+zucAqwoVFA==\"" ||     # >>>   } ||     # >>> } ||  ||     obj_again = sy.deserialize(blob=proto_obj; from_json=True) ||  || Binary || ****** ||  || .. code:: ||  ||     binary_obj = obj.serialize(to_binary=True) ||     binary_obj = obj.to_binary() ||     binary_obj = obj.binary() ||  ||     # print(binary_obj) ||     # >>> b'{  \""objType\"": \""syft.core.common.object.ObjectWithID\""; ||     # >>> \""id\"": {    \""objType\"": \""syft.core.common.uid.UID\""; ||     # >>> \""value\"": \""+xuwZ1u3TEm+zucAqwoVFA==\""  }}' ||  ||     obj_again = sy.deserialize(blob=proto_obj; from_binary=True) ||  || Now we can continue with the class definition for the Serializable class; which || is the parent class for all serializable objects within Syft. ||  || If you'd like to see a simple example of a class which can be serialized; please read || the source code of :py:mod:`syft.core.common.object.ObjectWithID`. || \""\""\""",,Yes,Yes
24388,TODO: Support ImmediateNodeServiceWithoutReply Parent Class,,,Yes
24389,this is a check to see if the must implement methods were implemented;,,Yes,Yes
24390,TODO: Fix AbstractNode and LocationAwareObject being incompatible,,Yes,Yes
24391,TODO: Fix AbstractNode and LocationAwareObject being incompatible,,Yes,Yes
24392,TODO: remove this flag if commenting it out doesn't break anything,,Yes,Yes
24395,)  # nosec # TODO make less insecure,,No,Yes
24396,TODO: ensure that constructor has been installed!!!,,No,Yes
24401,"TODO: obj should be just \""object\"" and the attributes",,,Yes
24402,TODO: use hash function here.,,,Yes
24403,TODO: remove this,,No,Yes
24405,TODO: overload all methods to incorporate this automatically,,Yes,Yes
24407,TODO: Support ImmediateNodeServiceWithoutReply Parent Class,,,Yes
24408,TODO: Support ImmediateNodeServiceWithReply Parent Class,,Yes,Yes
24410,TODO: put thought into garbage collection and then,,,Yes
24411,TODO: horrible temp hack; need to rethink address on SignedMessage,,No,Yes
24412,better way. But we want to support other frameworks so - gotta do it.,,,Yes
24420,TODO: not sure if this is needed anymore,,,Yes
24421,TODO: prevent device being set when Authorization fails,,,Yes
24424,TODO: we need _proto2object to include a reference to the node doing the,,No,Yes
24425,TODO: FIX THIS SECURITY BUG!!! WE CANNOT USE,,,Yes
24426,TODO remove brute search of all store objects,,,Yes
24430,serialize a client object. TODO: Fix limitation in Pointer so that we don't need this.,,,Yes
24431,TODO: Fix circular import for Client interface,,Yes,Yes
24432,TODO: Fix the Client; Address; Location confusion,,Yes,Yes
24433,TODO: we need _proto2object to include a reference to the node doing the,,No,Yes
24434,TODO: tighten to return Callable,,No,Yes
24435,"BASIC_METHOD_ARGS.append(\""0\"") #TODO: add ints as remote argument types (can't call .serialize() on int)",,No,Yes
24440,TODO: Fix this hack,,Yes,Yes
24441,TODO: overload all methods to incorporate this automatically,,Yes,Yes
24444,TODO: We should detect tensor vs primitive in a more reliable way,,Yes,Yes
24447,TODO reintroduce new primitive logic,,,Yes
24449,TODO: this should work but they are not,,No,Yes
24450,TODO this sould work,,Yes,Yes
24452,TODO; this might be a good lead on how to make Bool feel more real; make Bool subclass int,,Yes,Yes
24453,TODO this should work,,Yes,Yes
24455,TODO these should fail,,,Yes
24456,TODO: adapt to the new primitive,,Yes,Yes
24457,"BASIC_METHOD_ARGS.append(\""True\"") #TODO: can't call .serialize() on bool",,Yes,Yes
24461,TODO: put thought into garbage collection and then,,,Yes
24462,TODO why?,,Yes,Yes
24464,XXX: on a 64-bit system; this doesn't raise an overflow error;,,,Yes
24465,TODO Uncomment this,,Yes,Yes
24466,FIXME improve Complex.__new__() to have the same TypeError as complex,,,Yes
24473,TODO: remove hacky signaling_msgs when SyftMessages become Storable.,,Yes,Yes
24476,"\""\""\"" || PySyft Duet (WebRTC) ||  ||     This class aims to implement the PySyft Duet || concept by using WebRTC protocol as a connection || channel in order to allow two different users to || estabilish a direct connection with high-quality || Real-time Communication using private addresses. ||  ||     The most common example showing how does it || can be used is the notebook demo example: ||  ||     Two different jupyter\/collab notebooks in || different machines using private addresses behind || routers; proxies and firewalls can connect to || each other using a full-duplex channel in order || to perform machine learning and data science tasks; || working as a client and server at the same time. ||  || PS 1: You'll need a signaling server running somewhere. || If you don't know any public address running this service; or || want to set up your own signaling network you can use PyGrid's network app. ||  || PS 2: The PyGrid's dev\/master branches are still supporting PySyft 0.2.x; || To use this feature you must use the pygrid_0.3.0 branch. || (https:\/\/github.com\/OpenMined\/PyGrid\/tree\/pygrid_0.3.0) ||  || You can get more details about all this process; || in the syft\/grid\/connections\/webrtc.py source code. || \""\""\""",,,Yes
24478,TODO: remove temp hack,,,Yes
24479,hack for working around generators,,Yes,Yes
24485,TODO: add check to make sure this isn't getting around,,,Yes
24487,Starting from sequential data; batchify arranges the dataset into columns.,,,Yes
24488,These columns are treated as independent by the model; which means that the,,Yes,Yes
24489,dependence of e. g. 'g' on 'f' can not be learned; but allows more efficient,,Yes,Yes
24491,and using them as both Tensors and inputs covers a lot of the functionality.,,Yes,Yes
24492,actually needed,,Yes,Yes
24493,TODO: Fix this workaround for types that sometimes return Tensor tuples,,,Yes
24494,TODO: Fix this when we find one,,,Yes
24495,TODO: Fix this from deleting the object in the store due to the variable,,Yes,Yes
24498,TODO: Fix this when we find one,,,Yes
24500,TODO: support torch.nn.modules.module._IncompatibleKeys,,No,Yes
24502,nosec # TODO make less insecure,,,Yes
24503,TODO: FIX THIS SECURITY BUG!!! WE CANNOT USE,,Yes,Yes
24504,"allowlist[\""torch.Tensor.__torch_function__\""] = \""unknown\"" # 1.7.0 # probably wont work",,Yes,Yes
24505,keep this workaround,,,Yes
24507,TODO: rethink this and perhaps dunder __sy prefix all our attached methods,,,Yes
24510,TODO: Remove this Opacus workaround,,,Yes
24515,"\""\""\"" ||  The AST part of syft is responsible for the overall remote call execution. Basically; the AST is a ||  tree that maps function call to their exact path and know what to do with that node in the tree. ||  ||  Example: We want to append an object to a List; meaning ||  that we know where should we find it; so we need to know the following chain: ||  ||                 globals  <- the global scope or the entry point of execution (hidden) ||                    | ||                   syft   <- the syft module ||                    | ||                   lib   <- a submodule of syft ||                    | ||                   List <- the class we were looking for ||                    | ||                 append <- the method we were looking for ||  || This path has to be solved when doing remote execution as well; this is where the AST comes handy. || The ast is responsible for: ||  || A. Remote execution. || B. Local execution. ||  || A. Remote execution. || Remote execution can be performed only when the AST has been constructed with a client. Check || syft\/core\/node to be familiar with the roles of clients and nodes. Each valid action on the ast || triggers an Action (GetSetStaticAttributeAction; GetSetPropertyAction; etc. This kind of actions || require: the path on solving the required node (on the above example; the path is || syft.lib.List.append); the object on which to perform it (given by the __self attribute and from || id_at_location if executed on a pointer) and the attributes if needed. ||  || B Local execution. || After a call has been made; the remote execution starts; but we need a local handler for the result || of the remote execution through a Pointer. The AST is responsible to generate all the || permitted methods and attributes on a Pointer and the return type of the performed action. ||  ||  || The existing types of nodes are: || * a Globals; which is the entrypoint of execution; from here you can only access Modules. ||  || * a Callable; which can be a node for: a method; a static method; a function; a constructor. This || node can no longer have any attributes. ||  || * a Class; which is a node that represents a python class. This node can contain in it: methods - Callable; || static methods - Callable; class method - Callable; slot attributes - StaticAttribute; properties - Property; || enum attributes - EnumAttribute. ||  || * a Module; which represents a python file\/module. This node can have as an attribute: global || variables - StaticAttribute; global functions - Callable and classes - Klass. ||  || * a StaticAttribute - represents attribute of a Class or of a Module. This node can no longer have || any more attributes. This can be remotely get and set. ||  || * a Property - represents a @property object of a class. This node can no longer have any more || attributes - a leaf. This can remotely get and set. ||  || * a EnumAttribute - represents the fields generated by an Enum. This node can no longer have any || more attributes - a leaf. This can be remotely get. || \""\""\""",,,Yes
24516,todo: make sure that operations return the correct tensor type,,No,Yes
24524,TODO(niboshi): Remove this workaround after ChainerX supports,,Yes,Yes
24525,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
24526,TODO(niboshi): This is a temporary workaround to keep backward,,Yes,Yes
24527,TODO(niboshi): This is a temporary workaround to keep backward,,,Yes
24528,TODO(sonots): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24529,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24532,FIXME: avoid `isinstance`,,No,Yes
24536,This file defines workaround implementation for,,,Yes
24537,The workaround does not support backprop; and also requires external,,Yes,Yes
24539,Fix F812 (Python 2),,Yes,Yes
24540,TODO(sonots): Implement for ChainerX,,Yes,Yes
24541,Fix F812 (Python 2),,Yes,Yes
24543,Copy is needed to avoid being updated during backprop; which,,,Yes
24545,No trivial way to implement double-backward for this function.,,,Yes
24546,Workaround for ChainerX,,,Yes
24547,No trivial way to implement double-backward for this function.,,No,Yes
24548,with the CUDA backend. This is needed in order to share the GPU memory,,Yes,Yes
24549,FIXME: avoid `isinstance`,,No,Yes
24550,Fix F812 (Python 2),,Yes,Yes
24551,TODO(beam2d): implement mean,,Yes,Yes
24552,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
24554,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
24556,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
24557,TODO(sonots): Implement for ChainerX,,,Yes
24560,casuses some needed variables to be set to None,,Yes,Yes
24561,causes some needed variables to be set to None,,,Yes
24564,TODO(hvy): Move this function to backend?,,,Yes
24565,Work-around for NumPy's bug?,,Yes,Yes
24566,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,Yes,Yes
24567,Copy is needed to avoid being updated during backprop; which,,,Yes
24568,`skip_between_cupy_devices` argument is a workaround,,No,Yes
24569,FIXME: avoid `isinstance`,,No,Yes
24570,Fix F812 (Python 2),,Yes,Yes
24571,x.flags.writeable = True  # TODO(beam2d): remove this workaround,,Yes,Yes
24574,the CUDA backend. This is needed in order to share the GPU memory,,Yes,Yes
24576,TODO(niboshi): Better remove dependency to cupy,,Yes,Yes
24579,TODO(tommi): Implement group whitening,,Yes,Yes
24580,TODO(crcrpar): Implement this.,,Yes,Yes
24581,x.flags.writeable = True  # TODO(beam2d): remove this workaround,,Yes,Yes
24583,self._device as much as possible because it is really costly.,,,Yes
24586,fix py2 memory leak,,Yes,Yes
24589,FIXME: avoid `isinstance`,,,Yes
24590,Fix F812 (Python 2),,Yes,Yes
24591,FIXME: avoid `isinstance`,,No,Yes
24592,self._device as much as possible because it is really costly.,,Yes,Yes
24595,TODO(hvy): Move this function to backend?,,,Yes
24596,fix py2 memory leak,,Yes,Yes
24597,self._device as much as possible because it is really costly.,,Yes,Yes
24598,TODO(hvy): Fix exception.,,,Yes
24599,TODO(niboshi): Fix ChainerX for None inputs,,Yes,Yes
24600,This is a dirty workaround to avoid writing the skip logic in every,,,Yes
24601,self._device as much as possible because it is really costly.,,Yes,Yes
24604,Fix F812 (Python 2),,Yes,Yes
24606,FIXME: avoid `isinstance`,,No,Yes
24607,self._device as much as possible because it is really costly.,,Yes,Yes
24608,Fix F812 (Python 2),,Yes,Yes
24609,As there is no way to ensure correct finalization; we simply skip,,Yes,Yes
24610,self._device as much as possible because it is really costly.,,Yes,Yes
24612,TODO(hvy): Move this function to backend?,,,Yes
24613,TODO(beam2d): Fix after supporting correct dtype promotion.,,Yes,Yes
24614,TODO(hvy): Fix after supporting correct dtype promotion.,,Yes,Yes
24615,self._device as much as possible because it is really costly.,,Yes,Yes
24616,Fix F812 (Python 2),,,Yes
24621,in order to better utilize CPU cache memory.,,,Yes
24622,`entry_method_info` is for backward compatibility workaround for,,,Yes
24623,Backward compatibility workaround for overridden methods,,,Yes
24625,Explore better representation by if-block.,,,Yes
24626,TODO(sonots): Implement for ChainerX,,,Yes
24627,TODO(sonots): Implement for ChainerX,,,Yes
24628,`skip_between_cupy_devices` argument is a workaround,,,Yes
24629,TODO(niboshi): Deprecate overriding these methods in a future release,,,Yes
24630,It allows passing `params` as ndarrays instead of `Parameter`s and thus,,,Yes
24633,Explore better representation by if-block.,,Yes,Yes
24635,TODO(niboshi): Fix strides for 0-size inputs,,Yes,Yes
24636,sorted order. Fix this.,,Yes,Yes
24639,TODO(niboshi): Deprecate overriding these methods in a future release,,Yes,Yes
24640,`skip_between_cupy_devices` argument is a workaround,,No,Yes
24641,Workaround to reflect changing `alpha` in `final_lr`.,,Yes,Yes
24642,TODO(niboshi): Deprecate overriding these methods in a future release,,Yes,Yes
24644,TODO(niboshi): Deprecate overriding these methods in a future release,,Yes,Yes
24650,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24651,Test loading is nice.,,Yes,Yes
24652,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24653,Hack for Issue #6778,,No,Yes
24654,Workaround NumPy 1.9 issue.,,Yes,Yes
24658,workaround for overridden methods.,,,Yes
24659,It is a DeviceResident if to_xxx methods were initially called,,No,Yes
24660,that would occur by calling to_xxx methods.,,,Yes
24662,TODO(kataoka): Implement chainerx.backward(output; grad_outputs),,,Yes
24663,and remove this workaround.,,Yes,Yes
24665,workaround for overridden methods.,,,Yes
24668,TODO(niboshi): This is a temporary workaround to keep backward,,Yes,Yes
24669,TODO(niboshi): This is a temporary workaround to keep backward,,,Yes
24671,and remove this workaround.,,Yes,Yes
24672,Move the check to elsewhere and remove this workaround.,,,Yes
24674,and remove this workaround.,,,Yes
24676,fix py2 memory leak,,Yes,Yes
24677,Fix F812 (Python 2),,Yes,Yes
24678,TODO(sonots): Implement for ChainerX,,Yes,Yes
24679,TODO(sonots): Implement for ChainerX,,Yes,Yes
24680,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24681,((); 0); # TODO(sonots): Fix compatibility,,Yes,Yes
24683,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24684,((); 0); # TODO(sonots): Fix compatibility,,,Yes
24685,((); 0); # TODO(sonots): Fix compatibility,,,Yes
24686,fix py2 memory leak,,Yes,Yes
24687,Fix F812 (Python 2),,Yes,Yes
24688,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,,Yes
24693,TODO(sonots): Implement for ChainerX,,Yes,Yes
24695,Fix F812 (Python 2),,,Yes
24697,TODO(hvy): Temporarily disabled for chainerx. Fix it.,,,Yes
24700,Fix F812 (Python 2),,Yes,Yes
24701,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24705,TODO: when pickling in one process and restoring in other,,Yes,Yes
24710,TODO(niboshi): Fix it,,Yes,Yes
24711,TODO norm in chainerx,,,Yes
24712,TODO(niboshi): Fix it,,Yes,Yes
24714,TODO(niboshi): Fix it,,,Yes
24716,TODO(kshitij12345): Fix when chainerx.clip,,Yes,Yes
24718,TODO(niboshi): Fix it,,,Yes
24719,Fix F812 (Python 2),,Yes,Yes
24720,TODO(niboshi): Fix it,,,Yes
24721,Fix F812 (Python 2),,Yes,Yes
24723,sorted order. Fix this.,,,Yes
24724,sorted order. Fix this.,,Yes,Yes
24726,TODO(kshitij12345): Fix when chainerx.clip,,Yes,Yes
24728,support autotune so this hack is necessary,,Yes,Yes
24729,TODO(hvy): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24732,FIXME,,,Yes
24733,FIXME,,Yes,Yes
24734,FIXME,,,Yes
24735,FIXME,,Yes,Yes
24736,FIXME,,Yes,Yes
24737,TODO(hvy): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
24740,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,,Yes
24743,Unused for some reason; then params are not initialized.,,Yes,Yes
24745,sorted order. Fix this.,,Yes,Yes
24748,FIXME (himkt) workaround,,,Yes
24749,XXX,,,Yes
24751,TODO(matt): this isn't quite right; because you really want to split on sentences;,,,Yes
24752,"\""\""\"" || A ``TextField`` represents a string of text; the kind that you might want to represent with || standard word vectors; or pass through an LSTM. || \""\""\""",,Yes,Yes
24753,TODO(mattg): actually implement this.,,Yes,Yes
24754,TODO: replace with actual types,,No,Yes
24759,Throughout this class; in the `get_*` methods; we have unused import statements.  That is,,Yes,Yes
24760,Conll format data begins and ends with lines containing a hash;,,No,Yes
24761,TODO(joelgrus): add a predict_tensor method maybe?,,,Yes
24762,TODO(joelgrus) implement this,,No,Yes
24763,TODO(joelgrus): make this configurable,,,Yes
24764,TODO(joelgrus): make this configurable,,Yes,Yes
24766,There are no classes to decorate; so we hack these into Registrable._registry,,Yes,Yes
24767,"TODO(Mark): Add user specified metrics here; maybe a \""metrics\"" key?",,,Yes
24769,potential from 2 -> 1; making [3; 2; 1] the best path.,,Yes,Yes
24771,There are no classes to decorate; so we hack these into Registrable._registry,,Yes,Yes
24772,There are no classes to decorate; so we hack these into Registrable._registry,,,Yes
24775,TODO: get rid of this,,,Yes
24779,Grim hack to determine whether the validation metric we are recording,,Yes,Yes
24781,"\""\""\"" || The ``serve`` subcommand launches a server || that exposes trained models via a REST API; || and that includes a web interface for exploring || their predictions. ||  || .. code-block:: bash ||  ||     $ python -m allennlp.run serve --help ||     usage: run [command] serve [-h] [--port PORT] [--workers WORKERS] ||                             [--config-file CONFIG_FILE] ||  ||     Run the web service; which provides an HTTP API as well as a web demo. ||  ||     optional arguments: ||     -h; --help            show this help message and exit ||     --port PORT ||     --workers WORKERS ||     --config-file CONFIG_FILE ||                             path to a JSON file specifying the configuration for ||                             the models || \""\""\""",,Yes,Yes
24782,When we were using exlcusive span ends; this was an edge case of the dynamic program.,,Yes,Yes
24783,"\""\""\"" || A :class:`~allennlp.data.fields.field.Field` is some piece of data instance || that ends up as an array in a model. || \""\""\""",,No,Yes
24784,Hack to see what cuda device the model is on; so we know where to put these inputs.  For,,Yes,Yes
24785,a way to actually query what device a tensor \/ parameter is on.,,Yes,Yes
24786,In order to avoid loading spacy models a whole bunch of times; we'll save references to them;,,,Yes
24791,We'll special-case a few settings here; where there are efficient (but poorly-named),,,Yes
24792,Is (sequence_length; batch_size); but all the columns are the same; so take the first.,,,Yes
24795,the multiple calls to util.batched_index_select below more efficient.,,,Yes
24797,Masks for the unused states of shape (1; new_batch_size; 1),,No,Yes
24798,that there are some unused elements (zero-length) for the RNN computation.,,,Yes
24799,Private base class; no docs needed.,,Yes,Yes
24801,handle the different gate order convention,,,Yes
24803,reshape the input if needed,,,Yes
24808,Import any additional modules needed (to register custom classes),,Yes,Yes
24814,These span widths are off by 1; because the span ends are `inclusive`.,,Yes,Yes
24815,We're using <= here (and for the mask below) because the span ends are,,Yes,Yes
24817,With 100 instances; shuffling better change the order.,,Yes,Yes
24820,Save model if needed.,,Yes,Yes
24823,we add 1 to the span ends as the AllenNLP ``SpanField`` is inclusive.,,Yes,Yes
24825,Forward Direction: end indices are inclusive; so we can just use span_ends.,,No,Yes
24830,This is un-needed and clutters the label space.,,Yes,Yes
24831,Import any additional modules needed (to register custom classes).,,Yes,Yes
24836,We group together all current states to get more efficient (batched) computation.,,,Yes
24837,Instance with batch index 2 needed too many steps to finish; and batch index 3 had no,,Yes,Yes
24838,TODO (pradeep): Sort the indices and do intersections in order; so that we can return the,,Yes,Yes
24839,Following Sempre's convention for naming columns.  Sempre gives columns unique names when,,,Yes
24841,Following Sempre's convention for naming cells.,,,Yes
24842,need for this function somehow?  It's causing a whole lot of headaches.,,,Yes
24844,linking score won't have any way to differentiate them...  We should figure,,Yes,Yes
24846,appear in the logical forms; we have a way of specifying ``constant_type_prefixes`` and passing,,Yes,Yes
24847,"\""\""\"" || This module defines some classes that are generally useful for defining a type system for a new || domain. We inherit the type logic in ``nltk.sem.logic`` and add some functionality on top of it || here. There are two main improvements: || 1) Firstly; we allow defining multiple basic types with their own names (see ``NamedBasicType``). || 2) Secondly; we allow defining function types that have placeholders in them (see || ``PlaceholderType``). || We also extend NLTK's ``LogicParser`` to define a ``DynamicTypeLogicParser`` that knows how to deal || with the two improvements above. || \""\""\""",,Yes,Yes
24849,"TODO(pradeep): Assuming the mapping of \""var\"" function is \""V\"". Do something better.",,Yes,Yes
24852,TODO (pradeep): This is messy. Fix the type declaration so that we don't have to deal,,No,Yes
24853,cells and columns and a few simple numbers; so we can get them as valid actions in the,,Yes,Yes
24855,Most of these are instance-specific production rules.  These are the columns in the,,Yes,Yes
24856,"We add columns to the name mapping in sorted order; so \""league\"" and \""year\"" end up as C2",,Yes,Yes
24858,be in the bounds of DataArray; but ProductionRuleArray definitely isn't.  TODO(mattg): maybe we,,Yes,Yes
24859,should find a better way to loosen those bounds; or let people extend them.  E.g.; we could have,,Yes,Yes
24860,needed if we want to define some sort of a hinge-loss based trainer. Deal with,,,Yes
24862,We look at the epoch number and adjust the checklist cost weight if needed here.,,No,Yes
24863,TODO (pradeep): Assuming all worlds give the same set of valid actions.,,Yes,Yes
24864,TODO (pradeep): The denotation based cost below is strict. May be define a cost based on,,Yes,Yes
24865,TODO (pradeep): Make this cleaner.,,Yes,Yes
24869,No entities of this type; move along...,,,Yes
24870,TODO(mattg): this could probably be moved into a FullSequenceMatch metric; or something.,,Yes,Yes
24872,sequence currently. Maybe define top-k metrics?,,Yes,Yes
24873,TODO(Mark): Remove this once tqdm cleans up after itself properly.,,No,Yes
24874,TODO(pradeep): Can move most of this block to super class.,,Yes,Yes
24877,TODO(pradeep): Move this method to nn.decoding.util,,,Yes
24879,Hack to allow evaluation on different domains than the,,,Yes
24880,Hack in our Optimizer class to the trainer,,Yes,Yes
24882,Hack for RNNs,,,Yes
24884,TODO(joelgrus): better error handling,,,Yes
24885,Hack because e.g. typing.Union isn't a type.,,,Yes
24888,figure out where it really belongs,,Yes,Yes
24890,of instances each epoch; and we didn't specify how to many instances to load,,,Yes
24891,There's enough logic here to require a custom from_params.,,,Yes
24892,The empty_list here is needed for mypy,,,Yes
24895,"\""\""\"" || An implementation of the OpenAI Transformer Language Model. ||  || Mostly just a slightly modified version of || https:\/\/github.com\/huggingface\/pytorch-openai-transformer-lm || so thanks to them! ||  || Some of these modules duplicate code elsewhere in AllenNLP; || but the serialized weights depend on the exact parameter setup || here; so it's easiest to just reimplement them. || \""\""\""",,,Yes
24896,numpy can't read from a tarfile directly; so we need a workaround,,Yes,Yes
24897,Good request; should work.,,Yes,Yes
24900,them later; as that's a really easy operation.,,Yes,Yes
24901,regroup them later; as that's a really easy operation.,,Yes,Yes
24902,bmes_tag == 'M'; move to next.,,Yes,Yes
24903,Move to next span.,,Yes,Yes
24904,"\""\""\"" || This module contains the ``State`` abstraction for defining state-machine-based decoders; and some || pre-built concrete ``State`` classes for various kinds of decoding (e.g.; a ``GrammarBasedState`` || for doing grammar-based decoding; where the output is a sequence of production rules from a || grammar). ||  || The module also has some ``Statelet`` classes to help represent the ``State`` by grouping together || related pieces; including ``RnnStatelet``; which you can use to keep track of a decoder RNN's || internal state; ``GrammarStatelet``; which keeps track of what actions are allowed at each timestep || of decoding (if your outputs are production rules from a grammar); and ``ChecklistStatelet`` that || keeps track of coverage information if you are training a coverage-based parser. || \""\""\""",,Yes,Yes
24905,would make it really hard to compare to previous work. Sad times.,,,Yes
24906,needed if we want to define some sort of a hinge-loss based trainer. Deal with,,Yes,Yes
24908,between them. Also note that columns are basic types in this grammar.,,,Yes
24909,TODO(pradeep): Add different column types for string; number; and date columns; and may be a,,Yes,Yes
24913,### Our first order of business is to implement our <code>DatasetReader<\/code> subclass.,,,Yes
24914,### The other class you'll basically always have to implement is <code>Model<\/code>; which is a subclass of <code>torch.nn.Module<\/code>. How it works is largely up to you; it mostly just needs a <code>forward<\/code> method that takes tensor inputs and produces a dict of tensor outputs that includes the loss you'll use to train the model. As mentioned above; our model will consist of an embedding layer; a sequence encoder; and a feedforward network.,,,Yes
24915,### As in the original PyTorch tutorial; we'd like to look at the predictions our model generates. AllenNLP contains a <code>Predictor<\/code> abstraction that takes inputs; converts them to instances; feeds them through your model; and returns JSON-serializable results. Often you'd need to implement your own Predictor; but AllenNLP already has a <code>SentenceTaggerPredictor<\/code> that works perfectly here; so we can use it. It requires our model (for making predictions) and a dataset reader (for creating instances).,,Yes,Yes
24916,still TODO:,,Yes,Yes
24917,NOTE: DATA hack alert - the geography dataset doesn't alias derived tables consistently;,,Yes,Yes
24918,TODO(kevin): get this in a more principled way somehow?,,Yes,Yes
24920,TODO(mattg): this could probably be moved into a FullSequenceMatch metric; or something.,,Yes,Yes
24921,TODO(kevin): move the SQL execution to an executor.,,,Yes
24922,TODO (pradeep): This is messy. Fix the type declaration so that we don't have to deal,,,Yes
24923,TODO (pradeep): This will be unnecessary when we have column types identified.,,No,Yes
24925,"in \""league\"" columns.",,,Yes
24926,TODO (pradeep): Figure out whether this is expected behavior by looking at data.,,Yes,Yes
24927,TODO(Mark): Horrible hack; remove,,Yes,Yes
24928,"TODO(mattg): Move the \""valid_actions\"" construction to another method.",,Yes,Yes
24929,"Looking for lambda productions; but not for cells or columns with the word \""lambda\"" in",,Yes,Yes
24930,way we're doing this could lead to false positives for something like '1e2'; but,,,Yes
24931,linking score won't have any way to differentiate them...  We should figure,,Yes,Yes
24932,out a better way to handle this.,,Yes,Yes
24935,TODO (pradeep): Do we need constant type prefixes?,,Yes,Yes
24936,TODO (pradeep): Update agenda definition and rethink this field.,,,Yes
24937,The empty_list here is needed for mypy,,,Yes
24939,TODO: Keep token level information here?,,Yes,Yes
24941,Rest of init not needed for denotation only where no decoding to actions needed,,Yes,Yes
24942,No entities of this type; move along...,,Yes,Yes
24943,TODO(mattg): this could probably be moved into a FullSequenceMatch metric; or something.,,Yes,Yes
24945,TODO: Fix protected access,,,Yes
24948,First entry is by convention (above in __init__) the friction subset,,Yes,Yes
24950,"an columns of type \""date\""; then this condition would be triggered. We should",,Yes,Yes
24953,TODO (pradeep): Update agenda definition and rethink this field.,,Yes,Yes
24955,TODO (pradeep): We may eventually want to produce gzipped files like DPD output instead of,,Yes,Yes
24956,Generate instances where each token of input appears once.,,Yes,Yes
24959,TODO(mattg): this could probably be moved into a FullSequenceMatch metric; or something.,,Yes,Yes
24960,TODO(MARK): Massive hack; remove and modify the grammar accordingly,,,Yes
24962,mutable; we don't implement ``MutableMapping`` because we want,,,Yes
24963,now; and later add number and string entities as needed.,,Yes,Yes
24964,For all numbers (except -1); we add all number and date columns as their neighbors.,,Yes,Yes
24966,it as a wild-card in dates. The neighbors are the date columns.,,,Yes
24967,because we will add those to the final name mapping only if needed; based on the table content.,,No,Yes
24969,-1 is not in entities because there are no date columns in the table.,,No,Yes
24971,'5000' is neighbors with number and date columns. '-1' is in entities because there is a,,,Yes
24972,The table does not have date or number columns.,,No,Yes
24974,TODO(joelgrus): implement tie_embeddings (maybe),,,Yes
24976,columns = positions used for attention,,Yes,Yes
24977,TODO(joelgrus): figure out a better way to handle this,,,Yes
24978,TODO: figure out a better way to deal with them,,Yes,Yes
24979,Anything with a from_params method is itself configurable.,,Yes,Yes
24980,TODO(joelgrus): figure out a better way to handle this,,,Yes
24981,Postpone cleanup until exit in case the unarchived contents are needed outside,,No,Yes
24984,TODO(joelgrus): implement tie_embeddings (maybe),,,Yes
24986,this is stored to compute perplexity if needed,,,Yes
24987,TODO(brendanr): Find a way to remove this hack. The issue fundamentally is that the,,,Yes
24989,Update copy_probs needed for getting the `selective_weights` at the next timestep.,,Yes,Yes
24994,And maybe log to console,,,Yes
24995,Only the 'loss' is needed.,,Yes,Yes
24996,"Unfortunately; mypy doesn't like this very much; so we have to \""type: ignore\"" a bunch of things.",,,Yes
24997,columns as the neighbors only if any date columns exist in the table.,,,Yes
24998,type in the hierarchy going from its concrete class to the base Column.  String columns,,Yes,Yes
24999,get added as StringColumn and Column; and date and number columns get added as DateColumn,,,Yes
25002,"in \""league\"" columns.",,Yes,Yes
25007,### Next we need to implement <code>forward<\/code>; which is where,,,Yes
25008,### and returns JSON-serializable results. Often you'd need to implement your own Predictor;,,Yes,Yes
25010,Because of using +loss; 2nd epoch won't be better than 1st. So best val metrics should be same.,,,Yes
25011,the span ends before it starts.,,Yes,Yes
25013,TEST 1: Passing correct embedding_sources_mapping should work when pretrained_file attribute,,,Yes
25015,TEST 3: Passing no embedding_sources_mapping should work; if available pretrained_file,,Yes,Yes
25020,Really simple scorer - sum up the embedding_dim.,,Yes,Yes
25022,at some point in the future; once spacy has figured out a better way to handle this.,,Yes,Yes
25024,register pytorch modules directly).  This is a bit of a hack to make those work;,,Yes,Yes
25025,This is a contrived; ugly example (why would you want to duplicate names in a nested,,Yes,Yes
25028,Mapping from strings to the columns they are under.,,Yes,Yes
25029,columns of multiple types. So we just keep track of the first column type. Hence; the,,,Yes
25030,``token_columns[0]``.,,Yes,Yes
25031,register pytorch modules directly).  This is a bit of a hack to make those work;,,Yes,Yes
25032,instead of adding a `from_params` method for them somehow. Then the extras,,,Yes
25034,This is the best way to detect a NamedTuple; it turns out.,,,Yes
25036,Because of using +loss; 2nd epoch won't be better than 1st. So best val metrics should be same.,,No,Yes
25038,This is an ugly hack to get the tensorboard instance to know about the trainer; because,,Yes,Yes
25039,TODO: figure out a better way to handle this.,,,Yes
25040,TODO: gradient accumulation,,,Yes
25041,TODO(pradeep): We'll need a better way to input CoreNLP processed lines.,,Yes,Yes
25043,TODO (pradeep): We do not want the start types to be a static set. We want it to depend on the table,,Yes,Yes
25044,context instead; and include start types only when columns of a given type are present in the table.,,Yes,Yes
25046,be able to use interactive beam search (a functionality that's only implemented in the ``BeamSearch``,,,Yes
25049,TODO (nfliu): This is kind of a hack; consider splitting out part,,Yes,Yes
25052,A bit of a hack to get the right targets out of the TextField output...,,,Yes
25053,Using the namespace here is a hack...,,Yes,Yes
25054,Using the namespace here is a hack...,,Yes,Yes
25057,TODO(mattg): perhaps there's a way to get `predictions_to_labeled_instances` to,,,Yes
25059,vocab id in general...  I don't have better ideas at the moment; though.,,,Yes
25062,this process ends. Otherwise we'll crash. See,,,Yes
25064,Presumably this could be worked around with,,,Yes
25065,We'll have a check for single Embedding cases; because we can be more efficient,,Yes,Yes
25066,A bit of a ugly hack to tie embeddings.,,,Yes
25069,TODO: tighten up our type annotations and remove this,,No,Yes
25070,TODO; hardcoded position,,Yes,Yes
25071,TODO(brendanr): Is there a better way to do this?,,Yes,Yes
25077,temporary hack to not to add special tokens,,Yes,Yes
25078,to be indexed with PretrainedTokenIndexer. It also requeires hack to avoid adding special tokens...,,,Yes
25080,to be indexed with PretrainedTokenIndexer. It also requeires hack to avoid adding special tokens...,,Yes,Yes
25081,scenario 1: negative start character span (this should really never happen),,No,Yes
25082,Moved to another repo. Docs replaced by link to same.,,,Yes
25083,TEST 1: Passing correct embedding_sources_mapping should work when pretrained_file attribute,,,Yes
25084,TEST 2: Passing correct embedding_sources_mapping should work when pretrained_file,,Yes,Yes
25085,TEST 3: Passing no embedding_sources_mapping should work; if available pretrained_file,,,Yes
25086,These span widths are off by 1; because the span ends are `inclusive`.,,Yes,Yes
25087,We're using <= here (and for the mask below) because the span ends are,,Yes,Yes
25088,Hardcoding a few things because we know how BERT tokenization works,,,Yes
25089,pick the wrong superclass.  We'll worry about how to fix that when we run into an actual,,Yes,Yes
25090,really want to.  Not sure why you would ever want to in this case; this is just testing,,,Yes
25092,TODO: having to pass tokens here is SUPER gross; but otherwise this breaks the,,Yes,Yes
25093,TODO(joelgrus): implement tie_embeddings (maybe),,Yes,Yes
25095,be able to remove this work-around.,,Yes,Yes
25096,especially as we can't really call it here in a type-safe way; anyway; as we're,,,Yes
25097,If you're using from_archive to specify your model (e.g.; for fine tuning); then you,,,Yes
25098,"For most transformer models; \""a\"" and \""b\"" work just fine as dummy tokens.  For a few;",,Yes,Yes
25099,We have to check that the base reader doesn't implement manual distributed,,Yes,Yes
25100,warn about any other unused options in that group.,,,Yes
25101,because of a bug that's hard to detect; we'll read the,,,Yes
25104,NOTE: this is actually more efficient than calling `self.optimizer.zero_grad()`,,No,Yes
25106,I know of); so we'll ignore this corner case until it's needed.,,,Yes
25107,because of a bug that's hard to detect; we'll read the,,Yes,Yes
25111,W&B gives us much better system metrics,,Yes,Yes
25112,Guess common cases where the base form ends in -e:,,,Yes
25113,Converting the integral part to a long ensures a better accuracy during the recursion.,,,Yes
25114,"Rule 2: convert any type to adverb if it ends in \""ly\"".",,No,Yes
25115,"Rule 3: if a word has been categorized as a common noun and it ends with \""s\"";",,,Yes
25116,"Rule 5: convert a common noun (NN or NNS) to a adjective if it ends with \""al\""; \""ient\""; \""ish\""; \""less\""",,No,Yes
25117,"Rule 6: convert a noun to a past participle if word ends with \""ed\"".",,,Yes
25118,"In this case; if the NN-word ends with an \""s\""; it is tagged as NNS.",,Yes,Yes
25119,"python -m pattern.en.parser xml -s \""Hello; my name is Dr. Sbaitso. Nice to meet you.\"" -OTCLI",,Yes,Yes
25120,#NAME?,,Yes,Yes
25121,wish => feel => believe => seem => think => know => prove + THAT,,Yes,Yes
25123,of course; objectively; personally; really; roughly; seriously; simply; sincerely;,,,Yes
25124,"Improve 3rd person singular \""'s\"" lemma to \""be\""; e.g. as in \""he's fine\"".",,Yes,Yes
25125,since it starts with the PP and ends with the chunk head (and is meaningless without these).,,,Yes
25126,workaround for lack of nested closures in Python < 2.1,,,Yes
25127,work around a Windows Python bug,,Yes,Yes
25128,Ideally; we'd use a weak dict; but there aren't any.  A strong dict,,,Yes
25129,An better way to do this is to use a DOM parser and select the HTML elements we want.,,No,Yes
25132,A copy with only the type and id columns.,,No,Yes
25135,A better measure is term frequency - inverse document frequency (TF-IDF).,,Yes,Yes
25136,Fix HTML source indentation:,,,Yes
25137,XXX - We can probably rewrite all of this using (faster) regular expressions.,,No,Yes
25141,The given row might have more columns than the rows in the table.,,,Yes
25142,applying the group function to the other columns.,,No,Yes
25143,Table.columns[x].map(lambda s: date(s)),,No,Yes
25144,--- COLUMNS -----------------------------------------------------------------------------------------,,,Yes
25146,Columns[-1],,Yes,Yes
25147,At one point a Column object was created with Table.columns[j].,,Yes,Yes
25148,This makes most sense if the order in which columns should appear is supplied.,,Yes,Yes
25150,Filter words (columns) that have a low relevancy in all documents from the matrix.,,,Yes
25151,- If the word ends -at; -bl or -iz add -e (luxuriat => luxuriate).,,,Yes
25152,- If the word ends with a double remove the last letter (hopp => hop).,,,Yes
25154,Fix: ASCII ends at 127; not 255,,,Yes
25156,this is really out of control and should be refactored,,Yes,Yes
25157,Note: probably shouldn't simply recreate localname here; but,,No,Yes
25158,special hack for better tracking of empty textinput\/image elements in illformed feeds,,Yes,Yes
25160,thanks to Kevin Marks for this breathtaking hack to deal with (valid) high-bit attribute values in UTF-8 feeds,,,Yes
25161,This evil genius hack has been brought to you by Aaron Swartz.,,,Yes
25165,2.7.5 - 1\/15\/2004 - MAP - added workaround for malformed DOCTYPE (seen on many,,No,Yes
25166,2.7.6 - 1\/16\/2004 - MAP - fixed bug with StringIO importing,,,Yes
25168,in copyright; better sanitizing of dangerous HTML elements with end tags,,Yes,Yes
25170,fixed bug capturing author and contributor URL; fixed bug resolving relative,,Yes,Yes
25172,3.0b19 - 3\/15\/2004 - MAP - fixed bug exploding author information when author,,Yes,Yes
25173,workaround crash in PyXML\/expat when encountering invalid entities,,Yes,Yes
25176,3.3 - 7\/15\/2004 - MAP - optimize EBCDIC to ASCII conversion; fix obscure,,Yes,Yes
25178,generator dict is now FeedParserDict; better tracking of xml:lang;,,Yes,Yes
25180,TODO: replace with apos when,,,Yes
25182,ASCII ends at 127; not 255,,,Yes
25187,"In this case; if the NN-word ends with an \""s\""; it is tagged as NNS.",,Yes,Yes
25188,Pairs of nearest clusters are merged as we move up the hierarchy:,,Yes,Yes
25193,The only way to really know if you're classifier is working correctly,,Yes,Yes
25194,XXX term count is lost.,,Yes,Yes
25198,XXX this still takes O(n^2)  :(,,,Yes
25200,(maybe multiple times) at the end of the document.,,,Yes
25201,XXX may be AES,,Yes,Yes
25204,XXX limit objlen not to exceed object boundary,,,Yes
25206,XXX re-rasterize every line,,,Yes
25208,- or do Table.columns[x].map(lambda s: date(s)),,,Yes
25209,Number of columns per row; see Datasheet.insert().,,,Yes
25210,Datasheet.columns property can't be set; except in special case Datasheet.columns += column.,,Yes,Yes
25213,The given row might have more columns than the rows in the matrix.,,Yes,Yes
25214,applying the group function to the other columns.,,No,Yes
25217,At one point a DatasheetColumn object was created with Datasheet.columns[j].,,,Yes
25219,This is much more efficient than storing entire strings (e.g.; customer address).,,No,Yes
25220,No warning is issued; seems a bad idea to document the method.,,Yes,Yes
25221,In this case; imported columns will automatically map values to the defined type.,,,Yes
25223,"print sentiment(\""A really bad; horrible book.\"")",,,Yes
25224,"print sentiment(Text(parse(\""A bad book. Really horrible.\"")))",,,Yes
25225,"Rule 8: convert a noun to a verb if it ends with \""ate\""; \""ify\""; \""ise\""; \""ize\""; etc.",,,Yes
25227,"\""Perhaps you\"" (NP) => \""Perhaps\"" (ADVP) + \""you\"" (NP).",,,Yes
25228,should <=> perhaps,,Yes,Yes
25229,"Assert \""nice\"" => \""nicer\"".",,,Yes
25230,"- \""perhaps you\"" (ADVP + NP)",,,Yes
25231,"- \""very nice cats\"" (NP)",,,Yes
25234,Assert messy syntax (fix brackets and whitespace; don't fix empty options).,,Yes,Yes
25235,Assert Schema (= table schema in a uniform way across database engines).,,,Yes
25241,and hopefully decrease the time needed to run.,,Yes,Yes
25243,Implement <canvas> draw().,,Yes,Yes
25248,not otherwise acceptable; perhaps it is MathML or SVG?,,Yes,Yes
25249,declare xlink namespace; if needed,,,Yes
25251,Present tense 2sg gets -st; unless stem ends with -s or -z.,,Yes,Yes
25254,Probably infinitive if ends in -ar; -er or -ir.,,No,Yes
25255,a collection of thousands of wikis based on MediaWiki (i.e.; what Wikipedia uses too).,,Yes,Yes
25256,If the stem ends in -g; use -ge before hard vowels -a and -o: manger => mangeons.,,,Yes
25257,If the stem ends in -c; use -\u00E7 before hard vowels -a and -o: lancer => lan\u00E7ons.,,,Yes
25263,"python -m pattern.en.parser xml -s \""Hello; my name is Dr. Sbaitso. Nice to meet you.\"" -OTCLI",,Yes,Yes
25266,Guess common cases where the base form ends in -e:,,No,Yes
25267,If the stem ends in -g; use -ge before hard vowels -a and -o: manger => mangeons.,,,Yes
25269,Subclass the base parser with the language-specific functionality:,,No,Yes
25272,A Datasheet is a table of rows and columns that can be exported as a CSV-file.,,,Yes
25273,XXX doesn't work with spaces.,,Yes,Yes
25274,Probably infinitive if ends in -are; -ere; -ire or reflexive -rsi.,,No,Yes
25276,As more languages are implemented; this is becoming more problematic.,,Yes,Yes
25277,XXX Model.save() conflicts with Model.classifier.,,,Yes
25278,FIXME: rest of code below expects a single prefix,,Yes,Yes
25279,Quick hack: it seems every element that has a 'w' nsprefix for,,No,Yes
25283,We can of course improve the classifier by hand:,,Yes,Yes
25284,"\""Perhaps you\"" => ADVP + NP",,Yes,Yes
25285,"\""Really nice work\"" => NP",,Yes,Yes
25286,TODO: robots.txt; favicon.ico,,Yes,Yes
25287,Append\/remove trailing slash from path_info as needed,,Yes,Yes
25288,Hack for 3.2's warning about body_params,,No,Yes
25291,a subclass of OSError.  FIXME: We should really,,Yes,Yes
25292,Close parent's pipe ends,,Yes,Yes
25293,than a given size. Fix this by returning a body over that size,,Yes,Yes
25294,"\""\""\""Native adapter for serving CherryPy via mod_python ||  || Basic usage: ||  || ########################################## || # Application in a module called myapp.py || ########################################## ||  || import cherrypy ||  || class Root: ||     @cherrypy.expose ||     def index(self): ||         return 'Hi there; Ho there; Hey there' ||  ||  || # We will use this method from the mod_python configuration || # as the entry point to our application || def setup_server(): ||     cherrypy.tree.mount(Root()) ||     cherrypy.config.update({'environment': 'production'; ||                             'log.screen': False; ||                             'show_tracebacks': False}) ||  || ########################################## || # mod_python settings for apache2 || # This should reside in your httpd.conf || # or a file that will be loaded at || # apache startup || ########################################## ||  || # Start || DocumentRoot \""\/\"" || Listen 8080 || LoadModule python_module \/usr\/lib\/apache2\/modules\/mod_python.so ||  || <Location \""\/\""> || \tPythonPath \""sys.path+['\/path\/to\/my\/application']\"" || \tSetHandler python-program || \tPythonHandler cherrypy._cpmodpy::handler || \tPythonOption cherrypy.setup myapp::setup_server || \tPythonDebug On || <\/Location> || # End ||  || The actual path to your mod_python.so is dependent on your || environment. In this case we suppose a global mod_python || installation on a Linux distribution such as Ubuntu. ||  || We do set the PythonPath configuration setting so that || your application can be found by from the user running || the apache2 instance. Of course if your application || resides in the global site-package this won't be needed. ||  || Then restart apache2 and access http:\/\/127.0.0.1:8080 || \""\""\""",,,Yes
25295,"\""\""\""Request body processing for CherryPy. ||  || .. versionadded:: 3.2 ||  || Application authors have complete control over the parsing of HTTP request || entities. In short; :attr:`cherrypy.request.body<cherrypy._cprequest.Request.body>` || is now always set to an instance of :class:`RequestBody<cherrypy._cpreqbody.RequestBody>`; || and *that* class is a subclass of :class:`Entity<cherrypy._cpreqbody.Entity>`. ||  || When an HTTP request includes an entity body; it is often desirable to || provide that information to applications in a form other than the raw bytes. || Different content types demand different approaches. Examples: ||  ||  * For a GIF file; we want the raw bytes in a stream. ||  * An HTML form is better parsed into its component fields; and each text field ||    decoded from bytes to unicode. ||  * A JSON body should be deserialized into a Python dict or list. ||  || When the request contains a Content-Type header; the media type is used as a || key to look up a value in the || :attr:`request.body.processors<cherrypy._cpreqbody.Entity.processors>` dict. || If the full media || type is not found; then the major type is tried; for example; if no processor || is found for the 'image\/jpeg' type; then we look for a processor for the 'image' || types altogether. If neither the full type nor the major type has a matching || processor; then a default processor is used || (:func:`default_proc<cherrypy._cpreqbody.Entity.default_proc>`). For most || types; this means no processing is done; and the body is left unread as a || raw byte stream. Processors are configurable in an 'on_start_resource' hook. ||  || Some processors; especially those for the 'text' types; attempt to decode bytes || to unicode. If the Content-Type request header includes a 'charset' parameter; || this is used to decode the entity. Otherwise; one or more default charsets may || be attempted; although this decision is up to each processor. If a processor || successfully decodes an Entity or Part; it should set the || :attr:`charset<cherrypy._cpreqbody.Entity.charset>` attribute || on the Entity or Part to the name of the successful charset; so that || applications can easily re-encode or transcode the value if they wish. ||  || If the Content-Type of the request entity is of major type 'multipart'; then || the above parsing process; and possibly a decoding process; is performed for || each part. ||  || For both the full entity and multipart parts; a Content-Disposition header may || be used to fill :attr:`name<cherrypy._cpreqbody.Entity.name>` and || :attr:`filename<cherrypy._cpreqbody.Entity.filename>` attributes on the || request.body or the Part. ||  || .. _custombodyprocessors: ||  || Custom Processors || ================= ||  || You can add your own processors for any specific or major MIME type. Simply add || it to the :attr:`processors<cherrypy._cprequest.Entity.processors>` dict in a || hook\/tool that runs at ``on_start_resource`` or ``before_request_body``. || Here's the built-in JSON tool for an example:: ||  ||     def json_in(force=True; debug=False): ||         request = cherrypy.serving.request ||         def json_processor(entity): ||             \\\""\""\""",,,Yes
25296,"\""\""\""CherryPy tools. A \""tool\"" is any helper; adapted to CP. ||  || Tools are usually designed to be used in a variety of ways (although some || may only offer one if they choose): ||  ||     Library calls ||         All tools are callables that can be used wherever needed. ||         The arguments are straightforward and should be detailed within the ||         docstring. ||  ||     Function decorators ||         All tools; when called; may be used as decorators which configure ||         individual CherryPy page handlers (methods on the CherryPy tree). ||         That is; \""@tools.anytool()\"" should \""turn on\"" the tool via the ||         decorated function's _cp_config attribute. ||  ||     CherryPy config ||         If a tool exposes a \""_setup\"" callable; it will be called ||         once per Request (if the feature is \""turned on\"" via config). ||  || Tools may be implemented as any object with a namespace. The builtins || are generally either modules or instances of the tools.Tool class. || \""\""\""",,Yes,Yes
25297,a huge amount of work to make it relocatable; but the only reason why,,,Yes
25298,"\""\""\""CPStats; a package for collecting and reporting on program statistics. ||  || Overview || ======== ||  || Statistics about program operation are an invaluable monitoring and debugging || tool. Unfortunately; the gathering and reporting of these critical values is || usually ad-hoc. This package aims to add a centralized place for gathering || statistical performance data; a structure for recording that data which || provides for extrapolation of that data into more useful information; || and a method of serving that data to both human investigators and || monitoring software. Let's examine each of those in more detail. ||  || Data Gathering || -------------- ||  || Just as Python's `logging` module provides a common importable for gathering || and sending messages; performance statistics would benefit from a similar || common mechanism; and one that does *not* require each package which wishes || to collect stats to import a third-party module. Therefore; we choose to || re-use the `logging` module by adding a `statistics` object to it. ||  || That `logging.statistics` object is a nested dict. It is not a custom class; || because that would 1) require libraries and applications to import a third- || party module in order to participate; 2) inhibit innovation in extrapolation || approaches and in reporting tools; and 3) be slow. There are; however; some || specifications regarding the structure of the dict. ||  ||     { ||    +----\""SQLAlchemy\"": { ||    |        \""Inserts\"": 4389745; ||    |        \""Inserts per Second\"": ||    |            lambda s: s[\""Inserts\""] \/ (time() - s[\""Start\""]); ||    |  C +---\""Table Statistics\"": { ||    |  o |        \""widgets\"": {-----------+ ||  N |  l |            \""Rows\"": 1.3M;      | Record ||  a |  l |            \""Inserts\"": 400;    | ||  m |  e |        };---------------------+ ||  e |  c |        \""froobles\"": { ||  s |  t |            \""Rows\"": 7845; ||  p |  i |            \""Inserts\"": 0; ||  a |  o |        }; ||  c |  n +---}; ||  e |        \""Slow Queries\"": ||    |            [{\""Query\"": \""SELECT * FROM widgets;\""; ||    |              \""Processing Time\"": 47.840923343; ||    |              }; ||    |             ]; ||    +----}; ||     } ||  || The `logging.statistics` dict has four levels. The topmost level is nothing || more than a set of names to introduce modularity; usually along the lines of || package names. If the SQLAlchemy project wanted to participate; for example; || it might populate the item `logging.statistics['SQLAlchemy']`; whose value || would be a second-layer dict we call a \""namespace\"". Namespaces help multiple || packages to avoid collisions over key names; and make reports easier to read; || to boot. The maintainers of SQLAlchemy should feel free to use more than one || namespace if needed (such as 'SQLAlchemy ORM'). Note that there are no case || or other syntax constraints on the namespace names; they should be chosen || to be maximally readable by humans (neither too short nor too long). ||  || Each namespace; then; is a dict of named statistical values; such as || 'Requests\/sec' or 'Uptime'. You should choose names which will look || good on a report: spaces and capitalization are just fine. ||  || In addition to scalars; values in a namespace MAY be a (third-layer) || dict; or a list; called a \""collection\"". For example; the CherryPy StatsTool || keeps track of what each request is doing (or has most recently done) || in a 'Requests' collection; where each key is a thread ID; each || value in the subdict MUST be a fourth dict (whew!) of statistical data about || each thread. We call each subdict in the collection a \""record\"". Similarly; || the StatsTool also keeps a list of slow queries; where each record contains || data about each slow query; in order. ||  || Values in a namespace or record may also be functions; which brings us to: ||  || Extrapolation || ------------- ||  || The collection of statistical data needs to be fast; as close to unnoticeable || as possible to the host program. That requires us to minimize I\/O; for example; || but in Python it also means we need to minimize function calls. So when you || are designing your namespace and record values; try to insert the most basic || scalar values you already have on hand. ||  || When it comes time to report on the gathered data; however; we usually have || much more freedom in what we can calculate. Therefore; whenever reporting || tools (like the provided StatsPage CherryPy class) fetch the contents of || `logging.statistics` for reporting; they first call `extrapolate_statistics` || (passing the whole `statistics` dict as the only argument). This makes a || deep copy of the statistics dict so that the reporting tool can both iterate || over it and even change it without harming the original. But it also expands || any functions in the dict by calling them. For example; you might have a || 'Current Time' entry in the namespace with the value \""lambda scope: time.time()\"". || The \""scope\"" parameter is the current namespace dict (or record; if we're || currently expanding one of those instead); allowing you access to existing || static entries. If you're truly evil; you can even modify more than one entry || at a time. ||  || However; don't try to calculate an entry and then use its value in further || extrapolations; the order in which the functions are called is not guaranteed. || This can lead to a certain amount of duplicated work (or a redesign of your || schema); but that's better than complicating the spec. ||  || After the whole thing has been extrapolated; it's time for: ||  || Reporting || --------- ||  || The StatsPage class grabs the `logging.statistics` dict; extrapolates it all; || and then transforms it to HTML for easy viewing. Each namespace gets its own || header and attribute table; plus an extra table for each collection. This is || NOT part of the statistics specification; other tools can format how they like. ||  || You can control which columns are output and how they are formatted by updating || StatsPage.formatting; which is a dict that mirrors the keys and nesting of || `logging.statistics`. The difference is that; instead of data values; it has || formatting values. Use None for a given key to indicate to the StatsPage that a || given column should not be output. Use a string with formatting (such as '%.3f') || to interpolate the value(s); or use a callable (such as lambda v: v.isoformat()) || for more advanced formatting. Any entry which is not mentioned in the formatting || dict is output unchanged. ||  || Monitoring || ---------- ||  || Although the HTML output takes pains to assign unique id's to each <td> with || statistical data; you're probably better off fetching \/cpstats\/data; which || outputs the whole (extrapolated) `logging.statistics` dict in JSON format. || That is probably easier to parse; and doesn't have any formatting controls; || so you get the \""original\"" data in a consistently-serialized format. || Note: there's no treatment yet for datetime objects. Try time.time() instead || for now if you can. Nagios will probably thank you. ||  || Turning Collection Off || ---------------------- ||  || It is recommended each namespace have an \""Enabled\"" item which; if False; || stops collection (but not reporting) of statistical data. Applications || SHOULD provide controls to pause and resume collection by setting these || entries to False or True; if present. ||  ||  || Usage || ===== ||  || To collect statistics on CherryPy applications: ||  ||     from cherrypy.lib import cpstats ||     appconfig['\/']['tools.cpstats.on'] = True ||  || To collect statistics on your own code: ||  ||     import logging ||     # Initialize the repository ||     if not hasattr(logging; 'statistics'): logging.statistics = {} ||     # Initialize my namespace ||     mystats = logging.statistics.setdefault('My Stuff'; {}) ||     # Initialize my namespace's scalars and collections ||     mystats.update({ ||         'Enabled': True; ||         'Start Time': time.time(); ||         'Important Events': 0; ||         'Events\/Second': lambda s: ( ||             (s['Important Events'] \/ (time.time() - s['Start Time']))); ||         }) ||     ... ||     for event in events: ||         ... ||         # Collect stats ||         if mystats.get('Enabled'; False): ||             mystats['Important Events'] += 1 ||  || To report statistics: ||  ||     root.cpstats = cpstats.StatsPage() ||  || To format statistics reports: ||  ||     See 'Reporting'; above. ||  || \""\""\""",,Yes,Yes
25301,"\""\""\""Session implementation for CherryPy. ||  || You need to edit your config file to use sessions. Here's an example:: ||  ||     [\/] ||     tools.sessions.on = True ||     tools.sessions.storage_type = \""file\"" ||     tools.sessions.storage_path = \""\/home\/site\/sessions\"" ||     tools.sessions.timeout = 60 ||  || This sets the session to be stored in files in the directory \/home\/site\/sessions; || and the session timeout to 60 minutes. If you omit ``storage_type`` the sessions || will be saved in RAM.  ``tools.sessions.on`` is the only required line for || working sessions; the rest are optional. ||  || By default; the session ID is passed in a cookie; so the client's browser must || have cookies enabled for your site. ||  || To set data for the current session; use || ``cherrypy.session['fieldname'] = 'fieldvalue'``; || to get data use ``cherrypy.session.get('fieldname')``. ||  || ================ || Locking sessions || ================ ||  || By default; the ``'locking'`` mode of sessions is ``'implicit'``; which means || the session is locked early and unlocked late. If you want to control when the || session data is locked and unlocked; set ``tools.sessions.locking = 'explicit'``. || Then call ``cherrypy.session.acquire_lock()`` and ``cherrypy.session.release_lock()``. || Regardless of which mode you use; the session is guaranteed to be unlocked when || the request is complete. ||  || ================= || Expiring Sessions || ================= ||  || You can force a session to expire with :func:`cherrypy.lib.sessions.expire`. || Simply call that function at the point you want the session to expire; and it || will cause the session cookie to expire client-side. ||  || =========================== || Session Fixation Protection || =========================== ||  || If CherryPy receives; via a request cookie; a session id that it does not || recognize; it will reject that id and create a new one to return in the || response cookie. This `helps prevent session fixation attacks || <http:\/\/en.wikipedia.org\/wiki\/Session_fixation#Regenerate_SID_on_each_request>`_. || However; CherryPy \""recognizes\"" a session id by looking up the saved session || data for that id. Therefore; if you never save any session data; || **you will get a new session id for every request**. ||  || ================ || Sharing Sessions || ================ ||  || If you run multiple instances of CherryPy (for example via mod_python behind || Apache prefork); you most likely cannot use the RAM session backend; since each || instance of CherryPy will have its own memory space. Use a different backend || instead; and verify that all instances are pointing at the same file or db || location. Alternately; you might try a load balancer which makes sessions || \""sticky\"". Google is your friend; there. ||  || ================ || Expiration Dates || ================ ||  || The response cookie will possess an expiration date to inform the client at || which point to stop sending the cookie back in requests. If the server time || and client time differ; expect sessions to be unreliable. **Make sure the || system time of your server is accurate**. ||  || CherryPy defaults to a 60-minute session timeout; which also applies to the || cookie which is sent to the client. Unfortunately; some versions of Safari || (\""4 public beta\"" on Windows XP at least) appear to have a bug in their parsing || of the GMT expiration date--they appear to interpret the date as one hour in || the past. Sixty minutes minus one hour is pretty close to zero; so you may || experience this bug as a new session id for every request; unless the requests || are less than one second apart. To fix; try increasing the session.timeout. ||  || On the other extreme; some users report Firefox sending cookies after their || expiration date; although this was on a system with an inaccurate system time. || Maybe FF doesn't trust system time. || \""\""\""",,Yes,Yes
25302,If path is relative; users should fix it by making path absolute.,,Yes,Yes
25304,adjust as needed,,,Yes
25305,will be the directory from which the startup script was run.  This is needed,,No,Yes
25308,This is perhaps the wrong place for this call but this is the only,,Yes,Yes
25313,The start method MUST move the state to STARTED,,Yes,Yes
25314,The stop method MUST move the state to STOPPED,,Yes,Yes
25316,platform does not implement signals and sending SIGTERM,,,Yes
25317,Trying 10 times is simply in case of socket errors.,,,Yes
25319,no reason why you shouldn't let your root object take care of,,Yes,Yes
25321,application; we would probably do some database lookups here,,,Yes
25322,TODO: fill this out more with mod ssl env,,No,Yes
25326,Both server and client are HTTP\/1.1 or better,,,Yes
25328,allow AI_PASSIVE to work. Passing None instead,,No,Yes
25329,Apparently; the socket option is not available in,,Yes,Yes
25331,TODO: if you already have CherryPy installed; remove the one bundled in Pattern;,,Yes,Yes
25335,"If the URL ends in \""?edit\""; show the page editor.",,Yes,Yes
25338,Each table has fields (or columns) with a type (text; int; float; ...).,,,Yes
25339,Assert fix for common Unicode mistakes.,,,Yes
25341,"- line  916: implement \""x in Dictionary\"" instead of Dictionary.has_key(x)",,No,Yes
25343,probably there is a bug in IGTree Classifier,,,Yes
25345,TODO: finish this,,Yes,Yes
25350,TODO(rkn): fix this; this is just a placeholder that should work but is inefficient,,,Yes
25351,and has fewer rows than columns; this is a bit ugly so think about how to,,Yes,Yes
25353,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
25354,It is needed to use group_id to make it work with VPC,,Yes,Yes
25357,TODO Extract the actual task. EXTRACT...(c_task),,No,Yes
25358,functions to run may set the Python path; which is needed to import a,,Yes,Yes
25359,Check that it is fine if we add the same object ID multiple times with the,,,Yes
25362,The functionality being tested here is really multi-node functionality;,,,Yes
25363,TODO(rkn): This code currently takes around half a microsecond. Since we,,,Yes
25364,logging code; perhaps in C.,,,Yes
25365,This is a hack for getting the event log. It is not part of the API.,,,Yes
25366,Return all of the data needed to use the network.,,,Yes
25367,The ID of the driver that this task belongs to. This is needed so that,,Yes,Yes
25369,TODO(rkn): Maybe we should open a new web sockets for every request instead,,Yes,Yes
25371,TODO(rkn): Maybe none of these counters are necessary? When executing a,,No,Yes
25372,# TODO(rkn): Implement this.,,Yes,Yes
25373,It is more memory efficient than very deep residual network and has,,Yes,Yes
25374,elipson used to be 1e-5. Maybe 0.001 solves NaN problem in deeper net.,,Yes,Yes
25375,the timeout variable exists because apparently; if one worker dies; the other workers,,Yes,Yes
25378,TODO: better error handling: workers should die when we go away,,No,Yes
25379,We'll maintain our own weakref; thank you very much.,,Yes,Yes
25381,better; but it requires some care because the slice may be backed by the,,No,Yes
25382,128MB. This is a hack to make it less likely for pubsub messages to be,,Yes,Yes
25383,Really we should encode this message as a flatbuffer object. However; we're,,Yes,Yes
25385,TODO(pcm): replace by 10 ** 5 once this is faster.,,Yes,Yes
25387,been created; so we have to move the files manually.,,,Yes
25389,implement.,,Yes,Yes
25390,this better; but it requires some care because the slice may be,,,Yes
25393,However; we moved it here because the previous approach seemed to fail in,,,Yes
25394,location. An alternative fix would be to manually modify the easy-install.pth,,,Yes
25396,The ID of the driver that this task belongs to. This is needed so,,Yes,Yes
25399,TODO(rkn): Fix this.,,,Yes
25402,numpy array as a hack to pin the object in the object store.,,Yes,Yes
25405,TODO: serializing Series without extra copy,,,Yes
25406,a numpy array as a hack to pin the object in the object,,Yes,Yes
25407,Once the actor executes a task; it counts as loaded.,,,Yes
25408,The timeout variable exists because apparently; if one worker,,Yes,Yes
25410,TODO: Need scipy to run BrainIAK example; but don't want to add additional,,Yes,Yes
25411,TODO(rkn): Move these filters out of PPO to somewhere common.,,No,Yes
25413,The timeout variable exists because apparently; if one worker,,Yes,Yes
25414,Create extra workers if needed,,,Yes
25416,used when passing around actor handles.,,,Yes
25417,Launch a new node if needed,,No,Yes
25419,Hash of the node runtime config; used to determine if updates are needed,,Yes,Yes
25420,TODO find a better way,,,Yes
25422,Technically not needed when not remote,,Yes,Yes
25424,TODO(ekl) this isn't really a proper gym spec,,,Yes
25426,TODO (hme): do something to correct slider here;,,Yes,Yes
25430,TODO(rliaw): have better way of specifying a new trial,,Yes,Yes
25431,"\""\""\""Constructors for 3rd party libraries || Note: These can never be renamed due to client compatibility issues\""\""\""",,Yes,Yes
25432,is what gives us the ``nonlocal`` behavior in a Python 2 compatible way.,,Yes,Yes
25433,essentially save_reduce; but workaround needed to avoid recursion,,,Yes
25434,save the rest of the func data needed by _fill_function,,,Yes
25436,hack for __import__ not working as desired,,Yes,Yes
25437,TODO(ekl) restarting the trial is expensive. We should implement a,,,Yes
25439,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,No,Yes
25440,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,,Yes
25441,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,,Yes
25442,Return all of the data needed to use the network.,,Yes,Yes
25444,TODO: Clean up later.,,,Yes
25445,TODO: Clean up later.,,,Yes
25446,to ndarray and maybe infer different dtype,,,Yes
25447,Reassign the columns within partition to self.index.,,Yes,Yes
25448,Move after the next \ || ,,Yes,Yes
25451,Update weights if needed,,No,Yes
25454,TODO: Revist this to improve performance,,Yes,Yes
25456,equivalence of the labels\/axis and index\/columns API's (GH12392),,Yes,Yes
25457,df2 may have different index and columns,,Yes,Yes
25458,only those columns and indices which are shared get filled,,Yes,Yes
25463,df.columns = ['2001-01-01'],,Yes,Yes
25466,could encounter this kind of issue as well.,,Yes,Yes
25473,TODO implement level,,Yes,Yes
25475,TODO Revisit for performance,,Yes,Yes
25476,columns. Putting single occurrences in a pd.DataFrame and transposing,,Yes,Yes
25477,Cast cols as pd.Series as duplicate columns mean result may be,,Yes,Yes
25478,Since we are replacing columns with RangeIndex inside the,,,Yes
25479,TODO Fix pandas so that the behavior is correct,,Yes,Yes
25482,if not isinstance(df.columns; pd.RangeIndex):,,Yes,Yes
25483,df.columns = pd.RangeIndex(0; len(df.columns)),,No,Yes
25486,TODO: This doesn't work if the expression is not an assignment,,,Yes
25487,may result in multiple columns?,,,Yes
25488,TODO: Find out what this does; and write a docstring,,Yes,Yes
25489,Since we are replacing columns with RangeIndex inside the,,,Yes
25490,TODO: Stop-gap solution until we begin passing IndexMetadatas,,,Yes
25496,replace the partition columns names with real column names,,Yes,Yes
25499,TODO Make pandas error,,No,Yes
25500,TODO: This is very inefficient and needs fix,,No,Yes
25502,and it forces the error checking. It also puts the columns in the,,Yes,Yes
25504,Here we reuse all_columns\/index so we don't have to materialize objects,,Yes,Yes
25506,would otherwise require a lot more logic.,,Yes,Yes
25507,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,,Yes
25508,TODO: change action_bound to make more general,,No,Yes
25511,The Empty Dataframe should have either columns or index specified,,Yes,Yes
25512,the end; and the columns can be built asynchronously. This takes the,,,Yes
25513,columns defining off the critical path and speeds up the overall,,Yes,Yes
25515,cache to accept ObjectIDs and ray.get them when needed.,,,Yes
25516,TODO(kunalgosar): Handle the case of duplicate columns here,,,Yes
25518,TODO Reolve once Pandas-20962 is resolved.,,,Yes
25519,aren't sorting over. We need the order of the columns\/rows and,,,Yes
25520,check if there are any object columns,,Yes,Yes
25521,select only correct dtype columns,,No,Yes
25523,TODO: In the future `set_option` or similar needs to run on every node,,,Yes
25524,We have to reset the index and columns here because we are coming,,Yes,Yes
25526,implemented differently. TODO(rkn): Fix this.,,,Yes
25527,TODO(alok): fix to handle Discrete(n) state spaces,,Yes,Yes
25528,TODO: make sure that we have usable subnet. Maybe call,,,Yes
25530,Since we know that the index and columns match; we can just check the,,Yes,Yes
25532,truncate ends of the trajectory,,No,Yes
25536,truncate ends of the trajectory,,No,Yes
25538,We need to implement this in separate classes,,Yes,Yes
25540,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,,Yes
25541,TODO(rkn): This code currently takes around half a microsecond. Since,,,Yes
25542,the logging code; perhaps in C.,,Yes,Yes
25543,TODO: clean up the SerializationContext once the job finished.,,Yes,Yes
25544,"\""\""\""Example of using two different training methods at once in multi-agent. ||  || Here we create a number of CartPole agents; some of which are trained with || DQN; and some of which are trained with PPO. We periodically sync weights || between the two trainers (note that no such syncing is needed when using just || a single training method). ||  || For a simpler example; see also: multiagent_cartpole.py || \""\""\""",,Yes,Yes
25546,improve the PPO policy,,Yes,Yes
25548,boundaries. TODO(ekl) this is kind of a hack,,,Yes
25550,Hack to workaround https:\/\/github.com\/ray-project\/ray\/issues\/2541,,Yes,Yes
25551,Worker command for Java; not needed for Python.,,No,Yes
25552,env = ScaledFloatFrame(env)  # TODO: use for dqn?,,,Yes
25554,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,,Yes
25557,TODO: implement an generic resource allocate algorithm.,,,Yes
25558,TODO: logspace,,No,Yes
25560,Unused (for 'a trous' convolutions),,No,Yes
25562,Minor hack to avoid H2D copy when using synthetic data,,,Yes
25563,TODO: Consider providing named session functionality,,,Yes
25565,infeasibility warning (even though the actor creation task itself,,,Yes
25566,Workaround for https:\/\/github.com\/ray-project\/ray\/issues\/3045,,No,Yes
25568,Implement model interface,,Yes,Yes
25569,"\""\""\""Example of handling variable length and\/or parametric action spaces. ||  || This is a toy example of the action-embedding based approach for handling large || discrete action spaces (potentially infinite in size); similar to how || OpenAI Five works: ||  ||     https:\/\/neuro.cs.ut.ee\/the-use-of-embeddings-in-openai-five\/ ||  || This currently works with RLlib's policy gradient style algorithms || (e.g.; PG; PPO; IMPALA; A2C) and also DQN. ||  || Note that since the model outputs now include \""-inf\"" tf.float32.min || values; not all algorithm options are supported at the moment. For example; || algorithms might crash if they don't properly ignore the -inf action scores. || Working configurations are given below. || \""\""\""",,,Yes
25572,What sample batch columns to LZ4 compress in the output data.,,,Yes
25573,TODO(ekl) implement this and multi-agent batch handling,,No,Yes
25575,TODO support complex way of updating gradient;,,Yes,Yes
25576,ramp up slowly to better mix the input data,,,Yes
25577,created; there should be a better way to handle pickled,,,Yes
25578,same actor is likely a performance bug. We should consider,,,Yes
25579,boundaries. TODO(ekl) this is kind of a hack,,,Yes
25580,fixed later. I had tried to fix it but failed because of heartbeat,,Yes,Yes
25582,Do off-policy estimation if needed,,No,Yes
25583,Note; the lock is needed because `serialization_context` isn't,,,Yes
25584,TODO: doing the timer in Python land is a bit slow,,No,Yes
25585,TODO (john): In case of input skew; it might be better to pull from,,Yes,Yes
25586,TODO (john): We should detect this earlier,,Yes,Yes
25590,TODO (john): Specify the interface of state keepers,,Yes,Yes
25591,TODO (john): Add more channel types here,,,Yes
25592,TODO (john): Handle possible exception here,,Yes,Yes
25593,TODO (john): Is there a way to update state with,,Yes,Yes
25594,TODO (john): Actor placement information should be specified in,,,Yes
25596,TODO (john): Add support for other partitioning strategies,,,Yes
25597,TODO (john): There should be different types of sources; e.g. sources,,Yes,Yes
25599,TODO (john): Check if dataflow has any 'logical inconsistencies',,Yes,Yes
25600,TODO (john): Currently; only forward (default); shuffle;,,,Yes
25602,TODO (john): To support event-time windows we need a mechanism for,,,Yes
25603,TODO (john): This should returned a KeyedDataStream,,Yes,Yes
25604,TODO (john): This should return a WindowedDataStream,,Yes,Yes
25605,TODO (john): Registers window join operator to the environment,,Yes,Yes
25606,TODO (john): A sink now just drops records but it should be able to,,,Yes
25607,TODO (john): Currently each source has only one instance,,,Yes
25610,works well in Travis. We should consider moving it back to Jenkins once,,,Yes
25621,What sample batch columns to LZ4 compress in the output data.,,No,Yes
25622,workaround for https:\/\/github.com\/ray-project\/ray\/issues\/1516,,No,Yes
25623,"\""\""\""Example of running a custom hand-coded policy alongside trainable policies. ||  || This example has two policies: ||     (1) a simple PG policy ||     (2) a hand-coded policy that acts at random in the env (doesn't learn) ||  || In the console output; you can see the PG policy does much better than random: || Result for PG_multi_cartpole_0: ||   ... ||   policy_reward_mean: ||     pg_policy: 185.23 ||     random: 21.255 ||   ... || \""\""\""",,,Yes
25624,"\""\""\""Example of using policy evaluator classes directly to implement training. ||  || Instead of using the built-in Trainer classes provided by RLlib; here we define || a custom PolicyGraph class and manually coordinate distributed sample || collection and policy optimization. || \""\""\""",,No,Yes
25625,Improve the policy using the T1 batch,,No,Yes
25626,TODO(kismuz): implement determ. actions and include relevant keys hints,,Yes,Yes
25627,TODO: 5 retry attempts may be too little for Travis and we may need to,,,Yes
25628,FIXME: what do magic constants mean? (0.4; 7),,Yes,Yes
25629,FIXME: what about turning off exploration? Isn't that a good,,,Yes
25630,TODO(ng): would be nice to stack crawl at creation time to report,,Yes,Yes
25633,By convention; the loss inputs are followed by state inputs and then,,Yes,Yes
25636,TODO: restore timer stats,,,Yes
25637,TODO: add support for mixed precision,,No,Yes
25638,TODO: add support for callbacks,,Yes,Yes
25639,auto-add empty learner stats dict if needed,,,Yes
25640,Do off-policy estimation if needed,,,Yes
25641,XXX experimental support for automatically eagerifying the loss.,,Yes,Yes
25643,RLlib uses preprocessors to implement transforms such as one-hot encoding,,Yes,Yes
25644,TODO: make num_workers configurable,,Yes,Yes
25646,TODO: change this because this is blocking. But failures,,,Yes
25647,are rare; so maybe this is OK?,,Yes,Yes
25650,TODO: Somehow; the call to get the current IP on the,,Yes,Yes
25651,remote actor can be very slow - a better fix would,,,Yes
25654,"\""\""\""A simple multi-agent env with two agents playing rock paper scissors. ||  || This demonstrates running the following policies in competition: ||     (1) heuristic policy of repeating the same move ||     (2) heuristic policy of beating the last opponent move ||     (3) LSTM\/feedforward PG policies ||     (4) LSTM policy with custom safety loss || \""\""\""",,No,Yes
25655,TODO(ekl) these are unused; remove them from sac config,,,Yes
25656,hack: put in a noop VF so some of the inherited PPO code runs,,No,Yes
25657,TODO: implement this properly,,Yes,Yes
25658,--note: typically you'd want to implement P(a2 | a1; obs) as follows:,,No,Yes
25659,HACK: Skip git clone if exists so the this command can be idempotent,,,Yes
25662,model forward pass for the loss (needed after postprocess to,,Yes,Yes
25663,TODO: set seq len and state in properly,,Yes,Yes
25665,Repeat is needed to avoid,,,Yes
25666,FIXME: what about turning off exploration? Isn't that a good,,,Yes
25668,This behavior is no longer the case; so we manually refresh,,,Yes
25669,TODO(edoakes): Fix this.,,Yes,Yes
25672,TODO: remove python side effect to cull sources of bugs.,,Yes,Yes
25673,"\""\""\"" || Parameter Server || ================ ||  || The parameter server is a framework for distributed machine learning training. ||  || In the parameter server framework; a centralized server (or group of server || nodes) maintains global shared parameters of a machine-learning model || (e.g.; a neural network) while the data and computation of calculating || updates (i.e.; gradient descent updates) are distributed over worker nodes. ||  || .. image:: ..\/images\/param_actor.png ||     :align: center ||  || Parameter servers are a core part of many machine learning applications. This || document walks through how to implement simple synchronous and asynchronous || parameter servers using Ray actors. ||  || To run the application; first install some dependencies. ||  || .. code-block:: bash ||  ||   pip install torch torchvision filelock ||  || Let's first define some helper functions and import some dependencies. ||  || \""\""\""",,Yes,Yes
25674,When the epoch ends; start a new epoch.,,,Yes
25675,This approach is powerful because it enables you to implement a parameter,,Yes,Yes
25678,running the actual command. This is a little ugly; but it should,,Yes,Yes
25679,one regularization layer -- more would probably be needed.,,,Yes
25680,move on.,,Yes,Yes
25682,Parse columns.,,Yes,Yes
25683,TODO(edoakes): Spawning these threads directly seems to cause,,Yes,Yes
25684,TODO(rliaw): This behavior is probably undesirable; but right now,,,Yes
25685,TODO: Remove Worker.actor_id and just use CoreWorker.GetActorId.,,No,Yes
25688,Todo; move the db to session_dir,,No,Yes
25689,used when passing around actor handles.,,Yes,Yes
25691,usually needed only if your env itself requires a GPU (i.e.; it is a,,,Yes
25692,TODO: 5 retry attempts may be too little for Travis and we may need to,,Yes,Yes
25693,TODO(pcm): replace by 10 ** 5 once this is faster.,,,Yes
25694,TODO: remove once the multi-threaded function runner is gone.,,,Yes
25695,implement the ranked reward (r2) algorithm,,,Yes
25696,"TODO (weak todo) add \""softmax\"" version of the Q-value",,Yes,Yes
25699,TODO (john): Handle rescaling,,,Yes
25704,A hack to keep reference to the future so it doesn't get GC.,,,Yes
25706,This is needed for async plasma,,No,Yes
25709,TODO: Clean up tmpfiles?,,,Yes
25710,removing a node. This is needed because right now we don't,,Yes,Yes
25714,unified context needed,,,Yes
25717,`type_`: Indicator for the Configurable's constructor.,,Yes,Yes
25719,Chance that an episode ends at any step.,,,Yes
25721,Test default-initialized (dict) metric columns.,,Yes,Yes
25723,needed unless the user is reading the local weights.,,No,Yes
25724,TODO: Temporarily removing since it causes hangs on MacOSX.,,,Yes
25726,replica worker the async_future is still needed to retrieve the final,,No,Yes
25727,TODO: consider await this with timeout; or use ray_kill,,,Yes
25730,every worker ends up with the exact same metrics and model,,No,Yes
25731,todo: are these resource quotas right?,,,Yes
25733,in numpy C backend. This is a workaround for python3.5 pickling support.,,Yes,Yes
25735,TODO(sven): Move soft_q logic to different Exploration child-component.,,Yes,Yes
25736,todo: technically could be reused in get_worker_node_ips,,,Yes
25737,Magic numbers: 2: On travis; it seems to create only 2 files.,,,Yes
25738,TODO(edoakes): Fix this.,,Yes,Yes
25739,TODO(sven): Move into (deterministic_)sample(logp=True|False),,,Yes
25741,TODO(edoakes): Fix this.,,,Yes
25743,TODO return a JobSubmissionResult future,,Yes,Yes
25745,TODO support key group,,Yes,Yes
25747,"TODO: Have an auto \""use_gpu\"" option to detect and use GPUs.",,Yes,Yes
25749,TODO: not sure if we are going to implement it for python < 3.7.,,Yes,Yes
25750,handling dotted names is not needed; so we simply define _getattribute as,,Yes,Yes
25754,"Discrete case: \""Best\"" means weighted by the policy (prob) outputs.",,No,Yes
25758,SAC cont uses a squashed normal distribution. Implement it's logp,,Yes,Yes
25759,NOTE: Needed to unset the config set by the lru_evict flag; for Travis.,,,Yes
25763,"\""\""\""REST client to interact with a policy server. ||  || This client supports both local and remote policy inference modes. Local || inference is faster but causes more compute to be done on the client. || \""\""\""",,,Yes
25766,worker. This is a bit of a hack since it is patching the get_metrics,,Yes,Yes
25767,Uncomment if regret at each time step is needed,,,Yes
25768,Uncomment if regret at each time step is needed,,,Yes
25770,Temp fix to avoid OMP conflict,,Yes,Yes
25771,TODO: Handle batch of data rather than individual points,,No,Yes
25774,set the below if needed,,No,Yes
25776,This is not the most efficient because you have to wait for,,Yes,Yes
25784,Save the initial arguments needed by replicas.,,,Yes
25785,TODO(edoakes): this is a hacky workaround because there is,,,Yes
25786,Check mixing of query context (unified context needed).,,No,Yes
25787,TODO(edoakes): this should probably be configurable.,,Yes,Yes
25788,"Discrete case: \""Best\"" means weighted by the policy (prob) outputs.",,,Yes
25789,loss terms (no expectations needed).,,No,Yes
25790,TODO(sven): implement case: vf_shared_layers = False.,,Yes,Yes
25791,TODO(sven): Implement non-shared value branch.,,Yes,Yes
25793,todo: verbose should depend on rank,,Yes,Yes
25794,HACK(label indices are swapped in RoBERTa pretrained model),,,Yes
25795,Create output directory if needed,,Yes,Yes
25796,Fix categorical inputs (not needed for distribution itself; but,,Yes,Yes
25801,TODO(edoakes): move this to client side.,,Yes,Yes
25802,This behavior is no longer the case; so we manually refresh,,,Yes
25803,Does not preserve file mode (needed to avoid read-only bit),,,Yes
25804,Preserves file mode (needed to copy executable bit),,,Yes
25805,add too much overhead and handles the case where the user manually,,Yes,Yes
25808,"\""\""\""Example of handling variable length and\/or parametric action spaces. ||  || This is a toy example of the action-embedding based approach for handling large || discrete action spaces (potentially infinite in size); similar to this: ||  ||     https:\/\/neuro.cs.ut.ee\/the-use-of-embeddings-in-openai-five\/ ||  || This currently works with RLlib's policy gradient style algorithms || (e.g.; PG; PPO; IMPALA; A2C) and also DQN. ||  || Note that since the model outputs now include \""-inf\"" tf.float32.min || values; not all algorithm options are supported at the moment. For example; || algorithms might crash if they don't properly ignore the -inf action scores. || Working configurations are given below. || \""\""\""",,No,Yes
25811,Only needed to give some params to the optimizer (even though;,,Yes,Yes
25812,Alternatively; a numpy array would work here as well.,,,Yes
25813,TODO: impl update target.,,No,Yes
25814,Maybe generate free-floating bias variables for the second half of,,,Yes
25815,Maybe generate free-floating bias variables for the second half of,,,Yes
25819,XXX: force CI,,,Yes
25820,XXX: force CI,,,Yes
25821,This behavior is no longer the case; so we manually refresh,,Yes,Yes
25822,Maybe generate free-floating bias variables for the second half of,,Yes,Yes
25823,explicit cast to float32 needed in eager,,,Yes
25826,If the object id ends with =; that means it is base64 encoded.,,,Yes
25827,Additionally; if somehow the error is True but,,,Yes
25828,Progress csv file -> Filter out some columns; cut; and write to,,No,Yes
25830,Workaround bug in old Python versions: prior to Python 3.7;,,Yes,Yes
25831,TypeVar instances and instead exhaustively lookup those instances in,,,Yes
25837,FIXME(suquark): The upstream cloudpickle cannot work in Ray,,Yes,Yes
25839,Launch additional nodes of the default type; if still needed.,,,Yes
25840,Note: this is an (experimental) user-facing API; do not move.,,No,Yes
25841,This shouldn't be broken because actor,,,Yes
25843,TODO(ekl) reuse the other id def once we fix imports,,,Yes
25845,TODO: (sven) figure out API to query the latent space vector given,,,Yes
25847,TODO: loss function types: neg_log_llh; etc..?,,,Yes
25851,set the below if needed,,,Yes
25854,TODO (Alex): Python seems to always flush when writing. If that is no,,,Yes
25856,TODO (Alex): `current_logging_job` tracks the current job so that we know,,,Yes
25857,Workaround: We ensure there is a space following each colon.,,Yes,Yes
25859,TODO: (sven) support RNNs w\/ fast sampling.,,,Yes
25860,TODO: (sven): Here; we actually do create a copy of the data (from a,,,Yes
25863,"\""\""\"" || Tune's Scikit Learn Adapters || ============================ ||  || Scikit-Learn is one of the most widely used tools in the ML community for working with data; offering dozens of easy-to-use machine learning algorithms. However; to achieve high performance for these algorithms; you often need to perform **model selection**. ||  ||  || .. image:: \/images\/tune-sklearn.png ||     :align: center ||     :width: 50% ||  || Scikit-Learn `has an existing module for model selection <https:\/\/scikit-learn.org\/stable\/modules\/grid_search.html>`_; but the algorithms offered (Grid Search\/``GridSearchCV`` and Random Search\/``RandomizedSearchCV``) are often considered inefficient. In this tutorial; we'll cover ``tune-sklearn``; a drop-in replacement for Scikit-Learn's model selection module with state-of-the-art optimization features such as early stopping and Bayesian Optimization. ||  || .. tip:: Check out the `tune-sklearn code`_ and :ref:`documentation <tune-sklearn-docs>`. ||  || .. _`tune-sklearn code`: https:\/\/github.com\/ray-project\/tune-sklearn ||  || Overview || -------- ||  || ``tune-sklearn`` is a module that integrates Ray Tune's hyperparameter tuning and scikit-learn's Classifier API. ``tune-sklearn`` has two APIs: :ref:`TuneSearchCV <tunesearchcv-docs>`; and :ref:`TuneGridSearchCV <tunegridsearchcv-docs>`. They are drop-in replacements for Scikit-learn's RandomizedSearchCV and GridSearchCV; so you only need to change less than 5 lines in a standard Scikit-Learn script to use the API. ||  || Ray Tune's Scikit-learn APIs allows you to easily leverage Bayesian Optimization; HyperBand; and other cutting edge tuning techniques by simply toggling a few parameters. It also supports and provides examples for many other frameworks with Scikit-Learn wrappers such as Skorch (Pytorch); KerasClassifiers (Keras); and XGBoostClassifiers (XGBoost). ||  || Run ``pip install ray[tune] tune-sklearn`` to get started. ||  || Walkthrough || ----------- ||  || Let's compare Tune's Scikit-Learn APIs to the standard scikit-learn GridSearchCV. For this example; we'll be using ``TuneGridSearchCV`` with a `SGDClassifier`_. ||  || .. _`digits dataset`: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.load_digits.html || .. _`SGDClassifier`: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html ||  || To start out; change the import statement to get tune-scikit-learn\u2019s grid search cross validation interface: ||  || \""\""\""",,Yes,Yes
25865,TODO: (sven) Allow env var to force compat.v1 behavior even if tf2.x,,,Yes
25866,TODO: (sven) remove entire file in the future.,,,Yes
25868,all other columns due to the additional obs returned by Env.reset()).,,No,Yes
25869,Do an efficient memory swap: Move current trajectory simply to,,,Yes
25870,TODO: (sven) this will replace `TorchPolicy._convert_to_non_torch_tensor()`.,,No,Yes
25871,serialization is done by Serve manually for performance.,,,Yes
25872,todo: cli_logger should handle this assert properly,,,Yes
25873,this should probably also happens somewhere else,,,Yes
25875,todo: handle plural vs singular?,,Yes,Yes
25878,todo: handle plural vs singular?,,Yes,Yes
25879,todo: handle plurality?,,Yes,Yes
25880,todo: show node names?,,Yes,Yes
25882,apparently,,,Yes
25885,todo: implement timer,,No,Yes
25886,todo,,,Yes
25890,todo: make sure we tell the user if they,,No,Yes
25891,todo: add a flag for this; we might,,Yes,Yes
25893,todo: validate file_mounts; ssh keys; etc.,,,Yes
25895,todo: is it fine to re-resolve? afaik it should be.,,No,Yes
25899,todo: interval should be a variable,,No,Yes
25902,todo: print stderr here,,,Yes
25903,todo: why do we ignore this here,,No,Yes
25906,Auto-add empty learner stats dict if needed.,,Yes,Yes
25907,This SIGTERM seems to be needed to prevent jobs from lingering.,,No,Yes
25908,TODO: better Q stats for dist dqn,,Yes,Yes
25909,TODO: optimize if colocated,,Yes,Yes
25911,TODO (Alex): There's a race condition here if the worker is,,Yes,Yes
25912,worker's global worker is unset before shutdown and is needed,,No,Yes
25914,TODO: optimize if colocated,,Yes,Yes
25915,Needed to remove read-only bit,,Yes,Yes
25916,todo: timed here?,,No,Yes
25917,Change these as needed.,,,Yes
25920,Next obs are needed for PPO postprocessing.,,,Yes
25921,VF preds are needed for the loss.,,,Yes
25924,We only introduced an additional neural network layer with a configurable,,Yes,Yes
25926,Here you could also implement an incremental rollout; where only,,,Yes
25927,route only a certain percentage of users to the new model; maybe to,,,Yes
25928,For now; if the output is needed we just skip the new logic.,,,Yes
25930,todo: check for other connection failures for better error messages?,,No,Yes
25932,TODO: what should this look like for multidimensional obs spaces,,No,Yes
25933,TODO can we always assume 1,,,Yes
25935,also be considered as unused memory,,Yes,Yes
25936,TODO: (sven) make `num_agents` flexibly grow in size.,,Yes,Yes
25937,TODO: (sven) deprecate; use `self.total_env_steps`; instead.,,,Yes
25938,Add new columns' data to buffers.,,,Yes
25939,TODO: (sven) do we really need this?,,,Yes
25940,Skip columns that will only get added through postprocessing,,No,Yes
25941,TODO (Alex): Autoscaler creates the node during one update then,,Yes,Yes
25942,# This is a hack to wait for placement group creation.,,,Yes
25945,Currently; there's no way to prevent,,Yes,Yes
25946,Needed for postprocessing.,,,Yes
25947,TODO: (sven) add env infos to buffers as well.,,No,Yes
25948,TODO: (sven) Case: rollout_fragment_length reached: Do not,,No,Yes
25952,NOTE(maximsmol): This is needed for mocking,,Yes,Yes
25953,to fix this (add <stateReason> to EC2_RUN_INSTANCES),,,Yes
25955,TODO: this method should not be called in a normal task.,,No,Yes
25956,Conform to the convention used by python serialization libraries; which,,,Yes
25958,When reducer_override is not available; hack the pure-Python,,Yes,Yes
25960,"Here the workaround just set \""_abc_impl\"" to None.",,Yes,Yes
25961,Score gets better every iteration.,,,Yes
25963,Most of the imports are needed for building the PyTorch model. Only the last three,,Yes,Yes
25965,We can only tune those parameters that are configurable. In this example; we can specify,,Yes,Yes
25966,The learning rate of the optimizer is made configurable; too:,,No,Yes
25973,in numpy C backend. This is a workaround for python3.5 pickling support.,,Yes,Yes
25974,TODO: Right now; we only support reuse if there has been,,Yes,Yes
25975,TODO: (sven) deprecate this when trajectory view API gets activated.,,,Yes
25976,TODO: (sven) remove this del once we have trajectory view API fully in,,Yes,Yes
25979,TODO: optimize if colocated,,Yes,Yes
25980,Initialize ray if needed.,,No,Yes
25982,TODO(rliaw): move into ray.constants,,Yes,Yes
25983,TODO: this should be eventually removed as an arg,,,Yes
25985,TODO: come up with a plan to unify logging.,,No,Yes
25987,TODO: Implement len for Dataset?,,Yes,Yes
25989,defaults. Better to be defensive.,,Yes,Yes
25990,TODO (Alex): This makes the assumption that $HOME on the head and,,Yes,Yes
25992,Major hack. If we go from LocalDistributedRunner to a,,Yes,Yes
25993,This is needed to handle calling ray.get on a dead actor.,,Yes,Yes
25994,This is not the most efficient because you have to wait for,,Yes,Yes
25995,TODO (Alex): Don't implement this logic oursleves.,,,Yes
25997,defaults. Better to be defensive.,,,Yes
25998,TODO (Alex): This makes the assumption that $HOME on the head and,,,Yes
26000,defaults. Better to be defensive.,,Yes,Yes
26001,TODO (Alex): This makes the assumption that $HOME on the head and,,Yes,Yes
26002,failure. We need to fix it.,,Yes,Yes
26004,HACK: Workaround for UNIX idiosyncrasy,,,Yes
26013,instead of a SampleBatch for postprocessing (this would eliminate,,Yes,Yes
26014,copies (for creating this SampleBatch) of many unused columns for,,,Yes
26015,Some columns don't exist yet (get created during postprocessing).,,Yes,Yes
26016,Skip columns that are not used for training.,,Yes,Yes
26017,TODO: determine exact shift-before based on the view-req shifts.,,No,Yes
26018,TODO: (sven) Once we implement multi-agent communication channels;,,,Yes
26019,TODO: (sven): Get rid of `get_initial_state` once Trajectory,,Yes,Yes
26022,TODO: Implement len for Dataset?,,Yes,Yes
26023,If the object ref ends with =; that means it is base64 encoded.,,,Yes
26025,"\""\""\""Wrap Google's RecSim environment for RLlib ||  || RecSim is a configurable recommender systems simulation platform. || Source: https:\/\/github.com\/google-research\/recsim || \""\""\""",,No,Yes
26027,Note: Each actual env must implement one to output exact rewards.,,,Yes
26032,TODO (Alex): We will hit this case every time a placement group,,Yes,Yes
26034,TODO: (sven) Allow for setting observation and action spaces to,,No,Yes
26035,HACK: using two different ip address so the placement constraint for,,Yes,Yes
26038,TODO: (bcahlit) Mask out actions,,,Yes
26039,demand scheduler bin packing algorithm takes a reasonable amount of time,,Yes,Yes
26042,real imact; and can be set arbitrarily. TODO: fix this.,,,Yes
26043,TODO(edoakes): we should probably have a timeout here.,,,Yes
26044,State-outs (no placeholders needed).,,No,Yes
26045,TODO: (sven) This hack will not work for attention net traj.,,No,Yes
26046,Add new columns automatically to view-reqs.,,Yes,Yes
26047,Add those needed for postprocessing and training.,,Yes,Yes
26049,Remove those not needed at all (leave those that are needed,,,Yes
26051,Track syncer obj\/index to move callback after loggers,,,Yes
26052,Todo(krfricke): Maybe check if syncer comes after all loggers,,,Yes
26053,Conform to the convention used by python serialization libraries; which,,,Yes
26056,TODO: optimize if colocated,,Yes,Yes
26059,bytes to be memory efficient.,,Yes,Yes
26061,TODO: (sven) rename to simply stats_fn to match eager and torch.,,No,Yes
26062,Add new columns automatically to view-reqs.,,,Yes
26063,Add those needed for postprocessing and training.,,,Yes
26064,TODO: (sven) remove unsqueezing code here for non-traj.view API.,,No,Yes
26066,TODO: (sven) deprecate once _use_trajectory_view_api is always True.,,,Yes
26068,TODO: Add support for user-specified redis port and password,,,Yes
26070,TODO(barakmich): This is a dirty hack that assumes the,,Yes,Yes
26071,NOTE(simon): This is a just hack around the current data,,No,Yes
26072,Except; apparently sometimes redis-py raises a completely,,Yes,Yes
26073,redis connections from each worker until needed.,,,Yes
26074,todo: fix command numbering,,,Yes
26078,without columns,,No,Yes
26079,with columns one,,,Yes
26082,demand scheduler bin packing algorithm takes a reasonable amount of time,,,Yes
26083,before all other data columns).,,,Yes
26084,Apparently avoids memory leaks on k8s\/k3s\/pods,,Yes,Yes
26086,TODO: (sven) make this function return both optimizers and,,,Yes
26088,TODO: (sven) Allow tf-eager policy to have more than 1 optimizer.,,,Yes
26090,TODO: (sven) Deprecate this once trajectory view API has fully matured.,,Yes,Yes
26091,TODO: (sven) deprecate once _use_trajectory_view_api is always True.,,No,Yes
26092,TODO: we only differentiate between 'function' and 'object',,Yes,Yes
26093,but we should do a better job of diving into something,,Yes,Yes
26097,TODO: (sven) Experimental method.,,,Yes
26098,TODO (Dmitri): Think about how to use the node's HOME variable,,,Yes
26101,No resources of the node were needed for request_resources().,,No,Yes
26102,2 nodes and not 1 because 1 is needed for min_worker and the other 1,,Yes,Yes
26103,The reason for _is_server is a hack around the above comment while running,,,Yes
26104,TODO(barakmich): This ref might actually be better as a serialized,,,Yes
26105,Wrap single item into list if needed before calling server put.,,Yes,Yes
26108,TODO(Hao): implement a group auto-counter.,,Yes,Yes
26110,TODO(Hao): implement a thin wrapper,,,Yes
26113,TODO (Dmitri): Identify the exception we're trying to avoid.,,Yes,Yes
26114,We're passing back a reference; probably inside a reference.,,,Yes
26118,columns in the resulting batch may not all have the same batch size.,,,Yes
26119,Fix state_in_x data.,,Yes,Yes
26121,Discard last output (not needed as a memory since it's the last,,Yes,Yes
26122,TODO: (sven) Deprecate this once trajectory view API has fully matured.,,Yes,Yes
26124,TODO (Alex): Failed nodes are now immediately killed; so,,,Yes
26125,demand scheduler bin packing algorithm takes a reasonable amount,,Yes,Yes
26126,TODO (Alex): Would there be a benefit to properly,,Yes,Yes
26127,TODO (Alex): This set of nodes won't be very useful in practice,,,Yes
26128,because the node:xxx.xxx.xxx.xxx resources means that no 2 nodes,,No,Yes
26130,"TODO: (sven) Replace \""fetches\"" with \""process\"".",,,Yes
26131,Auto-add empty learner stats dict if needed.,,,Yes
26133,NOTE(ilr) This rsync is needed because when starting from,,Yes,Yes
26135,class to implement your own collection\/buffering\/retrieval logic.,,,Yes
26136,TODO: Whether to feed a_{t-n:t-1} to GTrXL (one-hot encoded if discrete).,,Yes,Yes
26138,FIXME(suquark): The upstream cloudpickle cannot work in Ray,,,Yes
26142,Range needed.,,Yes,Yes
26143,Hardcoded old way: Build fixed fields; if provided.,,,Yes
26144,TODO: (sven) This can be deprecated after trajectory view API flag is,,No,Yes
26147,Old way (w\/o traj. view API) via model config key: `framestack=True`.,,,Yes
26149,Defer the import of RuntimeContext until needed to avoid cycles,,Yes,Yes
26153,Sets of ready and unused placement groups by factory,,,Yes
26154,Otherwise; return an unused ready placement group.,,Yes,Yes
26155,Directly passing args because it might contain an ObjectRef.,,No,Yes
26157,env = ScaledFloatFrame(env)  # TODO: use for dqn?,,,Yes
26158,Old way (w\/o traj. view API) via model config key: `framestack=True`.,,,Yes
26159,Note: Each actual env must implement one to output exact rewards.,,,Yes
26160,TODO: (sven) Remove once trajectory view API is all-algo default.,,No,Yes
26162,TODO(ilr): FIX,,Yes,Yes
26163,TODO: Make changes in PTL to clean this up.,,Yes,Yes
26164,TODO: Upstream to PTL to not set this env var if using Ray.,,Yes,Yes
26165,TODO (Alex): Dynamically set this based on number of cores,,Yes,Yes
26166,TODO (Dacheng): how do we recycle this name actor?,,,Yes
26167,TODO (we need a declarative destroy() API here.),,No,Yes
26168,TODO (Hao): we need a lock here...,,Yes,Yes
26170,TODO(ilr): FIX,,Yes,Yes
26172,external storage is configurable.,,Yes,Yes
26173,Deprecated way of framestacking is used.,,Yes,Yes
26176,TODO: (sven) Support Dicts as well.,,No,Yes
26177,TODO: (sven) Multidiscrete (see e.g. our auto-LSTM wrappers).,,,Yes
26180,TODO: Add retry logic in case of 409 due to old resource version.,,Yes,Yes
26181,TODO(ekl) why doesn't TypeVar() deserialize properly in Ray?,,No,Yes
26182,TODO(ekl) using ray.wait can be more efficient for pipelining.,,No,Yes
26183,"\""\""\"" This script is meant to be run from a pod in the same Kubernetes namespace || as your Ray cluster. ||  || Just below are the environment variables used to access Ray client via a || service targetting the Ray cluster's head node pod. || These environment variables are set by Kubernetes. || See https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/#environment-variables || In the documentation examples; the head service has || \""example-cluster-ray-head\"" and the relevant port is named \""client\"". || Modify the environment variables as needed to match the name of the service || and port. ||  || Note: The default head service set up by the Ray Kubernetes operator is named || <cluster-name>-ray-head; || where <cluster-name> is the metadata.name field you set in the RayCluster || custom resource. || \""\""\""",,,Yes
26184,"\""\""\""Result throughput on a cluster ||  || In this run; we will start 1000 trials concurrently that report often || (10 results per second). We thus measure the amount of overhead incurred when || dealing with a large number of results from distributed trials. ||  || Cluster: cluster_16x64.yaml ||  || Test owner: krfricke ||  || Acceptance criteria: Should run faster than 120 seconds. ||  || Theoretical minimum time: 100 seconds || \""\""\""",,No,Yes
26185,"\""\""\""Result throughput on a single node ||  || In this run; we will start 96 trials concurrently that report very often || (500 results per second). We thus measure the amount of overhead incurred when || dealing with a large number of results. ||  || Cluster: cluster_1x96.yaml ||  || Test owner: krfricke ||  || Acceptance criteria: Should run faster than 120 seconds. ||  || Theoretical minimum time: 100 seconds || \""\""\""",,No,Yes
26189,Delay errors a little bit of time to attempt to suppress redundant,,,Yes
26190,TODO: Instead of just making the max message size large; the right thing to,,Yes,Yes
26192,Delay errors a little bit of time to attempt to suppress redundant,,Yes,Yes
26194,Decompress SampleBatch; in case some columns are compressed.,,Yes,Yes
26198,Todo: Re-enable when using buildkite,,,Yes
26200,TODO: Remove in future.,,,Yes
26201,TODO: Remove in future.,,,Yes
26202,TODO: This will not work with attention nets as their state_outs are,,Yes,Yes
26204,TODO: Remove in future.,,Yes,Yes
26208,3 Trials: Can only run 1 at a time (num_cpus=6; needed: 5).,,No,Yes
26209,FIXME(Clark): Monkey patching is bad and we should try to avoid this.,,Yes,Yes
26210,TODO (Alex): We are leaking the tag cache here. Naively; we would,,Yes,Yes
26211,We aren't using standard python logging convention; so we hardcode,,,Yes
26215,Implement non-blocking get with a short-polling loop. This allows,,No,Yes
26218,Return PlacementGroupFactory containing all needed resources,,No,Yes
26227,TODO(ekl) get rid of the env var hack and get runtime env from the,,Yes,Yes
26228,TODO: (sven) obsolete this method at some point (replace by,,,Yes
26229,TODO: (sven): Keep for a while to ensure backward compatibility.,,No,Yes
26230,TODO: deprecate,,Yes,Yes
26231,TODO: Remove in future.,,Yes,Yes
26233,TODO (Alex): We should find a more robust way of simulating a node,,Yes,Yes
26234,still ugly and should be removed once the old codepath,,Yes,Yes
26235,BUT it's needed still because of the shared asyncio thread.,,,Yes
26236,array) or take care of rendering itself (returning True).,,No,Yes
26237,A simple fix for this is described here:,,No,Yes
26238,"mode=\""rgb_array\"" is needed. RLlib will automatically produce a simple",,,Yes
26241,TODO: fix this mypy madness,,,Yes
26243,TODO: sending the secret key reduces the latency by a lot; but,,Yes,Yes
26244,insane hack,,Yes,Yes
26245,TODO: replace with proper tuple support,,No,Yes
26246,breaking convention here because index_globals needs,,Yes,Yes
26247,Filter out Pandas UserWarning about creating columns,,,Yes
26248,TODO: investigate this,,No,Yes
26249,TODO: overload all methods to incorporate this automatically,,Yes,Yes
26252,TODO: replace with proper tuple support,,No,Yes
26254,TODO: fix this mypy madness,,No,Yes
26257,TODO: add numpy support https:\/\/github.com\/OpenMined\/PySyft\/issues\/5164,,Yes,Yes
26258,there is probably a better\/shorter way,,No,Yes
26259,there is probably a better\/shorter way,,No,Yes
26260,Todo; fix this hacky isinstance. Right now it prevents circular dependency,,Yes,Yes
26261,TODO: This is a Tuple,,No,Yes
26262,horrible hack; we shouldnt be constructing these right now anyway,,No,Yes
26263,TODO: Remove this Opacus workaround,,No,Yes
26265,TODO: add numpy support https:\/\/github.com\/OpenMined\/PySyft\/issues\/5164,,Yes,Yes
26266,TODO: This is a Tuple,,No,Yes
26267,TODO: Make only for DataFrames etc,,No,Yes
26268,TODO: add numpy support https:\/\/github.com\/OpenMined\/PySyft\/issues\/5164,,Yes,Yes
26270,TODO: remove this requirement in pytorch lightning,,No,Yes
26273,TODO: this needs fixing but should be on by default for now,,No,Yes
26274,TODO: a better way. Loot at https:\/\/github.com\/OpenMined\/PySyft\/issues\/5249,,No,Yes
26275,TODO: a better way. Loot at https:\/\/github.com\/OpenMined\/PySyft\/issues\/5249,,,Yes
26276,TODO: Loot at https:\/\/github.com\/OpenMined\/PySyft\/issues\/5249,,Yes,Yes
26277,Todo: fix this,,,Yes
26278,TODO: a better way. Loot at https:\/\/github.com\/OpenMined\/PySyft\/issues\/5249,,No,Yes
26279,TODO: Create a remote print interface for objects which displays them in a,,Yes,Yes
26280,nice way; we could also even buffer this between chained ops until we,,,Yes
26284,TODO: https:\/\/github.com\/OpenMined\/PySyft\/issues\/5292,,No,Yes
26285,This is an interesting case; for some versions p = 0.2 is needed; for others its not needed,,Yes,Yes
26287,FIXME: Can't we just return an int??,,,Yes
26288,TODO: fix hacky work around,,,Yes
26289,TODO: Make only for DataFrames etc,,No,Yes
26290,TODO: remove this requirement in pytorch lightning,,No,Yes
26291,TODO: fix hacky work around,,,Yes
26292,TODO: Allow Classes to opt out in the AST like Pandas where the properties,,Yes,Yes
26294,TODO: Pandas can't have tags and description because they break the dict,,No,Yes
26295,TODO: add support for self referential unions using some kind of post update,,Yes,Yes
26296,TODO: Fix when we have PIL support,,No,Yes
26297,TODO: Create a remote print interface for objects which displays them in a,,,Yes
26298,nice way; we could also even buffer this between chained ops until we return,,Yes,Yes
26299,TODO: Make only for DataFrames etc,,No,Yes
26301,TODO: Fix when we have PIL support,,,Yes
26305,TODO: support numpy.object_; numpy.str_ and numpy.unicode_,,,Yes
26306,TODO: Support dynamic properties for types in AST,,,Yes
26307,keep this workaround,,,Yes
26308,TODO: add support for custom objects,,Yes,Yes
26311,keep this workaround,,,Yes
26316,TODO this should work!!!,,Yes,Yes
26322,FIX THIS SHIT!!!#,,Yes,Yes
26325,NN lines relate to original sample; columns to its,,,Yes
26326,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
26328,XXX: Calling sample in pipeline it means that the,,,Yes
26331,XXX: do we really want a special API for the binary case?,,,Yes
26333,FIXME remove at the end of the deprecation 0.4,,,Yes
26335,FIXME: Deprecated in 0.2. To be removed in 0.4,,,Yes
26337,FIXME: perfectly we should raise an error but the sklearn API does,,No,Yes
26338,FIXME: deprecated in 0.2 to be removed in 0.4,,Yes,Yes
26339,FIXME: to be removed in 0.4 due to deprecation,,Yes,Yes
26340,To improve the prediction of the class \\#3; it could be interesting to apply,,,Yes
26342,slightly better.,,Yes,Yes
26344,"\""\""\"" || ========================================================= || Comparison of balanced and imbalanced bagging classifiers || ========================================================= ||  || This example shows the benefit of balancing the training set when using a || bagging classifier. ``BalancedBaggingClassifier`` chains a || ``RandomUnderSampler`` and a given classifier while ``BaggingClassifier`` is || using directly the imbalanced data. ||  || Balancing the data set before training the classifier improve the || classification performance. In addition; it avoids the ensemble to focus on the || majority class which would be a known drawback of the decision tree || classifiers. ||  || \""\""\""",,Yes,Yes
26345,this is needed for some reason...,,,Yes
26347,FIXME: remove in 0.6,,No,Yes
26349,FIXME remove ratio at 0.6,,No,Yes
26351,FIXME remove in 0.6 -> ratio will be deprecated,,No,Yes
26352,FIXME: Turn into an error in 0.6,,Yes,Yes
26355,FIXME: remove in 0.6 after deprecation cycle,,,Yes
26356,FIXME: to be removed in 0.6,,,Yes
26357,FIXME: uncomment in version 0.6,,,Yes
26360,FIXME: Remove in 0.6,,,Yes
26361,FIXME: remove in 0.6,,,Yes
26363,making threading more efficient than multiprocessing in,,Yes,Yes
26365,TODO: remove the str tag once the following PR is merged:,,,Yes
26366,TODO: remove the str tag once the following PR is merged:,,Yes,Yes
26368,Temporary work-around for spacing problem between parameter and parameter,,Yes,Yes
26369,Temporary work-around for spacing problem between parameter and parameter,,,Yes
26371,store the columns name to reconstruct a dataframe,,Yes,Yes
26372,"\""\""\"" || ======================================================================== || Model fitting on imbalanced dataset and comparison of methods to improve || its performance || ======================================================================== ||  || This example illustrates the problem induced by learning on datasets having || imbalanced classes. Subsequently; we compare different approaches alleviating || these negative effects. ||  || \""\""\""",,Yes,Yes
26373,This dataset is only slightly imbalanced. To better highlight the effect of,,,Yes
26374,columns and standardized the numerical columns before to inject the data into,,,Yes
26375,columns to the categorical pipeline and the numerical columns to the,,,Yes
26377,tree. However; instead of under-sampling once the dataset; one could,,,Yes
26380,# FIXME: When we get Python 3.7 as minimal version; we will need to switch to,,Yes,Yes
26381,LazyLoader; lookups are efficient (__getattr__ is only called on,,,Yes
26383,TODO: Remove when https:\/\/github.com\/sphinx-doc\/sphinx\/pull\/8234 gets,,Yes,Yes
26385,this is needed for some reason...,,Yes,Yes
26386,change in sparsity structure more efficient with LIL than CSR,,Yes,Yes
26389,fix the axis if we are dealing with a vector. This is a hack,,No,Yes
26390,the above is what we ought to do; but generates Exceptions due to,,,Yes
26392,TODO: cudanet doesn't currently support noaxis argmin,,Yes,Yes
26393,TODO: cudanet doesn't currently support noaxis argmax,,Yes,Yes
26394,TODO: add >2 dimension support to cudanet,,No,Yes
26396,TODO: fix this for self.gpt,,No,Yes
26398,TODO: try and download and read in directly?,,No,Yes
26399,TODO: try and download and read in directly?,,,Yes
26400,TODO: make this work (numpy import errors at the moment),,No,Yes
26401,todo: Spearmint supports ENUM but we are not handling it yet.,,Yes,Yes
26407,TODO: better handle situation where metrics recorded differ from those,,Yes,Yes
26408,no coloring needed,,Yes,Yes
26409,[TODO] why need deepcopy?,,Yes,Yes
26411,TODO: remove randomness from expected target results,,,Yes
26412,TODO: remove randomness,,Yes,Yes
26416,todo: gpu -> cpu deserialization,,Yes,Yes
26418,temporary hack because we are not running via mpirun.,,No,Yes
26420,global variable hack so that we can use multiprocess pool.map,,,Yes
26422,may not be needed,,,Yes
26423,may not be needed,,,Yes
26425,TODO clean up this code to avoid indexing,,,Yes
26426,TODO: set ptype to be fragment in this case ??,,Yes,Yes
26427,TODO cleaner way to broadcast,,No,Yes
26428,TODO: fix shape in smarter way,,,Yes
26429,TODO,,Yes,Yes
26431,TODO: I can probably do much better than this code below;,,Yes,Yes
26432,TODO: build a program wide DAG and only call this once at startup per,,,Yes
26433,Each block gets a column and the threads work down the columns.,,,Yes
26435,TODO: don't allow output tensor itself to be broadcastable.,,,Yes
26437,remove unused dtype settings,,,Yes
26439,TODO: we need to accumulate the delta in the common output delta,,Yes,Yes
26440,3 is a special case that only ends up in the high bits,,No,Yes
26442,TODO: enable this flag to find numerical problems,,,Yes
26443,TODO add rand and onehot here,,Yes,Yes
26444,TODO: add an is_binary_compat like function,,No,Yes
26447,and manually fine tune the selection for each layer.,,,Yes
26450,TODO Reduction only allowed along one axis per kernel.,,Yes,Yes
26451,TODO potentially problematic,,,Yes
26453,state needed for the stop func,,Yes,Yes
26455,TODO: go back to 0.01 initialization,,No,Yes
26456,TODO: use glorot initialization?,,No,Yes
26457,TODO: maybe we don't need to,,No,Yes
26458,TODO: use an already existing sigmoid function,,,Yes
26466,TODO: Set up self.batch_sum if self.bsum,,No,Yes
26468,TODO: beta,,,Yes
26470,give gpu the input array without zero padding (not needed),,,Yes
26472,TODO: INSTEAD of just taking inputs... need to take the one that is specific to,,Yes,Yes
26476,"\""\""\"" || Interactive demo based on Facebook Q&A dataset: bAbI ||  || Reference: ||     \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"" ||     http:\/\/arxiv.org\/abs\/1502.05698 ||  || Usage: ||     use -t to specify which bAbI task to run ||     python examples\/babi\/demo.py -t 1 --rlayer_type gru --model_weights babi.p || \""\""\""",,No,Yes
26478,give gpu the input array without zero padding (not needed),,,Yes
26479,TODO: The above code can lead to a race condition.,,Yes,Yes
26482,TODO: generalize this for container layers,,Yes,Yes
26483,TODO: switch this to a general seralization op,,Yes,Yes
26485,by convention; use 2 as OOV word,,,Yes
26486,TODO put dropout back in,,,Yes
26491,sort that set of columns by elt in the last row (the priority),,,Yes
26492,put those columns back into minibatch in the right places,,Yes,Yes
26493,TODO: introduce Multicost metric support.  The line below currently failes,,Yes,Yes
26494,check that the needed csv files exist,,,Yes
26495,open the file; skip the headers if needed,,Yes,Yes
26496,update the vocab if needed,,,Yes
26498,3 is a special case that only ends up in the high bits,,No,Yes
26499,TODO small C bprop?,,,Yes
26500,The overlap kernel can be much more efficient if we aren't doing superblocking,,Yes,Yes
26501,hack this up for now to get decent performnace on this op,,No,Yes
26502,the real fix is 3d broadcast support in ew,,Yes,Yes
26503,TODO remove loop logic here.,,,Yes
26505,perhaps tune this for smaller cache sizes,,Yes,Yes
26506,TODO add cache_dir to mgpu,,Yes,Yes
26508,add any zero padding if needed,,Yes,Yes
26510,TODO: fill in rest of metadata.,,Yes,Yes
26511,TODO: generate these on the fly,,,Yes
26512,TODO: explore more superblock shapes here.,,No,Yes
26514,TODO: expose more compound operations,,,Yes
26515,This script no longer needed.,,,Yes
26518,TODO remove loop logic here.,,Yes,Yes
26519,add any zero padding if needed,,,Yes
26521,TODO: expose more compound operations,,,Yes
26522,TODO remove loop logic here.,,Yes,Yes
26524,skip; implement subset pct to fit,,,Yes
26526,TODO: explore more superblock shapes here.,,No,Yes
26527,FIXME: Do the packing of targets within the context of a,,,Yes
26530,"\""\""\"" || Defines interface that any backend must implement || \""\""\""",,,Yes
26533,TODO: some sensible default behavior,,,Yes
26535,TODO: not relevant for Seq2Seq?,,No,Yes
26536,TODO: look at impact of revert_tensors call inside encoder fprop,,No,Yes
26537,TODO: this assumes inputs will be given properly,,Yes,Yes
26539,TODO: this just implements special case of one-one encoder-decoder recurrent layers,,No,Yes
26540,TODO: added this for resizing,,No,Yes
26541,TODO: some sensible default behavior,,Yes,Yes
26542,TODO: understand this better,,,Yes
26544,TODO: look at impact of revert_tensors call inside encoder fprop,,No,Yes
26545,TODO: this assumes inputs will be given properly,,Yes,Yes
26548,TODO: cache and remove import,,,Yes
26550,subsample labels if needed,,Yes,Yes
26551,TODO: move these into the minibatch loop,,Yes,Yes
26553,TODO: cache and remove import,,No,Yes
26556,subsample labels if needed,,,Yes
26557,TODO: move these into the minibatch loop,,,Yes
26558,TODO: remove redundant blobs,,,Yes
26559,-- TODO: move compute to device -- #,,,Yes
26560,-- END TODO -- #,,,Yes
26561,number of rois to train frcnn (needed to initialize global buffers),,Yes,Yes
26562,Compute values needed for means and stds,,,Yes
26563,flip image if needed,,Yes,Yes
26565,normalize the model by the bbtarget mean and std if needed,,,Yes
26566,"\""\""\"" || Train a Faster-RCNN model to do object detection using PASCAL VOC dataset. || This training currently runs 1 image at a time. ||  || Reference: ||     \""Faster R-CNN\"" ||     http:\/\/arxiv.org\/abs\/1506.01497 ||     https:\/\/github.com\/rbgirshick\/py-faster-rcnn ||  || Usage: ||     python examples\/faster-rcnn\/train.py -r0 -e 16 -s frcn_model.pkl -vv \\ ||     --epoch_step 5 --roi_branch_scale --lr_scale 1.0 -H 16 ||  || \""\""\""",,,Yes
26569,"Move \""pointer\"" back to beginning of dataset",,,Yes
26571,use index. TODO: Backend needs to catch these striding mismatches,,Yes,Yes
26572,create unused layers,,Yes,Yes
26574,hack to convert single channel image to 3 channel for later processing,,Yes,Yes
26576,2x4  xxx,,,Yes
26577,2x4  xxx(nn),,No,Yes
26578,4x4  xxx(xn),,,Yes
26581,Data needed for training the RPN are provided by the DataLoader,,,Yes
26583,Get iterator from tokenized data. Second argument (train_text) not needed for evaluation,,,Yes
26586,TODO: remove,,No,Yes
26587,hack for dealing with dilated conv,,Yes,Yes
26589,TODO; support bias,,,Yes
26590,TODO: cffi cast not compatible with f_contiguous array with py3.4,,No,Yes
26591,TODO: enable this flag to find numerical problems,,Yes,Yes
26593,give gpu the input array without zero padding (not needed),,No,Yes
26597,move scores to host if needed,,,Yes
26598,apply threshold if needed,,,Yes
26599,this is needed for the progress bar callback,,,Yes
26600,just needed to interface with neon.models.model properly,,,Yes
26603,maybe here we need to move to host?,,,Yes
26605,TODO: inference and no-inference return different outputs; can we normalize this somehow?,,Yes,Yes
26606,TODO: We need to identify whether this is 4D image data; otherwise we shouldn't change the dimension order,,,Yes
26607,TODO: Axis,,,Yes
26609,TODO: Find a better solution for this.,,No,Yes
26610,FIXME:,,No,Yes
26612,Kit TODO: More activation functions,,,Yes
26614,Kit TODO: to handle padding,,,Yes
26615,You can just specify the packages manually here if your project is,,Yes,Yes
26616,"\""\""\""\r || int64 effective_filter_size = (filter_size - 1) * dilation_rate + 1;\r ||   switch (padding_type) {\r ||     case Padding::SAME:\r ||       *output_size = (input_size + stride - 1) \/ stride;\r ||       const int64 padding_needed =\r ||           std::max(0LL; (*output_size - 1) * stride + effective_filter_size -\r ||                             input_size);\r ||       \/\/ For odd values of total padding; add more padding at the 'right'\r ||       \/\/ side of the given dimension.\r ||       *padding_before = padding_needed \/ 2;\r ||       *padding_after = padding_needed - *padding_before;\r ||       break;\r || \""\""\""",,Yes,Yes
26618,Yuhao TODO: inference code,,No,Yes
26620,use this work-around,,,Yes
26621,Kit TODO: set blob_order,,,Yes
26622,TODO - remove style transfer 1D hack,,Yes,Yes
26623,Kit TODO: set running mode,,,Yes
26624,TODO: Deconv,,,Yes
26627,TODO: CntkEmit,,Yes,Yes
26628,TODO: PytorchEmit,,,Yes
26629,Check if a stride is needed; then use a strided 1x1 here,,,Yes
26630,'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,Yes,Yes
26631,'inception_resnet_v2' : [CntkEmit; TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,Yes,Yes
26634,'inception_v1'  : [CntkEmit; TensorflowEmit; KerasEmit; MXNetEmit]; # TODO: PytorchEmit,,,Yes
26635,TODO,,Yes,Yes
26636,'inception_v1'  : [CntkEmit; TensorflowEmit; KerasEmit; MXNetEmit]; # TODO: PytorchEmit,,,Yes
26637,TODO: Need to re-implement,,,Yes
26638,TODO: MXNetEmit,,,Yes
26640,TODO,,,Yes
26642,TODO: KerasEmit,,No,Yes
26643,'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,Yes,Yes
26644,TODO: Handle square,,Yes,Yes
26646,TODO: Caffe,,,Yes
26647,TODO: CntkEmit,,Yes,Yes
26648,'inception_v1' : [TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit]; # TODO: CntkEmit,,Yes,Yes
26649,'resnet_v1_50' : [TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit]; # TODO: CntkEmit,,,Yes
26650,'resnet_v1_152' : [TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit]; # TODO: CntkEmit,,Yes,Yes
26653,TODO,,Yes,Yes
26657,TODO: CntkEmit,,Yes,Yes
26658,TODO; same with caffe_Cntk_inception_v4,,Yes,Yes
26660,TODO: KerasEmit,,,Yes
26661,TODO MXNetEmit; CaffeEmit,,,Yes
26662,TODO,,Yes,Yes
26665,TODO  global pooling modification,,Yes,Yes
26666,TODO remain to be modified!,,,Yes
26667,self.data_format ? TODO,,,Yes
26668,TODO dtype_map,,Yes,Yes
26669,TODO,,Yes,Yes
26670,For concat axis TODO,,Yes,Yes
26671,Future Module TODO,,Yes,Yes
26674,TODO: Multiple outputs,,No,Yes
26676,TODO: It works with +1; don't know why.,,Yes,Yes
26677,TODO: use keras backend instead of tf.,,No,Yes
26678,'imagenet1k-inception-bn'   : [CntkEmit; TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit]; # TODO: Caffe,,Yes,Yes
26679,TODO,,Yes,Yes
26680,TODO; same with caffe_Cntk_inception_v4,,Yes,Yes
26683,TODO: CaffeEmit,,,Yes
26684,TODO: CaffeEmit(Crash); PytorchEmit(DepthwiseConv),,,Yes
26685,'inception_v3' : [CntkEmit; TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit; CoreMLEmit]; # TODO: Caffe,,Yes,Yes
26687,TODO: CntkEmit,,Yes,Yes
26688,TODO: CaffeEmit; CntkEmit,,Yes,Yes
26690,TODO,,,Yes
26691,TODO: MXNetEmit,,,Yes
26693,TODO: CaffeEmit(Crash); PytorchEmit(DepthwiseConv),,No,Yes
26694,TODO: CntkEmit,,,Yes
26696,TODO: CaffeEmit(Crash); PytorchEmit(DepthwiseConv),,,Yes
26701,TODO: KerasEmit,,,Yes
26710,'inception_resnet_v2' : [CntkEmit; TensorflowEmit; KerasEmit]; # TODO PytorchEmit,,,Yes
26712,'inception_v3' : [CntkEmit; TensorflowEmit; KerasEmit; PytorchEmit; MXNetEmit; CoreMLEmit]; # TODO: Caffe,,Yes,Yes
26714,TODO: CaffeEmit,,No,Yes
26715,'inception_resnet_v2' : [CntkEmit; TensorflowEmit; KerasEmit]; # TODO PytorchEmit,,Yes,Yes
26716,'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,,Yes
26717,TODO; same with caffe_Cntk_inception_v4,,Yes,Yes
26719,TODO: CaffeEmit(Crash),,No,Yes
26720,TODO: Caffe; Keras; and MXNet no constant layer,,Yes,Yes
26721,'inception_v3' : [CoreMLEmit; CntkEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: Caffe,,,Yes
26722,'mobilenet'    : [CoreMLEmit; KerasEmit; TensorflowEmit]; # TODO: MXNetEmit,,Yes,Yes
26724,'resnet_v1_50'      : [KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,No,Yes
26725,'resnet_v1_152'     : [KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,No,Yes
26727,'resnet_v2_152'     : [KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,No,Yes
26732,TODO: CaffeEmit(Crash),,No,Yes
26733,'inception_resnet_v2' : [CntkEmit; TensorflowEmit; KerasEmit]; # TODO PytorchEmit,,Yes,Yes
26736,# 'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,Yes,Yes
26737,TODO,,,Yes
26739,TODO: CaffeEmit(Crash),,,Yes
26741,!Alert! TODO,,Yes,Yes
26745,'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,,Yes
26747,TODO: KerasEmit(Slice Layer: https:\/\/blog.csdn.net\/lujiandong1\/article\/details\/54936185),,Yes,Yes
26748,'nasnet-a_large' : [TensorflowEmit; KerasEmit; PytorchEmit]; # TODO,,Yes,Yes
26750,flatten is needed,,Yes,Yes
26752,TODO: CaffeEmit(Crash) CntkEmit,,No,Yes
26755,TODO: Current it is only for slice,,Yes,Yes
26758,ends = [i if i else None for i in ends],,,Yes
26759,ends;,,No,Yes
26760,'voc-fcn8s'     : [OnnxEmit]; # TODO: ConvTranspose; Crop,,Yes,Yes
26761,'voc-fcn16s'    : [OnnxEmit]; # TODO: ConvTranspose; Crop,,,Yes
26762,'voc-fcn32s'    : [OnnxEmit]; # TODO: ConvTranspose; Crop,,Yes,Yes
26763,use_bias: TODO,,Yes,Yes
26765,implement asymmetric paddings by applying symmetric padding then cropping,,No,Yes
26766,'inception_v1'          : [CaffeEmit; CoreMLEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,Yes,Yes
26767,'resnet_v1_50'          : [CaffeEmit; CoreMLEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,,Yes
26768,'resnet_v1_152'         : [CaffeEmit; CoreMLEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,,Yes
26769,'resnet_v2_50'          : [CaffeEmit; CoreMLEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CntkEmit,,,Yes
26771,'mobilenet_v2_1.0_224'  : [CoreMLEmit; CntkEmit; KerasEmit; MXNetEmit; PytorchEmit; TensorflowEmit]; # TODO: CaffeEmit(Crash),,Yes,Yes
26773,'inception_v3'      : [TensorflowEmit; KerasEmit; MXNetEmit; CoreMLEmit]; # TODO: CntkEmit,,,Yes
26775,implement asymmetric paddings by applying symmetric padding then cropping,,No,Yes
26776,TODO: coredump,,,Yes
26777,TODO: CaffeEmit(Crash),,,Yes
26778,Moving averages ends up in the trainable variables collection,,No,Yes
26780,'facenet'      : [TensorflowEmit; CoreMLEmit;MXNetEmit;KerasEmit]  # TODO:,,No,Yes
26781,TODO:  only for 1D,,,Yes
26782,TODO: coreml_emit,,,Yes
26784,TODO cntk_emit,,No,Yes
26785,Temporarily disable 'xception'      : [coreml_emit; cntk_emit; mxnet_emit; pytorch_emit; tensorflow_emit]; #  TODO: Caffe(Crash) keras_emit(too slow),,Yes,Yes
26786,Temporarily disable 'facenet'               : [mxnet_emit; tensorflow_emit; keras_emit; pytorch_emit; caffe_emit]; # TODO: coreml_emit,,,Yes
26788,TODO: cntk_emit,,,Yes
26789,Temporarily disable 'facenet'           : [mxnet_emit; tensorflow_emit; keras_emit; caffe_emit] # TODO: coreml_emit,,,Yes
26791,Cannot run on Travis since it seems to consume too much memory.,,,Yes
26792,Cannot run on Travis since it seems to consume too much memory.,,Yes,Yes
26794,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26795,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
26796,Image dimensions ordering should follow the Theano convention,,,Yes
26797,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26799,Set TF random seed to improve reproducibility,,Yes,Yes
26800,Set TF random seed to improve reproducibility,,,Yes
26802,If clipping is needed; reset all values outside of [clip_min; clip_max],,,Yes
26803,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26805,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26808,A needed opening space was not found,,Yes,Yes
26810,Obviously; a newline token ends a single physical line.,,No,Yes
26811,The comment also ends a physical line,,Yes,Yes
26812,Set TF random seed to improve reproducibility,,Yes,Yes
26813,Image dimensions ordering should follow the Theano convention,,,Yes
26815,Set TF random seed to improve reproducibility,,Yes,Yes
26816,Image dimensions ordering should follow the Theano convention,,,Yes
26817,Set TF random seed to improve reproducibility,,Yes,Yes
26818,Image dimensions ordering should follow the Theano convention,,,Yes
26824,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26829,higher scores are better.,,No,Yes
26830,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26837,todo don't operate on the range [-0.5; 0.5],,Yes,Yes
26838,todo assumes y_val,,Yes,Yes
26842,Set TF random seed to improve reproducibility,,,Yes
26844,todo assumes y_val,,,Yes
26848,Image dimensions ordering should follow the TensorFlow convention,,Yes,Yes
26850,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26851,Image dimensions ordering should follow the TensorFlow convention,,,Yes
26853,Set TF random seed to improve reproducibility,,Yes,Yes
26854,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
26856,Image dimensions ordering should follow the Theano convention,,Yes,Yes
26857,Set TF random seed to improve reproducibility,,,Yes
26858,Set TF random seed to improve reproducibility,,,Yes
26859,epsilon used to be 1e-5. Maybe 0.001 solves NaN problem in deeper,,Yes,Yes
26860,else my own conv is used and no reuse is needed,,No,Yes
26861,It is more memory efficient than very deep residual network and,,Yes,Yes
26863,TODO: black box attacks,,No,Yes
26865,adjust the constant as needed,,,Yes
26866,Set TF random seed to improve reproducibility,,Yes,Yes
26867,was affected by the length of the unused adversarial generation,,Yes,Yes
26869,TODO: fix g0_inputs and gt 'y',,,Yes
26870,TODO: fix g0_inputs and gt 'y',,Yes,Yes
26874,cond_in: the boolean tensor to show if more iteration is needed for,,,Yes
26876,If clipping is needed; reset all values outside of [clip_min; clip_max],,,Yes
26877,If clipping is needed;,,Yes,Yes
26881,If clipping is needed;,,Yes,Yes
26886,If clipping is needed;,,,Yes
26887,adjust the constant as needed,,,Yes
26888,adjust the constant as needed,,No,Yes
26889,columns - second index,,,Yes
26891,load and resize adversarial image if needed,,,Yes
26894,It is more memory efficient than very deep residual network and has,,,Yes
26895,Set TF random seed to improve reproducibility,,,Yes
26896,If clipping is needed,,No,Yes
26897,Set TF random seed to improve reproducibility,,Yes,Yes
26899,Set TF random seed to improve reproducibility,,Yes,Yes
26902,"\""\""\"" || Multi-replica synchronous training ||  ||  || NOTE: This module is much more free to change than many other modules || in CleverHans. CleverHans is very conservative about changes to any || code that affects the output of benchmark tests (attacks; evaluation || methods; etc.). This module provides *model training* functionality || not *benchmarks* and thus is free to change rapidly to provide better || speed; accuracy; etc. || \""\""\""",,Yes,Yes
26904,TODO: before adding dataset augmentation; we didn't have to do this.,,Yes,Yes
26906,data_type unicode to ascii conversion (Python2 fix),,Yes,Yes
26907,data_type unicode to ascii conversion (Python2 fix),,Yes,Yes
26908,is a little better than a 10X speedup.,,,Yes
26909,"\""\""\"" || A module for hosting a variety of models of interest to the adversarial || example community. ||  || Warning: ||   This module is not nearly as conservative as the rest of CleverHans. ||   Most of CleverHans is used to create rigorous vulnerability benchmarks. ||   For example; the error rate caused by an Attack is considered to be ||   part of the API for that Attack; so we upgrade the major version number ||   whenever it changes. ||   Models in the model zoo can be tweaked regularly to improve accuracy; ||   training speed; robustness; etc. || \""\""\""",,Yes,Yes
26910,data_type unicode to ascii conversion (Python2 fix),,Yes,Yes
26912,Include an unused return so pylint understands the method signature,,Yes,Yes
26913,Include an unused return so pylint understands the method signature,,Yes,Yes
26914,For convenience; think of x as [\\alpha; \\beta],,,Yes
26916,TODO: consider whether we can use shallow copy of the lists without,,No,Yes
26917,TODO: Write this in terms of matrix multiply,,No,Yes
26918,TODO: figure out how to fix following,,No,Yes
26919,TODO: do we need to do it here or can do outside of this class?,,No,Yes
26921,Set TF random seed to improve reproducibility,,Yes,Yes
26923,This is much more efficient with data augmentation; see tutorials.,,,Yes
26924,TODO: lower priority: make it possible to initialize one attack with,,No,Yes
26926,TODO: make an interface to pass this in if it has already been computed elsewhere,,Yes,Yes
26927,TODO: refactor to avoid this duplicated method,,No,Yes
26928,"\""\""\""Functionality for making confidence reports. ||  || A confidence report is a dictionary. || Each dictionary key is the name of a type of data: ||   clean : Clean data ||   bundled : bundled adversarial examples || Each value in the dictionary contains an array of bools indicating whether || the model got each example correct and an array containing the confidence || that the model assigned to each prediction. || \""\""\""",,Yes,Yes
26929,Set TF random seed to improve reproducibility,,,Yes
26930,This is not needed to be optimal for t >= 0.5; but may as well do it,,Yes,Yes
26931,TODO: lower priority: make sure bundler won't waste time running targeted,,,Yes
26932,TODO: make an interface to pass this in if it has already been computed elsewhere,,,Yes
26933,TODO: refactor to avoid this duplicated method,,No,Yes
26934,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
26935,adjust the constant as needed,,,Yes
26936,TODO: lower priority: make sure bundler won't waste time running targeted,,No,Yes
26937,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
26938,adjust the constant as needed,,No,Yes
26939,TODO: lower priority: make sure bundler won't waste time running targeted,,,Yes
26942,"\""\""\"" || Plots a success-fail curve ( https:\/\/openreview.net\/forum?id=H1g0piA9tQ ) || Usage: || plot_success_fail_curve.py model.joblib || plot_success_fail_curve.py model1.joblib model2.joblib ||  || This script is mostly intended to rapidly visualize success-fail curves || during model development and testing. || To make nicely labeled plots formatted to fit the page \/ column of a || publication; you should probably write your own script that calls some || of the same plotting commands. || \""\""\""",,No,Yes
26944,The 1e-6 is needed to compensate for numerical error.,,Yes,Yes
26946,TODO: lower priority: make sure bundler won't waste time running targeted,,No,Yes
26947,TODO: this assert looks totally wrong.,,,Yes
26951,TODO: this assert looks totally wrong.,,Yes,Yes
26954,Include an unused return so pylint understands the method signature,,Yes,Yes
26955,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
26956,In Python 3; the `list` call is needed to convert the iterator returned by `range` into a list.,,Yes,Yes
26957,The 1e-6 is needed to compensate for numerical error.,,,Yes
26959,adjust the constant as needed,,,Yes
26960,This is not needed to be optimal for t >= 0.5; but may as well do it,,Yes,Yes
26961,TODO: this assert looks totally wrong.,,Yes,Yes
26962,1) Multiplying by 1.1 gives a huge margin of error. This should probably,,,Yes
26968,adjust the constant as needed,,,Yes
26969,these are variables to be more efficient in sending data to tf,,Yes,Yes
26970,adjust the constant as needed,,,Yes
26973,TODO: pylintrc,,,Yes
26975,TODO: Diff between new and original tutorial,,Yes,Yes
26976,Set TF random seed to improve reproducibility,,Yes,Yes
26981,Set TF random seed to improve reproducibility,,Yes,Yes
26982,For convenience; think of x as [\\alpha; \\beta],,Yes,Yes
26984,TODO support numpy tensors. Wrap x as a pytorch tensor before excuting?,,,Yes
26987,TODO case to x.dtype?,,,Yes
26988,TODO doc: make sure the caller has not passed probs by accident,,No,Yes
26990,In Python 3; the `list` call is needed to convert the iterator returned by `range` into a list.,,,Yes
26991,TODO Check the dtype,,,Yes
26992,TODO Deprecate. No need for a base class in the desired function-based API,,,Yes
26994,TODO,,Yes,Yes
26996,If clipping is needed; reset all values outside of [clip_min; clip_max],,,Yes
26997,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
27000,If clipping is needed; reset all values outside of [clip_min; clip_max],,,Yes
27002,TODO: this assert looks totally wrong.,,Yes,Yes
27003,1) Multiplying by 1.1 gives a huge margin of error. This should probably,,No,Yes
27008,generate the inputs that are needed for the lingvo model,,Yes,Yes
27009,generate the inputs that are needed for the lingvo model,,,Yes
27010,If clipping is needed; reset all values outside of [clip_min; clip_max],,,Yes
27012,TODO,,Yes,Yes
27013,TODO,,Yes,Yes
27021,TODO as of 01\/06\/2020; PyTorch does not natively support,,,Yes
27024,TODO: check if consistens with tf1 version,,No,Yes
27027,TODO: lower priority: make it possible to initialize one attack with,,No,Yes
27028,TODO: lower priority: make sure bundler won't waste time running targeted,,No,Yes
27029,TODO: make an interface to pass this in if it has already been computed,,Yes,Yes
27030,The incremental saves run on a timer. This save is needed so that the last,,No,Yes
27034,adjust the constant as needed,,No,Yes
27037,If clipping is needed;,,Yes,Yes
27038,If clipping is needed; reset all values outside of [clip_min; clip_max],,Yes,Yes
27039,In Python 3; the `list` call is needed to convert the iterator returned by `range` into a list.,,Yes,Yes
27041,This is not needed to be optimal for t >= 0.5; but may as well do it,,Yes,Yes
27042,The 1e-6 is needed to compensate for numerical error.,,Yes,Yes
27043,cond_in: the boolean tensor to show if more iteration is needed for,,,Yes
27046,TODO: this assert looks totally wrong.,,Yes,Yes
27048,TODO: let caller pass in a check_diff function as well as,,,Yes
27049,If clipping is needed,,No,Yes
27051,"\""\""\""Functionality for making confidence reports. ||  || A confidence report is a dictionary. || Each dictionary key is the name of a type of data: ||   clean : Clean data ||   bundled : bundled adversarial examples || Each value in the dictionary contains an array of bools indicating whether || the model got each example correct and an array containing the confidence || that the model assigned to each prediction. || \""\""\""",,Yes,Yes
27053,This is much more efficient with data augmentation; see tutorials.,,Yes,Yes
27054,data_type unicode to ascii conversion (Python2 fix),,,Yes
27057,For convenience; think of x as [\\alpha; \\beta],,,Yes
27059,"\""\""\"" || The Model class and related functionality. || \""\""\""",,Yes,Yes
27060,"\""\""\"" || A module for hosting a variety of models of interest to the adversarial || example community. ||  || Warning: ||   This module is not nearly as conservative as the rest of CleverHans. ||   Most of CleverHans is used to create rigorous vulnerability benchmarks. ||   For example; the error rate caused by an Attack is considered to be ||   part of the API for that Attack; so we upgrade the major version number ||   whenever it changes. ||   Models in the model zoo can be tweaked regularly to improve accuracy; ||   training speed; robustness; etc. || \""\""\""",,,Yes
27061,Center the dataset and the queries: this improves the performance of LSH quite a bit.,,,Yes
27062,It is more memory efficient than very deep residual network and has,,Yes,Yes
27065,"\""\""\"" || Multi-replica synchronous training ||  ||  || NOTE: This module is much more free to change than many other modules || in CleverHans. CleverHans is very conservative about changes to any || code that affects the output of benchmark tests (attacks; evaluation || methods; etc.). This module provides *model training* functionality || not *benchmarks* and thus is free to change rapidly to provide better || speed; accuracy; etc. || \""\""\""",,Yes,Yes
27067,Set TF random seed to improve reproducibility,,Yes,Yes
27069,Set TF random seed to improve reproducibility,,Yes,Yes
27077,If true; `todo` and `todoList` produce output; else they produce nothing.,,Yes,Yes
27078,generate the inputs that are needed for the lingvo model,,Yes,Yes
27079,generate the inputs that are needed for the lingvo model,,Yes,Yes
27082,It is more memory efficient than very deep residual network and,,,Yes
27083,Set TF random seed to improve reproducibility,,,Yes
27084,was affected by the length of the unused adversarial generation,,Yes,Yes
27085,In the matrices below: rows - attacks; columns - defenses.,,No,Yes
27086,higher scores are better.,,,Yes
27087,columns - second index,,Yes,Yes
27089,load and resize adversarial image if needed,,,Yes
27090,Number of work records to read at once,,No,Yes
27091,"\""\""\""Worker which runs all computations on Cloud VMs. ||  || Evaluation of competition is split into work pieces. One work piece is a || either evaluation of an attack on a batch of images or evaluation of a || defense on a batch of adversarial images. || All pieces of attack work are independent from each other and could be run || in parallel. Same for pieces of defense work - they are independent from each || other and could be run in parallel. But defense work could be run only after || all attack work is completed. ||  || Worker first runs all attack pieces; by querying next piece of undone work || and running it. After all attack pieces are done; worker runs all defense pieces || in a similar way. ||  || Before workers could be started; datastore has to be populated by master || with description of work to be done. See master.py for details. ||  || NOTE: Worker is designed to run on linux machine with NVidia docker || installed. Worker generally needs administrative privilege to run properly. || Also worker relies on very specific directory structure created in home || directory. That's why it's highly recommended to run worker only in VM. || \""\""\""",,Yes,Yes
27092,Set TF random seed to improve reproducibility,,Yes,Yes
27095,Set TF random seed to improve reproducibility,,,Yes
27096,"\""\""\"" || Plots a success-fail curve ( https:\/\/openreview.net\/forum?id=H1g0piA9tQ ) || Usage: || plot_success_fail_curve.py model.joblib || plot_success_fail_curve.py model1.joblib model2.joblib ||  || This script is mostly intended to rapidly visualize success-fail curves || during model development and testing. || To make nicely labeled plots formatted to fit the page \/ column of a || publication; you should probably write your own script that calls some || of the same plotting commands. || \""\""\""",,,Yes
27098,TODO: change this to use standard cleverhans label conventions,,No,Yes
27099,Initialize some values needed for binary search on const,,,Yes
27100,TODO as of 01\/06\/2020; PyTorch does not natively support,,Yes,Yes
27101,Initialize some values needed for the inner loop,,,Yes
27102,TODO(beam2d): Implement in-place version.,,Yes,Yes
27103,TODO(beam2d): Implement GPU forward\/backward,,Yes,Yes
27104,TODO(beam2d): Fix it!,,,Yes
27106,TODO(beam2d): Better kernel,,Yes,Yes
27107,TODO(beam2d): Implement CPU version.,,,Yes
27108,rows; columns. The strides are implicitly defined,,,Yes
27112,algorithm regardless how much workspace is needed to execute it.,,No,Yes
27114,Workaround: the original GPUArray.copy does not use the user-defined,,,Yes
27116,TODO(beam2d): Fix this ugly solution,,Yes,Yes
27117,If true; `todo` and `todoList` produce output; else they produce nothing.,,,Yes
27119,cover_all mode is needed also for average pooling,,Yes,Yes
27120,TODO: checking nobias by means of b is not smart?,,No,Yes
27124,TODO(beam2d0: Implement it,,No,Yes
27129,TODO(beam2d): Implement it,,Yes,Yes
27130,"I think this order is a bug of NumPy; though we select this \""buggy\""",,Yes,Yes
27132,TODO(beam2d): Implement it,,,Yes
27134,TODO(beam2d): Implement it,,Yes,Yes
27135,TODO(okuta): Fix this,,Yes,Yes
27136,TODO(okuta): Fix this,,Yes,Yes
27137,Workaround: the original GPUArray.copy does not use the user-defined,,No,Yes
27140,TODO(okuta): Fix document,,Yes,Yes
27143,TODO(beam2d): Fix this ugly solution,,,Yes
27144,Workaround: the original GPUArray.copy does not use the user-defined,,No,Yes
27146,TODO(beam2d): Fix this ugly solution,,,Yes
27148,directly use the original GPUArray class; we choose easy and ugly solution,,,Yes
27149,TODO(beam2d): Fix this ugly solution,,,Yes
27151,# TODO(beam2d): Implement it,,,Yes
27153,# TODO(beam2d): Implement it,,Yes,Yes
27154,# TODO(beam2d): Implement it,,,Yes
27157,# TODO(beam2d): Implement it,,Yes,Yes
27158,# TODO(beam2d): Implement it,,,Yes
27159,# TODO(beam2d): Implement it,,,Yes
27163,TODO(beam2d): Implement it,,Yes,Yes
27165,TODO(beam2d): Implement __array_interface__,,,Yes
27167,TODO(okuta): Implement itemset,,,Yes
27168,TODO(okuta): Implement tobytes,,Yes,Yes
27169,TODO(okuta): Implement byteswap,,Yes,Yes
27170,TODO(okuta): Implement setflags,,,Yes
27172,TODO(okuta): Implement put,,,Yes
27173,TODO(okuta): Implement repeat,,,Yes
27174,TODO(okuta): Implement choose,,,Yes
27175,TODO(okuta): Implement sort,,Yes,Yes
27176,TODO(okuta): Implement argsort,,Yes,Yes
27177,TODO(okuta): Implement partition,,Yes,Yes
27180,TODO(okuta): Implement round,,Yes,Yes
27181,TODO(okuta): Implement cumsum,,,Yes
27185,TODO(okuta): Implement unpackbits,,Yes,Yes
27186,TODO(okuta): Implement asmatrix,,Yes,Yes
27187,TODO(okuta): Implement frombuffer,,Yes,Yes
27188,TODO(okuta): Implement fromfile,,,Yes
27190,TODO(okuta): Implement fromstring,,Yes,Yes
27192,TODO(okuta): Implement vander,,Yes,Yes
27193,TODO(okuta): Implement bmat,,Yes,Yes
27194,# TODO(beam2d): Implement it,,Yes,Yes
27195,TODO(okuta): Implement indices,,,Yes
27196,TODO(okuta): Implement ix_,,,Yes
27197,TODO(okuta): Implement ravel_multi_index,,,Yes
27199,TODO(okuta): Implement diag_indices,,,Yes
27201,TODO(okuta): Implement mask_indices,,Yes,Yes
27202,TODO(okuta): Implement tril_indices,,Yes,Yes
27203,TODO(okuta): Implement tril_indices_from,,Yes,Yes
27204,TODO(okuta): Implement triu_indices,,Yes,Yes
27206,TODO(okuta): Implement choose,,,Yes
27207,TODO(okuta): Implement place,,Yes,Yes
27208,TODO(okuta): Implement put,,,Yes
27211,TODO(okuta): Implement loadtxt,,Yes,Yes
27213,TODO(okuta): Implement genfromtxt,,Yes,Yes
27216,TODO(okuta): Implement cholesky,,Yes,Yes
27218,TODO(okuta): Implement svd,,Yes,Yes
27219,TODO(okuta): Implement eig,,Yes,Yes
27221,TODO(okuta): Implement eigvals,,,Yes
27223,TODO(okuta): Implement norm,,Yes,Yes
27226,# TODO(beam2d): Implement it,,Yes,Yes
27227,TODO(okuta): Implement einsum,,Yes,Yes
27229,TODO(okuta): Implement tensorsolve,,,Yes
27231,TODO(okuta): Implement inv,,Yes,Yes
27232,TODO(okuta): Implement pinv,,,Yes
27235,# TODO(beam2d): Implement it,,Yes,Yes
27236,TODO(okuta): Implement isneginf,,Yes,Yes
27237,TODO(okuta): Implement all,,Yes,Yes
27238,TODO(okuta): Implement any,,,Yes
27239,TODO(okuta): Implement iscomplex,,Yes,Yes
27242,TODO(okuta): Implement isreal,,,Yes
27243,TODO(okuta): Implement isrealobj,,,Yes
27244,TODO(okuta): Implement delete,,Yes,Yes
27245,TODO(okuta): Implement insert,,Yes,Yes
27247,TODO(okuta): Implement resize,,,Yes
27248,TODO(okuta): Implement trim_zeros,,,Yes
27251,TODO(okuta): Implement asfortranarray,,Yes,Yes
27253,TODO(okuta): Implement asscalar,,,Yes
27257,TODO(okuta): Implement roll,,Yes,Yes
27261,TODO(okuta): Implement convolve,,Yes,Yes
27262,TODO(okuta): Implement nan_to_num,,Yes,Yes
27267,TODO(okuta): Implement cumprod,,Yes,Yes
27270,TODO(okuta): Implement shuffle,,Yes,Yes
27271,TODO(okuta): Implement permutation,,,Yes
27273,TODO(okuta): Implement nanargmin,,,Yes
27274,TODO(okuta): Implement argwhere,,,Yes
27275,TODO(okuta): Implement where,,Yes,Yes
27278,TODO(okuta): Implement sort,,,Yes
27281,TODO(okuta): Implement msort,,,Yes
27282,TODO(okuta): Implement sort_complex,,,Yes
27283,TODO(okuta): Implement partition,,Yes,Yes
27284,TODO(okuta): Implement argpartition,,,Yes
27285,TODO(okuta): Implement corrcoef,,,Yes
27286,TODO(okuta): Implement correlate,,,Yes
27287,TODO(okuta): Implement cov,,Yes,Yes
27288,TODO(okuta): Implement histogram,,Yes,Yes
27289,TODO(okuta): Implement histogram2d,,,Yes
27292,TODO(okuta): Implement digitize,,,Yes
27293,TODO(okuta): Implement median,,Yes,Yes
27295,TODO(okuta): Implement nanmin,,,Yes
27298,fixme: batch normarization of padded data.,,,Yes
27299,TODO(okuta): Implement randint,,,Yes
27300,TODO(okuta): Implement random_integers,,,Yes
27301,TODO(beam2d): Implement __array_interface__,,Yes,Yes
27303,TODO(okuta): Implement itemset,,,Yes
27304,TODO(okuta): Implement tostring,,Yes,Yes
27305,TODO(okuta): Implement tobytes,,Yes,Yes
27306,TODO(okuta): Implement byteswap,,Yes,Yes
27307,TODO(okuta): Implement getfield,,Yes,Yes
27311,TODO(okuta): Implement repeat,,,Yes
27312,TODO(okuta): Implement choose,,,Yes
27316,TODO(okuta): Implement argpartition,,Yes,Yes
27317,TODO(okuta): Implement searchsorted,,Yes,Yes
27318,TODO(okuta): Implement nonzero,,,Yes
27320,TODO(okuta): Implement ptp,,Yes,Yes
27321,TODO(okuta): Implement round,,Yes,Yes
27322,TODO(okuta): Implement cumsum,,Yes,Yes
27324,TODO(okuta): Implement __array_wrap__,,,Yes
27325,TODO(okuta): Implement __getslice__,,,Yes
27328,Hack for Read the Docs,,Yes,Yes
27332,TODO(okuta): Implement tostring,,,Yes
27335,TODO(okuta): Implement getfield,,Yes,Yes
27336,TODO(okuta): Implement setflags,,Yes,Yes
27338,TODO(okuta): Implement put,,,Yes
27339,TODO(okuta): Implement repeat,,,Yes
27340,TODO(okuta): Implement choose,,Yes,Yes
27341,TODO(okuta): Implement sort,,,Yes
27342,TODO(okuta): Implement argsort,,,Yes
27344,TODO(okuta): Implement argpartition,,Yes,Yes
27345,TODO(okuta): Implement searchsorted,,,Yes
27346,TODO(okuta): Implement nonzero,,,Yes
27347,TODO(okuta): Implement compress,,,Yes
27348,TODO(okuta): Implement ptp,,Yes,Yes
27350,TODO(okuta): Implement cumsum,,,Yes
27351,TODO(okuta): Implement cumprod,,Yes,Yes
27353,TODO(okuta): Implement __getslice__,,Yes,Yes
27354,TODO(okuta): Implement __setslice__,,,Yes
27357,TODO(okuta): Implement repeat,,Yes,Yes
27360,TODO(okuta): Implement itemset,,,Yes
27363,TODO(okuta): Implement byteswap,,Yes,Yes
27365,TODO(okuta): Implement setflags,,,Yes
27368,TODO(okuta): Implement choose,,,Yes
27371,TODO(okuta): Implement partition,,Yes,Yes
27372,TODO(okuta): Implement argpartition,,Yes,Yes
27373,TODO(okuta): Implement searchsorted,,Yes,Yes
27376,TODO(okuta): Implement ptp,,,Yes
27379,TODO(okuta): Implement cumprod,,Yes,Yes
27383,TODO(okuta): Implement __contains__,,Yes,Yes
27384,Hack for Read the Docs,,Yes,Yes
27386,move to front.,,Yes,Yes
27388,move to back.,,,Yes
27389,move to front.,,Yes,Yes
27390,fix samples,,,Yes
27392,TODO: How do we treat over-complete bases case?,,No,Yes
27394,TODO: old name,,,Yes
27397,TODO(okuta): Implement nonzero,,Yes,Yes
27398,TODO(okuta): Implement flatnonzero,,Yes,Yes
27399,TODO math,,No,Yes
27400,As a workaround; we wrap the function and invoke it in __call__ method.,,,Yes
27401,As a workaround; we wrap the function and invoke it in __call__ method.,,Yes,Yes
27403,TODO(okuta): Implement ix_,,,Yes
27404,TODO(okuta): Implement ix_,,,Yes
27405,TODO(okuta): Implement ix_,,,Yes
27406,TODO(okuta): Implement nanmin,,,Yes
27407,TODO(okuta): Implement nanmax,,Yes,Yes
27408,Hack for Read the Docs,,Yes,Yes
27409,Hack for Read the Docs,,Yes,Yes
27411,tuple() here is needed to avoid conflicts with add_param,,No,Yes
27413,This is a workaround for Anaconda.,,,Yes
27416,TODO(unno): Fix fill value,,No,Yes
27417,fix,,,Yes
27418,fix,,,Yes
27420,provided functions are insufficient to implement cupy.linalg,,Yes,Yes
27421,"\""\""\""Convnet example using CIFAR10 or CIFAR100 dataset ||  || This code is a custom loop version of train_cifar.py. That is; we train || models without using the Trainer class in chainer and instead write a || training loop that manually computes the loss of minibatches and || applies an optimizer to update the model. || \""\""\""",,,Yes
27422,"\""\""\""Fully-connected neural network example using MNIST dataset ||  || This code is a custom loop version of train_mnist.py. That is; we train || models without using the Trainer class in chainer and instead write a || training loop that manually computes the loss of minibatches and || applies an optimizer to update the model. || \""\""\""",,,Yes
27423,TODO(okuta): Implement fix,,Yes,Yes
27424,tuple() here is needed to avoid conflicts with add_param,,No,Yes
27425,Todo: check this is ok.,,No,Yes
27426,tuple() here is needed to avoid conflicts with add_param,,No,Yes
27428,TODO(okuta): Implement sort,,,Yes
27429,tuple() here is needed to avoid conflicts with add_param,,No,Yes
27432,tuple() here is needed to avoid conflicts with add_param,,,Yes
27433,tuple() here is needed to avoid conflicts with add_param,,,Yes
27434,To fix samples; use fixed samples.,,Yes,Yes
27435,fix samples,,No,Yes
27436,Needed for gradient check to be possible,,No,Yes
27437,Hack for making gradient check treat r and d as true,,No,Yes
27438,Freezing the update of running statistics is needed in order to,,,Yes
27439,Freezing the update of running statistics is needed in order to,,No,Yes
27440,Do not hold reference to this thread. Otherwise an unused iterator,,Yes,Yes
27442,"Autosummary extracts the \""first sentence\""; which ends at the first period",,Yes,Yes
27444,"Autosummary extracts the \""first sentence\""; which ends at the first period",,Yes,Yes
27447,"Autosummary extracts the \""first sentence\""; which ends at the first period",,Yes,Yes
27448,Work-around for NumPy's bug?,,,Yes
27450,Work-around for NumPy's bug?,,Yes,Yes
27451,TODO(beam2d): FIX IT,,Yes,Yes
27454,training_length is needed to set,,,Yes
27455,Work-around for NumPy's bug?,,Yes,Yes
27458,Work-around for NumPy's bug?,,Yes,Yes
27459,Load the dataset to obtain the vocabulary; which is needed to convert,,Yes,Yes
27464,XXX: WIP,,,Yes
27465,use the convention that any output arrays are supplied,,Yes,Yes
27466,fixme: move decorator to FunctionNode,,,Yes
27468,fixme: check that all array copies use x[:] = y.,,,Yes
27469,fixme: clean up documentation and API.,,,Yes
27471,fixme: remove underscore.,,,Yes
27472,This is needed so that the copy from input variable to static,,Yes,Yes
27473,fixme: remove undescore.,,,Yes
27475,fixme: bug:,,,Yes
27476,Retain all inputs? (fixme),,No,Yes
27480,XXX: WIP,,Yes,Yes
27486,todo: modify optimizers so that they never attempt to change the grad\/data,,,Yes
27487,todo: optimize later to prevent unnecessary allocation.,,No,Yes
27489,todo (vogel): optimize to prevent unnecessary allocation.,,No,Yes
27490,use the convention that any output arrays are supplied,,Yes,Yes
27492,todo (vogel): make a more optimized version that avoids,,,Yes
27494,todo: this performs unnecessary memory allocations.,,No,Yes
27496,use the convention that any output arrays are supplied,,,Yes
27497,fixme: remove after debug,,,Yes
27500,in_vars = tuple([chainer.as_variable(x) for x in in_vars]) # fixme: this sets requires_grad=False,,No,Yes
27501,fixme: remove.,,,Yes
27505,fixme: remove this? no longer used?,,Yes,Yes
27506,fixme: inform schedule manager that forward pass has finished.,,Yes,Yes
27508,(this is needed so that links like BN; dropout will work correctly),,Yes,Yes
27509,fixme_sum = np.sum(self._in_arrays[n]),,Yes,Yes
27510,"fixme: rename \""func\"" -> \""chain\""",,Yes,Yes
27513,fixme: inform schedule manager that forward pass has finished.,,Yes,Yes
27517,todo: optimize later to prevent unnecessary allocation. It seems,,,Yes
27519,Code below would be more efficient but does not work,,Yes,Yes
27522,todo (vogel): Also check if minibatch size has changed and clear schedules.,,Yes,Yes
27523,fixme: make default True after memory bug\/slow garbage collection is fixed.,,,Yes
27525,todo (vogel),,No,Yes
27526,todo: consider a modified ptb or char-rnn example in which the LSTM node is written,,Yes,Yes
27527,graph optimizations to get improved runtime performance.,,,Yes
27531,FIXME,,Yes,Yes
27532,arguments. This is workaround for limitation in iDeep internal,,Yes,Yes
27535,move to back.,,,Yes
27536,move to front.,,Yes,Yes
27538,move to front.,,,Yes
27539,TODO(niboshi): deprecate sep,,,Yes
27540,move to back.,,,Yes
27541,move to front.,,Yes,Yes
27542,move to back.,,,Yes
27543,move to front.,,Yes,Yes
27544,fixme: remove after debug,,No,Yes
27545,fixme: in_vars not used any more,,,Yes
27547,self._in_arrays = tuple([x.data.copy() for x in in_vars]) # fixme: remove; because not used,,Yes,Yes
27548,fixme: redundant; since the same arrays are in _local_in_vars,,Yes,Yes
27549,fixme: not used? remove it?,,,Yes
27551,out_vars.backward() #fixme,,No,Yes
27553,fixme: remove unused function,,,Yes
27559,fixme: remove check after debug.,,,Yes
27561,new_gxs = func.backward_accumulate(input_indexes; gys; gxs) # fixme: bug: should be tuple; not list!,,Yes,Yes
27563,fixme: remove?,,No,Yes
27565,fixme: clean up,,Yes,Yes
27567,todo: should double-backprop mode be configurable,,Yes,Yes
27569,todo: Note that instead of copying the data from,,No,Yes
27570,fixme: remove check after debug.,,,Yes
27573,todo (vogel): make sure this is necessary.,,Yes,Yes
27577,todo (vogel): make sure this is necessary.,,Yes,Yes
27578,fixme: remove check after debug.,,,Yes
27579,((); 0); # TODO(sonots): Fix compatibility,,Yes,Yes
27580,Work-around for NumPy's bug?,,Yes,Yes
27583,use the convention that any output arrays are supplied,,Yes,Yes
27586,"\""\""\""Sample script of recurrent neural network language model. ||  || This code is ported from the following implementation written in Torch. || https:\/\/github.com\/tomsercu\/lstm ||  || This code is a custom loop version of train_ptb.py. That is; we train || models without using the Trainer class in chainer and instead write a || training loop that manually computes the loss of minibatches and || applies an optimizer to update the model. || \""\""\""",,,Yes
27589,TODO(sonots): Fix type compatibility,,Yes,Yes
27591,TODO(sonots): Fix type compatibility,,Yes,Yes
27596,TODO(beam2d): implement len,,Yes,Yes
27597,TODO(beam2d): implement mean,,Yes,Yes
27599,TODO(niboshi): Implement diag as a view and remove strides_check=False.,,Yes,Yes
27600,TODO(niboshi): Implement diag as a view and remove strides_check=False.,,Yes,Yes
27601,TODO(niboshi): Implement diag as a view and remove strides_check=False.,,,Yes
27603,TODO(beam2d): Think better way to make multiple different arrays,,Yes,Yes
27605,TODO(sonots): Fix type compatibility,,Yes,Yes
27607,todo (vogel): make sure this is necessary.,,Yes,Yes
27608,fixme: need to check the dtype of inputs when checking the type signature for static schedules.,,Yes,Yes
27610,do not change from iteration to iteration. This is needed because some existing parts of Chainer;,,,Yes
27611,todo: We can allow it to return tuple of arrays in the future.,,Yes,Yes
27612,todo: rename to StaticSchedule. (the Function part makes it sound like,,Yes,Yes
27613,todo: Consider creating _schedule_funcs as a post-processing step.,,,Yes
27616,todo: We can potentially reduce memory usage by freeing memory,,Yes,Yes
27619,fixme: remove this old version,,Yes,Yes
27620,todo: Note that instead of copying the data from,,,Yes
27625,assert retain_grad is True # fixme: remove check after debug.,,Yes,Yes
27626,assert retain_grad is True # fixme: remove check after debug.,,Yes,Yes
27629,might be needed during the backward() method to compute gradients.,,,Yes
27635,fixme: Also; we should remember to set all references in self._in_vars to None after,,Yes,Yes
27637,fixme: This is probably the bug. We need to add ahook function to backward to set these references.,,No,Yes
27641,fixme: remove check?,,No,Yes
27643,TODO(hvy): Fix after supporting correct dtype promotion.,,Yes,Yes
27645,todo: How about only supporting,,No,Yes
27646,fixme: is this needed?,,,Yes
27647,fixme: debug,,,Yes
27648,of a StaticScheduleFunction (maybe this solution is simplest?) Yes; maybe this is best.,,Yes,Yes
27651,fixme: why call ._out_vars? why not a method?,,No,Yes
27653,fixme: debug,,,Yes
27654,fixme: only this one fails.,,,Yes
27655,use the convention that any output arrays are supplied,,Yes,Yes
27656,Work-around for NumPy's bug?,,Yes,Yes
27657,TODO(niboshi): better error messages,,,Yes
27658,Return arrays wrong way around,,No,Yes
27659,Work-around for NumPy's bug?,,,Yes
27660,use the convention that any output arrays are supplied,,Yes,Yes
27661,todo: Ideally; we would like to update the reference in,,Yes,Yes
27662,freed. If it is not deleted; assume that it is still needed and,,Yes,Yes
27664,todo: consider only appending a weak reference so,,Yes,Yes
27665,we can know when it is no longer needed and add a,,Yes,Yes
27668,note: this is not currently needed.,,,Yes
27669,todo: possible memory leak when need_copy False is allowed?,,No,Yes
27671,todo: set in initializer as keyword arg?,,,Yes
27672,todo: set device id,,,Yes
27677,todo (vogel): enable this eventually. For now; it,,Yes,Yes
27678,casuses some needed variables to be set to None,,Yes,Yes
27679,TODO(beam2d): implement mean,,Yes,Yes
27680,TODO(beam2d): implement len,,,Yes
27681,When no clipping is needed; skip the clipping on CPU and,,Yes,Yes
27684,TODO(beam2d): implement mean,,,Yes
27685,TODO(beam2d): implement len,,Yes,Yes
27687,TODO: using cupy.random.beta,,Yes,Yes
27688,TODO(beam2d): implement mean,,Yes,Yes
27690,TODO(beam2d): implement len,,Yes,Yes
27691,TODO: fix cupy.random.dirichlet to behave same as numpy.,,Yes,Yes
27694,TODO(beam2d): implement mean,,Yes,Yes
27696,TODO(beam2d): implement mean,,Yes,Yes
27698,TODO(beam2d): implement len,,Yes,Yes
27701,ChainerMN diff (2\/2) ends,,No,Yes
27705,use the convention that any output arrays are supplied,,Yes,Yes
27706,use the convention that any output arrays are supplied,,Yes,Yes
27709,TODO(hvy): Move this function to backend?,,Yes,Yes
27710,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27712,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27713,TODO(sonots): Implement for ChainerX,,Yes,Yes
27716,TODO,,Yes,Yes
27717,TODO,,,Yes
27718,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27720,TODO(sonots): Fix argmin to get aborted,,Yes,Yes
27721,TODO(sonots): Remove this workaround after numerical_grad is,,,Yes
27722,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27723,TODO(niboshi): Perhaps device name (as str) can also be acceptable,,Yes,Yes
27724,TODO(niboshi): Fix it,,,Yes
27725,TODO(hvy): Move this function to backend?,,Yes,Yes
27726,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,Yes,Yes
27727,TODO(niboshi): Perhaps device name (as str) can also be acceptable,,,Yes
27728,TODO(niboshi): Perhaps device name (as str) can also be acceptable,,Yes,Yes
27729,TODO(hvy): Move this function to backend?,,Yes,Yes
27730,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27731,TODO(niboshi): Perhaps backend.to_device should support integers,,,Yes
27732,TODO(niboshi): This is a workaround because get_device_from_array,,,Yes
27733,Work-around for NumPy's bug?,,Yes,Yes
27736,TODO(niboshi): Perhaps device name (as str) can also be acceptable,,Yes,Yes
27739,implementing those functions in more efficient manner.,,,Yes
27740,Populates workaround functions in the chainerx namespace,,Yes,Yes
27742,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,,Yes
27743,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,,Yes
27744,TODO(beam2d): implement mean,,Yes,Yes
27745,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
27746,TODO(beam2d): implement mean,,Yes,Yes
27747,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
27748,A workaround for processes crash should be done before making,,,Yes
27749,TODO(beam2d): implement mean,,,Yes
27750,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
27751,TODO(niboshi): This is a temporary workaround for,,Yes,Yes
27752,TODO(beam2d): implement mean,,Yes,Yes
27753,TODO(niboshi): Remove this workaround after ChainerX supports,,Yes,Yes
27754,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,Yes,Yes
27755,TODO(beam2d): implement mean,,Yes,Yes
27756,TODO(niboshi): Remove this workaround after ChainerX supports,,,Yes
27758,TODO(hvy): Move this function to backend?,,Yes,Yes
27761,TODO(beam2d): implement mean,,,Yes
27763,TODO(beam2d): implement mean,,,Yes
27766,Definition of __exit__ is needed to raise a custom error on,,Yes,Yes
27769,Definition of __exit__ is needed to raise a custom error on,,Yes,Yes
27770,TODO(niboshi): Fix this logic for updating self._device,,Yes,Yes
27773,TODO(sonots): Fix to use using_device() if it becomes available,,Yes,Yes
27774,TODO(niboshi): Temporarily disabled for chainerx. Fix it.,,Yes,Yes
27776,TODO(niboshi): Maybe better to deprecate the property.,,Yes,Yes
27777,TODO(hvy): Move this function to backend?,,,Yes
27779,TODO(niboshi): Fix this logic for updating self._device,,,Yes
27781,Definition of __exit__ is needed to raise a custom error on,,,Yes
27782,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,Yes,Yes
27783,TODO(sonots): Temporarily disabled for chainerx. Fix it.,,,Yes
27785,TODO(kmaehashi) fix circular imports around `chainer.backends.*`,,Yes,Yes
27789,TODO(niboshi): This is a temporary workaround to keep backward,,,Yes
27790,TODO(beam2d): implement mean,,,Yes
27792,TODO(sonots): Implement in C++,,Yes,Yes
27794,TODO(sonots): Move advanced indexing fallback to another method,,Yes,Yes
27797,TODO(niboshi): Remove this workaround after ChainerX supports,,Yes,Yes
27798,TODO(sonots): Temporarily disabled for chainerx. Fix it.,,,Yes
27805,TODO(niboshi): Remove this workaround after ChainerX supports,,Yes,Yes
27806,TODO(hvy): Implement multi-add with chainerx.ndarrays.,,Yes,Yes
27810,"What we really want to return is \""Steve Smith\"".",,No,Yes
27813,### NOTE kpi.py should shared in models in some way!!!!,,,Yes
27814,### NOTE kpi.py should shared in models in some way!!!!,,,Yes
27815,### NOTE kpi.py should shared in models in some way!!!!,,Yes,Yes
27816,"What we really want to return is \""Steve Smith\"".",,No,Yes
27817,The convention in BERT\/ERNIE is:,,No,Yes
27819,''' || Evaluation script for CMRC 2018 || version: v5 || Note:  || v5 formatted output; add usage description || v4 fixed segmentation issues || ''',,Yes,Yes
27821,TODO init,,Yes,Yes
27822,"What we really want to return is \""Steve Smith\"".",,,Yes
27823,F.io.load_program_state(param_path) #buggy in dygraph.gurad; push paddle to fix,,Yes,Yes
27825,maybe not?,,No,Yes
27826,FIXME:remove this,,No,Yes
27827,columns,,No,Yes